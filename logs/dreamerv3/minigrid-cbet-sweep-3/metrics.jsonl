{"step": 1560, "time": 104.0486330986023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.06637287139893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.45532894134521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.46360301971436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.4713294506073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.47967743873596, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.4890296459198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.49745345115662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 234.64983677864075, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3848876953125, "train/action_min": 0.0, "train/action_std": 2.2461841106414795, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006080919411033392, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.0756771564483643, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.7462356090545654, "train/cont_loss_std": 0.30274733901023865, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.484375, "train/cont_pos_loss": 0.7462356090545654, "train/cont_pred": 0.4946613907814026, "train/cont_rate": 1.0, "train/dyn_loss_mean": 11.256460189819336, "train/dyn_loss_std": 0.3996845781803131, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.501489639282227, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 25024.7890625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4931.86962890625, "train/image_loss_std": 37.63844680786133, "train/model_loss_mean": 4944.9111328125, "train/model_loss_std": 37.61184310913086, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 49449112.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.911950945854187, "train/policy_entropy_max": 1.911950945854187, "train/policy_entropy_mean": 1.5791573524475098, "train/policy_entropy_min": 0.681738555431366, "train/policy_entropy_std": 0.1570860743522644, "train/policy_logprob_mag": 4.781064510345459, "train/policy_logprob_max": -0.16680708527565002, "train/policy_logprob_mean": -1.5849798917770386, "train/policy_logprob_min": -4.781064510345459, "train/policy_logprob_std": 0.7817347049713135, "train/policy_randomness_mag": 0.9825484752655029, "train/policy_randomness_max": 0.9825484752655029, "train/policy_randomness_mean": 0.8115264177322388, "train/policy_randomness_min": 0.35034433007240295, "train/policy_randomness_std": 0.0807262733578682, "train/post_ent_mag": 105.65577697753906, "train/post_ent_max": 105.65577697753906, "train/post_ent_mean": 105.23209381103516, "train/post_ent_min": 104.89312744140625, "train/post_ent_std": 0.1576177030801773, "train/prior_ent_mag": 106.29686737060547, "train/prior_ent_max": 106.29686737060547, "train/prior_ent_mean": 105.44485473632812, "train/prior_ent_min": 104.38668060302734, "train/prior_ent_std": 0.3217611014842987, "train/rep_loss_mean": 11.256460189819336, "train/rep_loss_std": 0.3996845781803131, "train/reward_avg": 0.00021578592713922262, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.589545715636632e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.7496537566184998, "report/cont_loss_std": 0.30348384380340576, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.4814453125, "report/cont_pos_loss": 0.7496537566184998, "report/cont_pred": 0.4929741621017456, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.388032913208008, "report/dyn_loss_std": 0.4452286660671234, "report/image_loss_mean": 4929.65087890625, "report/image_loss_std": 39.15084457397461, "report/model_loss_mean": 4942.775390625, "report/model_loss_std": 39.130741119384766, "report/post_ent_mag": 105.6783447265625, "report/post_ent_max": 105.6783447265625, "report/post_ent_mean": 105.24514770507812, "report/post_ent_min": 104.67320251464844, "report/post_ent_std": 0.16126999258995056, "report/prior_ent_mag": 106.18562316894531, "report/prior_ent_max": 106.18562316894531, "report/prior_ent_mean": 105.4097671508789, "report/prior_ent_min": 104.34539794921875, "report/prior_ent_std": 0.2964206337928772, "report/rep_loss_mean": 11.388032913208008, "report/rep_loss_std": 0.4452286660671234, "report/reward_avg": 0.00021578592713922262, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.589545715636632e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.727626383304596, "eval/cont_loss_std": 0.2650434970855713, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.49609375, "eval/cont_pos_loss": 0.727626383304596, "eval/cont_pred": 0.49924787878990173, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.379919052124023, "eval/dyn_loss_std": 0.4175277054309845, "eval/image_loss_mean": 4926.5283203125, "eval/image_loss_std": 42.41277313232422, "eval/model_loss_mean": 4939.62548828125, "eval/model_loss_std": 42.37300109863281, "eval/post_ent_mag": 105.74424743652344, "eval/post_ent_max": 105.74424743652344, "eval/post_ent_mean": 105.2237319946289, "eval/post_ent_min": 104.89942932128906, "eval/post_ent_std": 0.1507093608379364, "eval/prior_ent_mag": 106.44182586669922, "eval/prior_ent_max": 106.44182586669922, "eval/prior_ent_mean": 105.43311309814453, "eval/prior_ent_min": 104.33372497558594, "eval/prior_ent_std": 0.29448026418685913, "eval/rep_loss_mean": 11.379919052124023, "eval/rep_loss_std": 0.4175277054309845, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.6038329847149954e-05, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.812465940202986e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4227954338961712e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1048146656581333e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 159.00744581222534, "timer/env.step_count": 196.0, "timer/env.step_total": 1.7021853923797607, "timer/env.step_frac": 0.010705067197858778, "timer/env.step_avg": 0.00868461934887633, "timer/env.step_min": 0.007733821868896484, "timer/env.step_max": 0.015295982360839844, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.09891867637634277, "timer/replay._sample_frac": 0.0006221009077345822, "timer/replay._sample_avg": 0.0008832024676459176, "timer/replay._sample_min": 0.0003592967987060547, "timer/replay._sample_max": 0.0029113292694091797, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.283947467803955, "timer/agent.save_frac": 0.01436377684162733, "timer/agent.save_avg": 2.283947467803955, "timer/agent.save_min": 2.283947467803955, "timer/agent.save_max": 2.283947467803955, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.29551386833191, "timer/agent.policy_frac": 0.14021679144925747, "timer/agent.policy_avg": 0.07688108230459278, "timer/agent.policy_min": 0.009971857070922852, "timer/agent.policy_max": 16.895809173583984, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.218650817871094e-05, "timer/dataset_train_frac": 2.0242138985567093e-07, "timer/dataset_train_avg": 3.218650817871094e-05, "timer/dataset_train_min": 3.218650817871094e-05, "timer/dataset_train_max": 3.218650817871094e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 94.20582675933838, "timer/agent.train_frac": 0.5924617320788089, "timer/agent.train_avg": 94.20582675933838, "timer/agent.train_min": 94.20582675933838, "timer/agent.train_max": 94.20582675933838, "timer/agent.report_count": 2.0, "timer/agent.report_total": 33.63613033294678, "timer/agent.report_frac": 0.21153808339685093, "timer/agent.report_avg": 16.81806516647339, "timer/agent.report_min": 8.371958017349243, "timer/agent.report_max": 25.264172315597534, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.8623809814453125e-05, "timer/dataset_eval_frac": 2.429056678268051e-07, "timer/dataset_eval_avg": 3.8623809814453125e-05, "timer/dataset_eval_min": 3.8623809814453125e-05, "timer/dataset_eval_max": 3.8623809814453125e-05}
{"step": 2312, "time": 258.5975799560547, "episode/length": 288.0, "episode/score": 0.0761102925148407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0761102925148407}
{"step": 2312, "time": 258.6058392524719, "episode/length": 288.0, "episode/score": 0.07570632068200212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07570632068200212}
{"step": 2312, "time": 258.6138355731964, "episode/length": 288.0, "episode/score": 0.07428587713275192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07428587713275192}
{"step": 2312, "time": 258.6212275028229, "episode/length": 288.0, "episode/score": 0.10123531849194478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10123531849194478}
{"step": 2312, "time": 258.6286287307739, "episode/length": 288.0, "episode/score": 0.08600458565410918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08600458565410918}
{"step": 2312, "time": 258.6366765499115, "episode/length": 288.0, "episode/score": 0.07132721548509835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07132721548509835}
{"step": 2312, "time": 258.64415740966797, "episode/length": 288.0, "episode/score": 0.061575841962849154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061575841962849154}
{"step": 2312, "time": 258.6515564918518, "episode/length": 288.0, "episode/score": 0.07338250769566912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07338250769566912}
{"step": 4544, "time": 330.7078700065613, "episode/length": 278.0, "episode/score": 0.23128378521096238, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.10003379233558007}
{"step": 4624, "time": 333.3234512805939, "episode/length": 288.0, "episode/score": 0.07410118790039633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07410118790039633}
{"step": 4624, "time": 333.33347940444946, "episode/length": 288.0, "episode/score": 0.05654479249687938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05654479249687938}
{"step": 4624, "time": 333.3432331085205, "episode/length": 288.0, "episode/score": 0.08095428806518612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08095428806518612}
{"step": 4624, "time": 333.35188150405884, "episode/length": 288.0, "episode/score": 0.06293037156160608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06293037156160608}
{"step": 4624, "time": 333.3599901199341, "episode/length": 288.0, "episode/score": 0.05867805849857177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05867805849857177}
{"step": 4624, "time": 333.36792397499084, "episode/length": 288.0, "episode/score": 0.062328955676093756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062328955676093756}
{"step": 4624, "time": 333.3765375614166, "episode/length": 288.0, "episode/score": 0.08286327020482531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08286327020482531}
{"step": 5448, "time": 359.6880910396576, "episode/length": 102.0, "episode/score": 0.7159979748487331, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.034747970052421806}
{"step": 6856, "time": 404.5814878940582, "episode/length": 288.0, "episode/score": 0.06066073275673034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06066073275673034}
{"step": 6936, "time": 407.11759757995605, "episode/length": 288.0, "episode/score": 0.042184976980649935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042184976980649935}
{"step": 6936, "time": 407.1257951259613, "episode/length": 288.0, "episode/score": 0.048213005939260256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048213005939260256}
{"step": 6936, "time": 407.1330955028534, "episode/length": 288.0, "episode/score": 0.053599082910182005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053599082910182005}
{"step": 6936, "time": 407.1404433250427, "episode/length": 288.0, "episode/score": 0.07731536270046035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07731536270046035}
{"step": 6936, "time": 407.14865899086, "episode/length": 288.0, "episode/score": 0.03006714240268593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03006714240268593}
{"step": 6936, "time": 407.15623021125793, "episode/length": 288.0, "episode/score": 0.05816658519461271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05816658519461271}
{"step": 7760, "time": 433.6879417896271, "episode/length": 288.0, "episode/score": 0.05561240467721973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05561240467721973}
{"step": 9168, "time": 479.47454166412354, "episode/length": 288.0, "episode/score": 0.04381482704610562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04381482704610562}
{"step": 9248, "time": 482.04539942741394, "episode/length": 288.0, "episode/score": 0.041745778827930735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041745778827930735}
{"step": 9248, "time": 482.0535635948181, "episode/length": 288.0, "episode/score": 0.04702652064179347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04702652064179347}
{"step": 9248, "time": 482.06075263023376, "episode/length": 288.0, "episode/score": 0.06515202462441039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06515202462441039}
{"step": 9248, "time": 482.0681359767914, "episode/length": 288.0, "episode/score": 0.058744743216436746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058744743216436746}
{"step": 9248, "time": 482.07618260383606, "episode/length": 288.0, "episode/score": 0.034365116374829086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034365116374829086}
{"step": 9248, "time": 482.0847451686859, "episode/length": 288.0, "episode/score": 0.03233396482636408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03233396482636408}
{"step": 10072, "time": 508.2796485424042, "episode/length": 288.0, "episode/score": 0.06052386953444966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06052386953444966}
{"step": 10088, "time": 515.0227460861206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0310208797455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0381779670715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0451667308807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0520489215851, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0588252544403, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0656435489655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 515.0723490715027, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11480, "time": 559.696056842804, "episode/length": 288.0, "episode/score": 0.07498842416327989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07498842416327989}
{"step": 11560, "time": 562.3767054080963, "episode/length": 288.0, "episode/score": 0.06979551348530322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06979551348530322}
{"step": 11560, "time": 562.3850162029266, "episode/length": 288.0, "episode/score": 0.07703961939387227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07703961939387227}
{"step": 11560, "time": 562.3922896385193, "episode/length": 288.0, "episode/score": 0.07994213971210229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07994213971210229}
{"step": 11560, "time": 562.3995370864868, "episode/length": 288.0, "episode/score": 0.05972382954303157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05972382954303157}
{"step": 11560, "time": 562.4066390991211, "episode/length": 288.0, "episode/score": 0.07428840241158241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07428840241158241}
{"step": 11560, "time": 562.414781332016, "episode/length": 288.0, "episode/score": 0.04585190838560038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04585190838560038}
{"step": 12384, "time": 589.0470371246338, "episode/length": 288.0, "episode/score": 0.03968803711103419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03968803711103419}
{"step": 13792, "time": 634.1575975418091, "episode/length": 288.0, "episode/score": 0.03209011052183541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03209011052183541}
{"step": 13872, "time": 636.7475461959839, "episode/length": 288.0, "episode/score": 0.06016794190509245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06016794190509245}
{"step": 13872, "time": 636.7570135593414, "episode/length": 288.0, "episode/score": 0.06510452150723722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06510452150723722}
{"step": 13872, "time": 636.7715785503387, "episode/length": 288.0, "episode/score": 0.0498277880792557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0498277880792557}
{"step": 13872, "time": 636.7829737663269, "episode/length": 288.0, "episode/score": 0.0543621259092788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0543621259092788}
{"step": 13872, "time": 636.7906639575958, "episode/length": 288.0, "episode/score": 0.07579750769855309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07579750769855309}
{"step": 13872, "time": 636.7986629009247, "episode/length": 288.0, "episode/score": 0.07962490711599912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07962490711599912}
{"step": 14696, "time": 662.9339015483856, "episode/length": 288.0, "episode/score": 0.046426883133108277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046426883133108277}
{"step": 16104, "time": 708.1313693523407, "episode/length": 288.0, "episode/score": 0.07578081761550948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07578081761550948}
{"step": 16184, "time": 710.6940560340881, "episode/length": 288.0, "episode/score": 0.06486331259020517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06486331259020517}
{"step": 16184, "time": 710.7024781703949, "episode/length": 288.0, "episode/score": 0.05278539227515466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05278539227515466}
{"step": 16184, "time": 710.7114119529724, "episode/length": 288.0, "episode/score": 0.0604039819558011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0604039819558011}
{"step": 16184, "time": 710.7191739082336, "episode/length": 288.0, "episode/score": 0.0866470019876715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0866470019876715}
{"step": 16184, "time": 710.7269251346588, "episode/length": 288.0, "episode/score": 0.05343643820128818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05343643820128818}
{"step": 16184, "time": 710.7345857620239, "episode/length": 288.0, "episode/score": 0.07652905499662666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07652905499662666}
{"step": 17008, "time": 737.8909010887146, "episode/length": 288.0, "episode/score": 0.04463034913044339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04463034913044339}
{"step": 18416, "time": 783.174763917923, "episode/length": 288.0, "episode/score": 0.06579169901488058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06579169901488058}
{"step": 18496, "time": 785.7209897041321, "episode/length": 288.0, "episode/score": 0.05780490869165078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05780490869165078}
{"step": 18496, "time": 785.7293050289154, "episode/length": 288.0, "episode/score": 0.05823674646603649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05823674646603649}
{"step": 18496, "time": 785.7366843223572, "episode/length": 288.0, "episode/score": 0.05712332504060669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05712332504060669}
{"step": 18496, "time": 785.7444257736206, "episode/length": 288.0, "episode/score": 0.0688313737430235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0688313737430235}
{"step": 18496, "time": 785.7524609565735, "episode/length": 288.0, "episode/score": 0.0643310440713094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0643310440713094}
{"step": 18496, "time": 785.7595517635345, "episode/length": 288.0, "episode/score": 0.059454327724154155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059454327724154155}
{"step": 19320, "time": 811.9457650184631, "episode/length": 288.0, "episode/score": 0.05013448627289563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05013448627289563}
{"step": 20072, "time": 843.1116516590118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.1209814548492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.1280834674835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.1350338459015, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.142502784729, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.149744272232, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.1571705341339, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 843.1648581027985, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20728, "time": 864.2312104701996, "episode/length": 288.0, "episode/score": 0.0768086804598056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0768086804598056}
{"step": 20808, "time": 866.8415305614471, "episode/length": 288.0, "episode/score": 0.05819083173867057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05819083173867057}
{"step": 20808, "time": 866.8738162517548, "episode/length": 288.0, "episode/score": 0.0631049577072531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0631049577072531}
{"step": 20808, "time": 866.9023990631104, "episode/length": 288.0, "episode/score": 0.0726644203291471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0726644203291471}
{"step": 20808, "time": 866.9352023601532, "episode/length": 288.0, "episode/score": 0.047889482019286334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047889482019286334}
{"step": 20808, "time": 866.9648132324219, "episode/length": 288.0, "episode/score": 0.06946546884762483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06946546884762483}
{"step": 20808, "time": 866.9919850826263, "episode/length": 288.0, "episode/score": 0.07350836872427635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07350836872427635}
{"step": 21632, "time": 893.6808335781097, "episode/length": 288.0, "episode/score": 0.04256601126047599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04256601126047599}
{"step": 23040, "time": 938.8913059234619, "episode/length": 288.0, "episode/score": 0.0672800318761233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0672800318761233}
{"step": 23120, "time": 941.4452896118164, "episode/length": 288.0, "episode/score": 0.05812677220359319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05812677220359319}
{"step": 23120, "time": 941.4536786079407, "episode/length": 288.0, "episode/score": 0.0736372878288023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0736372878288023}
{"step": 23120, "time": 941.4614162445068, "episode/length": 288.0, "episode/score": 0.06158744948035633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06158744948035633}
{"step": 23120, "time": 941.4701833724976, "episode/length": 288.0, "episode/score": 0.05005245869384112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05005245869384112}
{"step": 23120, "time": 941.4785244464874, "episode/length": 288.0, "episode/score": 0.050313032703627414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050313032703627414}
{"step": 23120, "time": 941.4863476753235, "episode/length": 288.0, "episode/score": 0.04652709077592476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04652709077592476}
{"step": 23944, "time": 967.6967649459839, "episode/length": 288.0, "episode/score": 0.04404199446659618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04404199446659618}
{"step": 25352, "time": 1013.6862440109253, "episode/length": 288.0, "episode/score": 0.04809948516802365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04809948516802365}
{"step": 25432, "time": 1016.276270866394, "episode/length": 288.0, "episode/score": 0.057441414171876204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057441414171876204}
{"step": 25432, "time": 1016.2847430706024, "episode/length": 288.0, "episode/score": 0.0385987840016071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0385987840016071}
{"step": 25432, "time": 1016.2925472259521, "episode/length": 288.0, "episode/score": 0.06051736842900368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06051736842900368}
{"step": 25432, "time": 1016.3002910614014, "episode/length": 288.0, "episode/score": 0.07594329309586101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07594329309586101}
{"step": 25432, "time": 1016.3085632324219, "episode/length": 288.0, "episode/score": 0.08973599065106441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08973599065106441}
{"step": 25432, "time": 1016.316659450531, "episode/length": 288.0, "episode/score": 0.06247333201957872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06247333201957872}
{"step": 26256, "time": 1043.219057559967, "episode/length": 288.0, "episode/score": 0.07030518854955403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07030518854955403}
{"step": 27664, "time": 1088.276186466217, "episode/length": 288.0, "episode/score": 0.05796586199832632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05796586199832632}
{"step": 27744, "time": 1090.8333921432495, "episode/length": 288.0, "episode/score": 0.03570645312797183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03570645312797183}
{"step": 27744, "time": 1090.8417527675629, "episode/length": 288.0, "episode/score": 0.07057303857718011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07057303857718011}
{"step": 27744, "time": 1090.849505186081, "episode/length": 288.0, "episode/score": 0.04389730122639435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04389730122639435}
{"step": 27744, "time": 1090.857908964157, "episode/length": 288.0, "episode/score": 0.03614765301583134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03614765301583134}
{"step": 27744, "time": 1090.8657011985779, "episode/length": 288.0, "episode/score": 0.03730102069584973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03730102069584973}
{"step": 27744, "time": 1090.872950553894, "episode/length": 288.0, "episode/score": 0.0416383689415909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0416383689415909}
{"step": 27968, "time": 1098.0394785404205, "episode/length": 37.0, "episode/score": 0.8976104991613738, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.01323549436506255}
{"step": 28568, "time": 1117.19105052948, "episode/length": 288.0, "episode/score": 0.04459211319857559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04459211319857559}
{"step": 30056, "time": 1165.565045118332, "episode/length": 288.0, "episode/score": 0.063628580869306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.063628580869306}
{"step": 30056, "time": 1165.573558807373, "episode/length": 288.0, "episode/score": 0.08207133452077642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08207133452077642}
{"step": 30056, "time": 1165.5809428691864, "episode/length": 288.0, "episode/score": 0.04957300512987217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04957300512987217}
{"step": 30056, "time": 1165.5884397029877, "episode/length": 288.0, "episode/score": 0.0590084532521189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0590084532521189}
{"step": 30056, "time": 1165.5957555770874, "episode/length": 288.0, "episode/score": 0.057000117870956046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057000117870956046}
{"step": 30056, "time": 1165.6034700870514, "episode/length": 288.0, "episode/score": 0.0516443732053915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0516443732053915}
{"step": 30056, "time": 1171.8820004463196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.890041589737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.8977270126343, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.9056124687195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.9138774871826, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.9218354225159, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.9293990135193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1171.9369218349457, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30280, "time": 1179.0813264846802, "episode/length": 288.0, "episode/score": 0.05012162857840963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05012162857840963}
{"step": 30880, "time": 1198.6533505916595, "episode/length": 288.0, "episode/score": 0.0567835822102154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0567835822102154}
{"step": 30953, "time": 1201.7540509700775, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0005403112192623, "train/action_min": 0.0, "train/action_std": 1.9998381834863965, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006734233555037915, "train/actor_opt_grad_steps": 920.0, "train/actor_opt_loss": 16.63410969835813, "train/adv_mag": 0.0019966773878010323, "train/adv_max": 0.0019966773878010323, "train/adv_mean": 0.0011695881341011872, "train/adv_min": 0.00014478954277649957, "train/adv_std": 0.00054354506745956, "train/cont_avg": 0.9968782018442623, "train/cont_loss_mean": 0.025566323672092165, "train/cont_loss_std": 0.30619201804544693, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.763438382829938, "train/cont_pos_acc": 0.9967928079308056, "train/cont_pos_loss": 0.007600197062806431, "train/cont_pred": 0.993928744818995, "train/cont_rate": 0.9968782018442623, "train/dyn_loss_mean": 1.0729141235351562, "train/dyn_loss_std": 0.005664554722281904, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.580524710439593, "train/extr_critic_critic_opt_grad_steps": 920.0, "train/extr_critic_critic_opt_loss": 11722.109153539106, "train/extr_critic_mag": 0.018924204378180164, "train/extr_critic_max": 0.0189242030753464, "train/extr_critic_mean": 0.018882174408654175, "train/extr_critic_min": 0.018838289656925723, "train/extr_critic_std": 1.0370584371146173e-05, "train/extr_return_normed_mag": 0.0037119139872006345, "train/extr_return_normed_max": 0.0037119127524848487, "train/extr_return_normed_mean": 0.0029191331509057106, "train/extr_return_normed_min": 0.0019113195699129895, "train/extr_return_normed_std": 0.0005430654477851746, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020844545230071922, "train/extr_return_raw_max": 0.02084454393115057, "train/extr_return_raw_mean": 0.020051765333771298, "train/extr_return_raw_min": 0.01904395074802126, "train/extr_return_raw_std": 0.0005430654474671, "train/extr_reward_mag": 0.00024174536512197692, "train/extr_reward_max": 0.00024174536512197692, "train/extr_reward_mean": 0.00024152224651112822, "train/extr_reward_min": 0.00024119752352354956, "train/extr_reward_std": 8.367870865438977e-08, "train/image_loss_mean": 28.07323457300663, "train/image_loss_std": 0.40799849675815614, "train/model_loss_mean": 28.867923630391314, "train/model_loss_std": 0.6714191740083564, "train/model_opt_grad_norm": 106.5669522180662, "train/model_opt_grad_steps": 910.0, "train/model_opt_loss": 549.9110985219153, "train/model_opt_model_opt_grad_overflow": 0.00546448087431694, "train/model_opt_model_opt_grad_scale": 14.141478825136613, "train/policy_entropy_mag": 1.9457207403547776, "train/policy_entropy_max": 1.9457207403547776, "train/policy_entropy_mean": 1.939960380720962, "train/policy_entropy_min": 1.8663956223289824, "train/policy_entropy_std": 0.0036569620912660504, "train/policy_logprob_mag": 2.4145199314492647, "train/policy_logprob_max": -1.454883070754223, "train/policy_logprob_mean": -1.939985078540656, "train/policy_logprob_min": -2.4145199314492647, "train/policy_logprob_std": 0.09504771163391937, "train/policy_randomness_mag": 0.9999027216369337, "train/policy_randomness_max": 0.9999027216369337, "train/policy_randomness_mean": 0.9969424774737957, "train/policy_randomness_min": 0.9591376724464645, "train/policy_randomness_std": 0.0018793068990961247, "train/post_ent_mag": 77.25217275150487, "train/post_ent_max": 77.25217275150487, "train/post_ent_mean": 77.2079486117337, "train/post_ent_min": 77.07696829206957, "train/post_ent_std": 0.026196551621163803, "train/prior_ent_mag": 83.19163396449689, "train/prior_ent_max": 83.19163396449689, "train/prior_ent_mean": 83.08409118652344, "train/prior_ent_min": 82.75746396591103, "train/prior_ent_std": 0.06512444707580277, "train/rep_loss_mean": 1.0729141235351562, "train/rep_loss_std": 0.005664554722281904, "train/reward_avg": 0.0003050268755569199, "train/reward_loss_mean": 0.12537246428002588, "train/reward_loss_std": 0.05032674569550702, "train/reward_max_data": 0.0646550546596183, "train/reward_max_pred": 0.00024161247607788752, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12409235808815135, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.995645046234131, "train/reward_pred": 0.00024124976664862996, "train/reward_rate": 0.00016009221311475409, "train_stats/mean_log_entropy": 1.9256567246509049, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014593207277357578, "report/cont_loss_std": 0.24817682802677155, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6247076988220215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036145125050097704, "report/cont_pred": 0.996392011642456, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.3235260248184204, "report/image_loss_std": 0.06542804837226868, "report/model_loss_mean": 0.9484127759933472, "report/model_loss_std": 0.2567063271999359, "report/post_ent_mag": 64.94454193115234, "report/post_ent_max": 64.94454193115234, "report/post_ent_mean": 64.79496765136719, "report/post_ent_min": 64.77244567871094, "report/post_ent_std": 0.021176932379603386, "report/prior_ent_mag": 72.14791107177734, "report/prior_ent_max": 72.14791107177734, "report/prior_ent_mean": 72.06919860839844, "report/prior_ent_min": 71.51966094970703, "report/prior_ent_std": 0.09233194589614868, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001995391648961231, "report/reward_loss_mean": 0.010293534956872463, "report/reward_loss_std": 0.015904076397418976, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002340078353881836, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010293534956872463, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00023306673392653465, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0036145392805337906, "eval/cont_loss_std": 2.342240122743533e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036145392805337906, "eval/cont_pred": 0.9963918924331665, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3172493577003479, "eval/image_loss_std": 0.05714114382863045, "eval/model_loss_mean": 0.9227160215377808, "eval/model_loss_std": 0.057141195982694626, "eval/post_ent_mag": 64.94454193115234, "eval/post_ent_max": 64.94454193115234, "eval/post_ent_mean": 64.7937240600586, "eval/post_ent_min": 64.7729263305664, "eval/post_ent_std": 0.01995224878191948, "eval/prior_ent_mag": 72.13418579101562, "eval/prior_ent_max": 72.13418579101562, "eval/prior_ent_mean": 72.07244873046875, "eval/prior_ent_min": 71.51966094970703, "eval/prior_ent_std": 0.0861600786447525, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0018521174788475037, "eval/reward_loss_std": 5.755302368015691e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002340078353881836, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018521174788475037, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023306685034185648, "eval/reward_rate": 0.0, "replay/size": 30449.0, "replay/inserts": 29392.0, "replay/samples": 29392.0, "replay/insert_wait_avg": 1.3776557498738761e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.69029731833552e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.345538763026465e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 967.0910377502441, "timer/env.step_count": 3674.0, "timer/env.step_total": 38.36680197715759, "timer/env.step_frac": 0.03967237879322174, "timer/env.step_avg": 0.010442787691115295, "timer/env.step_min": 0.009163141250610352, "timer/env.step_max": 0.03697562217712402, "timer/replay._sample_count": 29392.0, "timer/replay._sample_total": 15.366346597671509, "timer/replay._sample_frac": 0.01588924516705111, "timer/replay._sample_avg": 0.0005228071106992212, "timer/replay._sample_min": 0.00033092498779296875, "timer/replay._sample_max": 0.024411678314208984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4541.0, "timer/agent.policy_total": 50.215073347091675, "timer/agent.policy_frac": 0.05192383280058889, "timer/agent.policy_avg": 0.011058153126424063, "timer/agent.policy_min": 0.009514093399047852, "timer/agent.policy_max": 0.10253286361694336, "timer/dataset_train_count": 1837.0, "timer/dataset_train_total": 0.2121741771697998, "timer/dataset_train_frac": 0.00021939421304470282, "timer/dataset_train_avg": 0.00011550036862808917, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.0004673004150390625, "timer/agent.train_count": 1837.0, "timer/agent.train_total": 827.2996957302094, "timer/agent.train_frac": 0.855451724229362, "timer/agent.train_avg": 0.4503536721449153, "timer/agent.train_min": 0.43854451179504395, "timer/agent.train_max": 0.8451862335205078, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4819662570953369, "timer/agent.report_frac": 0.0004983669978128854, "timer/agent.report_avg": 0.24098312854766846, "timer/agent.report_min": 0.2367546558380127, "timer/agent.report_max": 0.24521160125732422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.525403036598953e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 30.391731522611444}
{"step": 32368, "time": 1247.279397726059, "episode/length": 288.0, "episode/score": 0.05527166889385171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05527166889385171}
{"step": 32368, "time": 1247.2880828380585, "episode/length": 288.0, "episode/score": 0.04451236956253979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04451236956253979}
{"step": 32368, "time": 1247.2957105636597, "episode/length": 288.0, "episode/score": 0.05626304035445173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05626304035445173}
{"step": 32368, "time": 1247.3030405044556, "episode/length": 288.0, "episode/score": 0.030774815179825055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030774815179825055}
{"step": 32368, "time": 1247.3109040260315, "episode/length": 288.0, "episode/score": 0.04610510064117079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04610510064117079}
{"step": 32368, "time": 1247.318190574646, "episode/length": 288.0, "episode/score": 0.06699643675318612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06699643675318612}
{"step": 32592, "time": 1254.640472650528, "episode/length": 288.0, "episode/score": 0.04632345290229978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04632345290229978}
{"step": 33192, "time": 1274.0845189094543, "episode/length": 288.0, "episode/score": 0.05335084555912317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05335084555912317}
{"step": 34680, "time": 1321.898616552353, "episode/length": 288.0, "episode/score": 0.06205241136802897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06205241136802897}
{"step": 34680, "time": 1321.9071855545044, "episode/length": 288.0, "episode/score": 0.059697431946176494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059697431946176494}
{"step": 34680, "time": 1321.9149100780487, "episode/length": 288.0, "episode/score": 0.0650776628802987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0650776628802987}
{"step": 34680, "time": 1321.9252479076385, "episode/length": 288.0, "episode/score": 0.030196858430315388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030196858430315388}
{"step": 34680, "time": 1321.9327809810638, "episode/length": 288.0, "episode/score": 0.052582876845633564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052582876845633564}
{"step": 34680, "time": 1321.9401550292969, "episode/length": 288.0, "episode/score": 0.018760896750677603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018760896750677603}
{"step": 34904, "time": 1329.0879530906677, "episode/length": 288.0, "episode/score": 0.043363001350087416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043363001350087416}
{"step": 35504, "time": 1348.6482994556427, "episode/length": 288.0, "episode/score": 0.05234028409176972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05234028409176972}
{"step": 36776, "time": 1389.2215490341187, "episode/length": 261.0, "episode/score": 0.23175735137016318, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.04738234955408416}
{"step": 36992, "time": 1396.330994606018, "episode/length": 288.0, "episode/score": 0.052674993369350886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052674993369350886}
{"step": 36992, "time": 1396.3398191928864, "episode/length": 288.0, "episode/score": 0.0396127030722937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0396127030722937}
{"step": 36992, "time": 1396.3486487865448, "episode/length": 288.0, "episode/score": 0.07269783695858223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07269783695858223}
{"step": 36992, "time": 1396.3598029613495, "episode/length": 288.0, "episode/score": 0.05852492930534936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05852492930534936}
{"step": 36992, "time": 1396.3681840896606, "episode/length": 288.0, "episode/score": 0.0734855706767803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0734855706767803}
{"step": 37216, "time": 1403.6827993392944, "episode/length": 288.0, "episode/score": 0.07246468330055222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07246468330055222}
{"step": 37816, "time": 1422.63143658638, "episode/length": 288.0, "episode/score": 0.0510960764007109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0510960764007109}
{"step": 38696, "time": 1450.8109664916992, "episode/length": 212.0, "episode/score": 0.386093067644282, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.048593062847970714}
{"step": 39088, "time": 1463.6382162570953, "episode/length": 288.0, "episode/score": 0.05503104273370241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05503104273370241}
{"step": 39304, "time": 1470.2963614463806, "episode/length": 288.0, "episode/score": 0.060954815519551175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060954815519551175}
{"step": 39304, "time": 1470.3048567771912, "episode/length": 288.0, "episode/score": 0.051692099460893814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051692099460893814}
{"step": 39304, "time": 1470.3124759197235, "episode/length": 288.0, "episode/score": 0.0774855422806695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0774855422806695}
{"step": 39304, "time": 1470.3200223445892, "episode/length": 288.0, "episode/score": 0.05387233635369171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05387233635369171}
{"step": 39528, "time": 1477.4895310401917, "episode/length": 288.0, "episode/score": 0.07621989107224181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07621989107224181}
{"step": 40040, "time": 1500.1781051158905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.1858613491058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.1925520896912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.1991369724274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.2054891586304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.2117097377777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.2178905010223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.2242381572723, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40128, "time": 1503.2765934467316, "episode/length": 288.0, "episode/score": 0.055703936508280094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055703936508280094}
{"step": 40312, "time": 1508.8977165222168, "episode/length": 125.0, "episode/score": 0.6396453456449365, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.030270346459843722}
{"step": 41008, "time": 1532.0291166305542, "episode/length": 288.0, "episode/score": 0.06430575762985313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06430575762985313}
{"step": 41400, "time": 1544.3625094890594, "episode/length": 288.0, "episode/score": 0.07811582025013308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07811582025013308}
{"step": 41616, "time": 1551.4998216629028, "episode/length": 288.0, "episode/score": 0.05757968502226163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05757968502226163}
{"step": 41616, "time": 1551.508130788803, "episode/length": 288.0, "episode/score": 0.05795491910939177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05795491910939177}
{"step": 41616, "time": 1551.5156819820404, "episode/length": 288.0, "episode/score": 0.08738764422054146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08738764422054146}
{"step": 41840, "time": 1558.7594285011292, "episode/length": 288.0, "episode/score": 0.054211320747299396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054211320747299396}
{"step": 42440, "time": 1577.6727664470673, "episode/length": 288.0, "episode/score": 0.042884537433167225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042884537433167225}
{"step": 42624, "time": 1583.974437713623, "episode/length": 288.0, "episode/score": 0.04507868172353824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04507868172353824}
{"step": 43320, "time": 1606.1055586338043, "episode/length": 288.0, "episode/score": 0.04682681153985868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04682681153985868}
{"step": 43712, "time": 1618.9994280338287, "episode/length": 288.0, "episode/score": 0.03078046498353615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03078046498353615}
{"step": 43928, "time": 1625.6454184055328, "episode/length": 288.0, "episode/score": 0.04284385530615964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04284385530615964}
{"step": 43928, "time": 1625.6536326408386, "episode/length": 288.0, "episode/score": 0.07405831855601264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07405831855601264}
{"step": 43928, "time": 1625.6618974208832, "episode/length": 288.0, "episode/score": 0.06933690365212897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06933690365212897}
{"step": 44152, "time": 1632.8032641410828, "episode/length": 288.0, "episode/score": 0.05597531714181514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05597531714181514}
{"step": 44752, "time": 1652.249881029129, "episode/length": 288.0, "episode/score": 0.06514622735141984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06514622735141984}
{"step": 44936, "time": 1657.9189620018005, "episode/length": 288.0, "episode/score": 0.0594556283658676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0594556283658676}
{"step": 45632, "time": 1680.427402973175, "episode/length": 288.0, "episode/score": 0.08229365112202913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08229365112202913}
{"step": 46024, "time": 1692.7638149261475, "episode/length": 288.0, "episode/score": 0.06136182196161144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06136182196161144}
{"step": 46240, "time": 1699.9311470985413, "episode/length": 288.0, "episode/score": 0.06951096188902284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06951096188902284}
{"step": 46240, "time": 1699.9393546581268, "episode/length": 288.0, "episode/score": 0.07578867384000887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07578867384000887}
{"step": 46240, "time": 1699.947273492813, "episode/length": 288.0, "episode/score": 0.06392456989516404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06392456989516404}
{"step": 46464, "time": 1707.2141621112823, "episode/length": 288.0, "episode/score": 0.060742269971513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060742269971513}
{"step": 47064, "time": 1726.1124258041382, "episode/length": 288.0, "episode/score": 0.07535541154277325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07535541154277325}
{"step": 47248, "time": 1732.3358204364777, "episode/length": 288.0, "episode/score": 0.0497161038869649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0497161038869649}
{"step": 47456, "time": 1738.9609558582306, "episode/length": 151.0, "episode/score": 0.5643996897815668, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.036274673064326635}
{"step": 47944, "time": 1754.274495124817, "episode/length": 288.0, "episode/score": 0.04962773862172298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04962773862172298}
{"step": 48336, "time": 1767.1454632282257, "episode/length": 288.0, "episode/score": 0.05281562532377393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05281562532377393}
{"step": 48552, "time": 1773.800132036209, "episode/length": 288.0, "episode/score": 0.0523191894020556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0523191894020556}
{"step": 48552, "time": 1773.8086726665497, "episode/length": 288.0, "episode/score": 0.03242387604450414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03242387604450414}
{"step": 48776, "time": 1780.993659734726, "episode/length": 288.0, "episode/score": 0.0653002281976569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0653002281976569}
{"step": 49376, "time": 1801.0886595249176, "episode/length": 288.0, "episode/score": 0.04552760979834147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04552760979834147}
{"step": 49560, "time": 1806.7840995788574, "episode/length": 288.0, "episode/score": 0.053531470936377445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053531470936377445}
{"step": 49768, "time": 1813.527801990509, "episode/length": 288.0, "episode/score": 0.04296349514356734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04296349514356734}
{"step": 50024, "time": 1824.8922955989838, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 50024, "time": 1827.9547472000122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1827.9629437923431, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1827.970440864563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1827.977186203003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1827.9837288856506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1827.990668296814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1827.9988963603973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50256, "time": 1835.6327781677246, "episode/length": 288.0, "episode/score": 0.07202323955073098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07202323955073098}
{"step": 50648, "time": 1847.8507013320923, "episode/length": 288.0, "episode/score": 0.0546404181339426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0546404181339426}
{"step": 50864, "time": 1855.094422340393, "episode/length": 288.0, "episode/score": 0.06378681928083552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06378681928083552}
{"step": 50864, "time": 1855.1028571128845, "episode/length": 288.0, "episode/score": 0.05503554145866474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05503554145866474}
{"step": 51088, "time": 1862.1856322288513, "episode/length": 288.0, "episode/score": 0.03995446332260144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03995446332260144}
{"step": 51688, "time": 1881.0862412452698, "episode/length": 288.0, "episode/score": 0.040177920009341506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040177920009341506}
{"step": 51872, "time": 1887.2542958259583, "episode/length": 288.0, "episode/score": 0.06085815656086879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06085815656086879}
{"step": 52080, "time": 1893.8957092761993, "episode/length": 288.0, "episode/score": 0.04663473560339071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04663473560339071}
{"step": 52568, "time": 1909.2904741764069, "episode/length": 288.0, "episode/score": 0.08378700255315152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08378700255315152}
{"step": 52960, "time": 1922.1043632030487, "episode/length": 288.0, "episode/score": 0.07093417289860326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07093417289860326}
{"step": 53176, "time": 1928.8673832416534, "episode/length": 288.0, "episode/score": 0.06448576876618972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06448576876618972}
{"step": 53176, "time": 1928.8762996196747, "episode/length": 288.0, "episode/score": 0.07623766296291024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07623766296291024}
{"step": 53400, "time": 1936.152889251709, "episode/length": 288.0, "episode/score": 0.08363046010208564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08363046010208564}
{"step": 54000, "time": 1955.6596438884735, "episode/length": 288.0, "episode/score": 0.07822567283562876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07822567283562876}
{"step": 54184, "time": 1961.3293135166168, "episode/length": 288.0, "episode/score": 0.05903995718506394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05903995718506394}
{"step": 54392, "time": 1967.9569494724274, "episode/length": 288.0, "episode/score": 0.06633593552697903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06633593552697903}
{"step": 54880, "time": 1983.855524778366, "episode/length": 288.0, "episode/score": 0.06774522764260382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06774522764260382}
{"step": 55272, "time": 1996.1369757652283, "episode/length": 288.0, "episode/score": 0.05180935296198186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05180935296198186}
{"step": 55488, "time": 2003.380672454834, "episode/length": 288.0, "episode/score": 0.061209422657384494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061209422657384494}
{"step": 55488, "time": 2003.389072418213, "episode/length": 288.0, "episode/score": 0.06133424665415532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06133424665415532}
{"step": 55712, "time": 2010.5531299114227, "episode/length": 288.0, "episode/score": 0.07731011769351426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07731011769351426}
{"step": 56312, "time": 2029.5076761245728, "episode/length": 288.0, "episode/score": 0.05321096395346103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05321096395346103}
{"step": 56464, "time": 2034.673022031784, "episode/length": 197.0, "episode/score": 0.42444078888468084, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.04006578408836958}
{"step": 56496, "time": 2035.6935296058655, "episode/length": 288.0, "episode/score": 0.08279523560497637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08279523560497637}
{"step": 56704, "time": 2042.3180854320526, "episode/length": 288.0, "episode/score": 0.06074278674270772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06074278674270772}
{"step": 57584, "time": 2071.078056335449, "episode/length": 288.0, "episode/score": 0.07955742358973339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07955742358973339}
{"step": 57800, "time": 2077.743147134781, "episode/length": 288.0, "episode/score": 0.052782882639291984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052782882639291984}
{"step": 57800, "time": 2077.7687747478485, "episode/length": 288.0, "episode/score": 0.060364264180634564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060364264180634564}
{"step": 58024, "time": 2084.914373397827, "episode/length": 288.0, "episode/score": 0.04451603349912148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04451603349912148}
{"step": 58624, "time": 2104.4189388751984, "episode/length": 288.0, "episode/score": 0.06586328528464946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06586328528464946}
{"step": 58776, "time": 2109.064327955246, "episode/length": 288.0, "episode/score": 0.05662599589123829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05662599589123829}
{"step": 58808, "time": 2110.0959265232086, "episode/length": 288.0, "episode/score": 0.06849104686932606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06849104686932606}
{"step": 59016, "time": 2116.7436718940735, "episode/length": 288.0, "episode/score": 0.0640529441091644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0640529441091644}
{"step": 59896, "time": 2145.001280784607, "episode/length": 288.0, "episode/score": 0.06310878588442392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06310878588442392}
{"step": 60008, "time": 2155.574204683304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.581808567047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.5884494781494, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.594854593277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.601405620575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.608337879181, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.6148149967194, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2155.62149143219, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2159.1692128181458, "episode/length": 288.0, "episode/score": 0.05468747602890289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05468747602890289}
{"step": 60112, "time": 2159.17822098732, "episode/length": 288.0, "episode/score": 0.05993255778992079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05993255778992079}
{"step": 60336, "time": 2166.226625919342, "episode/length": 288.0, "episode/score": 0.05015251565203016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05015251565203016}
{"step": 60936, "time": 2185.3034930229187, "episode/length": 288.0, "episode/score": 0.048986118346135754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048986118346135754}
{"step": 61088, "time": 2190.335866689682, "episode/length": 288.0, "episode/score": 0.09496423236703322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09496423236703322}
{"step": 61120, "time": 2191.3552401065826, "episode/length": 288.0, "episode/score": 0.056538597614235186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056538597614235186}
{"step": 61328, "time": 2197.9589512348175, "episode/length": 288.0, "episode/score": 0.04117052009627287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04117052009627287}
{"step": 61433, "time": 2202.0253417491913, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999888794584424, "train/action_min": 0.0, "train/action_std": 1.9995229980708418, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003020504447790009, "train/actor_opt_grad_steps": 2790.0, "train/actor_opt_loss": 6.228072215827348, "train/adv_mag": 0.0011417938113524651, "train/adv_max": 0.0011417938113524651, "train/adv_mean": 0.0006245590949977177, "train/adv_min": -3.86318455191807e-07, "train/adv_std": 0.0002928503876014403, "train/cont_avg": 0.9963084914921466, "train/cont_loss_mean": 0.024477997620429123, "train/cont_loss_std": 0.3335264189602816, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.69702478418959, "train/cont_pos_acc": 0.9999999822122264, "train/cont_pos_loss": 0.003438743612733889, "train/cont_pred": 0.9965673950330125, "train/cont_rate": 0.9963084914921466, "train/dyn_loss_mean": 1.0000000455616656, "train/dyn_loss_std": 5.499563109321965e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09221263477549503, "train/extr_critic_critic_opt_grad_steps": 2790.0, "train/extr_critic_critic_opt_loss": 12070.625695353403, "train/extr_critic_mag": 0.050482393559361, "train/extr_critic_max": 0.050482393559361, "train/extr_critic_mean": 0.05039252198413405, "train/extr_critic_min": 0.050310580518233214, "train/extr_critic_std": 2.3398183499912136e-05, "train/extr_return_normed_mag": 0.0022279997770698907, "train/extr_return_normed_max": 0.0022279997770698907, "train/extr_return_normed_mean": 0.0017839049401142055, "train/extr_return_normed_min": 0.0011991759986465513, "train/extr_return_normed_std": 0.0002909291584223889, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05146113506162354, "train/extr_return_raw_max": 0.05146113506162354, "train/extr_return_raw_mean": 0.0510170426395239, "train/extr_return_raw_min": 0.0504323112832002, "train/extr_return_raw_std": 0.0002909291588033291, "train/extr_reward_mag": 0.00025017598536626205, "train/extr_reward_max": 0.00025017598536626205, "train/extr_reward_mean": 0.0002500183129267455, "train/extr_reward_min": 0.00024961801099527566, "train/extr_reward_std": 8.857734159705091e-08, "train/image_loss_mean": 0.271986608495887, "train/image_loss_std": 0.08436173988574462, "train/model_loss_mean": 0.9082677408038634, "train/model_loss_std": 0.37849291636369614, "train/model_opt_grad_norm": 82.51987155694611, "train/model_opt_grad_steps": 2780.0, "train/model_opt_loss": 47.288489726201405, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 52.151505235602095, "train/policy_entropy_mag": 1.9458823996688683, "train/policy_entropy_max": 1.9458823996688683, "train/policy_entropy_mean": 1.9445838372744815, "train/policy_entropy_min": 1.9183022638890133, "train/policy_entropy_std": 0.0009335325339063027, "train/policy_logprob_mag": 2.21864064825767, "train/policy_logprob_max": -1.6371429946410094, "train/policy_logprob_mean": -1.9445515053434521, "train/policy_logprob_min": -2.21864064825767, "train/policy_logprob_std": 0.05109898274013509, "train/policy_randomness_mag": 0.9999857975550347, "train/policy_randomness_max": 0.9999857975550347, "train/policy_randomness_mean": 0.9993184670727915, "train/policy_randomness_min": 0.9858124093859607, "train/policy_randomness_std": 0.0004797408626054009, "train/post_ent_mag": 56.422066054419076, "train/post_ent_max": 56.422066054419076, "train/post_ent_mean": 56.288887683009605, "train/post_ent_min": 56.262926451198716, "train/post_ent_std": 0.019802408385534247, "train/prior_ent_mag": 64.34988650976051, "train/prior_ent_max": 64.34988650976051, "train/prior_ent_mean": 64.27136819649742, "train/prior_ent_min": 63.91070283020978, "train/prior_ent_std": 0.06392471014439123, "train/rep_loss_mean": 1.0000000455616656, "train/rep_loss_std": 5.499563109321965e-07, "train/reward_avg": 0.0002855368413997775, "train/reward_loss_mean": 0.011803085301363968, "train/reward_loss_std": 0.05775649268765256, "train/reward_max_data": 0.07906195519282361, "train/reward_max_pred": 0.0002500836137701704, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010438745051466358, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.540834086281913, "train/reward_pred": 0.00024980725476723064, "train/reward_rate": 0.0001431609947643979, "train_stats/mean_log_entropy": 1.9377476199765071, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020015103742480278, "report/cont_loss_std": 0.3135162889957428, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.803802013397217, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030206232331693172, "report/cont_pred": 0.9969837665557861, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2554358243942261, "report/image_loss_std": 0.0939166396856308, "report/model_loss_mean": 0.885546863079071, "report/model_loss_std": 0.32756611704826355, "report/post_ent_mag": 50.98237991333008, "report/post_ent_max": 50.98237991333008, "report/post_ent_mean": 50.7700309753418, "report/post_ent_min": 50.74535369873047, "report/post_ent_std": 0.03215273842215538, "report/prior_ent_mag": 53.86794662475586, "report/prior_ent_max": 53.86794662475586, "report/prior_ent_mean": 53.766815185546875, "report/prior_ent_min": 52.48423767089844, "report/prior_ent_std": 0.21510091423988342, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020326545927673578, "report/reward_loss_mean": 0.010095866397023201, "report/reward_loss_std": 0.017203480005264282, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00024139881134033203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010095866397023201, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002412984613329172, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0030206232331693172, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030206232331693172, "eval/cont_pred": 0.9969837665557861, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24611319601535797, "eval/image_loss_std": 0.07871663570404053, "eval/model_loss_mean": 0.8505339622497559, "eval/model_loss_std": 0.07871663570404053, "eval/post_ent_mag": 50.984981536865234, "eval/post_ent_max": 50.984981536865234, "eval/post_ent_mean": 50.76893615722656, "eval/post_ent_min": 50.7464599609375, "eval/post_ent_std": 0.029858900234103203, "eval/prior_ent_mag": 53.86524200439453, "eval/prior_ent_max": 53.86524200439453, "eval/prior_ent_mean": 53.778236389160156, "eval/prior_ent_min": 52.48423767089844, "eval/prior_ent_std": 0.19616368412971497, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014000763185322285, "eval/reward_loss_std": 1.803011429046819e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00024139881134033203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014000763185322285, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00024130020756274462, "eval/reward_rate": 0.0, "replay/size": 60929.0, "replay/inserts": 30480.0, "replay/samples": 30480.0, "replay/insert_wait_avg": 1.3836960154255545e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.005668026881581e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2870340886275524e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2533564567566, "timer/env.step_count": 3810.0, "timer/env.step_total": 39.71045684814453, "timer/env.step_frac": 0.0397003984958498, "timer/env.step_avg": 0.010422692086127174, "timer/env.step_min": 0.009134054183959961, "timer/env.step_max": 0.0509798526763916, "timer/replay._sample_count": 30480.0, "timer/replay._sample_total": 16.273070335388184, "timer/replay._sample_frac": 0.016268948492243033, "timer/replay._sample_avg": 0.0005338933837069614, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.025567293167114258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4677.0, "timer/agent.policy_total": 51.51169419288635, "timer/agent.policy_frac": 0.0514986466782362, "timer/agent.policy_avg": 0.011013832412419575, "timer/agent.policy_min": 0.009506940841674805, "timer/agent.policy_max": 0.20679974555969238, "timer/dataset_train_count": 1905.0, "timer/dataset_train_total": 0.21570777893066406, "timer/dataset_train_frac": 0.00021565314181476545, "timer/dataset_train_avg": 0.00011323242988486302, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0009541511535644531, "timer/agent.train_count": 1905.0, "timer/agent.train_total": 856.8346364498138, "timer/agent.train_frac": 0.8566176068481475, "timer/agent.train_avg": 0.44978196139097837, "timer/agent.train_min": 0.4375159740447998, "timer/agent.train_max": 0.6065301895141602, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47168469429016113, "timer/agent.report_frac": 0.00047156522019684244, "timer/agent.report_avg": 0.23584234714508057, "timer/agent.report_min": 0.22531533241271973, "timer/agent.report_max": 0.2463693618774414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.367134094238281e-05, "timer/dataset_eval_frac": 7.365268056020546e-08, "timer/dataset_eval_avg": 7.367134094238281e-05, "timer/dataset_eval_min": 7.367134094238281e-05, "timer/dataset_eval_max": 7.367134094238281e-05, "fps": 30.471752837367905}
{"step": 61568, "time": 2206.3386182785034, "episode/length": 55.0, "episode/score": 0.8447823627229809, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01665736353788816}
{"step": 62208, "time": 2226.7404577732086, "episode/length": 288.0, "episode/score": 0.07283184579858926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07283184579858926}
{"step": 62424, "time": 2233.432936191559, "episode/length": 288.0, "episode/score": 0.05935941026984892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05935941026984892}
{"step": 62424, "time": 2233.441575050354, "episode/length": 288.0, "episode/score": 0.046725502026390586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046725502026390586}
{"step": 62648, "time": 2240.584988117218, "episode/length": 288.0, "episode/score": 0.052524017841506065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052524017841506065}
{"step": 63248, "time": 2260.0657556056976, "episode/length": 288.0, "episode/score": 0.06417332553530741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06417332553530741}
{"step": 63400, "time": 2264.6730189323425, "episode/length": 288.0, "episode/score": 0.051975838167663824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051975838167663824}
{"step": 63640, "time": 2272.4139795303345, "episode/length": 288.0, "episode/score": 0.05330990145591841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05330990145591841}
{"step": 63880, "time": 2280.0558047294617, "episode/length": 288.0, "episode/score": 0.07665639395850121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07665639395850121}
{"step": 64520, "time": 2300.352381706238, "episode/length": 288.0, "episode/score": 0.06445475187456395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06445475187456395}
{"step": 64736, "time": 2307.537224292755, "episode/length": 288.0, "episode/score": 0.0617275228012204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0617275228012204}
{"step": 64736, "time": 2307.5464429855347, "episode/length": 288.0, "episode/score": 0.06662759155932463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06662759155932463}
{"step": 64960, "time": 2314.688923597336, "episode/length": 288.0, "episode/score": 0.0371006162077947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0371006162077947}
{"step": 65560, "time": 2334.164361000061, "episode/length": 288.0, "episode/score": 0.07109931485280185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07109931485280185}
{"step": 65712, "time": 2339.244040489197, "episode/length": 288.0, "episode/score": 0.058742405924533614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058742405924533614}
{"step": 65952, "time": 2346.8592648506165, "episode/length": 288.0, "episode/score": 0.04312768681967327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04312768681967327}
{"step": 66192, "time": 2354.5214927196503, "episode/length": 288.0, "episode/score": 0.04102188555759767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04102188555759767}
{"step": 66832, "time": 2374.9697144031525, "episode/length": 288.0, "episode/score": 0.06268354403130161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06268354403130161}
{"step": 66856, "time": 2375.510746240616, "episode/length": 82.0, "episode/score": 0.7683819045611244, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.02463189976481317}
{"step": 67048, "time": 2381.6234741210938, "episode/length": 288.0, "episode/score": 0.058667813447698336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058667813447698336}
{"step": 67048, "time": 2381.6320588588715, "episode/length": 288.0, "episode/score": 0.07530962015920295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07530962015920295}
{"step": 67272, "time": 2388.7620570659637, "episode/length": 288.0, "episode/score": 0.06039741771394347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06039741771394347}
{"step": 67872, "time": 2408.185061454773, "episode/length": 288.0, "episode/score": 0.06472566058124585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06472566058124585}
{"step": 68024, "time": 2412.7873995304108, "episode/length": 288.0, "episode/score": 0.0762598800321257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0762598800321257}
{"step": 68264, "time": 2420.410130739212, "episode/length": 288.0, "episode/score": 0.06175534608655653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06175534608655653}
{"step": 69144, "time": 2448.426172733307, "episode/length": 288.0, "episode/score": 0.05622989419367741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05622989419367741}
{"step": 69168, "time": 2449.4203596115112, "episode/length": 288.0, "episode/score": 0.06769143014537349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06769143014537349}
{"step": 69360, "time": 2455.6514105796814, "episode/length": 288.0, "episode/score": 0.053517783774225336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053517783774225336}
{"step": 69360, "time": 2455.659731388092, "episode/length": 288.0, "episode/score": 0.06714418955570522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06714418955570522}
{"step": 69432, "time": 2457.7364518642426, "episode/length": 175.0, "episode/score": 0.4973996597544783, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.044274660918631525}
{"step": 69584, "time": 2462.8118846416473, "episode/length": 288.0, "episode/score": 0.06480379977938355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06480379977938355}
{"step": 70096, "time": 2481.8888869285583, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 70096, "time": 2485.261210203171, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2485.270860671997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2485.2802908420563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2485.2879054546356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2485.2960290908813, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2485.3037116527557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2485.3108751773834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70184, "time": 2487.8699996471405, "episode/length": 288.0, "episode/score": 0.07039814601657213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07039814601657213}
{"step": 70576, "time": 2500.556296110153, "episode/length": 288.0, "episode/score": 0.04395753530673119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04395753530673119}
{"step": 71456, "time": 2528.6250245571136, "episode/length": 288.0, "episode/score": 0.0591327553557619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0591327553557619}
{"step": 71480, "time": 2529.1852412223816, "episode/length": 288.0, "episode/score": 0.04149668473368706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04149668473368706}
{"step": 71672, "time": 2535.393553495407, "episode/length": 288.0, "episode/score": 0.06980255364527466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06980255364527466}
{"step": 71672, "time": 2535.4022133350372, "episode/length": 288.0, "episode/score": 0.06554657665046193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06554657665046193}
{"step": 71744, "time": 2537.958019256592, "episode/length": 288.0, "episode/score": 0.05438257045454975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05438257045454975}
{"step": 71896, "time": 2542.7092571258545, "episode/length": 288.0, "episode/score": 0.06485932729592037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06485932729592037}
{"step": 72496, "time": 2561.9887058734894, "episode/length": 288.0, "episode/score": 0.08362508737567964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08362508737567964}
{"step": 72888, "time": 2574.3684692382812, "episode/length": 288.0, "episode/score": 0.07114814472748776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07114814472748776}
{"step": 73472, "time": 2593.248555421829, "episode/length": 251.0, "episode/score": 0.26075582845183476, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.04513082628650977}
{"step": 73792, "time": 2604.055424928665, "episode/length": 288.0, "episode/score": 0.0768220494399543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0768220494399543}
{"step": 73984, "time": 2610.1670265197754, "episode/length": 288.0, "episode/score": 0.03938290072338191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03938290072338191}
{"step": 73984, "time": 2610.2239520549774, "episode/length": 288.0, "episode/score": 0.08264373249025425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08264373249025425}
{"step": 74056, "time": 2612.3105294704437, "episode/length": 288.0, "episode/score": 0.07994759026536258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07994759026536258}
{"step": 74208, "time": 2617.3433899879456, "episode/length": 288.0, "episode/score": 0.061171987660515015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061171987660515015}
{"step": 74808, "time": 2636.1982686519623, "episode/length": 288.0, "episode/score": 0.04154914420740852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04154914420740852}
{"step": 75200, "time": 2648.959228038788, "episode/length": 288.0, "episode/score": 0.04866130113106237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04866130113106237}
{"step": 75784, "time": 2667.413192510605, "episode/length": 288.0, "episode/score": 0.06045334307046346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06045334307046346}
{"step": 76104, "time": 2677.579046726227, "episode/length": 288.0, "episode/score": 0.062260868156698734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062260868156698734}
{"step": 76296, "time": 2683.70565199852, "episode/length": 288.0, "episode/score": 0.06850419553222764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06850419553222764}
{"step": 76296, "time": 2683.714688539505, "episode/length": 288.0, "episode/score": 0.058823681936303274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058823681936303274}
{"step": 76368, "time": 2686.2271325588226, "episode/length": 288.0, "episode/score": 0.04574133388587143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04574133388587143}
{"step": 76520, "time": 2690.8298840522766, "episode/length": 288.0, "episode/score": 0.07942246708617517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07942246708617517}
{"step": 77120, "time": 2710.654727935791, "episode/length": 288.0, "episode/score": 0.07003377451596293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07003377451596293}
{"step": 77512, "time": 2722.9673290252686, "episode/length": 288.0, "episode/score": 0.06316230774250187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06316230774250187}
{"step": 78096, "time": 2741.682170152664, "episode/length": 288.0, "episode/score": 0.042283482131878714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042283482131878714}
{"step": 78416, "time": 2751.9175324440002, "episode/length": 288.0, "episode/score": 0.05992266485316122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05992266485316122}
{"step": 78608, "time": 2758.0289390087128, "episode/length": 288.0, "episode/score": 0.049951610561265625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049951610561265625}
{"step": 78608, "time": 2758.037750720978, "episode/length": 288.0, "episode/score": 0.051168111659677606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051168111659677606}
{"step": 78680, "time": 2760.1648552417755, "episode/length": 288.0, "episode/score": 0.0641874474222277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0641874474222277}
{"step": 78832, "time": 2765.261419773102, "episode/length": 288.0, "episode/score": 0.06660787776372956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06660787776372956}
{"step": 79432, "time": 2784.1985833644867, "episode/length": 288.0, "episode/score": 0.045121493817788405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045121493817788405}
{"step": 79824, "time": 2796.9322419166565, "episode/length": 288.0, "episode/score": 0.044988589070825924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044988589070825924}
{"step": 80080, "time": 2807.4232606887817, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 80080, "time": 2809.6948857307434, "eval_episode/length": 219.0, "eval_episode/score": 0.31562501192092896, "eval_episode/reward_rate": 0.004545454545454545}
{"step": 80080, "time": 2811.1585009098053, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2811.166846513748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2811.1734507083893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2811.1847655773163, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2811.1995685100555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2811.2067630290985, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80408, "time": 2821.467606306076, "episode/length": 288.0, "episode/score": 0.06608835539103097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06608835539103097}
{"step": 80672, "time": 2830.0404148101807, "episode/length": 32.0, "episode/score": 0.9101945024961964, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.010194497699885119}
{"step": 80728, "time": 2831.6015412807465, "episode/length": 288.0, "episode/score": 0.03935289722508628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03935289722508628}
{"step": 80920, "time": 2837.6898713111877, "episode/length": 288.0, "episode/score": 0.04536485776441168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04536485776441168}
{"step": 80920, "time": 2837.698090314865, "episode/length": 288.0, "episode/score": 0.07251018057733916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07251018057733916}
{"step": 80992, "time": 2840.1946063041687, "episode/length": 288.0, "episode/score": 0.03950154836068975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03950154836068975}
{"step": 81144, "time": 2844.890932559967, "episode/length": 288.0, "episode/score": 0.047640889419525934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047640889419525934}
{"step": 81744, "time": 2864.083690881729, "episode/length": 288.0, "episode/score": 0.05068048637910749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05068048637910749}
{"step": 82136, "time": 2876.9391009807587, "episode/length": 288.0, "episode/score": 0.032576059195889684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032576059195889684}
{"step": 82984, "time": 2903.8444361686707, "episode/length": 288.0, "episode/score": 0.038094141835244955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038094141835244955}
{"step": 83040, "time": 2905.859645843506, "episode/length": 288.0, "episode/score": 0.05779438871481091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05779438871481091}
{"step": 83232, "time": 2911.9254035949707, "episode/length": 288.0, "episode/score": 0.05291572320714977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05291572320714977}
{"step": 83232, "time": 2911.934252023697, "episode/length": 288.0, "episode/score": 0.0548679512403254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0548679512403254}
{"step": 83304, "time": 2913.98614859581, "episode/length": 288.0, "episode/score": 0.054107820424803776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054107820424803776}
{"step": 83456, "time": 2919.047160387039, "episode/length": 288.0, "episode/score": 0.03808242441407117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03808242441407117}
{"step": 84056, "time": 2937.8572659492493, "episode/length": 288.0, "episode/score": 0.033230944486689395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033230944486689395}
{"step": 84448, "time": 2950.422291994095, "episode/length": 288.0, "episode/score": 0.045922036937355415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045922036937355415}
{"step": 85296, "time": 2977.2730906009674, "episode/length": 288.0, "episode/score": 0.04520764301332747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04520764301332747}
{"step": 85352, "time": 2978.8191730976105, "episode/length": 288.0, "episode/score": 0.038149759924309024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038149759924309024}
{"step": 85544, "time": 2984.8904418945312, "episode/length": 288.0, "episode/score": 0.061457886545071005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061457886545071005}
{"step": 85544, "time": 2984.898849964142, "episode/length": 288.0, "episode/score": 0.056316888496084516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056316888496084516}
{"step": 85616, "time": 2987.4016783237457, "episode/length": 288.0, "episode/score": 0.0563544389382713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0563544389382713}
{"step": 85768, "time": 2992.085164308548, "episode/length": 288.0, "episode/score": 0.05461499218033339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05461499218033339}
{"step": 86368, "time": 3011.192139148712, "episode/length": 288.0, "episode/score": 0.04274406579445156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04274406579445156}
{"step": 86760, "time": 3023.4314584732056, "episode/length": 288.0, "episode/score": 0.044260408214896074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044260408214896074}
{"step": 87608, "time": 3050.1461431980133, "episode/length": 288.0, "episode/score": 0.044918733593149796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044918733593149796}
{"step": 87664, "time": 3052.3041203022003, "episode/length": 288.0, "episode/score": 0.053222603536838164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053222603536838164}
{"step": 87856, "time": 3058.394706726074, "episode/length": 288.0, "episode/score": 0.05577121499504756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05577121499504756}
{"step": 87856, "time": 3058.4034552574158, "episode/length": 288.0, "episode/score": 0.045234507415202074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045234507415202074}
{"step": 87928, "time": 3060.4747920036316, "episode/length": 288.0, "episode/score": 0.05333679721026385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05333679721026385}
{"step": 88080, "time": 3065.493942260742, "episode/length": 288.0, "episode/score": 0.03599912029771701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03599912029771701}
{"step": 88680, "time": 3084.3471326828003, "episode/length": 288.0, "episode/score": 0.036741844526289924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036741844526289924}
{"step": 89072, "time": 3096.957135915756, "episode/length": 288.0, "episode/score": 0.06308702179968861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06308702179968861}
{"step": 89920, "time": 3123.887354850769, "episode/length": 288.0, "episode/score": 0.04453763915097397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04453763915097397}
{"step": 89976, "time": 3125.4283726215363, "episode/length": 288.0, "episode/score": 0.03919305014525776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03919305014525776}
{"step": 90064, "time": 3134.9792137145996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3134.986636161804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3134.9937841892242, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3135.000259399414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3135.0066182613373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3135.013816833496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3135.020313024521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3135.0266165733337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3138.5787529945374, "episode/length": 288.0, "episode/score": 0.050690758624114096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050690758624114096}
{"step": 90168, "time": 3138.5873193740845, "episode/length": 288.0, "episode/score": 0.05381745721128084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05381745721128084}
{"step": 90240, "time": 3141.0868124961853, "episode/length": 288.0, "episode/score": 0.05841807919730968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05841807919730968}
{"step": 90392, "time": 3145.777355670929, "episode/length": 288.0, "episode/score": 0.03294893830511114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03294893830511114}
{"step": 90992, "time": 3164.849271297455, "episode/length": 288.0, "episode/score": 0.07151444296152931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07151444296152931}
{"step": 91384, "time": 3177.1516699790955, "episode/length": 288.0, "episode/score": 0.041483233246921714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041483233246921714}
{"step": 92137, "time": 3202.0752217769623, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999667167663574, "train/action_min": 0.0, "train/action_std": 2.0006614917268357, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00016848752558000038, "train/actor_opt_grad_steps": 4705.0, "train/actor_opt_loss": 1.2799260956332243, "train/adv_mag": 0.0007056581865375241, "train/adv_max": 0.0007056581865375241, "train/adv_mean": 0.00036530040708745065, "train/adv_min": -5.196007744719585e-05, "train/adv_std": 0.00017627009199827626, "train/cont_avg": 0.9963633219401041, "train/cont_loss_mean": 0.024131682901497697, "train/cont_loss_std": 0.3316451082197697, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.684835057509573, "train/cont_pos_acc": 0.9999999847883979, "train/cont_pos_loss": 0.003461765926961865, "train/cont_pred": 0.9965444182356199, "train/cont_rate": 0.9963633219401041, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.039104929203555606, "train/extr_critic_critic_opt_grad_steps": 4705.0, "train/extr_critic_critic_opt_loss": 13279.856587727865, "train/extr_critic_mag": 0.06901356764137745, "train/extr_critic_max": 0.06901356764137745, "train/extr_critic_mean": 0.06889094323075066, "train/extr_critic_min": 0.06881678104400635, "train/extr_critic_std": 2.660201149515609e-05, "train/extr_return_normed_mag": 0.0013321911101229489, "train/extr_return_normed_max": 0.0013321911101229489, "train/extr_return_normed_mean": 0.0010549826430784985, "train/extr_return_normed_min": 0.000685078693398585, "train/extr_return_normed_std": 0.0001724285623746861, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06953348000145827, "train/extr_return_raw_max": 0.06953348000145827, "train/extr_return_raw_mean": 0.06925627509675299, "train/extr_return_raw_min": 0.06888636758473392, "train/extr_return_raw_std": 0.00017242856210467986, "train/extr_reward_mag": 0.0002647986014684041, "train/extr_reward_max": 0.0002647986014684041, "train/extr_reward_mean": 0.00026469277774291794, "train/extr_reward_min": 0.00026457632581392926, "train/extr_reward_std": 4.4283069149687417e-08, "train/image_loss_mean": 0.26377951578858, "train/image_loss_std": 0.08596054563531652, "train/model_loss_mean": 0.8992969300597906, "train/model_loss_std": 0.3721158023690805, "train/model_opt_grad_norm": 67.2926503320535, "train/model_opt_grad_steps": 4695.0, "train/model_opt_loss": 177.99765606721243, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 198.16080729166666, "train/policy_entropy_mag": 1.945895462607344, "train/policy_entropy_max": 1.945895462607344, "train/policy_entropy_mean": 1.945173538600405, "train/policy_entropy_min": 1.9312702336659033, "train/policy_entropy_std": 0.0005264233348801403, "train/policy_logprob_mag": 2.1552437469363213, "train/policy_logprob_max": -1.71910734847188, "train/policy_logprob_mean": -1.9451745320111513, "train/policy_logprob_min": -2.1552437469363213, "train/policy_logprob_std": 0.03826927267558252, "train/policy_randomness_mag": 0.9999925121665001, "train/policy_randomness_max": 0.9999925121665001, "train/policy_randomness_mean": 0.9996215142309666, "train/policy_randomness_min": 0.9924766325081388, "train/policy_randomness_std": 0.0002705280850629303, "train/post_ent_mag": 45.011488358179726, "train/post_ent_max": 45.011488358179726, "train/post_ent_mean": 44.91612062851588, "train/post_ent_min": 44.86137159665426, "train/post_ent_std": 0.021832742718591664, "train/prior_ent_mag": 53.053029934565224, "train/prior_ent_max": 53.053029934565224, "train/prior_ent_mean": 52.9593817392985, "train/prior_ent_min": 51.795543690522514, "train/prior_ent_std": 0.20031033867659667, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00027700568762156763, "train/reward_loss_mean": 0.011385709503277516, "train/reward_loss_std": 0.050215488702330426, "train/reward_max_data": 0.06850802986567335, "train/reward_max_pred": 0.00026490166783332825, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010223069698743833, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.042623065766835, "train/reward_pred": 0.0002646905904839514, "train/reward_rate": 0.00011698404947916667, "train_stats/mean_log_entropy": 1.9375476792173565, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020039919763803482, "report/cont_loss_std": 0.3080270290374756, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.702561855316162, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033429861068725586, "report/cont_pred": 0.9966623783111572, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2575175166130066, "report/image_loss_std": 0.0759437307715416, "report/model_loss_mean": 0.8880233764648438, "report/model_loss_std": 0.31969937682151794, "report/post_ent_mag": 41.089759826660156, "report/post_ent_max": 41.089759826660156, "report/post_ent_mean": 41.06426239013672, "report/post_ent_min": 40.92736053466797, "report/post_ent_std": 0.03240106999874115, "report/prior_ent_mag": 51.19392395019531, "report/prior_ent_max": 51.19392395019531, "report/prior_ent_mean": 51.106014251708984, "report/prior_ent_min": 50.09489440917969, "report/prior_ent_std": 0.17307382822036743, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002140033757314086, "report/reward_loss_mean": 0.010465886443853378, "report/reward_loss_std": 0.01714523881673813, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00023734569549560547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010465887375175953, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00023639481514692307, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0033429863397032022, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033429863397032022, "eval/cont_pred": 0.9966623783111572, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2517632246017456, "eval/image_loss_std": 0.06981795281171799, "eval/model_loss_mean": 0.8564117550849915, "eval/model_loss_std": 0.06981796026229858, "eval/post_ent_mag": 41.091209411621094, "eval/post_ent_max": 41.091209411621094, "eval/post_ent_mean": 41.06618881225586, "eval/post_ent_min": 40.9294319152832, "eval/post_ent_std": 0.02979177236557007, "eval/prior_ent_mag": 51.189002990722656, "eval/prior_ent_max": 51.189002990722656, "eval/prior_ent_mean": 51.114131927490234, "eval/prior_ent_min": 50.09489440917969, "eval/prior_ent_std": 0.15941122174263, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013055321760475636, "eval/reward_loss_std": 2.814070114709466e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00023734569549560547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013055321760475636, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023639388382434845, "eval/reward_rate": 0.0, "replay/size": 91633.0, "replay/inserts": 30704.0, "replay/samples": 30704.0, "replay/insert_wait_avg": 1.3480697714331995e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.011353224873108e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2521100291743824e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0354726314545, "timer/env.step_count": 3838.0, "timer/env.step_total": 39.12223696708679, "timer/env.step_frac": 0.039120849247619244, "timer/env.step_avg": 0.01019339160163804, "timer/env.step_min": 0.00890493392944336, "timer/env.step_max": 0.03633904457092285, "timer/replay._sample_count": 30704.0, "timer/replay._sample_total": 16.08491086959839, "timer/replay._sample_frac": 0.01608434031572218, "timer/replay._sample_avg": 0.0005238702081031263, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.032446861267089844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4705.0, "timer/agent.policy_total": 50.35929870605469, "timer/agent.policy_frac": 0.050357512392576624, "timer/agent.policy_avg": 0.010703357854634365, "timer/agent.policy_min": 0.009196758270263672, "timer/agent.policy_max": 0.09180212020874023, "timer/dataset_train_count": 1919.0, "timer/dataset_train_total": 0.21024298667907715, "timer/dataset_train_frac": 0.00021023552907163575, "timer/dataset_train_avg": 0.00010955861734188491, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.00026988983154296875, "timer/agent.train_count": 1919.0, "timer/agent.train_total": 859.018308877945, "timer/agent.train_frac": 0.8589878383189324, "timer/agent.train_avg": 0.4476385142667769, "timer/agent.train_min": 0.43677234649658203, "timer/agent.train_max": 0.9529135227203369, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760160446166992, "timer/agent.report_frac": 0.0004759991596739355, "timer/agent.report_avg": 0.2380080223083496, "timer/agent.report_min": 0.22919082641601562, "timer/agent.report_max": 0.2468252182006836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0516495624597426e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 30.70238908320295}
{"step": 92232, "time": 3204.824512243271, "episode/length": 288.0, "episode/score": 0.056135942481844836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056135942481844836}
{"step": 92288, "time": 3206.8242421150208, "episode/length": 288.0, "episode/score": 0.04498587313987912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04498587313987912}
{"step": 92480, "time": 3212.8943779468536, "episode/length": 288.0, "episode/score": 0.030907927181729633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030907927181729633}
{"step": 92480, "time": 3212.9026482105255, "episode/length": 288.0, "episode/score": 0.047467163469022466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047467163469022466}
{"step": 92552, "time": 3214.9465112686157, "episode/length": 288.0, "episode/score": 0.042960511400039536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042960511400039536}
{"step": 92704, "time": 3219.958444595337, "episode/length": 288.0, "episode/score": 0.03308593936070281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03308593936070281}
{"step": 93304, "time": 3238.8166909217834, "episode/length": 288.0, "episode/score": 0.05840183216857042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05840183216857042}
{"step": 93696, "time": 3251.363480091095, "episode/length": 288.0, "episode/score": 0.03699367269238962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03699367269238962}
{"step": 94544, "time": 3278.2134516239166, "episode/length": 288.0, "episode/score": 0.07632503908745036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07632503908745036}
{"step": 94600, "time": 3279.763360261917, "episode/length": 288.0, "episode/score": 0.06277216316887291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06277216316887291}
{"step": 94792, "time": 3285.832896232605, "episode/length": 288.0, "episode/score": 0.06389866398003363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06389866398003363}
{"step": 94792, "time": 3285.8416006565094, "episode/length": 288.0, "episode/score": 0.041478132798623335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041478132798623335}
{"step": 94864, "time": 3288.3457510471344, "episode/length": 288.0, "episode/score": 0.05090793928981441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05090793928981441}
{"step": 94984, "time": 3291.992542743683, "episode/length": 23.0, "episode/score": 0.9436403901973733, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.01551535203643084}
{"step": 95016, "time": 3293.026386976242, "episode/length": 288.0, "episode/score": 0.052465959080684854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052465959080684854}
{"step": 95616, "time": 3312.0749344825745, "episode/length": 288.0, "episode/score": 0.05821792665329184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05821792665329184}
{"step": 96008, "time": 3324.363026380539, "episode/length": 288.0, "episode/score": 0.025268363025269025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025268363025269025}
{"step": 96856, "time": 3351.0223910808563, "episode/length": 288.0, "episode/score": 0.06249671365304721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06249671365304721}
{"step": 96912, "time": 3353.114063024521, "episode/length": 288.0, "episode/score": 0.054491365144194504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054491365144194504}
{"step": 97104, "time": 3359.143926858902, "episode/length": 288.0, "episode/score": 0.05075715235589229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05075715235589229}
{"step": 97176, "time": 3361.205451965332, "episode/length": 288.0, "episode/score": 0.042572759710758135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042572759710758135}
{"step": 97296, "time": 3365.380543231964, "episode/length": 288.0, "episode/score": 0.05542558991267299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05542558991267299}
{"step": 97328, "time": 3366.4057545661926, "episode/length": 288.0, "episode/score": 0.07025070370004016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07025070370004016}
{"step": 97928, "time": 3385.134519815445, "episode/length": 288.0, "episode/score": 0.06010867353780469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06010867353780469}
{"step": 98320, "time": 3398.2386333942413, "episode/length": 288.0, "episode/score": 0.06273238664001468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06273238664001468}
{"step": 99168, "time": 3425.2263538837433, "episode/length": 288.0, "episode/score": 0.06812617696357393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06812617696357393}
{"step": 99224, "time": 3426.8104569911957, "episode/length": 288.0, "episode/score": 0.0762149478288805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0762149478288805}
{"step": 99416, "time": 3432.9959766864777, "episode/length": 288.0, "episode/score": 0.06335683608077147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06335683608077147}
{"step": 99488, "time": 3435.5521986484528, "episode/length": 288.0, "episode/score": 0.05732235783251838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05732235783251838}
{"step": 99592, "time": 3438.663239002228, "episode/length": 45.0, "episode/score": 0.8733348662944991, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.01395983765632991}
{"step": 99608, "time": 3439.1840789318085, "episode/length": 288.0, "episode/score": 0.07149261076131097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07149261076131097}
{"step": 99640, "time": 3440.2343163490295, "episode/length": 288.0, "episode/score": 0.09410652125120578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09410652125120578}
{"step": 100048, "time": 3456.2907593250275, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 100048, "time": 3459.524467229843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3459.5319623947144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3459.5389387607574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3459.5458359718323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3459.552572488785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3459.559661626816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3459.5675048828125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100240, "time": 3465.631094932556, "episode/length": 288.0, "episode/score": 0.07646255837698845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07646255837698845}
{"step": 100632, "time": 3477.969660758972, "episode/length": 288.0, "episode/score": 0.0866236211809337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0866236211809337}
{"step": 101480, "time": 3504.733758211136, "episode/length": 288.0, "episode/score": 0.05633149532252446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05633149532252446}
{"step": 101728, "time": 3512.7411818504333, "episode/length": 288.0, "episode/score": 0.06908931809891783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06908931809891783}
{"step": 101800, "time": 3514.772400379181, "episode/length": 288.0, "episode/score": 0.05907054325393801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05907054325393801}
{"step": 101904, "time": 3518.254180908203, "episode/length": 288.0, "episode/score": 0.08220475781234882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08220475781234882}
{"step": 101920, "time": 3518.761193037033, "episode/length": 288.0, "episode/score": 0.0550737973841251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0550737973841251}
{"step": 101952, "time": 3519.768920660019, "episode/length": 288.0, "episode/score": 0.05417090224642607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05417090224642607}
{"step": 102552, "time": 3538.4668776988983, "episode/length": 288.0, "episode/score": 0.03557293966315456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03557293966315456}
{"step": 102944, "time": 3551.073256254196, "episode/length": 288.0, "episode/score": 0.05562670577381823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05562670577381823}
{"step": 103792, "time": 3577.993585586548, "episode/length": 288.0, "episode/score": 0.059629896269200344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059629896269200344}
{"step": 104040, "time": 3585.5903613567352, "episode/length": 288.0, "episode/score": 0.059158301436070815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059158301436070815}
{"step": 104112, "time": 3588.0938506126404, "episode/length": 288.0, "episode/score": 0.04777901104398552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04777901104398552}
{"step": 104216, "time": 3591.150505542755, "episode/length": 288.0, "episode/score": 0.060058547621906655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060058547621906655}
{"step": 104232, "time": 3591.7986738681793, "episode/length": 288.0, "episode/score": 0.04254385720236087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04254385720236087}
{"step": 104264, "time": 3592.80087351799, "episode/length": 288.0, "episode/score": 0.06301351353283735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06301351353283735}
{"step": 104864, "time": 3611.886237859726, "episode/length": 288.0, "episode/score": 0.054908666280198304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054908666280198304}
{"step": 105256, "time": 3624.168736219406, "episode/length": 288.0, "episode/score": 0.0547017561652865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0547017561652865}
{"step": 106104, "time": 3650.8956956863403, "episode/length": 288.0, "episode/score": 0.057536089315192385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057536089315192385}
{"step": 106352, "time": 3659.093882083893, "episode/length": 288.0, "episode/score": 0.07375908581693125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07375908581693125}
{"step": 106424, "time": 3661.1498136520386, "episode/length": 288.0, "episode/score": 0.058364493416263485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058364493416263485}
{"step": 106528, "time": 3665.1750195026398, "episode/length": 288.0, "episode/score": 0.061713060868498815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061713060868498815}
{"step": 106544, "time": 3665.692471265793, "episode/length": 288.0, "episode/score": 0.09013126115161185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09013126115161185}
{"step": 106576, "time": 3666.7112905979156, "episode/length": 288.0, "episode/score": 0.030363667513512382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030363667513512382}
{"step": 107176, "time": 3685.5700764656067, "episode/length": 288.0, "episode/score": 0.06406941958402967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06406941958402967}
{"step": 107568, "time": 3698.1409006118774, "episode/length": 288.0, "episode/score": 0.04817495007500838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04817495007500838}
{"step": 108416, "time": 3725.021468400955, "episode/length": 288.0, "episode/score": 0.030532464135944792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030532464135944792}
{"step": 108664, "time": 3732.673042535782, "episode/length": 288.0, "episode/score": 0.06264827834320386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06264827834320386}
{"step": 108736, "time": 3735.1689898967743, "episode/length": 288.0, "episode/score": 0.05557592680156631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05557592680156631}
{"step": 108840, "time": 3738.2452676296234, "episode/length": 288.0, "episode/score": 0.0558978401311947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0558978401311947}
{"step": 108856, "time": 3738.7580127716064, "episode/length": 288.0, "episode/score": 0.04518047677686354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04518047677686354}
{"step": 108888, "time": 3739.7813317775726, "episode/length": 288.0, "episode/score": 0.026785355932986477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026785355932986477}
{"step": 109488, "time": 3759.072410583496, "episode/length": 288.0, "episode/score": 0.04903172004821954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04903172004821954}
{"step": 109880, "time": 3771.2831239700317, "episode/length": 288.0, "episode/score": 0.060638077848068406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060638077848068406}
{"step": 110032, "time": 3780.0691182613373, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 110032, "time": 3783.028298854828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3783.0361936092377, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3783.043548822403, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3783.05073094368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3783.057867050171, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3783.0648086071014, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3783.0718755722046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110728, "time": 3804.995406150818, "episode/length": 288.0, "episode/score": 0.049710046760822024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049710046760822024}
{"step": 110976, "time": 3813.0128269195557, "episode/length": 288.0, "episode/score": 0.04901366625750825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04901366625750825}
{"step": 111048, "time": 3815.1162564754486, "episode/length": 288.0, "episode/score": 0.05409830611108646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05409830611108646}
{"step": 111152, "time": 3818.6171901226044, "episode/length": 288.0, "episode/score": 0.08010399056041706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08010399056041706}
{"step": 111168, "time": 3819.122403860092, "episode/length": 288.0, "episode/score": 0.04240107682767302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04240107682767302}
{"step": 111200, "time": 3820.1315274238586, "episode/length": 288.0, "episode/score": 0.08099494406616259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08099494406616259}
{"step": 111800, "time": 3838.922583580017, "episode/length": 288.0, "episode/score": 0.05608524391379888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05608524391379888}
{"step": 112192, "time": 3851.5739526748657, "episode/length": 288.0, "episode/score": 0.04375133822952648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04375133822952648}
{"step": 113040, "time": 3878.4871475696564, "episode/length": 288.0, "episode/score": 0.05719998711020935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05719998711020935}
{"step": 113288, "time": 3886.1151797771454, "episode/length": 288.0, "episode/score": 0.09044258671031002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09044258671031002}
{"step": 113360, "time": 3888.6187450885773, "episode/length": 288.0, "episode/score": 0.06479061026982436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06479061026982436}
{"step": 113464, "time": 3891.823091983795, "episode/length": 288.0, "episode/score": 0.0629020602680157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0629020602680157}
{"step": 113480, "time": 3892.3447585105896, "episode/length": 288.0, "episode/score": 0.04305992855904606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04305992855904606}
{"step": 113512, "time": 3893.3613419532776, "episode/length": 288.0, "episode/score": 0.039853275284599476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039853275284599476}
{"step": 114112, "time": 3912.597228050232, "episode/length": 288.0, "episode/score": 0.05750960476322575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05750960476322575}
{"step": 114504, "time": 3924.868572473526, "episode/length": 288.0, "episode/score": 0.06262694121963364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06262694121963364}
{"step": 114744, "time": 3933.0121750831604, "episode/length": 172.0, "episode/score": 0.5082399403041791, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.04573993550786781}
{"step": 115352, "time": 3952.342651605606, "episode/length": 288.0, "episode/score": 0.07161592306232478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07161592306232478}
{"step": 115600, "time": 3960.360339641571, "episode/length": 288.0, "episode/score": 0.06046869010253886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06046869010253886}
{"step": 115776, "time": 3965.89985537529, "episode/length": 288.0, "episode/score": 0.027746670319174882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027746670319174882}
{"step": 115792, "time": 3966.4293627738953, "episode/length": 288.0, "episode/score": 0.06792667681557418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06792667681557418}
{"step": 115824, "time": 3967.4391901493073, "episode/length": 288.0, "episode/score": 0.06270268656325584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06270268656325584}
{"step": 116424, "time": 3986.5576705932617, "episode/length": 288.0, "episode/score": 0.054415701175912545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054415701175912545}
{"step": 116816, "time": 3999.1704244613647, "episode/length": 288.0, "episode/score": 0.08119521480830372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08119521480830372}
{"step": 116840, "time": 3999.707544326782, "episode/length": 154.0, "episode/score": 0.5553809970940051, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.03663098598798342}
{"step": 117056, "time": 4006.7302651405334, "episode/length": 288.0, "episode/score": 0.0475665093088935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0475665093088935}
{"step": 117664, "time": 4026.0567939281464, "episode/length": 288.0, "episode/score": 0.05142774133804551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05142774133804551}
{"step": 118088, "time": 4039.2383959293365, "episode/length": 288.0, "episode/score": 0.04798474734857905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04798474734857905}
{"step": 118104, "time": 4039.751920223236, "episode/length": 288.0, "episode/score": 0.06721641412960366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06721641412960366}
{"step": 118136, "time": 4040.7635385990143, "episode/length": 288.0, "episode/score": 0.06068100961709888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06068100961709888}
{"step": 118736, "time": 4059.9376475811005, "episode/length": 288.0, "episode/score": 0.07629082518940322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07629082518940322}
{"step": 119128, "time": 4072.165831565857, "episode/length": 288.0, "episode/score": 0.07440269508254005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07440269508254005}
{"step": 119152, "time": 4073.170345544815, "episode/length": 288.0, "episode/score": 0.05946118790072319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05946118790072319}
{"step": 119368, "time": 4079.821669101715, "episode/length": 288.0, "episode/score": 0.062125884283460664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062125884283460664}
{"step": 119976, "time": 4099.030532360077, "episode/length": 288.0, "episode/score": 0.06384100438754103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06384100438754103}
{"step": 120016, "time": 4106.676104784012, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.683997154236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.693906784058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.705443620682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.715532779694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.72306060791, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.729808330536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4106.736115455627, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120400, "time": 4118.931376457214, "episode/length": 288.0, "episode/score": 0.06230818035191987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06230818035191987}
{"step": 120416, "time": 4119.441076040268, "episode/length": 288.0, "episode/score": 0.06714574895954684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06714574895954684}
{"step": 120448, "time": 4120.4724860191345, "episode/length": 288.0, "episode/score": 0.03713579035786552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03713579035786552}
{"step": 121048, "time": 4139.274690628052, "episode/length": 288.0, "episode/score": 0.05428601901900265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05428601901900265}
{"step": 121440, "time": 4151.838246583939, "episode/length": 288.0, "episode/score": 0.0661287149100076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0661287149100076}
{"step": 121464, "time": 4152.38072347641, "episode/length": 288.0, "episode/score": 0.06619888112385297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06619888112385297}
{"step": 121680, "time": 4159.4235026836395, "episode/length": 288.0, "episode/score": 0.08492568147880775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08492568147880775}
{"step": 122288, "time": 4178.826894044876, "episode/length": 288.0, "episode/score": 0.07685951630855925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07685951630855925}
{"step": 122712, "time": 4192.121935606003, "episode/length": 288.0, "episode/score": 0.052888731436610215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052888731436610215}
{"step": 122728, "time": 4192.631973981857, "episode/length": 288.0, "episode/score": 0.08252136850785519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08252136850785519}
{"step": 122760, "time": 4193.6493446826935, "episode/length": 288.0, "episode/score": 0.08542739248264297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08542739248264297}
{"step": 122985, "time": 4202.268592119217, "train_stats/mean_log_entropy": 1.937641708978585, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.002814258318491, "train/action_min": 0.0, "train/action_std": 1.999567332045402, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.55170811887131e-05, "train/actor_opt_grad_steps": 6630.0, "train/actor_opt_loss": -3.1282997480907277, "train/adv_mag": 0.0003513002797111946, "train/adv_max": 0.00033592687524044453, "train/adv_mean": 0.00013444130193810818, "train/adv_min": -0.00011671774591188974, "train/adv_std": 8.353394459162432e-05, "train/cont_avg": 0.996594681023316, "train/cont_loss_mean": 0.02277032661473697, "train/cont_loss_std": 0.31799884347685214, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666466040814177, "train/cont_pos_acc": 0.9999999839407174, "train/cont_pos_loss": 0.0034980416572966415, "train/cont_pred": 0.9965082369937798, "train/cont_rate": 0.996594681023316, "train/dyn_loss_mean": 1.0000000450895241, "train/dyn_loss_std": 3.724407381740027e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02341221551859626, "train/extr_critic_critic_opt_grad_steps": 6630.0, "train/extr_critic_critic_opt_loss": 13499.461666126943, "train/extr_critic_mag": 0.07734941139122364, "train/extr_critic_max": 0.07734941139122364, "train/extr_critic_mean": 0.07722408996190432, "train/extr_critic_min": 0.07715350173297941, "train/extr_critic_std": 2.985951942114451e-05, "train/extr_return_normed_mag": 0.0005435847479444712, "train/extr_return_normed_max": 0.0005346657080971515, "train/extr_return_normed_mean": 0.0003974375572126585, "train/extr_return_normed_min": 0.00021823935712557383, "train/extr_return_normed_std": 7.413945464003673e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07749571790194883, "train/extr_return_raw_max": 0.07749571790194883, "train/extr_return_raw_mean": 0.07735849422803197, "train/extr_return_raw_min": 0.07717929155097725, "train/extr_return_raw_std": 7.413945550343821e-05, "train/extr_reward_mag": 0.0002534130076670276, "train/extr_reward_max": 0.0002534130076670276, "train/extr_reward_mean": 0.00025328572545745866, "train/extr_reward_min": 0.00025316655944666096, "train/extr_reward_std": 5.644773996183596e-08, "train/image_loss_mean": 0.2563568183023077, "train/image_loss_std": 0.0856082364530761, "train/model_loss_mean": 0.8903988448449367, "train/model_loss_std": 0.36501218413287495, "train/model_opt_grad_norm": 58.138540900433, "train/model_opt_grad_steps": 6620.0, "train/model_opt_loss": 672.7367035070232, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 756.1528497409327, "train/policy_entropy_mag": 1.9458986860482803, "train/policy_entropy_max": 1.9458986860482803, "train/policy_entropy_mean": 1.9453300225302346, "train/policy_entropy_min": 1.9348858057526108, "train/policy_entropy_std": 0.0004146731151883138, "train/policy_logprob_mag": 2.1312488014833915, "train/policy_logprob_max": -1.7569087607872917, "train/policy_logprob_mean": -1.9453362177073028, "train/policy_logprob_min": -2.1312488014833915, "train/policy_logprob_std": 0.033706770543916235, "train/policy_randomness_mag": 0.9999941680097827, "train/policy_randomness_max": 0.9999941680097827, "train/policy_randomness_mean": 0.9997019285982754, "train/policy_randomness_min": 0.994334666840153, "train/policy_randomness_std": 0.00021309982899303786, "train/post_ent_mag": 41.66835775029474, "train/post_ent_max": 41.66835775029474, "train/post_ent_mean": 41.63063430786133, "train/post_ent_min": 41.346403250422505, "train/post_ent_std": 0.06389336751223845, "train/prior_ent_mag": 50.81307064313345, "train/prior_ent_max": 50.81307064313345, "train/prior_ent_mean": 50.72883876741241, "train/prior_ent_min": 49.8017791392272, "train/prior_ent_std": 0.16404156419665702, "train/rep_loss_mean": 1.0000000450895241, "train/rep_loss_std": 3.724407381740027e-07, "train/reward_avg": 0.00029220668296812226, "train/reward_loss_mean": 0.011271654748854859, "train/reward_loss_std": 0.05647013749483336, "train/reward_max_data": 0.09100712520200663, "train/reward_max_pred": 0.00025343771425553554, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009898893663013074, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.145599308013916, "train/reward_pred": 0.00025319717426354867, "train/reward_rate": 0.0001366175518134715, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009187457151710987, "report/cont_loss_std": 0.1745973378419876, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.593572616577148, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037286223378032446, "report/cont_pred": 0.9962780475616455, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2590276002883911, "report/image_loss_std": 0.07872527092695236, "report/model_loss_mean": 0.8801591992378235, "report/model_loss_std": 0.1939326673746109, "report/post_ent_mag": 49.73173522949219, "report/post_ent_max": 49.73173522949219, "report/post_ent_mean": 49.71931457519531, "report/post_ent_min": 49.59042739868164, "report/post_ent_std": 0.021613799035549164, "report/prior_ent_mag": 52.412071228027344, "report/prior_ent_max": 52.412071228027344, "report/prior_ent_mean": 52.37099075317383, "report/prior_ent_min": 52.33442687988281, "report/prior_ent_std": 0.01511712558567524, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002497783279977739, "report/reward_loss_mean": 0.01194409467279911, "report/reward_loss_std": 0.01778813637793064, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002416372299194336, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011944095604121685, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002416372299194336, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0037285799626260996, "eval/cont_loss_std": 1.011406766338041e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037285799626260996, "eval/cont_pred": 0.9962781071662903, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2551524043083191, "eval/image_loss_std": 0.07427731901407242, "eval/model_loss_mean": 0.8602399826049805, "eval/model_loss_std": 0.07427731156349182, "eval/post_ent_mag": 49.73381042480469, "eval/post_ent_max": 49.73381042480469, "eval/post_ent_mean": 49.719635009765625, "eval/post_ent_min": 49.590675354003906, "eval/post_ent_std": 0.02097785286605358, "eval/prior_ent_mag": 52.409461975097656, "eval/prior_ent_max": 52.409461975097656, "eval/prior_ent_mean": 52.37046813964844, "eval/prior_ent_min": 52.33442687988281, "eval/prior_ent_std": 0.014536264352500439, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013589859008789062, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002416372299194336, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013589859008789062, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002416372299194336, "eval/reward_rate": 0.0, "replay/size": 122481.0, "replay/inserts": 30848.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.3431140001384055e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.96785663470193e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3052867220622308e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1741383075714, "timer/env.step_count": 3856.0, "timer/env.step_total": 38.94088959693909, "timer/env.step_frac": 0.03893410967697314, "timer/env.step_avg": 0.010098778422442709, "timer/env.step_min": 0.008919477462768555, "timer/env.step_max": 0.036234140396118164, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.723891258239746, "timer/replay._sample_frac": 0.015721153603158223, "timer/replay._sample_avg": 0.000509721578651444, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.028296947479248047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4723.0, "timer/agent.policy_total": 49.73595881462097, "timer/agent.policy_frac": 0.049727299386865646, "timer/agent.policy_avg": 0.010530586240656567, "timer/agent.policy_min": 0.009071588516235352, "timer/agent.policy_max": 0.08641409873962402, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.20664072036743164, "timer/dataset_train_frac": 0.00020660474256722477, "timer/dataset_train_avg": 0.00010717879687107451, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0003566741943359375, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 860.1452705860138, "timer/agent.train_frac": 0.8599955124229615, "timer/agent.train_avg": 0.4461334391006296, "timer/agent.train_min": 0.43462204933166504, "timer/agent.train_max": 0.5963051319122314, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4672536849975586, "timer/agent.report_frac": 0.0004671723323982506, "timer/agent.report_avg": 0.2336268424987793, "timer/agent.report_min": 0.22197651863098145, "timer/agent.report_max": 0.24527716636657715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2896035456075494e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 30.842107746051468}
{"step": 123360, "time": 4214.180329799652, "episode/length": 288.0, "episode/score": 0.037256848246158825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037256848246158825}
{"step": 123752, "time": 4226.420600414276, "episode/length": 288.0, "episode/score": 0.07117544420913191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07117544420913191}
{"step": 123776, "time": 4227.405994415283, "episode/length": 288.0, "episode/score": 0.03205544764085744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03205544764085744}
{"step": 123992, "time": 4234.01526093483, "episode/length": 288.0, "episode/score": 0.0317173197631746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0317173197631746}
{"step": 124088, "time": 4237.043757200241, "episode/length": 224.0, "episode/score": 0.34676893415991117, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.04676892340313543}
{"step": 125024, "time": 4266.974326610565, "episode/length": 288.0, "episode/score": 0.06357158639497129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06357158639497129}
{"step": 125040, "time": 4267.489355325699, "episode/length": 288.0, "episode/score": 0.06269789422350414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06269789422350414}
{"step": 125072, "time": 4268.519948482513, "episode/length": 288.0, "episode/score": 0.044762070156423306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044762070156423306}
{"step": 125672, "time": 4287.408820390701, "episode/length": 288.0, "episode/score": 0.06249585420772519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06249585420772519}
{"step": 126064, "time": 4299.925685167313, "episode/length": 288.0, "episode/score": 0.047087020738672436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047087020738672436}
{"step": 126088, "time": 4300.459329128265, "episode/length": 288.0, "episode/score": 0.05684663852957783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05684663852957783}
{"step": 126304, "time": 4307.438903570175, "episode/length": 288.0, "episode/score": 0.06693172420153815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06693172420153815}
{"step": 126400, "time": 4310.464156627655, "episode/length": 288.0, "episode/score": 0.04001805456954344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04001805456954344}
{"step": 127336, "time": 4340.11470580101, "episode/length": 288.0, "episode/score": 0.06139893659349127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06139893659349127}
{"step": 127352, "time": 4340.630666017532, "episode/length": 288.0, "episode/score": 0.039661891965124596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039661891965124596}
{"step": 127384, "time": 4341.792391061783, "episode/length": 288.0, "episode/score": 0.029289773396783403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029289773396783403}
{"step": 127984, "time": 4360.990027427673, "episode/length": 288.0, "episode/score": 0.06315168000475069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06315168000475069}
{"step": 128376, "time": 4373.3391218185425, "episode/length": 288.0, "episode/score": 0.04487365469040583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04487365469040583}
{"step": 128400, "time": 4374.325615167618, "episode/length": 288.0, "episode/score": 0.06269533964717766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06269533964717766}
{"step": 128616, "time": 4381.006691455841, "episode/length": 288.0, "episode/score": 0.06134669090388911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06134669090388911}
{"step": 128712, "time": 4384.041532754898, "episode/length": 288.0, "episode/score": 0.04160527662705249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04160527662705249}
{"step": 129344, "time": 4404.315015077591, "episode/length": 90.0, "episode/score": 0.7441153735271655, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.025365344888996333}
{"step": 129536, "time": 4410.368941545486, "episode/length": 193.0, "episode/score": 0.44435819933710263, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.04748320646172033}
{"step": 129648, "time": 4413.916131973267, "episode/length": 288.0, "episode/score": 0.0531586283998422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0531586283998422}
{"step": 129664, "time": 4414.423297405243, "episode/length": 288.0, "episode/score": 0.05545409943363211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05545409943363211}
{"step": 129696, "time": 4415.435302734375, "episode/length": 288.0, "episode/score": 0.028190995293527976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028190995293527976}
{"step": 130000, "time": 4432.460729837418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.468242645264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.475289106369, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.482395887375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.489020347595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.495520353317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.502599477768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.510061502457, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130688, "time": 4454.142853975296, "episode/length": 288.0, "episode/score": 0.03925112650506435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03925112650506435}
{"step": 130712, "time": 4454.676978588104, "episode/length": 288.0, "episode/score": 0.05849474562978685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05849474562978685}
{"step": 131024, "time": 4464.83820605278, "episode/length": 288.0, "episode/score": 0.040096454333820475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040096454333820475}
{"step": 131656, "time": 4485.028818130493, "episode/length": 288.0, "episode/score": 0.04484486012756861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04484486012756861}
{"step": 131848, "time": 4491.085244178772, "episode/length": 288.0, "episode/score": 0.04833642558708107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04833642558708107}
{"step": 131960, "time": 4494.700996637344, "episode/length": 288.0, "episode/score": 0.03850393730772339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03850393730772339}
{"step": 131976, "time": 4495.206165552139, "episode/length": 288.0, "episode/score": 0.045530218364945085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045530218364945085}
{"step": 132008, "time": 4496.21284866333, "episode/length": 288.0, "episode/score": 0.026834087139832263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026834087139832263}
{"step": 133000, "time": 4527.456632137299, "episode/length": 288.0, "episode/score": 0.04333401018368477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04333401018368477}
{"step": 133024, "time": 4528.433669090271, "episode/length": 288.0, "episode/score": 0.04371727942094594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04371727942094594}
{"step": 133336, "time": 4538.047072649002, "episode/length": 288.0, "episode/score": 0.06122061594265915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06122061594265915}
{"step": 133968, "time": 4558.4027490615845, "episode/length": 288.0, "episode/score": 0.06101562028277385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06101562028277385}
{"step": 134160, "time": 4564.493606805801, "episode/length": 288.0, "episode/score": 0.06433370743218347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06433370743218347}
{"step": 134272, "time": 4568.028880119324, "episode/length": 288.0, "episode/score": 0.030987946900040697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030987946900040697}
{"step": 134288, "time": 4568.537225246429, "episode/length": 288.0, "episode/score": 0.05807509904570907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05807509904570907}
{"step": 134320, "time": 4569.544349431992, "episode/length": 288.0, "episode/score": 0.05253006360572954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05253006360572954}
{"step": 135312, "time": 4600.903822183609, "episode/length": 288.0, "episode/score": 0.050177279176921274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050177279176921274}
{"step": 135336, "time": 4601.44310092926, "episode/length": 288.0, "episode/score": 0.06401541490112095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06401541490112095}
{"step": 135648, "time": 4611.512548923492, "episode/length": 288.0, "episode/score": 0.060382476033396415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060382476033396415}
{"step": 136280, "time": 4631.271759033203, "episode/length": 288.0, "episode/score": 0.029690259533765584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029690259533765584}
{"step": 136472, "time": 4637.354475259781, "episode/length": 288.0, "episode/score": 0.042463380317485644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042463380317485644}
{"step": 136584, "time": 4640.892721652985, "episode/length": 288.0, "episode/score": 0.07548328406659266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07548328406659266}
{"step": 136600, "time": 4641.51092839241, "episode/length": 288.0, "episode/score": 0.06087872037528541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06087872037528541}
{"step": 136632, "time": 4642.59127664566, "episode/length": 288.0, "episode/score": 0.04185319915598029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04185319915598029}
{"step": 137624, "time": 4673.973617315292, "episode/length": 288.0, "episode/score": 0.038265077531548286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038265077531548286}
{"step": 137648, "time": 4674.968496084213, "episode/length": 288.0, "episode/score": 0.06425292551978146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06425292551978146}
{"step": 137960, "time": 4684.6369462013245, "episode/length": 288.0, "episode/score": 0.05950858964155259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05950858964155259}
{"step": 138592, "time": 4704.909257650375, "episode/length": 288.0, "episode/score": 0.050119195529021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050119195529021}
{"step": 138784, "time": 4710.954201936722, "episode/length": 288.0, "episode/score": 0.049442565799211025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049442565799211025}
{"step": 138896, "time": 4714.4809448719025, "episode/length": 288.0, "episode/score": 0.04757667402731158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04757667402731158}
{"step": 138912, "time": 4714.986923456192, "episode/length": 288.0, "episode/score": 0.0753080848807599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0753080848807599}
{"step": 138944, "time": 4715.998158216476, "episode/length": 288.0, "episode/score": 0.0546547863140745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0546547863140745}
{"step": 139936, "time": 4747.8910484313965, "episode/length": 288.0, "episode/score": 0.0683591574716047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0683591574716047}
{"step": 139960, "time": 4748.452153921127, "episode/length": 288.0, "episode/score": 0.09001999527691851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09001999527691851}
{"step": 140088, "time": 4758.436154603958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.444159984589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.452013254166, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.459252357483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.465864181519, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.473165512085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.48090839386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4758.4893090724945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140272, "time": 4764.618072509766, "episode/length": 288.0, "episode/score": 0.07725306532375953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07725306532375953}
{"step": 140904, "time": 4784.3296666145325, "episode/length": 288.0, "episode/score": 0.09483743005654333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09483743005654333}
{"step": 141096, "time": 4790.415342569351, "episode/length": 288.0, "episode/score": 0.060342158426124115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060342158426124115}
{"step": 141208, "time": 4794.032794952393, "episode/length": 288.0, "episode/score": 0.08348934562468457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08348934562468457}
{"step": 141224, "time": 4794.541090965271, "episode/length": 288.0, "episode/score": 0.06754389406000882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06754389406000882}
{"step": 141256, "time": 4795.569571971893, "episode/length": 288.0, "episode/score": 0.08469728348825356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08469728348825356}
{"step": 142024, "time": 4819.685133218765, "episode/length": 257.0, "episode/score": 0.25929273788997875, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.06241773309366749}
{"step": 142248, "time": 4826.884211301804, "episode/length": 288.0, "episode/score": 0.0640903389377172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0640903389377172}
{"step": 142584, "time": 4837.465902805328, "episode/length": 288.0, "episode/score": 0.08395057835724629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08395057835724629}
{"step": 143216, "time": 4857.627725839615, "episode/length": 288.0, "episode/score": 0.06259981138609305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06259981138609305}
{"step": 143408, "time": 4863.659257650375, "episode/length": 288.0, "episode/score": 0.04448448200957955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04448448200957955}
{"step": 143520, "time": 4867.186577320099, "episode/length": 288.0, "episode/score": 0.0494360436661907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0494360436661907}
{"step": 143536, "time": 4867.692925453186, "episode/length": 288.0, "episode/score": 0.06129289884589184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06129289884589184}
{"step": 143568, "time": 4868.697147369385, "episode/length": 288.0, "episode/score": 0.06804696827737189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06804696827737189}
{"step": 144336, "time": 4893.031139373779, "episode/length": 288.0, "episode/score": 0.07599475703295866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07599475703295866}
{"step": 144560, "time": 4900.102302789688, "episode/length": 288.0, "episode/score": 0.04907634601335076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04907634601335076}
{"step": 144896, "time": 4910.736034870148, "episode/length": 288.0, "episode/score": 0.04675203828239205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04675203828239205}
{"step": 145528, "time": 4930.514559268951, "episode/length": 288.0, "episode/score": 0.052144745959026295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052144745959026295}
{"step": 145720, "time": 4936.563963890076, "episode/length": 288.0, "episode/score": 0.060726755152330725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060726755152330725}
{"step": 145832, "time": 4940.093918800354, "episode/length": 288.0, "episode/score": 0.06257915330675701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06257915330675701}
{"step": 145848, "time": 4940.604177236557, "episode/length": 288.0, "episode/score": 0.05264235471358347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05264235471358347}
{"step": 145880, "time": 4941.752786159515, "episode/length": 288.0, "episode/score": 0.07863284732761144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07863284732761144}
{"step": 146648, "time": 4965.986958503723, "episode/length": 288.0, "episode/score": 0.053489560346406506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053489560346406506}
{"step": 146872, "time": 4973.151650905609, "episode/length": 288.0, "episode/score": 0.059951114543309814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059951114543309814}
{"step": 147208, "time": 4983.729541778564, "episode/length": 288.0, "episode/score": 0.07215452564514635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07215452564514635}
{"step": 147840, "time": 5004.564492464066, "episode/length": 288.0, "episode/score": 0.03447645117353204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03447645117353204}
{"step": 148032, "time": 5010.62991642952, "episode/length": 288.0, "episode/score": 0.08035222133958086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08035222133958086}
{"step": 148144, "time": 5014.20666384697, "episode/length": 288.0, "episode/score": 0.057469522374276494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057469522374276494}
{"step": 148160, "time": 5014.720218658447, "episode/length": 288.0, "episode/score": 0.0549342997084068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0549342997084068}
{"step": 148192, "time": 5015.743842124939, "episode/length": 288.0, "episode/score": 0.058381844919040304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058381844919040304}
{"step": 148960, "time": 5040.172356843948, "episode/length": 288.0, "episode/score": 0.06644495895511682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06644495895511682}
{"step": 149184, "time": 5047.183563947678, "episode/length": 288.0, "episode/score": 0.04071659782562165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04071659782562165}
{"step": 149520, "time": 5057.790781259537, "episode/length": 288.0, "episode/score": 0.050242846006540276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050242846006540276}
{"step": 150072, "time": 5077.112041711807, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 150072, "time": 5081.028908252716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5081.037934064865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5081.046365737915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5081.05354642868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5081.0600028038025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5081.066648721695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5081.073008060455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150152, "time": 5083.5976729393005, "episode/length": 288.0, "episode/score": 0.0649559872416603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0649559872416603}
{"step": 150344, "time": 5089.628532648087, "episode/length": 288.0, "episode/score": 0.04832608784761305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04832608784761305}
{"step": 150456, "time": 5093.318131446838, "episode/length": 288.0, "episode/score": 0.07371610628069902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07371610628069902}
{"step": 150472, "time": 5093.827622175217, "episode/length": 288.0, "episode/score": 0.0669828622684463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0669828622684463}
{"step": 150504, "time": 5094.839607954025, "episode/length": 288.0, "episode/score": 0.06134311213179444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06134311213179444}
{"step": 151272, "time": 5119.008856534958, "episode/length": 288.0, "episode/score": 0.0781168286018783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0781168286018783}
{"step": 151496, "time": 5126.160421133041, "episode/length": 288.0, "episode/score": 0.08134510904812942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08134510904812942}
{"step": 151832, "time": 5136.711668968201, "episode/length": 288.0, "episode/score": 0.05893100894161307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05893100894161307}
{"step": 152464, "time": 5156.93048119545, "episode/length": 288.0, "episode/score": 0.07329082680638521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07329082680638521}
{"step": 152656, "time": 5162.98295378685, "episode/length": 288.0, "episode/score": 0.044630703253801585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044630703253801585}
{"step": 152768, "time": 5166.5446565151215, "episode/length": 288.0, "episode/score": 0.06574886125031298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06574886125031298}
{"step": 152784, "time": 5167.050122499466, "episode/length": 288.0, "episode/score": 0.04171630030288043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04171630030288043}
{"step": 152808, "time": 5167.585314273834, "episode/length": 287.0, "episode/score": 0.18963241793579755, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.08650742059006689}
{"step": 153584, "time": 5192.368708610535, "episode/length": 288.0, "episode/score": 0.07585276444916644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07585276444916644}
{"step": 153808, "time": 5199.417400121689, "episode/length": 288.0, "episode/score": 0.06190659322339798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06190659322339798}
{"step": 153881, "time": 5202.480366945267, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0003431251011983, "train/action_min": 0.0, "train/action_std": 2.0007916608622653, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.00205358425309e-05, "train/actor_opt_grad_steps": 8560.0, "train/actor_opt_loss": -3.917341106199693, "train/adv_mag": 0.000351304140115649, "train/adv_max": 0.00032165739202746457, "train/adv_mean": 9.305685794066882e-05, "train/adv_min": -0.00015922616491663641, "train/adv_std": 7.931090644157749e-05, "train/cont_avg": 0.9966756395725389, "train/cont_loss_mean": 0.02233511634494318, "train/cont_loss_std": 0.3136936279515605, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.655344988170423, "train/cont_pos_acc": 0.9999999861025439, "train/cont_pos_loss": 0.0035395495644215628, "train/cont_pred": 0.9964668340015905, "train/cont_rate": 0.9966756395725389, "train/dyn_loss_mean": 1.0005263825154675, "train/dyn_loss_std": 9.184163498060074e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.017791912205748918, "train/extr_critic_critic_opt_grad_steps": 8560.0, "train/extr_critic_critic_opt_loss": 13529.827639248704, "train/extr_critic_mag": 0.08159581614281847, "train/extr_critic_max": 0.08159581614281847, "train/extr_critic_mean": 0.08147213337798193, "train/extr_critic_min": 0.08136318446441018, "train/extr_critic_std": 3.5171324434970763e-05, "train/extr_return_normed_mag": 0.0004605667887574033, "train/extr_return_normed_max": 0.00042642791962994197, "train/extr_return_normed_mean": 0.00029374970176949803, "train/extr_return_normed_min": 0.0001230306653161123, "train/extr_return_normed_std": 6.677208715667557e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0816978546621886, "train/extr_return_raw_max": 0.0816978546621886, "train/extr_return_raw_mean": 0.08156518078375356, "train/extr_return_raw_min": 0.08139445740787477, "train/extr_return_raw_std": 6.677208758962805e-05, "train/extr_reward_mag": 0.00025960139042355236, "train/extr_reward_max": 0.00025960139042355236, "train/extr_reward_mean": 0.00025947284129257625, "train/extr_reward_min": 0.0002594012670566381, "train/extr_reward_std": 4.661358227560961e-08, "train/image_loss_mean": 0.25239123612487874, "train/image_loss_std": 0.08560722041392574, "train/model_loss_mean": 0.8860612409720149, "train/model_loss_std": 0.35561622026825196, "train/model_opt_grad_norm": 51.17675401756801, "train/model_opt_grad_steps": 8549.746113989637, "train/model_opt_loss": 1995.916011830068, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2253.8860103626944, "train/policy_entropy_mag": 1.9458896533195218, "train/policy_entropy_max": 1.9458896533195218, "train/policy_entropy_mean": 1.9448800266097865, "train/policy_entropy_min": 1.9220919701719532, "train/policy_entropy_std": 0.0008050918041057691, "train/policy_logprob_mag": 2.2646110959621293, "train/policy_logprob_max": -1.693834778558405, "train/policy_logprob_mean": -1.9448785738623822, "train/policy_logprob_min": -2.2646110959621293, "train/policy_logprob_std": 0.04533029108313081, "train/policy_randomness_mag": 0.9999895284212933, "train/policy_randomness_max": 0.9999895284212933, "train/policy_randomness_mean": 0.999470676474003, "train/policy_randomness_min": 0.9877599344970031, "train/policy_randomness_std": 0.0004137353774056398, "train/post_ent_mag": 49.84743478014062, "train/post_ent_max": 49.84743478014062, "train/post_ent_mean": 49.83577129383779, "train/post_ent_min": 49.74851705126194, "train/post_ent_std": 0.016238742039920134, "train/prior_ent_mag": 54.32757348964869, "train/prior_ent_max": 54.32757348964869, "train/prior_ent_mean": 54.30486321325747, "train/prior_ent_min": 54.16006734581191, "train/prior_ent_std": 0.02713461756860654, "train/rep_loss_mean": 1.0005263825154675, "train/rep_loss_std": 9.184163498060074e-05, "train/reward_avg": 0.00026843322833355784, "train/reward_loss_mean": 0.01101903496503135, "train/reward_loss_std": 0.050728444396059745, "train/reward_max_data": 0.06928108889522716, "train/reward_max_pred": 0.0002597724835489698, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009829087899467025, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.505920306495998, "train/reward_pred": 0.0002595528476471033, "train/reward_rate": 0.00012649773316062175, "train_stats/mean_log_entropy": 1.938003815986492, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020138947293162346, "report/cont_loss_std": 0.30000442266464233, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.55465841293335, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003876895410940051, "report/cont_pred": 0.9961307048797607, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2600224018096924, "report/image_loss_std": 0.07461713999509811, "report/model_loss_mean": 0.8901616334915161, "report/model_loss_std": 0.31232768297195435, "report/post_ent_mag": 50.121055603027344, "report/post_ent_max": 50.121055603027344, "report/post_ent_mean": 50.10788345336914, "report/post_ent_min": 50.03120422363281, "report/post_ent_std": 0.013722424395382404, "report/prior_ent_mag": 54.617164611816406, "report/prior_ent_max": 54.617164611816406, "report/prior_ent_mean": 54.59418869018555, "report/prior_ent_min": 54.493011474609375, "report/prior_ent_std": 0.018624022603034973, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020375309395603836, "report/reward_loss_mean": 0.010000228881835938, "report/reward_loss_std": 0.016320571303367615, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00024199485778808594, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010000228881835938, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00024199485778808594, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0038768956437706947, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038768956437706947, "eval/cont_pred": 0.9961307048797607, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24745717644691467, "eval/image_loss_std": 0.06934470683336258, "eval/model_loss_mean": 0.8526883721351624, "eval/model_loss_std": 0.06934470683336258, "eval/post_ent_mag": 50.12064743041992, "eval/post_ent_max": 50.12064743041992, "eval/post_ent_mean": 50.107662200927734, "eval/post_ent_min": 50.03064727783203, "eval/post_ent_std": 0.012793620117008686, "eval/prior_ent_mag": 54.620887756347656, "eval/prior_ent_max": 54.620887756347656, "eval/prior_ent_mean": 54.59474182128906, "eval/prior_ent_min": 54.493011474609375, "eval/prior_ent_std": 0.017087141051888466, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001354217529296875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00024199485778808594, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001354217529296875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00024199485778808594, "eval/reward_rate": 0.0, "replay/size": 153377.0, "replay/inserts": 30896.0, "replay/samples": 30896.0, "replay/insert_wait_avg": 1.3310495032849304e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.874199289907636e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.239357247622093e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1883418560028, "timer/env.step_count": 3862.0, "timer/env.step_total": 38.91020607948303, "timer/env.step_frac": 0.038902879039040966, "timer/env.step_avg": 0.010075143987437347, "timer/env.step_min": 0.00886082649230957, "timer/env.step_max": 0.04929995536804199, "timer/replay._sample_count": 30896.0, "timer/replay._sample_total": 15.67846965789795, "timer/replay._sample_frac": 0.01567551730187551, "timer/replay._sample_avg": 0.0005074595306155473, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.011571168899536133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4729.0, "timer/agent.policy_total": 50.369140625, "timer/agent.policy_frac": 0.0503596557939601, "timer/agent.policy_avg": 0.010651118761894693, "timer/agent.policy_min": 0.009014368057250977, "timer/agent.policy_max": 0.6218051910400391, "timer/dataset_train_count": 1931.0, "timer/dataset_train_total": 0.2061467170715332, "timer/dataset_train_frac": 0.00020610789832742538, "timer/dataset_train_avg": 0.00010675645627733465, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0009396076202392578, "timer/agent.train_count": 1931.0, "timer/agent.train_total": 860.2434673309326, "timer/agent.train_frac": 0.8600814779890545, "timer/agent.train_avg": 0.44549117935314997, "timer/agent.train_min": 0.4360480308532715, "timer/agent.train_max": 0.6061985492706299, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46778416633605957, "timer/agent.report_frac": 0.00046769607958838463, "timer/agent.report_avg": 0.23389208316802979, "timer/agent.report_min": 0.2228529453277588, "timer/agent.report_max": 0.24493122100830078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122695252010974e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 30.889579454253745}
{"step": 154144, "time": 5211.026821613312, "episode/length": 288.0, "episode/score": 0.030670969844095453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030670969844095453}
{"step": 154776, "time": 5230.888722419739, "episode/length": 288.0, "episode/score": 0.051287631354796304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051287631354796304}
{"step": 154968, "time": 5236.953374385834, "episode/length": 288.0, "episode/score": 0.0689675257974045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0689675257974045}
{"step": 155080, "time": 5240.486210823059, "episode/length": 288.0, "episode/score": 0.048956131952422766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048956131952422766}
{"step": 155096, "time": 5240.995400667191, "episode/length": 288.0, "episode/score": 0.0424147324712294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0424147324712294}
{"step": 155120, "time": 5242.083191871643, "episode/length": 288.0, "episode/score": 0.06373225856077624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06373225856077624}
{"step": 155896, "time": 5266.758709430695, "episode/length": 288.0, "episode/score": 0.03502888934553994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03502888934553994}
{"step": 156120, "time": 5273.946537971497, "episode/length": 288.0, "episode/score": 0.04320682808474885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04320682808474885}
{"step": 156456, "time": 5284.579242944717, "episode/length": 288.0, "episode/score": 0.054830944065656695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054830944065656695}
{"step": 157088, "time": 5304.820426464081, "episode/length": 288.0, "episode/score": 0.07057532728640581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07057532728640581}
{"step": 157280, "time": 5310.858045339584, "episode/length": 288.0, "episode/score": 0.05187285366400829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05187285366400829}
{"step": 157392, "time": 5314.3949291706085, "episode/length": 288.0, "episode/score": 0.059947528857492216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059947528857492216}
{"step": 157408, "time": 5314.909540653229, "episode/length": 288.0, "episode/score": 0.05636360362433379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05636360362433379}
{"step": 157432, "time": 5315.449149131775, "episode/length": 288.0, "episode/score": 0.09782569727991586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09782569727991586}
{"step": 158208, "time": 5340.263982772827, "episode/length": 288.0, "episode/score": 0.061416002639816725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061416002639816725}
{"step": 158432, "time": 5347.470658779144, "episode/length": 288.0, "episode/score": 0.0596386080661091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0596386080661091}
{"step": 158768, "time": 5358.313778877258, "episode/length": 288.0, "episode/score": 0.057013316841789674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057013316841789674}
{"step": 159400, "time": 5378.144504785538, "episode/length": 288.0, "episode/score": 0.0637457598373885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0637457598373885}
{"step": 159592, "time": 5384.182750701904, "episode/length": 288.0, "episode/score": 0.06600554614271914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06600554614271914}
{"step": 159704, "time": 5387.735417842865, "episode/length": 288.0, "episode/score": 0.07468403536176993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07468403536176993}
{"step": 159720, "time": 5388.248557806015, "episode/length": 288.0, "episode/score": 0.05844792695125989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05844792695125989}
{"step": 159744, "time": 5389.237312793732, "episode/length": 288.0, "episode/score": 0.058005341474142824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058005341474142824}
{"step": 160056, "time": 5400.166574001312, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 160056, "time": 5405.026728153229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5405.035459518433, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5405.043194532394, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5405.05020403862, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5405.056542396545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5405.064894199371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5405.072672128677, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160520, "time": 5419.763138771057, "episode/length": 288.0, "episode/score": 0.07336817460588918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07336817460588918}
{"step": 160744, "time": 5426.94935464859, "episode/length": 288.0, "episode/score": 0.04946729429570951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04946729429570951}
{"step": 161080, "time": 5437.563514947891, "episode/length": 288.0, "episode/score": 0.05430715406765785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05430715406765785}
{"step": 161712, "time": 5457.896927833557, "episode/length": 288.0, "episode/score": 0.05971714233447756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05971714233447756}
{"step": 161904, "time": 5463.984155416489, "episode/length": 288.0, "episode/score": 0.055455925894591473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055455925894591473}
{"step": 162016, "time": 5467.532692670822, "episode/length": 288.0, "episode/score": 0.06327335472096252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06327335472096252}
{"step": 162032, "time": 5468.071574211121, "episode/length": 288.0, "episode/score": 0.052779631514454195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052779631514454195}
{"step": 162056, "time": 5468.617075920105, "episode/length": 288.0, "episode/score": 0.0406318176781042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0406318176781042}
{"step": 162832, "time": 5493.625264406204, "episode/length": 288.0, "episode/score": 0.04923372832098494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04923372832098494}
{"step": 163056, "time": 5500.762989282608, "episode/length": 288.0, "episode/score": 0.05921269718754729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05921269718754729}
{"step": 163392, "time": 5511.500266075134, "episode/length": 288.0, "episode/score": 0.05115126208619358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05115126208619358}
{"step": 164024, "time": 5531.848099708557, "episode/length": 288.0, "episode/score": 0.03312438202047474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03312438202047474}
{"step": 164216, "time": 5537.89935874939, "episode/length": 288.0, "episode/score": 0.04593532932565836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04593532932565836}
{"step": 164328, "time": 5541.509986400604, "episode/length": 288.0, "episode/score": 0.05492173157995239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05492173157995239}
{"step": 164344, "time": 5542.078891038895, "episode/length": 288.0, "episode/score": 0.05760761620396693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05760761620396693}
{"step": 164368, "time": 5543.063505649567, "episode/length": 288.0, "episode/score": 0.03392718611547707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03392718611547707}
{"step": 165144, "time": 5567.433826208115, "episode/length": 288.0, "episode/score": 0.06338260874832713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06338260874832713}
{"step": 165368, "time": 5574.619813203812, "episode/length": 288.0, "episode/score": 0.0884815468276372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0884815468276372}
{"step": 165704, "time": 5585.295099496841, "episode/length": 288.0, "episode/score": 0.06333601420098489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06333601420098489}
{"step": 166336, "time": 5605.617868185043, "episode/length": 288.0, "episode/score": 0.0810078103127978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0810078103127978}
{"step": 166528, "time": 5611.749313116074, "episode/length": 288.0, "episode/score": 0.05344023425919886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05344023425919886}
{"step": 166640, "time": 5615.294007062912, "episode/length": 288.0, "episode/score": 0.06758306225262345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06758306225262345}
{"step": 166656, "time": 5615.806722640991, "episode/length": 288.0, "episode/score": 0.04729020698201225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04729020698201225}
{"step": 166680, "time": 5616.371182918549, "episode/length": 288.0, "episode/score": 0.054066742506222454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054066742506222454}
{"step": 167456, "time": 5641.315990924835, "episode/length": 288.0, "episode/score": 0.06574134762317385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06574134762317385}
{"step": 167680, "time": 5648.394227266312, "episode/length": 288.0, "episode/score": 0.04841806576158092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04841806576158092}
{"step": 168016, "time": 5659.061614990234, "episode/length": 288.0, "episode/score": 0.01897686413730071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01897686413730071}
{"step": 168648, "time": 5678.99053812027, "episode/length": 288.0, "episode/score": 0.06172481806402175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06172481806402175}
{"step": 168840, "time": 5685.120290279388, "episode/length": 288.0, "episode/score": 0.04353407978703672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04353407978703672}
{"step": 168952, "time": 5688.743041753769, "episode/length": 288.0, "episode/score": 0.05547354911948332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05547354911948332}
{"step": 168968, "time": 5689.263787746429, "episode/length": 288.0, "episode/score": 0.04817497675585969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04817497675585969}
{"step": 168992, "time": 5690.2620215415955, "episode/length": 288.0, "episode/score": 0.05651318465811528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05651318465811528}
{"step": 169768, "time": 5714.757848262787, "episode/length": 288.0, "episode/score": 0.05980330098827835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05980330098827835}
{"step": 169992, "time": 5721.932962179184, "episode/length": 288.0, "episode/score": 0.051772204408848665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051772204408848665}
{"step": 170040, "time": 5730.167504310608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.1747806072235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.188955783844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.196862220764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.203764438629, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.210786819458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.217091798782, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5730.227936267853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170328, "time": 5739.4002232551575, "episode/length": 288.0, "episode/score": 0.04781176228618733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04781176228618733}
{"step": 170960, "time": 5759.852381229401, "episode/length": 288.0, "episode/score": 0.05829052424508063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05829052424508063}
{"step": 171152, "time": 5765.971382856369, "episode/length": 288.0, "episode/score": 0.04348221511423844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04348221511423844}
{"step": 171264, "time": 5769.49450969696, "episode/length": 288.0, "episode/score": 0.06952149607377578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06952149607377578}
{"step": 171280, "time": 5770.0082104206085, "episode/length": 288.0, "episode/score": 0.06793160944789634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06793160944789634}
{"step": 171304, "time": 5770.556647062302, "episode/length": 288.0, "episode/score": 0.051917554080546324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051917554080546324}
{"step": 172080, "time": 5796.001034975052, "episode/length": 288.0, "episode/score": 0.04946347802433593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04946347802433593}
{"step": 172304, "time": 5803.092778205872, "episode/length": 288.0, "episode/score": 0.06411845150694262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06411845150694262}
{"step": 172640, "time": 5813.873960494995, "episode/length": 288.0, "episode/score": 0.04630005714403751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04630005714403751}
{"step": 173272, "time": 5833.710385560989, "episode/length": 288.0, "episode/score": 0.038293999671736856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038293999671736856}
{"step": 173464, "time": 5839.765180110931, "episode/length": 288.0, "episode/score": 0.05845109308904739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05845109308904739}
{"step": 173576, "time": 5843.395527601242, "episode/length": 288.0, "episode/score": 0.030626125561070694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030626125561070694}
{"step": 173592, "time": 5843.910124778748, "episode/length": 288.0, "episode/score": 0.05240886177250559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05240886177250559}
{"step": 173616, "time": 5844.893728971481, "episode/length": 288.0, "episode/score": 0.0567773997211134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0567773997211134}
{"step": 174072, "time": 5859.054657936096, "episode/length": 56.0, "episode/score": 0.8321889502925046, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0071889335752644}
{"step": 174328, "time": 5867.148409128189, "episode/length": 131.0, "episode/score": 0.6178618226333583, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.027236835369194523}
{"step": 174392, "time": 5869.187273263931, "episode/length": 288.0, "episode/score": 0.05321373171994992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05321373171994992}
{"step": 174616, "time": 5876.418986320496, "episode/length": 288.0, "episode/score": 0.06823124030154304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06823124030154304}
{"step": 174952, "time": 5887.039870977402, "episode/length": 288.0, "episode/score": 0.04379157750156537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04379157750156537}
{"step": 175776, "time": 5913.370398283005, "episode/length": 288.0, "episode/score": 0.04223839460158274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04223839460158274}
{"step": 175888, "time": 5916.900488138199, "episode/length": 288.0, "episode/score": 0.045910987667099334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045910987667099334}
{"step": 175904, "time": 5917.412263393402, "episode/length": 288.0, "episode/score": 0.03345134309708442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03345134309708442}
{"step": 176384, "time": 5932.733677148819, "episode/length": 288.0, "episode/score": 0.03748376678569798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03748376678569798}
{"step": 176640, "time": 5940.873282194138, "episode/length": 288.0, "episode/score": 0.049181402350654935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049181402350654935}
{"step": 176704, "time": 5942.895239114761, "episode/length": 288.0, "episode/score": 0.04608662292778831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04608662292778831}
{"step": 176928, "time": 5949.970538854599, "episode/length": 288.0, "episode/score": 0.055727933063479895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055727933063479895}
{"step": 177264, "time": 5960.593888759613, "episode/length": 288.0, "episode/score": 0.04355965807704365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04355965807704365}
{"step": 177360, "time": 5963.72535443306, "episode/length": 81.0, "episode/score": 0.7700788385497503, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.02320382183251013}
{"step": 178088, "time": 5986.549705982208, "episode/length": 288.0, "episode/score": 0.0566213325942897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0566213325942897}
{"step": 178200, "time": 5990.13312292099, "episode/length": 288.0, "episode/score": 0.03924116035526026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03924116035526026}
{"step": 178216, "time": 5990.658616542816, "episode/length": 288.0, "episode/score": 0.05611711307017231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05611711307017231}
{"step": 178696, "time": 6006.016259670258, "episode/length": 288.0, "episode/score": 0.03922509849590483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03922509849590483}
{"step": 178696, "time": 6006.024617671967, "episode/length": 220.0, "episode/score": 0.3443067781505533, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.03180678461160369}
{"step": 178952, "time": 6014.103316068649, "episode/length": 288.0, "episode/score": 0.035289180137567655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035289180137567655}
{"step": 179576, "time": 6034.0751259326935, "episode/length": 288.0, "episode/score": 0.06476286452652857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06476286452652857}
{"step": 179672, "time": 6037.157694339752, "episode/length": 288.0, "episode/score": 0.02476957927419221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02476957927419221}
{"step": 180024, "time": 6054.422585487366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.434197425842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.444454431534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.452919721603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.4598042964935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.469406604767, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.477917671204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6054.48809671402, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180400, "time": 6067.095824480057, "episode/length": 288.0, "episode/score": 0.011476655293591875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011476655293591875}
{"step": 180512, "time": 6070.646530151367, "episode/length": 288.0, "episode/score": 0.047847183855168396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047847183855168396}
{"step": 180528, "time": 6071.158563613892, "episode/length": 288.0, "episode/score": 0.02820800078512775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02820800078512775}
{"step": 181008, "time": 6086.433035135269, "episode/length": 288.0, "episode/score": 0.03797697243518883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03797697243518883}
{"step": 181008, "time": 6086.441270828247, "episode/length": 288.0, "episode/score": 0.044675791978988855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044675791978988855}
{"step": 181264, "time": 6094.672522544861, "episode/length": 288.0, "episode/score": 0.06035757273943432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06035757273943432}
{"step": 181888, "time": 6114.5645163059235, "episode/length": 288.0, "episode/score": 0.05104070233514335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05104070233514335}
{"step": 181984, "time": 6117.6071434021, "episode/length": 288.0, "episode/score": 0.04074294657766586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04074294657766586}
{"step": 182712, "time": 6140.36355638504, "episode/length": 288.0, "episode/score": 0.03695104081451461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03695104081451461}
{"step": 182824, "time": 6144.028352499008, "episode/length": 288.0, "episode/score": 0.024533428159926984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024533428159926984}
{"step": 182840, "time": 6144.561718702316, "episode/length": 288.0, "episode/score": 0.03747462796305001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03747462796305001}
{"step": 183320, "time": 6159.7623636722565, "episode/length": 288.0, "episode/score": 0.042017501546823155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042017501546823155}
{"step": 183320, "time": 6159.7714104652405, "episode/length": 288.0, "episode/score": 0.05606647959658062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05606647959658062}
{"step": 183576, "time": 6167.852167129517, "episode/length": 288.0, "episode/score": 0.06319464209090597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06319464209090597}
{"step": 184200, "time": 6187.8734385967255, "episode/length": 288.0, "episode/score": 0.03977566698674195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03977566698674195}
{"step": 184296, "time": 6190.90879034996, "episode/length": 288.0, "episode/score": 0.03319321797188479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03319321797188479}
{"step": 184633, "time": 6202.663790941238, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9965438842773438, "train/action_min": 0.0, "train/action_std": 2.0050503922005496, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010130249613382603, "train/actor_opt_grad_steps": 10485.0, "train/actor_opt_loss": -5.479684715780119, "train/adv_mag": 0.0004463903605937958, "train/adv_max": 0.00037407017468164366, "train/adv_mean": 1.0972512833736422e-05, "train/adv_min": -0.00033097865525633097, "train/adv_std": 9.880452886079638e-05, "train/cont_avg": 0.9963226318359375, "train/cont_loss_mean": 0.024320769659728587, "train/cont_loss_std": 0.3315536507871002, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.647827056065904, "train/cont_pos_acc": 0.999999982615312, "train/cont_pos_loss": 0.003573266698367661, "train/cont_pred": 0.996433248432974, "train/cont_rate": 0.9963226318359375, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.012448638323197278, "train/extr_critic_critic_opt_grad_steps": 10485.0, "train/extr_critic_critic_opt_loss": 13523.76377360026, "train/extr_critic_mag": 0.08333938258389632, "train/extr_critic_max": 0.08333938258389632, "train/extr_critic_mean": 0.08316610101610422, "train/extr_critic_min": 0.08291088541348775, "train/extr_critic_std": 6.417097814311508e-05, "train/extr_return_normed_mag": 0.000412093591876328, "train/extr_return_normed_max": 0.000317918563572069, "train/extr_return_normed_mean": 0.0001286592896135493, "train/extr_return_normed_min": -0.0001151271474858125, "train/extr_return_normed_std": 7.557908744596868e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08336631949835767, "train/extr_return_raw_max": 0.08336631949835767, "train/extr_return_raw_mean": 0.08317706536035985, "train/extr_return_raw_min": 0.0829332737872998, "train/extr_return_raw_std": 7.557908813045817e-05, "train/extr_reward_mag": 0.00025165391465028125, "train/extr_reward_max": 0.00025165391465028125, "train/extr_reward_mean": 0.00025152119936440914, "train/extr_reward_min": 0.00025143784781297046, "train/extr_reward_std": 4.3139568664414076e-08, "train/image_loss_mean": 0.2447827106807381, "train/image_loss_std": 0.0855897789588198, "train/model_loss_mean": 0.8804440082361301, "train/model_loss_std": 0.374138036587586, "train/model_opt_grad_norm": 46.82505943377813, "train/model_opt_grad_steps": 10473.171875, "train/model_opt_loss": 2383.7404708862305, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2721.3541666666665, "train/policy_entropy_mag": 1.9458616953343153, "train/policy_entropy_max": 1.9458616953343153, "train/policy_entropy_mean": 1.9427977471301954, "train/policy_entropy_min": 1.903822371115287, "train/policy_entropy_std": 0.0024575807862371826, "train/policy_logprob_mag": 2.3562464055915675, "train/policy_logprob_max": -1.584622459486127, "train/policy_logprob_mean": -1.9427814117322366, "train/policy_logprob_min": -2.3562464055915675, "train/policy_logprob_std": 0.07202692424956088, "train/policy_randomness_mag": 0.9999751582120856, "train/policy_randomness_max": 0.9999751582120856, "train/policy_randomness_mean": 0.9984005990748605, "train/policy_randomness_min": 0.9783712178468704, "train/policy_randomness_std": 0.0012629467851184017, "train/post_ent_mag": 50.50899684429169, "train/post_ent_max": 50.50899684429169, "train/post_ent_mean": 50.49260081847509, "train/post_ent_min": 50.441665053367615, "train/post_ent_std": 0.010441147368207263, "train/prior_ent_mag": 54.57575124502182, "train/prior_ent_max": 54.57575124502182, "train/prior_ent_mean": 54.444904148578644, "train/prior_ent_min": 54.34041881561279, "train/prior_ent_std": 0.034141724322883725, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0002706309881735554, "train/reward_loss_mean": 0.011340507636001954, "train/reward_loss_std": 0.05522165744817661, "train/reward_max_data": 0.06715364629174776, "train/reward_max_pred": 0.00025153160095214844, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010024796227905123, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.231416666949237, "train/reward_pred": 0.00025139185587856144, "train/reward_rate": 0.00014241536458333334, "train_stats/mean_log_entropy": 1.936069149661947, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02011144906282425, "report/cont_loss_std": 0.3016933798789978, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.585789680480957, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037578409537672997, "report/cont_pred": 0.996249258518219, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2343301922082901, "report/image_loss_std": 0.08760693669319153, "report/model_loss_mean": 0.8649789094924927, "report/model_loss_std": 0.31851324439048767, "report/post_ent_mag": 52.46170425415039, "report/post_ent_max": 52.46170425415039, "report/post_ent_mean": 52.35452651977539, "report/post_ent_min": 52.27701187133789, "report/post_ent_std": 0.03070283867418766, "report/prior_ent_mag": 54.359962463378906, "report/prior_ent_max": 54.359962463378906, "report/prior_ent_mean": 53.998905181884766, "report/prior_ent_min": 53.63923645019531, "report/prior_ent_std": 0.10911127924919128, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002171688829548657, "report/reward_loss_mean": 0.010537253692746162, "report/reward_loss_std": 0.016435077413916588, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002548694610595703, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010537253692746162, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002548694610595703, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0037578411865979433, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037578411865979433, "eval/cont_pred": 0.996249258518219, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22824373841285706, "eval/image_loss_std": 0.08822783827781677, "eval/model_loss_mean": 0.8334473371505737, "eval/model_loss_std": 0.08822783827781677, "eval/post_ent_mag": 52.435272216796875, "eval/post_ent_max": 52.435272216796875, "eval/post_ent_mean": 52.3458366394043, "eval/post_ent_min": 52.28632354736328, "eval/post_ent_std": 0.03172890096902847, "eval/prior_ent_mag": 54.54629135131836, "eval/prior_ent_max": 54.54629135131836, "eval/prior_ent_mean": 54.029991149902344, "eval/prior_ent_min": 53.6114501953125, "eval/prior_ent_std": 0.13584363460540771, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001445770263671875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002548694610595703, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001445770263671875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002548694610595703, "eval/reward_rate": 0.0, "replay/size": 184129.0, "replay/inserts": 30752.0, "replay/samples": 30752.0, "replay/insert_wait_avg": 1.364347837966141e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.869111936372723e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2294575142337926e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1683309078217, "timer/env.step_count": 3844.0, "timer/env.step_total": 38.2363646030426, "timer/env.step_frac": 0.03822992932433348, "timer/env.step_avg": 0.009947025130864361, "timer/env.step_min": 0.008708715438842773, "timer/env.step_max": 0.03536057472229004, "timer/replay._sample_count": 30752.0, "timer/replay._sample_total": 15.718206644058228, "timer/replay._sample_frac": 0.01571556122936956, "timer/replay._sample_avg": 0.0005111279475825386, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.009869575500488281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4711.0, "timer/agent.policy_total": 50.21294713020325, "timer/agent.policy_frac": 0.050204496161787605, "timer/agent.policy_avg": 0.010658659972448152, "timer/agent.policy_min": 0.009193897247314453, "timer/agent.policy_max": 0.0902557373046875, "timer/dataset_train_count": 1922.0, "timer/dataset_train_total": 0.22236061096191406, "timer/dataset_train_frac": 0.00022232318709800006, "timer/dataset_train_avg": 0.0001156923053912144, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.00044083595275878906, "timer/agent.train_count": 1922.0, "timer/agent.train_total": 860.0763380527496, "timer/agent.train_frac": 0.8599315849883841, "timer/agent.train_avg": 0.4474902903500258, "timer/agent.train_min": 0.4355299472808838, "timer/agent.train_max": 0.5916726589202881, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786033630371094, "timer/agent.report_frac": 0.00047852281285760766, "timer/agent.report_avg": 0.2393016815185547, "timer/agent.report_min": 0.23270273208618164, "timer/agent.report_max": 0.24590063095092773, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289622646435098e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 30.74632017200272}
{"step": 185024, "time": 6214.954256057739, "episode/length": 288.0, "episode/score": 0.04332736158289663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04332736158289663}
{"step": 185136, "time": 6218.496947050095, "episode/length": 288.0, "episode/score": 0.043157313143893816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043157313143893816}
{"step": 185152, "time": 6219.006330728531, "episode/length": 288.0, "episode/score": 0.04820144959647621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04820144959647621}
{"step": 185632, "time": 6234.3423817157745, "episode/length": 288.0, "episode/score": 0.04881759205630942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04881759205630942}
{"step": 185632, "time": 6234.350906133652, "episode/length": 288.0, "episode/score": 0.052468734528048344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052468734528048344}
{"step": 185888, "time": 6242.479293823242, "episode/length": 288.0, "episode/score": 0.04167292661865929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04167292661865929}
{"step": 186512, "time": 6262.352606534958, "episode/length": 288.0, "episode/score": 0.04816164873884077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04816164873884077}
{"step": 186608, "time": 6265.38480257988, "episode/length": 288.0, "episode/score": 0.031471561443041196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031471561443041196}
{"step": 187008, "time": 6278.038729190826, "episode/length": 247.0, "episode/score": 0.27905033747697416, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.050925332680662905}
{"step": 187448, "time": 6291.840512037277, "episode/length": 288.0, "episode/score": 0.05168857426872364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05168857426872364}
{"step": 187464, "time": 6292.353845119476, "episode/length": 288.0, "episode/score": 0.02741421727165516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02741421727165516}
{"step": 187944, "time": 6307.549309015274, "episode/length": 288.0, "episode/score": 0.04971592797642188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04971592797642188}
{"step": 187944, "time": 6307.558026075363, "episode/length": 288.0, "episode/score": 0.03278330243460914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03278330243460914}
{"step": 188200, "time": 6315.693558454514, "episode/length": 288.0, "episode/score": 0.0637602814906586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0637602814906586}
{"step": 188824, "time": 6336.0542232990265, "episode/length": 288.0, "episode/score": 0.04580333819512816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04580333819512816}
{"step": 188920, "time": 6339.10210609436, "episode/length": 288.0, "episode/score": 0.043139237723039514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043139237723039514}
{"step": 189296, "time": 6351.213144779205, "episode/length": 58.0, "episode/score": 0.8369610530345426, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.018211030007591944}
{"step": 189320, "time": 6351.85546708107, "episode/length": 288.0, "episode/score": 0.019432777839313076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019432777839313076}
{"step": 189760, "time": 6365.993351697922, "episode/length": 288.0, "episode/score": 0.03820626176411679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03820626176411679}
{"step": 189776, "time": 6366.505661249161, "episode/length": 288.0, "episode/score": 0.03573041784198949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03573041784198949}
{"step": 190008, "time": 6374.271125555038, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 190008, "time": 6379.59650850296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6379.6043972969055, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6379.612466573715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6379.619899988174, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6379.627948522568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6379.635324239731, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6379.642611980438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190256, "time": 6387.8405792713165, "episode/length": 288.0, "episode/score": 0.02326097685678974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02326097685678974}
{"step": 190256, "time": 6387.8510937690735, "episode/length": 288.0, "episode/score": 0.06010644514776686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06010644514776686}
{"step": 190512, "time": 6395.986563682556, "episode/length": 288.0, "episode/score": 0.03799598328197362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03799598328197362}
{"step": 191232, "time": 6418.887575387955, "episode/length": 288.0, "episode/score": 0.034660081925210307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034660081925210307}
{"step": 191608, "time": 6430.511342048645, "episode/length": 288.0, "episode/score": 0.031211912210466153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031211912210466153}
{"step": 191632, "time": 6432.268021345139, "episode/length": 288.0, "episode/score": 0.025660278524100022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025660278524100022}
{"step": 192072, "time": 6446.059536218643, "episode/length": 288.0, "episode/score": 0.04559623385375744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04559623385375744}
{"step": 192088, "time": 6446.572525978088, "episode/length": 288.0, "episode/score": 0.06440022772341081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06440022772341081}
{"step": 192568, "time": 6461.732975244522, "episode/length": 288.0, "episode/score": 0.03854599810247805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03854599810247805}
{"step": 192568, "time": 6461.741878032684, "episode/length": 288.0, "episode/score": 0.038186693680358985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038186693680358985}
{"step": 192824, "time": 6469.817976236343, "episode/length": 288.0, "episode/score": 0.048523579352519164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048523579352519164}
{"step": 193544, "time": 6492.665755748749, "episode/length": 288.0, "episode/score": 0.018974693429953504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018974693429953504}
{"step": 193920, "time": 6504.8542304039, "episode/length": 288.0, "episode/score": 0.038020814540232095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038020814540232095}
{"step": 193944, "time": 6505.39600110054, "episode/length": 288.0, "episode/score": 0.03743419068194953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03743419068194953}
{"step": 194384, "time": 6519.553678035736, "episode/length": 288.0, "episode/score": 0.025410852970168207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025410852970168207}
{"step": 194400, "time": 6520.067799806595, "episode/length": 288.0, "episode/score": 0.05263874734899332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05263874734899332}
{"step": 194880, "time": 6535.373485565186, "episode/length": 288.0, "episode/score": 0.04878986103864236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04878986103864236}
{"step": 194880, "time": 6535.382503271103, "episode/length": 288.0, "episode/score": 0.04004647628246971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04004647628246971}
{"step": 195136, "time": 6543.499609231949, "episode/length": 288.0, "episode/score": 0.03149969654307938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03149969654307938}
{"step": 195856, "time": 6566.406596422195, "episode/length": 288.0, "episode/score": 0.033004498679446215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033004498679446215}
{"step": 196232, "time": 6578.0923438072205, "episode/length": 288.0, "episode/score": 0.024257137043377952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024257137043377952}
{"step": 196256, "time": 6579.073708534241, "episode/length": 288.0, "episode/score": 0.041561980456890524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041561980456890524}
{"step": 196696, "time": 6593.4482572078705, "episode/length": 288.0, "episode/score": 0.027949537820148862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027949537820148862}
{"step": 196712, "time": 6593.968906402588, "episode/length": 288.0, "episode/score": 0.029971332920894156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029971332920894156}
{"step": 197192, "time": 6609.153465509415, "episode/length": 288.0, "episode/score": 0.05042726837481837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05042726837481837}
{"step": 197192, "time": 6609.181957244873, "episode/length": 288.0, "episode/score": 0.044571421742205075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044571421742205075}
{"step": 197448, "time": 6617.300470590591, "episode/length": 288.0, "episode/score": 0.03407404824497462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03407404824497462}
{"step": 198168, "time": 6640.175811767578, "episode/length": 288.0, "episode/score": 0.03461875420441629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03461875420441629}
{"step": 198544, "time": 6652.4799773693085, "episode/length": 288.0, "episode/score": 0.03230417400139629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03230417400139629}
{"step": 198568, "time": 6653.021949768066, "episode/length": 288.0, "episode/score": 0.04709179789401219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04709179789401219}
{"step": 199008, "time": 6667.158442735672, "episode/length": 288.0, "episode/score": 0.032442289944086156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032442289944086156}
{"step": 199024, "time": 6667.676923036575, "episode/length": 288.0, "episode/score": 0.027345841092767387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027345841092767387}
{"step": 199504, "time": 6683.071353673935, "episode/length": 288.0, "episode/score": 0.042088455601799524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042088455601799524}
{"step": 199504, "time": 6683.080210924149, "episode/length": 288.0, "episode/score": 0.046555700655346755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046555700655346755}
{"step": 199760, "time": 6691.219264745712, "episode/length": 288.0, "episode/score": 0.05602480194892223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05602480194892223}
{"step": 200096, "time": 6703.421095132828, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 200096, "time": 6708.3571791648865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6708.364751815796, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6708.375933408737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6708.3963878154755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6708.404607057571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6708.412077903748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6708.421956539154, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200480, "time": 6720.758522510529, "episode/length": 288.0, "episode/score": 0.022592518010242202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022592518010242202}
{"step": 200856, "time": 6732.44135928154, "episode/length": 288.0, "episode/score": 0.05089215129741831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05089215129741831}
{"step": 200880, "time": 6733.426071166992, "episode/length": 288.0, "episode/score": 0.050709444789873714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050709444789873714}
{"step": 201320, "time": 6747.24458527565, "episode/length": 288.0, "episode/score": 0.05458871833079115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05458871833079115}
{"step": 201336, "time": 6747.76019859314, "episode/length": 288.0, "episode/score": 0.05248784546272134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05248784546272134}
{"step": 201816, "time": 6763.031097173691, "episode/length": 288.0, "episode/score": 0.06446808817003102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06446808817003102}
{"step": 201816, "time": 6763.0417494773865, "episode/length": 288.0, "episode/score": 0.05892988980821201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05892988980821201}
{"step": 202072, "time": 6771.150308132172, "episode/length": 288.0, "episode/score": 0.044865821708128806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044865821708128806}
{"step": 202792, "time": 6794.01060128212, "episode/length": 288.0, "episode/score": 0.068057217488672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.068057217488672}
{"step": 203168, "time": 6806.2094848155975, "episode/length": 288.0, "episode/score": 0.08602373066673863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08602373066673863}
{"step": 203192, "time": 6806.7502546310425, "episode/length": 288.0, "episode/score": 0.05586748657071894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05586748657071894}
{"step": 203632, "time": 6820.887815475464, "episode/length": 288.0, "episode/score": 0.07261820366136362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07261820366136362}
{"step": 203648, "time": 6821.405687093735, "episode/length": 288.0, "episode/score": 0.07846792753264253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07846792753264253}
{"step": 204128, "time": 6836.694868326187, "episode/length": 288.0, "episode/score": 0.06484647611489436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06484647611489436}
{"step": 204128, "time": 6836.703803539276, "episode/length": 288.0, "episode/score": 0.07288124540013996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07288124540013996}
{"step": 204384, "time": 6844.8087701797485, "episode/length": 288.0, "episode/score": 0.06197417428779772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06197417428779772}
{"step": 205104, "time": 6868.199774980545, "episode/length": 288.0, "episode/score": 0.08165080866382368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08165080866382368}
{"step": 205480, "time": 6879.866986274719, "episode/length": 288.0, "episode/score": 0.08001009174307683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08001009174307683}
{"step": 205504, "time": 6880.847666025162, "episode/length": 288.0, "episode/score": 0.07629090278709327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07629090278709327}
{"step": 205944, "time": 6894.585978269577, "episode/length": 288.0, "episode/score": 0.059008376630686143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059008376630686143}
{"step": 205960, "time": 6895.099711418152, "episode/length": 288.0, "episode/score": 0.04918707877982342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04918707877982342}
{"step": 206440, "time": 6910.198515176773, "episode/length": 288.0, "episode/score": 0.042504645239887395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042504645239887395}
{"step": 206440, "time": 6910.207200288773, "episode/length": 288.0, "episode/score": 0.06026528457960012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06026528457960012}
{"step": 206576, "time": 6914.6953201293945, "episode/length": 136.0, "episode/score": 0.6064424774308463, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.031442460713606124}
{"step": 206696, "time": 6918.257400512695, "episode/length": 288.0, "episode/score": 0.057595193410065804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057595193410065804}
{"step": 207416, "time": 6940.932039260864, "episode/length": 288.0, "episode/score": 0.08193969391186329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08193969391186329}
{"step": 207816, "time": 6953.867421388626, "episode/length": 288.0, "episode/score": 0.05714447036046977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05714447036046977}
{"step": 208256, "time": 6968.024147510529, "episode/length": 288.0, "episode/score": 0.06825080104101744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06825080104101744}
{"step": 208272, "time": 6968.555831193924, "episode/length": 288.0, "episode/score": 0.061660008717012715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061660008717012715}
{"step": 208752, "time": 6983.857303142548, "episode/length": 288.0, "episode/score": 0.029554019432822543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029554019432822543}
{"step": 208752, "time": 6983.86923623085, "episode/length": 288.0, "episode/score": 0.04063755324062868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04063755324062868}
{"step": 208888, "time": 6987.937224149704, "episode/length": 288.0, "episode/score": 0.03389116137913106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03389116137913106}
{"step": 209008, "time": 6991.965870380402, "episode/length": 288.0, "episode/score": 0.035886191207453066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035886191207453066}
{"step": 209728, "time": 7014.8459379673, "episode/length": 288.0, "episode/score": 0.05691170810914059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05691170810914059}
{"step": 210080, "time": 7031.756800413132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.764903306961, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.771896123886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.792261362076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.802815437317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.813932180405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.820102930069, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7031.828569889069, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210128, "time": 7033.3510484695435, "episode/length": 288.0, "episode/score": 0.04135349955873835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04135349955873835}
{"step": 210568, "time": 7047.137166976929, "episode/length": 288.0, "episode/score": 0.057650690354591916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057650690354591916}
{"step": 210584, "time": 7047.6503274440765, "episode/length": 288.0, "episode/score": 0.04960626357294018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04960626357294018}
{"step": 211064, "time": 7062.737766027451, "episode/length": 288.0, "episode/score": 0.03498942918446346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03498942918446346}
{"step": 211064, "time": 7062.745941162109, "episode/length": 288.0, "episode/score": 0.041309058954169586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041309058954169586}
{"step": 211200, "time": 7067.2824165821075, "episode/length": 288.0, "episode/score": 0.09122243145694142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09122243145694142}
{"step": 211320, "time": 7070.8666315078735, "episode/length": 288.0, "episode/score": 0.028390740366319278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028390740366319278}
{"step": 212040, "time": 7093.696510076523, "episode/length": 288.0, "episode/score": 0.05351207506612354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05351207506612354}
{"step": 212440, "time": 7106.387482881546, "episode/length": 288.0, "episode/score": 0.06728380186871163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06728380186871163}
{"step": 212880, "time": 7120.486847400665, "episode/length": 288.0, "episode/score": 0.047597203662832044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047597203662832044}
{"step": 212896, "time": 7120.996333599091, "episode/length": 288.0, "episode/score": 0.05218247505561635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05218247505561635}
{"step": 213376, "time": 7136.715802192688, "episode/length": 288.0, "episode/score": 0.03423729716817547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03423729716817547}
{"step": 213376, "time": 7136.7245581150055, "episode/length": 288.0, "episode/score": 0.05045744561945753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05045744561945753}
{"step": 213512, "time": 7140.811045408249, "episode/length": 288.0, "episode/score": 0.06020144388975268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06020144388975268}
{"step": 213632, "time": 7144.834275722504, "episode/length": 288.0, "episode/score": 0.028483818845444375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028483818845444375}
{"step": 214352, "time": 7167.626920223236, "episode/length": 288.0, "episode/score": 0.03688511896402247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03688511896402247}
{"step": 214752, "time": 7180.311381816864, "episode/length": 288.0, "episode/score": 0.05910130600966568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05910130600966568}
{"step": 215192, "time": 7194.134637594223, "episode/length": 288.0, "episode/score": 0.05964135958927841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05964135958927841}
{"step": 215208, "time": 7194.651382684708, "episode/length": 288.0, "episode/score": 0.027645762107908922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027645762107908922}
{"step": 215248, "time": 7196.13911652565, "episode/length": 201.0, "episode/score": 0.39985504560794993, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.027980058693032106}
{"step": 215433, "time": 7202.786196708679, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.992786407470703, "train/action_min": 0.0, "train/action_std": 2.0155618768185377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00017173595047855392, "train/actor_opt_grad_steps": 12405.0, "train/actor_opt_loss": -5.5478094993159175, "train/adv_mag": 0.0010739611461758614, "train/adv_max": 0.001023358238550524, "train/adv_mean": 5.8752520262217445e-06, "train/adv_min": -0.0008869639132171869, "train/adv_std": 0.00022623388099418662, "train/cont_avg": 0.9966532389322916, "train/cont_loss_mean": 0.022458092412610615, "train/cont_loss_std": 0.3140738884321763, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658882880337024, "train/cont_pos_acc": 0.9999999850988388, "train/cont_pos_loss": 0.003517801441679088, "train/cont_pred": 0.9964884712050358, "train/cont_rate": 0.9966532389322916, "train/dyn_loss_mean": 1.0000037346035242, "train/dyn_loss_std": 0.00010552725780144101, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007249082481090833, "train/extr_critic_critic_opt_grad_steps": 12405.0, "train/extr_critic_critic_opt_loss": 13527.206837972006, "train/extr_critic_mag": 0.08386294854183991, "train/extr_critic_max": 0.08386294854183991, "train/extr_critic_mean": 0.08336941731007148, "train/extr_critic_min": 0.08241915019849937, "train/extr_critic_std": 0.00019205440723150483, "train/extr_return_normed_mag": 0.0008266903460025787, "train/extr_return_normed_max": 0.0007319437184681495, "train/extr_return_normed_mean": 0.00025562453926397666, "train/extr_return_normed_min": -0.0004843182396143675, "train/extr_return_normed_std": 0.00016419363964814693, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08385156960381816, "train/extr_return_raw_max": 0.08385156960381816, "train/extr_return_raw_mean": 0.08337525534443557, "train/extr_return_raw_min": 0.08263530764573564, "train/extr_return_raw_std": 0.00016419364025447672, "train/extr_reward_mag": 0.00025303785999615985, "train/extr_reward_max": 0.00025303785999615985, "train/extr_reward_mean": 0.00025275663498784223, "train/extr_reward_min": 0.00025252625346183777, "train/extr_reward_std": 1.0507639122981267e-07, "train/image_loss_mean": 0.2061267131163428, "train/image_loss_std": 0.0947656932209308, "train/model_loss_mean": 0.8396936189383268, "train/model_loss_std": 0.3640136801016827, "train/model_opt_grad_norm": 41.90218035045423, "train/model_opt_grad_steps": 12391.432291666666, "train/model_opt_loss": 2250.891319910685, "train/model_opt_model_opt_grad_overflow": 0.010416666666666666, "train/model_opt_model_opt_grad_scale": 2656.25, "train/policy_entropy_mag": 1.9456214445332687, "train/policy_entropy_max": 1.9456214445332687, "train/policy_entropy_mean": 1.9286614544689655, "train/policy_entropy_min": 1.775617053732276, "train/policy_entropy_std": 0.013516642759592893, "train/policy_logprob_mag": 2.8658677649994693, "train/policy_logprob_max": -1.106214395724237, "train/policy_logprob_mean": -1.9286264094213645, "train/policy_logprob_min": -2.8658677649994693, "train/policy_logprob_std": 0.1841253989841789, "train/policy_randomness_mag": 0.9998516949514548, "train/policy_randomness_max": 0.9998516949514548, "train/policy_randomness_mean": 0.9911359821756681, "train/policy_randomness_min": 0.9124867149318258, "train/policy_randomness_std": 0.006946180658511973, "train/post_ent_mag": 56.96758157014847, "train/post_ent_max": 56.96758157014847, "train/post_ent_mean": 56.61843168735504, "train/post_ent_min": 56.31066260735194, "train/post_ent_std": 0.1364867505035363, "train/prior_ent_mag": 56.776199678579964, "train/prior_ent_max": 56.776199678579964, "train/prior_ent_mean": 54.29269560178121, "train/prior_ent_min": 52.924306193987526, "train/prior_ent_std": 0.5405957813685139, "train/rep_loss_mean": 1.0000037346035242, "train/rep_loss_std": 0.00010552725780144101, "train/reward_avg": 0.00028039892693717167, "train/reward_loss_mean": 0.011106549037018945, "train/reward_loss_std": 0.059349135587884426, "train/reward_max_data": 0.08402929782823776, "train/reward_max_pred": 0.0002528832604487737, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009647886913929446, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.552298940461258, "train/reward_pred": 0.00025261469454562757, "train/reward_rate": 0.000152587890625, "train_stats/mean_log_entropy": 1.9187517537983185, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008801562711596489, "report/cont_loss_std": 0.17947769165039062, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.749283790588379, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003190144430845976, "report/cont_pred": 0.9968147873878479, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18666785955429077, "report/image_loss_std": 0.09029699862003326, "report/model_loss_mean": 0.8067076206207275, "report/model_loss_std": 0.20187579095363617, "report/post_ent_mag": 56.90582275390625, "report/post_ent_max": 56.90582275390625, "report/post_ent_mean": 56.45564270019531, "report/post_ent_min": 56.03145980834961, "report/post_ent_std": 0.17305205762386322, "report/prior_ent_mag": 56.82710647583008, "report/prior_ent_max": 56.82710647583008, "report/prior_ent_mean": 54.225982666015625, "report/prior_ent_min": 51.4992790222168, "report/prior_ent_std": 0.7040063738822937, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023347922251559794, "report/reward_loss_mean": 0.011238141916692257, "report/reward_loss_std": 0.017025627195835114, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00029265880584716797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011238141916692257, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00029040093068033457, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02002440020442009, "eval/cont_loss_std": 0.3105604946613312, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.749284267425537, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031901446636766195, "eval/cont_pred": 0.9968147873878479, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19411520659923553, "eval/image_loss_std": 0.10652757436037064, "eval/model_loss_mean": 0.8157801032066345, "eval/model_loss_std": 0.32474735379219055, "eval/post_ent_mag": 56.9051513671875, "eval/post_ent_max": 56.9051513671875, "eval/post_ent_mean": 56.43547058105469, "eval/post_ent_min": 56.064903259277344, "eval/post_ent_std": 0.17634636163711548, "eval/prior_ent_mag": 57.3718147277832, "eval/prior_ent_max": 57.3718147277832, "eval/prior_ent_mean": 54.3765869140625, "eval/prior_ent_min": 51.83563995361328, "eval/prior_ent_std": 0.8145296573638916, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016404679045081139, "eval/reward_loss_std": 3.5278083032608265e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00029265880584716797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016404679045081139, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002903725253418088, "eval/reward_rate": 0.0, "replay/size": 214929.0, "replay/inserts": 30800.0, "replay/samples": 30800.0, "replay/insert_wait_avg": 1.3481022475601792e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.947395943976068e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.223717043831549e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1092410087585, "timer/env.step_count": 3850.0, "timer/env.step_total": 37.89320659637451, "timer/env.step_frac": 0.037889067556413726, "timer/env.step_avg": 0.00984239132373364, "timer/env.step_min": 0.008548974990844727, "timer/env.step_max": 0.035396575927734375, "timer/replay._sample_count": 30800.0, "timer/replay._sample_total": 15.881675481796265, "timer/replay._sample_frac": 0.015879940741050685, "timer/replay._sample_avg": 0.0005156388143440346, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.033708810806274414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4717.0, "timer/agent.policy_total": 49.99430012702942, "timer/agent.policy_frac": 0.049988839295798074, "timer/agent.policy_avg": 0.010598749231933309, "timer/agent.policy_min": 0.00898432731628418, "timer/agent.policy_max": 0.08872294425964355, "timer/dataset_train_count": 1925.0, "timer/dataset_train_total": 0.22530794143676758, "timer/dataset_train_frac": 0.00022528333125840442, "timer/dataset_train_avg": 0.00011704308646065848, "timer/dataset_train_min": 0.00010132789611816406, "timer/dataset_train_max": 0.0005147457122802734, "timer/agent.train_count": 1925.0, "timer/agent.train_total": 861.5398945808411, "timer/agent.train_frac": 0.8614457893738191, "timer/agent.train_avg": 0.4475531919900473, "timer/agent.train_min": 0.43588948249816895, "timer/agent.train_max": 1.197035789489746, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4773256778717041, "timer/agent.report_frac": 0.0004772735400287376, "timer/agent.report_avg": 0.23866283893585205, "timer/agent.report_min": 0.2322862148284912, "timer/agent.report_max": 0.2450394630432129, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051424471812549e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 30.796136253453227}
{"step": 215688, "time": 7210.63267827034, "episode/length": 288.0, "episode/score": 0.03945674582257652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03945674582257652}
{"step": 215688, "time": 7210.64245390892, "episode/length": 288.0, "episode/score": 0.04804136580287377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04804136580287377}
{"step": 215824, "time": 7215.175053358078, "episode/length": 288.0, "episode/score": 0.03518571046174657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03518571046174657}
{"step": 216664, "time": 7241.725339412689, "episode/length": 288.0, "episode/score": 0.06710311880718223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06710311880718223}
{"step": 217064, "time": 7254.500027179718, "episode/length": 288.0, "episode/score": 0.05314457618931101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05314457618931101}
{"step": 217336, "time": 7263.231082677841, "episode/length": 265.0, "episode/score": 0.21545422295227468, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.043579224116427895}
{"step": 217504, "time": 7268.718532800674, "episode/length": 288.0, "episode/score": 0.049045229362775444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049045229362775444}
{"step": 217560, "time": 7270.273480892181, "episode/length": 288.0, "episode/score": 0.03190231249134001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03190231249134001}
{"step": 218000, "time": 7284.474416255951, "episode/length": 288.0, "episode/score": 0.059333762310899374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059333762310899374}
{"step": 218000, "time": 7284.488015651703, "episode/length": 288.0, "episode/score": 0.03892168312027877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03892168312027877}
{"step": 218136, "time": 7288.592017173767, "episode/length": 288.0, "episode/score": 0.044394193112225366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044394193112225366}
{"step": 218976, "time": 7315.476137876511, "episode/length": 288.0, "episode/score": 0.06605163648760026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06605163648760026}
{"step": 219376, "time": 7328.1187863349915, "episode/length": 288.0, "episode/score": 0.023605395494598724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023605395494598724}
{"step": 219648, "time": 7336.7063891887665, "episode/length": 288.0, "episode/score": 0.08846582830256011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08846582830256011}
{"step": 219816, "time": 7341.873292684555, "episode/length": 288.0, "episode/score": 0.10378172995012847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10378172995012847}
{"step": 219872, "time": 7343.875809431076, "episode/length": 288.0, "episode/score": 0.07438187724983436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07438187724983436}
{"step": 220064, "time": 7355.818583250046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.827887773514, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.835596561432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.84295630455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.849963188171, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.857012271881, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.863776445389, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7355.870674133301, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220312, "time": 7363.46954536438, "episode/length": 288.0, "episode/score": 0.08442456179295732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08442456179295732}
{"step": 220312, "time": 7363.477899312973, "episode/length": 288.0, "episode/score": 0.0702101656368086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0702101656368086}
{"step": 220448, "time": 7368.009203195572, "episode/length": 288.0, "episode/score": 0.10039534783197723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10039534783197723}
{"step": 221288, "time": 7395.0307648181915, "episode/length": 288.0, "episode/score": 0.10764298380718174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10764298380718174}
{"step": 221688, "time": 7407.713795661926, "episode/length": 288.0, "episode/score": 0.08435490844203741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08435490844203741}
{"step": 221960, "time": 7416.420095682144, "episode/length": 288.0, "episode/score": 0.08028148119501566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08028148119501566}
{"step": 222128, "time": 7421.9766047000885, "episode/length": 288.0, "episode/score": 0.06526432838904839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06526432838904839}
{"step": 222184, "time": 7423.554002523422, "episode/length": 288.0, "episode/score": 0.06224077055912858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06224077055912858}
{"step": 222624, "time": 7437.881755828857, "episode/length": 288.0, "episode/score": 0.09714152543870114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09714152543870114}
{"step": 222624, "time": 7437.890499591827, "episode/length": 288.0, "episode/score": 0.08007831253860331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08007831253860331}
{"step": 222760, "time": 7441.986002445221, "episode/length": 288.0, "episode/score": 0.058018530122012635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058018530122012635}
{"step": 223600, "time": 7468.9934957027435, "episode/length": 288.0, "episode/score": 0.09373658132108176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09373658132108176}
{"step": 224000, "time": 7481.7023758888245, "episode/length": 288.0, "episode/score": 0.09698174830020889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09698174830020889}
{"step": 224232, "time": 7488.809184551239, "episode/length": 200.0, "episode/score": 0.4643885960956595, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.08938859725981274}
{"step": 224272, "time": 7490.317109823227, "episode/length": 288.0, "episode/score": 0.0828653938098114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0828653938098114}
{"step": 224440, "time": 7495.509265422821, "episode/length": 288.0, "episode/score": 0.09818976337396634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09818976337396634}
{"step": 224496, "time": 7497.506206035614, "episode/length": 288.0, "episode/score": 0.11395023845341257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11395023845341257}
{"step": 224936, "time": 7511.186349868774, "episode/length": 288.0, "episode/score": 0.11032586066448857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11032586066448857}
{"step": 225072, "time": 7515.713420391083, "episode/length": 288.0, "episode/score": 0.12515163515877248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12515163515877248}
{"step": 225912, "time": 7542.155319452286, "episode/length": 288.0, "episode/score": 0.12229273372315674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12229273372315674}
{"step": 226312, "time": 7554.922337293625, "episode/length": 288.0, "episode/score": 0.1424427100361072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1424427100361072}
{"step": 226544, "time": 7562.514966011047, "episode/length": 288.0, "episode/score": 0.04725001051986055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04725001051986055}
{"step": 226584, "time": 7563.552707433701, "episode/length": 288.0, "episode/score": 0.10970825289325603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10970825289325603}
{"step": 226752, "time": 7569.096923828125, "episode/length": 288.0, "episode/score": 0.0934615298974677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0934615298974677}
{"step": 226808, "time": 7570.680438280106, "episode/length": 288.0, "episode/score": 0.10505541854786316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10505541854786316}
{"step": 227248, "time": 7584.927555561066, "episode/length": 288.0, "episode/score": 0.11140140814256938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11140140814256938}
{"step": 227384, "time": 7589.02174115181, "episode/length": 288.0, "episode/score": 0.09507505013084483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09507505013084483}
{"step": 228224, "time": 7616.0767188072205, "episode/length": 288.0, "episode/score": 0.1010027545524963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1010027545524963}
{"step": 228624, "time": 7628.77890753746, "episode/length": 288.0, "episode/score": 0.11837643392436803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11837643392436803}
{"step": 228856, "time": 7635.96010684967, "episode/length": 288.0, "episode/score": 0.1322665895976911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1322665895976911}
{"step": 228896, "time": 7637.486760377884, "episode/length": 288.0, "episode/score": 0.09384536826479462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09384536826479462}
{"step": 229064, "time": 7642.773133277893, "episode/length": 288.0, "episode/score": 0.12776906892355555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12776906892355555}
{"step": 229120, "time": 7644.812880516052, "episode/length": 288.0, "episode/score": 0.12186375478722766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12186375478722766}
{"step": 229560, "time": 7659.073527812958, "episode/length": 288.0, "episode/score": 0.12167790176300741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12167790176300741}
{"step": 229696, "time": 7663.630971670151, "episode/length": 288.0, "episode/score": 0.14127378108861421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14127378108861421}
{"step": 230048, "time": 7680.620874643326, "eval_episode/length": 277.0, "eval_episode/score": 0.13437500596046448, "eval_episode/reward_rate": 0.0035971223021582736}
{"step": 230048, "time": 7680.856654167175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7680.864909648895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7680.879430294037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7680.892799139023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7680.900168180466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7680.912497758865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7680.922515630722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230536, "time": 7696.306851148605, "episode/length": 288.0, "episode/score": 0.12166837412075893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12166837412075893}
{"step": 230936, "time": 7709.000847101212, "episode/length": 288.0, "episode/score": 0.10382139440594074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10382139440594074}
{"step": 231168, "time": 7716.5154230594635, "episode/length": 288.0, "episode/score": 0.12847296400116193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12847296400116193}
{"step": 231208, "time": 7717.56348323822, "episode/length": 288.0, "episode/score": 0.10584736307203002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10584736307203002}
{"step": 231376, "time": 7723.084620714188, "episode/length": 288.0, "episode/score": 0.10131220614431413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10131220614431413}
{"step": 231432, "time": 7724.622776508331, "episode/length": 288.0, "episode/score": 0.0911603039838269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0911603039838269}
{"step": 231872, "time": 7738.906467914581, "episode/length": 288.0, "episode/score": 0.13114530886571174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13114530886571174}
{"step": 232008, "time": 7742.977592229843, "episode/length": 288.0, "episode/score": 0.10764406559451345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10764406559451345}
{"step": 232848, "time": 7769.702329874039, "episode/length": 288.0, "episode/score": 0.07870298204289838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07870298204289838}
{"step": 233248, "time": 7782.378023147583, "episode/length": 288.0, "episode/score": 0.0763018433269167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0763018433269167}
{"step": 233480, "time": 7789.515623807907, "episode/length": 288.0, "episode/score": 0.10894412817100374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10894412817100374}
{"step": 233520, "time": 7791.004048347473, "episode/length": 288.0, "episode/score": 0.11779973466678939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11779973466678939}
{"step": 233528, "time": 7791.043164491653, "episode/length": 268.0, "episode/score": 0.2655280112695664, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.10302801839418407}
{"step": 233744, "time": 7798.190545082092, "episode/length": 288.0, "episode/score": 0.09037142767294881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09037142767294881}
{"step": 233936, "time": 7804.265440702438, "episode/length": 135.0, "episode/score": 0.6263440087351455, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.04821900955005276}
{"step": 234184, "time": 7811.859770298004, "episode/length": 288.0, "episode/score": 0.08483307495100689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08483307495100689}
{"step": 234320, "time": 7816.41294169426, "episode/length": 288.0, "episode/score": 0.09536044524963927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09536044524963927}
{"step": 235560, "time": 7855.909426689148, "episode/length": 288.0, "episode/score": 0.07889313561750555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07889313561750555}
{"step": 235792, "time": 7863.530421495438, "episode/length": 288.0, "episode/score": 0.08503179512311476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08503179512311476}
{"step": 235832, "time": 7864.584443569183, "episode/length": 288.0, "episode/score": 0.0977436242151839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0977436242151839}
{"step": 235840, "time": 7865.064647912979, "episode/length": 288.0, "episode/score": 0.11919732132378158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11919732132378158}
{"step": 236056, "time": 7871.657518386841, "episode/length": 288.0, "episode/score": 0.107378201243165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.107378201243165}
{"step": 236248, "time": 7877.736177682877, "episode/length": 288.0, "episode/score": 0.094095446057338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.094095446057338}
{"step": 236496, "time": 7885.955214262009, "episode/length": 288.0, "episode/score": 0.10728224888984528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10728224888984528}
{"step": 236632, "time": 7890.042930603027, "episode/length": 288.0, "episode/score": 0.12445199490969117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12445199490969117}
{"step": 237872, "time": 7930.319077253342, "episode/length": 288.0, "episode/score": 0.09030908582300867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09030908582300867}
{"step": 238104, "time": 7937.439607143402, "episode/length": 288.0, "episode/score": 0.08835381704378165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08835381704378165}
{"step": 238144, "time": 7938.9347903728485, "episode/length": 288.0, "episode/score": 0.09285606522911394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09285606522911394}
{"step": 238152, "time": 7938.972372055054, "episode/length": 288.0, "episode/score": 0.06951309405050665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06951309405050665}
{"step": 238160, "time": 7939.470228910446, "episode/length": 238.0, "episode/score": 0.33084573313180954, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.07459574025642723}
{"step": 238368, "time": 7946.181933879852, "episode/length": 288.0, "episode/score": 0.07513325179542107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07513325179542107}
{"step": 238808, "time": 7959.958727121353, "episode/length": 288.0, "episode/score": 0.06824840359982431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06824840359982431}
{"step": 238944, "time": 7964.496159791946, "episode/length": 288.0, "episode/score": 0.08328143840620328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08328143840620328}
{"step": 239128, "time": 7970.0921947956085, "episode/length": 121.0, "episode/score": 0.6766920249102668, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.05481702251211118}
{"step": 239888, "time": 7994.563340425491, "episode/length": 134.0, "episode/score": 0.6082419673152231, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.026991956209201362}
{"step": 240032, "time": 8005.879638671875, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.888451576233, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.895445346832, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.902011632919, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.909381389618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.915855884552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.9233112335205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8005.93091750145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240184, "time": 8010.547802448273, "episode/length": 288.0, "episode/score": 0.08829473508600927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08829473508600927}
{"step": 240416, "time": 8018.148188114166, "episode/length": 288.0, "episode/score": 0.06911154045380385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06911154045380385}
{"step": 240456, "time": 8019.223960161209, "episode/length": 288.0, "episode/score": 0.07045843777561345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07045843777561345}
{"step": 240472, "time": 8019.738158941269, "episode/length": 288.0, "episode/score": 0.06506916483269265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06506916483269265}
{"step": 240680, "time": 8026.384954690933, "episode/length": 288.0, "episode/score": 0.08168800293165646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08168800293165646}
{"step": 241256, "time": 8044.781095981598, "episode/length": 288.0, "episode/score": 0.05849039582474802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05849039582474802}
{"step": 241440, "time": 8050.828735113144, "episode/length": 288.0, "episode/score": 0.06459393763728372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06459393763728372}
{"step": 241872, "time": 8064.6363134384155, "episode/length": 181.0, "episode/score": 0.4714620111565466, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.03708702953852594}
{"step": 242200, "time": 8074.866140604019, "episode/length": 288.0, "episode/score": 0.0613290484675133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0613290484675133}
{"step": 242344, "time": 8079.424655914307, "episode/length": 233.0, "episode/score": 0.3404360094781964, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0685610011195763}
{"step": 242496, "time": 8084.45467877388, "episode/length": 288.0, "episode/score": 0.05648521719402311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05648521719402311}
{"step": 242768, "time": 8093.206825971603, "episode/length": 288.0, "episode/score": 0.048522213172816464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048522213172816464}
{"step": 242768, "time": 8093.21582698822, "episode/length": 260.0, "episode/score": 0.25781066075444414, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0703106672154945}
{"step": 243080, "time": 8102.92645740509, "episode/length": 150.0, "episode/score": 0.5746727282285065, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0434227200503301}
{"step": 243568, "time": 8118.716267585754, "episode/length": 288.0, "episode/score": 0.06179226880843203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06179226880843203}
{"step": 243752, "time": 8124.438553094864, "episode/length": 288.0, "episode/score": 0.070875443434403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.070875443434403}
{"step": 244512, "time": 8148.753424167633, "episode/length": 288.0, "episode/score": 0.03665584891354001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03665584891354001}
{"step": 244656, "time": 8153.43209695816, "episode/length": 288.0, "episode/score": 0.05548464843343481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05548464843343481}
{"step": 244808, "time": 8158.047654390335, "episode/length": 288.0, "episode/score": 0.051451907282171305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051451907282171305}
{"step": 245080, "time": 8166.7181828022, "episode/length": 288.0, "episode/score": 0.04634445731497294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04634445731497294}
{"step": 245080, "time": 8166.72761964798, "episode/length": 288.0, "episode/score": 0.037785933859026954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037785933859026954}
{"step": 245392, "time": 8176.886351108551, "episode/length": 288.0, "episode/score": 0.048085688963084294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048085688963084294}
{"step": 245880, "time": 8192.781537294388, "episode/length": 288.0, "episode/score": 0.03131499732830889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03131499732830889}
{"step": 246064, "time": 8198.851132154465, "episode/length": 288.0, "episode/score": 0.03271268587536724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03271268587536724}
{"step": 246169, "time": 8202.917447090149, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4251279830932617, "train/action_min": 0.0, "train/action_std": 1.8054588201145332, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0012200935381467086, "train/actor_opt_grad_steps": 14325.0, "train/actor_opt_loss": 8.460179002198856, "train/adv_mag": 0.006159702975613375, "train/adv_max": 0.005628182281119128, "train/adv_mean": 0.001232124032757298, "train/adv_min": -0.0019524951154987018, "train/adv_std": 0.0010078776971719587, "train/cont_avg": 0.9965616861979166, "train/cont_loss_mean": 0.022976842140148317, "train/cont_loss_std": 0.3211970197939659, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658102123360885, "train/cont_pos_acc": 0.9999999844779571, "train/cont_pos_loss": 0.00351658425036779, "train/cont_pred": 0.996489679440856, "train/cont_rate": 0.9965616861979166, "train/dyn_loss_mean": 1.0000008984158437, "train/dyn_loss_std": 2.7166710727518268e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13502477202655427, "train/extr_critic_critic_opt_grad_steps": 14325.0, "train/extr_critic_critic_opt_loss": 12991.470876057943, "train/extr_critic_mag": 0.0988661131511132, "train/extr_critic_max": 0.0988661131511132, "train/extr_critic_mean": 0.09804145925833534, "train/extr_critic_min": 0.09649246620635192, "train/extr_critic_std": 0.0003374646215282458, "train/extr_return_normed_mag": 0.008676150736088553, "train/extr_return_normed_max": 0.008191956129545966, "train/extr_return_normed_mean": 0.003794318744004007, "train/extr_return_normed_min": 0.0005386609506482879, "train/extr_return_normed_std": 0.00104863589414587, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.10367123150111486, "train/extr_return_raw_max": 0.10367123150111486, "train/extr_return_raw_mean": 0.09927359886933118, "train/extr_return_raw_min": 0.09601793632221718, "train/extr_return_raw_std": 0.0010486358987691347, "train/extr_reward_mag": 0.001844600463906924, "train/extr_reward_max": 0.001844600463906924, "train/extr_reward_mean": 0.0004862774407380736, "train/extr_reward_min": 6.421717504660289e-05, "train/extr_reward_std": 0.0003192708746075172, "train/image_loss_mean": 0.1957348360059162, "train/image_loss_std": 0.10116941175268342, "train/model_loss_mean": 0.8289202957724532, "train/model_loss_std": 0.36765425248692435, "train/model_opt_grad_norm": 38.071285923322044, "train/model_opt_grad_steps": 14309.682291666666, "train/model_opt_loss": 2429.2309436798096, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2929.6875, "train/policy_entropy_mag": 1.8537733467916648, "train/policy_entropy_max": 1.8537733467916648, "train/policy_entropy_mean": 1.5641964011204739, "train/policy_entropy_min": 1.0654556998051703, "train/policy_entropy_std": 0.12437393016686353, "train/policy_logprob_mag": 3.9917889634768167, "train/policy_logprob_max": -0.41487359699385706, "train/policy_logprob_mean": -1.5645103282295167, "train/policy_logprob_min": -3.9917889634768167, "train/policy_logprob_std": 0.7112592721823603, "train/policy_randomness_mag": 0.9526511048898101, "train/policy_randomness_max": 0.9526511048898101, "train/policy_randomness_mean": 0.8038379840242366, "train/policy_randomness_min": 0.547535949270241, "train/policy_randomness_std": 0.0639155596436467, "train/post_ent_mag": 55.51380989948908, "train/post_ent_max": 55.51380989948908, "train/post_ent_mean": 54.909483194351196, "train/post_ent_min": 54.536992271741234, "train/post_ent_std": 0.19233968621119857, "train/prior_ent_mag": 56.23626983165741, "train/prior_ent_max": 56.23626983165741, "train/prior_ent_mean": 53.97197963794073, "train/prior_ent_min": 51.89379241069158, "train/prior_ent_std": 0.7031883243471384, "train/rep_loss_mean": 1.0000008984158437, "train/rep_loss_std": 2.7166710727518268e-05, "train/reward_avg": 0.00027435049673840695, "train/reward_loss_mean": 0.010208056866152523, "train/reward_loss_std": 0.05148873266686375, "train/reward_max_data": 0.07443945427803556, "train/reward_max_pred": 0.0011674072593450546, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008956927287120683, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.829936265945435, "train/reward_pred": 0.0002645330781282003, "train/reward_rate": 0.00014241536458333334, "train_stats/mean_log_entropy": 1.5974704910408366, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02560459077358246, "report/cont_loss_std": 0.3512416481971741, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.634439468383789, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0036091592628508806, "report/cont_pred": 0.9963974356651306, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18678617477416992, "report/image_loss_std": 0.1039377897977829, "report/model_loss_mean": 0.8213901519775391, "report/model_loss_std": 0.37010666728019714, "report/post_ent_mag": 53.454864501953125, "report/post_ent_max": 53.454864501953125, "report/post_ent_mean": 52.91678237915039, "report/post_ent_min": 52.5198974609375, "report/post_ent_std": 0.1848708540201187, "report/prior_ent_mag": 53.89445495605469, "report/prior_ent_max": 53.89445495605469, "report/prior_ent_mean": 51.638450622558594, "report/prior_ent_min": 50.05530548095703, "report/prior_ent_std": 0.6463377475738525, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020038602815475315, "report/reward_loss_mean": 0.008999376557767391, "report/reward_loss_std": 0.014731532894074917, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.003497481346130371, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008999377489089966, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003228350542485714, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02014465630054474, "eval/cont_loss_std": 0.3049968481063843, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.646764278411865, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036119860596954823, "eval/cont_pred": 0.9963947534561157, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18236839771270752, "eval/image_loss_std": 0.10952214896678925, "eval/model_loss_mean": 0.8041799068450928, "eval/model_loss_std": 0.3270188271999359, "eval/post_ent_mag": 53.53162384033203, "eval/post_ent_max": 53.53162384033203, "eval/post_ent_mean": 52.922298431396484, "eval/post_ent_min": 52.52540969848633, "eval/post_ent_std": 0.1795985996723175, "eval/prior_ent_mag": 55.50088119506836, "eval/prior_ent_max": 55.50088119506836, "eval/prior_ent_mean": 51.57122802734375, "eval/prior_ent_min": 50.09276580810547, "eval/prior_ent_std": 0.6126513481140137, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016668238677084446, "eval/reward_loss_std": 0.0016113794408738613, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0034372806549072266, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016668238677084446, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003338663373142481, "eval/reward_rate": 0.0, "replay/size": 245665.0, "replay/inserts": 30736.0, "replay/samples": 30736.0, "replay/insert_wait_avg": 1.329554362200251e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.984863977268423e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2411446994838692e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1150133609772, "timer/env.step_count": 3842.0, "timer/env.step_total": 38.041869163513184, "timer/env.step_frac": 0.038037494343445596, "timer/env.step_avg": 0.009901579688577092, "timer/env.step_min": 0.008568286895751953, "timer/env.step_max": 0.04911208152770996, "timer/replay._sample_count": 30736.0, "timer/replay._sample_total": 16.13054871559143, "timer/replay._sample_frac": 0.016128693700320787, "timer/replay._sample_avg": 0.0005248096276545885, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.029991865158081055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4709.0, "timer/agent.policy_total": 50.31561470031738, "timer/agent.policy_frac": 0.05030982839786316, "timer/agent.policy_avg": 0.010684989318394008, "timer/agent.policy_min": 0.009083747863769531, "timer/agent.policy_max": 0.09644317626953125, "timer/dataset_train_count": 1921.0, "timer/dataset_train_total": 0.22719359397888184, "timer/dataset_train_frac": 0.00022716746668503373, "timer/dataset_train_avg": 0.00011826839873965738, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.00043392181396484375, "timer/agent.train_count": 1921.0, "timer/agent.train_total": 860.80996966362, "timer/agent.train_frac": 0.8607109764013942, "timer/agent.train_avg": 0.44810513777387817, "timer/agent.train_min": 0.4366111755371094, "timer/agent.train_max": 0.5953667163848877, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47309041023254395, "timer/agent.report_frac": 0.00047303600477177193, "timer/agent.report_avg": 0.23654520511627197, "timer/agent.report_min": 0.22512292861938477, "timer/agent.report_max": 0.24796748161315918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.599706530087037e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 30.731908724674756}
{"step": 246224, "time": 8204.693199634552, "episode/length": 142.0, "episode/score": 0.582415068536875, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.02616506374056371}
{"step": 246824, "time": 8223.641293525696, "episode/length": 288.0, "episode/score": 0.04678211510207575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04678211510207575}
{"step": 246968, "time": 8228.195283174515, "episode/length": 288.0, "episode/score": 0.025104036948562225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025104036948562225}
{"step": 247120, "time": 8233.256421327591, "episode/length": 288.0, "episode/score": 0.022974584486405547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022974584486405547}
{"step": 247392, "time": 8242.045230865479, "episode/length": 288.0, "episode/score": 0.04898229781315422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04898229781315422}
{"step": 247704, "time": 8251.696373224258, "episode/length": 288.0, "episode/score": 0.03732666177302235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03732666177302235}
{"step": 248192, "time": 8267.283401727676, "episode/length": 288.0, "episode/score": 0.05613937183187545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05613937183187545}
{"step": 248376, "time": 8273.069257736206, "episode/length": 288.0, "episode/score": 0.05449227267661172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05449227267661172}
{"step": 248536, "time": 8278.145679235458, "episode/length": 288.0, "episode/score": 0.06581596433807135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06581596433807135}
{"step": 249136, "time": 8297.367120981216, "episode/length": 288.0, "episode/score": 0.07160771127712451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07160771127712451}
{"step": 249280, "time": 8302.052425861359, "episode/length": 288.0, "episode/score": 0.06830578271495824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06830578271495824}
{"step": 249432, "time": 8306.643296480179, "episode/length": 288.0, "episode/score": 0.07627286600779826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07627286600779826}
{"step": 249704, "time": 8315.21145248413, "episode/length": 288.0, "episode/score": 0.07431867676683623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07431867676683623}
{"step": 250016, "time": 8325.262591123581, "episode/length": 288.0, "episode/score": 0.06315453214062927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06315453214062927}
{"step": 250016, "time": 8331.061472177505, "eval_episode/length": 276.0, "eval_episode/score": 0.13750000298023224, "eval_episode/reward_rate": 0.0036101083032490976}
{"step": 250016, "time": 8331.311251401901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8331.31953907013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8331.326652765274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8331.334532737732, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8331.367846250534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8331.375518798828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8331.394817829132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250504, "time": 8346.716871500015, "episode/length": 288.0, "episode/score": 0.08304636794684939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08304636794684939}
{"step": 250688, "time": 8352.783821344376, "episode/length": 288.0, "episode/score": 0.09072898318669331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09072898318669331}
{"step": 250848, "time": 8357.836228847504, "episode/length": 288.0, "episode/score": 0.09103899030264984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09103899030264984}
{"step": 251448, "time": 8376.773831367493, "episode/length": 288.0, "episode/score": 0.0780598833104591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0780598833104591}
{"step": 251592, "time": 8381.34878230095, "episode/length": 288.0, "episode/score": 0.09981147984126437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09981147984126437}
{"step": 251744, "time": 8386.368107318878, "episode/length": 288.0, "episode/score": 0.07455028837131294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07455028837131294}
{"step": 252016, "time": 8395.090473890305, "episode/length": 288.0, "episode/score": 0.06575914304670505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06575914304670505}
{"step": 252328, "time": 8404.712452411652, "episode/length": 288.0, "episode/score": 0.07304944463857055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07304944463857055}
{"step": 252816, "time": 8420.339195013046, "episode/length": 288.0, "episode/score": 0.06722902140398901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06722902140398901}
{"step": 253000, "time": 8426.068766355515, "episode/length": 288.0, "episode/score": 0.04981971515965711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04981971515965711}
{"step": 253160, "time": 8431.112039089203, "episode/length": 288.0, "episode/score": 0.07106774628857693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106774628857693}
{"step": 253760, "time": 8450.26820731163, "episode/length": 288.0, "episode/score": 0.09880917715312876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09880917715312876}
{"step": 253904, "time": 8454.973000764847, "episode/length": 288.0, "episode/score": 0.08284941694932968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08284941694932968}
{"step": 254056, "time": 8460.123624324799, "episode/length": 288.0, "episode/score": 0.09305296047986644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09305296047986644}
{"step": 254328, "time": 8468.74067234993, "episode/length": 288.0, "episode/score": 0.0782913495177695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0782913495177695}
{"step": 254368, "time": 8470.243790149689, "episode/length": 193.0, "episode/score": 0.48244698185172297, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.08557198897634066}
{"step": 254640, "time": 8478.822792768478, "episode/length": 288.0, "episode/score": 0.10347582666975086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10347582666975086}
{"step": 254752, "time": 8482.522099018097, "episode/length": 123.0, "episode/score": 0.6829292462803096, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.06730419380028252}
{"step": 255312, "time": 8500.3197722435, "episode/length": 288.0, "episode/score": 0.0674207580327959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0674207580327959}
{"step": 255472, "time": 8505.401570558548, "episode/length": 288.0, "episode/score": 0.06951016254052433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06951016254052433}
{"step": 255872, "time": 8518.193802595139, "episode/length": 69.0, "episode/score": 0.8156190517053119, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.03124401114621378}
{"step": 256216, "time": 8528.899380922318, "episode/length": 288.0, "episode/score": 0.07481680635680732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07481680635680732}
{"step": 256368, "time": 8533.93794131279, "episode/length": 288.0, "episode/score": 0.04509669891353951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04509669891353951}
{"step": 256432, "time": 8536.020193099976, "episode/length": 262.0, "episode/score": 0.23202098707611185, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.05077098227980059}
{"step": 256680, "time": 8543.812846899033, "episode/length": 288.0, "episode/score": 0.050885511518686144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050885511518686144}
{"step": 256952, "time": 8552.59413099289, "episode/length": 288.0, "episode/score": 0.07646226405097423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07646226405097423}
{"step": 257064, "time": 8556.19875907898, "episode/length": 288.0, "episode/score": 0.08246254866719482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08246254866719482}
{"step": 257216, "time": 8561.232100248337, "episode/length": 66.0, "episode/score": 0.818453429583542, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.024703412866301733}
{"step": 257232, "time": 8561.760969400406, "episode/length": 99.0, "episode/score": 0.7260288286950072, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.035403817588985476}
{"step": 257552, "time": 8572.029382228851, "episode/length": 74.0, "episode/score": 0.8052415024108086, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.03649147617079507}
{"step": 257768, "time": 8578.713641643524, "episode/length": 174.0, "episode/score": 0.5017146290008441, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.045464623540965476}
{"step": 257784, "time": 8579.230096817017, "episode/length": 288.0, "episode/score": 0.0748551771083612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0748551771083612}
{"step": 257824, "time": 8580.730143785477, "episode/length": 94.0, "episode/score": 0.7389868919503897, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.032736850634591974}
{"step": 257832, "time": 8580.765768766403, "episode/length": 74.0, "episode/score": 0.8031994593065974, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.034449418747499294}
{"step": 257976, "time": 8585.343405485153, "episode/length": 25.0, "episode/score": 0.930814471178337, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.008939464018794752}
{"step": 258184, "time": 8591.950501680374, "episode/length": 288.0, "episode/score": 0.07138870063613467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07138870063613467}
{"step": 258528, "time": 8603.311143875122, "episode/length": 288.0, "episode/score": 0.08199196900932293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08199196900932293}
{"step": 258672, "time": 8607.971581459045, "episode/length": 60.0, "episode/score": 0.8409876807490946, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.028487681564001832}
{"step": 259528, "time": 8635.00089430809, "episode/length": 288.0, "episode/score": 0.07284065900762471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07284065900762471}
{"step": 259648, "time": 8639.075945615768, "episode/length": 208.0, "episode/score": 0.39845996172959985, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.04845995337097975}
{"step": 259864, "time": 8645.739781141281, "episode/length": 288.0, "episode/score": 0.06873654438322774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06873654438322774}
{"step": 260000, "time": 8656.089638710022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.09763789177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.104332208633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.112822532654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.121656417847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.128880023956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.138947725296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8656.146415948868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260096, "time": 8659.196697473526, "episode/length": 288.0, "episode/score": 0.06909539943080745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06909539943080745}
{"step": 260136, "time": 8660.270700216293, "episode/length": 288.0, "episode/score": 0.06954009852347554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06954009852347554}
{"step": 260144, "time": 8660.754426717758, "episode/length": 288.0, "episode/score": 0.06185215541904654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06185215541904654}
{"step": 260840, "time": 8683.603679180145, "episode/length": 288.0, "episode/score": 0.04890454354949725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04890454354949725}
{"step": 260984, "time": 8688.278442144394, "episode/length": 288.0, "episode/score": 0.07143246030454975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07143246030454975}
{"step": 261840, "time": 8715.763797521591, "episode/length": 288.0, "episode/score": 0.054030064622679674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054030064622679674}
{"step": 261960, "time": 8719.352359771729, "episode/length": 288.0, "episode/score": 0.03373881436550619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03373881436550619}
{"step": 262176, "time": 8727.102275371552, "episode/length": 288.0, "episode/score": 0.07102853189758207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07102853189758207}
{"step": 262408, "time": 8734.194525241852, "episode/length": 288.0, "episode/score": 0.04254805685627616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04254805685627616}
{"step": 262448, "time": 8735.674488306046, "episode/length": 288.0, "episode/score": 0.059291733433269656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059291733433269656}
{"step": 262456, "time": 8735.713654279709, "episode/length": 288.0, "episode/score": 0.06574449987249409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06574449987249409}
{"step": 262560, "time": 8739.249651908875, "episode/length": 89.0, "episode/score": 0.7581020495251778, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.03622703841915609}
{"step": 262992, "time": 8753.129058361053, "episode/length": 101.0, "episode/score": 0.7131071504893498, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.02873213377210959}
{"step": 263152, "time": 8758.197008132935, "episode/length": 288.0, "episode/score": 0.04755018726734761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04755018726734761}
{"step": 263296, "time": 8762.759550094604, "episode/length": 288.0, "episode/score": 0.04437413448204097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04437413448204097}
{"step": 263552, "time": 8770.900338888168, "episode/length": 49.0, "episode/score": 0.8635124767165507, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.016637465610529034}
{"step": 264272, "time": 8793.885997533798, "episode/length": 288.0, "episode/score": 0.041786600051977985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041786600051977985}
{"step": 264720, "time": 8808.11086320877, "episode/length": 288.0, "episode/score": 0.04268139983111041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04268139983111041}
{"step": 264760, "time": 8809.199615955353, "episode/length": 288.0, "episode/score": 0.032197329294376686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032197329294376686}
{"step": 264768, "time": 8809.680183649063, "episode/length": 288.0, "episode/score": 0.04671214152870107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04671214152870107}
{"step": 264872, "time": 8812.845921993256, "episode/length": 288.0, "episode/score": 0.04505648078492186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04505648078492186}
{"step": 265304, "time": 8826.577502965927, "episode/length": 288.0, "episode/score": 0.04332594587242511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04332594587242511}
{"step": 265608, "time": 8836.252640008926, "episode/length": 288.0, "episode/score": 0.02495217461790844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02495217461790844}
{"step": 265864, "time": 8844.45631146431, "episode/length": 288.0, "episode/score": 0.04678401067701543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04678401067701543}
{"step": 266584, "time": 8867.211274147034, "episode/length": 288.0, "episode/score": 0.056995643442007804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056995643442007804}
{"step": 267032, "time": 8881.507241487503, "episode/length": 288.0, "episode/score": 0.045975147669707894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045975147669707894}
{"step": 267072, "time": 8882.991387844086, "episode/length": 288.0, "episode/score": 0.035388159735703084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035388159735703084}
{"step": 267080, "time": 8883.033385038376, "episode/length": 288.0, "episode/score": 0.05447311245677611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05447311245677611}
{"step": 267184, "time": 8886.538052082062, "episode/length": 288.0, "episode/score": 0.07282128750773609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07282128750773609}
{"step": 267400, "time": 8893.12694311142, "episode/length": 101.0, "episode/score": 0.7085281535931927, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.024153151195037026}
{"step": 267616, "time": 8900.14143037796, "episode/length": 288.0, "episode/score": 0.04833594439372746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04833594439372746}
{"step": 267832, "time": 8906.924238920212, "episode/length": 245.0, "episode/score": 0.2776838307320304, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.043308831546937654}
{"step": 267920, "time": 8909.917227268219, "episode/length": 288.0, "episode/score": 0.05990120958955458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05990120958955458}
{"step": 268048, "time": 8914.00944685936, "episode/length": 120.0, "episode/score": 0.6608492241146564, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03584920077338438}
{"step": 268384, "time": 8924.61965084076, "episode/length": 68.0, "episode/score": 0.8142655552721862, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.026765502035459576}
{"step": 268392, "time": 8924.657008647919, "episode/length": 150.0, "episode/score": 0.5775744296523726, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.04632442249283031}
{"step": 268464, "time": 8927.16114449501, "episode/length": 132.0, "episode/score": 0.6326362463435657, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.04513625586633907}
{"step": 269344, "time": 8955.224479675293, "episode/length": 288.0, "episode/score": 0.06271887850851954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06271887850851954}
{"step": 269384, "time": 8956.27327799797, "episode/length": 288.0, "episode/score": 0.07690279782553944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07690279782553944}
{"step": 269928, "time": 8973.739614009857, "episode/length": 288.0, "episode/score": 0.08217846586404676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08217846586404676}
{"step": 270088, "time": 8979.796983718872, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 270088, "time": 8984.571032524109, "eval_episode/length": 250.0, "eval_episode/score": 0.21875, "eval_episode/reward_rate": 0.00398406374501992}
{"step": 270088, "time": 8985.36743402481, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.375679254532, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.382826328278, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.38990688324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.397124290466, "eval_episode/length": 288.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.0034602076124567475}
{"step": 270088, "time": 8985.40499162674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270232, "time": 8989.97978067398, "episode/length": 288.0, "episode/score": 0.07962694216837463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07962694216837463}
{"step": 270360, "time": 8994.613233566284, "episode/length": 288.0, "episode/score": 0.06407746864567798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06407746864567798}
{"step": 270672, "time": 9004.713142156601, "episode/length": 284.0, "episode/score": 0.1878460425653543, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.07534604455605631}
{"step": 270696, "time": 9005.261046886444, "episode/length": 288.0, "episode/score": 0.06892888559747234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06892888559747234}
{"step": 270776, "time": 9007.798551082611, "episode/length": 288.0, "episode/score": 0.06646698549377561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06646698549377561}
{"step": 271656, "time": 9035.748747587204, "episode/length": 288.0, "episode/score": 0.07634431922912199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07634431922912199}
{"step": 271696, "time": 9037.24340391159, "episode/length": 288.0, "episode/score": 0.09674662958218505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09674662958218505}
{"step": 272240, "time": 9054.622269153595, "episode/length": 288.0, "episode/score": 0.059865936993560354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059865936993560354}
{"step": 272296, "time": 9056.19760131836, "episode/length": 202.0, "episode/score": 0.45353699084100185, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.084786985287991}
{"step": 272336, "time": 9057.699719667435, "episode/length": 262.0, "episode/score": 0.24814608798095605, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.06689607486094928}
{"step": 272672, "time": 9068.30919599533, "episode/length": 288.0, "episode/score": 0.06735009558656202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06735009558656202}
{"step": 273008, "time": 9078.887386083603, "episode/length": 288.0, "episode/score": 0.08880456658249614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08880456658249614}
{"step": 273088, "time": 9081.458761453629, "episode/length": 288.0, "episode/score": 0.07273360272711216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07273360272711216}
{"step": 273968, "time": 9109.254756450653, "episode/length": 288.0, "episode/score": 0.09407165546525675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09407165546525675}
{"step": 274008, "time": 9110.294105768204, "episode/length": 288.0, "episode/score": 0.08440891554531049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08440891554531049}
{"step": 274552, "time": 9127.568945646286, "episode/length": 288.0, "episode/score": 0.0850401141779571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0850401141779571}
{"step": 274608, "time": 9129.551399946213, "episode/length": 288.0, "episode/score": 0.02842279062898001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02842279062898001}
{"step": 274648, "time": 9130.58764886856, "episode/length": 288.0, "episode/score": 0.06366311709217598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06366311709217598}
{"step": 274984, "time": 9141.173350095749, "episode/length": 288.0, "episode/score": 0.07094929567620056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07094929567620056}
{"step": 275064, "time": 9143.848937034607, "episode/length": 256.0, "episode/score": 0.29105924356915125, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.09105924175307223}
{"step": 275400, "time": 9154.474388122559, "episode/length": 288.0, "episode/score": 0.07456377486198562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07456377486198562}
{"step": 276280, "time": 9182.299255609512, "episode/length": 288.0, "episode/score": 0.06758943412427243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06758943412427243}
{"step": 276320, "time": 9183.850803613663, "episode/length": 288.0, "episode/score": 0.034459695420224534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034459695420224534}
{"step": 276864, "time": 9201.123163223267, "episode/length": 288.0, "episode/score": 0.04707247037003981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04707247037003981}
{"step": 276905, "time": 9203.356762886047, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4323553371923574, "train/action_min": 0.0, "train/action_std": 1.7363758389813913, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0020285279206856796, "train/actor_opt_grad_steps": 16250.0, "train/actor_opt_loss": 10.229186422999833, "train/adv_mag": 0.009882551632396916, "train/adv_max": 0.009737699760674194, "train/adv_mean": 0.002411739067766561, "train/adv_min": -0.0024433566035384343, "train/adv_std": 0.0018101593134490473, "train/cont_avg": 0.9965036026554405, "train/cont_loss_mean": 0.023218933642489614, "train/cont_loss_std": 0.3205263899149008, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.630922390285291, "train/cont_pos_acc": 0.9999999876467057, "train/cont_pos_loss": 0.0035151539242541698, "train/cont_pred": 0.9964908917333178, "train/cont_rate": 0.9965036026554405, "train/dyn_loss_mean": 1.4315212057044469, "train/dyn_loss_std": 0.012729996542079576, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2791839318152112, "train/extr_critic_critic_opt_grad_steps": 16250.0, "train/extr_critic_critic_opt_loss": 5850.182264891313, "train/extr_critic_mag": 0.17048940201497448, "train/extr_critic_max": 0.17048940201497448, "train/extr_critic_mean": 0.16938227662150723, "train/extr_critic_min": 0.16749937237853213, "train/extr_critic_std": 0.0004985627319110036, "train/extr_return_normed_mag": 0.014243643750180852, "train/extr_return_normed_max": 0.014211053520904304, "train/extr_return_normed_mean": 0.006590749199081145, "train/extr_return_normed_min": 0.0015930917905402308, "train/extr_return_normed_std": 0.0019242140177065515, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.17941430473574702, "train/extr_return_raw_max": 0.17941430473574702, "train/extr_return_raw_mean": 0.17179400987266877, "train/extr_return_raw_min": 0.16679634300538296, "train/extr_return_raw_std": 0.0019242140161985812, "train/extr_reward_mag": 0.004162024339863673, "train/extr_reward_max": 0.004162024339863673, "train/extr_reward_mean": 0.0008468097096931556, "train/extr_reward_min": 1.4657801297044507e-05, "train/extr_reward_std": 0.0009300557602742213, "train/image_loss_mean": 0.18763614279927368, "train/image_loss_std": 0.10318532362194259, "train/model_loss_mean": 1.0805303395720962, "train/model_loss_std": 0.3772602859556366, "train/model_opt_grad_norm": 36.584905999929795, "train/model_opt_grad_steps": 16233.295336787565, "train/model_opt_loss": 3150.38603629473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3044.041450777202, "train/policy_entropy_mag": 1.6917624158562774, "train/policy_entropy_max": 1.6917624158562774, "train/policy_entropy_mean": 0.8406833133858103, "train/policy_entropy_min": 0.1146688209991381, "train/policy_entropy_std": 0.3233182766894602, "train/policy_logprob_mag": 6.117661179656192, "train/policy_logprob_max": -0.01772442611098444, "train/policy_logprob_mean": -0.8410735119500926, "train/policy_logprob_min": -6.117661179656192, "train/policy_logprob_std": 1.0284095724629614, "train/policy_randomness_mag": 0.8693939540052661, "train/policy_randomness_max": 0.8693939540052661, "train/policy_randomness_mean": 0.4320257852732209, "train/policy_randomness_min": 0.058928120553184665, "train/policy_randomness_std": 0.16615273533244207, "train/post_ent_mag": 54.269226706707414, "train/post_ent_max": 54.269226706707414, "train/post_ent_mean": 53.70966099951551, "train/post_ent_min": 53.33359675827422, "train/post_ent_std": 0.17656915578894664, "train/prior_ent_mag": 55.28234809915019, "train/prior_ent_max": 55.28234809915019, "train/prior_ent_mean": 52.33004383225515, "train/prior_ent_min": 50.472497475579615, "train/prior_ent_std": 0.7561448926752713, "train/rep_loss_mean": 1.4315212057044469, "train/rep_loss_std": 0.012729996542079576, "train/reward_avg": 0.0003103202845541751, "train/reward_loss_mean": 0.010762520071717433, "train/reward_loss_std": 0.05585482811140273, "train/reward_max_data": 0.09745811906503273, "train/reward_max_pred": 0.0031556162809460893, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00926844611609538, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.533088452888258, "train/reward_pred": 0.0002874289530720272, "train/reward_rate": 0.00019733646373056994, "train_stats/mean_log_entropy": 0.7755250049238446, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.026264414191246033, "report/cont_loss_std": 0.3573494553565979, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.725100517272949, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003916038665920496, "report/cont_pred": 0.9960939288139343, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16481736302375793, "report/image_loss_std": 0.09716857224702835, "report/model_loss_mean": 0.8001729249954224, "report/model_loss_std": 0.37155234813690186, "report/post_ent_mag": 61.27510070800781, "report/post_ent_max": 61.27510070800781, "report/post_ent_mean": 60.52839279174805, "report/post_ent_min": 59.914302825927734, "report/post_ent_std": 0.2174793928861618, "report/prior_ent_mag": 64.9774169921875, "report/prior_ent_max": 64.9774169921875, "report/prior_ent_mean": 59.504302978515625, "report/prior_ent_min": 56.617855072021484, "report/prior_ent_std": 1.3691030740737915, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019633016199804842, "report/reward_loss_mean": 0.009091155603528023, "report/reward_loss_std": 0.015139112249016762, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.005641460418701172, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009091155603528023, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00038386054802685976, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019593620672822, "eval/cont_loss_std": 0.2912495732307434, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.392581939697266, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003806192660704255, "eval/cont_pred": 0.9961991310119629, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22986868023872375, "eval/image_loss_std": 0.10649150609970093, "eval/model_loss_mean": 0.8508121371269226, "eval/model_loss_std": 0.3113040626049042, "eval/post_ent_mag": 61.25518035888672, "eval/post_ent_max": 61.25518035888672, "eval/post_ent_mean": 60.52471160888672, "eval/post_ent_min": 60.00076675415039, "eval/post_ent_std": 0.20444242656230927, "eval/prior_ent_mag": 66.20352172851562, "eval/prior_ent_max": 66.20352172851562, "eval/prior_ent_mean": 59.531009674072266, "eval/prior_ent_min": 57.0504264831543, "eval/prior_ent_std": 1.261464238166809, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013498151674866676, "eval/reward_loss_std": 0.001691945712082088, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005870819091796875, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013498151674866676, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00029610050842165947, "eval/reward_rate": 0.0, "replay/size": 276401.0, "replay/inserts": 30736.0, "replay/samples": 30736.0, "replay/insert_wait_avg": 1.3342240649793746e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.004350675635509e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65792.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.234785495744857e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4192957878113, "timer/env.step_count": 3842.0, "timer/env.step_total": 38.11692023277283, "timer/env.step_frac": 0.038100944667162254, "timer/env.step_avg": 0.009921114063709742, "timer/env.step_min": 0.008574485778808594, "timer/env.step_max": 0.036156654357910156, "timer/replay._sample_count": 30736.0, "timer/replay._sample_total": 16.107635021209717, "timer/replay._sample_frac": 0.016100883988373355, "timer/replay._sample_avg": 0.0005240641274469586, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.025555133819580078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4709.0, "timer/agent.policy_total": 50.63173866271973, "timer/agent.policy_frac": 0.050610517885751286, "timer/agent.policy_avg": 0.01075212118554252, "timer/agent.policy_min": 0.009241580963134766, "timer/agent.policy_max": 0.09678149223327637, "timer/dataset_train_count": 1921.0, "timer/dataset_train_total": 0.22826886177062988, "timer/dataset_train_frac": 0.00022817318971329162, "timer/dataset_train_avg": 0.00011882814251464335, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0004372596740722656, "timer/agent.train_count": 1921.0, "timer/agent.train_total": 860.6941540241241, "timer/agent.train_frac": 0.8603334198450698, "timer/agent.train_avg": 0.4480448485289558, "timer/agent.train_min": 0.43446993827819824, "timer/agent.train_max": 1.3750882148742676, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4781346321105957, "timer/agent.report_frac": 0.00047793423629846496, "timer/agent.report_avg": 0.23906731605529785, "timer/agent.report_min": 0.2326664924621582, "timer/agent.report_max": 0.2454681396484375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169638086152371e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 30.72251679584335}
{"step": 276920, "time": 9203.430149793625, "episode/length": 288.0, "episode/score": 0.07130233849076717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07130233849076717}
{"step": 276960, "time": 9205.314130783081, "episode/length": 288.0, "episode/score": 0.058409258301850286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058409258301850286}
{"step": 277296, "time": 9215.951468467712, "episode/length": 288.0, "episode/score": 0.06831777030112107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06831777030112107}
{"step": 277376, "time": 9218.469476938248, "episode/length": 288.0, "episode/score": 0.07342781948864285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07342781948864285}
{"step": 277712, "time": 9229.133927106857, "episode/length": 288.0, "episode/score": 0.0925907327565767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0925907327565767}
{"step": 278472, "time": 9253.175053358078, "episode/length": 146.0, "episode/score": 0.60460122799077, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.06085121127352977}
{"step": 278592, "time": 9257.730874061584, "episode/length": 288.0, "episode/score": 0.07258998494489788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07258998494489788}
{"step": 278632, "time": 9258.797287464142, "episode/length": 288.0, "episode/score": 0.06906184564400064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06906184564400064}
{"step": 279064, "time": 9272.620709896088, "episode/length": 58.0, "episode/score": 0.8397739109723261, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.02102385849229904}
{"step": 279176, "time": 9276.153773784637, "episode/length": 288.0, "episode/score": 0.04086317005919682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04086317005919682}
{"step": 279232, "time": 9278.17084813118, "episode/length": 288.0, "episode/score": 0.11026124739441912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11026124739441912}
{"step": 279272, "time": 9279.23545908928, "episode/length": 288.0, "episode/score": 0.07355428484640925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07355428484640925}
{"step": 279688, "time": 9292.551683425903, "episode/length": 288.0, "episode/score": 0.07567390622648418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07567390622648418}
{"step": 280024, "time": 9303.225667476654, "episode/length": 288.0, "episode/score": 0.05058315200506058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05058315200506058}
{"step": 280072, "time": 9306.488556861877, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 280072, "time": 9306.785796642303, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 280072, "time": 9310.681153535843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9310.689078092575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9310.696664333344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9310.70385313034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9310.711159706116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9310.718589544296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280216, "time": 9315.293228626251, "episode/length": 122.0, "episode/score": 0.6611646589003612, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.04241468355712641}
{"step": 280424, "time": 9321.984859228134, "episode/length": 91.0, "episode/score": 0.7405428118139525, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.024917824549788747}
{"step": 280784, "time": 9333.55022096634, "episode/length": 288.0, "episode/score": 0.06220233152646415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06220233152646415}
{"step": 280944, "time": 9338.600623607635, "episode/length": 288.0, "episode/score": 0.08204766604148972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08204766604148972}
{"step": 281376, "time": 9352.401785612106, "episode/length": 288.0, "episode/score": 0.06731579852680625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06731579852680625}
{"step": 281384, "time": 9352.467300891876, "episode/length": 54.0, "episode/score": 0.8619996495623354, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.030749623322321895}
{"step": 281488, "time": 9356.002440929413, "episode/length": 288.0, "episode/score": 0.060478461547177176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060478461547177176}
{"step": 281584, "time": 9359.081163406372, "episode/length": 288.0, "episode/score": 0.057341356905851626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057341356905851626}
{"step": 281928, "time": 9369.686051130295, "episode/length": 68.0, "episode/score": 0.8149384576915963, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.027438434664645683}
{"step": 282024, "time": 9372.702992677689, "episode/length": 199.0, "episode/score": 0.4300065417073142, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.05188153095053849}
{"step": 282336, "time": 9382.850223779678, "episode/length": 288.0, "episode/score": 0.04994306655135006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04994306655135006}
{"step": 282528, "time": 9388.963061332703, "episode/length": 288.0, "episode/score": 0.09151368696467443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09151368696467443}
{"step": 283096, "time": 9406.63718366623, "episode/length": 288.0, "episode/score": 0.05080093607011804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05080093607011804}
{"step": 283464, "time": 9418.378684520721, "episode/length": 191.0, "episode/score": 0.4375785885715686, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.03445358617341299}
{"step": 283696, "time": 9425.950867414474, "episode/length": 288.0, "episode/score": 0.019030717341024683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019030717341024683}
{"step": 283800, "time": 9429.036548614502, "episode/length": 288.0, "episode/score": 0.050764789970571655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050764789970571655}
{"step": 283896, "time": 9432.055481910706, "episode/length": 288.0, "episode/score": 0.04289324768762981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04289324768762981}
{"step": 283968, "time": 9434.548124313354, "episode/length": 33.0, "episode/score": 0.9142294405635312, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.01735438808350409}
{"step": 284336, "time": 9446.287055015564, "episode/length": 288.0, "episode/score": 0.05942853808267046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05942853808267046}
{"step": 284648, "time": 9455.929997205734, "episode/length": 288.0, "episode/score": 0.06976838066509572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06976838066509572}
{"step": 284736, "time": 9458.916531085968, "episode/length": 49.0, "episode/score": 0.8686474420933337, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.02177240153423554}
{"step": 284840, "time": 9461.975256681442, "episode/length": 288.0, "episode/score": 0.06151998776408618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06151998776408618}
{"step": 285408, "time": 9480.210593700409, "episode/length": 288.0, "episode/score": 0.05208900726915999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05208900726915999}
{"step": 285776, "time": 9491.818305253983, "episode/length": 288.0, "episode/score": 0.0392244281413241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0392244281413241}
{"step": 286112, "time": 9502.570173025131, "episode/length": 288.0, "episode/score": 0.033244511491375306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033244511491375306}
{"step": 286208, "time": 9505.62065577507, "episode/length": 288.0, "episode/score": 0.0522557361160807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0522557361160807}
{"step": 286280, "time": 9507.66517496109, "episode/length": 288.0, "episode/score": 0.04474419363327797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04474419363327797}
{"step": 286624, "time": 9518.752596378326, "episode/length": 105.0, "episode/score": 0.6951629593576172, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.023287930719448013}
{"step": 286960, "time": 9529.905447483063, "episode/length": 288.0, "episode/score": 0.06233222404193839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06233222404193839}
{"step": 287048, "time": 9532.577495574951, "episode/length": 288.0, "episode/score": 0.04096761595906173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04096761595906173}
{"step": 287152, "time": 9536.092679262161, "episode/length": 288.0, "episode/score": 0.04494310174192151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04494310174192151}
{"step": 287456, "time": 9545.63457608223, "episode/length": 103.0, "episode/score": 0.7076636098970539, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.029538571736111408}
{"step": 287720, "time": 9553.767794132233, "episode/length": 288.0, "episode/score": 0.06407417599518794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06407417599518794}
{"step": 288424, "time": 9576.070578336716, "episode/length": 288.0, "episode/score": 0.05735160263969874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05735160263969874}
{"step": 288520, "time": 9579.110451936722, "episode/length": 288.0, "episode/score": 0.08197334494212782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08197334494212782}
{"step": 288568, "time": 9580.623897314072, "episode/length": 189.0, "episode/score": 0.4883985193509943, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.07902350859421858}
{"step": 288592, "time": 9581.637664318085, "episode/length": 288.0, "episode/score": 0.05646033730795352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05646033730795352}
{"step": 289176, "time": 9600.061044692993, "episode/length": 72.0, "episode/score": 0.7912726681865934, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.016272668687179248}
{"step": 289272, "time": 9603.124388933182, "episode/length": 288.0, "episode/score": 0.06043250333772221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06043250333772221}
{"step": 289464, "time": 9609.190121889114, "episode/length": 288.0, "episode/score": 0.06646862496609174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06646862496609174}
{"step": 289720, "time": 9617.276730537415, "episode/length": 161.0, "episode/score": 0.5483561080266668, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.05148110562851116}
{"step": 289768, "time": 9618.787818908691, "episode/length": 288.0, "episode/score": 0.05541244424608749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05541244424608749}
{"step": 290032, "time": 9627.485034704208, "episode/length": 288.0, "episode/score": 0.04988703653054927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04988703653054927}
{"step": 290056, "time": 9628.463462591171, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 290056, "time": 9629.65459227562, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 290056, "time": 9630.7221159935, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 290056, "time": 9633.381963729858, "eval_episode/length": 259.0, "eval_episode/score": 0.19062499701976776, "eval_episode/reward_rate": 0.0038461538461538464}
{"step": 290056, "time": 9633.984495639801, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9633.993278503418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9634.000324487686, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9634.00801897049, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290192, "time": 9638.52629518509, "episode/length": 58.0, "episode/score": 0.8411997505600084, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.02244971853997413}
{"step": 290304, "time": 9642.067619562149, "episode/length": 140.0, "episode/score": 0.6062102565821306, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.04371025739703782}
{"step": 290328, "time": 9642.607291698456, "episode/length": 225.0, "episode/score": 0.3794435687033797, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.08256857516443006}
{"step": 290656, "time": 9653.285432100296, "episode/length": 172.0, "episode/score": 0.5078740544415155, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0453740488885046}
{"step": 290880, "time": 9660.372185230255, "episode/length": 288.0, "episode/score": 0.08583069050206404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08583069050206404}
{"step": 291312, "time": 9674.010560035706, "episode/length": 125.0, "episode/score": 0.6518725869964328, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.042497572677348217}
{"step": 291488, "time": 9679.566544532776, "episode/length": 161.0, "episode/score": 0.5434228962811289, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.04654791466310826}
{"step": 291552, "time": 9681.670538187027, "episode/length": 260.0, "episode/score": 0.24378383422032357, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.056283840943308405}
{"step": 291656, "time": 9684.746891975403, "episode/length": 96.0, "episode/score": 0.7334554103291566, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03345541407190922}
{"step": 292032, "time": 9696.913484811783, "episode/length": 171.0, "episode/score": 0.5087851125480256, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.04316012487640819}
{"step": 292080, "time": 9698.4321911335, "episode/length": 288.0, "episode/score": 0.05881627668929923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05881627668929923}
{"step": 292344, "time": 9706.619115114212, "episode/length": 288.0, "episode/score": 0.0706159202960066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0706159202960066}
{"step": 292640, "time": 9716.343350887299, "episode/length": 288.0, "episode/score": 0.0519064143429091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0519064143429091}
{"step": 293328, "time": 9738.181258678436, "episode/length": 221.0, "episode/score": 0.3555523681132513, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.04617738084908751}
{"step": 293384, "time": 9739.726342916489, "episode/length": 168.0, "episode/score": 0.5305168184013382, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.055516810042718134}
{"step": 293624, "time": 9747.426243066788, "episode/length": 288.0, "episode/score": 0.05686129198460321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05686129198460321}
{"step": 293800, "time": 9753.00087761879, "episode/length": 288.0, "episode/score": 0.06301905873442593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06301905873442593}
{"step": 293968, "time": 9758.505870103836, "episode/length": 288.0, "episode/score": 0.04704884870744763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04704884870744763}
{"step": 294016, "time": 9760.020672798157, "episode/length": 78.0, "episode/score": 0.7972997374315582, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.04104968419483157}
{"step": 294392, "time": 9771.760178089142, "episode/length": 288.0, "episode/score": 0.03335125429509844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03335125429509844}
{"step": 294656, "time": 9780.370219945908, "episode/length": 288.0, "episode/score": 0.04390987932606549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04390987932606549}
{"step": 294704, "time": 9781.922433376312, "episode/length": 257.0, "episode/score": 0.2583796527951563, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.06150465329574217}
{"step": 295264, "time": 9800.149669647217, "episode/length": 182.0, "episode/score": 0.4990159032821566, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.06776589772914576}
{"step": 295544, "time": 9808.948500156403, "episode/length": 196.0, "episode/score": 0.46162048654343835, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.07412049130482501}
{"step": 295640, "time": 9812.019253730774, "episode/length": 288.0, "episode/score": 0.10758382146650547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10758382146650547}
{"step": 295744, "time": 9815.53176188469, "episode/length": 135.0, "episode/score": 0.6512619383519223, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.07313690971375308}
{"step": 295880, "time": 9819.60888338089, "episode/length": 185.0, "episode/score": 0.49078094773119574, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.06890594057165345}
{"step": 295936, "time": 9821.59447979927, "episode/length": 288.0, "episode/score": 0.08249078671889265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08249078671889265}
{"step": 296024, "time": 9824.1528840065, "episode/length": 47.0, "episode/score": 0.8855225365399519, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.032397561196717106}
{"step": 296224, "time": 9830.66941690445, "episode/length": 119.0, "episode/score": 0.6682164959106558, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.04009145535155767}
{"step": 296312, "time": 9833.365449905396, "episode/length": 200.0, "episode/score": 0.4516991021039303, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.07669908778484569}
{"step": 296328, "time": 9833.876950263977, "episode/length": 288.0, "episode/score": 0.1010382883094394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1010382883094394}
{"step": 297568, "time": 9873.229214668274, "episode/length": 252.0, "episode/score": 0.2724240360596468, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.05992403050663597}
{"step": 297664, "time": 9876.246512413025, "episode/length": 179.0, "episode/score": 0.5068958178956109, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0662708124357323}
{"step": 297808, "time": 9880.807905197144, "episode/length": 186.0, "episode/score": 0.47804841223558014, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.05929842437478783}
{"step": 298056, "time": 9888.44827079773, "episode/length": 288.0, "episode/score": 0.09436899263425857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09436899263425857}
{"step": 298080, "time": 9889.432175397873, "episode/length": 267.0, "episode/score": 0.264497115874633, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.09887211314469369}
{"step": 298104, "time": 9889.977846622467, "episode/length": 66.0, "episode/score": 0.8155865387838048, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.021836546615645602}
{"step": 298192, "time": 9893.093426465988, "episode/length": 288.0, "episode/score": 0.0828221636900821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0828221636900821}
{"step": 298208, "time": 9893.614891767502, "episode/length": 272.0, "episode/score": 0.2317398449092707, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.08173983976371346}
{"step": 298640, "time": 9907.20177412033, "episode/length": 288.0, "episode/score": 0.10173327860411518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10173327860411518}
{"step": 299976, "time": 9949.580149412155, "episode/length": 288.0, "episode/score": 0.05280170402875228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05280170402875228}
{"step": 300040, "time": 9953.743325710297, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 300040, "time": 9954.984974622726, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 300040, "time": 9957.54110956192, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9957.549611330032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9957.557351589203, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9957.56416273117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9957.571660995483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9957.578605413437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300120, "time": 9960.122435808182, "episode/length": 288.0, "episode/score": 0.07776182623979366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07776182623979366}
{"step": 300368, "time": 9968.19603228569, "episode/length": 288.0, "episode/score": 0.04295902790914852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04295902790914852}
{"step": 300384, "time": 9968.704247236252, "episode/length": 217.0, "episode/score": 0.37033787444778454, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.04846286889477369}
{"step": 300392, "time": 9968.741875171661, "episode/length": 288.0, "episode/score": 0.03591220729390443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03591220729390443}
{"step": 300416, "time": 9969.740200281143, "episode/length": 288.0, "episode/score": 0.07683222334986795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07683222334986795}
{"step": 300504, "time": 9972.33870792389, "episode/length": 288.0, "episode/score": 0.03712738746736477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03712738746736477}
{"step": 300520, "time": 9972.85229229927, "episode/length": 288.0, "episode/score": 0.017099913609058603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017099913609058603}
{"step": 301480, "time": 10003.318144083023, "episode/length": 135.0, "episode/score": 0.6143588960383113, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.03623391914675267}
{"step": 302288, "time": 10029.281082391739, "episode/length": 288.0, "episode/score": 0.032277164814786374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032277164814786374}
{"step": 302384, "time": 10032.33763384819, "episode/length": 249.0, "episode/score": 0.2640795607429709, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.04220455963411496}
{"step": 302432, "time": 10033.852210998535, "episode/length": 288.0, "episode/score": 0.020609218615959435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020609218615959435}
{"step": 302680, "time": 10041.549199342728, "episode/length": 288.0, "episode/score": 0.04394411324312841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04394411324312841}
{"step": 302728, "time": 10043.11799955368, "episode/length": 288.0, "episode/score": 0.05616453620319817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05616453620319817}
{"step": 302744, "time": 10043.625129938126, "episode/length": 157.0, "episode/score": 0.5315696461784682, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0221946962428774}
{"step": 302816, "time": 10046.104079008102, "episode/length": 288.0, "episode/score": 0.03349145243782914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03349145243782914}
{"step": 302832, "time": 10046.63481092453, "episode/length": 288.0, "episode/score": 0.063666656528369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.063666656528369}
{"step": 303608, "time": 10071.603377103806, "episode/length": 115.0, "episode/score": 0.6609025951883041, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.020277605258229414}
{"step": 303672, "time": 10073.710399150848, "episode/length": 115.0, "episode/score": 0.6806314262572073, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.040006419097665}
{"step": 303736, "time": 10075.771093845367, "episode/length": 112.0, "episode/score": 0.6854977197351673, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03549772925794059}
{"step": 304440, "time": 10098.15281867981, "episode/length": 213.0, "episode/score": 0.3970056859991473, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0626306848000695}
{"step": 304528, "time": 10101.128737449646, "episode/length": 213.0, "episode/score": 0.3638585564289656, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.02948356260770879}
{"step": 304600, "time": 10103.352465867996, "episode/length": 288.0, "episode/score": 0.07771534785243261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07771534785243261}
{"step": 304696, "time": 10106.40620803833, "episode/length": 288.0, "episode/score": 0.05245297301485152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05245297301485152}
{"step": 304744, "time": 10107.904574632645, "episode/length": 288.0, "episode/score": 0.06269248708468922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06269248708468922}
{"step": 305392, "time": 10128.547125339508, "episode/length": 118.0, "episode/score": 0.6623425820666284, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.031092568294695866}
{"step": 305920, "time": 10145.324331998825, "episode/length": 288.0, "episode/score": 0.09663672949733382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09663672949733382}
{"step": 305984, "time": 10147.349952697754, "episode/length": 288.0, "episode/score": 0.05363704693323257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05363704693323257}
{"step": 306048, "time": 10149.394293785095, "episode/length": 288.0, "episode/score": 0.0722881789997416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0722881789997416}
{"step": 306088, "time": 10150.43282198906, "episode/length": 185.0, "episode/score": 0.48938654613209565, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.06751153446145963}
{"step": 306416, "time": 10160.97077012062, "episode/length": 40.0, "episode/score": 0.8791619111488558, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.004161928291011918}
{"step": 306784, "time": 10172.730056524277, "episode/length": 99.0, "episode/score": 0.7279688202529826, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.037343809146960893}
{"step": 306840, "time": 10174.288074970245, "episode/length": 288.0, "episode/score": 0.0785287012695619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0785287012695619}
{"step": 307008, "time": 10179.7651720047, "episode/length": 288.0, "episode/score": 0.07368539595253765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07368539595253765}
{"step": 307056, "time": 10181.27133345604, "episode/length": 288.0, "episode/score": 0.06441958142221438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06441958142221438}
{"step": 307256, "time": 10187.33809185028, "episode/length": 104.0, "episode/score": 0.713925616143456, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03892560503743425}
{"step": 307352, "time": 10190.383360862732, "episode/length": 42.0, "episode/score": 0.8823772334490059, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.01362722789599502}
{"step": 307512, "time": 10195.55923461914, "episode/length": 31.0, "episode/score": 0.9156864806673184, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.012561485428705055}
{"step": 307672, "time": 10200.628824234009, "episode/length": 110.0, "episode/score": 0.7073188357053368, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.051068836520244076}
{"step": 307704, "time": 10201.64205956459, "episode/length": 288.0, "episode/score": 0.043427741432054745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043427741432054745}
{"step": 307737, "time": 10203.656523227692, "train_stats/mean_log_entropy": 0.7104583207679831, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2246007919311523, "train/action_min": 0.0, "train/action_std": 1.7334527056664228, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001929760387611168, "train/actor_opt_grad_steps": 18175.0, "train/actor_opt_loss": 9.582064368296415, "train/adv_mag": 0.014167586419110497, "train/adv_max": 0.013775328174233437, "train/adv_mean": 0.0025354503343777424, "train/adv_min": -0.005670577210063736, "train/adv_std": 0.0024315252539963694, "train/cont_avg": 0.9966481526692709, "train/cont_loss_mean": 0.022221521100921866, "train/cont_loss_std": 0.31332033196364745, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.568883960783793, "train/cont_pos_acc": 0.9999999854092797, "train/cont_pos_loss": 0.00354043109715955, "train/cont_pred": 0.9964648385842642, "train/cont_rate": 0.9966481526692709, "train/dyn_loss_mean": 1.000036978473266, "train/dyn_loss_std": 0.0010868471617868636, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17053740161160627, "train/extr_critic_critic_opt_grad_steps": 18175.0, "train/extr_critic_critic_opt_loss": 11717.933186848959, "train/extr_critic_mag": 0.23923352671166262, "train/extr_critic_max": 0.23923352671166262, "train/extr_critic_mean": 0.2343932477136453, "train/extr_critic_min": 0.22859877161681652, "train/extr_critic_std": 0.001773750810571073, "train/extr_return_normed_mag": 0.022571957825372618, "train/extr_return_normed_max": 0.02254744021532436, "train/extr_return_normed_mean": 0.009192693003380251, "train/extr_return_normed_min": 0.0007822217109302679, "train/extr_return_normed_std": 0.0030239755221070177, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.25028344445551437, "train/extr_return_raw_max": 0.25028344445551437, "train/extr_return_raw_mean": 0.236928708696117, "train/extr_return_raw_min": 0.22851822595112026, "train/extr_return_raw_std": 0.003023975526654491, "train/extr_reward_mag": 0.009674113864699999, "train/extr_reward_max": 0.009674113864699999, "train/extr_reward_mean": 0.001090298769668152, "train/extr_reward_min": 1.2985741098721823e-05, "train/extr_reward_std": 0.0018341028847620084, "train/image_loss_mean": 0.17345917434431612, "train/image_loss_std": 0.10705801863999416, "train/model_loss_mean": 0.8067379919812083, "train/model_loss_std": 0.3660192531145488, "train/model_opt_grad_norm": 34.049032121896744, "train/model_opt_grad_steps": 18156.458333333332, "train/model_opt_loss": 2049.126635869344, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2552.0833333333335, "train/policy_entropy_mag": 1.755744842812419, "train/policy_entropy_max": 1.755744842812419, "train/policy_entropy_mean": 0.7510124042940637, "train/policy_entropy_min": 0.06669914159768571, "train/policy_entropy_std": 0.3991251861055692, "train/policy_logprob_mag": 6.508768439292908, "train/policy_logprob_max": -0.008920672635819452, "train/policy_logprob_mean": -0.750083688336114, "train/policy_logprob_min": -6.508768439292908, "train/policy_logprob_std": 1.0294940248131752, "train/policy_randomness_mag": 0.9022744195535779, "train/policy_randomness_max": 0.9022744195535779, "train/policy_randomness_mean": 0.3859440521337092, "train/policy_randomness_min": 0.03427658036040763, "train/policy_randomness_std": 0.2051097840691606, "train/post_ent_mag": 58.304132322470345, "train/post_ent_max": 58.304132322470345, "train/post_ent_mean": 57.56861271460851, "train/post_ent_min": 56.99856867392858, "train/post_ent_std": 0.22012811767247817, "train/prior_ent_mag": 63.83956144253413, "train/prior_ent_max": 63.83956144253413, "train/prior_ent_mean": 58.65858926375707, "train/prior_ent_min": 56.05457389354706, "train/prior_ent_std": 1.1560577483226855, "train/rep_loss_mean": 1.000036978473266, "train/rep_loss_std": 0.0010868471617868636, "train/reward_avg": 0.00035078622014831734, "train/reward_loss_mean": 0.011035087266160796, "train/reward_loss_std": 0.06004020137576541, "train/reward_max_data": 0.1335735703711786, "train/reward_max_pred": 0.006430358936389287, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00941660039340301, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.446030833504417, "train/reward_pred": 0.0003355543691820155, "train/reward_rate": 0.0002492268880208333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00928198266774416, "report/cont_loss_std": 0.16609451174736023, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.321304798126221, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004089390393346548, "report/cont_pred": 0.9959203004837036, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1861288845539093, "report/image_loss_std": 0.10951811820268631, "report/model_loss_mean": 0.8038415908813477, "report/model_loss_std": 0.20487311482429504, "report/post_ent_mag": 56.81428527832031, "report/post_ent_max": 56.81428527832031, "report/post_ent_mean": 56.035255432128906, "report/post_ent_min": 55.293033599853516, "report/post_ent_std": 0.22533611953258514, "report/prior_ent_mag": 60.89258575439453, "report/prior_ent_max": 60.89258575439453, "report/prior_ent_mean": 57.103355407714844, "report/prior_ent_min": 54.57366180419922, "report/prior_ent_std": 1.131238341331482, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001818293530959636, "report/reward_loss_mean": 0.00843074731528759, "report/reward_loss_std": 0.013810325413942337, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.008593916893005371, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00843074731528759, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00029417918995022774, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.032121822237968445, "eval/cont_loss_std": 0.39856240153312683, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.718968391418457, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0042177652940154076, "eval/cont_pred": 0.9957982301712036, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22642295062541962, "eval/image_loss_std": 0.11804290860891342, "eval/model_loss_mean": 0.8599339127540588, "eval/model_loss_std": 0.41866105794906616, "eval/post_ent_mag": 56.94593048095703, "eval/post_ent_max": 56.94593048095703, "eval/post_ent_mean": 56.06018829345703, "eval/post_ent_min": 55.518733978271484, "eval/post_ent_std": 0.22680720686912537, "eval/prior_ent_mag": 61.84096145629883, "eval/prior_ent_max": 61.84096145629883, "eval/prior_ent_mean": 57.140995025634766, "eval/prior_ent_min": 54.458396911621094, "eval/prior_ent_std": 1.1236248016357422, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013891211710870266, "eval/reward_loss_std": 0.0018860305426642299, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.012193441390991211, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013891211710870266, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002570884535089135, "eval/reward_rate": 0.0, "replay/size": 307233.0, "replay/inserts": 30832.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.3295516611444685e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.917816969787884e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72728.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2039519511292137e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2772400379181, "timer/env.step_count": 3854.0, "timer/env.step_total": 38.057589054107666, "timer/env.step_frac": 0.03804704089104836, "timer/env.step_avg": 0.009874828503919996, "timer/env.step_min": 0.008590936660766602, "timer/env.step_max": 0.043229103088378906, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 16.138823986053467, "timer/replay._sample_frac": 0.016134350897998723, "timer/replay._sample_avg": 0.0005234439538808207, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.011219024658203125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4721.0, "timer/agent.policy_total": 49.67321848869324, "timer/agent.policy_frac": 0.049659450900642554, "timer/agent.policy_avg": 0.010521757781972726, "timer/agent.policy_min": 0.009094476699829102, "timer/agent.policy_max": 0.08571696281433105, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.22897815704345703, "timer/dataset_train_frac": 0.00022891469272536585, "timer/dataset_train_avg": 0.00011882623614087028, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.0005774497985839844, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 861.2673690319061, "timer/agent.train_frac": 0.861028657414276, "timer/agent.train_avg": 0.44694725948723724, "timer/agent.train_min": 0.4357726573944092, "timer/agent.train_max": 0.6143436431884766, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753246307373047, "timer/agent.report_frac": 0.00047519288824294983, "timer/agent.report_avg": 0.23766231536865234, "timer/agent.report_min": 0.23188185691833496, "timer/agent.report_max": 0.24344277381896973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.718298972636211e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 30.822888102166633}
{"step": 307784, "time": 10204.939177751541, "episode/length": 216.0, "episode/score": 0.3832899987274061, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.05829001105578868}
{"step": 307952, "time": 10210.5083630085, "episode/length": 111.0, "episode/score": 0.6794045482738511, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.026279578326466435}
{"step": 308216, "time": 10218.663992404938, "episode/length": 63.0, "episode/score": 0.8296550022118936, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.02652997918494293}
{"step": 308232, "time": 10219.18086194992, "episode/length": 288.0, "episode/score": 0.05747720872099649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05747720872099649}
{"step": 308568, "time": 10229.979053497314, "episode/length": 131.0, "episode/score": 0.6351321288742611, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.044507117453918}
{"step": 309152, "time": 10248.755433321, "episode/length": 288.0, "episode/score": 0.03801871615428354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03801871615428354}
{"step": 309192, "time": 10249.829838991165, "episode/length": 121.0, "episode/score": 0.6696672921284517, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.047792289730296034}
{"step": 309480, "time": 10259.169458150864, "episode/length": 265.0, "episode/score": 0.22641475740226724, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.05453976412525208}
{"step": 309496, "time": 10259.685673952103, "episode/length": 115.0, "episode/score": 0.6757020988105751, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.035077118950425756}
{"step": 309984, "time": 10275.39866065979, "episode/length": 288.0, "episode/score": 0.06937720761459332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06937720761459332}
{"step": 310024, "time": 10276.638889551163, "eval_episode/length": 8.0, "eval_episode/score": 0.9750000238418579, "eval_episode/reward_rate": 0.1111111111111111}
{"step": 310024, "time": 10279.746410369873, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 310024, "time": 10279.836680173874, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 310024, "time": 10281.00983095169, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 310024, "time": 10281.848642110825, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 310024, "time": 10282.117363452911, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 310024, "time": 10283.056504487991, "eval_episode/length": 272.0, "eval_episode/score": 0.15000000596046448, "eval_episode/reward_rate": 0.003663003663003663}
{"step": 310024, "time": 10283.414106845856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10283.422760248184, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10283.43161702156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10283.440424919128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310096, "time": 10286.034965515137, "episode/length": 288.0, "episode/score": 0.05971536590971027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05971536590971027}
{"step": 310264, "time": 10291.266207456589, "episode/length": 288.0, "episode/score": 0.03574677312701624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03574677312701624}
{"step": 310392, "time": 10295.348521232605, "episode/length": 113.0, "episode/score": 0.6779043496113673, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.031029302428237315}
{"step": 310544, "time": 10300.43684387207, "episode/length": 288.0, "episode/score": 0.061176841848350705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061176841848350705}
{"step": 310568, "time": 10300.983240365982, "episode/length": 21.0, "episode/score": 0.9510522358156095, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.016677219098369278}
{"step": 310784, "time": 10308.065826177597, "episode/length": 85.0, "episode/score": 0.7645814837570697, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0302064765975274}
{"step": 310840, "time": 10309.642746925354, "episode/length": 33.0, "episode/score": 0.9122150957066424, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.015340092004635153}
{"step": 311464, "time": 10330.13501739502, "episode/length": 288.0, "episode/score": 0.03877232381898921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03877232381898921}
{"step": 311504, "time": 10331.646647453308, "episode/length": 288.0, "episode/score": 0.10035212628122281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10035212628122281}
{"step": 311808, "time": 10341.317098140717, "episode/length": 288.0, "episode/score": 0.06518797355715833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06518797355715833}
{"step": 312296, "time": 10356.706794500351, "episode/length": 288.0, "episode/score": 0.056748930008552634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056748930008552634}
{"step": 312320, "time": 10357.687288761139, "episode/length": 63.0, "episode/score": 0.8194677404372896, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.016342734727118113}
{"step": 312576, "time": 10365.8239736557, "episode/length": 288.0, "episode/score": 0.03228677797596902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03228677797596902}
{"step": 312856, "time": 10374.595576047897, "episode/length": 288.0, "episode/score": 0.06873864619080905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06873864619080905}
{"step": 313072, "time": 10381.679273366928, "episode/length": 61.0, "episode/score": 0.830623986296871, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.021248968822931147}
{"step": 313096, "time": 10382.221385717392, "episode/length": 288.0, "episode/score": 0.046733106651686285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046733106651686285}
{"step": 313152, "time": 10384.215343236923, "episode/length": 288.0, "episode/score": 0.05954488495632404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05954488495632404}
{"step": 313368, "time": 10390.940197706223, "episode/length": 36.0, "episode/score": 0.9017820122127205, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.014282024351928158}
{"step": 313416, "time": 10392.499962568283, "episode/length": 32.0, "episode/score": 0.9158350999516074, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.01583511561528894}
{"step": 313512, "time": 10395.563341617584, "episode/length": 81.0, "episode/score": 0.786117248544258, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03924225330564468}
{"step": 313568, "time": 10397.578591823578, "episode/length": 58.0, "episode/score": 0.8439828304332764, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.02523280740632572}
{"step": 313776, "time": 10404.360616445541, "episode/length": 288.0, "episode/score": 0.058254313735744745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058254313735744745}
{"step": 313808, "time": 10405.368818759918, "episode/length": 54.0, "episode/score": 0.8483028687252272, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.017052828166129075}
{"step": 313816, "time": 10405.406842470169, "episode/length": 288.0, "episode/score": 0.037150483729703865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037150483729703865}
{"step": 314016, "time": 10411.960644960403, "episode/length": 24.0, "episode/score": 0.9400945830402634, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.015094571934241685}
{"step": 314224, "time": 10418.553364038467, "episode/length": 88.0, "episode/score": 0.770178659434066, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.04517860695403897}
{"step": 314608, "time": 10430.707545757294, "episode/length": 99.0, "episode/score": 0.7240824616956161, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03345745058959437}
{"step": 314608, "time": 10430.716318368912, "episode/length": 288.0, "episode/score": 0.0740710095627719, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0740710095627719}
{"step": 314632, "time": 10431.254775762558, "episode/length": 288.0, "episode/score": 0.054745544336071816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054745544336071816}
{"step": 314688, "time": 10433.37113070488, "episode/length": 57.0, "episode/score": 0.8533427268916967, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.03146773641446998}
{"step": 314880, "time": 10439.462910175323, "episode/length": 23.0, "episode/score": 0.9407682654391465, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.012643218256016553}
{"step": 314968, "time": 10442.02670788765, "episode/length": 44.0, "episode/score": 0.8805130874509359, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.01801304613513821}
{"step": 315096, "time": 10446.098522901535, "episode/length": 26.0, "episode/score": 0.9304613240913113, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.011711336827147534}
{"step": 315280, "time": 10452.199320554733, "episode/length": 83.0, "episode/score": 0.772781722468153, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03215669944120236}
{"step": 315464, "time": 10457.839007616043, "episode/length": 45.0, "episode/score": 0.8754652136003642, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.016090190259092196}
{"step": 315560, "time": 10460.936860084534, "episode/length": 73.0, "episode/score": 0.7978929740595504, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.02601794203951613}
{"step": 315728, "time": 10466.61438202858, "episode/length": 288.0, "episode/score": 0.05436355047015695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05436355047015695}
{"step": 315752, "time": 10467.157252311707, "episode/length": 58.0, "episode/score": 0.8380465317359267, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.019296493574984197}
{"step": 315880, "time": 10471.219659090042, "episode/length": 288.0, "episode/score": 0.030763268304440317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030763268304440317}
{"step": 316072, "time": 10477.265240907669, "episode/length": 63.0, "episode/score": 0.8230411537426789, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01991615004067171}
{"step": 316080, "time": 10477.745000839233, "episode/length": 24.0, "episode/score": 0.9361366246409943, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.011136630851751761}
{"step": 316088, "time": 10477.783680438995, "episode/length": 288.0, "episode/score": 0.05130940731453393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05130940731453393}
{"step": 316328, "time": 10485.347932815552, "episode/length": 288.0, "episode/score": 0.03999623608183356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03999623608183356}
{"step": 316448, "time": 10489.355113506317, "episode/length": 89.0, "episode/score": 0.7480039803178897, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.02612893900209201}
{"step": 316584, "time": 10493.560953140259, "episode/length": 62.0, "episode/score": 0.8256574155982435, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.01940741004523261}
{"step": 316736, "time": 10498.61994934082, "episode/length": 80.0, "episode/score": 0.7848538865997625, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.034853886818041246}
{"step": 316776, "time": 10499.703897953033, "episode/length": 163.0, "episode/score": 0.5380668439396459, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.04744184274056806}
{"step": 316944, "time": 10505.349513530731, "episode/length": 288.0, "episode/score": 0.0919077203765255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0919077203765255}
{"step": 316944, "time": 10505.35763335228, "episode/length": 148.0, "episode/score": 0.5798594343972354, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.04235938191720834}
{"step": 317368, "time": 10518.706319332123, "episode/length": 78.0, "episode/score": 0.7849906538044706, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.028740630777519982}
{"step": 317496, "time": 10522.869809150696, "episode/length": 130.0, "episode/score": 0.6071629477959277, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.013412924454655695}
{"step": 317560, "time": 10524.918714284897, "episode/length": 97.0, "episode/score": 0.7327160740121599, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03584109866892504}
{"step": 317776, "time": 10532.021639585495, "episode/length": 50.0, "episode/score": 0.8640963821273999, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.020346358786127894}
{"step": 318000, "time": 10539.198856830597, "episode/length": 54.0, "episode/score": 0.8500023282715574, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0187522869557597}
{"step": 318384, "time": 10551.40267252922, "episode/length": 288.0, "episode/score": 0.048875541494339814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048875541494339814}
{"step": 318512, "time": 10555.57427406311, "episode/length": 63.0, "episode/score": 0.8239160849993823, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.020791061972431635}
{"step": 318640, "time": 10559.612891197205, "episode/length": 288.0, "episode/score": 0.059145157475199994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059145157475199994}
{"step": 318824, "time": 10565.22778582573, "episode/length": 22.0, "episode/score": 0.9375244107814069, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.006274411281992798}
{"step": 318896, "time": 10567.744614839554, "episode/length": 288.0, "episode/score": 0.0520695069243402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0520695069243402}
{"step": 319256, "time": 10578.931651115417, "episode/length": 288.0, "episode/score": 0.07730772322770463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07730772322770463}
{"step": 319256, "time": 10578.940380334854, "episode/length": 288.0, "episode/score": 0.04182735191534448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04182735191534448}
{"step": 319808, "time": 10597.31436252594, "episode/length": 288.0, "episode/score": 0.04847153607943255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04847153607943255}
{"step": 320008, "time": 10603.717342615128, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 320008, "time": 10604.215237140656, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 320008, "time": 10604.242399215698, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 320008, "time": 10604.592810630798, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 320008, "time": 10604.837879657745, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 320008, "time": 10605.006206035614, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 320008, "time": 10606.202508211136, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 320008, "time": 10606.339187145233, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 320032, "time": 10607.320549249649, "episode/length": 150.0, "episode/score": 0.5596158361508969, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.028365821831812355}
{"step": 320088, "time": 10608.887957334518, "episode/length": 288.0, "episode/score": 0.04440900024815164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04440900024815164}
{"step": 320168, "time": 10611.486825466156, "episode/length": 158.0, "episode/score": 0.5403751633245975, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.034125140297646794}
{"step": 320200, "time": 10612.58143901825, "episode/length": 226.0, "episode/score": 0.32463153038906967, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.030881543124905875}
{"step": 320336, "time": 10617.11345410347, "episode/length": 65.0, "episode/score": 0.819623164577024, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.022748165391931252}
{"step": 320440, "time": 10620.213427305222, "episode/length": 147.0, "episode/score": 0.5855299031254617, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.04490491264823504}
{"step": 320688, "time": 10628.282519102097, "episode/length": 74.0, "episode/score": 0.7946088611849973, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02585881986919958}
{"step": 320744, "time": 10629.825908660889, "episode/length": 50.0, "episode/score": 0.8617695487439505, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.018019525402678482}
{"step": 320760, "time": 10630.359141588211, "episode/length": 90.0, "episode/score": 0.7575145292230445, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.038764514903959935}
{"step": 320800, "time": 10631.845034837723, "episode/length": 74.0, "episode/score": 0.7998716216995945, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.031121601600489157}
{"step": 320808, "time": 10631.883758068085, "episode/length": 286.0, "episode/score": 0.15543772311161774, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.04918772129553872}
{"step": 320880, "time": 10634.3788793087, "episode/length": 88.0, "episode/score": 0.7650159951374462, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.04001596311741196}
{"step": 321072, "time": 10640.456918478012, "episode/length": 32.0, "episode/score": 0.9108485113690676, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.010848511869653521}
{"step": 321216, "time": 10645.088019132614, "episode/length": 244.0, "episode/score": 0.2700994533803396, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.03259945694264843}
{"step": 321840, "time": 10664.74702334404, "episode/length": 143.0, "episode/score": 0.6067542267727504, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.05362919577135017}
{"step": 322072, "time": 10671.965395450592, "episode/length": 148.0, "episode/score": 0.5845858320794832, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.04708582636931169}
{"step": 322752, "time": 10693.647689342499, "episode/length": 288.0, "episode/score": 0.06095082388321771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06095082388321771}
{"step": 322936, "time": 10699.213991641998, "episode/length": 136.0, "episode/score": 0.6221043499932648, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.04710433857292173}
{"step": 323056, "time": 10703.347743988037, "episode/length": 288.0, "episode/score": 0.0747074373406349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0747074373406349}
{"step": 323072, "time": 10703.86199760437, "episode/length": 288.0, "episode/score": 0.06672556476519276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06672556476519276}
{"step": 323112, "time": 10704.904171466827, "episode/length": 288.0, "episode/score": 0.03360024397147754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03360024397147754}
{"step": 323384, "time": 10713.50570178032, "episode/length": 288.0, "episode/score": 0.06489519056970039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06489519056970039}
{"step": 323528, "time": 10718.04690027237, "episode/length": 288.0, "episode/score": 0.06997435268885965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06997435268885965}
{"step": 323712, "time": 10724.105301856995, "episode/length": 96.0, "episode/score": 0.7403758951878672, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.04037587847062696}
{"step": 323824, "time": 10727.654495239258, "episode/length": 88.0, "episode/score": 0.767905765517412, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.042905713037384885}
{"step": 323872, "time": 10729.179310321808, "episode/length": 139.0, "episode/score": 0.6213571094801864, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.05573208324017287}
{"step": 324264, "time": 10741.541818380356, "episode/length": 148.0, "episode/score": 0.5948689436170298, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.05736889113700272}
{"step": 324384, "time": 10745.639615058899, "episode/length": 288.0, "episode/score": 0.046237822090688496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046237822090688496}
{"step": 324528, "time": 10750.301796913147, "episode/length": 142.0, "episode/score": 0.5984373083191485, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.04218731784192187}
{"step": 324808, "time": 10758.966367006302, "episode/length": 52.0, "episode/score": 0.8631136999806586, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.025613709503431892}
{"step": 324856, "time": 10760.486315250397, "episode/length": 40.0, "episode/score": 0.8978121089539854, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.022812080315816274}
{"step": 325008, "time": 10765.619345903397, "episode/length": 184.0, "episode/score": 0.5102475938997486, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.08524758314297287}
{"step": 325368, "time": 10776.758008003235, "episode/length": 288.0, "episode/score": 0.06710136819094714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06710136819094714}
{"step": 326024, "time": 10797.688291311264, "episode/length": 288.0, "episode/score": 0.06284197753666376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06284197753666376}
{"step": 326136, "time": 10801.232397794724, "episode/length": 288.0, "episode/score": 0.09665230470091046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09665230470091046}
{"step": 326184, "time": 10802.762250423431, "episode/length": 288.0, "episode/score": 0.07136707117547303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07136707117547303}
{"step": 326472, "time": 10811.84548664093, "episode/length": 41.0, "episode/score": 0.8892774287628527, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.017402412045612436}
{"step": 326576, "time": 10815.383853912354, "episode/length": 288.0, "episode/score": 0.09633273719146018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09633273719146018}
{"step": 326592, "time": 10815.90154004097, "episode/length": 70.0, "episode/score": 0.8117184430200268, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.03046842870094224}
{"step": 326840, "time": 10823.67535853386, "episode/length": 81.0, "episode/score": 0.7868890561594526, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.040014053761296964}
{"step": 327120, "time": 10832.720985412598, "episode/length": 288.0, "episode/score": 0.06730020221016275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06730020221016275}
{"step": 327168, "time": 10834.264503002167, "episode/length": 288.0, "episode/score": 0.07796266994478174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07796266994478174}
{"step": 327320, "time": 10838.956748962402, "episode/length": 288.0, "episode/score": 0.07864015738005037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07864015738005037}
{"step": 327680, "time": 10850.759818553925, "episode/length": 288.0, "episode/score": 0.06363167648964918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06363167648964918}
{"step": 327704, "time": 10851.835820436478, "episode/length": 47.0, "episode/score": 0.8758378669144804, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.02271286211816914}
{"step": 328096, "time": 10864.425805807114, "episode/length": 202.0, "episode/score": 0.4505183900846532, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.08176838528834196}
{"step": 328632, "time": 10881.210939645767, "episode/length": 118.0, "episode/score": 0.6922833099902164, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.06103325751018929}
{"step": 328888, "time": 10889.421129465103, "episode/length": 288.0, "episode/score": 0.09386887564323843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09386887564323843}
{"step": 328904, "time": 10889.931943655014, "episode/length": 288.0, "episode/score": 0.08060259955368565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08060259955368565}
{"step": 329152, "time": 10898.11458683014, "episode/length": 288.0, "episode/score": 0.09057488858593388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09057488858593388}
{"step": 329296, "time": 10902.720139026642, "episode/length": 265.0, "episode/score": 0.25589426805777293, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.08401926887268019}
{"step": 329432, "time": 10906.842407226562, "episode/length": 288.0, "episode/score": 0.08677653763925264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08677653763925264}
{"step": 329776, "time": 10918.126051425934, "episode/length": 108.0, "episode/score": 0.7092203341485401, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.046720311121589475}
{"step": 330016, "time": 10925.718281030655, "episode/length": 288.0, "episode/score": 0.07764285790881331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07764285790881331}
{"step": 330096, "time": 10929.256155490875, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 330096, "time": 10929.322705507278, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 330096, "time": 10929.532074451447, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 330096, "time": 10930.156987190247, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 330096, "time": 10930.305924892426, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 330096, "time": 10931.053187131882, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 330096, "time": 10931.802946329117, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 330096, "time": 10933.041196584702, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 330352, "time": 10941.108554124832, "episode/length": 41.0, "episode/score": 0.8961125831810932, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.024237566463853}
{"step": 330408, "time": 10942.783237457275, "episode/length": 288.0, "episode/score": 0.07058215692359227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07058215692359227}
{"step": 330568, "time": 10947.860402822495, "episode/length": 158.0, "episode/score": 0.5612140642992927, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.05496401711616272}
{"step": 330944, "time": 10960.047125339508, "episode/length": 288.0, "episode/score": 0.17729286045209847, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.07729285954405896}
{"step": 331200, "time": 10968.129811525345, "episode/length": 288.0, "episode/score": 0.06453658139764684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06453658139764684}
{"step": 331464, "time": 10976.396144151688, "episode/length": 288.0, "episode/score": 0.06857797046779979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06857797046779979}
{"step": 331560, "time": 10979.498557329178, "episode/length": 44.0, "episode/score": 0.8717715879402022, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.00927156784109684}
{"step": 331744, "time": 10985.615832805634, "episode/length": 288.0, "episode/score": 0.039219590197944854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039219590197944854}
{"step": 332088, "time": 10996.358383178711, "episode/length": 288.0, "episode/score": 0.05725128964536452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05725128964536452}
{"step": 332120, "time": 10997.38845205307, "episode/length": 69.0, "episode/score": 0.8042062844515385, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.019831243892440398}
{"step": 332664, "time": 11014.76669216156, "episode/length": 288.0, "episode/score": 0.06627557961314778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06627557961314778}
{"step": 332712, "time": 11016.279784202576, "episode/length": 73.0, "episode/score": 0.8046048769015215, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03272982442149441}
{"step": 332720, "time": 11016.761006593704, "episode/length": 288.0, "episode/score": 0.08611858319056864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08611858319056864}
{"step": 332880, "time": 11021.821142435074, "episode/length": 288.0, "episode/score": 0.07152417925647114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07152417925647114}
{"step": 333080, "time": 11027.969195365906, "episode/length": 24.0, "episode/score": 0.9387674180984504, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.013767406992428732}
{"step": 333256, "time": 11033.683154582977, "episode/length": 288.0, "episode/score": 0.06921409917924848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06921409917924848}
{"step": 333264, "time": 11034.166102409363, "episode/length": 67.0, "episode/score": 0.8283470913297606, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03772210085253391}
{"step": 333272, "time": 11034.2024371624, "episode/length": 75.0, "episode/score": 0.8019081287948211, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.03628312960972835}
{"step": 333776, "time": 11050.372697114944, "episode/length": 288.0, "episode/score": 0.06979124031568062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06979124031568062}
{"step": 333792, "time": 11050.887911081314, "episode/length": 66.0, "episode/score": 0.8237004833472383, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.02995047192689526}
{"step": 333896, "time": 11053.96485877037, "episode/length": 101.0, "episode/score": 0.7312740295974436, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.04689902719928796}
{"step": 334056, "time": 11059.027770280838, "episode/length": 288.0, "episode/score": 0.08225497402509063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08225497402509063}
{"step": 334400, "time": 11070.175188541412, "episode/length": 288.0, "episode/score": 0.05418260542774078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05418260542774078}
{"step": 335024, "time": 11089.83991265297, "episode/length": 288.0, "episode/score": 0.05942180917350015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05942180917350015}
{"step": 335576, "time": 11107.217011451721, "episode/length": 288.0, "episode/score": 0.06279053041635052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06279053041635052}
{"step": 335584, "time": 11107.694786787033, "episode/length": 288.0, "episode/score": 0.04393647700010206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04393647700010206}
{"step": 335808, "time": 11114.750097751617, "episode/length": 218.0, "episode/score": 0.3602450105023536, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.041495017626971276}
{"step": 336088, "time": 11123.995247125626, "episode/length": 288.0, "episode/score": 0.04026053911115923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04026053911115923}
{"step": 336104, "time": 11124.505444049835, "episode/length": 288.0, "episode/score": 0.05003573503529424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05003573503529424}
{"step": 336208, "time": 11128.03016090393, "episode/length": 288.0, "episode/score": 0.06843550370683715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06843550370683715}
{"step": 336512, "time": 11137.653193473816, "episode/length": 263.0, "episode/score": 0.2388814519825928, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0607564591072105}
{"step": 337336, "time": 11163.62987112999, "episode/length": 288.0, "episode/score": 0.04352912452691271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04352912452691271}
{"step": 337888, "time": 11181.319278478622, "episode/length": 288.0, "episode/score": 0.04000983193316188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04000983193316188}
{"step": 337896, "time": 11181.406374931335, "episode/length": 288.0, "episode/score": 0.044421469727353724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044421469727353724}
{"step": 338120, "time": 11188.535088062286, "episode/length": 288.0, "episode/score": 0.029993266261385543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029993266261385543}
{"step": 338368, "time": 11196.641249895096, "episode/length": 269.0, "episode/score": 0.19895836400917233, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.03958336780431182}
{"step": 338400, "time": 11197.65359377861, "episode/length": 288.0, "episode/score": 0.03826259335050963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03826259335050963}
{"step": 338416, "time": 11198.16349029541, "episode/length": 288.0, "episode/score": 0.025851049320294806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025851049320294806}
{"step": 338569, "time": 11203.731175661087, "train_stats/mean_log_entropy": 0.23797824806193027, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4230741985103625, "train/action_min": 0.0, "train/action_std": 1.6949968683904935, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0029623845424454833, "train/actor_opt_grad_steps": 20100.0, "train/actor_opt_loss": 11.69789258246865, "train/adv_mag": 0.03788043087628221, "train/adv_max": 0.03561745252016295, "train/adv_mean": 0.006426708323290207, "train/adv_min": -0.013425765568728274, "train/adv_std": 0.0059024825121560785, "train/cont_avg": 0.9962506071891192, "train/cont_loss_mean": 0.023156529222494424, "train/cont_loss_std": 0.3135488201849587, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.200008305410544, "train/cont_pos_acc": 0.9999999867202086, "train/cont_pos_loss": 0.0036670293856817513, "train/cont_pred": 0.996328977105531, "train/cont_rate": 0.9962506071891192, "train/dyn_loss_mean": 1.0000182099910597, "train/dyn_loss_std": 0.0004893741460331267, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4899539003110071, "train/extr_critic_critic_opt_grad_steps": 20100.0, "train/extr_critic_critic_opt_loss": 9518.625743806671, "train/extr_critic_mag": 0.3957404120598432, "train/extr_critic_max": 0.3957404120598432, "train/extr_critic_mean": 0.3891906154588097, "train/extr_critic_min": 0.3770144479880061, "train/extr_critic_std": 0.0036106027751422725, "train/extr_return_normed_mag": 0.055405535846176544, "train/extr_return_normed_max": 0.053874379612621245, "train/extr_return_normed_mean": 0.020924956762546146, "train/extr_return_normed_min": 0.00024010634792901074, "train/extr_return_normed_std": 0.00721498102630088, "train/extr_return_rate": 0.02613173438501671, "train/extr_return_raw_mag": 0.4285667398124161, "train/extr_return_raw_max": 0.4285667398124161, "train/extr_return_raw_mean": 0.3956173360347748, "train/extr_return_raw_min": 0.3749324665477239, "train/extr_return_raw_std": 0.007214981017253058, "train/extr_reward_mag": 0.028619373400594287, "train/extr_reward_max": 0.028619373400594287, "train/extr_reward_mean": 0.0020381776526102245, "train/extr_reward_min": 1.2661508945603444e-05, "train/extr_reward_std": 0.004516213943209461, "train/image_loss_mean": 0.15850936385942865, "train/image_loss_std": 0.10962662668271386, "train/model_loss_mean": 0.7945859985030377, "train/model_loss_std": 0.39253109643341966, "train/model_opt_grad_norm": 31.9012634297109, "train/model_opt_grad_steps": 20079.818652849743, "train/model_opt_loss": 2551.518043004169, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3212.435233160622, "train/policy_entropy_mag": 1.6428518943836035, "train/policy_entropy_max": 1.6428518943836035, "train/policy_entropy_mean": 0.29586348910405846, "train/policy_entropy_min": 0.06480177750550403, "train/policy_entropy_std": 0.30968351291560137, "train/policy_logprob_mag": 6.550039570566286, "train/policy_logprob_max": -0.008626163121640992, "train/policy_logprob_mean": -0.2961530873040461, "train/policy_logprob_min": -6.550039570566286, "train/policy_logprob_std": 0.8276347128838455, "train/policy_randomness_mag": 0.8442589143397277, "train/policy_randomness_max": 0.8442589143397277, "train/policy_randomness_mean": 0.15204376615390877, "train/policy_randomness_min": 0.033301527964173204, "train/policy_randomness_std": 0.15914585441350937, "train/post_ent_mag": 50.96641176846361, "train/post_ent_max": 50.96641176846361, "train/post_ent_mean": 50.20819919961722, "train/post_ent_min": 49.63565429134072, "train/post_ent_std": 0.22199065296143447, "train/prior_ent_mag": 56.63584571798848, "train/prior_ent_max": 56.63584571798848, "train/prior_ent_mean": 52.537558975615035, "train/prior_ent_min": 50.00764309186392, "train/prior_ent_std": 1.0139004992697522, "train/rep_loss_mean": 1.0000182099910597, "train/rep_loss_std": 0.0004893741460331267, "train/reward_avg": 0.00052679705489644, "train/reward_loss_mean": 0.012909154431807563, "train/reward_loss_std": 0.09343977606918065, "train/reward_max_data": 0.2611657391287811, "train/reward_max_pred": 0.01584431791552608, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009809095214647024, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.639464984705419, "train/reward_pred": 0.00044604382475287957, "train/reward_rate": 0.0005414102979274611, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.026205293834209442, "report/cont_loss_std": 0.3822833299636841, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.074631690979004, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0024859756231307983, "report/cont_pred": 0.9975190162658691, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13498112559318542, "report/image_loss_std": 0.10265456885099411, "report/model_loss_mean": 0.770972490310669, "report/model_loss_std": 0.3976314961910248, "report/post_ent_mag": 47.128047943115234, "report/post_ent_max": 47.128047943115234, "report/post_ent_mean": 46.45526123046875, "report/post_ent_min": 45.948631286621094, "report/post_ent_std": 0.1932397186756134, "report/prior_ent_mag": 52.13307189941406, "report/prior_ent_max": 52.13307189941406, "report/prior_ent_mean": 48.300994873046875, "report/prior_ent_min": 45.58580780029297, "report/prior_ent_std": 1.105698585510254, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002125391038134694, "report/reward_loss_mean": 0.009786007925868034, "report/reward_loss_std": 0.014891340397298336, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.011823177337646484, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009786007925868034, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00042240892071276903, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.012869797646999359, "eval/cont_loss_std": 0.24097345769405365, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.434661865234375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022596365306526423, "eval/cont_pred": 0.9977471828460693, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21355164051055908, "eval/image_loss_std": 0.1303592175245285, "eval/model_loss_mean": 0.8328069448471069, "eval/model_loss_std": 0.4178086817264557, "eval/post_ent_mag": 47.085906982421875, "eval/post_ent_max": 47.085906982421875, "eval/post_ent_mean": 46.40043640136719, "eval/post_ent_min": 45.94867706298828, "eval/post_ent_std": 0.1914472132921219, "eval/prior_ent_mag": 52.255157470703125, "eval/prior_ent_max": 52.255157470703125, "eval/prior_ent_mean": 48.14802169799805, "eval/prior_ent_min": 45.542083740234375, "eval/prior_ent_std": 1.0604370832443237, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005157470586709678, "eval/reward_loss_mean": 0.006385489366948605, "eval/reward_loss_std": 0.16722984611988068, "eval/reward_max_data": 0.528124988079071, "eval/reward_max_pred": 0.008504033088684082, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011572865769267082, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.354836940765381, "eval/reward_pred": 0.00022213580086827278, "eval/reward_rate": 0.0009765625, "replay/size": 338065.0, "replay/inserts": 30832.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.3455818153504083e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0089253785391205e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78016.0, "eval_replay/inserts": 5288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.228297532235981e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0585718154907, "timer/env.step_count": 3854.0, "timer/env.step_total": 38.33516526222229, "timer/env.step_frac": 0.03833292003350287, "timer/env.step_avg": 0.009946851391339462, "timer/env.step_min": 0.00847935676574707, "timer/env.step_max": 0.047720909118652344, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 16.253416538238525, "timer/replay._sample_frac": 0.016252464601880595, "timer/replay._sample_avg": 0.0005271606298079439, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.011513471603393555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4515.0, "timer/agent.policy_total": 49.05881857872009, "timer/agent.policy_frac": 0.049055945282944255, "timer/agent.policy_avg": 0.010865740548996698, "timer/agent.policy_min": 0.00927877426147461, "timer/agent.policy_max": 0.09437394142150879, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.2328932285308838, "timer/dataset_train_frac": 0.00023287958835060336, "timer/dataset_train_avg": 0.00012085792866158993, "timer/dataset_train_min": 0.00010466575622558594, "timer/dataset_train_max": 0.00043582916259765625, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 863.1841063499451, "timer/agent.train_frac": 0.8631335510508491, "timer/agent.train_avg": 0.44794193375710695, "timer/agent.train_min": 0.4358794689178467, "timer/agent.train_max": 0.7378571033477783, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783971309661865, "timer/agent.report_frac": 0.0004783691120188209, "timer/agent.report_avg": 0.23919856548309326, "timer/agent.report_min": 0.23336267471313477, "timer/agent.report_max": 0.24503445625305176, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1231004605665335e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 30.829693931096678}
{"step": 338824, "time": 11211.602361917496, "episode/length": 288.0, "episode/score": 0.046598447379892605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046598447379892605}
{"step": 338976, "time": 11216.609097719193, "episode/length": 204.0, "episode/score": 0.40216649331432563, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.03966648785444704}
{"step": 339024, "time": 11218.130388736725, "episode/length": 81.0, "episode/score": 0.770292690338465, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.023417703074301244}
{"step": 339320, "time": 11227.302718877792, "episode/length": 178.0, "episode/score": 0.48322126547816424, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.03947127225353597}
{"step": 339504, "time": 11233.318783044815, "episode/length": 137.0, "episode/score": 0.5905325153214562, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.01865751052514497}
{"step": 339688, "time": 11238.923409938812, "episode/length": 195.0, "episode/score": 0.43574322544395727, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.045118226258864524}
{"step": 339904, "time": 11246.126725196838, "episode/length": 109.0, "episode/score": 0.680492125795638, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.021117090533437022}
{"step": 340016, "time": 11249.687868833542, "episode/length": 40.0, "episode/score": 0.8889384444829034, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.013938430163818794}
{"step": 340080, "time": 11252.39627456665, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 340080, "time": 11252.544292449951, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 340080, "time": 11252.835410118103, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 340080, "time": 11253.62310743332, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 340080, "time": 11255.75387954712, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 340080, "time": 11257.673247814178, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11257.682520627975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11257.69043803215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340160, "time": 11260.248027086258, "episode/length": 81.0, "episode/score": 0.773528091596404, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.02665308017606094}
{"step": 340208, "time": 11261.783128738403, "episode/length": 288.0, "episode/score": 0.05372414353945487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05372414353945487}
{"step": 340384, "time": 11268.537249565125, "episode/length": 194.0, "episode/score": 0.4298798452986716, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.036129819058658086}
{"step": 340728, "time": 11279.30875492096, "episode/length": 288.0, "episode/score": 0.05968459710931029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05968459710931029}
{"step": 341288, "time": 11297.064378023148, "episode/length": 288.0, "episode/score": 0.07438934935112229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07438934935112229}
{"step": 341416, "time": 11301.12045121193, "episode/length": 128.0, "episode/score": 0.6520007431467434, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.05200069066671631}
{"step": 341480, "time": 11303.264437198639, "episode/length": 164.0, "episode/score": 0.5613599869830068, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.07385997587698512}
{"step": 341632, "time": 11308.293491363525, "episode/length": 288.0, "episode/score": 0.0985518032695154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0985518032695154}
{"step": 342216, "time": 11326.575490236282, "episode/length": 288.0, "episode/score": 0.09738921212198193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09738921212198193}
{"step": 342328, "time": 11330.115590572357, "episode/length": 288.0, "episode/score": 0.10504064696652904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10504064696652904}
{"step": 342520, "time": 11336.376762866974, "episode/length": 288.0, "episode/score": 0.1114181430006056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1114181430006056}
{"step": 342584, "time": 11338.419449567795, "episode/length": 137.0, "episode/score": 0.6258753197694205, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0540003149731092}
{"step": 343040, "time": 11353.043853998184, "episode/length": 288.0, "episode/score": 0.08200170796521888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08200170796521888}
{"step": 343040, "time": 11353.051779985428, "episode/length": 175.0, "episode/score": 0.5156172578911082, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.062492243572023654}
{"step": 343496, "time": 11367.381750583649, "episode/length": 275.0, "episode/score": 0.26216995533104637, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.12154495649519959}
{"step": 343728, "time": 11374.909990310669, "episode/length": 288.0, "episode/score": 0.051408423921202484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051408423921202484}
{"step": 343840, "time": 11378.474387645721, "episode/length": 202.0, "episode/score": 0.43677880528048263, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.06802879972747178}
{"step": 344168, "time": 11389.17519402504, "episode/length": 197.0, "episode/score": 0.44078634690890794, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.05641134176335072}
{"step": 344640, "time": 11404.487425804138, "episode/length": 288.0, "episode/score": 0.0919209847259026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0919209847259026}
{"step": 344832, "time": 11410.510075092316, "episode/length": 288.0, "episode/score": 0.10165303105907242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10165303105907242}
{"step": 344840, "time": 11410.547610759735, "episode/length": 224.0, "episode/score": 0.38109242248117425, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.08109241096769892}
{"step": 344960, "time": 11414.524696826935, "episode/length": 153.0, "episode/score": 0.5943484033359709, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.07247337131593667}
{"step": 345024, "time": 11416.527407884598, "episode/length": 147.0, "episode/score": 0.5765392407291756, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.03591426538594078}
{"step": 345352, "time": 11426.706108808517, "episode/length": 288.0, "episode/score": 0.0782938542743068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0782938542743068}
{"step": 345504, "time": 11431.794948101044, "episode/length": 83.0, "episode/score": 0.760439152659842, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.01981410547671203}
{"step": 345576, "time": 11433.86831521988, "episode/length": 259.0, "episode/score": 0.26192477040035556, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.07129977419549505}
{"step": 345768, "time": 11439.954599380493, "episode/length": 100.0, "episode/score": 0.7217558733739224, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03425584473575327}
{"step": 345776, "time": 11440.441808700562, "episode/length": 141.0, "episode/score": 0.625956514988502, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.06658152772433823}
{"step": 346112, "time": 11451.164647579193, "episode/length": 158.0, "episode/score": 0.5340321214313235, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.027782098404372846}
{"step": 346320, "time": 11457.874017000198, "episode/length": 92.0, "episode/score": 0.7541002901207321, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.04160031477749726}
{"step": 346480, "time": 11462.923572540283, "episode/length": 288.0, "episode/score": 0.07244962959828172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07244962959828172}
{"step": 346728, "time": 11470.52650642395, "episode/length": 171.0, "episode/score": 0.5253438975396421, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.059718910275478265}
{"step": 346784, "time": 11472.509104013443, "episode/length": 125.0, "episode/score": 0.6311207003536765, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.021745686034591927}
{"step": 347336, "time": 11489.804446697235, "episode/length": 288.0, "episode/score": 0.0661534862190365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0661534862190365}
{"step": 347608, "time": 11498.457052230835, "episode/length": 229.0, "episode/score": 0.3504342788392023, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.06605927337932371}
{"step": 347744, "time": 11503.017987728119, "episode/length": 50.0, "episode/score": 0.8633045326710089, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.01955453348591618}
{"step": 347816, "time": 11505.10630106926, "episode/length": 288.0, "episode/score": 0.10059291191350894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10059291191350894}
{"step": 347936, "time": 11509.104216575623, "episode/length": 143.0, "episode/score": 0.5916435989740876, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.03851854573736091}
{"step": 348000, "time": 11511.15943813324, "episode/length": 158.0, "episode/score": 0.5433146637294612, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.03706461654633131}
{"step": 348424, "time": 11524.487652301788, "episode/length": 288.0, "episode/score": 0.08138631568772325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08138631568772325}
{"step": 348472, "time": 11526.01959657669, "episode/length": 268.0, "episode/score": 0.23980555152161287, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.07730556394312771}
{"step": 348792, "time": 11536.142208099365, "episode/length": 288.0, "episode/score": 0.08999176654674557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08999176654674557}
{"step": 349016, "time": 11543.39055466652, "episode/length": 175.0, "episode/score": 0.5120475720359536, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.05892255771686905}
{"step": 349576, "time": 11561.13016819954, "episode/length": 97.0, "episode/score": 0.7506375186737841, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.05376251917437003}
{"step": 349808, "time": 11568.719697475433, "episode/length": 166.0, "episode/score": 0.5657497730788918, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.08449979146087117}
{"step": 349928, "time": 11572.409544706345, "episode/length": 272.0, "episode/score": 0.23633067178582223, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.08633066623281138}
{"step": 350064, "time": 11577.658564329147, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 350064, "time": 11578.093976736069, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 350064, "time": 11578.613229513168, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 350064, "time": 11579.549532175064, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 350064, "time": 11583.81155204773, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11583.819585323334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11583.826707363129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11583.83543086052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350128, "time": 11585.899345874786, "episode/length": 288.0, "episode/score": 0.10102394322098007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10102394322098007}
{"step": 350248, "time": 11589.497189760208, "episode/length": 288.0, "episode/score": 0.07494444881763229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07494444881763229}
{"step": 350312, "time": 11591.509243011475, "episode/length": 288.0, "episode/score": 0.07605702402997849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07605702402997849}
{"step": 350656, "time": 11602.647051334381, "episode/length": 134.0, "episode/score": 0.6609412536108721, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.07969121305177396}
{"step": 350736, "time": 11605.17702293396, "episode/length": 288.0, "episode/score": 0.09050048475398853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09050048475398853}
{"step": 350768, "time": 11606.194599151611, "episode/length": 104.0, "episode/score": 0.7284685792095615, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.05346856810353984}
{"step": 351328, "time": 11623.836170911789, "episode/length": 288.0, "episode/score": 0.0825773842475428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0825773842475428}
{"step": 352064, "time": 11647.231822490692, "episode/length": 281.0, "episode/score": 0.22620504609392356, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.10433004427784454}
{"step": 352440, "time": 11659.366175889969, "episode/length": 288.0, "episode/score": 0.07464339214220672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07464339214220672}
{"step": 352552, "time": 11663.002013921738, "episode/length": 13.0, "episode/score": 0.9695426370440146, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.01016759888307206}
{"step": 352560, "time": 11663.479959249496, "episode/length": 288.0, "episode/score": 0.09125980339126727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09125980339126727}
{"step": 352624, "time": 11665.528655290604, "episode/length": 288.0, "episode/score": 0.07968609626846046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07968609626846046}
{"step": 352968, "time": 11676.13438129425, "episode/length": 288.0, "episode/score": 0.07656855563595855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07656855563595855}
{"step": 352992, "time": 11677.114017009735, "episode/length": 115.0, "episode/score": 0.6853726548858958, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.04474762624772666}
{"step": 353048, "time": 11678.662867069244, "episode/length": 288.0, "episode/score": 0.055152241927316936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055152241927316936}
{"step": 353080, "time": 11679.689160346985, "episode/length": 288.0, "episode/score": 0.06757636668430678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06757636668430678}
{"step": 353360, "time": 11688.705971479416, "episode/length": 100.0, "episode/score": 0.7321252592694236, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04462523063125445}
{"step": 353560, "time": 11694.940433502197, "episode/length": 59.0, "episode/score": 0.8483258502258195, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03270081496361854}
{"step": 353640, "time": 11697.47337937355, "episode/length": 288.0, "episode/score": 0.10094373264928436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10094373264928436}
{"step": 354240, "time": 11716.60552072525, "episode/length": 109.0, "episode/score": 0.6927025075850679, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03332746626927019}
{"step": 354272, "time": 11717.617511749268, "episode/length": 205.0, "episode/score": 0.41368638853350603, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.05431137421442145}
{"step": 354872, "time": 11736.556401491165, "episode/length": 288.0, "episode/score": 0.07339894747167364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07339894747167364}
{"step": 355080, "time": 11743.15935587883, "episode/length": 260.0, "episode/score": 0.24598559608921278, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.058485596671289386}
{"step": 355280, "time": 11749.74221086502, "episode/length": 288.0, "episode/score": 0.06020365083566048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06020365083566048}
{"step": 355360, "time": 11752.419854164124, "episode/length": 288.0, "episode/score": 0.07131279131715473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07131279131715473}
{"step": 355552, "time": 11758.574231624603, "episode/length": 159.0, "episode/score": 0.5400414951011498, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.03691645983894887}
{"step": 355576, "time": 11759.120158910751, "episode/length": 166.0, "episode/score": 0.514653801795248, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.03340381412363058}
{"step": 355672, "time": 11762.189441680908, "episode/length": 38.0, "episode/score": 0.893178280816187, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.011928249814786795}
{"step": 355872, "time": 11768.784291505814, "episode/length": 288.0, "episode/score": 0.031080092667366443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031080092667366443}
{"step": 355872, "time": 11768.79269862175, "episode/length": 39.0, "episode/score": 0.8916198112697202, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.013494792189248983}
{"step": 355952, "time": 11771.34642624855, "episode/length": 288.0, "episode/score": 0.15731543642192491, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.05731543574671605}
{"step": 357184, "time": 11810.512734651566, "episode/length": 288.0, "episode/score": 0.03517313049752602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03517313049752602}
{"step": 357208, "time": 11811.050814151764, "episode/length": 240.0, "episode/score": 0.2865648205906268, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.036564821405534076}
{"step": 357392, "time": 11817.210599422455, "episode/length": 288.0, "episode/score": 0.05289513313033467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05289513313033467}
{"step": 357888, "time": 11832.840759038925, "episode/length": 288.0, "episode/score": 0.05091619035692929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05091619035692929}
{"step": 357984, "time": 11835.865846157074, "episode/length": 288.0, "episode/score": 0.03134807047706545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03134807047706545}
{"step": 358112, "time": 11839.945959568024, "episode/length": 279.0, "episode/score": 0.19446449203240945, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.06633949617679491}
{"step": 358184, "time": 11842.095540761948, "episode/length": 288.0, "episode/score": 0.04881156899335792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04881156899335792}
{"step": 358264, "time": 11844.658264398575, "episode/length": 288.0, "episode/score": 0.062484498342087136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062484498342087136}
{"step": 358560, "time": 11854.260171175003, "episode/length": 71.0, "episode/score": 0.80025011008604, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.022125098665696896}
{"step": 359128, "time": 11872.13448190689, "episode/length": 242.0, "episode/score": 0.2939239666696949, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.05017396129130702}
{"step": 359352, "time": 11879.286542415619, "episode/length": 135.0, "episode/score": 0.6014601106376176, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.02333510245944126}
{"step": 359520, "time": 11884.828373908997, "episode/length": 288.0, "episode/score": 0.08683810003276449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08683810003276449}
{"step": 359704, "time": 11890.425888061523, "episode/length": 288.0, "episode/score": 0.08958598338335833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08958598338335833}
{"step": 360048, "time": 11902.382754325867, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 360048, "time": 11905.814800024033, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 360048, "time": 11907.555023431778, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11907.564802408218, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11907.57205915451, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11907.579168081284, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11907.586284160614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11907.593187570572, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360200, "time": 11912.18139076233, "episode/length": 288.0, "episode/score": 0.0767742157054272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0767742157054272}
{"step": 360424, "time": 11919.234008550644, "episode/length": 288.0, "episode/score": 0.054567147789953196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054567147789953196}
{"step": 360496, "time": 11922.235748767853, "episode/length": 288.0, "episode/score": 0.05423865870636746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05423865870636746}
{"step": 360872, "time": 11933.997983455658, "episode/length": 288.0, "episode/score": 0.06388852246868737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06388852246868737}
{"step": 361440, "time": 11952.285697937012, "episode/length": 288.0, "episode/score": 0.016271216403652033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016271216403652033}
{"step": 361664, "time": 11959.335568666458, "episode/length": 288.0, "episode/score": 0.05283154361762854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05283154361762854}
{"step": 361832, "time": 11964.55501627922, "episode/length": 288.0, "episode/score": 0.04044798199106481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04044798199106481}
{"step": 362016, "time": 11970.57841706276, "episode/length": 288.0, "episode/score": 0.03113470640982996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03113470640982996}
{"step": 362512, "time": 11986.258424520493, "episode/length": 288.0, "episode/score": 0.03731297472859296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03731297472859296}
{"step": 362736, "time": 11993.445681095123, "episode/length": 288.0, "episode/score": 0.03256798196326827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03256798196326827}
{"step": 362808, "time": 11995.501124620438, "episode/length": 288.0, "episode/score": 0.05317755018626258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05317755018626258}
{"step": 363040, "time": 12003.028557300568, "episode/length": 37.0, "episode/score": 0.9035407170257486, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.01916572654852189}
{"step": 363184, "time": 12007.58569741249, "episode/length": 288.0, "episode/score": 0.06157126526471757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06157126526471757}
{"step": 363704, "time": 12023.871196746826, "episode/length": 282.0, "episode/score": 0.194172222983525, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.07542222563779433}
{"step": 363792, "time": 12026.885462999344, "episode/length": 93.0, "episode/score": 0.7479817946824028, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03860677165545212}
{"step": 363976, "time": 12032.493431806564, "episode/length": 288.0, "episode/score": 0.06196768279914977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06196768279914977}
{"step": 363984, "time": 12032.972549438477, "episode/length": 99.0, "episode/score": 0.7185142859402731, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.027889259700259572}
{"step": 364144, "time": 12038.04019021988, "episode/length": 288.0, "episode/score": 0.0792500339837261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0792500339837261}
{"step": 364328, "time": 12043.670935630798, "episode/length": 288.0, "episode/score": 0.08436079257364781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08436079257364781}
{"step": 364824, "time": 12059.492329597473, "episode/length": 288.0, "episode/score": 0.07991083448843028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07991083448843028}
{"step": 365120, "time": 12069.113552331924, "episode/length": 288.0, "episode/score": 0.1041454497726022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1041454497726022}
{"step": 366016, "time": 12097.445243120193, "episode/length": 288.0, "episode/score": 0.05195682568955817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05195682568955817}
{"step": 366104, "time": 12100.016723155975, "episode/length": 288.0, "episode/score": 0.05685571740553996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05685571740553996}
{"step": 366288, "time": 12106.061536073685, "episode/length": 288.0, "episode/score": 0.061336437703062074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061336437703062074}
{"step": 366296, "time": 12106.103452205658, "episode/length": 288.0, "episode/score": 0.07641969021887007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07641969021887007}
{"step": 366456, "time": 12111.219541072845, "episode/length": 288.0, "episode/score": 0.0755915937776308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0755915937776308}
{"step": 366640, "time": 12117.457856178284, "episode/length": 288.0, "episode/score": 0.06495435190953458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06495435190953458}
{"step": 367136, "time": 12133.100231647491, "episode/length": 288.0, "episode/score": 0.05810616230252208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05810616230252208}
{"step": 367432, "time": 12142.365679740906, "episode/length": 288.0, "episode/score": 0.0558800096524692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0558800096524692}
{"step": 368328, "time": 12170.665957450867, "episode/length": 288.0, "episode/score": 0.03760238359154755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03760238359154755}
{"step": 368416, "time": 12173.812029123306, "episode/length": 288.0, "episode/score": 0.0746858440901974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0746858440901974}
{"step": 368600, "time": 12179.471239566803, "episode/length": 288.0, "episode/score": 0.0562631175590127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0562631175590127}
{"step": 368608, "time": 12179.957860946655, "episode/length": 288.0, "episode/score": 0.07185995627185093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07185995627185093}
{"step": 368768, "time": 12185.519942760468, "episode/length": 288.0, "episode/score": 0.08777118262605654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08777118262605654}
{"step": 368952, "time": 12191.11308503151, "episode/length": 288.0, "episode/score": 0.06436831793530473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06436831793530473}
{"step": 369321, "time": 12203.897015094757, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.203472137451172, "train/action_min": 0.0, "train/action_std": 1.699105119953553, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009785113979887683, "train/actor_opt_grad_steps": 22025.0, "train/actor_opt_loss": 3.99246201167504, "train/adv_mag": 0.34802180994302034, "train/adv_max": 0.1947320067944626, "train/adv_mean": 0.007374736132836309, "train/adv_min": -0.28014774806797504, "train/adv_std": 0.02648726680248122, "train/cont_avg": 0.9962310791015625, "train/cont_loss_mean": 0.020896375830488978, "train/cont_loss_std": 0.288591494915939, "train/cont_neg_acc": 0.04483282740445847, "train/cont_neg_loss": 4.628288681519792, "train/cont_pos_acc": 0.9999029071380695, "train/cont_pos_loss": 0.0036733970991917886, "train/cont_pred": 0.9961872889349858, "train/cont_rate": 0.9962310791015625, "train/dyn_loss_mean": 1.0000079336265724, "train/dyn_loss_std": 0.000237681468812904, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1133336521646318, "train/extr_critic_critic_opt_grad_steps": 22025.0, "train/extr_critic_critic_opt_loss": 8616.268161773682, "train/extr_critic_mag": 0.5912959420432647, "train/extr_critic_max": 0.5912959420432647, "train/extr_critic_mean": 0.581226730098327, "train/extr_critic_min": 0.5659310389310122, "train/extr_critic_std": 0.005276135464858574, "train/extr_return_normed_mag": 0.3533906973898411, "train/extr_return_normed_max": 0.2235373950873812, "train/extr_return_normed_mean": 0.030169007240090195, "train/extr_return_normed_min": -0.2554733397749563, "train/extr_return_normed_std": 0.027483102820648735, "train/extr_return_rate": 0.9029761714458573, "train/extr_return_raw_mag": 0.7819698277550439, "train/extr_return_raw_max": 0.7819698277550439, "train/extr_return_raw_mean": 0.5886014713905752, "train/extr_return_raw_min": 0.3029590928927064, "train/extr_return_raw_std": 0.02748310265693969, "train/extr_reward_mag": 0.17728551725546518, "train/extr_reward_max": 0.17728551725546518, "train/extr_reward_mean": 0.0027796963627224613, "train/extr_reward_min": 1.2228886286417643e-05, "train/extr_reward_std": 0.010915293346746088, "train/image_loss_mean": 0.14145274355541915, "train/image_loss_std": 0.10934800549875945, "train/model_loss_mean": 0.7761807565887769, "train/model_loss_std": 0.38021312122388434, "train/model_opt_grad_norm": 30.144772544503212, "train/model_opt_grad_steps": 22003.604166666668, "train/model_opt_loss": 2486.6047732035317, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3203.125, "train/policy_entropy_mag": 1.5109044096122186, "train/policy_entropy_max": 1.5109044096122186, "train/policy_entropy_mean": 0.22494969171627113, "train/policy_entropy_min": 0.0646950794228663, "train/policy_entropy_std": 0.24820928749007484, "train/policy_logprob_mag": 6.55103715757529, "train/policy_logprob_max": -0.008609634673727365, "train/policy_logprob_mean": -0.22492941620294005, "train/policy_logprob_min": -6.55103715757529, "train/policy_logprob_std": 0.7496364771698912, "train/policy_randomness_mag": 0.7764513172830144, "train/policy_randomness_max": 0.7764513172830144, "train/policy_randomness_mean": 0.1156012795205849, "train/policy_randomness_min": 0.033246696014733366, "train/policy_randomness_std": 0.12755434964007387, "train/post_ent_mag": 44.3310691912969, "train/post_ent_max": 44.3310691912969, "train/post_ent_mean": 43.56439731518427, "train/post_ent_min": 43.00744664669037, "train/post_ent_std": 0.2344300796588262, "train/prior_ent_mag": 47.77511018514633, "train/prior_ent_max": 47.77511018514633, "train/prior_ent_mean": 43.61285767952601, "train/prior_ent_min": 40.796443462371826, "train/prior_ent_std": 1.1122759841382504, "train/rep_loss_mean": 1.0000079336265724, "train/rep_loss_std": 0.000237681468812904, "train/reward_avg": 0.000604881190611195, "train/reward_loss_mean": 0.01382685319307105, "train/reward_loss_std": 0.10656695661115616, "train/reward_max_data": 0.3094973407132784, "train/reward_max_pred": 0.04480735460917155, "train/reward_neg_acc": 0.9999338584020734, "train/reward_neg_loss": 0.010156888791243546, "train/reward_pos_acc": 0.09, "train/reward_pos_loss": 5.223033691644669, "train/reward_pred": 0.0005512522329809144, "train/reward_rate": 0.0007069905598958334, "train_stats/mean_log_entropy": 0.22149371411791421, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.025605708360671997, "report/cont_loss_std": 0.3833906054496765, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 4.90127420425415, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001681918860413134, "report/cont_pred": 0.9975847601890564, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1175643801689148, "report/image_loss_std": 0.10236185044050217, "report/model_loss_mean": 0.7532424926757812, "report/model_loss_std": 0.39989665150642395, "report/post_ent_mag": 42.02578353881836, "report/post_ent_max": 42.02578353881836, "report/post_ent_mean": 41.16996765136719, "report/post_ent_min": 40.68788146972656, "report/post_ent_std": 0.23309332132339478, "report/prior_ent_mag": 46.259193420410156, "report/prior_ent_max": 46.259193420410156, "report/prior_ent_mean": 40.90111541748047, "report/prior_ent_min": 38.21604919433594, "report/prior_ent_std": 1.1463148593902588, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00022178968356456608, "report/reward_loss_mean": 0.010072396136820316, "report/reward_loss_std": 0.015706732869148254, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0318453311920166, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010072395205497742, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003812211798503995, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.026766061782836914, "eval/cont_loss_std": 0.4134000241756439, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.497663974761963, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0013899938203394413, "eval/cont_pred": 0.9986170530319214, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18850140273571014, "eval/image_loss_std": 0.14197957515716553, "eval/model_loss_mean": 0.8164646625518799, "eval/model_loss_std": 0.44256219267845154, "eval/post_ent_mag": 42.017662048339844, "eval/post_ent_max": 42.017662048339844, "eval/post_ent_mean": 41.1218147277832, "eval/post_ent_min": 40.69569778442383, "eval/post_ent_std": 0.23281903564929962, "eval/prior_ent_mag": 44.96205139160156, "eval/prior_ent_max": 44.96205139160156, "eval/prior_ent_mean": 40.610809326171875, "eval/prior_ent_min": 37.76979064941406, "eval/prior_ent_std": 1.1396551132202148, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011971737258136272, "eval/reward_loss_std": 0.0016838300507515669, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00754094123840332, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011971737258136272, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020032725296914577, "eval/reward_rate": 0.0, "replay/size": 368817.0, "replay/inserts": 30752.0, "replay/samples": 30752.0, "replay/insert_wait_avg": 1.332560761538058e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.978893644231664e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84952.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.249738218050102e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4156103134155273e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.124630689621, "timer/env.step_count": 3844.0, "timer/env.step_total": 37.984713077545166, "timer/env.step_frac": 0.03797997960649502, "timer/env.step_avg": 0.009881559073242759, "timer/env.step_min": 0.008522272109985352, "timer/env.step_max": 0.04950070381164551, "timer/replay._sample_count": 30752.0, "timer/replay._sample_total": 16.154961585998535, "timer/replay._sample_frac": 0.01615294843289593, "timer/replay._sample_avg": 0.0005253304365894425, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.008842706680297852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4711.0, "timer/agent.policy_total": 50.03161144256592, "timer/agent.policy_frac": 0.050025376745363594, "timer/agent.policy_avg": 0.010620167998846512, "timer/agent.policy_min": 0.009193181991577148, "timer/agent.policy_max": 0.1018381118774414, "timer/dataset_train_count": 1922.0, "timer/dataset_train_total": 0.23023557662963867, "timer/dataset_train_frac": 0.00023020688578670757, "timer/dataset_train_avg": 0.00011978958201333958, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.0011010169982910156, "timer/agent.train_count": 1922.0, "timer/agent.train_total": 860.9531626701355, "timer/agent.train_frac": 0.8608458748550949, "timer/agent.train_avg": 0.4479464946254607, "timer/agent.train_min": 0.43562984466552734, "timer/agent.train_max": 1.5846142768859863, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4689304828643799, "timer/agent.report_frac": 0.0004688720470178161, "timer/agent.report_avg": 0.23446524143218994, "timer/agent.report_min": 0.22370409965515137, "timer/agent.report_max": 0.24522638320922852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908344196096248e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 30.74737434369883}
{"step": 369448, "time": 12207.709080219269, "episode/length": 288.0, "episode/score": 0.10082021648565842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10082021648565842}
{"step": 369664, "time": 12214.754317522049, "episode/length": 132.0, "episode/score": 0.6544586629038349, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.06695865810752366}
{"step": 369744, "time": 12217.294084072113, "episode/length": 288.0, "episode/score": 0.09289143821979451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09289143821979451}
{"step": 370032, "time": 12226.56740784645, "eval_episode/length": 7.0, "eval_episode/score": 0.9781249761581421, "eval_episode/reward_rate": 0.125}
{"step": 370032, "time": 12227.472317695618, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 370032, "time": 12231.282352685928, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 370032, "time": 12232.639145612717, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12232.648452281952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12232.656270503998, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12232.664461374283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12232.67273759842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370448, "time": 12245.824326753616, "episode/length": 209.0, "episode/score": 0.4426292962984917, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.09575428554171594}
{"step": 370640, "time": 12251.881547689438, "episode/length": 288.0, "episode/score": 0.07854461414197544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07854461414197544}
{"step": 370728, "time": 12254.441595077515, "episode/length": 288.0, "episode/score": 0.08413566701369746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08413566701369746}
{"step": 370920, "time": 12260.512302160263, "episode/length": 288.0, "episode/score": 0.11209608117269454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11209608117269454}
{"step": 371264, "time": 12271.716578722, "episode/length": 288.0, "episode/score": 0.10699925416929545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10699925416929545}
{"step": 371760, "time": 12287.419002056122, "episode/length": 288.0, "episode/score": 0.08206253361390736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08206253361390736}
{"step": 371976, "time": 12294.135313510895, "episode/length": 288.0, "episode/score": 0.08520625054916309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08520625054916309}
{"step": 372056, "time": 12296.669820308685, "episode/length": 288.0, "episode/score": 0.08978548950813092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08978548950813092}
{"step": 372432, "time": 12308.759308099747, "episode/length": 56.0, "episode/score": 0.8648153872711646, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.03981537055392437}
{"step": 372760, "time": 12318.891022920609, "episode/length": 288.0, "episode/score": 0.10766481023802044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10766481023802044}
{"step": 372952, "time": 12325.057605028152, "episode/length": 288.0, "episode/score": 0.07219688479585784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07219688479585784}
{"step": 373040, "time": 12328.058494091034, "episode/length": 288.0, "episode/score": 0.0647483608222501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0647483608222501}
{"step": 373232, "time": 12334.128203392029, "episode/length": 288.0, "episode/score": 0.10096363575075884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10096363575075884}
{"step": 373328, "time": 12337.15853214264, "episode/length": 111.0, "episode/score": 0.7031382398013193, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.05001322308407907}
{"step": 373576, "time": 12344.780825138092, "episode/length": 288.0, "episode/score": 0.09974059830551596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09974059830551596}
{"step": 373736, "time": 12349.82529592514, "episode/length": 209.0, "episode/score": 0.4501909533473736, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.10331594259059784}
{"step": 374072, "time": 12360.514459848404, "episode/length": 288.0, "episode/score": 0.07129593430568093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07129593430568093}
{"step": 374128, "time": 12362.504690170288, "episode/length": 99.0, "episode/score": 0.7451177518469194, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.054492740740897716}
{"step": 375072, "time": 12392.44285273552, "episode/length": 288.0, "episode/score": 0.0910433496915175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0910433496915175}
{"step": 375264, "time": 12398.493086338043, "episode/length": 288.0, "episode/score": 0.08463606450891348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08463606450891348}
{"step": 375352, "time": 12401.059549570084, "episode/length": 288.0, "episode/score": 0.06976824538446635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06976824538446635}
{"step": 375408, "time": 12403.04139328003, "episode/length": 41.0, "episode/score": 0.902806065393861, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.030931078129697198}
{"step": 375544, "time": 12407.128257274628, "episode/length": 288.0, "episode/score": 0.09317303915668163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09317303915668163}
{"step": 375744, "time": 12413.832195997238, "episode/length": 250.0, "episode/score": 0.29955389765314067, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.08080389823521728}
{"step": 375872, "time": 12417.889430761337, "episode/length": 64.0, "episode/score": 0.8309233549425699, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.03092332870255632}
{"step": 375888, "time": 12418.40862607956, "episode/length": 288.0, "episode/score": 0.05959271921869913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05959271921869913}
{"step": 376344, "time": 12432.57673239708, "episode/length": 56.0, "episode/score": 0.8552588850459415, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.030258868328701283}
{"step": 376384, "time": 12434.061444282532, "episode/length": 288.0, "episode/score": 0.07756488581071608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07756488581071608}
{"step": 376440, "time": 12435.624999523163, "episode/length": 288.0, "episode/score": 0.08424101105242698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08424101105242698}
{"step": 376800, "time": 12447.39785695076, "episode/length": 131.0, "episode/score": 0.6423297565083885, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.05170473979114831}
{"step": 376824, "time": 12447.943415641785, "episode/length": 59.0, "episode/score": 0.8534476763779821, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03782266527196043}
{"step": 377576, "time": 12472.3847219944, "episode/length": 288.0, "episode/score": 0.10683271029779462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10683271029779462}
{"step": 377720, "time": 12476.97020149231, "episode/length": 288.0, "episode/score": 0.06649405846519585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06649405846519585}
{"step": 377856, "time": 12481.504093647003, "episode/length": 288.0, "episode/score": 0.09338483511419327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09338483511419327}
{"step": 377952, "time": 12484.556790590286, "episode/length": 188.0, "episode/score": 0.4871140188743084, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.07461402564968012}
{"step": 378160, "time": 12491.151638269424, "episode/length": 72.0, "episode/score": 0.824750756710273, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.04975075191396172}
{"step": 378184, "time": 12491.698272705078, "episode/length": 288.0, "episode/score": 0.06630484666175107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06630484666175107}
{"step": 378392, "time": 12498.293973445892, "episode/length": 250.0, "episode/score": 0.3213254975767086, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.1025754981587852}
{"step": 378504, "time": 12501.950340032578, "episode/length": 80.0, "episode/score": 0.7851309706966276, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0351309473553556}
{"step": 379112, "time": 12521.271754026413, "episode/length": 288.0, "episode/score": 0.08693373096002688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08693373096002688}
{"step": 379136, "time": 12522.262676000595, "episode/length": 288.0, "episode/score": 0.0827235683532308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0827235683532308}
{"step": 379200, "time": 12524.305020570755, "episode/length": 155.0, "episode/score": 0.5757516481849052, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.060126618790036446}
{"step": 379224, "time": 12524.850176095963, "episode/length": 103.0, "episode/score": 0.7245216509452348, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.04639660376210486}
{"step": 379512, "time": 12534.121190786362, "episode/length": 168.0, "episode/score": 0.5448678195843968, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.06986782595231489}
{"step": 379624, "time": 12537.69409584999, "episode/length": 179.0, "episode/score": 0.5280426844656176, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.08741766436651233}
{"step": 379712, "time": 12540.7840924263, "episode/length": 71.0, "episode/score": 0.8130566824061134, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03493166493217359}
{"step": 379840, "time": 12544.884053945541, "episode/length": 90.0, "episode/score": 0.7722225404843357, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0534725333247934}
{"step": 379888, "time": 12546.40640759468, "episode/length": 85.0, "episode/score": 0.7796458578229704, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.04527087796282103}
{"step": 380016, "time": 12551.295837640762, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 380016, "time": 12551.645988225937, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 380016, "time": 12551.713760137558, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 380016, "time": 12552.04825258255, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 380016, "time": 12552.219969511032, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 380016, "time": 12552.807620286942, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 380016, "time": 12553.04129934311, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 380016, "time": 12553.285577774048, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 380032, "time": 12553.800287485123, "episode/length": 288.0, "episode/score": 0.10229262059419852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10229262059419852}
{"step": 380192, "time": 12558.850401878357, "episode/length": 70.0, "episode/score": 0.8107738599838967, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.029523860202175456}
{"step": 380648, "time": 12573.211262702942, "episode/length": 100.0, "episode/score": 0.727262959050563, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03976297415545105}
{"step": 380816, "time": 12578.740482330322, "episode/length": 288.0, "episode/score": 0.09079603777195189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09079603777195189}
{"step": 380984, "time": 12583.816510915756, "episode/length": 158.0, "episode/score": 0.577582444082168, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.07133239160214089}
{"step": 381040, "time": 12585.80608844757, "episode/length": 105.0, "episode/score": 0.7146290509139135, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.04275407402235487}
{"step": 381296, "time": 12594.042908668518, "episode/length": 59.0, "episode/score": 0.8492984181577867, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03367341831494741}
{"step": 381328, "time": 12595.054182052612, "episode/length": 84.0, "episode/score": 0.7938231464189585, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.056323130408941324}
{"step": 381536, "time": 12601.626688718796, "episode/length": 288.0, "episode/score": 0.061429273283692964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061429273283692964}
{"step": 381824, "time": 12610.84440279007, "episode/length": 288.0, "episode/score": 0.07898833817910145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07898833817910145}
{"step": 382112, "time": 12619.960549592972, "episode/length": 101.0, "episode/score": 0.7416070408322639, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.05723205356810013}
{"step": 382200, "time": 12622.635600566864, "episode/length": 288.0, "episode/score": 0.05809270533245581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05809270533245581}
{"step": 382344, "time": 12627.188037633896, "episode/length": 288.0, "episode/score": 0.05420560235143057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05420560235143057}
{"step": 382448, "time": 12630.727272510529, "episode/length": 77.0, "episode/score": 0.7821515571217788, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0227765930417263}
{"step": 382456, "time": 12630.763628721237, "episode/length": 140.0, "episode/score": 0.6158869289357654, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.053386955158316596}
{"step": 382504, "time": 12632.27034664154, "episode/length": 48.0, "episode/score": 0.8708810182298521, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.020881008547007696}
{"step": 382720, "time": 12639.292268276215, "episode/length": 64.0, "episode/score": 0.8256287893907484, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.025628749355519176}
{"step": 383184, "time": 12654.12645149231, "episode/length": 90.0, "episode/score": 0.7600195178328022, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.04126948971850197}
{"step": 383296, "time": 12657.672446489334, "episode/length": 288.0, "episode/score": 0.10826803407667285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10826803407667285}
{"step": 383352, "time": 12659.244096517563, "episode/length": 288.0, "episode/score": 0.05018161663394949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05018161663394949}
{"step": 383848, "time": 12674.900406360626, "episode/length": 288.0, "episode/score": 0.09338683790576852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09338683790576852}
{"step": 384392, "time": 12692.253263950348, "episode/length": 208.0, "episode/score": 0.3979330756497461, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.04793306729112601}
{"step": 384448, "time": 12694.29724574089, "episode/length": 249.0, "episode/score": 0.27670357528978684, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.05482858473106944}
{"step": 384656, "time": 12700.849448919296, "episode/length": 288.0, "episode/score": 0.09921136479698589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09921136479698589}
{"step": 384816, "time": 12705.887255430222, "episode/length": 288.0, "episode/score": 0.057642574184853856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057642574184853856}
{"step": 385496, "time": 12727.751403093338, "episode/length": 288.0, "episode/score": 0.07914673664453176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07914673664453176}
{"step": 385608, "time": 12731.314688444138, "episode/length": 288.0, "episode/score": 0.06169575829147789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06169575829147789}
{"step": 385664, "time": 12733.30637550354, "episode/length": 288.0, "episode/score": 0.056078547928336775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056078547928336775}
{"step": 386160, "time": 12749.119086027145, "episode/length": 288.0, "episode/score": 0.03889722254854178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03889722254854178}
{"step": 386256, "time": 12752.175254583359, "episode/length": 73.0, "episode/score": 0.7928269567544817, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.020951924734447402}
{"step": 386704, "time": 12766.345714330673, "episode/length": 288.0, "episode/score": 0.07945435840571236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07945435840571236}
{"step": 386760, "time": 12767.896867513657, "episode/length": 288.0, "episode/score": 0.06725951071916825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06725951071916825}
{"step": 386968, "time": 12774.598745584488, "episode/length": 288.0, "episode/score": 0.08338143638280826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08338143638280826}
{"step": 387128, "time": 12779.756978273392, "episode/length": 288.0, "episode/score": 0.06965677391048075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06965677391048075}
{"step": 387808, "time": 12801.701256275177, "episode/length": 288.0, "episode/score": 0.0875387176513982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0875387176513982}
{"step": 387920, "time": 12805.265601158142, "episode/length": 288.0, "episode/score": 0.06305845400919452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06305845400919452}
{"step": 388136, "time": 12811.994557380676, "episode/length": 40.0, "episode/score": 0.8900476991571509, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.01504770822299406}
{"step": 388472, "time": 12822.69545340538, "episode/length": 288.0, "episode/score": 0.041445052334097454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041445052334097454}
{"step": 388568, "time": 12825.718606948853, "episode/length": 288.0, "episode/score": 0.031633166806727786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031633166806727786}
{"step": 388576, "time": 12826.195249319077, "episode/length": 81.0, "episode/score": 0.7857191223923792, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.038844126135131773}
{"step": 389016, "time": 12840.007560014725, "episode/length": 288.0, "episode/score": 0.05984312994280572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05984312994280572}
{"step": 389072, "time": 12842.044831991196, "episode/length": 288.0, "episode/score": 0.050732106635337004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050732106635337004}
{"step": 389280, "time": 12848.673572063446, "episode/length": 288.0, "episode/score": 0.04892400306766831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04892400306766831}
{"step": 389440, "time": 12853.741061210632, "episode/length": 288.0, "episode/score": 0.044669967092147544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044669967092147544}
{"step": 389600, "time": 12858.817776441574, "episode/length": 65.0, "episode/score": 0.8179656955527435, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.021090666914574285}
{"step": 389728, "time": 12863.008130788803, "episode/length": 143.0, "episode/score": 0.6041325352808258, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0510074828007987}
{"step": 390000, "time": 12874.224930047989, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 390000, "time": 12876.364649534225, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 390000, "time": 12877.098310470581, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 390000, "time": 12878.225924253464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12878.233800888062, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12878.240449428558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12878.247650384903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12878.2547955513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390072, "time": 12880.328289985657, "episode/length": 131.0, "episode/score": 0.6357744665111227, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.04514944979388247}
{"step": 390128, "time": 12882.321261405945, "episode/length": 248.0, "episode/score": 0.3017325906624251, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.07673259778704278}
{"step": 390504, "time": 12894.14419746399, "episode/length": 152.0, "episode/score": 0.5660064016865363, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.04100640218712215}
{"step": 390784, "time": 12903.255283594131, "episode/length": 288.0, "episode/score": 0.08423955706291508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08423955706291508}
{"step": 390880, "time": 12906.297008275986, "episode/length": 288.0, "episode/score": 0.08351096025342031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08351096025342031}
{"step": 391248, "time": 12917.957557916641, "episode/length": 45.0, "episode/score": 0.8712620788069216, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.011887079621828889}
{"step": 391336, "time": 12920.539469003677, "episode/length": 157.0, "episode/score": 0.5470862049396601, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.037711205440245976}
{"step": 391752, "time": 12933.83430814743, "episode/length": 288.0, "episode/score": 0.08587138713096465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08587138713096465}
{"step": 391912, "time": 12938.932390928268, "episode/length": 288.0, "episode/score": 0.07656842411802245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07656842411802245}
{"step": 392040, "time": 12943.00259423256, "episode/length": 288.0, "episode/score": 0.10625661944004605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10625661944004605}
{"step": 392440, "time": 12955.872657060623, "episode/length": 288.0, "episode/score": 0.07110501232477873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07110501232477873}
{"step": 392496, "time": 12957.858272790909, "episode/length": 72.0, "episode/score": 0.8126815185405576, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.03768151374424633}
{"step": 392696, "time": 12963.970286369324, "episode/length": 117.0, "episode/score": 0.6940623515120024, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.059687376168767514}
{"step": 392816, "time": 12967.990280628204, "episode/length": 288.0, "episode/score": 0.10040639253793415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10040639253793415}
{"step": 393096, "time": 12976.731870651245, "episode/length": 288.0, "episode/score": 0.12009195759810609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12009195759810609}
{"step": 393560, "time": 12992.126357078552, "episode/length": 288.0, "episode/score": 0.23625176272275894, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.13625176239679604}
{"step": 393648, "time": 12995.117710113525, "episode/length": 288.0, "episode/score": 0.1296950658379501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1296950658379501}
{"step": 393704, "time": 12996.67105269432, "episode/length": 157.0, "episode/score": 0.6023156358610322, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.09294063106472095}
{"step": 394072, "time": 13008.288058042526, "episode/length": 171.0, "episode/score": 0.5609824221992312, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.09535743493506743}
{"step": 394352, "time": 13017.476521968842, "episode/length": 288.0, "episode/score": 0.11175229208333803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11175229208333803}
{"step": 394360, "time": 13017.515706300735, "episode/length": 99.0, "episode/score": 0.7191478031259066, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.02852277688589311}
{"step": 394448, "time": 13020.500195264816, "episode/length": 11.0, "episode/score": 0.9739729819445984, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.008347994680434567}
{"step": 394576, "time": 13024.568131685257, "episode/length": 115.0, "episode/score": 0.6934873793409224, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.05286236502183783}
{"step": 394592, "time": 13025.076647996902, "episode/length": 64.0, "episode/score": 0.8306521548697674, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.030652114310669276}
{"step": 394640, "time": 13026.590853452682, "episode/length": 116.0, "episode/score": 0.6887867730340531, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.05128676161371004}
{"step": 394752, "time": 13030.142750740051, "episode/length": 241.0, "episode/score": 0.3439084238398209, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.09703342732063902}
{"step": 394808, "time": 13031.694024801254, "episode/length": 44.0, "episode/score": 0.8815108102637623, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.01901079016465701}
{"step": 394808, "time": 13031.702947378159, "episode/length": 288.0, "episode/score": 0.111096880796822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.111096880796822}
{"step": 395336, "time": 13048.563962459564, "episode/length": 121.0, "episode/score": 0.6787706482466547, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.05689563077271487}
{"step": 395408, "time": 13051.079497098923, "episode/length": 288.0, "episode/score": 0.08248141179774393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08248141179774393}
{"step": 395752, "time": 13061.814899921417, "episode/length": 144.0, "episode/score": 0.5931672686300544, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.043167276848976144}
{"step": 395880, "time": 13065.889492750168, "episode/length": 67.0, "episode/score": 0.824588754583715, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03396377126603056}
{"step": 396032, "time": 13070.954601049423, "episode/length": 181.0, "episode/score": 0.4915815487264581, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.05720655348784476}
{"step": 396080, "time": 13072.5986597538, "episode/length": 158.0, "episode/score": 0.5628051754242733, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.056555137263330835}
{"step": 396952, "time": 13100.037488222122, "episode/length": 288.0, "episode/score": 0.0816836931396665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0816836931396665}
{"step": 397064, "time": 13103.667056798935, "episode/length": 288.0, "episode/score": 0.07718677240416127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07718677240416127}
{"step": 397120, "time": 13105.674744844437, "episode/length": 288.0, "episode/score": 0.05101222309986042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05101222309986042}
{"step": 397568, "time": 13119.87076330185, "episode/length": 226.0, "episode/score": 0.34529186821009716, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.05154187046855441}
{"step": 397720, "time": 13124.475443601608, "episode/length": 288.0, "episode/score": 0.0771744664785956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0771744664785956}
{"step": 398064, "time": 13135.776103496552, "episode/length": 253.0, "episode/score": 0.25753409604556055, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.048159108467075384}
{"step": 398192, "time": 13139.836377620697, "episode/length": 288.0, "episode/score": 0.06293648926362039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06293648926362039}
{"step": 398392, "time": 13145.929594039917, "episode/length": 288.0, "episode/score": 0.05921053973912649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05921053973912649}
{"step": 398912, "time": 13162.953841924667, "episode/length": 244.0, "episode/score": 0.2998976197262664, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.06239761554695633}
{"step": 399296, "time": 13175.376725196838, "episode/length": 271.0, "episode/score": 0.19958750834359762, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.04646250577081901}
{"step": 399376, "time": 13177.918862104416, "episode/length": 288.0, "episode/score": 0.06984360440742421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06984360440742421}
{"step": 399448, "time": 13179.969733715057, "episode/length": 234.0, "episode/score": 0.3323343544749946, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.06358433437588928}
{"step": 399688, "time": 13187.629140138626, "episode/length": 202.0, "episode/score": 0.4445640150015606, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0758140098560034}
{"step": 399912, "time": 13194.932859420776, "episode/length": 214.0, "episode/score": 0.3776850704408048, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.046435048857404126}
{"step": 400024, "time": 13198.523061990738, "episode/length": 71.0, "episode/score": 0.7942204188861979, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.01609543102540556}
{"step": 400032, "time": 13199.008882045746, "episode/length": 288.0, "episode/score": 0.05537014749302216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05537014749302216}
{"step": 400088, "time": 13201.186316013336, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 400088, "time": 13201.494108200073, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 400088, "time": 13202.651781320572, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 400088, "time": 13204.293055534363, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 400088, "time": 13206.492562532425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13206.52284359932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13206.53766655922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13206.546314001083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13206.554758787155, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400089, "time": 13207.579716920853, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.9586925506591797, "train/action_min": 0.0, "train/action_std": 1.633679521580537, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00977832322799562, "train/actor_opt_grad_steps": 23945.0, "train/actor_opt_loss": -4.741677445747579, "train/adv_mag": 0.5686473725363612, "train/adv_max": 0.22766470412413278, "train/adv_mean": 0.0030544670784517316, "train/adv_min": -0.5491806607072552, "train/adv_std": 0.03323614433854042, "train/cont_avg": 0.99603271484375, "train/cont_loss_mean": 0.017497658095332252, "train/cont_loss_std": 0.2544925473727441, "train/cont_neg_acc": 0.21127402217764604, "train/cont_neg_loss": 3.598064015250604, "train/cont_pos_acc": 0.9998620804399252, "train/cont_pos_loss": 0.003247368990438796, "train/cont_pred": 0.9960625863944491, "train/cont_rate": 0.99603271484375, "train/dyn_loss_mean": 1.000012972081701, "train/dyn_loss_std": 0.00036568138894684427, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7211813015552858, "train/extr_critic_critic_opt_grad_steps": 23945.0, "train/extr_critic_critic_opt_loss": 10340.047892252604, "train/extr_critic_mag": 0.6900860344370207, "train/extr_critic_max": 0.6900860344370207, "train/extr_critic_mean": 0.6650833726550142, "train/extr_critic_min": 0.6459007107963165, "train/extr_critic_std": 0.007542689568557155, "train/extr_return_normed_mag": 0.5493911520267526, "train/extr_return_normed_max": 0.264800320379436, "train/extr_return_normed_mean": 0.02370966487039065, "train/extr_return_normed_min": -0.5215447604035338, "train/extr_return_normed_std": 0.034660573195045195, "train/extr_return_rate": 0.9953152568389972, "train/extr_return_raw_mag": 0.9092284701764584, "train/extr_return_raw_max": 0.9092284701764584, "train/extr_return_raw_mean": 0.668137845893701, "train/extr_return_raw_min": 0.12288338939348857, "train/extr_return_raw_std": 0.03466057325567817, "train/extr_reward_mag": 0.27006118185818195, "train/extr_reward_max": 0.27006118185818195, "train/extr_reward_mean": 0.002425077864851725, "train/extr_reward_min": 9.559094905853271e-06, "train/extr_reward_std": 0.011886218616079228, "train/image_loss_mean": 0.1264103218757858, "train/image_loss_std": 0.1075299601846685, "train/model_loss_mean": 0.7582338082914551, "train/model_loss_std": 0.35627063472444814, "train/model_opt_grad_norm": 29.57933370769024, "train/model_opt_grad_steps": 23922.015625, "train/model_opt_loss": 2229.6881198883057, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2955.7291666666665, "train/policy_entropy_mag": 1.435911665360133, "train/policy_entropy_max": 1.435911665360133, "train/policy_entropy_mean": 0.15384364481239268, "train/policy_entropy_min": 0.0646874171992143, "train/policy_entropy_std": 0.19522982897857824, "train/policy_logprob_mag": 6.55107818543911, "train/policy_logprob_max": -0.008608394156908616, "train/policy_logprob_mean": -0.15328039865319928, "train/policy_logprob_min": -6.55107818543911, "train/policy_logprob_std": 0.6878820176546773, "train/policy_randomness_mag": 0.7379126682256659, "train/policy_randomness_max": 0.7379126682256659, "train/policy_randomness_mean": 0.07905999848541494, "train/policy_randomness_min": 0.03324275847990066, "train/policy_randomness_std": 0.1003282912618791, "train/post_ent_mag": 40.52600143353144, "train/post_ent_max": 40.52600143353144, "train/post_ent_mean": 39.66654100020727, "train/post_ent_min": 39.09710987408956, "train/post_ent_std": 0.2575195607884477, "train/prior_ent_mag": 43.33104228973389, "train/prior_ent_max": 43.33104228973389, "train/prior_ent_mean": 38.88149789969126, "train/prior_ent_min": 36.24767424662908, "train/prior_ent_std": 1.1573623319466908, "train/rep_loss_mean": 1.000012972081701, "train/rep_loss_std": 0.00036568138894684427, "train/reward_avg": 0.0007121332681284306, "train/reward_loss_mean": 0.014318024392802423, "train/reward_loss_std": 0.11204154307294327, "train/reward_max_data": 0.38461159739623935, "train/reward_max_pred": 0.08610281658669312, "train/reward_neg_acc": 0.9999032864967982, "train/reward_neg_loss": 0.010360460585313072, "train/reward_pos_acc": 0.2186781611165096, "train/reward_pos_loss": 4.665295389191858, "train/reward_pred": 0.0005961358425944733, "train/reward_rate": 0.0008392333984375, "train_stats/mean_log_entropy": 0.13860455079346287, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.025746945291757584, "report/cont_loss_std": 0.3311295807361603, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.919567584991455, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0027971186209470034, "report/cont_pred": 0.9963403940200806, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1102844700217247, "report/image_loss_std": 0.09806684404611588, "report/model_loss_mean": 0.751681923866272, "report/model_loss_std": 0.40960928797721863, "report/post_ent_mag": 40.683860778808594, "report/post_ent_max": 40.683860778808594, "report/post_ent_mean": 39.712684631347656, "report/post_ent_min": 39.049705505371094, "report/post_ent_std": 0.30686154961586, "report/prior_ent_mag": 42.13685607910156, "report/prior_ent_max": 42.13685607910156, "report/prior_ent_mean": 37.829063415527344, "report/prior_ent_min": 35.3118782043457, "report/prior_ent_std": 1.1323120594024658, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008501708507537842, "report/reward_loss_mean": 0.015650540590286255, "report/reward_loss_std": 0.1302562952041626, "report/reward_max_data": 0.6195833086967468, "report/reward_max_pred": 0.06917214393615723, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011614222079515457, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.144802570343018, "report/reward_pred": 0.0007368231890723109, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014552775770425797, "eval/cont_loss_std": 0.29674196243286133, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.569472312927246, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017251436365768313, "eval/cont_pred": 0.9983025193214417, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20783501863479614, "eval/image_loss_std": 0.1211487352848053, "eval/model_loss_mean": 0.8238564729690552, "eval/model_loss_std": 0.3201667368412018, "eval/post_ent_mag": 40.68132781982422, "eval/post_ent_max": 40.68132781982422, "eval/post_ent_mean": 39.655799865722656, "eval/post_ent_min": 39.145179748535156, "eval/post_ent_std": 0.2691437602043152, "eval/prior_ent_mag": 42.19390106201172, "eval/prior_ent_max": 42.19390106201172, "eval/prior_ent_mean": 37.92216491699219, "eval/prior_ent_min": 35.64363479614258, "eval/prior_ent_std": 1.0631496906280518, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001468670554459095, "eval/reward_loss_std": 0.001893145963549614, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.013634920120239258, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001468670554459095, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002506276359781623, "eval/reward_rate": 0.0, "replay/size": 399585.0, "replay/inserts": 30768.0, "replay/samples": 30768.0, "replay/insert_wait_avg": 1.3577801698951502e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0010046817583153e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 92968.0, "eval_replay/inserts": 8016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.229271441400646e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1003.6779327392578, "timer/env.step_count": 3846.0, "timer/env.step_total": 38.325519323349, "timer/env.step_frac": 0.038185077177845514, "timer/env.step_avg": 0.009965033625415756, "timer/env.step_min": 0.008603096008300781, "timer/env.step_max": 0.038934946060180664, "timer/replay._sample_count": 30768.0, "timer/replay._sample_total": 16.29924464225769, "timer/replay._sample_frac": 0.016239516791779478, "timer/replay._sample_avg": 0.0005297466407390045, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.02616095542907715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4848.0, "timer/agent.policy_total": 52.24484038352966, "timer/agent.policy_frac": 0.05205339151070305, "timer/agent.policy_avg": 0.010776575986701663, "timer/agent.policy_min": 0.009103775024414062, "timer/agent.policy_max": 0.0929117202758789, "timer/dataset_train_count": 1923.0, "timer/dataset_train_total": 0.23164057731628418, "timer/dataset_train_frac": 0.00023079174081678383, "timer/dataset_train_avg": 0.00012045791852120863, "timer/dataset_train_min": 0.00010442733764648438, "timer/dataset_train_max": 0.00044798851013183594, "timer/agent.train_count": 1923.0, "timer/agent.train_total": 860.601964712143, "timer/agent.train_frac": 0.8574483274364426, "timer/agent.train_avg": 0.44753092288722984, "timer/agent.train_min": 0.4366130828857422, "timer/agent.train_max": 0.734473466873169, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787790775299072, "timer/agent.report_frac": 0.0004770246130879991, "timer/agent.report_avg": 0.2393895387649536, "timer/agent.report_min": 0.23073434829711914, "timer/agent.report_max": 0.24804472923278809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2781196878783094e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 30.654641825510623}
{"step": 400424, "time": 13217.974044799805, "episode/length": 49.0, "episode/score": 0.8725127348153592, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.02563770857534564}
{"step": 400704, "time": 13227.217083215714, "episode/length": 288.0, "episode/score": 0.061335845289704594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061335845289704594}
{"step": 400992, "time": 13236.435410022736, "episode/length": 119.0, "episode/score": 0.6635064785133409, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0353814432511399}
{"step": 401016, "time": 13236.98465180397, "episode/length": 262.0, "episode/score": 0.22562153181127087, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.04437152908133157}
{"step": 401080, "time": 13239.039159536362, "episode/length": 46.0, "episode/score": 0.8764269299000489, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.020176912426109084}
{"step": 401240, "time": 13244.141014814377, "episode/length": 30.0, "episode/score": 0.9173562821998189, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.011106300331505281}
{"step": 401608, "time": 13256.453240394592, "episode/length": 288.0, "episode/score": 0.04341575524165364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04341575524165364}
{"step": 401688, "time": 13258.999351024628, "episode/length": 288.0, "episode/score": 0.056670655812979476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056670655812979476}
{"step": 401768, "time": 13261.57670545578, "episode/length": 93.0, "episode/score": 0.730837316367797, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.021462292744217848}
{"step": 401920, "time": 13266.631373882294, "episode/length": 186.0, "episode/score": 0.46800819235551216, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.04925820449471985}
{"step": 402000, "time": 13269.165483474731, "episode/length": 288.0, "episode/score": 0.029925090012625333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029925090012625333}
{"step": 402224, "time": 13276.324807405472, "episode/length": 288.0, "episode/score": 0.06395369627108494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06395369627108494}
{"step": 402576, "time": 13287.64375591278, "episode/length": 71.0, "episode/score": 0.7966991851142211, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.01857421717500074}
{"step": 402640, "time": 13289.686578512192, "episode/length": 174.0, "episode/score": 0.5285102357183291, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.07226021212676415}
{"step": 402848, "time": 13296.33271408081, "episode/length": 134.0, "episode/score": 0.628948762049788, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.04769874195068269}
{"step": 403160, "time": 13306.058568954468, "episode/length": 154.0, "episode/score": 0.5612382582162354, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.04248824651358518}
{"step": 403376, "time": 13313.297647237778, "episode/length": 91.0, "episode/score": 0.7389257109470577, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.023300737972874686}
{"step": 403392, "time": 13313.808100223541, "episode/length": 288.0, "episode/score": 0.03459340736333161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03459340736333161}
{"step": 403768, "time": 13325.487762928009, "episode/length": 75.0, "episode/score": 0.7984626745903256, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.03283766743078331}
{"step": 403920, "time": 13330.504925251007, "episode/length": 288.0, "episode/score": 0.04862508349506811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04862508349506811}
{"step": 403944, "time": 13331.041971683502, "episode/length": 136.0, "episode/score": 0.630854422073071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0558544571024413}
{"step": 404000, "time": 13333.120303630829, "episode/length": 288.0, "episode/score": 0.08733081639604734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08733081639604734}
{"step": 404088, "time": 13335.675319194794, "episode/length": 188.0, "episode/score": 0.4595215103753105, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.04702151749992822}
{"step": 404144, "time": 13337.670945167542, "episode/length": 95.0, "episode/score": 0.73421493478304, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.031089906144870838}
{"step": 404416, "time": 13346.38794541359, "episode/length": 273.0, "episode/score": 0.19267189680286378, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.04579690334540487}
{"step": 404696, "time": 13355.122060775757, "episode/length": 34.0, "episode/score": 0.9160652102937092, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.022315169734611118}
{"step": 405032, "time": 13365.7551009655, "episode/length": 110.0, "episode/score": 0.6897227704812394, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.033472771296146675}
{"step": 405144, "time": 13369.288975715637, "episode/length": 149.0, "episode/score": 0.5829767520327209, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.04860171677051994}
{"step": 405256, "time": 13372.963660478592, "episode/length": 232.0, "episode/score": 0.35254609661652125, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0775460910635104}
{"step": 405800, "time": 13390.161101818085, "episode/length": 137.0, "episode/score": 0.6283391735566966, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.056464174057282435}
{"step": 406080, "time": 13399.242721796036, "episode/length": 288.0, "episode/score": 0.08169936718260828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08169936718260828}
{"step": 406120, "time": 13400.294401168823, "episode/length": 39.0, "episode/score": 0.8980760060726425, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.019950994966620783}
{"step": 406232, "time": 13403.993358135223, "episode/length": 288.0, "episode/score": 0.06871289745228637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06871289745228637}
{"step": 406312, "time": 13406.54019355774, "episode/length": 288.0, "episode/score": 0.08569749645607772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08569749645607772}
{"step": 406400, "time": 13409.599125862122, "episode/length": 288.0, "episode/score": 0.08637595584309565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08637595584309565}
{"step": 406896, "time": 13425.41200709343, "episode/length": 72.0, "episode/score": 0.8131056336058009, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.03810563410638679}
{"step": 406920, "time": 13425.960748195648, "episode/length": 104.0, "episode/score": 0.7137042101485349, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.038704191068063665}
{"step": 407056, "time": 13430.526556253433, "episode/length": 238.0, "episode/score": 0.3419752507134035, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.08572524849569163}
{"step": 407120, "time": 13432.661905050278, "episode/length": 110.0, "episode/score": 0.7129687922476933, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0567187636095241}
{"step": 407152, "time": 13433.692928552628, "episode/length": 236.0, "episode/score": 0.3514031322556548, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.08890314499149099}
{"step": 407296, "time": 13438.220476865768, "episode/length": 29.0, "episode/score": 0.9259395938169064, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.016564552501108665}
{"step": 407344, "time": 13439.767176151276, "episode/length": 288.0, "episode/score": 0.09200232360592508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09200232360592508}
