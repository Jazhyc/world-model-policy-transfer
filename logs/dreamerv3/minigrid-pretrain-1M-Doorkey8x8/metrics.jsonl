{"step": 1560, "time": 148.01888489723206, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 148.0832245349884, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 149.45842385292053, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 149.46766114234924, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 149.47865962982178, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 149.48845958709717, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 149.49744987487793, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 149.50606489181519, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 271.16774320602417, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.8463134765625, "train/action_min": 0.0, "train/action_std": 1.8442964553833008, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009421570575796068, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.7566996812820435, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.6315197944641113, "train/cont_loss_std": 0.26165688037872314, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.6494140625, "train/cont_pos_loss": 0.6315197944641113, "train/cont_pred": 0.5487500429153442, "train/cont_rate": 1.0, "train/dyn_loss_mean": 11.011225700378418, "train/dyn_loss_std": 0.3680916428565979, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 9.831459045410156, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 39337.51953125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5000.77001953125, "train/image_loss_std": 43.10456848144531, "train/model_loss_mean": 5013.5498046875, "train/model_loss_std": 43.12039566040039, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50135500.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9261173009872437, "train/policy_entropy_max": 1.9261173009872437, "train/policy_entropy_mean": 1.6440507173538208, "train/policy_entropy_min": 0.7454129457473755, "train/policy_entropy_std": 0.1370316594839096, "train/policy_logprob_mag": 4.690417766571045, "train/policy_logprob_max": -0.23726673424243927, "train/policy_logprob_mean": -1.6499848365783691, "train/policy_logprob_min": -4.690417766571045, "train/policy_logprob_std": 0.7230586409568787, "train/policy_randomness_mag": 0.9898285269737244, "train/policy_randomness_max": 0.9898285269737244, "train/policy_randomness_mean": 0.844874918460846, "train/policy_randomness_min": 0.3830665051937103, "train/policy_randomness_std": 0.07042033970355988, "train/post_ent_mag": 105.63103485107422, "train/post_ent_max": 105.63103485107422, "train/post_ent_mean": 105.30867004394531, "train/post_ent_min": 105.00345611572266, "train/post_ent_std": 0.11143764853477478, "train/prior_ent_mag": 106.31761932373047, "train/prior_ent_max": 106.31761932373047, "train/prior_ent_mean": 105.55225372314453, "train/prior_ent_min": 104.527099609375, "train/prior_ent_std": 0.26935118436813354, "train/rep_loss_mean": 11.011225700378418, "train/rep_loss_std": 0.3680916428565979, "train/reward_avg": 0.000295876816380769, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.763753457202256e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.623670220375061, "report/cont_loss_std": 0.2668728828430176, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.64453125, "report/cont_pos_loss": 0.623670220375061, "report/cont_pred": 0.5541303157806396, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.04434585571289, "report/dyn_loss_std": 0.36162781715393066, "report/image_loss_mean": 5000.0947265625, "report/image_loss_std": 42.547767639160156, "report/model_loss_mean": 5012.88623046875, "report/model_loss_std": 42.5671272277832, "report/post_ent_mag": 105.66044616699219, "report/post_ent_max": 105.66044616699219, "report/post_ent_mean": 105.2905044555664, "report/post_ent_min": 104.85536193847656, "report/post_ent_std": 0.11542098969221115, "report/prior_ent_mag": 106.1494369506836, "report/prior_ent_max": 106.1494369506836, "report/prior_ent_mean": 105.54510498046875, "report/prior_ent_min": 104.69877624511719, "report/prior_ent_std": 0.254974901676178, "report/rep_loss_mean": 11.04434585571289, "report/rep_loss_std": 0.36162781715393066, "report/reward_avg": 0.000295876816380769, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.763753457202256e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.5923629403114319, "eval/cont_loss_std": 0.2655635178089142, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.7060546875, "eval/cont_pos_loss": 0.5923629403114319, "eval/cont_pred": 0.5711941123008728, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.024686813354492, "eval/dyn_loss_std": 0.39196014404296875, "eval/image_loss_mean": 4996.58984375, "eval/image_loss_std": 40.65910339355469, "eval/model_loss_mean": 5009.3388671875, "eval/model_loss_std": 40.69269561767578, "eval/post_ent_mag": 105.64175415039062, "eval/post_ent_max": 105.64175415039062, "eval/post_ent_mean": 105.27256774902344, "eval/post_ent_min": 104.94096374511719, "eval/post_ent_std": 0.11783119291067123, "eval/prior_ent_mag": 106.65653991699219, "eval/prior_ent_max": 106.65653991699219, "eval/prior_ent_mean": 105.5533676147461, "eval/prior_ent_min": 104.76142883300781, "eval/prior_ent_std": 0.2963699996471405, "eval/rep_loss_mean": 11.024686813354492, "eval/rep_loss_std": 0.39196014404296875, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.1731457236586816e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.131776537214006e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6184.0, "eval_replay/inserts": 6184.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.739445509916752e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.770397731236049e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 161.35035133361816, "timer/env.step_count": 196.0, "timer/env.step_total": 1.6630594730377197, "timer/env.step_frac": 0.010307132642054637, "timer/env.step_avg": 0.008484997311416937, "timer/env.step_min": 0.006045103073120117, "timer/env.step_max": 0.018474102020263672, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.07946252822875977, "timer/replay._sample_frac": 0.000492484383033403, "timer/replay._sample_avg": 0.0007094868591853551, "timer/replay._sample_min": 0.00033354759216308594, "timer/replay._sample_max": 0.0011780261993408203, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.1503493785858154, "timer/agent.save_frac": 0.013327206050761039, "timer/agent.save_avg": 2.1503493785858154, "timer/agent.save_min": 2.1503493785858154, "timer/agent.save_max": 2.1503493785858154, "timer/agent.policy_count": 642.0, "timer/agent.policy_total": 27.941269636154175, "timer/agent.policy_frac": 0.1731714211045072, "timer/agent.policy_avg": 0.043522226847592174, "timer/agent.policy_min": 0.009054183959960938, "timer/agent.policy_max": 18.326029300689697, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.218650817871094e-05, "timer/dataset_train_frac": 1.9948210780254257e-07, "timer/dataset_train_avg": 3.218650817871094e-05, "timer/dataset_train_min": 3.218650817871094e-05, "timer/dataset_train_max": 3.218650817871094e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 90.21342921257019, "timer/agent.train_frac": 0.5591151706018862, "timer/agent.train_avg": 90.21342921257019, "timer/agent.train_min": 90.21342921257019, "timer/agent.train_max": 90.21342921257019, "timer/agent.report_count": 2.0, "timer/agent.report_total": 29.317680835723877, "timer/agent.report_frac": 0.18170199564737724, "timer/agent.report_avg": 14.658840417861938, "timer/agent.report_min": 7.026125431060791, "timer/agent.report_max": 22.291555404663086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 2.408561746060329e-07, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05}
{"step": 4040, "time": 348.5319640636444, "episode/length": 504.0, "episode/score": 0.15977130732767364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15977130732767364}
{"step": 5128, "time": 382.85410475730896, "episode/length": 640.0, "episode/score": 0.12705568920688393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12705568920688393}
{"step": 5128, "time": 382.8645668029785, "episode/length": 640.0, "episode/score": 0.16600806725307393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16600806725307393}
{"step": 5128, "time": 382.87343859672546, "episode/length": 640.0, "episode/score": 0.11609797891946982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11609797891946982}
{"step": 5128, "time": 382.88161969184875, "episode/length": 640.0, "episode/score": 0.12343598540849143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12343598540849143}
{"step": 5128, "time": 382.88959431648254, "episode/length": 640.0, "episode/score": 0.09176724892012089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09176724892012089}
{"step": 5128, "time": 382.8979637622833, "episode/length": 640.0, "episode/score": 0.11673202351528289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11673202351528289}
{"step": 5128, "time": 382.90604519844055, "episode/length": 640.0, "episode/score": 0.1562968525498718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1562968525498718}
{"step": 9168, "time": 509.57117676734924, "episode/length": 640.0, "episode/score": 0.12227383040163886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12227383040163886}
{"step": 10088, "time": 549.9570479393005, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.9722936153412, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.981616973877, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.9907448291779, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.999299287796, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 550.0078551769257, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 550.0159554481506, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 550.0240306854248, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10256, "time": 555.621710062027, "episode/length": 640.0, "episode/score": 0.11089541530719771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11089541530719771}
{"step": 10256, "time": 555.6308076381683, "episode/length": 640.0, "episode/score": 0.09378287443195177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09378287443195177}
{"step": 10256, "time": 555.6394765377045, "episode/length": 640.0, "episode/score": 0.13323041438513883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13323041438513883}
{"step": 10256, "time": 555.6485350131989, "episode/length": 640.0, "episode/score": 0.14131554947448421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14131554947448421}
{"step": 10256, "time": 555.6575510501862, "episode/length": 640.0, "episode/score": 0.16001274448126424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16001274448126424}
{"step": 10256, "time": 555.6662085056305, "episode/length": 640.0, "episode/score": 0.08745330581513144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08745330581513144}
{"step": 10256, "time": 555.6742031574249, "episode/length": 640.0, "episode/score": 0.14337698829496048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14337698829496048}
{"step": 14296, "time": 681.4594078063965, "episode/length": 640.0, "episode/score": 0.13060082373630166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13060082373630166}
{"step": 15384, "time": 715.4599931240082, "episode/length": 640.0, "episode/score": 0.12904109909561612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12904109909561612}
{"step": 15384, "time": 715.4692528247833, "episode/length": 640.0, "episode/score": 0.132513006282295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.132513006282295}
{"step": 15384, "time": 715.4779894351959, "episode/length": 640.0, "episode/score": 0.12378601450160431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12378601450160431}
{"step": 15384, "time": 715.4865231513977, "episode/length": 640.0, "episode/score": 0.08559969664037226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08559969664037226}
{"step": 15384, "time": 715.4948949813843, "episode/length": 640.0, "episode/score": 0.11288693670411476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11288693670411476}
{"step": 15384, "time": 715.503036737442, "episode/length": 640.0, "episode/score": 0.0760433465981123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0760433465981123}
{"step": 15384, "time": 715.511373758316, "episode/length": 640.0, "episode/score": 0.14164596344215852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14164596344215852}
{"step": 18656, "time": 818.4293353557587, "episode/length": 408.0, "episode/score": 0.09336555018711579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09336555018711579}
{"step": 19424, "time": 842.4214997291565, "episode/length": 640.0, "episode/score": 0.13496544443222547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13496544443222547}
{"step": 20072, "time": 874.0889663696289, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.0982091426849, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.1062860488892, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.1138927936554, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.1214396953583, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.1291370391846, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.1366288661957, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 874.1441476345062, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20512, "time": 888.1072885990143, "episode/length": 640.0, "episode/score": 0.10253667366339414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10253667366339414}
{"step": 20512, "time": 888.1167278289795, "episode/length": 640.0, "episode/score": 0.10498014962178104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10498014962178104}
{"step": 20512, "time": 888.125893831253, "episode/length": 640.0, "episode/score": 0.06429596290831796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06429596290831796}
{"step": 20512, "time": 888.1346659660339, "episode/length": 640.0, "episode/score": 0.07512462416696053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07512462416696053}
{"step": 20512, "time": 888.1433539390564, "episode/length": 640.0, "episode/score": 0.109022843956609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.109022843956609}
{"step": 20512, "time": 888.1513493061066, "episode/length": 640.0, "episode/score": 0.09356575437311676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09356575437311676}
{"step": 23784, "time": 990.2605900764465, "episode/length": 640.0, "episode/score": 0.09648285119470756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09648285119470756}
{"step": 24552, "time": 1014.4758489131927, "episode/length": 640.0, "episode/score": 0.12185526760649168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12185526760649168}
{"step": 25640, "time": 1049.0544836521149, "episode/length": 640.0, "episode/score": 0.07989966849754637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07989966849754637}
{"step": 25640, "time": 1049.0636267662048, "episode/length": 640.0, "episode/score": 0.07391513409135086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07391513409135086}
{"step": 25640, "time": 1049.0720415115356, "episode/length": 640.0, "episode/score": 0.0549851846724323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0549851846724323}
{"step": 25640, "time": 1049.080418586731, "episode/length": 640.0, "episode/score": 0.05546812306548077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05546812306548077}
{"step": 25640, "time": 1049.088466644287, "episode/length": 640.0, "episode/score": 0.11985897810629353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11985897810629353}
{"step": 25640, "time": 1049.1060633659363, "episode/length": 640.0, "episode/score": 0.05190441274771729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05190441274771729}
{"step": 28912, "time": 1152.0265781879425, "episode/length": 640.0, "episode/score": 0.07387170886340755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07387170886340755}
{"step": 29680, "time": 1176.0878167152405, "episode/length": 640.0, "episode/score": 0.13419169746367743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13419169746367743}
{"step": 30056, "time": 1199.6123082637787, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6213653087616, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6294932365417, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6375098228455, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6454572677612, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6537644863129, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6615798473358, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1199.6691358089447, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30768, "time": 1222.1622800827026, "episode/length": 640.0, "episode/score": 0.16937657800644956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16937657800644956}
{"step": 30768, "time": 1222.1718423366547, "episode/length": 640.0, "episode/score": 0.1270808931029137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1270808931029137}
{"step": 30768, "time": 1222.179949760437, "episode/length": 640.0, "episode/score": 0.18202411709398802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18202411709398802}
{"step": 30768, "time": 1222.1881611347198, "episode/length": 640.0, "episode/score": 0.14542641271719958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14542641271719958}
{"step": 30768, "time": 1222.1969459056854, "episode/length": 640.0, "episode/score": 0.14890288737535684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14890288737535684}
{"step": 30768, "time": 1222.2048182487488, "episode/length": 640.0, "episode/score": 0.13958350817489418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13958350817489418}
{"step": 31401, "time": 1242.6954081058502, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0014651718960015, "train/action_min": 0.0, "train/action_std": 1.9995191404896397, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004953961686096004, "train/actor_opt_grad_steps": 935.0, "train/actor_opt_loss": 10.741163772102746, "train/adv_mag": 0.0014652878832347724, "train/adv_max": 0.0014650445647676343, "train/adv_mean": 0.0008592385176742689, "train/adv_min": 0.00010654191339065763, "train/adv_std": 0.0003994129917072484, "train/cont_avg": 0.9988291750672043, "train/cont_loss_mean": 0.012445570921791445, "train/cont_loss_std": 0.18476587752197612, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.699283206273639, "train/cont_pos_acc": 0.9980311223896601, "train/cont_pos_loss": 0.00461586340392575, "train/cont_pred": 0.9964114783271667, "train/cont_rate": 0.9988291750672043, "train/dyn_loss_mean": 1.0712046046410837, "train/dyn_loss_std": 0.005151320526404375, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.528451369013838, "train/extr_critic_critic_opt_grad_steps": 935.0, "train/extr_critic_critic_opt_loss": 10425.294054256972, "train/extr_critic_mag": 0.01320953074321952, "train/extr_critic_max": 0.013209516002285865, "train/extr_critic_mean": 0.01317831139243169, "train/extr_critic_min": 0.01314636456069126, "train/extr_critic_std": 7.3346042737837585e-06, "train/extr_return_normed_mag": 0.0026686630004391686, "train/extr_return_normed_max": 0.0026684365964839, "train/extr_return_normed_mean": 0.002085442978099215, "train/extr_return_normed_min": 0.001346124630895253, "train/extr_return_normed_std": 0.0003991766492177553, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014620793112632485, "train/extr_return_raw_max": 0.01462054651198096, "train/extr_return_raw_mean": 0.01403755345342939, "train/extr_return_raw_min": 0.013298234549511312, "train/extr_return_raw_std": 0.00039917664569713064, "train/extr_reward_mag": 0.00017557349256289902, "train/extr_reward_max": 0.00017553439704320764, "train/extr_reward_mean": 0.0001753745303088386, "train/extr_reward_min": 0.00017492873694307062, "train/extr_reward_std": 6.38515082647022e-08, "train/image_loss_mean": 28.170861874857255, "train/image_loss_std": 0.4465485673838405, "train/model_loss_mean": 28.946496305286242, "train/model_loss_std": 0.5721310054663048, "train/model_opt_grad_norm": 105.91453493479136, "train/model_opt_grad_steps": 925.0, "train/model_opt_loss": 550.1352808142221, "train/model_opt_model_opt_grad_overflow": 0.005376344086021506, "train/model_opt_model_opt_grad_scale": 14.22841061827957, "train/policy_entropy_mag": 1.9458036288138358, "train/policy_entropy_max": 1.9458036288138358, "train/policy_entropy_mean": 1.9409924066194923, "train/policy_entropy_min": 1.884514231194732, "train/policy_entropy_std": 0.0030574194350910765, "train/policy_logprob_mag": 2.368645536002292, "train/policy_logprob_max": -1.527589388592269, "train/policy_logprob_mean": -1.9409511236734287, "train/policy_logprob_min": -2.368645536002292, "train/policy_logprob_std": 0.0872388552794213, "train/policy_randomness_mag": 0.999945318827065, "train/policy_randomness_max": 0.999945318827065, "train/policy_randomness_mean": 0.9974728361252816, "train/policy_randomness_min": 0.968448797861735, "train/policy_randomness_std": 0.0015712028227856643, "train/post_ent_mag": 79.49833355155043, "train/post_ent_max": 79.49833355155043, "train/post_ent_mean": 79.41755327614405, "train/post_ent_min": 79.33750246929866, "train/post_ent_std": 0.022144441768246634, "train/prior_ent_mag": 85.71631179317352, "train/prior_ent_max": 85.71631179317352, "train/prior_ent_mean": 85.62557667557911, "train/prior_ent_min": 85.38064923850439, "train/prior_ent_std": 0.047586538328198334, "train/rep_loss_mean": 1.0712046046410837, "train/rep_loss_std": 0.005151320526404375, "train/reward_avg": 0.00019081427050085978, "train/reward_loss_mean": 0.12046671373849754, "train/reward_loss_std": 0.01518677359066704, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00017557221074258127, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12046671030862678, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00017520574219424717, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.93533260623614, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020038118585944176, "report/cont_loss_std": 0.32238340377807617, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.967408180236816, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025629913434386253, "report/cont_pred": 0.9974404573440552, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.30683934688568115, "report/image_loss_std": 0.11224592477083206, "report/model_loss_mean": 0.9358754754066467, "report/model_loss_std": 0.336523175239563, "report/post_ent_mag": 65.98463439941406, "report/post_ent_max": 65.98463439941406, "report/post_ent_mean": 65.80523681640625, "report/post_ent_min": 65.78314208984375, "report/post_ent_std": 0.026617255061864853, "report/prior_ent_mag": 74.99307250976562, "report/prior_ent_max": 74.99307250976562, "report/prior_ent_mean": 74.9011459350586, "report/prior_ent_min": 74.84957885742188, "report/prior_ent_std": 0.022645574063062668, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017194883548654616, "report/reward_loss_mean": 0.008997974917292595, "report/reward_loss_std": 0.015126986429095268, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00017213821411132812, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008997974917292595, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017190887592732906, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0025631606113165617, "eval/cont_loss_std": 2.990066150232451e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0025631606113165617, "eval/cont_pred": 0.9974403381347656, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2544326186180115, "eval/image_loss_std": 0.08016235381364822, "eval/model_loss_mean": 0.8585535287857056, "eval/model_loss_std": 0.08016253262758255, "eval/post_ent_mag": 65.98403930664062, "eval/post_ent_max": 65.98403930664062, "eval/post_ent_mean": 65.80412292480469, "eval/post_ent_min": 65.78297424316406, "eval/post_ent_std": 0.02471458539366722, "eval/prior_ent_mag": 74.98566436767578, "eval/prior_ent_max": 74.98566436767578, "eval/prior_ent_mean": 74.89990997314453, "eval/prior_ent_min": 74.81161499023438, "eval/prior_ent_std": 0.02150430716574192, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015577636659145355, "eval/reward_loss_std": 9.753077847562963e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00017213821411132812, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015577636659145355, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017190806102007627, "eval/reward_rate": 0.0, "replay/size": 30897.0, "replay/inserts": 29840.0, "replay/samples": 29840.0, "replay/insert_wait_avg": 1.286437620106715e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.866470556796077e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21568.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.107366272266247e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 971.5170600414276, "timer/env.step_count": 3730.0, "timer/env.step_total": 34.57907581329346, "timer/env.step_frac": 0.03559286525737276, "timer/env.step_avg": 0.009270529708657764, "timer/env.step_min": 0.007641792297363281, "timer/env.step_max": 0.035074710845947266, "timer/replay._sample_count": 29840.0, "timer/replay._sample_total": 14.388192892074585, "timer/replay._sample_frac": 0.014810025972638134, "timer/replay._sample_avg": 0.0004821780459810518, "timer/replay._sample_min": 0.00031948089599609375, "timer/replay._sample_max": 0.026079893112182617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5653.0, "timer/agent.policy_total": 56.19212007522583, "timer/agent.policy_frac": 0.05783956081309542, "timer/agent.policy_avg": 0.009940229979696768, "timer/agent.policy_min": 0.008455991744995117, "timer/agent.policy_max": 0.39227724075317383, "timer/dataset_train_count": 1865.0, "timer/dataset_train_total": 0.1894514560699463, "timer/dataset_train_frac": 0.00019500579440351532, "timer/dataset_train_avg": 0.00010158255017155297, "timer/dataset_train_min": 6.532669067382812e-05, "timer/dataset_train_max": 0.0004489421844482422, "timer/agent.train_count": 1865.0, "timer/agent.train_total": 826.1678459644318, "timer/agent.train_frac": 0.8503894372469405, "timer/agent.train_avg": 0.44298544019540576, "timer/agent.train_min": 0.43181300163269043, "timer/agent.train_max": 0.5999016761779785, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783906936645508, "timer/agent.report_frac": 0.0004924161533963708, "timer/agent.report_avg": 0.2391953468322754, "timer/agent.report_min": 0.23505878448486328, "timer/agent.report_max": 0.2433319091796875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.944902428266931e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 30.71439815724789}
{"step": 34040, "time": 1325.4332225322723, "episode/length": 640.0, "episode/score": 0.09313744829682946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09313744829682946}
{"step": 34808, "time": 1349.3880364894867, "episode/length": 640.0, "episode/score": 0.11546064476581819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11546064476581819}
{"step": 35896, "time": 1383.4948270320892, "episode/length": 640.0, "episode/score": 0.1261053968254089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1261053968254089}
{"step": 35896, "time": 1383.5040667057037, "episode/length": 640.0, "episode/score": 0.10277423972561905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10277423972561905}
{"step": 35896, "time": 1383.5127749443054, "episode/length": 640.0, "episode/score": 0.14488897553650304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14488897553650304}
{"step": 35896, "time": 1383.520979642868, "episode/length": 640.0, "episode/score": 0.0684197512173057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0684197512173057}
{"step": 35896, "time": 1383.5293290615082, "episode/length": 640.0, "episode/score": 0.0968099357261849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0968099357261849}
{"step": 35896, "time": 1383.5374767780304, "episode/length": 640.0, "episode/score": 0.05546246320503201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05546246320503201}
{"step": 39168, "time": 1485.9461991786957, "episode/length": 640.0, "episode/score": 0.10573192049082536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10573192049082536}
{"step": 39936, "time": 1509.9007484912872, "episode/length": 640.0, "episode/score": 0.12616680325797347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12616680325797347}
{"step": 40040, "time": 1524.9865188598633, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1524.995300769806, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1525.0031070709229, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1525.0105679035187, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1525.0181074142456, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1525.0253834724426, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1525.03280377388, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1525.0403861999512, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 41024, "time": 1556.3577315807343, "episode/length": 640.0, "episode/score": 0.11452416844815616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11452416844815616}
{"step": 41024, "time": 1556.3668458461761, "episode/length": 640.0, "episode/score": 0.07628660465172743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07628660465172743}
{"step": 41024, "time": 1556.3754441738129, "episode/length": 640.0, "episode/score": 0.07942046393338842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07942046393338842}
{"step": 41024, "time": 1556.3835890293121, "episode/length": 640.0, "episode/score": 0.09363170634082962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09363170634082962}
{"step": 41024, "time": 1556.3920729160309, "episode/length": 640.0, "episode/score": 0.090092015747814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.090092015747814}
{"step": 41024, "time": 1556.400859117508, "episode/length": 640.0, "episode/score": 0.12714790579047985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12714790579047985}
{"step": 44296, "time": 1658.1582300662994, "episode/length": 640.0, "episode/score": 0.1068221616337155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1068221616337155}
{"step": 45064, "time": 1682.2415926456451, "episode/length": 640.0, "episode/score": 0.11282293098366836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11282293098366836}
{"step": 46152, "time": 1716.1217231750488, "episode/length": 640.0, "episode/score": 0.05645054408012129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05645054408012129}
{"step": 46152, "time": 1716.1311452388763, "episode/length": 640.0, "episode/score": 0.10609328533558937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10609328533558937}
{"step": 46152, "time": 1716.1404078006744, "episode/length": 640.0, "episode/score": 0.129062149096967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.129062149096967}
{"step": 46152, "time": 1716.1491310596466, "episode/length": 640.0, "episode/score": 0.13763461915738162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13763461915738162}
{"step": 46152, "time": 1716.1573531627655, "episode/length": 640.0, "episode/score": 0.10708807375721108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10708807375721108}
{"step": 46152, "time": 1716.165390253067, "episode/length": 640.0, "episode/score": 0.09691652070148393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09691652070148393}
{"step": 49424, "time": 1819.0664401054382, "episode/length": 640.0, "episode/score": 0.15790644549826993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15790644549826993}
{"step": 50024, "time": 1849.3824384212494, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.3910055160522, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.3987834453583, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.4064300060272, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.414144039154, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.4217483997345, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.4294714927673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1849.4370226860046, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50192, "time": 1854.906506061554, "episode/length": 640.0, "episode/score": 0.1410196291176362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1410196291176362}
{"step": 51280, "time": 1888.8098731040955, "episode/length": 640.0, "episode/score": 0.10609730339820089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10609730339820089}
{"step": 51280, "time": 1888.8197093009949, "episode/length": 640.0, "episode/score": 0.14226846249835035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14226846249835035}
{"step": 51280, "time": 1888.8280763626099, "episode/length": 640.0, "episode/score": 0.11875547629983885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11875547629983885}
{"step": 51280, "time": 1888.8392794132233, "episode/length": 640.0, "episode/score": 0.08543736868688256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08543736868688256}
{"step": 51280, "time": 1888.8455774784088, "episode/length": 640.0, "episode/score": 0.12188653601384658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12188653601384658}
{"step": 51280, "time": 1888.8540501594543, "episode/length": 640.0, "episode/score": 0.1670328707346016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1670328707346016}
{"step": 54552, "time": 1990.990061044693, "episode/length": 640.0, "episode/score": 0.15961548031822304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15961548031822304}
{"step": 55320, "time": 2014.890863418579, "episode/length": 640.0, "episode/score": 0.12958176649175357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12958176649175357}
{"step": 56408, "time": 2048.924221754074, "episode/length": 640.0, "episode/score": 0.09684520934962393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09684520934962393}
{"step": 56408, "time": 2048.937613248825, "episode/length": 640.0, "episode/score": 0.11806808725620499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11806808725620499}
{"step": 56408, "time": 2048.946520090103, "episode/length": 640.0, "episode/score": 0.11187848469512574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11187848469512574}
{"step": 56408, "time": 2048.9556465148926, "episode/length": 640.0, "episode/score": 0.11698852833714568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11698852833714568}
{"step": 56408, "time": 2048.964460372925, "episode/length": 640.0, "episode/score": 0.07291987909098907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07291987909098907}
{"step": 56408, "time": 2048.9731090068817, "episode/length": 640.0, "episode/score": 0.08937600792501144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08937600792501144}
{"step": 59680, "time": 2151.43088889122, "episode/length": 640.0, "episode/score": 0.1073189039482827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1073189039482827}
{"step": 60008, "time": 2172.8992853164673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.908001422882, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.9164745807648, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.9245624542236, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.9324119091034, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.9400086402893, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.947832584381, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2172.955355644226, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60448, "time": 2186.881420612335, "episode/length": 640.0, "episode/score": 0.05542249898138607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05542249898138607}
{"step": 61536, "time": 2220.621522426605, "episode/length": 640.0, "episode/score": 0.056187190611979076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056187190611979076}
{"step": 61536, "time": 2220.631073951721, "episode/length": 640.0, "episode/score": 0.1024117572201817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1024117572201817}
{"step": 61536, "time": 2220.63924241066, "episode/length": 640.0, "episode/score": 0.05271485386879249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05271485386879249}
{"step": 61536, "time": 2220.6475038528442, "episode/length": 640.0, "episode/score": 0.07483567842393768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07483567842393768}
{"step": 61536, "time": 2220.655883550644, "episode/length": 640.0, "episode/score": 0.05729900505508567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05729900505508567}
{"step": 61536, "time": 2220.6653277873993, "episode/length": 640.0, "episode/score": 0.08980969572058939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08980969572058939}
{"step": 62233, "time": 2243.0756504535675, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9988583579582255, "train/action_min": 0.0, "train/action_std": 1.9996405240785273, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00020421781268639133, "train/actor_opt_grad_steps": 2830.0, "train/actor_opt_loss": 2.477253781795656, "train/adv_mag": 0.0008029783617492784, "train/adv_max": 0.0008029783617492784, "train/adv_mean": 0.00042771366013182624, "train/adv_min": -1.628809835317839e-05, "train/adv_std": 0.00020262473976870497, "train/cont_avg": 0.9986844235751295, "train/cont_loss_mean": 0.010073050332721323, "train/cont_loss_std": 0.2007090931354006, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.6125061180856495, "train/cont_pos_acc": 0.9999999972205088, "train/cont_pos_loss": 0.0013914511833397836, "train/cont_pred": 0.9986096163487805, "train/cont_rate": 0.9986844235751295, "train/dyn_loss_mean": 1.0000000061766472, "train/dyn_loss_std": 1.5118027142420353e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08916934513983948, "train/extr_critic_critic_opt_grad_steps": 2830.0, "train/extr_critic_critic_opt_loss": 10401.226800315739, "train/extr_critic_mag": 0.03604504481498442, "train/extr_critic_max": 0.03604504481498442, "train/extr_critic_mean": 0.03597389405757343, "train/extr_critic_min": 0.03590601034115015, "train/extr_critic_std": 2.3012268285531245e-05, "train/extr_return_normed_mag": 0.0015351791610371882, "train/extr_return_normed_max": 0.0015351791610371882, "train/extr_return_normed_mean": 0.0012209829310355757, "train/extr_return_normed_min": 0.0008191402731318548, "train/extr_return_normed_std": 0.00020015038322347307, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.03671579667091987, "train/extr_return_raw_max": 0.03671579667091987, "train/extr_return_raw_mean": 0.03640160224173662, "train/extr_return_raw_min": 0.03599975778301454, "train/extr_return_raw_std": 0.0002001503831103753, "train/extr_reward_mag": 0.00017577440627498332, "train/extr_reward_max": 0.00017577440627498332, "train/extr_reward_mean": 0.00017565834133009971, "train/extr_reward_min": 0.00017552857571932935, "train/extr_reward_std": 5.144914376281761e-08, "train/image_loss_mean": 0.2881297884518618, "train/image_loss_std": 0.12542705226284234, "train/model_loss_mean": 0.9072896174198605, "train/model_loss_std": 0.2573796482901499, "train/model_opt_grad_norm": 80.89732740333044, "train/model_opt_grad_steps": 2820.0, "train/model_opt_loss": 48.23092484350649, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 53.331444300518136, "train/policy_entropy_mag": 1.9458864204624156, "train/policy_entropy_max": 1.9458864204624156, "train/policy_entropy_mean": 1.944811962429106, "train/policy_entropy_min": 1.9288774518769023, "train/policy_entropy_std": 0.0007280708806965636, "train/policy_logprob_mag": 2.185450513128172, "train/policy_logprob_max": -1.7119014473159078, "train/policy_logprob_mean": -1.9448051292043893, "train/policy_logprob_min": -2.185450513128172, "train/policy_logprob_std": 0.04658538199613749, "train/policy_randomness_mag": 0.9999878644325573, "train/policy_randomness_max": 0.9999878644325573, "train/policy_randomness_mean": 0.9994357018273111, "train/policy_randomness_min": 0.9912469828684713, "train/policy_randomness_std": 0.00037415444394308165, "train/post_ent_mag": 56.79438878588108, "train/post_ent_max": 56.79438878588108, "train/post_ent_mean": 56.64936308786659, "train/post_ent_min": 56.62286321610367, "train/post_ent_std": 0.020091626822099168, "train/prior_ent_mag": 65.75600397772122, "train/prior_ent_max": 65.75600397772122, "train/prior_ent_mean": 65.64189719165545, "train/prior_ent_min": 65.58255680855073, "train/prior_ent_std": 0.027034733849794754, "train/rep_loss_mean": 1.0000000061766472, "train/rep_loss_std": 1.5118027142420353e-07, "train/reward_avg": 0.00017978488463109814, "train/reward_loss_mean": 0.009086749777004818, "train/reward_loss_std": 0.015323632449838163, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00017572869908624361, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009086749791481333, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00017560637734560151, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9418855706850688, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.00210148049518466, "report/cont_loss_std": 4.656612873077393e-10, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00210148049518466, "report/cont_pred": 0.9979009032249451, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2523585855960846, "report/image_loss_std": 0.1182241290807724, "report/model_loss_mean": 0.8618394136428833, "report/model_loss_std": 0.12330944836139679, "report/post_ent_mag": 49.04853057861328, "report/post_ent_max": 49.04853057861328, "report/post_ent_mean": 48.958717346191406, "report/post_ent_min": 48.918556213378906, "report/post_ent_std": 0.0132941585034132, "report/prior_ent_mag": 59.38791275024414, "report/prior_ent_max": 59.38791275024414, "report/prior_ent_mean": 59.255149841308594, "report/prior_ent_min": 59.21145248413086, "report/prior_ent_std": 0.031958527863025665, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00014312351413536817, "report/reward_loss_mean": 0.007379311136901379, "report/reward_loss_std": 0.01382642425596714, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00016760826110839844, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007379311136901379, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00016760826110839844, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00210148049518466, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00210148049518466, "eval/cont_pred": 0.9979009032249451, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22702118754386902, "eval/image_loss_std": 0.11792365461587906, "eval/model_loss_mean": 0.8302842378616333, "eval/model_loss_std": 0.11792363226413727, "eval/post_ent_mag": 49.04756164550781, "eval/post_ent_max": 49.04756164550781, "eval/post_ent_mean": 48.95863342285156, "eval/post_ent_min": 48.91178894042969, "eval/post_ent_std": 0.013909515924751759, "eval/prior_ent_mag": 59.3773078918457, "eval/prior_ent_max": 59.3773078918457, "eval/prior_ent_mean": 59.25335693359375, "eval/prior_ent_min": 59.20878601074219, "eval/prior_ent_std": 0.03078814223408699, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011615753173828125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00016760826110839844, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011615753173828125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00016760826110839844, "eval/reward_rate": 0.0, "replay/size": 61729.0, "replay/inserts": 30832.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.2987131396908802e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.258979951772407e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36952.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0595244786048766e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.366616487503, "timer/env.step_count": 3854.0, "timer/env.step_total": 34.61193013191223, "timer/env.step_frac": 0.03459924547806481, "timer/env.step_avg": 0.008980781040973594, "timer/env.step_min": 0.007310628890991211, "timer/env.step_max": 0.038208723068237305, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 15.108915567398071, "timer/replay._sample_frac": 0.015103378419852355, "timer/replay._sample_avg": 0.0004900400741890916, "timer/replay._sample_min": 0.0003380775451660156, "timer/replay._sample_max": 0.008815288543701172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5777.0, "timer/agent.policy_total": 57.745773792266846, "timer/agent.policy_frac": 0.057724610998140226, "timer/agent.policy_avg": 0.00999580643798976, "timer/agent.policy_min": 0.008291244506835938, "timer/agent.policy_max": 0.08541464805603027, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.1952807903289795, "timer/dataset_train_frac": 0.00019520922340916504, "timer/dataset_train_avg": 0.00010133927884223118, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.00043272972106933594, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 852.1040375232697, "timer/agent.train_frac": 0.8517917566213731, "timer/agent.train_avg": 0.4421920277754383, "timer/agent.train_min": 0.4329662322998047, "timer/agent.train_max": 0.5540218353271484, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47089076042175293, "timer/agent.report_frac": 0.0004707181873732943, "timer/agent.report_avg": 0.23544538021087646, "timer/agent.report_min": 0.22925376892089844, "timer/agent.report_max": 0.2416369915008545, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1459718789805695e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 30.82020855348494}
{"step": 64808, "time": 2322.6659283638, "episode/length": 640.0, "episode/score": 0.12514796925086102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12514796925086102}
{"step": 65576, "time": 2347.057492494583, "episode/length": 640.0, "episode/score": 0.09421614859707006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09421614859707006}
{"step": 66664, "time": 2380.6871659755707, "episode/length": 640.0, "episode/score": 0.15661575092894964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15661575092894964}
{"step": 66664, "time": 2380.696451663971, "episode/length": 640.0, "episode/score": 0.1466410095882793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1466410095882793}
{"step": 66664, "time": 2380.704724550247, "episode/length": 640.0, "episode/score": 0.05215421382945351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05215421382945351}
{"step": 66664, "time": 2380.7129464149475, "episode/length": 640.0, "episode/score": 0.1087509714512862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1087509714512862}
{"step": 66664, "time": 2380.7212698459625, "episode/length": 640.0, "episode/score": 0.04363460279432729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04363460279432729}
{"step": 66664, "time": 2380.729956626892, "episode/length": 640.0, "episode/score": 0.12866308244474567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12866308244474567}
{"step": 69936, "time": 2482.706993341446, "episode/length": 640.0, "episode/score": 0.11289108384306701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11289108384306701}
{"step": 70096, "time": 2499.040859937668, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.0495433807373, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.057508468628, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.0654487609863, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.072921037674, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.080590248108, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.0881826877594, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2499.096022605896, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70704, "time": 2517.9686284065247, "episode/length": 640.0, "episode/score": 0.1142898934040204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1142898934040204}
{"step": 71792, "time": 2551.777698993683, "episode/length": 640.0, "episode/score": 0.11939297189951503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11939297189951503}
{"step": 71792, "time": 2551.787249326706, "episode/length": 640.0, "episode/score": 0.10981535467530534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10981535467530534}
{"step": 71792, "time": 2551.7961342334747, "episode/length": 640.0, "episode/score": 0.09314494802725903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09314494802725903}
{"step": 71792, "time": 2551.8045608997345, "episode/length": 640.0, "episode/score": 0.10615607670121108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10615607670121108}
{"step": 71792, "time": 2551.8127114772797, "episode/length": 640.0, "episode/score": 0.11203511449795656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11203511449795656}
{"step": 71792, "time": 2551.82111287117, "episode/length": 640.0, "episode/score": 0.144795186272205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.144795186272205}
{"step": 75064, "time": 2654.3652172088623, "episode/length": 640.0, "episode/score": 0.1418542445165656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1418542445165656}
{"step": 75832, "time": 2678.2203302383423, "episode/length": 640.0, "episode/score": 0.10054617269000232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10054617269000232}
{"step": 76920, "time": 2712.170173406601, "episode/length": 640.0, "episode/score": 0.10557502180321876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10557502180321876}
{"step": 76920, "time": 2712.1766192913055, "episode/length": 640.0, "episode/score": 0.15426020065334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15426020065334}
{"step": 76920, "time": 2712.185776948929, "episode/length": 640.0, "episode/score": 0.14989715314106888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14989715314106888}
{"step": 76920, "time": 2712.194765329361, "episode/length": 640.0, "episode/score": 0.12307878240443415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12307878240443415}
{"step": 76920, "time": 2712.203759908676, "episode/length": 640.0, "episode/score": 0.14036361564444633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14036361564444633}
{"step": 76920, "time": 2712.2125816345215, "episode/length": 640.0, "episode/score": 0.14412440017474637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14412440017474637}
{"step": 80080, "time": 2821.6610572338104, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.67005443573, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.678309202194, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.6867158412933, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.6949598789215, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.7025949954987, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.7101459503174, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2821.71778011322, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80192, "time": 2825.2117490768433, "episode/length": 640.0, "episode/score": 0.11583127020230677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11583127020230677}
{"step": 80960, "time": 2849.2977995872498, "episode/length": 640.0, "episode/score": 0.09130307336084797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09130307336084797}
{"step": 82048, "time": 2883.4972705841064, "episode/length": 640.0, "episode/score": 0.11613204652348941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11613204652348941}
{"step": 82048, "time": 2883.50700879097, "episode/length": 640.0, "episode/score": 0.1127496157193093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1127496157193093}
{"step": 82048, "time": 2883.5162494182587, "episode/length": 640.0, "episode/score": 0.07420301126146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07420301126146}
{"step": 82048, "time": 2883.5243005752563, "episode/length": 640.0, "episode/score": 0.09368897357680339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09368897357680339}
{"step": 82048, "time": 2883.532970905304, "episode/length": 640.0, "episode/score": 0.041922865794674635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041922865794674635}
{"step": 82048, "time": 2883.541312932968, "episode/length": 640.0, "episode/score": 0.12784972598180389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12784972598180389}
{"step": 85320, "time": 2984.6652359962463, "episode/length": 640.0, "episode/score": 0.1026077789999249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1026077789999249}
{"step": 86088, "time": 3008.4479796886444, "episode/length": 640.0, "episode/score": 0.07184722097628082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07184722097628082}
{"step": 87176, "time": 3042.2182035446167, "episode/length": 640.0, "episode/score": 0.09961712240254883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09961712240254883}
{"step": 87176, "time": 3042.227100133896, "episode/length": 640.0, "episode/score": 0.06150935460954088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06150935460954088}
{"step": 87176, "time": 3042.235235452652, "episode/length": 640.0, "episode/score": 0.08999088697061097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08999088697061097}
{"step": 87176, "time": 3042.243864774704, "episode/length": 640.0, "episode/score": 0.05935490673368804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05935490673368804}
{"step": 87176, "time": 3042.2518763542175, "episode/length": 640.0, "episode/score": 0.061774415960002216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061774415960002216}
{"step": 87176, "time": 3042.2598617076874, "episode/length": 640.0, "episode/score": 0.09720104936917551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09720104936917551}
{"step": 90064, "time": 3143.9056363105774, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.9147555828094, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.92294549942, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.9303710460663, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.9378073215485, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.9452736377716, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.952527999878, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3143.9598276615143, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90448, "time": 3156.2957575321198, "episode/length": 640.0, "episode/score": 0.07163787655812826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07163787655812826}
{"step": 91216, "time": 3180.0621798038483, "episode/length": 640.0, "episode/score": 0.1754835620399149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1754835620399149}
{"step": 92304, "time": 3213.963287591934, "episode/length": 640.0, "episode/score": 0.1354489247677293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1354489247677293}
{"step": 92304, "time": 3213.9725618362427, "episode/length": 640.0, "episode/score": 0.14288874555154507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14288874555154507}
{"step": 92304, "time": 3213.980566263199, "episode/length": 640.0, "episode/score": 0.1363616821204232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1363616821204232}
{"step": 92304, "time": 3213.9886589050293, "episode/length": 640.0, "episode/score": 0.16136863435701798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16136863435701798}
{"step": 92304, "time": 3213.9968893527985, "episode/length": 640.0, "episode/score": 0.15177462169674527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15177462169674527}
{"step": 92304, "time": 3214.00519990921, "episode/length": 640.0, "episode/score": 0.09157443861266756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09157443861266756}
{"step": 93225, "time": 3243.2848019599915, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9997407578930413, "train/action_min": 0.0, "train/action_std": 1.9996547447037452, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.9991781913847e-05, "train/actor_opt_grad_steps": 4765.0, "train/actor_opt_loss": -2.040712565817323, "train/adv_mag": 0.0004127187481553284, "train/adv_max": 0.00041230979193117203, "train/adv_mean": 0.00019155877210314147, "train/adv_min": -5.676896916222326e-05, "train/adv_std": 9.615599537468857e-05, "train/cont_avg": 0.9984848179768041, "train/cont_loss_mean": 0.011430230402728524, "train/cont_loss_std": 0.2258961229748162, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.529576151459305, "train/cont_pos_acc": 0.9999999978493169, "train/cont_pos_loss": 0.00151414121351128, "train/cont_pred": 0.9984870786519394, "train/cont_rate": 0.9984848179768041, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.032436447069240905, "train/extr_critic_critic_opt_grad_steps": 4765.0, "train/extr_critic_critic_opt_loss": 11821.902263208764, "train/extr_critic_mag": 0.04723044769051149, "train/extr_critic_max": 0.04723044769051149, "train/extr_critic_mean": 0.047155264553796386, "train/extr_critic_min": 0.0470856624780242, "train/extr_critic_std": 1.9465010470446112e-05, "train/extr_return_normed_mag": 0.0007017104281592614, "train/extr_return_normed_max": 0.0007012364329751005, "train/extr_return_normed_mean": 0.0005482375336776892, "train/extr_return_normed_min": 0.00033975999379895396, "train/extr_return_normed_std": 9.197773022737537e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.04749982702286588, "train/extr_return_raw_max": 0.04749982702286588, "train/extr_return_raw_mean": 0.04734683059847232, "train/extr_return_raw_min": 0.04713835058368973, "train/extr_return_raw_std": 9.197773063524156e-05, "train/extr_reward_mag": 0.00017207246465781301, "train/extr_reward_max": 0.00017207246465781301, "train/extr_reward_mean": 0.00017192849063388908, "train/extr_reward_min": 0.0001716957878820675, "train/extr_reward_std": 5.902002355225191e-08, "train/image_loss_mean": 0.2735608362967206, "train/image_loss_std": 0.12187911520145603, "train/model_loss_mean": 0.8935453501558795, "train/model_loss_std": 0.2721823481170787, "train/model_opt_grad_norm": 64.97892851682053, "train/model_opt_grad_steps": 4755.0, "train/model_opt_loss": 183.29917254890364, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 205.38015463917526, "train/policy_entropy_mag": 1.9458976111461206, "train/policy_entropy_max": 1.9458976111461206, "train/policy_entropy_mean": 1.945282879563951, "train/policy_entropy_min": 1.935551409254369, "train/policy_entropy_std": 0.0004299822623166976, "train/policy_logprob_mag": 2.135438464351536, "train/policy_logprob_max": -1.7694174223339434, "train/policy_logprob_mean": -1.9453186448087398, "train/policy_logprob_min": -2.135438464351536, "train/policy_logprob_std": 0.03535764145943308, "train/policy_randomness_mag": 0.9999936176944024, "train/policy_randomness_max": 0.9999936176944024, "train/policy_randomness_mean": 0.9996776998657542, "train/policy_randomness_min": 0.9946767220792082, "train/policy_randomness_std": 0.0002209671783367815, "train/post_ent_mag": 45.47809262619805, "train/post_ent_max": 45.47809262619805, "train/post_ent_mean": 45.44151990438245, "train/post_ent_min": 45.31748447221579, "train/post_ent_std": 0.02922910367397918, "train/prior_ent_mag": 55.30546984721705, "train/prior_ent_max": 55.30546984721705, "train/prior_ent_mean": 55.18724917382309, "train/prior_ent_min": 55.13577496636774, "train/prior_ent_std": 0.02782359695273269, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00017109913812991058, "train/reward_loss_mean": 0.00855425897188792, "train/reward_loss_std": 0.014958772822715266, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00017202760755401296, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00855425900069171, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00017186712303208476, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.94234944631656, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007871624082326889, "report/cont_loss_std": 0.20180568099021912, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.462499618530273, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015621149213984609, "report/cont_pred": 0.9984389543533325, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2837642729282379, "report/image_loss_std": 0.13983921706676483, "report/model_loss_mean": 0.8999415636062622, "report/model_loss_std": 0.2459060102701187, "report/post_ent_mag": 43.17087936401367, "report/post_ent_max": 43.17087936401367, "report/post_ent_mean": 43.133094787597656, "report/post_ent_min": 42.84931945800781, "report/post_ent_std": 0.06459423154592514, "report/prior_ent_mag": 53.39723205566406, "report/prior_ent_max": 53.39723205566406, "report/prior_ent_mean": 53.32410430908203, "report/prior_ent_min": 53.2501335144043, "report/prior_ent_std": 0.016035791486501694, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00016602332470938563, "report/reward_loss_mean": 0.008305597119033337, "report/reward_loss_std": 0.01503898948431015, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0001691579818725586, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008305596187710762, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001691579818725586, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001562126912176609, "eval/cont_loss_std": 3.301815638678818e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001562126912176609, "eval/cont_pred": 0.9984389543533325, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24768108129501343, "eval/image_loss_std": 0.11048954725265503, "eval/model_loss_mean": 0.8503461480140686, "eval/model_loss_std": 0.11048953980207443, "eval/post_ent_mag": 43.169715881347656, "eval/post_ent_max": 43.169715881347656, "eval/post_ent_mean": 43.13462448120117, "eval/post_ent_min": 42.848907470703125, "eval/post_ent_std": 0.06317228078842163, "eval/prior_ent_mag": 53.37377166748047, "eval/prior_ent_max": 53.37377166748047, "eval/prior_ent_mean": 53.3243408203125, "eval/prior_ent_min": 53.24618911743164, "eval/prior_ent_std": 0.014860804192721844, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011029243469238281, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001691579818725586, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011029243469238281, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001691579818725586, "eval/reward_rate": 0.0, "replay/size": 92721.0, "replay/inserts": 30992.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.297531881219158e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.351651817483267e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52336.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.055169589062005e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1900703907013, "timer/env.step_count": 3874.0, "timer/env.step_total": 33.77142000198364, "timer/env.step_frac": 0.03376500227480924, "timer/env.step_avg": 0.008717454827564182, "timer/env.step_min": 0.0072400569915771484, "timer/env.step_max": 0.0349886417388916, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.36720085144043, "timer/replay._sample_frac": 0.015364280556632186, "timer/replay._sample_avg": 0.0004958441162700191, "timer/replay._sample_min": 0.0003490447998046875, "timer/replay._sample_max": 0.011429548263549805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5797.0, "timer/agent.policy_total": 56.792428970336914, "timer/agent.policy_frac": 0.056781636462509825, "timer/agent.policy_avg": 0.009796865442528361, "timer/agent.policy_min": 0.008462190628051758, "timer/agent.policy_max": 0.08619475364685059, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.19548797607421875, "timer/dataset_train_frac": 0.00019545082665923275, "timer/dataset_train_avg": 0.00010092306457109899, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.001081228256225586, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 855.1358458995819, "timer/agent.train_frac": 0.8549733407826602, "timer/agent.train_avg": 0.4414743654618389, "timer/agent.train_min": 0.43262529373168945, "timer/agent.train_max": 0.9499974250793457, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46680164337158203, "timer/agent.report_frac": 0.0004667129350616695, "timer/agent.report_avg": 0.23340082168579102, "timer/agent.report_min": 0.223618745803833, "timer/agent.report_max": 0.24318289756774902, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051177873929403e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 30.985519752955184}
{"step": 95384, "time": 3310.053442955017, "episode/length": 384.0, "episode/score": 0.08878895788734553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08878895788734553}
{"step": 95576, "time": 3316.0999059677124, "episode/length": 640.0, "episode/score": 0.06609620794154125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06609620794154125}
{"step": 96344, "time": 3339.959857940674, "episode/length": 640.0, "episode/score": 0.08515138698163582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08515138698163582}
{"step": 97432, "time": 3373.7408623695374, "episode/length": 640.0, "episode/score": 0.0950753887871656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0950753887871656}
{"step": 97432, "time": 3373.7504456043243, "episode/length": 640.0, "episode/score": 0.13369859993991895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13369859993991895}
{"step": 97432, "time": 3373.7590663433075, "episode/length": 640.0, "episode/score": 0.04747288988573928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04747288988573928}
{"step": 97432, "time": 3373.767392396927, "episode/length": 640.0, "episode/score": 0.11991931953178891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11991931953178891}
{"step": 97432, "time": 3373.775579214096, "episode/length": 640.0, "episode/score": 0.05719313478709864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05719313478709864}
{"step": 100048, "time": 3467.9352202415466, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.9441170692444, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.9526057243347, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.9604108333588, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.968341588974, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.9762642383575, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.983877658844, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3467.991693019867, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100512, "time": 3482.4581208229065, "episode/length": 640.0, "episode/score": 0.1316630150070921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1316630150070921}
{"step": 100704, "time": 3488.372949361801, "episode/length": 640.0, "episode/score": 0.087287950328232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.087287950328232}
{"step": 101472, "time": 3512.2119896411896, "episode/length": 640.0, "episode/score": 0.12148265429402727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12148265429402727}
{"step": 102560, "time": 3546.2431659698486, "episode/length": 640.0, "episode/score": 0.11564087672743995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11564087672743995}
{"step": 102560, "time": 3546.263146162033, "episode/length": 640.0, "episode/score": 0.04873380159133944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04873380159133944}
{"step": 102560, "time": 3546.270886182785, "episode/length": 640.0, "episode/score": 0.1108098428597657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1108098428597657}
{"step": 102560, "time": 3546.279159784317, "episode/length": 640.0, "episode/score": 0.05243532442250398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05243532442250398}
{"step": 102560, "time": 3546.287498474121, "episode/length": 640.0, "episode/score": 0.0950331309604735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0950331309604735}
{"step": 105640, "time": 3641.8987607955933, "episode/length": 640.0, "episode/score": 0.06553341422855397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06553341422855397}
{"step": 105832, "time": 3647.9236640930176, "episode/length": 640.0, "episode/score": 0.0862141191005037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0862141191005037}
{"step": 106600, "time": 3672.1474339962006, "episode/length": 640.0, "episode/score": 0.12165375531341738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12165375531341738}
{"step": 107688, "time": 3705.9001653194427, "episode/length": 640.0, "episode/score": 0.1322516967983347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1322516967983347}
{"step": 107688, "time": 3705.9094965457916, "episode/length": 640.0, "episode/score": 0.1253420908305145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1253420908305145}
{"step": 107688, "time": 3705.917699813843, "episode/length": 640.0, "episode/score": 0.10109881091963757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10109881091963757}
{"step": 107688, "time": 3705.9263060092926, "episode/length": 640.0, "episode/score": 0.09825279799230202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09825279799230202}
{"step": 107688, "time": 3705.9343292713165, "episode/length": 640.0, "episode/score": 0.12472869492609107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12472869492609107}
{"step": 110032, "time": 3790.085778236389, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.094674348831, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.1029381752014, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.1105284690857, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.1178815364838, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.1250035762787, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.1323330402374, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3790.1397244930267, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110768, "time": 3813.01833152771, "episode/length": 640.0, "episode/score": 0.13002955857501775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13002955857501775}
{"step": 110960, "time": 3818.9716968536377, "episode/length": 640.0, "episode/score": 0.07378646778246889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07378646778246889}
{"step": 111728, "time": 3842.697547674179, "episode/length": 640.0, "episode/score": 0.0743752371706421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0743752371706421}
{"step": 112816, "time": 3876.5973777770996, "episode/length": 640.0, "episode/score": 0.08613069994652278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08613069994652278}
{"step": 112816, "time": 3876.6067507267, "episode/length": 640.0, "episode/score": 0.08334861299334761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08334861299334761}
{"step": 112816, "time": 3876.614939928055, "episode/length": 640.0, "episode/score": 0.16248949468749174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16248949468749174}
{"step": 112816, "time": 3876.6235740184784, "episode/length": 640.0, "episode/score": 0.08552298149902526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08552298149902526}
{"step": 112816, "time": 3876.6319127082825, "episode/length": 640.0, "episode/score": 0.09996840523416495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09996840523416495}
{"step": 115896, "time": 3972.1785662174225, "episode/length": 640.0, "episode/score": 0.14063802838637685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14063802838637685}
{"step": 116088, "time": 3978.178572177887, "episode/length": 640.0, "episode/score": 0.11174636603919907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11174636603919907}
{"step": 116856, "time": 4001.8626730442047, "episode/length": 640.0, "episode/score": 0.1596832591827706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1596832591827706}
{"step": 117944, "time": 4035.6962490081787, "episode/length": 640.0, "episode/score": 0.1502695530552387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1502695530552387}
{"step": 117944, "time": 4035.7055530548096, "episode/length": 640.0, "episode/score": 0.16795452577815695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16795452577815695}
{"step": 117944, "time": 4035.7136697769165, "episode/length": 640.0, "episode/score": 0.0929002183920602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0929002183920602}
{"step": 117944, "time": 4035.7278978824615, "episode/length": 640.0, "episode/score": 0.07868809238254926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07868809238254926}
{"step": 117944, "time": 4035.735528230667, "episode/length": 640.0, "episode/score": 0.13894718908090908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13894718908090908}
{"step": 120016, "time": 4111.139211893082, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.147846221924, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.15599656105, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.163512945175, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.1707010269165, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.177834272385, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.185028553009, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4111.192085027695, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 121024, "time": 4142.275012254715, "episode/length": 640.0, "episode/score": 0.15083116916838435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15083116916838435}
{"step": 121216, "time": 4148.194832086563, "episode/length": 640.0, "episode/score": 0.15981721515902336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15981721515902336}
{"step": 121984, "time": 4171.944412231445, "episode/length": 640.0, "episode/score": 0.044623071655280455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044623071655280455}
{"step": 123072, "time": 4205.948270559311, "episode/length": 640.0, "episode/score": 0.13802585782056553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13802585782056553}
{"step": 123072, "time": 4205.956948041916, "episode/length": 640.0, "episode/score": 0.11419562308503828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11419562308503828}
{"step": 123072, "time": 4205.9651799201965, "episode/length": 640.0, "episode/score": 0.1189858107211137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1189858107211137}
{"step": 123072, "time": 4205.972998142242, "episode/length": 640.0, "episode/score": 0.12299868201981212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12299868201981212}
{"step": 123072, "time": 4205.9817497730255, "episode/length": 640.0, "episode/score": 0.061590956519069096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061590956519069096}
{"step": 124265, "time": 4244.200275182724, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0002982542686856, "train/action_min": 0.0, "train/action_std": 2.000148974128605, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.037231627171685e-05, "train/actor_opt_grad_steps": 6705.0, "train/actor_opt_loss": -4.048383490940959, "train/adv_mag": 0.0002617530870376174, "train/adv_max": 0.00025149104521446624, "train/adv_mean": 8.666890701383683e-05, "train/adv_min": -9.686868522585053e-05, "train/adv_std": 5.978543894924929e-05, "train/cont_avg": 0.9985653592139175, "train/cont_loss_mean": 0.010833955028144758, "train/cont_loss_std": 0.21199313794897492, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.485282482639436, "train/cont_pos_acc": 0.9999999966203552, "train/cont_pos_loss": 0.001553464819228315, "train/cont_pred": 0.9984477973475898, "train/cont_rate": 0.9985653592139175, "train/dyn_loss_mean": 1.001450987206292, "train/dyn_loss_std": 8.151146880898279e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02390299049282888, "train/extr_critic_critic_opt_grad_steps": 6705.0, "train/extr_critic_critic_opt_loss": 12291.749088877255, "train/extr_critic_mag": 0.05211483264706798, "train/extr_critic_max": 0.05211483264706798, "train/extr_critic_mean": 0.05203129043898631, "train/extr_critic_min": 0.051953051508087475, "train/extr_critic_std": 2.6063148634851844e-05, "train/extr_return_normed_mag": 0.00036356423395810666, "train/extr_return_normed_max": 0.0003537320599113543, "train/extr_return_normed_mean": 0.0002613116128559247, "train/extr_return_normed_min": 0.00013483645989722812, "train/extr_return_normed_std": 5.017654802706846e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.052210381773022035, "train/extr_return_raw_max": 0.052210381773022035, "train/extr_return_raw_mean": 0.05211796423362702, "train/extr_return_raw_min": 0.0519914861730079, "train/extr_return_raw_std": 5.017654825913025e-05, "train/extr_reward_mag": 0.0001700919928009977, "train/extr_reward_max": 0.0001700919928009977, "train/extr_reward_mean": 0.00017001007181909126, "train/extr_reward_min": 0.00016989351547870438, "train/extr_reward_std": 3.957750144736728e-08, "train/image_loss_mean": 0.26945308280974317, "train/image_loss_std": 0.1250118628605125, "train/model_loss_mean": 0.8896520927394789, "train/model_loss_std": 0.2632764095882165, "train/model_opt_grad_norm": 57.52017636643242, "train/model_opt_grad_steps": 6695.0, "train/model_opt_loss": 704.1096499728174, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 792.5257731958762, "train/policy_entropy_mag": 1.9458974722734432, "train/policy_entropy_max": 1.9458974722734432, "train/policy_entropy_mean": 1.9453403292243014, "train/policy_entropy_min": 1.9325502600866495, "train/policy_entropy_std": 0.0004599628434156442, "train/policy_logprob_mag": 2.1436465155218065, "train/policy_logprob_max": -1.7234273786397325, "train/policy_logprob_mean": -1.9453376666786744, "train/policy_logprob_min": -2.1436465155218065, "train/policy_logprob_std": 0.033562581189284006, "train/policy_randomness_mag": 0.999993544878419, "train/policy_randomness_max": 0.999993544878419, "train/policy_randomness_mean": 0.9997072244427868, "train/policy_randomness_min": 0.99313443438294, "train/policy_randomness_std": 0.00023637417768075409, "train/post_ent_mag": 40.26420408425872, "train/post_ent_max": 40.26420408425872, "train/post_ent_mean": 40.24055795571239, "train/post_ent_min": 40.070017883458085, "train/post_ent_std": 0.03666320969782693, "train/prior_ent_mag": 45.99295952393837, "train/prior_ent_max": 45.99295952393837, "train/prior_ent_mean": 45.95842518757299, "train/prior_ent_min": 45.83677508167385, "train/prior_ent_std": 0.024320789027152602, "train/rep_loss_mean": 1.001450987206292, "train/rep_loss_std": 8.151146880898279e-05, "train/reward_avg": 0.0001706163476256668, "train/reward_loss_mean": 0.008494438855553564, "train/reward_loss_std": 0.014968875795602798, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00017013377750042788, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008494438877156408, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016997670442749237, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9423355783025424, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014230865985155106, "report/cont_loss_std": 0.2899133563041687, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.567811965942383, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0014058554079383612, "report/cont_pred": 0.9985951781272888, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2729458808898926, "report/image_loss_std": 0.12686923146247864, "report/model_loss_mean": 0.8968330025672913, "report/model_loss_std": 0.3246539831161499, "report/post_ent_mag": 38.3680534362793, "report/post_ent_max": 38.3680534362793, "report/post_ent_mean": 38.35913848876953, "report/post_ent_min": 38.31982421875, "report/post_ent_std": 0.00851584691554308, "report/prior_ent_mag": 42.06776428222656, "report/prior_ent_max": 42.06776428222656, "report/prior_ent_mean": 42.047386169433594, "report/prior_ent_min": 41.90917205810547, "report/prior_ent_std": 0.028785374015569687, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001976474013645202, "report/reward_loss_mean": 0.009656259790062904, "report/reward_loss_std": 0.016320068389177322, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00017082691192626953, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009656259790062904, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017079536337405443, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001405855524353683, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001405855524353683, "eval/cont_pred": 0.9985951781272888, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23805168271064758, "eval/image_loss_std": 0.10436679422855377, "eval/model_loss_mean": 0.8405511379241943, "eval/model_loss_std": 0.10436682403087616, "eval/post_ent_mag": 38.3689079284668, "eval/post_ent_max": 38.3689079284668, "eval/post_ent_mean": 38.35942077636719, "eval/post_ent_min": 38.31901550292969, "eval/post_ent_std": 0.008250582963228226, "eval/prior_ent_mag": 42.0693359375, "eval/prior_ent_max": 42.0693359375, "eval/prior_ent_mean": 42.048316955566406, "eval/prior_ent_min": 41.90917205810547, "eval/prior_ent_std": 0.027671463787555695, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010936278849840164, "eval/reward_loss_std": 4.995744689040293e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00017082691192626953, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010936278849840164, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017079710960388184, "eval/reward_rate": 0.0, "replay/size": 123761.0, "replay/inserts": 31040.0, "replay/samples": 31040.0, "replay/insert_wait_avg": 1.293958462390703e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.502869905884733e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67720.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.093294244846576e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2769837379456, "timer/env.step_count": 3880.0, "timer/env.step_total": 33.77929759025574, "timer/env.step_frac": 0.033769943864973805, "timer/env.step_avg": 0.008706004533571066, "timer/env.step_min": 0.0072612762451171875, "timer/env.step_max": 0.03545880317687988, "timer/replay._sample_count": 31040.0, "timer/replay._sample_total": 15.334622144699097, "timer/replay._sample_frac": 0.015330375879883775, "timer/replay._sample_avg": 0.0004940277752802545, "timer/replay._sample_min": 0.0003371238708496094, "timer/replay._sample_max": 0.01105809211730957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5803.0, "timer/agent.policy_total": 57.300766468048096, "timer/agent.policy_frac": 0.057284899482461606, "timer/agent.policy_avg": 0.009874335079794605, "timer/agent.policy_min": 0.008479118347167969, "timer/agent.policy_max": 0.09051799774169922, "timer/dataset_train_count": 1940.0, "timer/dataset_train_total": 0.1972191333770752, "timer/dataset_train_frac": 0.0001971645220107784, "timer/dataset_train_avg": 0.00010165934710158516, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.00035452842712402344, "timer/agent.train_count": 1940.0, "timer/agent.train_total": 854.7147808074951, "timer/agent.train_frac": 0.8544781042681823, "timer/agent.train_avg": 0.44057462928221397, "timer/agent.train_min": 0.43262553215026855, "timer/agent.train_max": 0.5869624614715576, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47544002532958984, "timer/agent.report_frac": 0.00047530837263985926, "timer/agent.report_avg": 0.23772001266479492, "timer/agent.report_min": 0.2303457260131836, "timer/agent.report_max": 0.24509429931640625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931736479620422e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 31.030889742521804}
{"step": 126152, "time": 4302.314230680466, "episode/length": 640.0, "episode/score": 0.10629283336027129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10629283336027129}
{"step": 126344, "time": 4308.331418514252, "episode/length": 640.0, "episode/score": 0.05429806179898833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05429806179898833}
{"step": 127112, "time": 4331.984179258347, "episode/length": 640.0, "episode/score": 0.10135397438736504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10135397438736504}
{"step": 128200, "time": 4365.708868741989, "episode/length": 640.0, "episode/score": 0.07892391947370925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07892391947370925}
{"step": 128200, "time": 4365.718718528748, "episode/length": 640.0, "episode/score": 0.017582283273412713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017582283273412713}
{"step": 128200, "time": 4365.726781368256, "episode/length": 640.0, "episode/score": 0.06495726905617971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06495726905617971}
{"step": 128200, "time": 4365.734781265259, "episode/length": 640.0, "episode/score": 0.054186269811822285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054186269811822285}
{"step": 128200, "time": 4365.742684602737, "episode/length": 640.0, "episode/score": 0.13819203319852136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13819203319852136}
{"step": 130000, "time": 4428.779571771622, "eval_episode/length": 432.0, "eval_episode/score": 0.39250001311302185, "eval_episode/reward_rate": 0.0023094688221709007}
{"step": 130000, "time": 4432.303297758102, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.314226865768, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.322140455246, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.329781532288, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.337304353714, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.345312595367, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4432.352577447891, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 131280, "time": 4472.407874822617, "episode/length": 640.0, "episode/score": 0.10640873574264731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10640873574264731}
{"step": 131472, "time": 4478.358511686325, "episode/length": 640.0, "episode/score": 0.10317929642697266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10317929642697266}
{"step": 132240, "time": 4502.145576477051, "episode/length": 640.0, "episode/score": 0.11136028486559724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11136028486559724}
{"step": 133328, "time": 4535.713269948959, "episode/length": 640.0, "episode/score": 0.1498433293560879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1498433293560879}
{"step": 133328, "time": 4535.722285270691, "episode/length": 640.0, "episode/score": 0.07056841001316627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07056841001316627}
{"step": 133328, "time": 4535.73039150238, "episode/length": 640.0, "episode/score": 0.1477363217460379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1477363217460379}
{"step": 133328, "time": 4535.7385177612305, "episode/length": 640.0, "episode/score": 0.141850712357396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.141850712357396}
{"step": 133328, "time": 4535.746511936188, "episode/length": 640.0, "episode/score": 0.12376403529680147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12376403529680147}
{"step": 136408, "time": 4630.6437249183655, "episode/length": 640.0, "episode/score": 0.10192078446176822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10192078446176822}
{"step": 136600, "time": 4636.715805053711, "episode/length": 640.0, "episode/score": 0.09117231759205424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09117231759205424}
{"step": 137368, "time": 4660.492520570755, "episode/length": 640.0, "episode/score": 0.13152422056474222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13152422056474222}
{"step": 138456, "time": 4694.180456161499, "episode/length": 640.0, "episode/score": 0.07644562159707391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07644562159707391}
{"step": 138456, "time": 4694.1898419857025, "episode/length": 640.0, "episode/score": 0.11145945074251529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11145945074251529}
{"step": 138456, "time": 4694.198087215424, "episode/length": 640.0, "episode/score": 0.13273182230373948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13273182230373948}
{"step": 138456, "time": 4694.206351518631, "episode/length": 640.0, "episode/score": 0.09907887002913185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09907887002913185}
{"step": 138456, "time": 4694.214134216309, "episode/length": 640.0, "episode/score": 0.08525366015274471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08525366015274471}
{"step": 140088, "time": 4756.722493171692, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.731834411621, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.739825487137, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.747287750244, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.754786968231, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.7624299526215, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.769599199295, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.776809453964, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 141536, "time": 4801.6431477069855, "episode/length": 640.0, "episode/score": 0.17758019172951833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17758019172951833}
{"step": 141728, "time": 4807.568661928177, "episode/length": 640.0, "episode/score": 0.17619190848792243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17619190848792243}
{"step": 142408, "time": 4828.234849214554, "episode/length": 493.0, "episode/score": 0.1262190016805107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1262190016805107}
{"step": 142496, "time": 4831.151200771332, "episode/length": 640.0, "episode/score": 0.15885043651036312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15885043651036312}
{"step": 143584, "time": 4864.650425672531, "episode/length": 640.0, "episode/score": 0.14534796427784613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14534796427784613}
{"step": 143584, "time": 4864.659506320953, "episode/length": 640.0, "episode/score": 0.07165419952877983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07165419952877983}
{"step": 143584, "time": 4864.667625904083, "episode/length": 640.0, "episode/score": 0.08927112286130523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08927112286130523}
{"step": 143584, "time": 4864.675724744797, "episode/length": 640.0, "episode/score": 0.07028737225624582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07028737225624582}
{"step": 146664, "time": 4959.061295509338, "episode/length": 640.0, "episode/score": 0.07499179463229666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07499179463229666}
{"step": 146856, "time": 4964.988575458527, "episode/length": 640.0, "episode/score": 0.07665633274430661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07665633274430661}
{"step": 147536, "time": 4986.547452688217, "episode/length": 640.0, "episode/score": 0.1428655379579311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1428655379579311}
{"step": 147624, "time": 4989.020910978317, "episode/length": 640.0, "episode/score": 0.07908919803176673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07908919803176673}
{"step": 148712, "time": 5022.743036031723, "episode/length": 640.0, "episode/score": 0.02145872289656836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02145872289656836}
{"step": 148712, "time": 5022.752984285355, "episode/length": 640.0, "episode/score": 0.07393717464529459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07393717464529459}
{"step": 148712, "time": 5022.76150393486, "episode/length": 640.0, "episode/score": 0.07025247277744029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07025247277744029}
{"step": 148712, "time": 5022.770434379578, "episode/length": 640.0, "episode/score": 0.04477204728596007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04477204728596007}
{"step": 148720, "time": 5023.247373580933, "episode/length": 147.0, "episode/score": 0.05314927064250696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05314927064250696}
{"step": 150072, "time": 5076.263321876526, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.271799564362, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.279441356659, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.287028312683, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.294840097427, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.3019869327545, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.309036254883, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.316422224045, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 151792, "time": 5129.466817140579, "episode/length": 640.0, "episode/score": 0.13715109468557785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13715109468557785}
{"step": 151984, "time": 5135.369924783707, "episode/length": 640.0, "episode/score": 0.1313958553682255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313958553682255}
{"step": 152752, "time": 5159.037057161331, "episode/length": 640.0, "episode/score": 0.12301042714668142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12301042714668142}
{"step": 153840, "time": 5192.4727783203125, "episode/length": 640.0, "episode/score": 0.09669985418759097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09669985418759097}
{"step": 153840, "time": 5192.491225481033, "episode/length": 640.0, "episode/score": 0.11828246165737255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11828246165737255}
{"step": 153840, "time": 5192.499669313431, "episode/length": 640.0, "episode/score": 0.13539149570794962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13539149570794962}
{"step": 153840, "time": 5192.507876157761, "episode/length": 640.0, "episode/score": 0.07224239884357075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07224239884357075}
{"step": 153848, "time": 5192.544956445694, "episode/length": 640.0, "episode/score": 0.12537214607141323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12537214607141323}
{"step": 155481, "time": 5243.8168914318085, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9983461037660257, "train/action_min": 0.0, "train/action_std": 2.0000095636416706, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.221764972505088e-05, "train/actor_opt_grad_steps": 8650.0, "train/actor_opt_loss": -4.930890037463262, "train/adv_mag": 0.00022304344635743363, "train/adv_max": 0.0002040821963395828, "train/adv_mean": 4.052778889328506e-05, "train/adv_min": -0.00011504651644291022, "train/adv_std": 4.7344369899385644e-05, "train/cont_avg": 0.998417467948718, "train/cont_loss_mean": 0.011838737221506353, "train/cont_loss_std": 0.2210656766720812, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.48433130128043, "train/cont_pos_acc": 0.9999999972490164, "train/cont_pos_loss": 0.0015426734384770195, "train/cont_pred": 0.9984585603078207, "train/cont_rate": 0.998417467948718, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.022520483741297937, "train/extr_critic_critic_opt_grad_steps": 8650.0, "train/extr_critic_critic_opt_loss": 12466.688962339744, "train/extr_critic_mag": 0.05421443413465451, "train/extr_critic_max": 0.05421443413465451, "train/extr_critic_mean": 0.054135980724524226, "train/extr_critic_min": 0.054049271192306125, "train/extr_critic_std": 2.485768315186221e-05, "train/extr_return_normed_mag": 0.0002584349459562546, "train/extr_return_normed_max": 0.00022067582378020652, "train/extr_return_normed_mean": 0.00013794111262378022, "train/extr_return_normed_min": 4.56636341718527e-05, "train/extr_return_normed_std": 3.713484509728751e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05425925293029883, "train/extr_return_raw_max": 0.05425925293029883, "train/extr_return_raw_mean": 0.05417652124395737, "train/extr_return_raw_min": 0.05408424074069047, "train/extr_return_raw_std": 3.7134845570108155e-05, "train/extr_reward_mag": 0.0001690821769909981, "train/extr_reward_max": 0.0001690821769909981, "train/extr_reward_mean": 0.00016901067798384106, "train/extr_reward_min": 0.00016893729185446716, "train/extr_reward_std": 4.216794418714478e-08, "train/image_loss_mean": 0.2651408612728119, "train/image_loss_std": 0.1236819572173632, "train/model_loss_mean": 0.885370766505217, "train/model_loss_std": 0.27126900928142744, "train/model_opt_grad_norm": 49.76372486994817, "train/model_opt_grad_steps": 8639.712820512821, "train/model_opt_loss": 2076.449487930689, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2346.153846153846, "train/policy_entropy_mag": 1.9459017460162824, "train/policy_entropy_max": 1.9459017460162824, "train/policy_entropy_mean": 1.9454774398070116, "train/policy_entropy_min": 1.9376630923686884, "train/policy_entropy_std": 0.00031082487220350556, "train/policy_logprob_mag": 2.109199268389971, "train/policy_logprob_max": -1.7747534886384622, "train/policy_logprob_mean": -1.945468657444685, "train/policy_logprob_min": -2.109199268389971, "train/policy_logprob_std": 0.029399270659837967, "train/policy_randomness_mag": 0.9999957393377256, "train/policy_randomness_max": 0.9999957393377256, "train/policy_randomness_mean": 0.9997776948488676, "train/policy_randomness_min": 0.9957619089346665, "train/policy_randomness_std": 0.00015973239713229048, "train/post_ent_mag": 38.3978034386268, "train/post_ent_max": 38.3978034386268, "train/post_ent_mean": 38.389092919765375, "train/post_ent_min": 38.34452590942383, "train/post_ent_std": 0.009195655030317796, "train/prior_ent_mag": 42.06713262704702, "train/prior_ent_max": 42.06713262704702, "train/prior_ent_mean": 42.04715898953951, "train/prior_ent_min": 41.906637338491585, "train/prior_ent_std": 0.028401866860878772, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00016846574211600596, "train/reward_loss_mean": 0.00839114381860082, "train/reward_loss_std": 0.01493957715634352, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00016905894646277795, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008391143780392714, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0001689659765897653, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9422410312963991, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020573468878865242, "report/cont_loss_std": 0.352362722158432, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.521005153656006, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0014732741983607411, "report/cont_pred": 0.9985275864601135, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23418864607810974, "report/image_loss_std": 0.11857528984546661, "report/model_loss_mean": 0.8612349033355713, "report/model_loss_std": 0.3688361644744873, "report/post_ent_mag": 38.46294403076172, "report/post_ent_max": 38.46294403076172, "report/post_ent_mean": 38.45580291748047, "report/post_ent_min": 38.41099548339844, "report/post_ent_std": 0.009533355012536049, "report/prior_ent_mag": 42.06284713745117, "report/prior_ent_max": 42.06284713745117, "report/prior_ent_mean": 42.04359436035156, "report/prior_ent_min": 41.90191650390625, "report/prior_ent_std": 0.02942708320915699, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00012403810978867114, "report/reward_loss_mean": 0.006472760811448097, "report/reward_loss_std": 0.01227779220789671, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00017642974853515625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0064727612771093845, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017642974853515625, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0014732741983607411, "eval/cont_loss_std": 1.1641532182693481e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014732741983607411, "eval/cont_pred": 0.9985275864601135, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2163519412279129, "eval/image_loss_std": 0.09392104297876358, "eval/model_loss_mean": 0.8189495801925659, "eval/model_loss_std": 0.09392105787992477, "eval/post_ent_mag": 38.463321685791016, "eval/post_ent_max": 38.463321685791016, "eval/post_ent_mean": 38.45637512207031, "eval/post_ent_min": 38.41067123413086, "eval/post_ent_std": 0.008769182488322258, "eval/prior_ent_mag": 42.06271743774414, "eval/prior_ent_max": 42.06271743774414, "eval/prior_ent_mean": 42.04560852050781, "eval/prior_ent_min": 41.90191650390625, "eval/prior_ent_std": 0.027141878381371498, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011243820190429688, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00017642974853515625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011243820190429688, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017642974853515625, "eval/reward_rate": 0.0, "replay/size": 154977.0, "replay/inserts": 31216.0, "replay/samples": 31216.0, "replay/insert_wait_avg": 1.2724568207162519e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.369171930544808e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83104.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0366496851341339e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2195255756378, "timer/env.step_count": 3902.0, "timer/env.step_total": 33.47965359687805, "timer/env.step_frac": 0.03347230556972993, "timer/env.step_avg": 0.008580126498431075, "timer/env.step_min": 0.007189273834228516, "timer/env.step_max": 0.034691572189331055, "timer/replay._sample_count": 31216.0, "timer/replay._sample_total": 15.216227769851685, "timer/replay._sample_frac": 0.015212888151823041, "timer/replay._sample_avg": 0.0004874496338368684, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.011770486831665039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5825.0, "timer/agent.policy_total": 56.7434561252594, "timer/agent.policy_frac": 0.05673100221934069, "timer/agent.policy_avg": 0.00974136585841363, "timer/agent.policy_min": 0.008261680603027344, "timer/agent.policy_max": 0.08336496353149414, "timer/dataset_train_count": 1951.0, "timer/dataset_train_total": 0.19667530059814453, "timer/dataset_train_frac": 0.00019663213481556024, "timer/dataset_train_avg": 0.00010080743239269325, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0004410743713378906, "timer/agent.train_count": 1951.0, "timer/agent.train_total": 855.5819337368011, "timer/agent.train_frac": 0.855394152843001, "timer/agent.train_avg": 0.43853507623618715, "timer/agent.train_min": 0.42695116996765137, "timer/agent.train_max": 0.5773711204528809, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47285962104797363, "timer/agent.report_frac": 0.00047275583905026996, "timer/agent.report_avg": 0.23642981052398682, "timer/agent.report_min": 0.23041677474975586, "timer/agent.report_max": 0.24244284629821777, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0034147703233534e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.208623609290555}
{"step": 156920, "time": 5288.528359889984, "episode/length": 640.0, "episode/score": 0.14569441226475988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14569441226475988}
{"step": 157112, "time": 5294.439708471298, "episode/length": 640.0, "episode/score": 0.10411081098695263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10411081098695263}
{"step": 157880, "time": 5318.167010545731, "episode/length": 640.0, "episode/score": 0.11937475249547447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11937475249547447}
{"step": 158968, "time": 5352.005757570267, "episode/length": 640.0, "episode/score": 0.10663846719853609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10663846719853609}
{"step": 158968, "time": 5352.0153687000275, "episode/length": 640.0, "episode/score": 0.12827490440901101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12827490440901101}
{"step": 158968, "time": 5352.023643255234, "episode/length": 640.0, "episode/score": 0.12190574053164482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12190574053164482}
{"step": 158968, "time": 5352.032059669495, "episode/length": 640.0, "episode/score": 0.12940076024636937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12940076024636937}
{"step": 158976, "time": 5352.508869886398, "episode/length": 640.0, "episode/score": 0.08135342846873073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08135342846873073}
{"step": 160056, "time": 5396.673780441284, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.6839191913605, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.692123889923, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.699864625931, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.707499265671, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.715213537216, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.72282576561, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5396.73290848732, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 162048, "time": 5458.600106477737, "episode/length": 640.0, "episode/score": 0.13731267403312586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13731267403312586}
{"step": 162240, "time": 5464.5377423763275, "episode/length": 640.0, "episode/score": 0.07715377644458954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07715377644458954}
{"step": 163008, "time": 5488.399174213409, "episode/length": 640.0, "episode/score": 0.10671264781171885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10671264781171885}
{"step": 164096, "time": 5522.809207677841, "episode/length": 640.0, "episode/score": 0.051040110752836654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051040110752836654}
{"step": 164096, "time": 5522.819272279739, "episode/length": 640.0, "episode/score": 0.055874576311964574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055874576311964574}
{"step": 164096, "time": 5522.828324079514, "episode/length": 640.0, "episode/score": 0.05803053968008953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05803053968008953}
{"step": 164096, "time": 5522.836860656738, "episode/length": 640.0, "episode/score": 0.10371639918520259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10371639918520259}
{"step": 164104, "time": 5522.877599954605, "episode/length": 640.0, "episode/score": 0.06815848440726313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06815848440726313}
{"step": 167176, "time": 5618.113838195801, "episode/length": 640.0, "episode/score": 0.12115006351891111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12115006351891111}
{"step": 167368, "time": 5624.024109363556, "episode/length": 640.0, "episode/score": 0.14638853568725096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14638853568725096}
{"step": 168136, "time": 5647.802684545517, "episode/length": 640.0, "episode/score": 0.09799458346887491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09799458346887491}
{"step": 169224, "time": 5681.71218085289, "episode/length": 640.0, "episode/score": 0.13978316741344088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13978316741344088}
{"step": 169224, "time": 5681.7211174964905, "episode/length": 640.0, "episode/score": 0.14675635447710533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14675635447710533}
{"step": 169224, "time": 5681.729676485062, "episode/length": 640.0, "episode/score": 0.10242182516772402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10242182516772402}
{"step": 169224, "time": 5681.737684726715, "episode/length": 640.0, "episode/score": 0.16372748120974734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16372748120974734}
{"step": 169232, "time": 5682.231062173843, "episode/length": 640.0, "episode/score": 0.09814262589162581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09814262589162581}
{"step": 170040, "time": 5714.21569609642, "eval_episode/length": 396.0, "eval_episode/score": 0.44312500953674316, "eval_episode/reward_rate": 0.0025188916876574307}
{"step": 170040, "time": 5718.432756900787, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5718.441588878632, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5718.449269533157, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5718.4569845199585, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5718.464944601059, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5718.472571134567, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5718.479804992676, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 172304, "time": 5789.325854063034, "episode/length": 640.0, "episode/score": 0.1626487575771307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1626487575771307}
{"step": 172496, "time": 5795.280014038086, "episode/length": 640.0, "episode/score": 0.07841017011242002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07841017011242002}
{"step": 173264, "time": 5819.206052780151, "episode/length": 640.0, "episode/score": 0.0915057256040086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0915057256040086}
{"step": 174352, "time": 5852.958285808563, "episode/length": 640.0, "episode/score": 0.09577845942010299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09577845942010299}
{"step": 174352, "time": 5852.967664241791, "episode/length": 640.0, "episode/score": 0.16024738569939245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16024738569939245}
{"step": 174352, "time": 5852.976656675339, "episode/length": 640.0, "episode/score": 0.12591997722273618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12591997722273618}
{"step": 174352, "time": 5852.984966278076, "episode/length": 640.0, "episode/score": 0.05592278067342704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05592278067342704}
{"step": 174360, "time": 5853.02201294899, "episode/length": 640.0, "episode/score": 0.17608267217411822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17608267217411822}
{"step": 177432, "time": 5948.13872718811, "episode/length": 640.0, "episode/score": 0.047624543638136174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047624543638136174}
{"step": 177624, "time": 5954.138548135757, "episode/length": 640.0, "episode/score": 0.10305561893926551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10305561893926551}
{"step": 178392, "time": 5977.968525648117, "episode/length": 640.0, "episode/score": 0.06948376988071914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06948376988071914}
{"step": 179480, "time": 6011.659519910812, "episode/length": 640.0, "episode/score": 0.07999971818850327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07999971818850327}
{"step": 179480, "time": 6011.6692061424255, "episode/length": 640.0, "episode/score": 0.11425017705582263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11425017705582263}
{"step": 179480, "time": 6011.677523851395, "episode/length": 640.0, "episode/score": 0.03726217791560771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03726217791560771}
{"step": 179480, "time": 6011.686106443405, "episode/length": 640.0, "episode/score": 0.07845198103731832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07845198103731832}
{"step": 179488, "time": 6012.165283441544, "episode/length": 640.0, "episode/score": 0.09709948030584314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09709948030584314}
{"step": 180024, "time": 6039.951968669891, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6039.960438013077, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6039.968152999878, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6039.975914716721, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6039.983301639557, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6039.990580797195, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6039.99760055542, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.00527715683, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 182560, "time": 6119.7779858112335, "episode/length": 640.0, "episode/score": 0.08778771601677704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08778771601677704}
{"step": 182752, "time": 6125.732963085175, "episode/length": 640.0, "episode/score": 0.013363962456878653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013363962456878653}
{"step": 183520, "time": 6149.493296384811, "episode/length": 640.0, "episode/score": 0.11168210382393795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11168210382393795}
{"step": 184608, "time": 6183.310917377472, "episode/length": 640.0, "episode/score": 0.0878564465773195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0878564465773195}
{"step": 184608, "time": 6183.320237874985, "episode/length": 640.0, "episode/score": 0.1048192025600656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1048192025600656}
{"step": 184608, "time": 6183.328281402588, "episode/length": 640.0, "episode/score": 0.10359200465889273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10359200465889273}
{"step": 184608, "time": 6183.336202144623, "episode/length": 640.0, "episode/score": 0.07667475882212216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07667475882212216}
{"step": 184616, "time": 6183.372729301453, "episode/length": 640.0, "episode/score": 0.06987482932868261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06987482932868261}
{"step": 186537, "time": 6243.884878396988, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9974925247664306, "train/action_min": 0.0, "train/action_std": 2.0005525706969585, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.7427321458167876e-05, "train/actor_opt_grad_steps": 10595.0, "train/actor_opt_loss": -5.333804859328516, "train/adv_mag": 0.00026260418145312476, "train/adv_max": 0.0002207616440106913, "train/adv_mean": 1.9426243130093315e-05, "train/adv_min": -0.00018794974792249423, "train/adv_std": 6.027018982244157e-05, "train/cont_avg": 0.9983539384664949, "train/cont_loss_mean": 0.012229943263930143, "train/cont_loss_std": 0.23723700591331143, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.486347061431337, "train/cont_pos_acc": 0.9999999975420765, "train/cont_pos_loss": 0.001551189246532248, "train/cont_pred": 0.9984500604806487, "train/cont_rate": 0.9983539384664949, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021528740303072426, "train/extr_critic_critic_opt_grad_steps": 10595.0, "train/extr_critic_critic_opt_loss": 12542.03780404317, "train/extr_critic_mag": 0.05520901421910709, "train/extr_critic_max": 0.05520901421910709, "train/extr_critic_mean": 0.05509865049695231, "train/extr_critic_min": 0.05498796824327449, "train/extr_critic_std": 3.885550244231314e-05, "train/extr_return_normed_mag": 0.0002578097520415316, "train/extr_return_normed_max": 0.00019764859882212177, "train/extr_return_normed_mean": 9.483165130517329e-05, "train/extr_return_normed_min": -1.7291895046676556e-05, "train/extr_return_normed_std": 4.304106214324269e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05522088426136479, "train/extr_return_raw_max": 0.05522088426136479, "train/extr_return_raw_mean": 0.05511807068491105, "train/extr_return_raw_min": 0.05500594376749599, "train/extr_return_raw_std": 4.304106248781929e-05, "train/extr_reward_mag": 0.0001686645537307582, "train/extr_reward_max": 0.0001686645537307582, "train/extr_reward_mean": 0.0001685929258285599, "train/extr_reward_min": 0.00016847406465982654, "train/extr_reward_std": 4.752324669412395e-08, "train/image_loss_mean": 0.2615078067042164, "train/image_loss_std": 0.12473009691871319, "train/model_loss_mean": 0.8821753266545915, "train/model_loss_std": 0.2814664638687655, "train/model_opt_grad_norm": 45.156505230775814, "train/model_opt_grad_steps": 10583.030927835052, "train/model_opt_loss": 2296.5343156008375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2603.092783505155, "train/policy_entropy_mag": 1.9458991922054094, "train/policy_entropy_max": 1.9458991922054094, "train/policy_entropy_mean": 1.945378522283023, "train/policy_entropy_min": 1.9384106385339166, "train/policy_entropy_std": 0.00036325138353277, "train/policy_logprob_mag": 2.107831948811246, "train/policy_logprob_max": -1.7760884503728336, "train/policy_logprob_mean": -1.9453516270696503, "train/policy_logprob_min": -2.107831948811246, "train/policy_logprob_std": 0.032002298871880955, "train/policy_randomness_mag": 0.9999944288091561, "train/policy_randomness_max": 0.9999944288091561, "train/policy_randomness_mean": 0.9997268509619015, "train/policy_randomness_min": 0.9961460708957357, "train/policy_randomness_std": 0.00018667428395422847, "train/post_ent_mag": 39.39329412794605, "train/post_ent_max": 39.39329412794605, "train/post_ent_mean": 39.38008835389442, "train/post_ent_min": 39.340627670288086, "train/post_ent_std": 0.009233044834865122, "train/prior_ent_mag": 42.07826921128735, "train/prior_ent_max": 42.07826921128735, "train/prior_ent_mean": 42.04221041177966, "train/prior_ent_min": 41.896585661111416, "train/prior_ent_std": 0.03202985092690311, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0001695959978963767, "train/reward_loss_mean": 0.008437552952601277, "train/reward_loss_std": 0.01498602590878907, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00016856439334830058, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008437552899794327, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0001684116552459057, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9424296940366428, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007860461249947548, "report/cont_loss_std": 0.20241571962833405, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.482000827789307, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015318768564611673, "report/cont_pred": 0.998469352722168, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24418458342552185, "report/image_loss_std": 0.13840913772583008, "report/model_loss_mean": 0.8590756058692932, "report/model_loss_std": 0.2508638799190521, "report/post_ent_mag": 41.900604248046875, "report/post_ent_max": 41.900604248046875, "report/post_ent_mean": 41.844417572021484, "report/post_ent_min": 41.80669403076172, "report/post_ent_std": 0.026514291763305664, "report/prior_ent_mag": 42.14301300048828, "report/prior_ent_max": 42.14301300048828, "report/prior_ent_mean": 42.051536560058594, "report/prior_ent_min": 41.902469635009766, "report/prior_ent_std": 0.05417076125741005, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00013753995881415904, "report/reward_loss_mean": 0.007030528970062733, "report/reward_loss_std": 0.013337940908968449, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0001556873321533203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007030528504401445, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015568267554044724, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0015318011865019798, "eval/cont_loss_std": 8.258402885985561e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0015318011865019798, "eval/cont_pred": 0.9984694123268127, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24675846099853516, "eval/image_loss_std": 0.1478089839220047, "eval/model_loss_mean": 0.8492811322212219, "eval/model_loss_std": 0.14780905842781067, "eval/post_ent_mag": 41.901519775390625, "eval/post_ent_max": 41.901519775390625, "eval/post_ent_mean": 41.84904098510742, "eval/post_ent_min": 41.809226989746094, "eval/post_ent_std": 0.028448186814785004, "eval/prior_ent_mag": 42.14262390136719, "eval/prior_ent_max": 42.14262390136719, "eval/prior_ent_mean": 42.04512023925781, "eval/prior_ent_min": 41.88775634765625, "eval/prior_ent_std": 0.05438355728983879, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009908527135849, "eval/reward_loss_std": 3.3684534628264373e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001556873321533203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009908527135849, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00015568500384688377, "eval/reward_rate": 0.0, "replay/size": 186033.0, "replay/inserts": 31056.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.2818683612475624e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.269812007591566e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98488.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0394547919215352e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0503666400909, "timer/env.step_count": 3882.0, "timer/env.step_total": 33.27511739730835, "timer/env.step_frac": 0.03327344152585443, "timer/env.step_avg": 0.008571642812289632, "timer/env.step_min": 0.00721287727355957, "timer/env.step_max": 0.03473663330078125, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 15.091263771057129, "timer/replay._sample_frac": 0.015090503713087821, "timer/replay._sample_avg": 0.0004859371384291966, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.010772943496704102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5805.0, "timer/agent.policy_total": 56.733158826828, "timer/agent.policy_frac": 0.05673030151214949, "timer/agent.policy_avg": 0.009773153975336435, "timer/agent.policy_min": 0.008161306381225586, "timer/agent.policy_max": 0.08200955390930176, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.20029377937316895, "timer/dataset_train_frac": 0.00020028369175655015, "timer/dataset_train_avg": 0.00010319102492177689, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0004630088806152344, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 855.8203389644623, "timer/agent.train_frac": 0.8557772363404015, "timer/agent.train_avg": 0.4409172276993623, "timer/agent.train_min": 0.43016839027404785, "timer/agent.train_max": 1.2189099788665771, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745142459869385, "timer/agent.report_frac": 0.0004744903475023792, "timer/agent.report_avg": 0.23725712299346924, "timer/agent.report_min": 0.22993230819702148, "timer/agent.report_max": 0.244581937789917, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.19464805627207e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.053899023563382}
{"step": 187688, "time": 6279.292137145996, "episode/length": 640.0, "episode/score": 0.09401980485468187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09401980485468187}
{"step": 187880, "time": 6285.24063539505, "episode/length": 640.0, "episode/score": 0.08072579477875763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08072579477875763}
{"step": 188648, "time": 6309.459253072739, "episode/length": 640.0, "episode/score": 0.10002180370048563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10002180370048563}
{"step": 189736, "time": 6343.050688505173, "episode/length": 640.0, "episode/score": 0.08833906269056513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08833906269056513}
{"step": 189736, "time": 6343.059950590134, "episode/length": 640.0, "episode/score": 0.04561782779269663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04561782779269663}
{"step": 189736, "time": 6343.0681619644165, "episode/length": 640.0, "episode/score": 0.07403506465213638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07403506465213638}
{"step": 189736, "time": 6343.076253652573, "episode/length": 640.0, "episode/score": 0.02708873224271713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02708873224271713}
{"step": 189744, "time": 6343.550519943237, "episode/length": 640.0, "episode/score": 0.05865485095110046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05865485095110046}
{"step": 190008, "time": 6362.387579202652, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.396010160446, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.403762340546, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.411513328552, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.4192106723785, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.426657915115, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.433975458145, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.441372871399, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 192816, "time": 6449.867624282837, "episode/length": 640.0, "episode/score": 0.0693912644784973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0693912644784973}
{"step": 193008, "time": 6455.854294300079, "episode/length": 640.0, "episode/score": 0.0401697753364374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0401697753364374}
{"step": 193776, "time": 6479.783815145493, "episode/length": 640.0, "episode/score": 0.06124781527847745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06124781527847745}
{"step": 194864, "time": 6513.729332923889, "episode/length": 640.0, "episode/score": 0.08934451391814946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08934451391814946}
{"step": 194864, "time": 6513.738775014877, "episode/length": 640.0, "episode/score": 0.06572864088332153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06572864088332153}
{"step": 194864, "time": 6513.746907949448, "episode/length": 640.0, "episode/score": 0.0802825655811148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0802825655811148}
{"step": 194864, "time": 6513.755440950394, "episode/length": 640.0, "episode/score": 0.12122523529296814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12122523529296814}
{"step": 194872, "time": 6513.793334007263, "episode/length": 640.0, "episode/score": 0.11533976103510213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11533976103510213}
{"step": 197944, "time": 6609.855581521988, "episode/length": 640.0, "episode/score": 0.08268573901045784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08268573901045784}
{"step": 198136, "time": 6615.943621873856, "episode/length": 640.0, "episode/score": 0.145981196003504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.145981196003504}
{"step": 198904, "time": 6639.6982345581055, "episode/length": 640.0, "episode/score": 0.15136816717432566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15136816717432566}
{"step": 199992, "time": 6673.50078868866, "episode/length": 640.0, "episode/score": 0.14419339404400944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14419339404400944}
{"step": 199992, "time": 6673.510579586029, "episode/length": 640.0, "episode/score": 0.10727504614811778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10727504614811778}
{"step": 199992, "time": 6673.519372224808, "episode/length": 640.0, "episode/score": 0.10819336556818371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10819336556818371}
{"step": 199992, "time": 6673.528558254242, "episode/length": 640.0, "episode/score": 0.15393515226696763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15393515226696763}
{"step": 200000, "time": 6674.014654159546, "episode/length": 640.0, "episode/score": 0.14711070441308038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14711070441308038}
{"step": 200096, "time": 6689.05322933197, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.062723875046, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.070920467377, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.078731298447, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.086516618729, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.094066143036, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.1016211509705, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6689.10929107666, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 201584, "time": 6735.111232280731, "episode/length": 198.0, "episode/score": 0.048307153790233315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048307153790233315}
{"step": 203024, "time": 6779.805857181549, "episode/length": 378.0, "episode/score": 0.07936433793605602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07936433793605602}
{"step": 203072, "time": 6781.2989501953125, "episode/length": 640.0, "episode/score": 0.0711884548757098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0711884548757098}
{"step": 203264, "time": 6787.253982782364, "episode/length": 640.0, "episode/score": 0.09665538168394505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09665538168394505}
{"step": 204032, "time": 6811.126713037491, "episode/length": 640.0, "episode/score": 0.12070707702088157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12070707702088157}
{"step": 205120, "time": 6845.428406238556, "episode/length": 640.0, "episode/score": 0.03548873170444722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03548873170444722}
{"step": 205120, "time": 6845.437454938889, "episode/length": 640.0, "episode/score": 0.07569254096171107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07569254096171107}
{"step": 205128, "time": 6845.473970651627, "episode/length": 640.0, "episode/score": 0.08672463496117189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08672463496117189}
{"step": 206712, "time": 6894.730256080627, "episode/length": 640.0, "episode/score": 0.09881057435089247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09881057435089247}
{"step": 208152, "time": 6939.4035058021545, "episode/length": 640.0, "episode/score": 0.06881052290145817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06881052290145817}
{"step": 208200, "time": 6940.885457038879, "episode/length": 640.0, "episode/score": 0.03289943855983779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03289943855983779}
{"step": 208392, "time": 6946.927532911301, "episode/length": 640.0, "episode/score": 0.08124839059624378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08124839059624378}
{"step": 209160, "time": 6970.646694898605, "episode/length": 640.0, "episode/score": 0.10563920416677774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10563920416677774}
{"step": 210080, "time": 7010.543904542923, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.552561283112, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.560722589493, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.5688235759735, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.57613158226, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.583524465561, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.590667724609, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7010.597877025604, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210248, "time": 7015.658420801163, "episode/length": 640.0, "episode/score": 0.1347676045248818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1347676045248818}
{"step": 210248, "time": 7015.667963266373, "episode/length": 640.0, "episode/score": 0.1701812878971225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1701812878971225}
{"step": 210256, "time": 7016.153477191925, "episode/length": 640.0, "episode/score": 0.0832201563404169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0832201563404169}
{"step": 211840, "time": 7065.723350286484, "episode/length": 640.0, "episode/score": 0.04058132385310387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04058132385310387}
{"step": 213280, "time": 7110.819227695465, "episode/length": 640.0, "episode/score": 0.2048111449366843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2048111449366843}
{"step": 213328, "time": 7112.308251142502, "episode/length": 640.0, "episode/score": 0.25090320537083244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25090320537083244}
{"step": 213520, "time": 7118.260326862335, "episode/length": 640.0, "episode/score": 0.20081010428202717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20081010428202717}
{"step": 214288, "time": 7142.16416144371, "episode/length": 640.0, "episode/score": 0.22559020361541116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22559020361541116}
{"step": 215376, "time": 7176.020086526871, "episode/length": 640.0, "episode/score": 0.15884962317704776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15884962317704776}
{"step": 215376, "time": 7176.029005527496, "episode/length": 640.0, "episode/score": 0.12114139586481087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12114139586481087}
{"step": 215384, "time": 7176.066532611847, "episode/length": 640.0, "episode/score": 0.25190534719024527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25190534719024527}
{"step": 216968, "time": 7225.528792381287, "episode/length": 640.0, "episode/score": 0.23561831913877995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23561831913877995}
{"step": 217545, "time": 7244.274503469467, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6128071263893364, "train/action_min": 0.0, "train/action_std": 1.9252505068926467, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003528772934813103, "train/actor_opt_grad_steps": 12535.0, "train/actor_opt_loss": -1.3416486745796252, "train/adv_mag": 0.001438557199135269, "train/adv_max": 0.0014118858872307944, "train/adv_mean": 0.00027608837513833014, "train/adv_min": -0.0006772612519178194, "train/adv_std": 0.0002986946258425098, "train/cont_avg": 0.9986106636597938, "train/cont_loss_mean": 0.010555210291076759, "train/cont_loss_std": 0.2083216594592191, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.512961773495925, "train/cont_pos_acc": 0.9999999969275957, "train/cont_pos_loss": 0.0015066102442341212, "train/cont_pred": 0.9984945747041211, "train/cont_rate": 0.9986106636597938, "train/dyn_loss_mean": 1.0000036451005445, "train/dyn_loss_std": 7.602289083807431e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.047444793212373944, "train/extr_critic_critic_opt_grad_steps": 12535.0, "train/extr_critic_critic_opt_loss": 12688.441074017397, "train/extr_critic_mag": 0.057670103520462195, "train/extr_critic_max": 0.057670103520462195, "train/extr_critic_mean": 0.05730743815680755, "train/extr_critic_min": 0.056777968234622604, "train/extr_critic_std": 0.00012065982373877483, "train/extr_return_normed_mag": 0.0019428938934483479, "train/extr_return_normed_max": 0.0019062302968243963, "train/extr_return_normed_mean": 0.0009514171127565082, "train/extr_return_normed_min": 0.00011332060412033316, "train/extr_return_normed_std": 0.0002717364191319331, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05853833982087288, "train/extr_return_raw_max": 0.05853833982087288, "train/extr_return_raw_mean": 0.05758353015503932, "train/extr_return_raw_min": 0.056745430128168815, "train/extr_return_raw_std": 0.00027173642064150683, "train/extr_reward_mag": 0.00036534451946769795, "train/extr_reward_max": 0.00036534451946769795, "train/extr_reward_mean": 0.0002160045838423947, "train/extr_reward_min": 0.00011346696578350264, "train/extr_reward_std": 6.697039638243957e-05, "train/image_loss_mean": 0.24871908059132466, "train/image_loss_std": 0.12252232797213436, "train/model_loss_mean": 0.8672340945484712, "train/model_loss_std": 0.25938401328995053, "train/model_opt_grad_norm": 41.938981007054906, "train/model_opt_grad_steps": 12521.216494845361, "train/model_opt_loss": 2344.925610099871, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2706.185567010309, "train/policy_entropy_mag": 1.9170820577857421, "train/policy_entropy_max": 1.9170820577857421, "train/policy_entropy_mean": 1.8510947399532671, "train/policy_entropy_min": 1.6822051448920339, "train/policy_entropy_std": 0.024625298976070083, "train/policy_logprob_mag": 2.8969101033259914, "train/policy_logprob_max": -1.082135891330611, "train/policy_logprob_mean": -1.8510514264254225, "train/policy_logprob_min": -2.8969101033259914, "train/policy_logprob_std": 0.30819852275716275, "train/policy_randomness_mag": 0.9851853506466777, "train/policy_randomness_max": 0.9851853506466777, "train/policy_randomness_mean": 0.9512745793332759, "train/policy_randomness_min": 0.8644824869853934, "train/policy_randomness_std": 0.012654901003301834, "train/post_ent_mag": 46.12947139543356, "train/post_ent_max": 46.12947139543356, "train/post_ent_mean": 45.84214704061292, "train/post_ent_min": 45.61162364605776, "train/post_ent_std": 0.11246321180393708, "train/prior_ent_mag": 46.87373536886628, "train/prior_ent_max": 46.87373536886628, "train/prior_ent_mean": 44.48405955993023, "train/prior_ent_min": 42.89147097794051, "train/prior_ent_std": 0.7142738967980307, "train/rep_loss_mean": 1.0000036451005445, "train/rep_loss_std": 7.602289083807431e-05, "train/reward_avg": 0.00016421269013044742, "train/reward_loss_mean": 0.007957594231558368, "train/reward_loss_std": 0.014388237580580195, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0003527814579993179, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.007957594245960264, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016595822454132524, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.874451605641112, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0015181552153080702, "report/cont_loss_std": 2.744672656262992e-06, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015181552153080702, "report/cont_pred": 0.998482882976532, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.22907543182373047, "report/image_loss_std": 0.11696784198284149, "report/model_loss_mean": 0.838360071182251, "report/model_loss_std": 0.12142874300479889, "report/post_ent_mag": 46.560848236083984, "report/post_ent_max": 46.560848236083984, "report/post_ent_mean": 46.175537109375, "report/post_ent_min": 45.857906341552734, "report/post_ent_std": 0.1507117599248886, "report/prior_ent_mag": 49.94800567626953, "report/prior_ent_max": 49.94800567626953, "report/prior_ent_mean": 46.34953308105469, "report/prior_ent_min": 43.342140197753906, "report/prior_ent_std": 1.2784435749053955, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017197252600453794, "report/reward_loss_mean": 0.007766511756926775, "report/reward_loss_std": 0.014156383462250233, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0005266666412353516, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007766511756926775, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00013266806490719318, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.007854443043470383, "eval/cont_loss_std": 0.20265984535217285, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.489801406860352, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001518228673376143, "eval/cont_pred": 0.9984828233718872, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25120627880096436, "eval/image_loss_std": 0.13056309521198273, "eval/model_loss_mean": 0.8597840070724487, "eval/model_loss_std": 0.2447463572025299, "eval/post_ent_mag": 46.618736267089844, "eval/post_ent_max": 46.618736267089844, "eval/post_ent_mean": 46.165992736816406, "eval/post_ent_min": 45.86075973510742, "eval/post_ent_std": 0.14238937199115753, "eval/prior_ent_mag": 49.950775146484375, "eval/prior_ent_max": 49.950775146484375, "eval/prior_ent_mean": 46.49757766723633, "eval/prior_ent_min": 43.37451934814453, "eval/prior_ent_std": 1.3431332111358643, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0007232530042529106, "eval/reward_loss_std": 0.0009301931713707745, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0006227493286132812, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007232530042529106, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011356628965586424, "eval/reward_rate": 0.0, "replay/size": 217041.0, "replay/inserts": 31008.0, "replay/samples": 31008.0, "replay/insert_wait_avg": 1.2900499613538493e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.471617862043981e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0496058689698663e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3722009658813, "timer/env.step_count": 3876.0, "timer/env.step_total": 33.334938287734985, "timer/env.step_frac": 0.03332253560779615, "timer/env.step_avg": 0.008600345275473422, "timer/env.step_min": 0.007190704345703125, "timer/env.step_max": 0.03461456298828125, "timer/replay._sample_count": 31008.0, "timer/replay._sample_total": 15.173868179321289, "timer/replay._sample_frac": 0.015168222552236644, "timer/replay._sample_avg": 0.00048935333395644, "timer/replay._sample_min": 0.00037789344787597656, "timer/replay._sample_max": 0.022707462310791016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5799.0, "timer/agent.policy_total": 56.78871941566467, "timer/agent.policy_frac": 0.056767590463663344, "timer/agent.policy_avg": 0.009792846941828708, "timer/agent.policy_min": 0.008547306060791016, "timer/agent.policy_max": 0.08527684211730957, "timer/dataset_train_count": 1938.0, "timer/dataset_train_total": 0.20246124267578125, "timer/dataset_train_frac": 0.0002023859144429448, "timer/dataset_train_avg": 0.00010446916546737939, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0002856254577636719, "timer/agent.train_count": 1938.0, "timer/agent.train_total": 856.1849348545074, "timer/agent.train_frac": 0.8558663805609973, "timer/agent.train_avg": 0.4417878920817892, "timer/agent.train_min": 0.43198561668395996, "timer/agent.train_max": 0.5875420570373535, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4734992980957031, "timer/agent.report_frac": 0.0004733231267707451, "timer/agent.report_avg": 0.23674964904785156, "timer/agent.report_min": 0.23014426231384277, "timer/agent.report_max": 0.24335503578186035, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.384284189398077e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 30.995916909955294}
{"step": 218408, "time": 7270.820741653442, "episode/length": 640.0, "episode/score": 0.044499536643570536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044499536643570536}
{"step": 218456, "time": 7272.322649240494, "episode/length": 640.0, "episode/score": 0.16691848717880475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16691848717880475}
{"step": 218648, "time": 7278.423011302948, "episode/length": 640.0, "episode/score": 0.18448156534532245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18448156534532245}
{"step": 219416, "time": 7302.3048503398895, "episode/length": 640.0, "episode/score": 0.14406956397010617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14406956397010617}
{"step": 220064, "time": 7334.0503470897675, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.05872797966, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.0664319992065, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.073946714401, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.081501722336, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.08901143074, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.096316099167, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7334.103917837143, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220504, "time": 7347.641865968704, "episode/length": 640.0, "episode/score": 0.19982582074260336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19982582074260336}
{"step": 220504, "time": 7347.651028871536, "episode/length": 640.0, "episode/score": 0.14727880050702424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14727880050702424}
{"step": 220512, "time": 7348.129712343216, "episode/length": 640.0, "episode/score": 0.13979508247138028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13979508247138028}
{"step": 222096, "time": 7398.210639953613, "episode/length": 640.0, "episode/score": 0.12633996299337014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12633996299337014}
{"step": 223536, "time": 7442.928476572037, "episode/length": 640.0, "episode/score": 0.06156607980051376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06156607980051376}
{"step": 223584, "time": 7444.412214517593, "episode/length": 640.0, "episode/score": 0.19435168603183683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19435168603183683}
{"step": 223776, "time": 7450.348950147629, "episode/length": 640.0, "episode/score": 0.17208676255745559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17208676255745559}
{"step": 224544, "time": 7474.223504781723, "episode/length": 640.0, "episode/score": 0.09167650649311554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09167650649311554}
{"step": 225632, "time": 7507.926596164703, "episode/length": 640.0, "episode/score": 0.17895321110097484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17895321110097484}
{"step": 225632, "time": 7507.936188697815, "episode/length": 640.0, "episode/score": 0.09371448999598897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09371448999598897}
{"step": 225640, "time": 7507.973404169083, "episode/length": 640.0, "episode/score": 0.08452532420795933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08452532420795933}
{"step": 227224, "time": 7557.209743738174, "episode/length": 640.0, "episode/score": 0.146860567518047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.146860567518047}
{"step": 228664, "time": 7601.892294883728, "episode/length": 640.0, "episode/score": 0.13903367163558755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13903367163558755}
{"step": 228712, "time": 7603.386403083801, "episode/length": 640.0, "episode/score": 0.14531995473421944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14531995473421944}
{"step": 228904, "time": 7609.392919301987, "episode/length": 640.0, "episode/score": 0.10824180703795605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10824180703795605}
{"step": 229672, "time": 7633.601332187653, "episode/length": 640.0, "episode/score": 0.15890993721188806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15890993721188806}
{"step": 230048, "time": 7657.189190387726, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.197817802429, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.205494642258, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.212914943695, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.220014333725, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.227232694626, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.234485626221, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7657.242405414581, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230760, "time": 7679.040328264236, "episode/length": 640.0, "episode/score": 0.032280645487162474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032280645487162474}
{"step": 230760, "time": 7679.05077791214, "episode/length": 640.0, "episode/score": 0.13703048477958646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13703048477958646}
{"step": 230768, "time": 7679.5286700725555, "episode/length": 640.0, "episode/score": 0.03238264897882459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03238264897882459}
{"step": 232352, "time": 7728.679047584534, "episode/length": 640.0, "episode/score": 0.166435887223372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166435887223372}
{"step": 233792, "time": 7773.403252363205, "episode/length": 640.0, "episode/score": 0.21025615124864316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21025615124864316}
{"step": 233840, "time": 7774.9094223976135, "episode/length": 640.0, "episode/score": 0.20483871377049923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20483871377049923}
{"step": 234032, "time": 7780.916605949402, "episode/length": 640.0, "episode/score": 0.14680075999083897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14680075999083897}
{"step": 234800, "time": 7804.756806612015, "episode/length": 640.0, "episode/score": 0.17625798800119696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17625798800119696}
{"step": 235888, "time": 7838.5463943481445, "episode/length": 640.0, "episode/score": 0.19584495132531288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19584495132531288}
{"step": 235888, "time": 7838.555773496628, "episode/length": 640.0, "episode/score": 0.146041737007522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.146041737007522}
{"step": 235896, "time": 7838.593336343765, "episode/length": 640.0, "episode/score": 0.07494511832965145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07494511832965145}
{"step": 237480, "time": 7887.886696338654, "episode/length": 640.0, "episode/score": 0.1443098217042973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1443098217042973}
{"step": 238920, "time": 7933.032921552658, "episode/length": 640.0, "episode/score": 0.18961315245056198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18961315245056198}
{"step": 238968, "time": 7934.526150226593, "episode/length": 640.0, "episode/score": 0.11631134514738051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11631134514738051}
{"step": 239160, "time": 7940.549664258957, "episode/length": 640.0, "episode/score": 0.19274560133860064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19274560133860064}
{"step": 239928, "time": 7964.543742418289, "episode/length": 640.0, "episode/score": 0.09470255265202354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09470255265202354}
{"step": 240032, "time": 7979.53230714798, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.541177272797, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.549193143845, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.557134151459, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.565021038055, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.572297811508, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.57999253273, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7979.587893247604, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 241016, "time": 8009.9569408893585, "episode/length": 640.0, "episode/score": 0.2114087961726625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2114087961726625}
{"step": 241016, "time": 8009.968787908554, "episode/length": 640.0, "episode/score": 0.1763078990115332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1763078990115332}
{"step": 241024, "time": 8010.455646038055, "episode/length": 640.0, "episode/score": 0.2143413982203981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2143413982203981}
{"step": 242608, "time": 8059.637944221497, "episode/length": 640.0, "episode/score": 0.2117787945041414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2117787945041414}
{"step": 244048, "time": 8104.344016313553, "episode/length": 640.0, "episode/score": 0.25434259392346803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25434259392346803}
{"step": 244096, "time": 8105.832770586014, "episode/length": 640.0, "episode/score": 0.2090847281809829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2090847281809829}
{"step": 244288, "time": 8111.794537782669, "episode/length": 640.0, "episode/score": 0.22237086087648095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22237086087648095}
{"step": 245056, "time": 8135.6694939136505, "episode/length": 640.0, "episode/score": 0.23952536683759718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23952536683759718}
{"step": 246144, "time": 8170.069243192673, "episode/length": 640.0, "episode/score": 0.14421542757963834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14421542757963834}
{"step": 246144, "time": 8170.081825256348, "episode/length": 640.0, "episode/score": 0.21388853184498657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21388853184498657}
{"step": 246152, "time": 8170.121243476868, "episode/length": 640.0, "episode/score": 0.27517652261144576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27517652261144576}
{"step": 247736, "time": 8219.50886464119, "episode/length": 640.0, "episode/score": 0.1797156917618281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1797156917618281}
{"step": 248505, "time": 8244.544107437134, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1203078828327397, "train/action_min": 0.0, "train/action_std": 1.8265695244537117, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00034799126560897494, "train/actor_opt_grad_steps": 14470.0, "train/actor_opt_loss": -1.0813258334492464, "train/adv_mag": 0.0023842771667890597, "train/adv_max": 0.0023389308100537315, "train/adv_mean": 0.0003028410300904148, "train/adv_min": -0.001619538572168103, "train/adv_std": 0.0004984342622500723, "train/cont_avg": 0.9983960087435233, "train/cont_loss_mean": 0.011938649522854797, "train/cont_loss_std": 0.2305824258160555, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.47020420121269, "train/cont_pos_acc": 0.9999999969116764, "train/cont_pos_loss": 0.001566803817506976, "train/cont_pred": 0.9984344559012299, "train/cont_rate": 0.9983960087435233, "train/dyn_loss_mean": 1.000001883259709, "train/dyn_loss_std": 4.174337227784466e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02501427095083018, "train/extr_critic_critic_opt_grad_steps": 14470.0, "train/extr_critic_critic_opt_loss": 13461.944128481218, "train/extr_critic_mag": 0.07501052080658434, "train/extr_critic_max": 0.07501052080658434, "train/extr_critic_mean": 0.07426206431703863, "train/extr_critic_min": 0.0729918646688906, "train/extr_critic_std": 0.00025505883493424523, "train/extr_return_normed_mag": 0.0034227565394164368, "train/extr_return_normed_max": 0.0034227565394164368, "train/extr_return_normed_mean": 0.0014117573093263423, "train/extr_return_normed_min": -0.00034526824333507163, "train/extr_return_normed_std": 0.0005091071191275193, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0765759290963257, "train/extr_return_raw_max": 0.0765759290963257, "train/extr_return_raw_mean": 0.07456493420149995, "train/extr_return_raw_min": 0.07280790431357419, "train/extr_return_raw_std": 0.000509107121389475, "train/extr_reward_mag": 0.0008087226146243397, "train/extr_reward_max": 0.0008087226146243397, "train/extr_reward_mean": 0.0002816552197508794, "train/extr_reward_min": 5.3878892888676936e-06, "train/extr_reward_std": 0.00021563982002924492, "train/image_loss_mean": 0.2357547902381482, "train/image_loss_std": 0.11929836433014104, "train/model_loss_mean": 0.8554488794173601, "train/model_loss_std": 0.2736543620034203, "train/model_opt_grad_norm": 38.1941390534242, "train/model_opt_grad_steps": 14454.60103626943, "train/model_opt_loss": 2551.423016009553, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 2966.321243523316, "train/policy_entropy_mag": 1.9025485466181304, "train/policy_entropy_max": 1.9025485466181304, "train/policy_entropy_mean": 1.7459489891566142, "train/policy_entropy_min": 1.4126109873074941, "train/policy_entropy_std": 0.05532102939223996, "train/policy_logprob_mag": 3.29898454982382, "train/policy_logprob_max": -0.5616870402054466, "train/policy_logprob_mean": -1.7457910979967661, "train/policy_logprob_min": -3.29898454982382, "train/policy_logprob_std": 0.6232304844831555, "train/policy_randomness_mag": 0.9777166025008562, "train/policy_randomness_max": 0.9777166025008562, "train/policy_randomness_mean": 0.897240341327351, "train/policy_randomness_min": 0.7259384884735464, "train/policy_randomness_std": 0.028429386876716516, "train/post_ent_mag": 44.602531531931824, "train/post_ent_max": 44.602531531931824, "train/post_ent_mean": 44.28864766649632, "train/post_ent_min": 44.04820034046865, "train/post_ent_std": 0.10498874877709799, "train/prior_ent_mag": 46.94005391017143, "train/prior_ent_max": 46.94005391017143, "train/prior_ent_mean": 44.03449980582598, "train/prior_ent_min": 41.367480974740936, "train/prior_ent_std": 0.9877782692563348, "train/rep_loss_mean": 1.000001883259709, "train/rep_loss_std": 4.174337227784466e-05, "train/reward_avg": 0.00017258405584089187, "train/reward_loss_mean": 0.007754287680060906, "train/reward_loss_std": 0.013744788244366646, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007515966583410076, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.007754287672822649, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00017247215357314737, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7319417943557103, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.001735713449306786, "report/cont_loss_std": 1.1641532182693481e-10, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001735713449306786, "report/cont_pred": 0.9982659816741943, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23272600769996643, "report/image_loss_std": 0.12639419734477997, "report/model_loss_mean": 0.8429157733917236, "report/model_loss_std": 0.13158291578292847, "report/post_ent_mag": 41.319175720214844, "report/post_ent_max": 41.319175720214844, "report/post_ent_mean": 41.075286865234375, "report/post_ent_min": 40.76832580566406, "report/post_ent_std": 0.09327992796897888, "report/prior_ent_mag": 43.41701126098633, "report/prior_ent_max": 43.41701126098633, "report/prior_ent_mean": 40.644065856933594, "report/prior_ent_min": 38.527286529541016, "report/prior_ent_std": 0.8203336000442505, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019093086302746087, "report/reward_loss_mean": 0.00845404900610447, "report/reward_loss_std": 0.01504477858543396, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.000687718391418457, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00845404900610447, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00014571286737918854, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001735713449306786, "eval/cont_loss_std": 1.1641532182693481e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001735713449306786, "eval/cont_pred": 0.9982659816741943, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2296869158744812, "eval/image_loss_std": 0.13280218839645386, "eval/model_loss_mean": 0.8322148323059082, "eval/model_loss_std": 0.1328323483467102, "eval/post_ent_mag": 41.304901123046875, "eval/post_ent_max": 41.304901123046875, "eval/post_ent_mean": 41.0562858581543, "eval/post_ent_min": 40.81804656982422, "eval/post_ent_std": 0.0875353217124939, "eval/prior_ent_mag": 42.833465576171875, "eval/prior_ent_max": 42.833465576171875, "eval/prior_ent_mean": 40.79667663574219, "eval/prior_ent_min": 38.625057220458984, "eval/prior_ent_std": 0.8227908611297607, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0007922099903225899, "eval/reward_loss_std": 0.001090363715775311, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0006985664367675781, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007922099903225899, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00012454262468963861, "eval/reward_rate": 0.0, "replay/size": 248001.0, "replay/inserts": 30960.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.298988512320112e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.296707404676334e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0451889881167756e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2526330947876, "timer/env.step_count": 3870.0, "timer/env.step_total": 33.36599540710449, "timer/env.step_frac": 0.03335756818142023, "timer/env.step_avg": 0.008621704239561885, "timer/env.step_min": 0.007241725921630859, "timer/env.step_max": 0.03394889831542969, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.173223972320557, "timer/replay._sample_frac": 0.015169391681953899, "timer/replay._sample_avg": 0.0004900912135762453, "timer/replay._sample_min": 0.0003800392150878906, "timer/replay._sample_max": 0.010582923889160156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5793.0, "timer/agent.policy_total": 57.10934495925903, "timer/agent.policy_frac": 0.05709492089269726, "timer/agent.policy_avg": 0.009858336778743143, "timer/agent.policy_min": 0.008442401885986328, "timer/agent.policy_max": 0.08453893661499023, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.2044684886932373, "timer/dataset_train_frac": 0.00020441684623274682, "timer/dataset_train_avg": 0.00010566846960890816, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0003294944763183594, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 855.6154735088348, "timer/agent.train_frac": 0.8553993713183793, "timer/agent.train_avg": 0.4421785392810516, "timer/agent.train_min": 0.4323570728302002, "timer/agent.train_max": 0.5891306400299072, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4659850597381592, "timer/agent.report_frac": 0.00046586736622366957, "timer/agent.report_avg": 0.2329925298690796, "timer/agent.report_min": 0.22226428985595703, "timer/agent.report_max": 0.24372076988220215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265509557905734e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 30.951619426995144}
{"step": 249176, "time": 8265.1847012043, "episode/length": 640.0, "episode/score": 0.2022857567502001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2022857567502001}
{"step": 249224, "time": 8266.74299621582, "episode/length": 640.0, "episode/score": 0.24562645849368892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24562645849368892}
{"step": 249416, "time": 8272.724540948868, "episode/length": 640.0, "episode/score": 0.22581336111772998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22581336111772998}
{"step": 250016, "time": 8303.042387485504, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.051010131836, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.058827161789, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.0664498806, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.073897838593, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.081342935562, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.088601112366, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8303.096068620682, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250184, "time": 8309.02271604538, "episode/length": 640.0, "episode/score": 0.17223368076781753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17223368076781753}
{"step": 251272, "time": 8342.75685286522, "episode/length": 640.0, "episode/score": 0.203600834957399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.203600834957399}
{"step": 251272, "time": 8342.766262054443, "episode/length": 640.0, "episode/score": 0.18499348053734366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18499348053734366}
{"step": 251280, "time": 8343.245261907578, "episode/length": 640.0, "episode/score": 0.20979742530761314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20979742530761314}
{"step": 252864, "time": 8392.548210859299, "episode/length": 640.0, "episode/score": 0.21042475654462578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21042475654462578}
{"step": 254304, "time": 8438.202966451645, "episode/length": 640.0, "episode/score": 0.1777084771732973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1777084771732973}
{"step": 254352, "time": 8439.71224617958, "episode/length": 640.0, "episode/score": 0.20439443981928207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20439443981928207}
{"step": 254544, "time": 8445.745811223984, "episode/length": 640.0, "episode/score": 0.156192816298784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.156192816298784}
{"step": 255312, "time": 8469.48103427887, "episode/length": 640.0, "episode/score": 0.08285420295817403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08285420295817403}
{"step": 256400, "time": 8503.46729516983, "episode/length": 640.0, "episode/score": 0.2348777078196349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2348777078196349}
{"step": 256400, "time": 8503.476521492004, "episode/length": 640.0, "episode/score": 0.13604991152880075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13604991152880075}
{"step": 256408, "time": 8503.51294541359, "episode/length": 640.0, "episode/score": 0.15273227174310477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15273227174310477}
{"step": 257992, "time": 8552.98381614685, "episode/length": 640.0, "episode/score": 0.18332465896079952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18332465896079952}
{"step": 259432, "time": 8597.880243778229, "episode/length": 640.0, "episode/score": 0.18630224692500974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18630224692500974}
{"step": 259480, "time": 8599.379871368408, "episode/length": 640.0, "episode/score": 0.1862169047734028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1862169047734028}
{"step": 259672, "time": 8605.32329583168, "episode/length": 640.0, "episode/score": 0.22659312599040504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22659312599040504}
{"step": 260000, "time": 8627.21313214302, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.221396684647, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.22885131836, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.236390829086, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.243572235107, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.25090456009, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.25854587555, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8627.26568889618, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260440, "time": 8640.658504486084, "episode/length": 640.0, "episode/score": 0.2268441596762898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2268441596762898}
{"step": 261528, "time": 8674.392879962921, "episode/length": 640.0, "episode/score": 0.1875816727362576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1875816727362576}
{"step": 261528, "time": 8674.402578830719, "episode/length": 640.0, "episode/score": 0.22224693666512962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22224693666512962}
{"step": 261536, "time": 8674.875617742538, "episode/length": 640.0, "episode/score": 0.13849984905138513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13849984905138513}
{"step": 263120, "time": 8724.843112707138, "episode/length": 640.0, "episode/score": 0.22876762321965316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22876762321965316}
{"step": 264416, "time": 8765.274442911148, "episode/length": 360.0, "episode/score": 0.12696162235715747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12696162235715747}
{"step": 264560, "time": 8769.78025650978, "episode/length": 640.0, "episode/score": 0.11065837998330608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11065837998330608}
{"step": 264608, "time": 8771.294963359833, "episode/length": 640.0, "episode/score": 0.2375707190568619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2375707190568619}
{"step": 264800, "time": 8777.336024522781, "episode/length": 640.0, "episode/score": 0.18511870086331328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18511870086331328}
{"step": 265568, "time": 8801.217000722885, "episode/length": 640.0, "episode/score": 0.17064103159827937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17064103159827937}
{"step": 266656, "time": 8835.17712020874, "episode/length": 640.0, "episode/score": 0.07646390488525867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07646390488525867}
{"step": 266664, "time": 8835.214568138123, "episode/length": 640.0, "episode/score": 0.054229105725312365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054229105725312365}
{"step": 268248, "time": 8884.490844964981, "episode/length": 640.0, "episode/score": 0.2201077064302126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2201077064302126}
{"step": 269544, "time": 8924.669982910156, "episode/length": 640.0, "episode/score": 0.10030581122828153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10030581122828153}
{"step": 269688, "time": 8929.208800792694, "episode/length": 640.0, "episode/score": 0.24981179345354576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24981179345354576}
{"step": 269736, "time": 8930.714787006378, "episode/length": 640.0, "episode/score": 0.2240967844586521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2240967844586521}
{"step": 269928, "time": 8936.689221382141, "episode/length": 640.0, "episode/score": 0.08689971560761478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08689971560761478}
{"step": 270088, "time": 8946.192712306976, "eval_episode/length": 263.0, "eval_episode/score": 0.6301562786102295, "eval_episode/reward_rate": 0.003787878787878788}
{"step": 270088, "time": 8952.599609375, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8952.60846042633, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8952.616340875626, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8952.623849868774, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8952.631360530853, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8952.642108917236, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8952.648965835571, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270696, "time": 8972.109166145325, "episode/length": 640.0, "episode/score": 0.2455499979881779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2455499979881779}
{"step": 271784, "time": 9005.877369642258, "episode/length": 640.0, "episode/score": 0.11307754278317361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11307754278317361}
{"step": 271792, "time": 9006.373971223831, "episode/length": 640.0, "episode/score": 0.20411383850995435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20411383850995435}
{"step": 273376, "time": 9055.591611862183, "episode/length": 640.0, "episode/score": 0.15404206155807287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15404206155807287}
{"step": 274672, "time": 9096.02725815773, "episode/length": 640.0, "episode/score": 0.2269487609677867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2269487609677867}
{"step": 274816, "time": 9100.450288534164, "episode/length": 640.0, "episode/score": 0.2855313652545419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2855313652545419}
{"step": 274864, "time": 9101.950113534927, "episode/length": 640.0, "episode/score": 0.10839351536185404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10839351536185404}
{"step": 275056, "time": 9107.972677230835, "episode/length": 640.0, "episode/score": 0.11358752236452574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11358752236452574}
{"step": 275824, "time": 9131.958899497986, "episode/length": 640.0, "episode/score": 0.11478340780485041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11478340780485041}
{"step": 276912, "time": 9166.212713003159, "episode/length": 640.0, "episode/score": 0.06791614454567707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06791614454567707}
{"step": 276920, "time": 9166.249974489212, "episode/length": 640.0, "episode/score": 0.11526600457682434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11526600457682434}
{"step": 278504, "time": 9215.326594114304, "episode/length": 640.0, "episode/score": 0.24440318727567956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24440318727567956}
{"step": 279401, "time": 9244.578521490097, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.149535184079501, "train/action_min": 0.0, "train/action_std": 1.8511608906978152, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00029624273280921956, "train/actor_opt_grad_steps": 16400.0, "train/actor_opt_loss": -4.0499588943670455, "train/adv_mag": 0.002111003574929707, "train/adv_max": 0.001966591712106695, "train/adv_mean": 0.0001201462526760554, "train/adv_min": -0.0017982730207665597, "train/adv_std": 0.00045497943387834904, "train/cont_avg": 0.9983605893782384, "train/cont_loss_mean": 0.012148231003732647, "train/cont_loss_std": 0.2247664291520356, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.449241544686112, "train/cont_pos_acc": 0.9999999962940117, "train/cont_pos_loss": 0.0015989325342246287, "train/cont_pred": 0.9984023953966527, "train/cont_rate": 0.9983605893782384, "train/dyn_loss_mean": 1.0002785284902147, "train/dyn_loss_std": 0.00017456001223009466, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.016347131821407738, "train/extr_critic_critic_opt_grad_steps": 16400.0, "train/extr_critic_critic_opt_loss": 13547.97114839702, "train/extr_critic_mag": 0.08141180208927609, "train/extr_critic_max": 0.08141180208927609, "train/extr_critic_mean": 0.08054145935131478, "train/extr_critic_min": 0.0792813795218196, "train/extr_critic_std": 0.00027095702403059734, "train/extr_return_normed_mag": 0.00291019272773377, "train/extr_return_normed_max": 0.0029095305139536683, "train/extr_return_normed_mean": 0.0009903020792914592, "train/extr_return_normed_min": -0.0007881071283409632, "train/extr_return_normed_std": 0.00047634314888017013, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08258080787454862, "train/extr_return_raw_max": 0.08258080787454862, "train/extr_return_raw_mean": 0.08066158452182236, "train/extr_return_raw_min": 0.07888317023225398, "train/extr_return_raw_std": 0.00047634315084053175, "train/extr_reward_mag": 0.0007697615598767532, "train/extr_reward_max": 0.0007697615598767532, "train/extr_reward_mean": 0.0002722074101266446, "train/extr_reward_min": 4.324888318313836e-06, "train/extr_reward_std": 0.00021798930281997597, "train/image_loss_mean": 0.23768327389047553, "train/image_loss_std": 0.1207620473337297, "train/model_loss_mean": 0.8582873492660917, "train/model_loss_std": 0.2731278185476911, "train/model_opt_grad_norm": 37.00381825007305, "train/model_opt_grad_steps": 16382.865284974094, "train/model_opt_loss": 2257.2760743452477, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2629.5336787564765, "train/policy_entropy_mag": 1.9136587924907862, "train/policy_entropy_max": 1.9136587924907862, "train/policy_entropy_mean": 1.7782227511233, "train/policy_entropy_min": 1.4983068327829627, "train/policy_entropy_std": 0.048881929652485515, "train/policy_logprob_mag": 3.2582545255749955, "train/policy_logprob_max": -0.6483399827863269, "train/policy_logprob_mean": -1.7782294076959086, "train/policy_logprob_min": -3.2582545255749955, "train/policy_logprob_std": 0.5720275980203263, "train/policy_randomness_mag": 0.9834261385270351, "train/policy_randomness_max": 0.9834261385270351, "train/policy_randomness_mean": 0.9138257812341878, "train/policy_randomness_min": 0.7699774438853091, "train/policy_randomness_std": 0.025120344215646927, "train/post_ent_mag": 37.32437855221447, "train/post_ent_max": 37.32437855221447, "train/post_ent_mean": 37.1459160641685, "train/post_ent_min": 36.98763439198232, "train/post_ent_std": 0.05725518038370912, "train/prior_ent_mag": 39.411906860035316, "train/prior_ent_max": 39.411906860035316, "train/prior_ent_mean": 37.37204772079547, "train/prior_ent_min": 36.10380852654808, "train/prior_ent_std": 0.5129181287526466, "train/rep_loss_mean": 1.0002785284902147, "train/rep_loss_std": 0.00017456001223009466, "train/reward_avg": 0.00018548775630776283, "train/reward_loss_mean": 0.008288705096594564, "train/reward_loss_std": 0.014033873922582426, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007353156341789917, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008288705096594564, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00018349128119029838, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7784626732269924, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02077304944396019, "report/cont_loss_std": 0.3593297004699707, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.64973258972168, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001295206369832158, "report/cont_pred": 0.9987058043479919, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23654985427856445, "report/image_loss_std": 0.11778652667999268, "report/model_loss_mean": 0.8660855293273926, "report/model_loss_std": 0.377920538187027, "report/post_ent_mag": 35.26556396484375, "report/post_ent_max": 35.26556396484375, "report/post_ent_mean": 35.15428924560547, "report/post_ent_min": 35.07341003417969, "report/post_ent_std": 0.03221360221505165, "report/prior_ent_mag": 36.676265716552734, "report/prior_ent_max": 36.676265716552734, "report/prior_ent_mean": 35.368370056152344, "report/prior_ent_min": 34.703556060791016, "report/prior_ent_std": 0.3110596537590027, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019936449825763702, "report/reward_loss_mean": 0.008762611076235771, "report/reward_loss_std": 0.014950974844396114, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0007375478744506836, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008762611076235771, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017159932758659124, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001295206369832158, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001295206369832158, "eval/cont_pred": 0.9987058043479919, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2296798676252365, "eval/image_loss_std": 0.11571276932954788, "eval/model_loss_mean": 0.8318623304367065, "eval/model_loss_std": 0.11585842818021774, "eval/post_ent_mag": 35.24839401245117, "eval/post_ent_max": 35.24839401245117, "eval/post_ent_mean": 35.152645111083984, "eval/post_ent_min": 35.07347869873047, "eval/post_ent_std": 0.03078712522983551, "eval/prior_ent_mag": 36.5050048828125, "eval/prior_ent_max": 36.5050048828125, "eval/prior_ent_mean": 35.42554473876953, "eval/prior_ent_min": 34.721473693847656, "eval/prior_ent_std": 0.30936020612716675, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0008872682228684425, "eval/reward_loss_std": 0.0011510043404996395, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0006985664367675781, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008872682228684425, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00013951852452009916, "eval/reward_rate": 0.0, "replay/size": 278897.0, "replay/inserts": 30896.0, "replay/samples": 30896.0, "replay/insert_wait_avg": 1.2858212765852199e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.332324852293974e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0000128207948143e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0185465812683, "timer/env.step_count": 3862.0, "timer/env.step_total": 33.22346353530884, "timer/env.step_frac": 0.03322284736507022, "timer/env.step_avg": 0.008602657569991932, "timer/env.step_min": 0.007219791412353516, "timer/env.step_max": 0.03464221954345703, "timer/replay._sample_count": 30896.0, "timer/replay._sample_total": 15.207000494003296, "timer/replay._sample_frac": 0.015206718461363528, "timer/replay._sample_avg": 0.0004921996534827582, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.0286712646484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5785.0, "timer/agent.policy_total": 57.32558226585388, "timer/agent.policy_frac": 0.057324519092001876, "timer/agent.policy_avg": 0.009909348706284163, "timer/agent.policy_min": 0.00851583480834961, "timer/agent.policy_max": 0.13665056228637695, "timer/dataset_train_count": 1931.0, "timer/dataset_train_total": 0.20498919486999512, "timer/dataset_train_frac": 0.00020498539309174332, "timer/dataset_train_avg": 0.00010615701443293378, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.000263214111328125, "timer/agent.train_count": 1931.0, "timer/agent.train_total": 855.8038382530212, "timer/agent.train_frac": 0.8557879663119556, "timer/agent.train_avg": 0.44319204466754075, "timer/agent.train_min": 0.4326040744781494, "timer/agent.train_max": 1.364091157913208, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47427892684936523, "timer/agent.report_frac": 0.00047427013075984197, "timer/agent.report_avg": 0.23713946342468262, "timer/agent.report_min": 0.23223137855529785, "timer/agent.report_max": 0.24204754829406738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8848113037416176e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 30.89489515664479}
{"step": 279800, "time": 9256.760243654251, "episode/length": 640.0, "episode/score": 0.2303418222485334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2303418222485334}
{"step": 279944, "time": 9261.21856045723, "episode/length": 640.0, "episode/score": 0.13012576728999647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13012576728999647}
{"step": 279992, "time": 9262.748002290726, "episode/length": 640.0, "episode/score": 0.21014263706194924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21014263706194924}
{"step": 280072, "time": 9273.919132947922, "eval_episode/length": 459.0, "eval_episode/score": 0.35453125834465027, "eval_episode/reward_rate": 0.002173913043478261}
{"step": 280072, "time": 9276.970224618912, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9276.979148864746, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9276.986804485321, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9276.994459152222, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9277.001898765564, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9277.009109973907, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9277.016243457794, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280184, "time": 9280.509771347046, "episode/length": 640.0, "episode/score": 0.23532961990770218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23532961990770218}
{"step": 280952, "time": 9304.328820228577, "episode/length": 640.0, "episode/score": 0.11762425275162514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11762425275162514}
{"step": 282040, "time": 9338.195842504501, "episode/length": 640.0, "episode/score": 0.24702971997339773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24702971997339773}
{"step": 282048, "time": 9338.678079366684, "episode/length": 640.0, "episode/score": 0.1210754344444922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1210754344444922}
{"step": 283632, "time": 9387.96457695961, "episode/length": 640.0, "episode/score": 0.1997642466020011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1997642466020011}
{"step": 284928, "time": 9428.456740617752, "episode/length": 640.0, "episode/score": 0.209701967768126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.209701967768126}
{"step": 285072, "time": 9433.028574466705, "episode/length": 640.0, "episode/score": 0.10097035244115204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10097035244115204}
{"step": 285120, "time": 9434.559229135513, "episode/length": 640.0, "episode/score": 0.19385690915152054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19385690915152054}
{"step": 285312, "time": 9440.728487730026, "episode/length": 640.0, "episode/score": 0.272480637188778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.272480637188778}
{"step": 286080, "time": 9464.535916805267, "episode/length": 640.0, "episode/score": 0.1262613263888852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1262613263888852}
{"step": 287168, "time": 9498.935349225998, "episode/length": 640.0, "episode/score": 0.23486073310505162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23486073310505162}
{"step": 287176, "time": 9498.972772836685, "episode/length": 640.0, "episode/score": 0.19208483815253885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19208483815253885}
{"step": 288760, "time": 9548.057221651077, "episode/length": 640.0, "episode/score": 0.2064524929394338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2064524929394338}
{"step": 290056, "time": 9588.245613098145, "episode/length": 640.0, "episode/score": 0.1911956065700906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1911956065700906}
{"step": 290056, "time": 9599.124465227127, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.132882356644, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.140469551086, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.14845943451, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.155637741089, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.163146972656, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.170127630234, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9599.177274942398, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290200, "time": 9603.661932229996, "episode/length": 640.0, "episode/score": 0.15961786581002002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15961786581002002}
{"step": 290248, "time": 9605.149964809418, "episode/length": 640.0, "episode/score": 0.22552036084647398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22552036084647398}
{"step": 290440, "time": 9611.122257947922, "episode/length": 640.0, "episode/score": 0.04344351514995992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04344351514995992}
{"step": 291208, "time": 9635.162049531937, "episode/length": 640.0, "episode/score": 0.16790018911041216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16790018911041216}
{"step": 292296, "time": 9669.151907920837, "episode/length": 640.0, "episode/score": 0.15512883747544493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15512883747544493}
{"step": 292304, "time": 9669.630159378052, "episode/length": 640.0, "episode/score": 0.2205002299724299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2205002299724299}
{"step": 293888, "time": 9719.101526021957, "episode/length": 640.0, "episode/score": 0.23024191094896196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23024191094896196}
{"step": 295184, "time": 9759.95993590355, "episode/length": 640.0, "episode/score": 0.08429897749118709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08429897749118709}
{"step": 295328, "time": 9764.422754764557, "episode/length": 640.0, "episode/score": 0.13961809473352105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13961809473352105}
{"step": 295376, "time": 9765.96003484726, "episode/length": 640.0, "episode/score": 0.21211052871456104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21211052871456104}
{"step": 295568, "time": 9771.924518823624, "episode/length": 640.0, "episode/score": 0.24757388082912257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24757388082912257}
{"step": 296128, "time": 9789.288536071777, "episode/length": 478.0, "episode/score": 0.13708820246986875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13708820246986875}
{"step": 296336, "time": 9795.814227342606, "episode/length": 640.0, "episode/score": 0.21883732652887034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21883732652887034}
{"step": 297432, "time": 9829.698960781097, "episode/length": 640.0, "episode/score": 0.14712482868975485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14712482868975485}
{"step": 299016, "time": 9879.116955518723, "episode/length": 640.0, "episode/score": 0.21707594682987974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21707594682987974}
{"step": 300040, "time": 9923.046866416931, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.055371522903, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.06307888031, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.070611000061, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.077861070633, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.085412740707, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.092363119125, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9923.099905490875, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300312, "time": 9931.537918329239, "episode/length": 640.0, "episode/score": 0.13669121615276936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13669121615276936}
{"step": 300456, "time": 9936.021692276001, "episode/length": 640.0, "episode/score": 0.24741499439912218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24741499439912218}
{"step": 300504, "time": 9937.514320850372, "episode/length": 640.0, "episode/score": 0.24425330824976754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24425330824976754}
{"step": 300696, "time": 9943.476595640182, "episode/length": 640.0, "episode/score": 0.17876909137922325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17876909137922325}
{"step": 301256, "time": 9960.90597987175, "episode/length": 640.0, "episode/score": 0.19232295931655585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19232295931655585}
{"step": 301464, "time": 9967.371416330338, "episode/length": 640.0, "episode/score": 0.11733346846801851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11733346846801851}
{"step": 302560, "time": 10001.588855981827, "episode/length": 640.0, "episode/score": 0.2265104986969959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2265104986969959}
{"step": 304144, "time": 10051.546662330627, "episode/length": 640.0, "episode/score": 0.14004580470349026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14004580470349026}
{"step": 305440, "time": 10091.768631219864, "episode/length": 640.0, "episode/score": 0.2246178081364718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2246178081364718}
{"step": 305584, "time": 10096.32035779953, "episode/length": 640.0, "episode/score": 0.06066642092734753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06066642092734753}
{"step": 305632, "time": 10097.811297178268, "episode/length": 640.0, "episode/score": 0.12862058756377337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12862058756377337}
{"step": 305824, "time": 10103.826255321503, "episode/length": 640.0, "episode/score": 0.19468106583819633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19468106583819633}
{"step": 306384, "time": 10121.201267242432, "episode/length": 640.0, "episode/score": 0.1707708405505599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1707708405505599}
{"step": 306592, "time": 10127.709644079208, "episode/length": 640.0, "episode/score": 0.12996536028555283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12996536028555283}
{"step": 307688, "time": 10161.633742570877, "episode/length": 640.0, "episode/score": 0.1079839235871276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1079839235871276}
{"step": 309272, "time": 10211.21332526207, "episode/length": 640.0, "episode/score": 0.16861363020707643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16861363020707643}
{"step": 310024, "time": 10246.044403076172, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.052750587463, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.060596227646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.06799697876, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.075159311295, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.082784891129, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.090252399445, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10246.097606658936, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310025, "time": 10247.113366603851, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1341940561930337, "train/action_min": 0.0, "train/action_std": 1.829117448379596, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00024148549262766514, "train/actor_opt_grad_steps": 18325.0, "train/actor_opt_loss": -4.52183389403702, "train/adv_mag": 0.002099984403078755, "train/adv_max": 0.001924229902215302, "train/adv_mean": 9.237698689190665e-05, "train/adv_min": -0.0019116527400910854, "train/adv_std": 0.00046202063640521374, "train/cont_avg": 0.9982808430989584, "train/cont_loss_mean": 0.012675971813223441, "train/cont_loss_std": 0.23620462295204225, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.445463842815823, "train/cont_pos_acc": 0.999999995653828, "train/cont_pos_loss": 0.0016005334843309054, "train/cont_pred": 0.9984007828558484, "train/cont_rate": 0.9982808430989584, "train/dyn_loss_mean": 1.0000012175490458, "train/dyn_loss_std": 3.8951714183591925e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01167491283573933, "train/extr_critic_critic_opt_grad_steps": 18325.0, "train/extr_critic_critic_opt_loss": 13546.002655029297, "train/extr_critic_mag": 0.08483390944699447, "train/extr_critic_max": 0.08483390944699447, "train/extr_critic_mean": 0.08377447285844634, "train/extr_critic_min": 0.08248793023327987, "train/extr_critic_std": 0.0002923546838549858, "train/extr_return_normed_mag": 0.0029921327562381825, "train/extr_return_normed_max": 0.0029921327562381825, "train/extr_return_normed_mean": 0.0009524558968223573, "train/extr_return_normed_min": -0.0009050023897240559, "train/extr_return_normed_std": 0.0004883535698354535, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08590650822346409, "train/extr_return_raw_max": 0.08590650822346409, "train/extr_return_raw_mean": 0.0838668354942153, "train/extr_return_raw_min": 0.08200937307750185, "train/extr_return_raw_std": 0.0004883535708965306, "train/extr_reward_mag": 0.0008228818575541178, "train/extr_reward_max": 0.0008228818575541178, "train/extr_reward_mean": 0.00027294794669311767, "train/extr_reward_min": 2.382323145866394e-06, "train/extr_reward_std": 0.00022137616694332488, "train/image_loss_mean": 0.23436633870005608, "train/image_loss_std": 0.11967358365654945, "train/model_loss_mean": 0.8556992911423246, "train/model_loss_std": 0.27974771584073704, "train/model_opt_grad_norm": 34.85181823372841, "train/model_opt_grad_steps": 18306.390625, "train/model_opt_loss": 2684.0356636047363, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3151.0416666666665, "train/policy_entropy_mag": 1.917058549200495, "train/policy_entropy_max": 1.917058549200495, "train/policy_entropy_mean": 1.7744660762449105, "train/policy_entropy_min": 1.445939142877857, "train/policy_entropy_std": 0.05673290059591333, "train/policy_logprob_mag": 3.4439862382908664, "train/policy_logprob_max": -0.6040708369885882, "train/policy_logprob_mean": -1.7748679723590612, "train/policy_logprob_min": -3.4439862382908664, "train/policy_logprob_std": 0.5728815756738186, "train/policy_randomness_mag": 0.9851732682436705, "train/policy_randomness_max": 0.9851732682436705, "train/policy_randomness_mean": 0.9118952313438058, "train/policy_randomness_min": 0.7430657728885611, "train/policy_randomness_std": 0.029154945271632943, "train/post_ent_mag": 34.76842186848322, "train/post_ent_max": 34.76842186848322, "train/post_ent_mean": 34.67329945166906, "train/post_ent_min": 34.599047223726906, "train/post_ent_std": 0.029866421323580045, "train/prior_ent_mag": 37.24145839611689, "train/prior_ent_max": 37.24145839611689, "train/prior_ent_mean": 35.35106792052587, "train/prior_ent_min": 34.49848985671997, "train/prior_ent_std": 0.3780803185266753, "train/rep_loss_mean": 1.0000012175490458, "train/rep_loss_std": 3.8951714183591925e-05, "train/reward_avg": 0.00019401583464665842, "train/reward_loss_mean": 0.008656231065591177, "train/reward_loss_std": 0.014138062246881114, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007657104482253393, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008656231097120326, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00019359867716654358, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7767269189159076, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0019620954990386963, "report/cont_loss_std": 5.99867053097114e-05, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0019620954990386963, "report/cont_pred": 0.9980398416519165, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21314193308353424, "report/image_loss_std": 0.12671197950839996, "report/model_loss_mean": 0.8216235637664795, "report/model_loss_std": 0.1304292231798172, "report/post_ent_mag": 33.744388580322266, "report/post_ent_max": 33.744388580322266, "report/post_ent_mean": 33.66163635253906, "report/post_ent_min": 33.60009002685547, "report/post_ent_std": 0.02316116914153099, "report/prior_ent_mag": 36.3126106262207, "report/prior_ent_max": 36.3126106262207, "report/prior_ent_mean": 35.02384948730469, "report/prior_ent_min": 34.16244125366211, "report/prior_ent_std": 0.3448973298072815, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00014461774844676256, "report/reward_loss_mean": 0.006519550457596779, "report/reward_loss_std": 0.012677183374762535, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0006810426712036133, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006519550457596779, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001445967936888337, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00805872306227684, "eval/cont_loss_std": 0.19546008110046387, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.259726047515869, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0019476121524348855, "eval/cont_pred": 0.9980543851852417, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22181761264801025, "eval/image_loss_std": 0.11303707957267761, "eval/model_loss_mean": 0.8307684659957886, "eval/model_loss_std": 0.22110436856746674, "eval/post_ent_mag": 33.72698974609375, "eval/post_ent_max": 33.72698974609375, "eval/post_ent_mean": 33.660369873046875, "eval/post_ent_min": 33.60045623779297, "eval/post_ent_std": 0.02289138361811638, "eval/prior_ent_mag": 36.762718200683594, "eval/prior_ent_max": 36.762718200683594, "eval/prior_ent_mean": 35.11063003540039, "eval/prior_ent_min": 34.050514221191406, "eval/prior_ent_std": 0.3706241846084595, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0008921157568693161, "eval/reward_loss_std": 0.0011558905243873596, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0007206201553344727, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008921157568693161, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014030560851097107, "eval/reward_rate": 0.0, "replay/size": 309521.0, "replay/inserts": 30624.0, "replay/samples": 30624.0, "replay/insert_wait_avg": 1.2948595244308999e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.452583523255032e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 20512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.033468756028531e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.5102546215057, "timer/env.step_count": 3828.0, "timer/env.step_total": 32.82270288467407, "timer/env.step_frac": 0.03274051585344249, "timer/env.step_avg": 0.00857437379432447, "timer/env.step_min": 0.006885528564453125, "timer/env.step_max": 0.029959678649902344, "timer/replay._sample_count": 30624.0, "timer/replay._sample_total": 15.063573122024536, "timer/replay._sample_frac": 0.01502585440157092, "timer/replay._sample_avg": 0.0004918878370567051, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.010791540145874023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 6392.0, "timer/agent.policy_total": 63.02245616912842, "timer/agent.policy_frac": 0.06286464989120967, "timer/agent.policy_avg": 0.009859583255495685, "timer/agent.policy_min": 0.008511781692504883, "timer/agent.policy_max": 0.09082674980163574, "timer/dataset_train_count": 1914.0, "timer/dataset_train_total": 0.20346593856811523, "timer/dataset_train_frac": 0.0002029564661609702, "timer/dataset_train_avg": 0.00010630404313903617, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00033664703369140625, "timer/agent.train_count": 1914.0, "timer/agent.train_total": 848.229415178299, "timer/agent.train_frac": 0.8461054749994004, "timer/agent.train_avg": 0.44317106331154593, "timer/agent.train_min": 0.43437719345092773, "timer/agent.train_max": 0.5891838073730469, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46529221534729004, "timer/agent.report_frac": 0.0004641271380540237, "timer/agent.report_avg": 0.23264610767364502, "timer/agent.report_min": 0.2219386100769043, "timer/agent.report_max": 0.24335360527038574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.210591415931485e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 30.546778032895553}
{"step": 310568, "time": 10263.722136497498, "episode/length": 640.0, "episode/score": 0.19715616533871128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19715616533871128}
{"step": 310712, "time": 10268.213744878769, "episode/length": 640.0, "episode/score": 0.17867539588390002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17867539588390002}
{"step": 310760, "time": 10269.714329242706, "episode/length": 640.0, "episode/score": 0.27073282955866773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27073282955866773}
{"step": 310952, "time": 10275.769193172455, "episode/length": 640.0, "episode/score": 0.1857347337854378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1857347337854378}
{"step": 311512, "time": 10293.83183312416, "episode/length": 640.0, "episode/score": 0.23559779542880221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23559779542880221}
{"step": 311720, "time": 10300.309625387192, "episode/length": 640.0, "episode/score": 0.19638743456501118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19638743456501118}
{"step": 312816, "time": 10334.79680275917, "episode/length": 640.0, "episode/score": 0.21589164095641422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21589164095641422}
{"step": 314400, "time": 10384.456785202026, "episode/length": 640.0, "episode/score": 0.17458274325372258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17458274325372258}
{"step": 315696, "time": 10425.099732637405, "episode/length": 640.0, "episode/score": 0.07106355333417014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106355333417014}
{"step": 315840, "time": 10429.751442432404, "episode/length": 640.0, "episode/score": 0.07500459525476799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07500459525476799}
{"step": 315888, "time": 10431.268256187439, "episode/length": 640.0, "episode/score": 0.14347457956819198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14347457956819198}
{"step": 316080, "time": 10437.274602651596, "episode/length": 640.0, "episode/score": 0.12677308098227513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12677308098227513}
{"step": 316640, "time": 10454.745584964752, "episode/length": 640.0, "episode/score": 0.16340034645611468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16340034645611468}
{"step": 316848, "time": 10461.288746833801, "episode/length": 640.0, "episode/score": 0.12552604722850447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12552604722850447}
{"step": 317944, "time": 10495.233703374863, "episode/length": 640.0, "episode/score": 0.1446148589900531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1446148589900531}
{"step": 319528, "time": 10544.97709608078, "episode/length": 640.0, "episode/score": 0.18066178332696836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18066178332696836}
{"step": 320008, "time": 10570.59171128273, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.600908279419, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.60881471634, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.616115093231, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.6232213974, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.630146980286, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.637142896652, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10570.644248008728, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320824, "time": 10596.125679254532, "episode/length": 640.0, "episode/score": 0.08692385835678351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08692385835678351}
{"step": 320968, "time": 10600.619731426239, "episode/length": 640.0, "episode/score": 0.15594627783752912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15594627783752912}
{"step": 321016, "time": 10602.129988908768, "episode/length": 640.0, "episode/score": 0.12465448167108661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12465448167108661}
{"step": 321208, "time": 10608.21087050438, "episode/length": 640.0, "episode/score": 0.17913057240986063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17913057240986063}
{"step": 321768, "time": 10625.656951189041, "episode/length": 640.0, "episode/score": 0.1942970692664403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942970692664403}
{"step": 321976, "time": 10632.128221273422, "episode/length": 640.0, "episode/score": 0.13528510110745628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13528510110745628}
{"step": 323072, "time": 10666.685956954956, "episode/length": 640.0, "episode/score": 0.19173561168435072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19173561168435072}
{"step": 324656, "time": 10716.14358496666, "episode/length": 640.0, "episode/score": 0.07872160383396931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07872160383396931}
{"step": 325952, "time": 10756.665944814682, "episode/length": 640.0, "episode/score": 0.20214338060645787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20214338060645787}
{"step": 326096, "time": 10761.138288497925, "episode/length": 640.0, "episode/score": 0.09523279556447051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09523279556447051}
{"step": 326144, "time": 10762.645826339722, "episode/length": 640.0, "episode/score": 0.15255237905307695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15255237905307695}
{"step": 326336, "time": 10768.609374523163, "episode/length": 640.0, "episode/score": 0.2663598776168783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2663598776168783}
{"step": 326896, "time": 10786.20451784134, "episode/length": 640.0, "episode/score": 0.17506306125676474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17506306125676474}
{"step": 327104, "time": 10793.802319526672, "episode/length": 640.0, "episode/score": 0.17782783419283987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17782783419283987}
{"step": 328200, "time": 10828.379665613174, "episode/length": 640.0, "episode/score": 0.143108266092554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.143108266092554}
{"step": 329784, "time": 10877.984018564224, "episode/length": 640.0, "episode/score": 0.24798814432125482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24798814432125482}
{"step": 330096, "time": 10899.439718723297, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.448170900345, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.455938100815, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.463442087173, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.47125697136, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.479053974152, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.486637830734, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10899.493824720383, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 331080, "time": 10930.103548049927, "episode/length": 640.0, "episode/score": 0.09221282684404741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09221282684404741}
{"step": 331224, "time": 10934.579896211624, "episode/length": 640.0, "episode/score": 0.07671292224711124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07671292224711124}
{"step": 331272, "time": 10936.180449724197, "episode/length": 640.0, "episode/score": 0.16994019743600575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16994019743600575}
{"step": 331464, "time": 10942.130504131317, "episode/length": 640.0, "episode/score": 0.13745064548515984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13745064548515984}
{"step": 332024, "time": 10959.543922185898, "episode/length": 640.0, "episode/score": 0.14000074602671475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14000074602671475}
{"step": 332232, "time": 10966.086742162704, "episode/length": 640.0, "episode/score": 0.06321388004687378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06321388004687378}
{"step": 333328, "time": 11000.501524448395, "episode/length": 640.0, "episode/score": 0.14690780418379745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14690780418379745}
{"step": 334912, "time": 11050.356006145477, "episode/length": 640.0, "episode/score": 0.18847284755076998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18847284755076998}
{"step": 336208, "time": 11091.206652879715, "episode/length": 640.0, "episode/score": 0.1508332571409028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1508332571409028}
{"step": 336352, "time": 11095.696947336197, "episode/length": 640.0, "episode/score": 0.03247374030661376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03247374030661376}
{"step": 336400, "time": 11097.185562610626, "episode/length": 640.0, "episode/score": 0.23848659914926884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23848659914926884}
{"step": 336592, "time": 11103.201802253723, "episode/length": 640.0, "episode/score": 0.07815305964720665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07815305964720665}
{"step": 337152, "time": 11120.73030591011, "episode/length": 640.0, "episode/score": 0.22882954065823924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22882954065823924}
{"step": 337360, "time": 11127.204599380493, "episode/length": 640.0, "episode/score": 0.16716275093415334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16716275093415334}
{"step": 338456, "time": 11161.217724084854, "episode/length": 640.0, "episode/score": 0.22368634459371606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22368634459371606}
{"step": 340040, "time": 11210.872762680054, "episode/length": 640.0, "episode/score": 0.25732786294440757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25732786294440757}
{"step": 340080, "time": 11223.983369588852, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11223.992169618607, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11224.000230073929, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11224.008421182632, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11224.01636147499, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11224.024005413055, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11224.031574249268, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11224.038964271545, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340793, "time": 11247.142264842987, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.108881950378418, "train/action_min": 0.0, "train/action_std": 1.8240195146451395, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00027718736335676414, "train/actor_opt_grad_steps": 20245.0, "train/actor_opt_loss": -4.681451830547303, "train/adv_mag": 0.0036650006659328938, "train/adv_max": 0.0021397259552031755, "train/adv_mean": 8.664916181781261e-05, "train/adv_min": -0.0034042318584397435, "train/adv_std": 0.0005289094554730885, "train/cont_avg": 0.998504638671875, "train/cont_loss_mean": 0.010936435085871684, "train/cont_loss_std": 0.20887470886750256, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.289130640029907, "train/cont_pos_acc": 0.9999999981373549, "train/cont_pos_loss": 0.0015324638973955491, "train/cont_pred": 0.9984663675228754, "train/cont_rate": 0.998504638671875, "train/dyn_loss_mean": 1.000012558574478, "train/dyn_loss_std": 0.00039255022390231414, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.013848594616320042, "train/extr_critic_critic_opt_grad_steps": 20245.0, "train/extr_critic_critic_opt_loss": 13513.871459960938, "train/extr_critic_mag": 0.08838899744053681, "train/extr_critic_max": 0.08838899744053681, "train/extr_critic_mean": 0.08736428082920611, "train/extr_critic_min": 0.0860866451015075, "train/extr_critic_std": 0.0002762263114467108, "train/extr_return_normed_mag": 0.004489098481523494, "train/extr_return_normed_max": 0.003185768572924038, "train/extr_return_normed_mean": 0.000983710411901484, "train/extr_return_normed_min": -0.002312650166762372, "train/extr_return_normed_std": 0.0005417232138521891, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08965296542737633, "train/extr_return_raw_max": 0.08965296542737633, "train/extr_return_raw_mean": 0.0874509117177998, "train/extr_return_raw_min": 0.08415454668768992, "train/extr_return_raw_std": 0.0005417232141553541, "train/extr_reward_mag": 0.0008664472649494807, "train/extr_reward_max": 0.0008664472649494807, "train/extr_reward_mean": 0.00028030623692150886, "train/extr_reward_min": 1.8849968910217285e-06, "train/extr_reward_std": 0.00022434166953644308, "train/image_loss_mean": 0.2272777366451919, "train/image_loss_std": 0.11747855596089114, "train/model_loss_mean": 0.8471023387586077, "train/model_loss_std": 0.2577805285885309, "train/model_opt_grad_norm": 32.90945875644684, "train/model_opt_grad_steps": 20224.682291666668, "train/model_opt_loss": 2471.103640874227, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2916.6666666666665, "train/policy_entropy_mag": 1.9165465589612722, "train/policy_entropy_max": 1.9165465589612722, "train/policy_entropy_mean": 1.7587334730972846, "train/policy_entropy_min": 1.3147423062473536, "train/policy_entropy_std": 0.06652242220782985, "train/policy_logprob_mag": 3.57222368940711, "train/policy_logprob_max": -0.5011363021718959, "train/policy_logprob_mean": -1.7592576512446005, "train/policy_logprob_min": -3.57222368940711, "train/policy_logprob_std": 0.6014297045767307, "train/policy_randomness_mag": 0.9849101562673847, "train/policy_randomness_max": 0.9849101562673847, "train/policy_randomness_mean": 0.9038102682679892, "train/policy_randomness_min": 0.6756439280385772, "train/policy_randomness_std": 0.03418576439920192, "train/post_ent_mag": 32.62460723519325, "train/post_ent_max": 32.62460723519325, "train/post_ent_mean": 32.554017305374146, "train/post_ent_min": 32.4914381702741, "train/post_ent_std": 0.02227298741733345, "train/prior_ent_mag": 35.93369986613592, "train/prior_ent_max": 35.93369986613592, "train/prior_ent_mean": 33.82769248882929, "train/prior_ent_min": 32.9269043803215, "train/prior_ent_std": 0.3579236591855685, "train/rep_loss_mean": 1.000012558574478, "train/rep_loss_std": 0.00039255022390231414, "train/reward_avg": 0.00019951900261124442, "train/reward_loss_mean": 0.008880611814674921, "train/reward_loss_std": 0.014222903148038313, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007990679393212, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008880611804973645, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020078985714159595, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.757207455734412, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014742309227585793, "report/cont_loss_std": 0.3115634322166443, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 7.057502746582031, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0009599985787644982, "report/cont_pred": 0.9990414381027222, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.22872063517570496, "report/image_loss_std": 0.11903465539216995, "report/model_loss_mean": 0.8536101579666138, "report/model_loss_std": 0.35245272517204285, "report/post_ent_mag": 30.845401763916016, "report/post_ent_max": 30.845401763916016, "report/post_ent_mean": 30.757946014404297, "report/post_ent_min": 30.67498016357422, "report/post_ent_std": 0.028635922819375992, "report/prior_ent_mag": 34.779510498046875, "report/prior_ent_max": 34.779510498046875, "report/prior_ent_mean": 31.99991226196289, "report/prior_ent_min": 31.074769973754883, "report/prior_ent_std": 0.3814733028411865, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00022794252436142415, "report/reward_loss_mean": 0.010147146880626678, "report/reward_loss_std": 0.014257367700338364, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0007262229919433594, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010147146880626678, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002339719794690609, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0013856461737304926, "eval/cont_loss_std": 0.01470277737826109, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013856461737304926, "eval/cont_pred": 0.9987081289291382, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24096880853176117, "eval/image_loss_std": 0.12892012298107147, "eval/model_loss_mean": 0.843268632888794, "eval/model_loss_std": 0.13007885217666626, "eval/post_ent_mag": 30.83826446533203, "eval/post_ent_max": 30.83826446533203, "eval/post_ent_mean": 30.750038146972656, "eval/post_ent_min": 30.67524528503418, "eval/post_ent_std": 0.027458304539322853, "eval/prior_ent_mag": 33.42685317993164, "eval/prior_ent_max": 33.42685317993164, "eval/prior_ent_mean": 32.04315185546875, "eval/prior_ent_min": 30.7490234375, "eval/prior_ent_std": 0.39450812339782715, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009142337366938591, "eval/reward_loss_std": 0.0012123144697397947, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008159875869750977, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009142337366938591, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014379702042788267, "eval/reward_rate": 0.0, "replay/size": 340289.0, "replay/inserts": 30768.0, "replay/samples": 30768.0, "replay/insert_wait_avg": 1.2731387847051357e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.426708588424103e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0263746254653652e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0153641700745, "timer/env.step_count": 3846.0, "timer/env.step_total": 32.92297172546387, "timer/env.step_frac": 0.03292246589909852, "timer/env.step_avg": 0.008560315061223055, "timer/env.step_min": 0.007258892059326172, "timer/env.step_max": 0.03325080871582031, "timer/replay._sample_count": 30768.0, "timer/replay._sample_total": 15.131937503814697, "timer/replay._sample_frac": 0.015131705017725289, "timer/replay._sample_avg": 0.0004918076411796248, "timer/replay._sample_min": 0.0003597736358642578, "timer/replay._sample_max": 0.010600090026855469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5769.0, "timer/agent.policy_total": 56.60376787185669, "timer/agent.policy_frac": 0.0566028982153018, "timer/agent.policy_avg": 0.009811712232944476, "timer/agent.policy_min": 0.008506298065185547, "timer/agent.policy_max": 0.09064841270446777, "timer/dataset_train_count": 1923.0, "timer/dataset_train_total": 0.20411038398742676, "timer/dataset_train_frac": 0.0002041072480489543, "timer/dataset_train_avg": 0.00010614164533927548, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.00027060508728027344, "timer/agent.train_count": 1923.0, "timer/agent.train_total": 857.0144467353821, "timer/agent.train_frac": 0.8570012796219679, "timer/agent.train_avg": 0.44566533891595533, "timer/agent.train_min": 0.436443567276001, "timer/agent.train_max": 1.5232832431793213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4657254219055176, "timer/agent.report_frac": 0.0004657182665308638, "timer/agent.report_avg": 0.2328627109527588, "timer/agent.report_min": 0.2220909595489502, "timer/agent.report_max": 0.24363446235656738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218601366732293e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 30.766959867515236}
{"step": 341336, "time": 11263.848314523697, "episode/length": 640.0, "episode/score": 0.22145338837503914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22145338837503914}
{"step": 341480, "time": 11268.455065488815, "episode/length": 640.0, "episode/score": 0.22076796167277735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22076796167277735}
{"step": 341528, "time": 11269.947173833847, "episode/length": 640.0, "episode/score": 0.22760978549752053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22760978549752053}
{"step": 341720, "time": 11275.954517364502, "episode/length": 640.0, "episode/score": 0.2254967819741296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2254967819741296}
{"step": 342280, "time": 11293.481760978699, "episode/length": 640.0, "episode/score": 0.333077353840622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.333077353840622}
{"step": 342488, "time": 11300.083150863647, "episode/length": 640.0, "episode/score": 0.22733266635520977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22733266635520977}
{"step": 343584, "time": 11334.687882900238, "episode/length": 640.0, "episode/score": 0.23407400665587375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23407400665587375}
{"step": 345168, "time": 11384.698200702667, "episode/length": 640.0, "episode/score": 0.19832323483194614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19832323483194614}
{"step": 346464, "time": 11425.502834558487, "episode/length": 640.0, "episode/score": 0.11129673941559304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11129673941559304}
{"step": 346608, "time": 11430.003211021423, "episode/length": 640.0, "episode/score": 0.17795189595994998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17795189595994998}
{"step": 346656, "time": 11431.505306482315, "episode/length": 640.0, "episode/score": 0.18999548132546806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18999548132546806}
{"step": 346848, "time": 11437.507336378098, "episode/length": 640.0, "episode/score": 0.23374365687664067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23374365687664067}
{"step": 347408, "time": 11454.993267536163, "episode/length": 640.0, "episode/score": 0.12109202187497203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12109202187497203}
{"step": 347616, "time": 11461.461574554443, "episode/length": 640.0, "episode/score": 0.1919943445849981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1919943445849981}
{"step": 348712, "time": 11495.72796201706, "episode/length": 640.0, "episode/score": 0.14365950874503142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14365950874503142}
{"step": 350064, "time": 11549.09703207016, "eval_episode/length": 621.0, "eval_episode/score": 0.12671874463558197, "eval_episode/reward_rate": 0.001607717041800643}
{"step": 350064, "time": 11549.427319526672, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11549.436019182205, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11549.444023609161, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11549.451812505722, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11549.459230661392, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11549.466680049896, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11549.47453737259, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350296, "time": 11556.471806526184, "episode/length": 640.0, "episode/score": 0.2794033351023586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2794033351023586}
{"step": 351592, "time": 11596.85085773468, "episode/length": 640.0, "episode/score": 0.16697486094665237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16697486094665237}
{"step": 351736, "time": 11601.328925609589, "episode/length": 640.0, "episode/score": 0.262213207377215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.262213207377215}
{"step": 351784, "time": 11602.825546503067, "episode/length": 640.0, "episode/score": 0.18543277046001094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18543277046001094}
{"step": 351976, "time": 11608.817281246185, "episode/length": 640.0, "episode/score": 0.28439353909283227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28439353909283227}
{"step": 352536, "time": 11626.861961364746, "episode/length": 640.0, "episode/score": 0.13102297414530995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13102297414530995}
{"step": 352744, "time": 11633.359923124313, "episode/length": 640.0, "episode/score": 0.127256061856599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.127256061856599}
{"step": 353840, "time": 11667.903119802475, "episode/length": 640.0, "episode/score": 0.21549067706206415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21549067706206415}
{"step": 355424, "time": 11717.436891317368, "episode/length": 640.0, "episode/score": 0.1557614934691287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1557614934691287}
{"step": 356720, "time": 11758.190485477448, "episode/length": 640.0, "episode/score": 0.08706080569123742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08706080569123742}
{"step": 356864, "time": 11762.752418518066, "episode/length": 640.0, "episode/score": 0.28212994651659073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28212994651659073}
{"step": 356912, "time": 11764.269047737122, "episode/length": 640.0, "episode/score": 0.2676839517376379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2676839517376379}
{"step": 357104, "time": 11770.243594884872, "episode/length": 640.0, "episode/score": 0.25399994374720336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25399994374720336}
{"step": 357664, "time": 11787.705365896225, "episode/length": 640.0, "episode/score": 0.18435464037690963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18435464037690963}
{"step": 357872, "time": 11794.200639724731, "episode/length": 640.0, "episode/score": 0.18397742428317088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18397742428317088}
{"step": 358968, "time": 11828.095858335495, "episode/length": 640.0, "episode/score": 0.30371990603873655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30371990603873655}
{"step": 360048, "time": 11873.916074037552, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.924580812454, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.932555913925, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.940125465393, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.94784283638, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.955299377441, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.96276307106, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.970516681671, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360552, "time": 11889.887865543365, "episode/length": 640.0, "episode/score": 0.2577539895935388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2577539895935388}
{"step": 361848, "time": 11930.533627033234, "episode/length": 640.0, "episode/score": 0.23520701107918285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23520701107918285}
{"step": 361992, "time": 11935.114817619324, "episode/length": 640.0, "episode/score": 0.10000460567783875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10000460567783875}
{"step": 362040, "time": 11936.660422563553, "episode/length": 640.0, "episode/score": 0.1395532072850756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1395532072850756}
{"step": 362232, "time": 11942.783250331879, "episode/length": 640.0, "episode/score": 0.21076425870080584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21076425870080584}
{"step": 362792, "time": 11960.398806810379, "episode/length": 640.0, "episode/score": 0.24679789015254983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24679789015254983}
{"step": 363000, "time": 11966.913933992386, "episode/length": 640.0, "episode/score": 0.21946649457635203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21946649457635203}
{"step": 364096, "time": 12001.414826393127, "episode/length": 640.0, "episode/score": 0.2159611622491866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2159611622491866}
{"step": 365680, "time": 12050.822973489761, "episode/length": 640.0, "episode/score": 0.1306088291934202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1306088291934202}
{"step": 366976, "time": 12091.3019323349, "episode/length": 640.0, "episode/score": 0.160523285483805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.160523285483805}
{"step": 367120, "time": 12095.773393154144, "episode/length": 640.0, "episode/score": 0.27058567108895204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27058567108895204}
{"step": 367168, "time": 12097.279390096664, "episode/length": 640.0, "episode/score": 0.19787300716404843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19787300716404843}
{"step": 367360, "time": 12103.255324602127, "episode/length": 640.0, "episode/score": 0.17641617655806385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17641617655806385}
{"step": 367920, "time": 12120.767105340958, "episode/length": 640.0, "episode/score": 0.20619213147563187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20619213147563187}
{"step": 368128, "time": 12127.26446390152, "episode/length": 640.0, "episode/score": 0.08664420894399427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08664420894399427}
{"step": 369224, "time": 12161.733701705933, "episode/length": 640.0, "episode/score": 0.26202232475134224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26202232475134224}
{"step": 370032, "time": 12198.392960309982, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.401581287384, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.40954709053, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.417206525803, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.425352573395, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.432877540588, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.440223932266, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12198.447452306747, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370808, "time": 12222.44367146492, "episode/length": 640.0, "episode/score": 0.24170811962858352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24170811962858352}
{"step": 371577, "time": 12247.58163690567, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1207911173502603, "train/action_min": 0.0, "train/action_std": 1.8105743465324242, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004515090063250682, "train/actor_opt_grad_steps": 22165.0, "train/actor_opt_loss": -4.4897529310546815, "train/adv_mag": 0.030354309555453558, "train/adv_max": 0.002914412373987337, "train/adv_mean": 0.00010549019982101597, "train/adv_min": -0.02988684910815209, "train/adv_std": 0.0010761930833117124, "train/cont_avg": 0.998565673828125, "train/cont_loss_mean": 0.008550767553970218, "train/cont_loss_std": 0.17611570116938915, "train/cont_neg_acc": 0.0915032687530019, "train/cont_neg_loss": 5.063889437641194, "train/cont_pos_acc": 0.999943943383793, "train/cont_pos_loss": 0.0013974530481088248, "train/cont_pred": 0.9984908274685343, "train/cont_rate": 0.998565673828125, "train/dyn_loss_mean": 1.0000252947211266, "train/dyn_loss_std": 0.0007273149203967932, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02009216699373913, "train/extr_critic_critic_opt_grad_steps": 22165.0, "train/extr_critic_critic_opt_loss": 13445.873438517252, "train/extr_critic_mag": 0.09199571857849757, "train/extr_critic_max": 0.09199571857849757, "train/extr_critic_mean": 0.09069005073979497, "train/extr_critic_min": 0.08899777693053086, "train/extr_critic_std": 0.00036160003552746883, "train/extr_return_normed_mag": 0.03087430513308694, "train/extr_return_normed_max": 0.004270589949252705, "train/extr_return_normed_mean": 0.0012656471788830004, "train/extr_return_normed_min": -0.02881494366253416, "train/extr_return_normed_std": 0.001132569304293914, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09380048777287205, "train/extr_return_raw_max": 0.09380048777287205, "train/extr_return_raw_mean": 0.0907955493312329, "train/extr_return_raw_min": 0.06071495416108519, "train/extr_return_raw_std": 0.0011325693049002439, "train/extr_reward_mag": 0.0009246493379275004, "train/extr_reward_max": 0.0009246493379275004, "train/extr_reward_mean": 0.00028863732245554274, "train/extr_reward_min": 1.6751388708750408e-06, "train/extr_reward_std": 0.00023719465116300853, "train/image_loss_mean": 0.20804196021830043, "train/image_loss_std": 0.1174359704212596, "train/model_loss_mean": 0.8258534669876099, "train/model_loss_std": 0.23031675920356065, "train/model_opt_grad_norm": 31.239152053991955, "train/model_opt_grad_steps": 22143.213541666668, "train/model_opt_loss": 2629.1129035949707, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3190.1041666666665, "train/policy_entropy_mag": 1.9197366690884035, "train/policy_entropy_max": 1.9197366690884035, "train/policy_entropy_mean": 1.7412673414995272, "train/policy_entropy_min": 1.1754057072103024, "train/policy_entropy_std": 0.08320794840498517, "train/policy_logprob_mag": 3.6757208419342837, "train/policy_logprob_max": -0.3995157992467284, "train/policy_logprob_mean": -1.74116481654346, "train/policy_logprob_min": -3.6757208419342837, "train/policy_logprob_std": 0.6308543172975382, "train/policy_randomness_mag": 0.9865495515987277, "train/policy_randomness_max": 0.9865495515987277, "train/policy_randomness_mean": 0.8948344569653273, "train/policy_randomness_min": 0.6040390799753368, "train/policy_randomness_std": 0.042760429244178035, "train/post_ent_mag": 29.524542421102524, "train/post_ent_max": 29.524542421102524, "train/post_ent_mean": 29.39826050400734, "train/post_ent_min": 29.28356658418973, "train/post_ent_std": 0.041816917480900884, "train/prior_ent_mag": 31.680260250965755, "train/prior_ent_max": 31.680260250965755, "train/prior_ent_mean": 29.863201330105465, "train/prior_ent_min": 28.27930822968483, "train/prior_ent_std": 0.5412365132942796, "train/rep_loss_mean": 1.0000252947211266, "train/rep_loss_std": 0.0007273149203967932, "train/reward_avg": 0.00020888484012478634, "train/reward_loss_mean": 0.009245543735839115, "train/reward_loss_std": 0.014397599040724648, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.000859605148434639, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009245543735839115, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020691578902187757, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7385921726624172, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0013260463019832969, "report/cont_loss_std": 0.013912295922636986, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.2281724065542221, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0008821200462989509, "report/cont_pred": 0.9975316524505615, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19656077027320862, "report/image_loss_std": 0.11917514353990555, "report/model_loss_mean": 0.8086398839950562, "report/model_loss_std": 0.12541352212429047, "report/post_ent_mag": 28.30011558532715, "report/post_ent_max": 28.30011558532715, "report/post_ent_mean": 28.125566482543945, "report/post_ent_min": 27.980892181396484, "report/post_ent_std": 0.05543218553066254, "report/prior_ent_mag": 29.947885513305664, "report/prior_ent_max": 29.947885513305664, "report/prior_ent_mean": 27.674936294555664, "report/prior_ent_min": 25.676366806030273, "report/prior_ent_std": 0.7404605150222778, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000248756812652573, "report/reward_loss_mean": 0.010753017850220203, "report/reward_loss_std": 0.01578240469098091, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001124262809753418, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010753016918897629, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002408804139122367, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.016047751531004906, "eval/cont_loss_std": 0.34031301736831665, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.707485198974609, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0009960143361240625, "eval/cont_pred": 0.9990099668502808, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.278400182723999, "eval/image_loss_std": 0.14499719440937042, "eval/model_loss_mean": 0.8956022262573242, "eval/model_loss_std": 0.3649541735649109, "eval/post_ent_mag": 28.296855926513672, "eval/post_ent_max": 28.296855926513672, "eval/post_ent_mean": 28.12161636352539, "eval/post_ent_min": 27.979801177978516, "eval/post_ent_std": 0.05712281912565231, "eval/prior_ent_mag": 30.107322692871094, "eval/prior_ent_max": 30.107322692871094, "eval/prior_ent_mean": 27.659578323364258, "eval/prior_ent_min": 25.721887588500977, "eval/prior_ent_std": 0.7525313496589661, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011542486026883125, "eval/reward_loss_std": 0.0015086260391399264, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009871721267700195, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011542486026883125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00018151395488530397, "eval/reward_rate": 0.0, "replay/size": 371073.0, "replay/inserts": 30784.0, "replay/samples": 30784.0, "replay/insert_wait_avg": 1.2737627212817852e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.409494682557865e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0214773119580788e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4243154525757, "timer/env.step_count": 3848.0, "timer/env.step_total": 33.324575424194336, "timer/env.step_frac": 0.033310441289223204, "timer/env.step_avg": 0.008660232698595201, "timer/env.step_min": 0.007273197174072266, "timer/env.step_max": 0.03540802001953125, "timer/replay._sample_count": 30784.0, "timer/replay._sample_total": 15.207490921020508, "timer/replay._sample_frac": 0.01520104088447799, "timer/replay._sample_avg": 0.0004940063318938574, "timer/replay._sample_min": 0.00033402442932128906, "timer/replay._sample_max": 0.010785102844238281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5771.0, "timer/agent.policy_total": 57.15345501899719, "timer/agent.policy_frac": 0.05712921421061412, "timer/agent.policy_avg": 0.009903561777681024, "timer/agent.policy_min": 0.00784611701965332, "timer/agent.policy_max": 0.09234166145324707, "timer/dataset_train_count": 1924.0, "timer/dataset_train_total": 0.20855975151062012, "timer/dataset_train_frac": 0.00020847129391919175, "timer/dataset_train_avg": 0.00010839903924668406, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0005471706390380859, "timer/agent.train_count": 1924.0, "timer/agent.train_total": 856.1095509529114, "timer/agent.train_frac": 0.8557464445130178, "timer/agent.train_avg": 0.44496338407115976, "timer/agent.train_min": 0.43625330924987793, "timer/agent.train_max": 0.5912981033325195, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46814656257629395, "timer/agent.report_frac": 0.0004679480050067676, "timer/agent.report_avg": 0.23407328128814697, "timer/agent.report_min": 0.22265839576721191, "timer/agent.report_max": 0.24548816680908203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.12195869091561e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 30.770416711338807}
{"step": 372104, "time": 12263.851099729538, "episode/length": 640.0, "episode/score": 0.13212688083888224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13212688083888224}
{"step": 372248, "time": 12268.328280210495, "episode/length": 640.0, "episode/score": 0.20923829864921117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20923829864921117}
{"step": 372296, "time": 12269.843556404114, "episode/length": 640.0, "episode/score": 0.14437211563347319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14437211563347319}
{"step": 372488, "time": 12275.8323199749, "episode/length": 640.0, "episode/score": 0.23190402813986566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23190402813986566}
{"step": 373048, "time": 12293.5033121109, "episode/length": 640.0, "episode/score": 0.2534566901213111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2534566901213111}
{"step": 373256, "time": 12299.999309301376, "episode/length": 640.0, "episode/score": 0.06441012033440074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06441012033440074}
{"step": 374352, "time": 12334.358762025833, "episode/length": 640.0, "episode/score": 0.25921252493674274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25921252493674274}
{"step": 375936, "time": 12383.755795955658, "episode/length": 640.0, "episode/score": 0.1740260414895829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1740260414895829}
{"step": 377232, "time": 12424.678198575974, "episode/length": 640.0, "episode/score": 0.14916814446593207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14916814446593207}
{"step": 377376, "time": 12429.142189025879, "episode/length": 640.0, "episode/score": 0.13875948005124883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13875948005124883}
{"step": 377424, "time": 12430.652604579926, "episode/length": 640.0, "episode/score": 0.20739419986881558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20739419986881558}
{"step": 377616, "time": 12436.792444467545, "episode/length": 640.0, "episode/score": 0.25538806443341855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25538806443341855}
{"step": 378176, "time": 12454.23919391632, "episode/length": 640.0, "episode/score": 0.27074680418587604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27074680418587604}
{"step": 378384, "time": 12460.703669309616, "episode/length": 640.0, "episode/score": 0.23762685132840033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23762685132840033}
{"step": 379480, "time": 12494.722595214844, "episode/length": 640.0, "episode/score": 0.2888225239175881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2888225239175881}
{"step": 380016, "time": 12523.630685567856, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.639701843262, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.647894859314, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.655548095703, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.663409233093, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.670990228653, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.67848110199, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12523.687597751617, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 381064, "time": 12556.192402124405, "episode/length": 640.0, "episode/score": 0.17387868975799847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17387868975799847}
{"step": 382360, "time": 12596.469412326813, "episode/length": 640.0, "episode/score": 0.07574342246334709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07574342246334709}
{"step": 382504, "time": 12600.960767030716, "episode/length": 640.0, "episode/score": 0.10908261170146716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10908261170146716}
{"step": 382552, "time": 12602.509143352509, "episode/length": 640.0, "episode/score": 0.1769927922296688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1769927922296688}
{"step": 382744, "time": 12608.584014892578, "episode/length": 640.0, "episode/score": 0.21872665443891037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21872665443891037}
{"step": 383304, "time": 12626.2771525383, "episode/length": 640.0, "episode/score": 0.18607941674707718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18607941674707718}
{"step": 383512, "time": 12632.794167280197, "episode/length": 640.0, "episode/score": 0.2525307264607193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2525307264607193}
{"step": 384608, "time": 12667.395773887634, "episode/length": 640.0, "episode/score": 0.1714289821061925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714289821061925}
{"step": 386192, "time": 12717.365382909775, "episode/length": 640.0, "episode/score": 0.06533554643476691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06533554643476691}
{"step": 387488, "time": 12757.66630578041, "episode/length": 640.0, "episode/score": 0.12320023607000508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12320023607000508}
{"step": 387632, "time": 12762.16315126419, "episode/length": 640.0, "episode/score": 0.14656841728574932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14656841728574932}
{"step": 387680, "time": 12763.65319275856, "episode/length": 640.0, "episode/score": 0.12830454914708866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12830454914708866}
{"step": 387872, "time": 12769.687446594238, "episode/length": 640.0, "episode/score": 0.09576946314925294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09576946314925294}
{"step": 388432, "time": 12787.08557844162, "episode/length": 640.0, "episode/score": 0.20644853621297443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20644853621297443}
{"step": 388640, "time": 12793.650196552277, "episode/length": 640.0, "episode/score": 0.21571088116806436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21571088116806436}
{"step": 389736, "time": 12827.688355207443, "episode/length": 640.0, "episode/score": 0.15626785340066363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15626785340066363}
{"step": 390000, "time": 12840.649419784546, "eval_episode/length": 266.0, "eval_episode/score": 0.6259375214576721, "eval_episode/reward_rate": 0.003745318352059925}
{"step": 390000, "time": 12847.661260604858, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12847.66982126236, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12847.677825450897, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12847.685647726059, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12847.693120002747, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12847.70025920868, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12847.707391738892, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 391320, "time": 12888.742824077606, "episode/length": 640.0, "episode/score": 0.11360685946485205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11360685946485205}
{"step": 392616, "time": 12929.01875090599, "episode/length": 640.0, "episode/score": 0.20025590663013304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20025590663013304}
{"step": 392760, "time": 12933.50473022461, "episode/length": 640.0, "episode/score": 0.1648776773845384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1648776773845384}
{"step": 392808, "time": 12935.006366968155, "episode/length": 640.0, "episode/score": 0.09057542823049403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09057542823049403}
{"step": 393000, "time": 12940.960534334183, "episode/length": 640.0, "episode/score": 0.17429170214373357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17429170214373357}
{"step": 393560, "time": 12958.920498132706, "episode/length": 640.0, "episode/score": 0.22713163832415262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22713163832415262}
{"step": 393768, "time": 12965.375642061234, "episode/length": 640.0, "episode/score": 0.1336098091792337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1336098091792337}
{"step": 394864, "time": 12999.773893356323, "episode/length": 640.0, "episode/score": 0.23237314609582427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23237314609582427}
{"step": 396448, "time": 13049.338188409805, "episode/length": 640.0, "episode/score": 0.12416004908698142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12416004908698142}
{"step": 397624, "time": 13085.673030376434, "episode/length": 625.0, "episode/score": 0.19867601796556755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19867601796556755}
{"step": 397888, "time": 13094.082557439804, "episode/length": 640.0, "episode/score": 0.056496037895158224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056496037895158224}
{"step": 397936, "time": 13095.696003198624, "episode/length": 640.0, "episode/score": 0.11756755152089227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11756755152089227}
{"step": 398128, "time": 13101.647270202637, "episode/length": 640.0, "episode/score": 0.250664250117552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.250664250117552}
{"step": 398688, "time": 13119.089867830276, "episode/length": 640.0, "episode/score": 0.15220985024927813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15220985024927813}
{"step": 398896, "time": 13125.678273916245, "episode/length": 640.0, "episode/score": 0.1181501429311993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1181501429311993}
{"step": 399992, "time": 13159.97485613823, "episode/length": 640.0, "episode/score": 0.14235524169725977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14235524169725977}
{"step": 400088, "time": 13173.901463985443, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.910310268402, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.918509483337, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.926460504532, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.934475660324, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.942336559296, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.95007109642, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13173.957551240921, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400960, "time": 13201.683232307434, "episode/length": 383.0, "episode/score": 0.16674382756445993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16674382756445993}
{"step": 401576, "time": 13221.180020809174, "episode/length": 640.0, "episode/score": 0.2295604379719407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2295604379719407}
{"step": 402393, "time": 13247.615233421326, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.144335494757934, "train/action_min": 0.0, "train/action_std": 1.834324593988725, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007090848462518614, "train/actor_opt_grad_steps": 24090.0, "train/actor_opt_loss": -4.089440816579088, "train/adv_mag": 0.06665465633331803, "train/adv_max": 0.004076860034404023, "train/adv_mean": 0.0001400861233496047, "train/adv_min": -0.06635987175715402, "train/adv_std": 0.0018878243957076782, "train/cont_avg": 0.9984719073834197, "train/cont_loss_mean": 0.006448338447480072, "train/cont_loss_std": 0.14546821398465712, "train/cont_neg_acc": 0.36729559939612383, "train/cont_neg_loss": 3.6659836302622684, "train/cont_pos_acc": 0.9998985800718396, "train/cont_pos_loss": 0.0010467474718295867, "train/cont_pred": 0.9985040166835093, "train/cont_rate": 0.9984719073834197, "train/dyn_loss_mean": 1.000020224195688, "train/dyn_loss_std": 0.0005476697676192602, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02869298480845592, "train/extr_critic_critic_opt_grad_steps": 24090.0, "train/extr_critic_critic_opt_loss": 13287.440525825778, "train/extr_critic_mag": 0.09839388311218103, "train/extr_critic_max": 0.09839388311218103, "train/extr_critic_mean": 0.09561772235316934, "train/extr_critic_min": 0.09117408181719212, "train/extr_critic_std": 0.0008809139615484547, "train/extr_return_normed_mag": 0.0659910959283305, "train/extr_return_normed_max": 0.006725167749459262, "train/extr_return_normed_mean": 0.00230808448079018, "train/extr_return_normed_min": -0.06465794647913523, "train/extr_return_normed_std": 0.0021289219989904583, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1001749149489897, "train/extr_return_raw_max": 0.1001749149489897, "train/extr_return_raw_mean": 0.09575783731560633, "train/extr_return_raw_min": 0.0287918007203952, "train/extr_return_raw_std": 0.0021289220086414696, "train/extr_reward_mag": 0.0010284012463426342, "train/extr_reward_max": 0.0010284012463426342, "train/extr_reward_mean": 0.00030197482782300236, "train/extr_reward_min": 1.6275465179601482e-06, "train/extr_reward_std": 0.0002553443884485464, "train/image_loss_mean": 0.18018944144557794, "train/image_loss_std": 0.11838078255634851, "train/model_loss_mean": 0.7962191935647954, "train/model_loss_std": 0.2109696137781588, "train/model_opt_grad_norm": 28.609908749659855, "train/model_opt_grad_steps": 24066.533678756477, "train/model_opt_loss": 2822.0184667715753, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 3523.316062176166, "train/policy_entropy_mag": 1.9326182585306118, "train/policy_entropy_max": 1.9326182585306118, "train/policy_entropy_mean": 1.70713744324106, "train/policy_entropy_min": 0.901246427563188, "train/policy_entropy_std": 0.1250647194104491, "train/policy_logprob_mag": 3.990324423103135, "train/policy_logprob_max": -0.2564629835940396, "train/policy_logprob_mean": -1.7066247765882028, "train/policy_logprob_min": -3.990324423103135, "train/policy_logprob_std": 0.6835117454355862, "train/policy_randomness_mag": 0.9931693768871881, "train/policy_randomness_max": 0.9931693768871881, "train/policy_randomness_mean": 0.8772951546728303, "train/policy_randomness_min": 0.46314907243832404, "train/policy_randomness_std": 0.06427055570282467, "train/post_ent_mag": 26.740907066226622, "train/post_ent_max": 26.740907066226622, "train/post_ent_mean": 26.51585288368976, "train/post_ent_min": 26.32546981258096, "train/post_ent_std": 0.07664140684462582, "train/prior_ent_mag": 29.027507752334515, "train/prior_ent_max": 29.027507752334515, "train/prior_ent_mean": 26.207325950187723, "train/prior_ent_min": 24.152740537811436, "train/prior_ent_std": 0.8071710983088597, "train/rep_loss_mean": 1.000020224195688, "train/rep_loss_std": 0.0005476697676192602, "train/reward_avg": 0.00021772704526318786, "train/reward_loss_mean": 0.009569256115280131, "train/reward_loss_std": 0.01446961483150875, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0009634031532959617, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00956925610562912, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021629953766579455, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7022945783576187, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0006342089036479592, "report/cont_loss_std": 0.002129063243046403, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0006342089036479592, "report/cont_pred": 0.9993681907653809, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1662261188030243, "report/image_loss_std": 0.11536045372486115, "report/model_loss_mean": 0.7734519839286804, "report/model_loss_std": 0.11865036934614182, "report/post_ent_mag": 25.456459045410156, "report/post_ent_max": 25.456459045410156, "report/post_ent_mean": 25.174808502197266, "report/post_ent_min": 24.959081649780273, "report/post_ent_std": 0.0884832963347435, "report/prior_ent_mag": 28.627843856811523, "report/prior_ent_max": 28.627843856811523, "report/prior_ent_mean": 24.90170669555664, "report/prior_ent_min": 22.86433982849121, "report/prior_ent_std": 0.8671227097511292, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001449562842026353, "report/reward_loss_mean": 0.006591579411178827, "report/reward_loss_std": 0.01213049329817295, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.000858306884765625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006591579411178827, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00014907075092196465, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00863851048052311, "eval/cont_loss_std": 0.2429993897676468, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.7777628898620605, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001044057309627533, "eval/cont_pred": 0.9989793300628662, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2459878921508789, "eval/image_loss_std": 0.13340039551258087, "eval/model_loss_mean": 0.855471134185791, "eval/model_loss_std": 0.272884726524353, "eval/post_ent_mag": 25.45798110961914, "eval/post_ent_max": 25.45798110961914, "eval/post_ent_mean": 25.176101684570312, "eval/post_ent_min": 24.99549102783203, "eval/post_ent_std": 0.08941346406936646, "eval/prior_ent_mag": 28.627843856811523, "eval/prior_ent_max": 28.627843856811523, "eval/prior_ent_mean": 24.836763381958008, "eval/prior_ent_min": 23.12942886352539, "eval/prior_ent_std": 0.9257104992866516, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0008447179570794106, "eval/reward_loss_std": 0.0011956006055697799, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008769035339355469, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008447179570794106, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00013286620378494263, "eval/reward_rate": 0.0, "replay/size": 401889.0, "replay/inserts": 30816.0, "replay/samples": 30816.0, "replay/insert_wait_avg": 1.2863199163696353e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.472759465686009e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.07686654763859e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6391277313232422e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0138208866119, "timer/env.step_count": 3852.0, "timer/env.step_total": 33.36611294746399, "timer/env.step_frac": 0.03336565180457367, "timer/env.step_avg": 0.00866202309124195, "timer/env.step_min": 0.007294178009033203, "timer/env.step_max": 0.034776926040649414, "timer/replay._sample_count": 30816.0, "timer/replay._sample_total": 15.322176456451416, "timer/replay._sample_frac": 0.015321964693314717, "timer/replay._sample_avg": 0.0004972149680831846, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.02816486358642578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5775.0, "timer/agent.policy_total": 57.33043122291565, "timer/agent.policy_frac": 0.05732963887647723, "timer/agent.policy_avg": 0.009927347397907472, "timer/agent.policy_min": 0.008501768112182617, "timer/agent.policy_max": 0.09258818626403809, "timer/dataset_train_count": 1926.0, "timer/dataset_train_total": 0.20723557472229004, "timer/dataset_train_frac": 0.0002072327105824948, "timer/dataset_train_avg": 0.00010759894845394083, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.00023245811462402344, "timer/agent.train_count": 1926.0, "timer/agent.train_total": 855.2561550140381, "timer/agent.train_frac": 0.8552443347790616, "timer/agent.train_avg": 0.4440582320945161, "timer/agent.train_min": 0.434009313583374, "timer/agent.train_max": 0.5925817489624023, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4690573215484619, "timer/agent.report_frac": 0.00046905083885000296, "timer/agent.report_avg": 0.23452866077423096, "timer/agent.report_min": 0.22422266006469727, "timer/agent.report_max": 0.24483466148376465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0993986918824265e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 30.814964584969555}
{"step": 402752, "time": 13258.84212398529, "episode/length": 640.0, "episode/score": 0.2101759573383788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2101759573383788}
{"step": 403064, "time": 13268.372052192688, "episode/length": 640.0, "episode/score": 0.23015998186383513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23015998186383513}
{"step": 403256, "time": 13274.365663528442, "episode/length": 640.0, "episode/score": 0.2420453254151198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2420453254151198}
{"step": 403816, "time": 13291.900676488876, "episode/length": 640.0, "episode/score": 0.20766876346090157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20766876346090157}
{"step": 404024, "time": 13298.366676807404, "episode/length": 640.0, "episode/score": 0.2318317061021844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2318317061021844}
{"step": 405120, "time": 13332.770110845566, "episode/length": 640.0, "episode/score": 0.22753001349235547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22753001349235547}
{"step": 406088, "time": 13362.767124176025, "episode/length": 640.0, "episode/score": 0.16805955437382636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16805955437382636}
{"step": 406704, "time": 13382.172621011734, "episode/length": 640.0, "episode/score": 0.17674258842760082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17674258842760082}
{"step": 407880, "time": 13418.916266918182, "episode/length": 640.0, "episode/score": 0.11077220190321668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11077220190321668}
{"step": 408192, "time": 13428.926027536392, "episode/length": 640.0, "episode/score": 0.11172003822986198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11172003822986198}
{"step": 408384, "time": 13434.921152830124, "episode/length": 640.0, "episode/score": 0.2683396520363317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2683396520363317}
{"step": 408944, "time": 13452.302940130234, "episode/length": 640.0, "episode/score": 0.20478614799975503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20478614799975503}
{"step": 409152, "time": 13458.943995475769, "episode/length": 640.0, "episode/score": 0.1311632755410983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1311632755410983}
{"step": 410072, "time": 13500.461034536362, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.469478845596, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.47684764862, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.484039068222, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.491158246994, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.498663663864, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.505874633789, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13500.513109207153, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410248, "time": 13505.96058678627, "episode/length": 640.0, "episode/score": 0.2849372627449043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2849372627449043}
{"step": 411216, "time": 13536.39911532402, "episode/length": 640.0, "episode/score": 0.0747965681405276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0747965681405276}
{"step": 411832, "time": 13555.430107355118, "episode/length": 640.0, "episode/score": 0.21745373882879449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21745373882879449}
{"step": 413008, "time": 13592.301218748093, "episode/length": 640.0, "episode/score": 0.1700858133362999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1700858133362999}
{"step": 413320, "time": 13601.807258367538, "episode/length": 640.0, "episode/score": 0.2524333716842193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2524333716842193}
{"step": 413512, "time": 13607.88516831398, "episode/length": 640.0, "episode/score": 0.2366896575195767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2366896575195767}
{"step": 414072, "time": 13625.350589513779, "episode/length": 640.0, "episode/score": 0.24914561297984505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24914561297984505}
{"step": 414280, "time": 13631.825303554535, "episode/length": 640.0, "episode/score": 0.16731801670522373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16731801670522373}
{"step": 415376, "time": 13666.469922065735, "episode/length": 640.0, "episode/score": 0.19743506957695445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19743506957695445}
{"step": 416344, "time": 13696.470799922943, "episode/length": 640.0, "episode/score": 0.23067346990154647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23067346990154647}
{"step": 416960, "time": 13715.856858968735, "episode/length": 640.0, "episode/score": 0.16560245875183455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16560245875183455}
{"step": 418136, "time": 13753.134394407272, "episode/length": 640.0, "episode/score": 0.18304414549621129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18304414549621129}
{"step": 418448, "time": 13763.193016529083, "episode/length": 640.0, "episode/score": 0.18433129217575583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18433129217575583}
{"step": 418640, "time": 13769.156204938889, "episode/length": 640.0, "episode/score": 0.26250998162231554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26250998162231554}
{"step": 419200, "time": 13786.696253061295, "episode/length": 640.0, "episode/score": 0.2866994662781792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2866994662781792}
{"step": 419408, "time": 13793.175815820694, "episode/length": 640.0, "episode/score": 0.26540162760372255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26540162760372255}
{"step": 420056, "time": 13824.934914827347, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.943945884705, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.9517724514, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.959635019302, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.967676877975, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.975546121597, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.984205245972, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13824.99198460579, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420504, "time": 13838.92868924141, "episode/length": 640.0, "episode/score": 0.2878529954809892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2878529954809892}
{"step": 421472, "time": 13869.663677215576, "episode/length": 640.0, "episode/score": 0.15498902900787925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15498902900787925}
{"step": 422088, "time": 13888.705914735794, "episode/length": 640.0, "episode/score": 0.07511233571642606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07511233571642606}
{"step": 423264, "time": 13926.013684511185, "episode/length": 640.0, "episode/score": 0.12472303242032012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12472303242032012}
{"step": 423576, "time": 13935.514189004898, "episode/length": 640.0, "episode/score": 0.21965883995858348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21965883995858348}
{"step": 423768, "time": 13941.472912311554, "episode/length": 640.0, "episode/score": 0.1933866873552006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1933866873552006}
{"step": 424328, "time": 13958.826524972916, "episode/length": 640.0, "episode/score": 0.10591310229830242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10591310229830242}
{"step": 424536, "time": 13965.35597729683, "episode/length": 640.0, "episode/score": 0.04566273702920398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04566273702920398}
{"step": 425032, "time": 13980.805365800858, "episode/length": 181.0, "episode/score": 0.08322649347496736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08322649347496736}
{"step": 425632, "time": 13999.717201948166, "episode/length": 640.0, "episode/score": 0.19494711184921698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19494711184921698}
{"step": 425792, "time": 14004.681436538696, "episode/length": 252.0, "episode/score": 0.08063848439587673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08063848439587673}
{"step": 426600, "time": 14030.223836898804, "episode/length": 640.0, "episode/score": 0.061774888733452826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061774888733452826}
{"step": 427216, "time": 14049.701646566391, "episode/length": 640.0, "episode/score": 0.15576733740243753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15576733740243753}
{"step": 428392, "time": 14086.26056933403, "episode/length": 640.0, "episode/score": 0.18557982407776308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18557982407776308}
{"step": 429456, "time": 14119.693061351776, "episode/length": 640.0, "episode/score": 0.0668410872733034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0668410872733034}
{"step": 429664, "time": 14126.170234203339, "episode/length": 640.0, "episode/score": 0.12897181839053928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12897181839053928}
{"step": 430040, "time": 14149.05791759491, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.066767930984, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.074882507324, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.082659006119, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.09043264389, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.098036527634, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.105492591858, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14149.113046646118, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430160, "time": 14153.144036531448, "episode/length": 640.0, "episode/score": 0.1620332832720237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1620332832720237}
{"step": 430760, "time": 14171.826272249222, "episode/length": 640.0, "episode/score": 0.08520115962539876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08520115962539876}
{"step": 430920, "time": 14176.93748164177, "episode/length": 640.0, "episode/score": 0.053414084595715394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053414084595715394}
{"step": 431728, "time": 14202.355556249619, "episode/length": 640.0, "episode/score": 0.07677846757525231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07677846757525231}
{"step": 432344, "time": 14221.423998594284, "episode/length": 640.0, "episode/score": 0.10609636929177668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10609636929177668}
{"step": 433161, "time": 14247.904969215393, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1733760833740234, "train/action_min": 0.0, "train/action_std": 1.8667844776064157, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008451771518593887, "train/actor_opt_grad_steps": 26015.0, "train/actor_opt_loss": -5.5960852722637355, "train/adv_mag": 0.0845830908510834, "train/adv_max": 0.004224150480392079, "train/adv_mean": 5.2824872576924996e-05, "train/adv_min": -0.08447504319095363, "train/adv_std": 0.002360011173550447, "train/cont_avg": 0.9984944661458334, "train/cont_loss_mean": 0.00399285905632496, "train/cont_loss_std": 0.0952245096700608, "train/cont_neg_acc": 0.6043010771274566, "train/cont_neg_loss": 2.153529093898983, "train/cont_pos_acc": 0.999908289561669, "train/cont_pos_loss": 0.0007507511471279334, "train/cont_pred": 0.9984623737012347, "train/cont_rate": 0.9984944661458334, "train/dyn_loss_mean": 1.0000077827523153, "train/dyn_loss_std": 0.00023345374565527285, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03129108187780124, "train/extr_critic_critic_opt_grad_steps": 26015.0, "train/extr_critic_critic_opt_loss": 13123.051233927408, "train/extr_critic_mag": 0.10258599867423375, "train/extr_critic_max": 0.10258599867423375, "train/extr_critic_mean": 0.09942461961569886, "train/extr_critic_min": 0.09321548479298751, "train/extr_critic_std": 0.0011668312751377623, "train/extr_return_normed_mag": 0.08274542028084397, "train/extr_return_normed_max": 0.007408225753655036, "train/extr_return_normed_mean": 0.0026597727980212462, "train/extr_return_normed_min": -0.08212654894062628, "train/extr_return_normed_std": 0.00267196863751451, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.10422586715624978, "train/extr_return_raw_max": 0.10422586715624978, "train/extr_return_raw_mean": 0.09947741904761642, "train/extr_return_raw_min": 0.014691092461968461, "train/extr_return_raw_std": 0.00267196863872717, "train/extr_reward_mag": 0.0011021153380473454, "train/extr_reward_max": 0.0011021153380473454, "train/extr_reward_mean": 0.0002951341900825355, "train/extr_reward_min": 1.6906609137852986e-06, "train/extr_reward_std": 0.00025917738859485934, "train/image_loss_mean": 0.15999247839984795, "train/image_loss_std": 0.1209628659998998, "train/model_loss_mean": 0.7736620487024387, "train/model_loss_std": 0.1789073513743157, "train/model_opt_grad_norm": 27.539012948671978, "train/model_opt_grad_steps": 25989.489583333332, "train/model_opt_loss": 2004.4970251719158, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2591.1458333333335, "train/policy_entropy_mag": 1.939300863693158, "train/policy_entropy_max": 1.939300863693158, "train/policy_entropy_mean": 1.7048793211579323, "train/policy_entropy_min": 0.7312845836083094, "train/policy_entropy_std": 0.1498217578822126, "train/policy_logprob_mag": 4.067755784839392, "train/policy_logprob_max": -0.18665204267017543, "train/policy_logprob_mean": -1.7054367729773123, "train/policy_logprob_min": -4.067755784839392, "train/policy_logprob_std": 0.6938834286605319, "train/policy_randomness_mag": 0.9966035609443983, "train/policy_randomness_max": 0.9966035609443983, "train/policy_randomness_mean": 0.8761347094550729, "train/policy_randomness_min": 0.3758059577085078, "train/policy_randomness_std": 0.07699315777669351, "train/post_ent_mag": 24.36669905980428, "train/post_ent_max": 24.36669905980428, "train/post_ent_mean": 24.009655217329662, "train/post_ent_min": 23.77810627222061, "train/post_ent_std": 0.11179025304348518, "train/prior_ent_mag": 27.26490844289462, "train/prior_ent_max": 27.26490844289462, "train/prior_ent_mean": 23.274369368950527, "train/prior_ent_min": 21.304366221030552, "train/prior_ent_std": 0.9369946255659064, "train/rep_loss_mean": 1.0000077827523153, "train/rep_loss_std": 0.00023345374565527285, "train/reward_avg": 0.00022024688655619684, "train/reward_loss_mean": 0.009672016928864954, "train/reward_loss_std": 0.014427670418323638, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0010058569411436717, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00967201693856623, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002183478961039024, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.6934802341461181, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.008776702918112278, "report/cont_loss_std": 0.2548375427722931, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 4.34524393081665, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00029046504641883075, "report/cont_pred": 0.9991476535797119, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0001084804534912, "report/dyn_loss_std": 0.002772645791992545, "report/image_loss_mean": 0.12376244366168976, "report/image_loss_std": 0.1118849590420723, "report/model_loss_mean": 0.7400814294815063, "report/model_loss_std": 0.2868589460849762, "report/post_ent_mag": 23.38205337524414, "report/post_ent_max": 23.38205337524414, "report/post_ent_mean": 22.990930557250977, "report/post_ent_min": 22.800973892211914, "report/post_ent_std": 0.12585057318210602, "report/prior_ent_mag": 25.676708221435547, "report/prior_ent_max": 25.676708221435547, "report/prior_ent_mean": 22.794776916503906, "report/prior_ent_min": 21.634567260742188, "report/prior_ent_std": 0.4309757947921753, "report/rep_loss_mean": 1.0001084804534912, "report/rep_loss_std": 0.002772645791992545, "report/reward_avg": 0.00016899386537261307, "report/reward_loss_mean": 0.007477160543203354, "report/reward_loss_std": 0.012922153808176517, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011870861053466797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007477160543203354, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019340054132044315, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009924954734742641, "eval/cont_loss_std": 0.3084385097026825, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.875051498413086, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00028162598027847707, "eval/cont_pred": 0.999719500541687, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0000653266906738, "eval/dyn_loss_std": 0.001590651459991932, "eval/image_loss_mean": 0.2624939978122711, "eval/image_loss_std": 0.14438019692897797, "eval/model_loss_mean": 0.873603343963623, "eval/model_loss_std": 0.3503578305244446, "eval/post_ent_mag": 23.380632400512695, "eval/post_ent_max": 23.380632400512695, "eval/post_ent_mean": 22.99327278137207, "eval/post_ent_min": 22.7532901763916, "eval/post_ent_std": 0.12018962949514389, "eval/prior_ent_mag": 24.189010620117188, "eval/prior_ent_max": 24.189010620117188, "eval/prior_ent_mean": 22.759197235107422, "eval/prior_ent_min": 21.675697326660156, "eval/prior_ent_std": 0.39909031987190247, "eval/rep_loss_mean": 1.0000653266906738, "eval/rep_loss_std": 0.001590651459991932, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011452129110693932, "eval/reward_loss_std": 0.0014809693675488234, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010689496994018555, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011452129110693932, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00018011219799518585, "eval/reward_rate": 0.0, "replay/size": 432657.0, "replay/inserts": 30768.0, "replay/samples": 30768.0, "replay/insert_wait_avg": 1.2981522783784277e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0433912401204301e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0375020656496425e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2722861766815, "timer/env.step_count": 3846.0, "timer/env.step_total": 33.4094762802124, "timer/env.step_frac": 0.03340038181794749, "timer/env.step_avg": 0.008686811305307436, "timer/env.step_min": 0.0072901248931884766, "timer/env.step_max": 0.04780077934265137, "timer/replay._sample_count": 30768.0, "timer/replay._sample_total": 15.291700601577759, "timer/replay._sample_frac": 0.015287538016300428, "timer/replay._sample_avg": 0.0004970001495572594, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.025300264358520508, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5769.0, "timer/agent.policy_total": 57.353267669677734, "timer/agent.policy_frac": 0.05733765541870389, "timer/agent.policy_avg": 0.00994163072797326, "timer/agent.policy_min": 0.008224725723266602, "timer/agent.policy_max": 0.08741545677185059, "timer/dataset_train_count": 1923.0, "timer/dataset_train_total": 0.2059614658355713, "timer/dataset_train_frac": 0.00020590540064127261, "timer/dataset_train_avg": 0.00010710424640435324, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0003066062927246094, "timer/agent.train_count": 1923.0, "timer/agent.train_total": 855.5981633663177, "timer/agent.train_frac": 0.8553652592302158, "timer/agent.train_avg": 0.4449288421041694, "timer/agent.train_min": 0.4353675842285156, "timer/agent.train_max": 1.6672947406768799, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47960591316223145, "timer/agent.report_frac": 0.00047947535865001164, "timer/agent.report_avg": 0.23980295658111572, "timer/agent.report_min": 0.2352464199066162, "timer/agent.report_max": 0.24435949325561523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170103926572932e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 30.759081546904625}
{"step": 433520, "time": 14259.015370607376, "episode/length": 640.0, "episode/score": 0.05438337919946434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05438337919946434}
{"step": 434584, "time": 14292.708976984024, "episode/length": 640.0, "episode/score": 0.12661883888949887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12661883888949887}
{"step": 434792, "time": 14299.238374710083, "episode/length": 640.0, "episode/score": 0.17158776128906084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17158776128906084}
{"step": 435288, "time": 14314.622330665588, "episode/length": 640.0, "episode/score": 0.1388246626592604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1388246626592604}
{"step": 435888, "time": 14333.72027015686, "episode/length": 640.0, "episode/score": 0.061703905066792686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061703905066792686}
{"step": 436048, "time": 14338.755036830902, "episode/length": 640.0, "episode/score": 0.19592096359781408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19592096359781408}
{"step": 436856, "time": 14363.813873291016, "episode/length": 640.0, "episode/score": 0.07541552585269073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07541552585269073}
{"step": 437472, "time": 14383.208146572113, "episode/length": 640.0, "episode/score": 0.16616909035880667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16616909035880667}
{"step": 438648, "time": 14419.698293685913, "episode/length": 640.0, "episode/score": 0.13948221947654815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13948221947654815}
{"step": 439712, "time": 14452.888701677322, "episode/length": 640.0, "episode/score": 0.06605692869200652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06605692869200652}
{"step": 439920, "time": 14459.297380924225, "episode/length": 640.0, "episode/score": 0.06547447596994971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06547447596994971}
{"step": 440024, "time": 14473.77467250824, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.783188343048, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.790785312653, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.798352718353, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.80625963211, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.813698291779, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.820986747742, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14473.828300237656, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440416, "time": 14486.278567314148, "episode/length": 640.0, "episode/score": 0.15191403698528916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15191403698528916}
{"step": 441016, "time": 14504.6139190197, "episode/length": 640.0, "episode/score": 0.134245111199931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.134245111199931}
{"step": 441176, "time": 14509.668964862823, "episode/length": 640.0, "episode/score": 0.11431714003452953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11431714003452953}
{"step": 441984, "time": 14534.934966087341, "episode/length": 640.0, "episode/score": 0.10492919437456294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10492919437456294}
{"step": 442600, "time": 14554.36380314827, "episode/length": 640.0, "episode/score": 0.04664393664083377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04664393664083377}
{"step": 443776, "time": 14591.070079803467, "episode/length": 640.0, "episode/score": 0.0732682976207002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0732682976207002}
{"step": 444840, "time": 14623.828328847885, "episode/length": 640.0, "episode/score": 0.09065317960258312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09065317960258312}
{"step": 445048, "time": 14630.473403215408, "episode/length": 640.0, "episode/score": 0.12550943229192058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12550943229192058}
{"step": 445544, "time": 14645.951084852219, "episode/length": 640.0, "episode/score": 0.18590089913067231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18590089913067231}
{"step": 446144, "time": 14664.80506324768, "episode/length": 640.0, "episode/score": 0.11620661030511314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11620661030511314}
{"step": 446304, "time": 14669.75672507286, "episode/length": 640.0, "episode/score": 0.106346560156652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.106346560156652}
{"step": 447112, "time": 14694.638367414474, "episode/length": 640.0, "episode/score": 0.11843005674435858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11843005674435858}
{"step": 447728, "time": 14713.959854125977, "episode/length": 640.0, "episode/score": 0.20674678706677696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20674678706677696}
{"step": 448904, "time": 14750.436814308167, "episode/length": 640.0, "episode/score": 0.036143577739181865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036143577739181865}
{"step": 449968, "time": 14783.742409229279, "episode/length": 640.0, "episode/score": 0.13345356282324872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13345356282324872}
{"step": 450008, "time": 14795.67935180664, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.687706232071, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.695261001587, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.702702760696, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.709907531738, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.716907978058, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.723928689957, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14795.731227874756, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450176, "time": 14801.196044921875, "episode/length": 640.0, "episode/score": 0.20866849303259016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20866849303259016}
{"step": 450672, "time": 14817.11969280243, "episode/length": 640.0, "episode/score": 0.21681376333960145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21681376333960145}
{"step": 451272, "time": 14835.523713350296, "episode/length": 640.0, "episode/score": 0.07596218538418498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07596218538418498}
{"step": 451432, "time": 14840.474340438843, "episode/length": 640.0, "episode/score": 0.15475979618004487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15475979618004487}
{"step": 452240, "time": 14865.952286720276, "episode/length": 640.0, "episode/score": 0.18118579258948841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18118579258948841}
{"step": 452856, "time": 14884.905121803284, "episode/length": 640.0, "episode/score": 0.1952185768158472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952185768158472}
{"step": 454032, "time": 14922.014865636826, "episode/length": 640.0, "episode/score": 0.1737336672402705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1737336672402705}
{"step": 455096, "time": 14954.631947755814, "episode/length": 640.0, "episode/score": 0.22442945291372496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22442945291372496}
{"step": 455304, "time": 14961.154349327087, "episode/length": 640.0, "episode/score": 0.09032886980092769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09032886980092769}
{"step": 455800, "time": 14976.516890525818, "episode/length": 640.0, "episode/score": 0.10487504357824662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10487504357824662}
{"step": 456400, "time": 14995.363982200623, "episode/length": 640.0, "episode/score": 0.0978220260340521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0978220260340521}
{"step": 456560, "time": 15000.303786039352, "episode/length": 640.0, "episode/score": 0.19276721859803558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19276721859803558}
{"step": 457368, "time": 15025.197006464005, "episode/length": 640.0, "episode/score": 0.11350232228569723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11350232228569723}
{"step": 457984, "time": 15044.464469909668, "episode/length": 640.0, "episode/score": 0.16621965065499467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16621965065499467}
{"step": 459160, "time": 15081.433645009995, "episode/length": 640.0, "episode/score": 0.13136863404321275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13136863404321275}
{"step": 460096, "time": 15122.293041944504, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.301715612411, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.30955529213, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.317229509354, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.32483458519, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.332546710968, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.3402094841, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15122.348306417465, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460224, "time": 15126.321932554245, "episode/length": 640.0, "episode/score": 0.15524758068690403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15524758068690403}
{"step": 460432, "time": 15132.772815942764, "episode/length": 640.0, "episode/score": 0.16996042910544418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16996042910544418}
{"step": 460928, "time": 15148.19722032547, "episode/length": 640.0, "episode/score": 0.1733228871737964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733228871737964}
{"step": 461528, "time": 15166.504263162613, "episode/length": 640.0, "episode/score": 0.13470638921842237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13470638921842237}
{"step": 461688, "time": 15171.447780370712, "episode/length": 640.0, "episode/score": 0.0548983825681546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0548983825681546}
{"step": 462496, "time": 15196.686042547226, "episode/length": 640.0, "episode/score": 0.1085667098123082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1085667098123082}
{"step": 463112, "time": 15215.538582801819, "episode/length": 640.0, "episode/score": 0.15824172054382757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15824172054382757}
{"step": 464121, "time": 15248.026696681976, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2523734495811856, "train/action_min": 0.0, "train/action_std": 1.8599301816261922, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008516546912472119, "train/actor_opt_grad_steps": 27945.0, "train/actor_opt_loss": -7.10471732376777, "train/adv_mag": 0.0803277754445666, "train/adv_max": 0.004033639105324892, "train/adv_mean": -4.2268118330279083e-05, "train/adv_min": -0.08017620763059743, "train/adv_std": 0.0022626070311105783, "train/cont_avg": 0.9984294458762887, "train/cont_loss_mean": 0.003675148181632862, "train/cont_loss_std": 0.088303891189556, "train/cont_neg_acc": 0.6842708358541131, "train/cont_neg_loss": 1.8720810920509394, "train/cont_pos_acc": 0.9999343927988072, "train/cont_pos_loss": 0.0006860989287253181, "train/cont_pred": 0.9984265077359897, "train/cont_rate": 0.9984294458762887, "train/dyn_loss_mean": 1.0000105487931634, "train/dyn_loss_std": 0.00027436278775528933, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.032229163994191734, "train/extr_critic_critic_opt_grad_steps": 27945.0, "train/extr_critic_critic_opt_loss": 13094.449133174936, "train/extr_critic_mag": 0.10297386793746162, "train/extr_critic_max": 0.10297386793746162, "train/extr_critic_mean": 0.10007086204192073, "train/extr_critic_min": 0.09428910434860543, "train/extr_critic_std": 0.001101729862113512, "train/extr_return_normed_mag": 0.07890528743875395, "train/extr_return_normed_max": 0.00712654321003206, "train/extr_return_normed_mean": 0.0023329609722383894, "train/extr_return_normed_min": -0.07809133654863563, "train/extr_return_normed_std": 0.002557070277146419, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.10482220643574429, "train/extr_return_raw_max": 0.10482220643574429, "train/extr_return_raw_mean": 0.1000286291555031, "train/extr_return_raw_min": 0.019604326677076594, "train/extr_return_raw_std": 0.0025570702615443654, "train/extr_reward_mag": 0.0011810752534374747, "train/extr_reward_max": 0.0011810752534374747, "train/extr_reward_mean": 0.00028199721388782843, "train/extr_reward_min": 1.8035013651110462e-06, "train/extr_reward_std": 0.000263401783403302, "train/image_loss_mean": 0.14348086342215538, "train/image_loss_std": 0.12021116935407992, "train/model_loss_mean": 0.7568199904923586, "train/model_loss_std": 0.17551949132502692, "train/model_opt_grad_norm": 27.310113066250516, "train/model_opt_grad_steps": 27918.17525773196, "train/model_opt_loss": 2597.2855954514334, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3427.8350515463917, "train/policy_entropy_mag": 1.9394859862081784, "train/policy_entropy_max": 1.9394859862081784, "train/policy_entropy_mean": 1.7202841909890323, "train/policy_entropy_min": 0.744893959502584, "train/policy_entropy_std": 0.14379559864395672, "train/policy_logprob_mag": 4.077158571518574, "train/policy_logprob_max": -0.1906247763443239, "train/policy_logprob_mean": -1.7196761068609572, "train/policy_logprob_min": -4.077158571518574, "train/policy_logprob_std": 0.6722066875585576, "train/policy_randomness_mag": 0.9966986910584047, "train/policy_randomness_max": 0.9966986910584047, "train/policy_randomness_mean": 0.8840512482775855, "train/policy_randomness_min": 0.38279979376448797, "train/policy_randomness_std": 0.0738963241468078, "train/post_ent_mag": 22.743810289913846, "train/post_ent_max": 22.743810289913846, "train/post_ent_mean": 22.298427050875635, "train/post_ent_min": 22.043343661986675, "train/post_ent_std": 0.13307803166434937, "train/prior_ent_mag": 23.651268349480382, "train/prior_ent_max": 23.651268349480382, "train/prior_ent_mean": 21.191508381637103, "train/prior_ent_min": 19.562063984035216, "train/prior_ent_std": 0.6105718216330734, "train/rep_loss_mean": 1.0000105487931634, "train/rep_loss_std": 0.00027436278775528933, "train/reward_avg": 0.00021992249716764565, "train/reward_loss_mean": 0.009657622675036955, "train/reward_loss_std": 0.014317364484724617, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0010822704157878442, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0096576226366319, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022041433209975817, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7105107605457306, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.00022998641361482441, "report/cont_loss_std": 0.0006791097111999989, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00022998641361482441, "report/cont_pred": 0.9997702836990356, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10658625513315201, "report/image_loss_std": 0.11216255277395248, "report/model_loss_mean": 0.7172901630401611, "report/model_loss_std": 0.11585483700037003, "report/post_ent_mag": 22.101577758789062, "report/post_ent_max": 22.101577758789062, "report/post_ent_mean": 21.662626266479492, "report/post_ent_min": 21.389989852905273, "report/post_ent_std": 0.13259966671466827, "report/prior_ent_mag": 25.39977264404297, "report/prior_ent_max": 25.39977264404297, "report/prior_ent_mean": 20.958049774169922, "report/prior_ent_min": 19.492103576660156, "report/prior_ent_std": 0.6919249892234802, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002458877279423177, "report/reward_loss_mean": 0.01047387532889843, "report/reward_loss_std": 0.015422197990119457, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001155257225036621, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01047387532889843, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020334799773991108, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.026959378272294998, "eval/cont_loss_std": 0.48574626445770264, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.936408042907715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0007807860383763909, "eval/cont_pred": 0.9992867112159729, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3044537305831909, "eval/image_loss_std": 0.16442473232746124, "eval/model_loss_mean": 0.9327564239501953, "eval/model_loss_std": 0.5072723031044006, "eval/post_ent_mag": 22.120725631713867, "eval/post_ent_max": 22.120725631713867, "eval/post_ent_mean": 21.665546417236328, "eval/post_ent_min": 21.425132751464844, "eval/post_ent_std": 0.13857896625995636, "eval/prior_ent_mag": 23.096038818359375, "eval/prior_ent_max": 23.096038818359375, "eval/prior_ent_mean": 20.918922424316406, "eval/prior_ent_min": 19.26189613342285, "eval/prior_ent_std": 0.6477404832839966, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013432642444968224, "eval/reward_loss_std": 0.0013516625622287393, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009795427322387695, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013432642444968224, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021129613742232323, "eval/reward_rate": 0.0, "replay/size": 463617.0, "replay/inserts": 30960.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.3112251764736126e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.341988452645236e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0244218991934727e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1004853248596, "timer/env.step_count": 3870.0, "timer/env.step_total": 33.4664990901947, "timer/env.step_frac": 0.03346313653604906, "timer/env.step_avg": 0.008647674183512843, "timer/env.step_min": 0.007297515869140625, "timer/env.step_max": 0.033043861389160156, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.378139972686768, "timer/replay._sample_frac": 0.015376594850557975, "timer/replay._sample_avg": 0.0004967099474382031, "timer/replay._sample_min": 0.0003752708435058594, "timer/replay._sample_max": 0.011482954025268555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5793.0, "timer/agent.policy_total": 57.37332105636597, "timer/agent.policy_frac": 0.0573675564588188, "timer/agent.policy_avg": 0.009903904894936297, "timer/agent.policy_min": 0.00836801528930664, "timer/agent.policy_max": 0.0869758129119873, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.2100977897644043, "timer/dataset_train_frac": 0.0002100766801409549, "timer/dataset_train_avg": 0.0001085776691288911, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0002872943878173828, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 855.0328063964844, "timer/agent.train_frac": 0.8549468967798237, "timer/agent.train_avg": 0.4418774193263485, "timer/agent.train_min": 0.4310569763183594, "timer/agent.train_max": 0.5769858360290527, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757204055786133, "timer/agent.report_frac": 0.00047567260746212564, "timer/agent.report_avg": 0.23786020278930664, "timer/agent.report_min": 0.23084568977355957, "timer/agent.report_max": 0.2448747158050537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.4567220471348006e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 30.956324118072825}
{"step": 464288, "time": 15253.258142232895, "episode/length": 640.0, "episode/score": 0.07462860146499395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07462860146499395}
{"step": 465352, "time": 15286.43073296547, "episode/length": 640.0, "episode/score": 0.18482951466278053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18482951466278053}
{"step": 465560, "time": 15292.938828468323, "episode/length": 640.0, "episode/score": 0.03750848322296463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03750848322296463}
{"step": 466056, "time": 15308.56531739235, "episode/length": 640.0, "episode/score": 0.09777760741805253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09777760741805253}
{"step": 466656, "time": 15327.493371963501, "episode/length": 640.0, "episode/score": 0.1964948768889201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1964948768889201}
{"step": 466816, "time": 15332.485272884369, "episode/length": 640.0, "episode/score": 0.0882268766366252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0882268766366252}
{"step": 467624, "time": 15357.876997709274, "episode/length": 640.0, "episode/score": 0.1624559058032844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1624559058032844}
{"step": 468240, "time": 15377.306181907654, "episode/length": 640.0, "episode/score": 0.20625018102249726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20625018102249726}
{"step": 469416, "time": 15413.796110153198, "episode/length": 640.0, "episode/score": 0.15903970363686426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15903970363686426}
{"step": 470080, "time": 15446.491376161575, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.499782085419, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.507471561432, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.515052556992, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.522528409958, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.529690027237, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.536806821823, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15446.543970108032, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470480, "time": 15458.976672649384, "episode/length": 640.0, "episode/score": 0.17972618202477975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17972618202477975}
{"step": 470688, "time": 15465.55031967163, "episode/length": 640.0, "episode/score": 0.21891870605406893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21891870605406893}
{"step": 471184, "time": 15480.911858081818, "episode/length": 640.0, "episode/score": 0.24750955916928774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24750955916928774}
{"step": 471784, "time": 15499.290738582611, "episode/length": 640.0, "episode/score": 0.07263602913536715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07263602913536715}
{"step": 471944, "time": 15504.251570224762, "episode/length": 640.0, "episode/score": 0.0996230394786437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0996230394786437}
{"step": 472752, "time": 15529.61550283432, "episode/length": 640.0, "episode/score": 0.12893520893722155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12893520893722155}
{"step": 473368, "time": 15548.42557477951, "episode/length": 640.0, "episode/score": 0.1495227572979303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1495227572979303}
{"step": 474544, "time": 15585.19942355156, "episode/length": 640.0, "episode/score": 0.14920403273936955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14920403273936955}
{"step": 475608, "time": 15618.90187716484, "episode/length": 640.0, "episode/score": 0.11770389655533364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11770389655533364}
{"step": 475816, "time": 15625.369473934174, "episode/length": 640.0, "episode/score": 0.16299820769190632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16299820769190632}
{"step": 476312, "time": 15640.73137998581, "episode/length": 640.0, "episode/score": 0.12292004620459096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12292004620459096}
{"step": 476912, "time": 15659.579518795013, "episode/length": 640.0, "episode/score": 0.09541695101601277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09541695101601277}
{"step": 477072, "time": 15664.532248735428, "episode/length": 640.0, "episode/score": 0.14508828800433093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14508828800433093}
{"step": 477880, "time": 15689.409054994583, "episode/length": 640.0, "episode/score": 0.08494985635830687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08494985635830687}
{"step": 478496, "time": 15708.823918104172, "episode/length": 640.0, "episode/score": 0.07106089547983885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106089547983885}
{"step": 479672, "time": 15745.138891220093, "episode/length": 640.0, "episode/score": 0.13044861885573056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13044861885573056}
{"step": 480064, "time": 15768.762607574463, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.7711789608, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.778719186783, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.7864985466, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.793840169907, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.801067829132, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.808299779892, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15768.816080093384, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480736, "time": 15789.691682577133, "episode/length": 640.0, "episode/score": 0.12086201068780156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12086201068780156}
{"step": 480944, "time": 15796.219805240631, "episode/length": 640.0, "episode/score": 0.0912716041158319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0912716041158319}
{"step": 481440, "time": 15811.645314693451, "episode/length": 640.0, "episode/score": 0.06813230491616196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06813230491616196}
{"step": 482040, "time": 15830.197829008102, "episode/length": 640.0, "episode/score": 0.12327037094462412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12327037094462412}
{"step": 482200, "time": 15835.1576526165, "episode/length": 640.0, "episode/score": 0.18798070889545215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18798070889545215}
{"step": 483008, "time": 15860.411898612976, "episode/length": 640.0, "episode/score": 0.194121912942137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.194121912942137}
{"step": 483624, "time": 15879.830055475235, "episode/length": 640.0, "episode/score": 0.04043191280766223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04043191280766223}
{"step": 484800, "time": 15917.17301249504, "episode/length": 640.0, "episode/score": 0.06522518224483065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06522518224483065}
{"step": 485864, "time": 15950.04155921936, "episode/length": 640.0, "episode/score": 0.12310924095527298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12310924095527298}
{"step": 486072, "time": 15956.523007631302, "episode/length": 640.0, "episode/score": 0.1202543273431047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1202543273431047}
{"step": 486568, "time": 15971.95977139473, "episode/length": 640.0, "episode/score": 0.05363678539413286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05363678539413286}
{"step": 487168, "time": 15990.859355926514, "episode/length": 640.0, "episode/score": 0.11442673338058285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11442673338058285}
{"step": 487328, "time": 15995.80554652214, "episode/length": 640.0, "episode/score": 0.11876983355091397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11876983355091397}
{"step": 488136, "time": 16020.836981773376, "episode/length": 640.0, "episode/score": 0.1734224530581514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1734224530581514}
{"step": 488472, "time": 16031.253429412842, "episode/length": 299.0, "episode/score": 0.1318061654333178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1318061654333178}
{"step": 488752, "time": 16040.212676763535, "episode/length": 640.0, "episode/score": 0.2262444438001694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2262444438001694}
{"step": 489928, "time": 16076.456917762756, "episode/length": 640.0, "episode/score": 0.12401290862635506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12401290862635506}
{"step": 490048, "time": 16091.892825126648, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.901366233826, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.908864021301, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.916342496872, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.92344212532, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.930437803268, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.937529802322, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16091.944599151611, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490992, "time": 16121.263927936554, "episode/length": 640.0, "episode/score": 0.18977417381893247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18977417381893247}
{"step": 491696, "time": 16143.598461151123, "episode/length": 640.0, "episode/score": 0.13869046493709902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13869046493709902}
{"step": 492296, "time": 16161.967988729477, "episode/length": 640.0, "episode/score": 0.15965717241033417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15965717241033417}
{"step": 492456, "time": 16166.943562984467, "episode/length": 640.0, "episode/score": 0.18532506321906794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18532506321906794}
{"step": 493264, "time": 16192.442008256912, "episode/length": 640.0, "episode/score": 0.17115481330955618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17115481330955618}
{"step": 493600, "time": 16203.007807970047, "episode/length": 640.0, "episode/score": 0.24358697858741607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24358697858741607}
{"step": 493880, "time": 16211.64038658142, "episode/length": 640.0, "episode/score": 0.1352273787027798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1352273787027798}
{"step": 495001, "time": 16248.172172546387, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.257262234860751, "train/action_min": 0.0, "train/action_std": 1.8633449633504442, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007622232396756371, "train/actor_opt_grad_steps": 29880.0, "train/actor_opt_loss": -7.517435598867545, "train/adv_mag": 0.07761347594965307, "train/adv_max": 0.004221378174161664, "train/adv_mean": -6.77717780531136e-05, "train/adv_min": -0.07740617728758352, "train/adv_std": 0.002104170356848195, "train/cont_avg": 0.9984364880181347, "train/cont_loss_mean": 0.003229956740363853, "train/cont_loss_std": 0.08050753015930127, "train/cont_neg_acc": 0.6960215070555287, "train/cont_neg_loss": 1.7276437500427897, "train/cont_pos_acc": 0.9999189129765169, "train/cont_pos_loss": 0.0005943014635855255, "train/cont_pred": 0.9984167653661935, "train/cont_rate": 0.9984364880181347, "train/dyn_loss_mean": 1.0000210889262857, "train/dyn_loss_std": 0.0004151483410800484, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.024252598143455335, "train/extr_critic_critic_opt_grad_steps": 29880.0, "train/extr_critic_critic_opt_loss": 13211.873679363665, "train/extr_critic_mag": 0.10028931637502088, "train/extr_critic_max": 0.10028931637502088, "train/extr_critic_mean": 0.09747862236796266, "train/extr_critic_min": 0.09249117152060869, "train/extr_critic_std": 0.0010315214900222698, "train/extr_return_normed_mag": 0.07650350906688315, "train/extr_return_normed_max": 0.007212100328559085, "train/extr_return_normed_mean": 0.0021277106345336826, "train/extr_return_normed_min": -0.07557422243097285, "train/extr_return_normed_std": 0.0023901838286890806, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.10249526547798839, "train/extr_return_raw_max": 0.10249526547798839, "train/extr_return_raw_mean": 0.09741088130313498, "train/extr_return_raw_min": 0.019708942718456447, "train/extr_return_raw_std": 0.0023901838353241507, "train/extr_reward_mag": 0.0012264640837753374, "train/extr_reward_max": 0.0012264640837753374, "train/extr_reward_mean": 0.0002743939269235155, "train/extr_reward_min": 4.051880515301166e-07, "train/extr_reward_std": 0.00026372270227332693, "train/image_loss_mean": 0.13113008937533038, "train/image_loss_std": 0.12087125192188845, "train/model_loss_mean": 0.7437963068794092, "train/model_loss_std": 0.17029505184431767, "train/model_opt_grad_norm": 24.869226737343585, "train/model_opt_grad_steps": 29851.487046632123, "train/model_opt_loss": 1994.5676636374676, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2681.3471502590673, "train/policy_entropy_mag": 1.939713862893495, "train/policy_entropy_max": 1.939713862893495, "train/policy_entropy_mean": 1.7288042733088675, "train/policy_entropy_min": 0.8118077025512339, "train/policy_entropy_std": 0.13316810771900137, "train/policy_logprob_mag": 4.051193959972402, "train/policy_logprob_max": -0.21858195516575185, "train/policy_logprob_mean": -1.7284602056513179, "train/policy_logprob_min": -4.051193959972402, "train/policy_logprob_std": 0.6594475353320028, "train/policy_randomness_mag": 0.9968157975784855, "train/policy_randomness_max": 0.9968157975784855, "train/policy_randomness_mean": 0.8884297000929482, "train/policy_randomness_min": 0.4171866555288048, "train/policy_randomness_std": 0.06843487377920299, "train/post_ent_mag": 21.40307686365948, "train/post_ent_max": 21.40307686365948, "train/post_ent_mean": 20.913065351970456, "train/post_ent_min": 20.630416830586647, "train/post_ent_std": 0.14667046880783813, "train/prior_ent_mag": 22.265895645853153, "train/prior_ent_max": 22.265895645853153, "train/prior_ent_mean": 19.776705904945807, "train/prior_ent_min": 18.167512468723434, "train/prior_ent_std": 0.6661559927031167, "train/rep_loss_mean": 1.0000210889262857, "train/rep_loss_std": 0.0004151483410800484, "train/reward_avg": 0.00021463972615883952, "train/reward_loss_mean": 0.00942358221868391, "train/reward_loss_std": 0.014084188648803555, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0011444190623229032, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00942358221868391, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002193910358087618, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7247959594337308, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0003393984225112945, "report/cont_loss_std": 0.0008386913686990738, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003393984225112945, "report/cont_pred": 0.9996609687805176, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09770020842552185, "report/image_loss_std": 0.09750708192586899, "report/model_loss_mean": 0.7053508162498474, "report/model_loss_std": 0.10108952224254608, "report/post_ent_mag": 21.67233657836914, "report/post_ent_max": 21.67233657836914, "report/post_ent_mean": 21.164703369140625, "report/post_ent_min": 20.868993759155273, "report/post_ent_std": 0.14469709992408752, "report/prior_ent_mag": 21.5866641998291, "report/prior_ent_max": 21.5866641998291, "report/prior_ent_mean": 18.993515014648438, "report/prior_ent_min": 16.798423767089844, "report/prior_ent_std": 0.7884642481803894, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015876724501140416, "report/reward_loss_mean": 0.007311150897294283, "report/reward_loss_std": 0.011483516544103622, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013129711151123047, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00731115136295557, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00022574258036911488, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0003846457111649215, "eval/cont_loss_std": 0.001222647842951119, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003846457111649215, "eval/cont_pred": 0.9996161460876465, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2748548090457916, "eval/image_loss_std": 0.1609245240688324, "eval/model_loss_mean": 0.8766946792602539, "eval/model_loss_std": 0.16119273006916046, "eval/post_ent_mag": 21.674667358398438, "eval/post_ent_max": 21.674667358398438, "eval/post_ent_mean": 21.16114616394043, "eval/post_ent_min": 20.88089942932129, "eval/post_ent_std": 0.14417874813079834, "eval/prior_ent_mag": 22.547393798828125, "eval/prior_ent_max": 22.547393798828125, "eval/prior_ent_mean": 18.853349685668945, "eval/prior_ent_min": 17.220367431640625, "eval/prior_ent_std": 0.8605685830116272, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014552287757396698, "eval/reward_loss_std": 0.001701940898783505, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0012853145599365234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014552287757396698, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022883410565555096, "eval/reward_rate": 0.0, "replay/size": 494497.0, "replay/inserts": 30880.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.3024309756224638e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.530798141202778e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.01696744413966e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1282620429993, "timer/env.step_count": 3860.0, "timer/env.step_total": 33.40783929824829, "timer/env.step_frac": 0.03340355489005466, "timer/env.step_avg": 0.008654880647214582, "timer/env.step_min": 0.007278919219970703, "timer/env.step_max": 0.05024576187133789, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 15.25433349609375, "timer/replay._sample_frac": 0.01525237719503412, "timer/replay._sample_avg": 0.0004939874836817924, "timer/replay._sample_min": 0.0003972053527832031, "timer/replay._sample_max": 0.010623931884765625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5783.0, "timer/agent.policy_total": 57.629637479782104, "timer/agent.policy_frac": 0.05762224673269396, "timer/agent.policy_avg": 0.009965353186889521, "timer/agent.policy_min": 0.008597612380981445, "timer/agent.policy_max": 0.08490872383117676, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.2103745937347412, "timer/dataset_train_frac": 0.00021034761412001414, "timer/dataset_train_avg": 0.00010900238017344104, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0010790824890136719, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 854.8120889663696, "timer/agent.train_frac": 0.8547024630822981, "timer/agent.train_avg": 0.44290781811728996, "timer/agent.train_min": 0.4294109344482422, "timer/agent.train_max": 0.5742373466491699, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4830906391143799, "timer/agent.report_frac": 0.00048302868486843143, "timer/agent.report_avg": 0.24154531955718994, "timer/agent.report_min": 0.23507404327392578, "timer/agent.report_max": 0.2480165958404541, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4089484424606344e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 30.875460900080373}
{"step": 495056, "time": 16249.925272464752, "episode/length": 640.0, "episode/score": 0.16696686880015932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16696686880015932}
{"step": 496120, "time": 16282.967297315598, "episode/length": 640.0, "episode/score": 0.1323328669869852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1323328669869852}
{"step": 496824, "time": 16304.782150268555, "episode/length": 640.0, "episode/score": 0.18458986015707524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18458986015707524}
{"step": 497424, "time": 16323.75815486908, "episode/length": 640.0, "episode/score": 0.13289477278476625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13289477278476625}
{"step": 497584, "time": 16328.748139381409, "episode/length": 640.0, "episode/score": 0.07749552345063648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07749552345063648}
{"step": 498392, "time": 16353.768853664398, "episode/length": 640.0, "episode/score": 0.13141830397421472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13141830397421472}
{"step": 498728, "time": 16364.189990282059, "episode/length": 640.0, "episode/score": 0.1515336831146783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1515336831146783}
{"step": 499008, "time": 16373.165390729904, "episode/length": 640.0, "episode/score": 0.15725136285567487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15725136285567487}
{"step": 500032, "time": 16416.895563840866, "eval_episode/length": 552.0, "eval_episode/score": 0.22374999523162842, "eval_episode/reward_rate": 0.0018083182640144665}
{"step": 500032, "time": 16418.483055591583, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16418.49192404747, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16418.50018143654, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16418.5078496933, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16418.515510559082, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16418.52323460579, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16418.530824899673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500184, "time": 16423.120643138885, "episode/length": 640.0, "episode/score": 0.16763054569099722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16763054569099722}
{"step": 501248, "time": 16456.727791070938, "episode/length": 640.0, "episode/score": 0.11948975802525297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11948975802525297}
{"step": 501952, "time": 16478.698041915894, "episode/length": 640.0, "episode/score": 0.13022690368461554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13022690368461554}
{"step": 502552, "time": 16497.16022825241, "episode/length": 640.0, "episode/score": 0.09216449114239822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09216449114239822}
{"step": 502712, "time": 16502.121104002, "episode/length": 640.0, "episode/score": 0.13548319849223844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13548319849223844}
{"step": 503520, "time": 16527.458287477493, "episode/length": 640.0, "episode/score": 0.1453233104600713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1453233104600713}
{"step": 503856, "time": 16537.917013645172, "episode/length": 640.0, "episode/score": 0.12196819746554866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12196819746554866}
{"step": 504136, "time": 16546.632387161255, "episode/length": 640.0, "episode/score": 0.08666109463410976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08666109463410976}
{"step": 505312, "time": 16583.35430955887, "episode/length": 640.0, "episode/score": 0.11442595906123643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11442595906123643}
{"step": 506376, "time": 16616.18295288086, "episode/length": 640.0, "episode/score": 0.15329466312925888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15329466312925888}
{"step": 507080, "time": 16638.02371239662, "episode/length": 640.0, "episode/score": 0.06297193782506838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06297193782506838}
{"step": 507680, "time": 16656.77449822426, "episode/length": 640.0, "episode/score": 0.12421036852629186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12421036852629186}
{"step": 507840, "time": 16661.71816444397, "episode/length": 640.0, "episode/score": 0.16239370624793992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16239370624793992}
{"step": 508648, "time": 16687.09744501114, "episode/length": 640.0, "episode/score": 0.1498059149328128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1498059149328128}
{"step": 508984, "time": 16697.724881649017, "episode/length": 640.0, "episode/score": 0.18103240407123167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18103240407123167}
{"step": 509264, "time": 16706.726588487625, "episode/length": 640.0, "episode/score": 0.1707407704649313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1707407704649313}
{"step": 510016, "time": 16741.076063871384, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.084686517715, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.092192411423, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.0995926857, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.107038974762, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.11462163925, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.121950149536, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16741.129160642624, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510440, "time": 16754.190753936768, "episode/length": 640.0, "episode/score": 0.1280383778781129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1280383778781129}
{"step": 511504, "time": 16787.53354692459, "episode/length": 640.0, "episode/score": 0.08248329691309664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08248329691309664}
{"step": 512208, "time": 16809.2823073864, "episode/length": 640.0, "episode/score": 0.13241445158973875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13241445158973875}
{"step": 512808, "time": 16827.67331981659, "episode/length": 640.0, "episode/score": 0.1446358638876859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1446358638876859}
{"step": 512968, "time": 16832.590718746185, "episode/length": 640.0, "episode/score": 0.08991761398104359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08991761398104359}
{"step": 513776, "time": 16858.014736890793, "episode/length": 640.0, "episode/score": 0.13485505283495058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13485505283495058}
{"step": 514112, "time": 16868.461198091507, "episode/length": 640.0, "episode/score": 0.08453224164756534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08453224164756534}
{"step": 514392, "time": 16877.031910181046, "episode/length": 640.0, "episode/score": 0.14543593266628818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14543593266628818}
{"step": 515568, "time": 16913.746047735214, "episode/length": 640.0, "episode/score": 0.1532062064947013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1532062064947013}
{"step": 516632, "time": 16947.223944187164, "episode/length": 640.0, "episode/score": 0.1471599641411956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1471599641411956}
{"step": 517336, "time": 16969.016256809235, "episode/length": 640.0, "episode/score": 0.12446137246095645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12446137246095645}
{"step": 517936, "time": 16987.75575852394, "episode/length": 640.0, "episode/score": 0.04519067117951181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04519067117951181}
{"step": 518096, "time": 16992.7173743248, "episode/length": 640.0, "episode/score": 0.03800906849252783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03800906849252783}
{"step": 518904, "time": 17017.647356987, "episode/length": 640.0, "episode/score": 0.11195288394361569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11195288394361569}
{"step": 519240, "time": 17028.26970219612, "episode/length": 640.0, "episode/score": 0.1545446961165169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1545446961165169}
{"step": 519520, "time": 17037.291384220123, "episode/length": 640.0, "episode/score": 0.05680825941712442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05680825941712442}
{"step": 520000, "time": 17063.69140791893, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.69971728325, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.707158088684, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.71462035179, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.721876859665, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.729325532913, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.737077236176, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17063.745078086853, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520696, "time": 17084.975572824478, "episode/length": 640.0, "episode/score": 0.17111248283657687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17111248283657687}
{"step": 521760, "time": 17118.229810476303, "episode/length": 640.0, "episode/score": 0.18985032121310041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18985032121310041}
{"step": 522464, "time": 17140.049334526062, "episode/length": 640.0, "episode/score": 0.15789377904638968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15789377904638968}
{"step": 523064, "time": 17158.53320336342, "episode/length": 640.0, "episode/score": 0.17969052881196035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17969052881196035}
{"step": 523224, "time": 17163.512062072754, "episode/length": 640.0, "episode/score": 0.09519833991802784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09519833991802784}
{"step": 524032, "time": 17188.86106324196, "episode/length": 640.0, "episode/score": 0.18721297477827648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18721297477827648}
{"step": 524368, "time": 17199.729899168015, "episode/length": 640.0, "episode/score": 0.14848384486072064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14848384486072064}
{"step": 524648, "time": 17208.396610736847, "episode/length": 640.0, "episode/score": 0.16918538396473082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16918538396473082}
{"step": 525824, "time": 17245.225511550903, "episode/length": 640.0, "episode/score": 0.12486786890522694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12486786890522694}
{"step": 525897, "time": 17248.279037952423, "train_stats/mean_log_entropy": 1.726137947063057, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2389178498421307, "train/action_min": 0.0, "train/action_std": 1.8521666230315372, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007616070081380925, "train/actor_opt_grad_steps": 31810.0, "train/actor_opt_loss": -7.479443809722063, "train/adv_mag": 0.07670840470438794, "train/adv_max": 0.004338346383114553, "train/adv_mean": -6.530215985106182e-05, "train/adv_min": -0.07653047982120761, "train/adv_std": 0.002090943383397969, "train/cont_avg": 0.9983656492875648, "train/cont_loss_mean": 0.0029817361741566817, "train/cont_loss_std": 0.07472067265204332, "train/cont_neg_acc": 0.7154008453782601, "train/cont_neg_loss": 1.6200839384063663, "train/cont_pos_acc": 0.9999239441644342, "train/cont_pos_loss": 0.0005337667804985872, "train/cont_pred": 0.998341137881106, "train/cont_rate": 0.9983656492875648, "train/dyn_loss_mean": 1.0000001809757608, "train/dyn_loss_std": 5.796942796553316e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0286626503085042, "train/extr_critic_critic_opt_grad_steps": 31810.0, "train/extr_critic_critic_opt_loss": 13319.429049951425, "train/extr_critic_mag": 0.09737799451758825, "train/extr_critic_max": 0.09737799451758825, "train/extr_critic_mean": 0.0945445374040406, "train/extr_critic_min": 0.08926709822422482, "train/extr_critic_std": 0.0010744188474901407, "train/extr_return_normed_mag": 0.07539926195237304, "train/extr_return_normed_max": 0.007493680893139518, "train/extr_return_normed_mean": 0.0022565182473346435, "train/extr_return_normed_min": -0.07459477775300723, "train/extr_return_normed_std": 0.002381879519647074, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09971638251617165, "train/extr_return_raw_max": 0.09971638251617165, "train/extr_return_raw_mean": 0.09447922491965516, "train/extr_return_raw_min": 0.017627923870024903, "train/extr_return_raw_std": 0.0023818795268853326, "train/extr_reward_mag": 0.0013345949390391612, "train/extr_reward_max": 0.0013345949390391612, "train/extr_reward_mean": 0.0002681780594444491, "train/extr_reward_min": 2.04570552845693e-06, "train/extr_reward_std": 0.0002651540002299453, "train/image_loss_mean": 0.12489755459400038, "train/image_loss_std": 0.1217990152808051, "train/model_loss_mean": 0.737337012982739, "train/model_loss_std": 0.16687297790161687, "train/model_opt_grad_norm": 24.272947217516332, "train/model_opt_grad_steps": 31780.455958549224, "train/model_opt_loss": 3561.7289703843508, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4831.606217616581, "train/policy_entropy_mag": 1.9389165695467143, "train/policy_entropy_max": 1.9389165695467143, "train/policy_entropy_mean": 1.7304268630675084, "train/policy_entropy_min": 0.783003925659496, "train/policy_entropy_std": 0.131688597211566, "train/policy_logprob_mag": 4.068963153374628, "train/policy_logprob_max": -0.2077127452264178, "train/policy_logprob_mean": -1.7306363446724846, "train/policy_logprob_min": -4.068963153374628, "train/policy_logprob_std": 0.6546900954888892, "train/policy_randomness_mag": 0.99640606876482, "train/policy_randomness_max": 0.99640606876482, "train/policy_randomness_mean": 0.8892635551758998, "train/policy_randomness_min": 0.4023844425233535, "train/policy_randomness_std": 0.06767455598464901, "train/post_ent_mag": 20.991130058011862, "train/post_ent_max": 20.991130058011862, "train/post_ent_mean": 20.42385014351168, "train/post_ent_min": 20.095863342285156, "train/post_ent_std": 0.1707278090128627, "train/prior_ent_mag": 21.454914191843933, "train/prior_ent_max": 21.454914191843933, "train/prior_ent_mean": 18.913706774538664, "train/prior_ent_min": 17.426141244759833, "train/prior_ent_std": 0.6225471101276615, "train/rep_loss_mean": 1.0000001809757608, "train/rep_loss_std": 5.796942796553316e-06, "train/reward_avg": 0.00021620883829252303, "train/reward_loss_mean": 0.009457591040436314, "train/reward_loss_std": 0.014110826583183491, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0011852182872554799, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009457591050087324, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021866777576409627, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00042677094461396337, "report/cont_loss_std": 0.0013615615898743272, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0028048569802194834, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004244463052600622, "report/cont_pred": 0.998603105545044, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10382723063230515, "report/image_loss_std": 0.10442406684160233, "report/model_loss_mean": 0.7113931179046631, "report/model_loss_std": 0.10762973874807358, "report/post_ent_mag": 21.855873107910156, "report/post_ent_max": 21.855873107910156, "report/post_ent_mean": 21.248266220092773, "report/post_ent_min": 20.91489028930664, "report/post_ent_std": 0.18016384541988373, "report/prior_ent_mag": 21.389110565185547, "report/prior_ent_max": 21.389110565185547, "report/prior_ent_mean": 19.021827697753906, "report/prior_ent_min": 17.67727279663086, "report/prior_ent_std": 0.5869483947753906, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015712833555880934, "report/reward_loss_mean": 0.007139062043279409, "report/reward_loss_std": 0.01183425635099411, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0010731220245361328, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007139062508940697, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019732140935957432, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009843189269304276, "eval/cont_loss_std": 0.28847822546958923, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.234472274780273, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0008259562309831381, "eval/cont_pred": 0.9991936087608337, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3037412762641907, "eval/image_loss_std": 0.15299580991268158, "eval/model_loss_mean": 0.9149600267410278, "eval/model_loss_std": 0.3202817142009735, "eval/post_ent_mag": 21.83614730834961, "eval/post_ent_max": 21.83614730834961, "eval/post_ent_mean": 21.251787185668945, "eval/post_ent_min": 20.846078872680664, "eval/post_ent_std": 0.18520866334438324, "eval/prior_ent_mag": 21.389110565185547, "eval/prior_ent_max": 21.389110565185547, "eval/prior_ent_mean": 19.04802703857422, "eval/prior_ent_min": 17.602890014648438, "eval/prior_ent_std": 0.5729090571403503, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013755117543041706, "eval/reward_loss_std": 0.0014758919132873416, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001155257225036621, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013755117543041706, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021635729353874922, "eval/reward_rate": 0.0, "replay/size": 525393.0, "replay/inserts": 30896.0, "replay/samples": 30896.0, "replay/insert_wait_avg": 1.300305730008758e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.654193020805308e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0252897775365361e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0892338752747, "timer/env.step_count": 3862.0, "timer/env.step_total": 33.36212730407715, "timer/env.step_frac": 0.03335915053779879, "timer/env.step_avg": 0.008638562222702524, "timer/env.step_min": 0.0072479248046875, "timer/env.step_max": 0.04834771156311035, "timer/replay._sample_count": 30896.0, "timer/replay._sample_total": 15.318498373031616, "timer/replay._sample_frac": 0.015317131566023889, "timer/replay._sample_avg": 0.000495808466242608, "timer/replay._sample_min": 0.00040912628173828125, "timer/replay._sample_max": 0.010915994644165039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5785.0, "timer/agent.policy_total": 57.077136754989624, "timer/agent.policy_frac": 0.057072043995334075, "timer/agent.policy_avg": 0.00986640220483831, "timer/agent.policy_min": 0.008542060852050781, "timer/agent.policy_max": 0.09796404838562012, "timer/dataset_train_count": 1931.0, "timer/dataset_train_total": 0.2089858055114746, "timer/dataset_train_frac": 0.00020896715856211099, "timer/dataset_train_avg": 0.00010822672475995578, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0002617835998535156, "timer/agent.train_count": 1931.0, "timer/agent.train_total": 855.7093844413757, "timer/agent.train_frac": 0.855633032990029, "timer/agent.train_avg": 0.44314313021303764, "timer/agent.train_min": 0.43127989768981934, "timer/agent.train_max": 1.837174892425537, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752790927886963, "timer/agent.report_frac": 0.0004752366855775695, "timer/agent.report_avg": 0.23763954639434814, "timer/agent.report_min": 0.2317812442779541, "timer/agent.report_max": 0.2434978485107422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.266043092009492e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 30.892678253999595}
{"step": 526888, "time": 17278.97759079933, "episode/length": 640.0, "episode/score": 0.11337168276310194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11337168276310194}
{"step": 527592, "time": 17301.01104450226, "episode/length": 640.0, "episode/score": 0.11010374207199902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11010374207199902}
{"step": 528192, "time": 17320.009984493256, "episode/length": 640.0, "episode/score": 0.16451533389459883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16451533389459883}
{"step": 528352, "time": 17325.07718849182, "episode/length": 640.0, "episode/score": 0.17274439926060836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17274439926060836}
{"step": 529160, "time": 17350.309314489365, "episode/length": 640.0, "episode/score": 0.09925798108130834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09925798108130834}
{"step": 529496, "time": 17360.836547374725, "episode/length": 640.0, "episode/score": 0.12342595109669219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12342595109669219}
{"step": 529776, "time": 17369.780267477036, "episode/length": 640.0, "episode/score": 0.07083397218832488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07083397218832488}
{"step": 530088, "time": 17390.220368623734, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.22875714302, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.236461877823, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.244444847107, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.25211071968, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.25966501236, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.26712369919, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17390.27481007576, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530952, "time": 17417.23273873329, "episode/length": 640.0, "episode/score": 0.09484032667489828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09484032667489828}
{"step": 532016, "time": 17450.919491291046, "episode/length": 640.0, "episode/score": 0.2077003365618566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2077003365618566}
{"step": 532720, "time": 17473.44527697563, "episode/length": 640.0, "episode/score": 0.10368934851078393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10368934851078393}
{"step": 533320, "time": 17492.007947444916, "episode/length": 640.0, "episode/score": 0.06647010302913259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06647010302913259}
{"step": 533480, "time": 17497.034062623978, "episode/length": 640.0, "episode/score": 0.13576218324578804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13576218324578804}
{"step": 533520, "time": 17498.531494140625, "episode/length": 467.0, "episode/score": 0.16206977376691611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16206977376691611}
{"step": 534288, "time": 17522.96321797371, "episode/length": 640.0, "episode/score": 0.1533878341556374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1533878341556374}
{"step": 534624, "time": 17533.485579013824, "episode/length": 640.0, "episode/score": 0.15903131861227848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15903131861227848}
{"step": 536080, "time": 17579.14324760437, "episode/length": 640.0, "episode/score": 0.1478788011565939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1478788011565939}
{"step": 537144, "time": 17612.277265310287, "episode/length": 640.0, "episode/score": 0.13531635429819744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13531635429819744}
{"step": 537848, "time": 17634.40268945694, "episode/length": 640.0, "episode/score": 0.11055741885957104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11055741885957104}
{"step": 538448, "time": 17653.354331970215, "episode/length": 640.0, "episode/score": 0.14327304756079684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14327304756079684}
{"step": 538608, "time": 17658.445684671402, "episode/length": 640.0, "episode/score": 0.17279906753935848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17279906753935848}
{"step": 538648, "time": 17659.476738214493, "episode/length": 640.0, "episode/score": 0.1629222735601843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1629222735601843}
{"step": 539416, "time": 17683.514970064163, "episode/length": 640.0, "episode/score": 0.1731521897239645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731521897239645}
{"step": 539752, "time": 17694.08277606964, "episode/length": 640.0, "episode/score": 0.10431663535177904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10431663535177904}
{"step": 540072, "time": 17715.857103824615, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.866067171097, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.87354159355, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.881456375122, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.888949394226, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.896085739136, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.903200626373, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17715.910556793213, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 541208, "time": 17752.024988651276, "episode/length": 640.0, "episode/score": 0.134267433116122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.134267433116122}
{"step": 542272, "time": 17785.439739465714, "episode/length": 640.0, "episode/score": 0.12748861412876522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12748861412876522}
{"step": 542976, "time": 17807.43642926216, "episode/length": 640.0, "episode/score": 0.09944746826010942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09944746826010942}
{"step": 543576, "time": 17825.97964668274, "episode/length": 640.0, "episode/score": 0.03671868417973201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03671868417973201}
{"step": 543736, "time": 17831.01206302643, "episode/length": 640.0, "episode/score": 0.10142009874880387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10142009874880387}
{"step": 543776, "time": 17832.49864935875, "episode/length": 640.0, "episode/score": 0.1198733470051252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1198733470051252}
{"step": 544544, "time": 17856.660868644714, "episode/length": 640.0, "episode/score": 0.15854524082908483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15854524082908483}
{"step": 544880, "time": 17867.221007585526, "episode/length": 640.0, "episode/score": 0.12955398003322216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12955398003322216}
{"step": 546336, "time": 17912.68114089966, "episode/length": 640.0, "episode/score": 0.052748432619353025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052748432619353025}
{"step": 547400, "time": 17945.797770023346, "episode/length": 640.0, "episode/score": 0.16189935783842202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16189935783842202}
{"step": 548104, "time": 17967.90319919586, "episode/length": 640.0, "episode/score": 0.1159924675347952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1159924675347952}
{"step": 548704, "time": 17986.96697974205, "episode/length": 640.0, "episode/score": 0.04958431995109436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04958431995109436}
{"step": 548864, "time": 17992.152409553528, "episode/length": 640.0, "episode/score": 0.0954681784659499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0954681784659499}
{"step": 548904, "time": 17993.516979455948, "episode/length": 640.0, "episode/score": 0.12819382401207235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12819382401207235}
{"step": 549672, "time": 18017.70100045204, "episode/length": 640.0, "episode/score": 0.12671672176486481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12671672176486481}
{"step": 550008, "time": 18028.18481183052, "episode/length": 640.0, "episode/score": 0.17805868058937335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17805868058937335}
{"step": 550056, "time": 18041.404592514038, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.414351940155, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.422917366028, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.43149280548, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.439628362656, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.44804573059, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.45590019226, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18041.46379494667, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 551112, "time": 18074.516944885254, "episode/length": 596.0, "episode/score": 0.1333525177079764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1333525177079764}
{"step": 552528, "time": 18119.101116895676, "episode/length": 640.0, "episode/score": 0.0903429441908088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0903429441908088}
{"step": 553232, "time": 18141.26039147377, "episode/length": 640.0, "episode/score": 0.2600611651661211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2600611651661211}
{"step": 553832, "time": 18159.766701698303, "episode/length": 640.0, "episode/score": 0.16038594548359697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16038594548359697}
{"step": 553992, "time": 18164.779163599014, "episode/length": 640.0, "episode/score": 0.12346720659593302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12346720659593302}
{"step": 554032, "time": 18166.34332728386, "episode/length": 640.0, "episode/score": 0.07695235848768789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07695235848768789}
{"step": 554800, "time": 18190.318221092224, "episode/length": 640.0, "episode/score": 0.10410493637706963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10410493637706963}
{"step": 555136, "time": 18200.909041643143, "episode/length": 640.0, "episode/score": 0.10333660968242953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10333660968242953}
{"step": 556240, "time": 18235.8061439991, "episode/length": 640.0, "episode/score": 0.14259513926728573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14259513926728573}
{"step": 556617, "time": 18248.462863445282, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2707389195760093, "train/action_min": 0.0, "train/action_std": 1.8519027475267649, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007476946749799632, "train/actor_opt_grad_steps": 33735.0, "train/actor_opt_loss": -8.044249243335798, "train/adv_mag": 0.074252734426409, "train/adv_max": 0.004268051008693874, "train/adv_mean": -0.00010043715218029566, "train/adv_min": -0.07405532760700832, "train/adv_std": 0.0021254622067014375, "train/cont_avg": 0.9984029134114584, "train/cont_loss_mean": 0.003360942257965386, "train/cont_loss_std": 0.08374617163174965, "train/cont_neg_acc": 0.7211740061921893, "train/cont_neg_loss": 1.6980947412615612, "train/cont_pos_acc": 0.9999643523866931, "train/cont_pos_loss": 0.0005063989049934511, "train/cont_pred": 0.9984275894239545, "train/cont_rate": 0.9984029134114584, "train/dyn_loss_mean": 1.000007492179672, "train/dyn_loss_std": 0.00018097673637385014, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02684983564116313, "train/extr_critic_critic_opt_grad_steps": 33735.0, "train/extr_critic_critic_opt_loss": 13421.050028483072, "train/extr_critic_mag": 0.09372905207177003, "train/extr_critic_max": 0.09372905207177003, "train/extr_critic_mean": 0.09100437241916855, "train/extr_critic_min": 0.08619119289020698, "train/extr_critic_std": 0.0010146132902567235, "train/extr_return_normed_mag": 0.07300242801041652, "train/extr_return_normed_max": 0.007215759173656504, "train/extr_return_normed_mean": 0.0020298173558330745, "train/extr_return_normed_min": -0.07217187496523063, "train/extr_return_normed_std": 0.0023912016907464326, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09608991409186274, "train/extr_return_raw_max": 0.09608991409186274, "train/extr_return_raw_mean": 0.090903976932168, "train/extr_return_raw_min": 0.016702279952975612, "train/extr_return_raw_std": 0.002391201689533773, "train/extr_reward_mag": 0.0012562616417805355, "train/extr_reward_max": 0.0012562616417805355, "train/extr_reward_mean": 0.0002573723332564744, "train/extr_reward_min": 1.559033989906311e-06, "train/extr_reward_std": 0.0002647330751036255, "train/image_loss_mean": 0.120522202225402, "train/image_loss_std": 0.12097048041565965, "train/model_loss_mean": 0.7334759548927346, "train/model_loss_std": 0.1738531251127521, "train/model_opt_grad_norm": 23.744594519337017, "train/model_opt_grad_steps": 33703.546875, "train/model_opt_loss": 2015.4705410003662, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2747.3958333333335, "train/policy_entropy_mag": 1.9408039047072332, "train/policy_entropy_max": 1.9408039047072332, "train/policy_entropy_mean": 1.7411061550180118, "train/policy_entropy_min": 0.8272021226584911, "train/policy_entropy_std": 0.1276804213412106, "train/policy_logprob_mag": 4.025675081958373, "train/policy_logprob_max": -0.22493097861297429, "train/policy_logprob_mean": -1.7412520665675402, "train/policy_logprob_min": -4.025675081958373, "train/policy_logprob_std": 0.6420341224099199, "train/policy_randomness_mag": 0.9973759685332576, "train/policy_randomness_max": 0.9973759685332576, "train/policy_randomness_mean": 0.8947516217206916, "train/policy_randomness_min": 0.42509782609219354, "train/policy_randomness_std": 0.0656147610085706, "train/post_ent_mag": 20.581725647052128, "train/post_ent_max": 20.581725647052128, "train/post_ent_mean": 19.962439944346745, "train/post_ent_min": 19.59000277519226, "train/post_ent_std": 0.1875617514985303, "train/prior_ent_mag": 21.180448085069656, "train/prior_ent_max": 21.180448085069656, "train/prior_ent_mean": 18.841971427202225, "train/prior_ent_min": 17.39555797477563, "train/prior_ent_std": 0.5697729495974878, "train/rep_loss_mean": 1.000007492179672, "train/rep_loss_std": 0.00018097673637385014, "train/reward_avg": 0.00021983667670610885, "train/reward_loss_mean": 0.009588290267856792, "train/reward_loss_std": 0.014215989343938418, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001196367045243581, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009588290233902322, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002173841354912535, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.742774873971939, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.000274012447334826, "report/cont_loss_std": 0.0014832287561148405, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007908728905022144, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00025907173403538764, "report/cont_pred": 0.9978047609329224, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12747730314731598, "report/image_loss_std": 0.13858559727668762, "report/model_loss_mean": 0.7350989580154419, "report/model_loss_std": 0.1427561491727829, "report/post_ent_mag": 20.8847713470459, "report/post_ent_max": 20.8847713470459, "report/post_ent_mean": 20.23904037475586, "report/post_ent_min": 19.849552154541016, "report/post_ent_std": 0.1946975588798523, "report/prior_ent_mag": 19.368789672851562, "report/prior_ent_max": 19.368789672851562, "report/prior_ent_mean": 18.158706665039062, "report/prior_ent_min": 16.947093963623047, "report/prior_ent_std": 0.431324303150177, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00016280284035019577, "report/reward_loss_mean": 0.007347674109041691, "report/reward_loss_std": 0.012187061831355095, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011463165283203125, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007347674109041691, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000185607117600739, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.020623259246349335, "eval/cont_loss_std": 0.46086934208869934, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.437529563903809, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0002379236393608153, "eval/cont_pred": 0.9997628927230835, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2941187024116516, "eval/image_loss_std": 0.15588368475437164, "eval/model_loss_mean": 0.9160532355308533, "eval/model_loss_std": 0.4896261692047119, "eval/post_ent_mag": 20.87026596069336, "eval/post_ent_max": 20.87026596069336, "eval/post_ent_mean": 20.239803314208984, "eval/post_ent_min": 19.8559627532959, "eval/post_ent_std": 0.19213196635246277, "eval/prior_ent_mag": 20.159252166748047, "eval/prior_ent_max": 20.159252166748047, "eval/prior_ent_mean": 18.163509368896484, "eval/prior_ent_min": 16.875085830688477, "eval/prior_ent_std": 0.5096378922462463, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001311296597123146, "eval/reward_loss_std": 0.0013024440268054605, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.000977635383605957, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001311296597123146, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002062866697087884, "eval/reward_rate": 0.0, "replay/size": 556113.0, "replay/inserts": 30720.0, "replay/samples": 30720.0, "replay/insert_wait_avg": 1.3028116275866827e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.520212188363075e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0472966926642153e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1659986972809, "timer/env.step_count": 3840.0, "timer/env.step_total": 33.212238788604736, "timer/env.step_frac": 0.03320672651526224, "timer/env.step_avg": 0.008649020517865817, "timer/env.step_min": 0.007184028625488281, "timer/env.step_max": 0.03475499153137207, "timer/replay._sample_count": 30720.0, "timer/replay._sample_total": 15.117738962173462, "timer/replay._sample_frac": 0.015115229853708645, "timer/replay._sample_avg": 0.0004921138985082507, "timer/replay._sample_min": 0.0003371238708496094, "timer/replay._sample_max": 0.010442495346069336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5763.0, "timer/agent.policy_total": 56.94917321205139, "timer/agent.policy_frac": 0.0569397212924933, "timer/agent.policy_avg": 0.009881862434851882, "timer/agent.policy_min": 0.008164405822753906, "timer/agent.policy_max": 0.08982443809509277, "timer/dataset_train_count": 1920.0, "timer/dataset_train_total": 0.20665955543518066, "timer/dataset_train_frac": 0.00020662525591187396, "timer/dataset_train_avg": 0.00010763518512248992, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0004436969757080078, "timer/agent.train_count": 1920.0, "timer/agent.train_total": 856.3173325061798, "timer/agent.train_frac": 0.8561752085369185, "timer/agent.train_avg": 0.445998610680302, "timer/agent.train_min": 0.4369046688079834, "timer/agent.train_max": 0.5682973861694336, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47433972358703613, "timer/agent.report_frac": 0.000474260996879383, "timer/agent.report_avg": 0.23716986179351807, "timer/agent.report_min": 0.23102283477783203, "timer/agent.report_max": 0.2433168888092041, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908223903659654e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 30.714357638089076}
{"step": 557656, "time": 18281.278295993805, "episode/length": 640.0, "episode/score": 0.10920556144998272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10920556144998272}
{"step": 558360, "time": 18303.368551254272, "episode/length": 640.0, "episode/score": 0.08651806933096395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08651806933096395}
{"step": 558960, "time": 18322.599978923798, "episode/length": 640.0, "episode/score": 0.2642957906571155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2642957906571155}
{"step": 559120, "time": 18327.584367275238, "episode/length": 640.0, "episode/score": 0.237139699522686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.237139699522686}
{"step": 559160, "time": 18328.635847330093, "episode/length": 640.0, "episode/score": 0.25618005572573566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25618005572573566}
{"step": 559928, "time": 18352.725112199783, "episode/length": 640.0, "episode/score": 0.1722202832423818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1722202832423818}
{"step": 560040, "time": 18366.190794944763, "eval_episode/length": 579.0, "eval_episode/score": 0.18578125536441803, "eval_episode/reward_rate": 0.0017241379310344827}
{"step": 560040, "time": 18367.247832775116, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18367.256961345673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18367.26489496231, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18367.272410154343, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18367.27992081642, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18367.287190914154, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18367.29439496994, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560264, "time": 18374.30666899681, "episode/length": 640.0, "episode/score": 0.14123940474314622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14123940474314622}
{"step": 561368, "time": 18408.984586954117, "episode/length": 640.0, "episode/score": 0.2606114841122462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2606114841122462}
{"step": 562784, "time": 18453.459137439728, "episode/length": 640.0, "episode/score": 0.20405461104735423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20405461104735423}
{"step": 563488, "time": 18475.65486049652, "episode/length": 640.0, "episode/score": 0.18099623518514818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18099623518514818}
{"step": 564088, "time": 18494.26641726494, "episode/length": 640.0, "episode/score": 0.14050832005500524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14050832005500524}
{"step": 564248, "time": 18499.3562335968, "episode/length": 640.0, "episode/score": 0.15968420082674584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15968420082674584}
{"step": 564288, "time": 18500.8480117321, "episode/length": 640.0, "episode/score": 0.06526553579340089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06526553579340089}
{"step": 565056, "time": 18524.853389263153, "episode/length": 640.0, "episode/score": 0.1692894476626634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1692894476626634}
{"step": 565392, "time": 18536.0559527874, "episode/length": 640.0, "episode/score": 0.1628120357968328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1628120357968328}
{"step": 566496, "time": 18570.709596157074, "episode/length": 640.0, "episode/score": 0.14314292081269286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14314292081269286}
{"step": 567912, "time": 18614.810272693634, "episode/length": 640.0, "episode/score": 0.16766901026051073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16766901026051073}
{"step": 568616, "time": 18636.96213030815, "episode/length": 640.0, "episode/score": 0.06607286068185658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06607286068185658}
{"step": 569216, "time": 18656.073451280594, "episode/length": 640.0, "episode/score": 0.1418366225408363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1418366225408363}
{"step": 569376, "time": 18661.091295719147, "episode/length": 640.0, "episode/score": 0.14777184005498611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14777184005498611}
{"step": 569416, "time": 18662.150915384293, "episode/length": 640.0, "episode/score": 0.05870511239743337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05870511239743337}
{"step": 570024, "time": 18690.34440612793, "eval_episode/length": 499.0, "eval_episode/score": 0.2982812523841858, "eval_episode/reward_rate": 0.002}
{"step": 570024, "time": 18692.73189663887, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18692.740224838257, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18692.747873306274, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18692.755205631256, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18692.762516498566, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18692.76970410347, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18692.776980161667, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570184, "time": 18697.777741909027, "episode/length": 640.0, "episode/score": 0.08823223927515755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08823223927515755}
{"step": 570520, "time": 18708.443404197693, "episode/length": 640.0, "episode/score": 0.10839767440160131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10839767440160131}
{"step": 571624, "time": 18742.98192882538, "episode/length": 640.0, "episode/score": 0.11750626499832606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11750626499832606}
{"step": 573040, "time": 18787.621267080307, "episode/length": 640.0, "episode/score": 0.09383333002364225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09383333002364225}
{"step": 573744, "time": 18810.184697151184, "episode/length": 640.0, "episode/score": 0.1506001154112937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1506001154112937}
{"step": 574344, "time": 18828.747485399246, "episode/length": 640.0, "episode/score": 0.1361715151200542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1361715151200542}
{"step": 574504, "time": 18833.753269672394, "episode/length": 640.0, "episode/score": 0.1392556017493689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1392556017493689}
{"step": 574544, "time": 18835.25244617462, "episode/length": 640.0, "episode/score": 0.15514194981744822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15514194981744822}
{"step": 575312, "time": 18859.291387557983, "episode/length": 640.0, "episode/score": 0.11365351338054097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11365351338054097}
{"step": 575648, "time": 18869.800192832947, "episode/length": 640.0, "episode/score": 0.13232591290307028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13232591290307028}
{"step": 576752, "time": 18904.361474752426, "episode/length": 640.0, "episode/score": 0.02889300144875051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02889300144875051}
{"step": 578168, "time": 18948.852786779404, "episode/length": 640.0, "episode/score": 0.1745030242351504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745030242351504}
{"step": 578872, "time": 18970.829545497894, "episode/length": 640.0, "episode/score": 0.10911624820278121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10911624820278121}
{"step": 579472, "time": 18989.95347094536, "episode/length": 640.0, "episode/score": 0.15165530185527132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15165530185527132}
{"step": 579632, "time": 18994.981954813004, "episode/length": 640.0, "episode/score": 0.22566742734602485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22566742734602485}
{"step": 579672, "time": 18996.015788793564, "episode/length": 640.0, "episode/score": 0.14056025311936082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14056025311936082}
{"step": 580008, "time": 19018.255002737045, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.263528823853, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.27130126953, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.279173374176, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.28654718399, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.293916225433, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.301248788834, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19018.308749198914, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580440, "time": 19031.824647426605, "episode/length": 640.0, "episode/score": 0.21498370843221437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21498370843221437}
{"step": 580776, "time": 19042.43030977249, "episode/length": 640.0, "episode/score": 0.060175905139317365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060175905139317365}
{"step": 581880, "time": 19077.456375837326, "episode/length": 640.0, "episode/score": 0.18156337454928462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18156337454928462}
{"step": 583296, "time": 19121.899673461914, "episode/length": 640.0, "episode/score": 0.11137317553590265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11137317553590265}
{"step": 584000, "time": 19144.04513835907, "episode/length": 640.0, "episode/score": 0.16139345246170933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16139345246170933}
{"step": 584600, "time": 19162.722967386246, "episode/length": 640.0, "episode/score": 0.0803084706447521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0803084706447521}
{"step": 584760, "time": 19167.74585700035, "episode/length": 640.0, "episode/score": 0.1819841137584035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1819841137584035}
{"step": 584800, "time": 19169.219414711, "episode/length": 640.0, "episode/score": 0.15322158350892323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15322158350892323}
{"step": 585568, "time": 19193.24854040146, "episode/length": 640.0, "episode/score": 0.2344117276494444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2344117276494444}
{"step": 585904, "time": 19203.744421720505, "episode/length": 640.0, "episode/score": 0.19230131249179294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19230131249179294}
{"step": 587008, "time": 19238.19191980362, "episode/length": 640.0, "episode/score": 0.05401724281873044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05401724281873044}
{"step": 587321, "time": 19248.790313482285, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.230234146118164, "train/action_min": 0.0, "train/action_std": 1.8471428429087002, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007408442738778831, "train/actor_opt_grad_steps": 35655.0, "train/actor_opt_loss": -7.05191631669489, "train/adv_mag": 0.07169921354701121, "train/adv_max": 0.004497733044748505, "train/adv_mean": -3.85273989132647e-05, "train/adv_min": -0.0714805865039428, "train/adv_std": 0.001974462345970096, "train/cont_avg": 0.99835205078125, "train/cont_loss_mean": 0.003314979787470899, "train/cont_loss_std": 0.08186916920794829, "train/cont_neg_acc": 0.6909552872544382, "train/cont_neg_loss": 1.6553412726608236, "train/cont_pos_acc": 0.9999643219634891, "train/cont_pos_loss": 0.00048191494670390966, "train/cont_pred": 0.998466315989693, "train/cont_rate": 0.99835205078125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.029037963586233673, "train/extr_critic_critic_opt_grad_steps": 35655.0, "train/extr_critic_critic_opt_loss": 13479.260635375977, "train/extr_critic_mag": 0.0911690245072047, "train/extr_critic_max": 0.0911690245072047, "train/extr_critic_mean": 0.08828036328001569, "train/extr_critic_min": 0.08314230230947335, "train/extr_critic_std": 0.0011122079486085568, "train/extr_return_normed_mag": 0.07039660925511271, "train/extr_return_normed_max": 0.007856400838742653, "train/extr_return_normed_mean": 0.002374033136826862, "train/extr_return_normed_min": -0.06938513348965596, "train/extr_return_normed_std": 0.002304986429711183, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0937241940991953, "train/extr_return_raw_max": 0.0937241940991953, "train/extr_return_raw_mean": 0.08824183039056759, "train/extr_return_raw_min": 0.016482659770796698, "train/extr_return_raw_std": 0.0023049864303175127, "train/extr_reward_mag": 0.0012606171270211537, "train/extr_reward_max": 0.0012606171270211537, "train/extr_reward_mean": 0.0002603361883757316, "train/extr_reward_min": 2.4139881134033203e-06, "train/extr_reward_std": 0.00026620092648954596, "train/image_loss_mean": 0.11733205954078585, "train/image_loss_std": 0.12179768458008766, "train/model_loss_mean": 0.7302423774575194, "train/model_loss_std": 0.17048492604711404, "train/model_opt_grad_norm": 23.676877652605373, "train/model_opt_grad_steps": 35622.588541666664, "train/model_opt_loss": 3526.887106577555, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4830.729166666667, "train/policy_entropy_mag": 1.9401603577037652, "train/policy_entropy_max": 1.9401603577037652, "train/policy_entropy_mean": 1.7313187749435504, "train/policy_entropy_min": 0.8361097350716591, "train/policy_entropy_std": 0.1262544421867157, "train/policy_logprob_mag": 4.038000551362832, "train/policy_logprob_max": -0.22661759130035838, "train/policy_logprob_mean": -1.7309651461740334, "train/policy_logprob_min": -4.038000551362832, "train/policy_logprob_std": 0.6552232460429271, "train/policy_randomness_mag": 0.9970452524721622, "train/policy_randomness_max": 0.9970452524721622, "train/policy_randomness_mean": 0.889721908296148, "train/policy_randomness_min": 0.42967543362950283, "train/policy_randomness_std": 0.06488195195561275, "train/post_ent_mag": 20.52310250202815, "train/post_ent_max": 20.52310250202815, "train/post_ent_mean": 19.825772752364475, "train/post_ent_min": 19.39098357160886, "train/post_ent_std": 0.20990948216058314, "train/prior_ent_mag": 20.38583394885063, "train/prior_ent_max": 20.38583394885063, "train/prior_ent_mean": 18.405809203783672, "train/prior_ent_min": 17.14072275161743, "train/prior_ent_std": 0.4494324380842348, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.000220206363565012, "train/reward_loss_mean": 0.009595315515374144, "train/reward_loss_std": 0.0141692245718635, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012009379764397938, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009595315493546272, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002187839351487734, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7350853780905406, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.00036428141174837947, "report/cont_loss_std": 0.0010906198294833302, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00036428141174837947, "report/cont_pred": 0.9996363520622253, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10016536712646484, "report/image_loss_std": 0.11229824274778366, "report/model_loss_mean": 0.7113224267959595, "report/model_loss_std": 0.11699661612510681, "report/post_ent_mag": 20.318384170532227, "report/post_ent_max": 20.318384170532227, "report/post_ent_mean": 19.587099075317383, "report/post_ent_min": 19.17554473876953, "report/post_ent_std": 0.21904808282852173, "report/prior_ent_mag": 20.089582443237305, "report/prior_ent_max": 20.089582443237305, "report/prior_ent_mean": 18.612316131591797, "report/prior_ent_min": 17.52722930908203, "report/prior_ent_std": 0.4049156904220581, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000250554527156055, "report/reward_loss_mean": 0.010792672634124756, "report/reward_loss_std": 0.014590203762054443, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012606382369995117, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010792671702802181, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002635660348460078, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.010378988459706306, "eval/cont_loss_std": 0.29813075065612793, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.53913402557373, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0010644674766808748, "eval/cont_pred": 0.9989952445030212, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2757524847984314, "eval/image_loss_std": 0.14738404750823975, "eval/model_loss_mean": 0.8878982663154602, "eval/model_loss_std": 0.3287380039691925, "eval/post_ent_mag": 20.30815315246582, "eval/post_ent_max": 20.30815315246582, "eval/post_ent_mean": 19.59156608581543, "eval/post_ent_min": 19.138179779052734, "eval/post_ent_std": 0.21359987556934357, "eval/prior_ent_mag": 20.553829193115234, "eval/prior_ent_max": 20.553829193115234, "eval/prior_ent_mean": 18.531408309936523, "eval/prior_ent_min": 17.20250701904297, "eval/prior_ent_std": 0.4199415147304535, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0017667682841420174, "eval/reward_loss_std": 0.0016697291284799576, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001175522804260254, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017667682841420174, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00027784332633018494, "eval/reward_rate": 0.0, "replay/size": 586817.0, "replay/inserts": 30704.0, "replay/samples": 30704.0, "replay/insert_wait_avg": 1.2918041049347004e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.590322117807966e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0180832877235987e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3070862293243, "timer/env.step_count": 3838.0, "timer/env.step_total": 33.25805115699768, "timer/env.step_frac": 0.03324784120280953, "timer/env.step_avg": 0.008665464084678916, "timer/env.step_min": 0.007250547409057617, "timer/env.step_max": 0.03480386734008789, "timer/replay._sample_count": 30704.0, "timer/replay._sample_total": 15.249220371246338, "timer/replay._sample_frac": 0.015244538983252183, "timer/replay._sample_avg": 0.0004966525655043753, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.028026342391967773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5761.0, "timer/agent.policy_total": 57.07347822189331, "timer/agent.policy_frac": 0.05705595712315987, "timer/agent.policy_avg": 0.00990687002636579, "timer/agent.policy_min": 0.008377313613891602, "timer/agent.policy_max": 0.08786201477050781, "timer/dataset_train_count": 1919.0, "timer/dataset_train_total": 0.2056736946105957, "timer/dataset_train_frac": 0.0002056105544407232, "timer/dataset_train_avg": 0.00010717753757717338, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.00025963783264160156, "timer/agent.train_count": 1919.0, "timer/agent.train_total": 856.4376020431519, "timer/agent.train_frac": 0.8561746825882328, "timer/agent.train_avg": 0.44629369569731725, "timer/agent.train_min": 0.4379723072052002, "timer/agent.train_max": 0.5966644287109375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748671054840088, "timer/agent.report_frac": 0.00047472132510230326, "timer/agent.report_avg": 0.2374335527420044, "timer/agent.report_min": 0.23044276237487793, "timer/agent.report_max": 0.24442434310913086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241497256611352e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 30.694044134330543}
{"step": 588016, "time": 19270.32082414627, "episode/length": 263.0, "episode/score": 0.1226890314054856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1226890314054856}
{"step": 588424, "time": 19282.85598540306, "episode/length": 640.0, "episode/score": 0.18837115665374426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18837115665374426}
{"step": 589128, "time": 19304.593621253967, "episode/length": 640.0, "episode/score": 0.18337333669134637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18337333669134637}
{"step": 589728, "time": 19323.517447948456, "episode/length": 640.0, "episode/score": 0.20598708370314966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20598708370314966}
{"step": 589888, "time": 19328.971440553665, "episode/length": 640.0, "episode/score": 0.07605911754862404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07605911754862404}
{"step": 589928, "time": 19329.99330163002, "episode/length": 640.0, "episode/score": 0.12408011691030651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12408011691030651}
{"step": 590096, "time": 19342.272740125656, "eval_episode/length": 395.0, "eval_episode/score": 0.44453126192092896, "eval_episode/reward_rate": 0.0025252525252525255}
{"step": 590096, "time": 19346.45469236374, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19346.463315486908, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19346.470913410187, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19346.478484869003, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19346.485785007477, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19346.493207216263, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19346.500416994095, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590696, "time": 19364.914674520493, "episode/length": 640.0, "episode/score": 0.18631777569947872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18631777569947872}
{"step": 592136, "time": 19410.202124118805, "episode/length": 640.0, "episode/score": 0.21545224591531564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21545224591531564}
{"step": 593144, "time": 19441.723219156265, "episode/length": 640.0, "episode/score": 0.2558281689087494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2558281689087494}
{"step": 593552, "time": 19454.7422311306, "episode/length": 640.0, "episode/score": 0.2607649483008174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2607649483008174}
{"step": 594256, "time": 19476.828848838806, "episode/length": 640.0, "episode/score": 0.2367537162635358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2367537162635358}
{"step": 594856, "time": 19495.571299552917, "episode/length": 640.0, "episode/score": 0.26115505196847266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26115505196847266}
{"step": 595016, "time": 19500.51092004776, "episode/length": 640.0, "episode/score": 0.18251222564367708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18251222564367708}
{"step": 595056, "time": 19501.972997426987, "episode/length": 640.0, "episode/score": 0.13891391561458022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13891391561458022}
{"step": 595824, "time": 19526.000448942184, "episode/length": 640.0, "episode/score": 0.25997442872235865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25997442872235865}
{"step": 597264, "time": 19570.951766252518, "episode/length": 640.0, "episode/score": 0.11744167271467632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11744167271467632}
{"step": 598272, "time": 19602.87394976616, "episode/length": 640.0, "episode/score": 0.25793291424906784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25793291424906784}
{"step": 598680, "time": 19615.488874912262, "episode/length": 640.0, "episode/score": 0.09893934201750199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09893934201750199}
{"step": 599384, "time": 19639.020998954773, "episode/length": 640.0, "episode/score": 0.10358978804254093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10358978804254093}
{"step": 599984, "time": 19657.84845638275, "episode/length": 640.0, "episode/score": 0.05634215329644121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05634215329644121}
{"step": 600080, "time": 19672.680052042007, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.689581632614, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.697618484497, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.705139160156, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.71259188652, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.720018148422, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.727234840393, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19672.73452115059, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600144, "time": 19674.746460437775, "episode/length": 640.0, "episode/score": 0.09666044867708479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09666044867708479}
{"step": 600184, "time": 19675.77333688736, "episode/length": 640.0, "episode/score": 0.22366636025469688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22366636025469688}
{"step": 600952, "time": 19699.71390771866, "episode/length": 640.0, "episode/score": 0.2098797486123658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2098797486123658}
{"step": 602392, "time": 19744.423383951187, "episode/length": 640.0, "episode/score": 0.10313681092571869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10313681092571869}
{"step": 603400, "time": 19776.009892463684, "episode/length": 640.0, "episode/score": 0.03776136440899336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03776136440899336}
{"step": 603808, "time": 19789.087844371796, "episode/length": 640.0, "episode/score": 0.15952719069969135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15952719069969135}
{"step": 604512, "time": 19811.017750501633, "episode/length": 640.0, "episode/score": 0.17538178925434522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17538178925434522}
{"step": 605112, "time": 19829.637721538544, "episode/length": 640.0, "episode/score": 0.13861497012800328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13861497012800328}
{"step": 605272, "time": 19834.61097407341, "episode/length": 640.0, "episode/score": 0.16648313970330264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16648313970330264}
{"step": 605312, "time": 19836.077378988266, "episode/length": 640.0, "episode/score": 0.1411782961559993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1411782961559993}
{"step": 606080, "time": 19860.07176589966, "episode/length": 640.0, "episode/score": 0.22068823224014977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22068823224014977}
{"step": 607520, "time": 19905.151601076126, "episode/length": 640.0, "episode/score": 0.2662600471479095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2662600471479095}
{"step": 608528, "time": 19936.476353406906, "episode/length": 640.0, "episode/score": 0.2129010079645468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2129010079645468}
{"step": 608936, "time": 19948.934571266174, "episode/length": 640.0, "episode/score": 0.26683068249758435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26683068249758435}
{"step": 609640, "time": 19970.895071029663, "episode/length": 640.0, "episode/score": 0.267227960403261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.267227960403261}
{"step": 610064, "time": 19995.368633508682, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.553149938583, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.603409290314, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.652391433716, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.709545373917, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.717495441437, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.76566672325, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19995.81965279579, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610240, "time": 20001.321897745132, "episode/length": 640.0, "episode/score": 0.27582473397615104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27582473397615104}
{"step": 610400, "time": 20006.268475055695, "episode/length": 640.0, "episode/score": 0.21110958071449204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21110958071449204}
{"step": 610440, "time": 20007.29244852066, "episode/length": 640.0, "episode/score": 0.23763374258646763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23763374258646763}
{"step": 611208, "time": 20031.165096759796, "episode/length": 640.0, "episode/score": 0.2701412530921061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2701412530921061}
{"step": 612648, "time": 20075.761432886124, "episode/length": 640.0, "episode/score": 0.14313785630110942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14313785630110942}
{"step": 613656, "time": 20107.07362985611, "episode/length": 640.0, "episode/score": 0.20313052023732325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20313052023732325}
{"step": 614064, "time": 20120.232766389847, "episode/length": 640.0, "episode/score": 0.184767564089384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.184767564089384}
{"step": 614768, "time": 20142.573661088943, "episode/length": 640.0, "episode/score": 0.1796975759750694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1796975759750694}
{"step": 615368, "time": 20161.012080430984, "episode/length": 640.0, "episode/score": 0.22127508798610052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22127508798610052}
{"step": 615528, "time": 20165.98473572731, "episode/length": 640.0, "episode/score": 0.18711700373535223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18711700373535223}
{"step": 615568, "time": 20167.44750404358, "episode/length": 640.0, "episode/score": 0.11396004270318372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11396004270318372}
{"step": 616336, "time": 20191.271695375443, "episode/length": 640.0, "episode/score": 0.19597847122508938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19597847122508938}
{"step": 617168, "time": 20217.301484823227, "episode/length": 199.0, "episode/score": 0.07677077066784932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07677077066784932}
{"step": 617776, "time": 20236.198687553406, "episode/length": 640.0, "episode/score": 0.14126827426321142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14126827426321142}
{"step": 618169, "time": 20249.131407499313, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2253475189208984, "train/action_min": 0.0, "train/action_std": 1.850230713064472, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007527926403175419, "train/actor_opt_grad_steps": 37575.0, "train/actor_opt_loss": -6.796785476927956, "train/adv_mag": 0.07481009474334617, "train/adv_max": 0.004667100845836103, "train/adv_mean": -2.400358691708367e-05, "train/adv_min": -0.07461103168316185, "train/adv_std": 0.002080049969966543, "train/cont_avg": 0.9983774820963541, "train/cont_loss_mean": 0.003269358694069524, "train/cont_loss_std": 0.08380071253759525, "train/cont_neg_acc": 0.7280922457107208, "train/cont_neg_loss": 1.6580624469649632, "train/cont_pos_acc": 0.9999643387272954, "train/cont_pos_loss": 0.0005234848194580385, "train/cont_pred": 0.9984040204435587, "train/cont_rate": 0.9983774820963541, "train/dyn_loss_mean": 1.0000073841462533, "train/dyn_loss_std": 0.0002361719869981016, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.029405382450022444, "train/extr_critic_critic_opt_grad_steps": 37575.0, "train/extr_critic_critic_opt_loss": 13497.201146443686, "train/extr_critic_mag": 0.08991029796501, "train/extr_critic_max": 0.08991029796501, "train/extr_critic_mean": 0.08687346688626955, "train/extr_critic_min": 0.08158199054499467, "train/extr_critic_std": 0.0011528405390587675, "train/extr_return_normed_mag": 0.07316494329522054, "train/extr_return_normed_max": 0.008190265779073039, "train/extr_return_normed_mean": 0.002540705880164751, "train/extr_return_normed_min": -0.07236148770122479, "train/extr_return_normed_std": 0.002412394351874051, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09249898643853764, "train/extr_return_raw_max": 0.09249898643853764, "train/extr_return_raw_mean": 0.08684943049835663, "train/extr_return_raw_min": 0.011947232958239814, "train/extr_return_raw_std": 0.00241239435611836, "train/extr_reward_mag": 0.0012423321604728699, "train/extr_reward_max": 0.0012423321604728699, "train/extr_reward_mean": 0.00026076452574367676, "train/extr_reward_min": 2.635642886161804e-06, "train/extr_reward_std": 0.00026794384734785126, "train/image_loss_mean": 0.11473139542310189, "train/image_loss_std": 0.12185632173592846, "train/model_loss_mean": 0.7275509337584177, "train/model_loss_std": 0.1741372945252806, "train/model_opt_grad_norm": 22.020600850383442, "train/model_opt_grad_steps": 37540.739583333336, "train/model_opt_loss": 2992.379221598307, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4140.625, "train/policy_entropy_mag": 1.9396092779934406, "train/policy_entropy_max": 1.9396092779934406, "train/policy_entropy_mean": 1.725545370330413, "train/policy_entropy_min": 0.7892170324921608, "train/policy_entropy_std": 0.12946363457012922, "train/policy_logprob_mag": 4.126163507501285, "train/policy_logprob_max": -0.21094256670524678, "train/policy_logprob_mean": -1.725347999483347, "train/policy_logprob_min": -4.126163507501285, "train/policy_logprob_std": 0.659605427334706, "train/policy_randomness_mag": 0.9967620506261786, "train/policy_randomness_max": 0.9967620506261786, "train/policy_randomness_mean": 0.8867549675827225, "train/policy_randomness_min": 0.40557734792431194, "train/policy_randomness_std": 0.06653115085403745, "train/post_ent_mag": 21.083095371723175, "train/post_ent_max": 21.083095371723175, "train/post_ent_mean": 20.17412981390953, "train/post_ent_min": 19.59331637620926, "train/post_ent_std": 0.27409825668049353, "train/prior_ent_mag": 20.909196217854817, "train/prior_ent_max": 20.909196217854817, "train/prior_ent_mean": 18.9488964676857, "train/prior_ent_min": 17.66712259252866, "train/prior_ent_std": 0.4525702213868499, "train/rep_loss_mean": 1.0000073841462533, "train/rep_loss_std": 0.0002361719869981016, "train/reward_avg": 0.00021884883805493396, "train/reward_loss_mean": 0.00954572514698763, "train/reward_loss_std": 0.014111450587127669, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0011922804017861683, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009545725205195291, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021874173156296214, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7296696755350853, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.000757775385864079, "report/cont_loss_std": 0.006917767692357302, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03975493088364601, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0007196550141088665, "report/cont_pred": 0.9983648657798767, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09215895086526871, "report/image_loss_std": 0.10164056718349457, "report/model_loss_mean": 0.7021892070770264, "report/model_loss_std": 0.1059076115489006, "report/post_ent_mag": 21.459697723388672, "report/post_ent_max": 21.459697723388672, "report/post_ent_mean": 20.49366569519043, "report/post_ent_min": 19.848499298095703, "report/post_ent_std": 0.2845190763473511, "report/prior_ent_mag": 21.28195571899414, "report/prior_ent_max": 21.28195571899414, "report/prior_ent_mean": 19.691408157348633, "report/prior_ent_min": 18.331790924072266, "report/prior_ent_std": 0.5210674405097961, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021529174409806728, "report/reward_loss_mean": 0.00927240401506424, "report/reward_loss_std": 0.014098444022238255, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012173652648925781, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009272403083741665, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002220753813162446, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0021695178002119064, "eval/cont_loss_std": 0.03544096276164055, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.9990234375, "eval/cont_pos_loss": 0.0021695178002119064, "eval/cont_pred": 0.9983092546463013, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.31325262784957886, "eval/image_loss_std": 0.15380865335464478, "eval/model_loss_mean": 0.9168469905853271, "eval/model_loss_std": 0.1581178903579712, "eval/post_ent_mag": 21.46846580505371, "eval/post_ent_max": 21.46846580505371, "eval/post_ent_mean": 20.469491958618164, "eval/post_ent_min": 19.890283584594727, "eval/post_ent_std": 0.2840380072593689, "eval/prior_ent_mag": 21.543485641479492, "eval/prior_ent_max": 21.543485641479492, "eval/prior_ent_mean": 19.67140769958496, "eval/prior_ent_min": 18.196359634399414, "eval/prior_ent_std": 0.4974993169307709, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014248699881136417, "eval/reward_loss_std": 0.0014476161450147629, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011870861053466797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014248699881136417, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022412312682718039, "eval/reward_rate": 0.0, "replay/size": 617665.0, "replay/inserts": 30848.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.3045781133580504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.590226584944981e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0062429474718052e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3269474506378, "timer/env.step_count": 3856.0, "timer/env.step_total": 33.39573001861572, "timer/env.step_frac": 0.03338481493848157, "timer/env.step_avg": 0.00866071836582358, "timer/env.step_min": 0.0072612762451171875, "timer/env.step_max": 0.04123973846435547, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.343278884887695, "timer/replay._sample_frac": 0.015338264078550004, "timer/replay._sample_avg": 0.0004973832626065772, "timer/replay._sample_min": 0.0004074573516845703, "timer/replay._sample_max": 0.010868310928344727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5779.0, "timer/agent.policy_total": 57.03094935417175, "timer/agent.policy_frac": 0.057012309324982975, "timer/agent.policy_avg": 0.009868653634568568, "timer/agent.policy_min": 0.008521318435668945, "timer/agent.policy_max": 0.09347939491271973, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.20844268798828125, "timer/dataset_train_frac": 0.00020837456045696208, "timer/dataset_train_avg": 0.00010811342737981393, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0010902881622314453, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 855.5414419174194, "timer/agent.train_frac": 0.8552618162469696, "timer/agent.train_avg": 0.44374556116048725, "timer/agent.train_min": 0.4329869747161865, "timer/agent.train_max": 2.037357807159424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47714829444885254, "timer/agent.report_frac": 0.00047699234301832894, "timer/agent.report_avg": 0.23857414722442627, "timer/agent.report_min": 0.23307275772094727, "timer/agent.report_max": 0.24407553672790527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2175988321357517e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 30.837355920672906}
{"step": 618784, "time": 20268.308730840683, "episode/length": 640.0, "episode/score": 0.13791679127177758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13791679127177758}
{"step": 619192, "time": 20280.744411468506, "episode/length": 640.0, "episode/score": 0.16684052526875348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16684052526875348}
{"step": 619896, "time": 20302.671837091446, "episode/length": 640.0, "episode/score": 0.172342389185701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.172342389185701}
{"step": 620048, "time": 20318.550768613815, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.561406612396, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.569336891174, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.576823472977, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.58429121971, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.59161567688, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.598814964294, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20318.60599088669, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620496, "time": 20332.562560796738, "episode/length": 640.0, "episode/score": 0.20003067137645303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20003067137645303}
{"step": 620656, "time": 20337.527595758438, "episode/length": 640.0, "episode/score": 0.16861378651753967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16861378651753967}
{"step": 621464, "time": 20362.425535917282, "episode/length": 640.0, "episode/score": 0.21524374853527206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21524374853527206}
{"step": 622296, "time": 20388.22937107086, "episode/length": 640.0, "episode/score": 0.2581434912784175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2581434912784175}
{"step": 622904, "time": 20407.600253343582, "episode/length": 640.0, "episode/score": 0.13567190084853564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13567190084853564}
{"step": 623912, "time": 20438.912608623505, "episode/length": 640.0, "episode/score": 0.2470655658657961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2470655658657961}
{"step": 624320, "time": 20451.895307064056, "episode/length": 640.0, "episode/score": 0.2115586065127104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2115586065127104}
{"step": 625024, "time": 20473.79098367691, "episode/length": 640.0, "episode/score": 0.15978998864852656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15978998864852656}
{"step": 625624, "time": 20492.615023851395, "episode/length": 640.0, "episode/score": 0.17713161665108146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17713161665108146}
{"step": 625784, "time": 20497.64911174774, "episode/length": 640.0, "episode/score": 0.11207835687815759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11207835687815759}
{"step": 626592, "time": 20523.124637126923, "episode/length": 640.0, "episode/score": 0.13618200748572917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13618200748572917}
{"step": 627424, "time": 20549.29337477684, "episode/length": 640.0, "episode/score": 0.1101279127659609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1101279127659609}
{"step": 628032, "time": 20568.263641357422, "episode/length": 640.0, "episode/score": 0.22288857492844727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22288857492844727}
{"step": 629040, "time": 20599.510593414307, "episode/length": 640.0, "episode/score": 0.21422105536800018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21422105536800018}
{"step": 629448, "time": 20612.13576245308, "episode/length": 640.0, "episode/score": 0.24123865544356704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24123865544356704}
{"step": 630032, "time": 20642.389188289642, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.397827148438, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.4054415226, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.412970781326, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.42024374008, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.427468299866, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.434628248215, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20642.441691875458, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630152, "time": 20645.935291051865, "episode/length": 640.0, "episode/score": 0.20179917587438467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20179917587438467}
{"step": 630752, "time": 20664.78130865097, "episode/length": 640.0, "episode/score": 0.2097265564116242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2097265564116242}
{"step": 630912, "time": 20670.23217010498, "episode/length": 640.0, "episode/score": 0.2062339885717961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2062339885717961}
{"step": 631720, "time": 20695.10617876053, "episode/length": 640.0, "episode/score": 0.08813553233710536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08813553233710536}
{"step": 632552, "time": 20720.953672409058, "episode/length": 640.0, "episode/score": 0.24129597280585813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24129597280585813}
{"step": 633160, "time": 20739.78413438797, "episode/length": 640.0, "episode/score": 0.20928798336342425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20928798336342425}
{"step": 634168, "time": 20771.037997484207, "episode/length": 640.0, "episode/score": 0.14328490638021663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14328490638021663}
{"step": 634576, "time": 20783.91248512268, "episode/length": 640.0, "episode/score": 0.14095387601201992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14095387601201992}
{"step": 635280, "time": 20805.761058092117, "episode/length": 640.0, "episode/score": 0.2020315539712385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2020315539712385}
{"step": 635880, "time": 20824.143781900406, "episode/length": 640.0, "episode/score": 0.1488305883083001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1488305883083001}
{"step": 636040, "time": 20829.095722913742, "episode/length": 640.0, "episode/score": 0.22154695652866963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22154695652866963}
{"step": 636848, "time": 20854.41180086136, "episode/length": 640.0, "episode/score": 0.20675950662368336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20675950662368336}
{"step": 637680, "time": 20880.59960794449, "episode/length": 640.0, "episode/score": 0.2630625493022194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2630625493022194}
{"step": 638288, "time": 20899.670000314713, "episode/length": 640.0, "episode/score": 0.14415532274077236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14415532274077236}
{"step": 639032, "time": 20922.96617460251, "episode/length": 393.0, "episode/score": 0.13729614628363151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13729614628363151}
{"step": 639296, "time": 20931.428310394287, "episode/length": 640.0, "episode/score": 0.19558798595434723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19558798595434723}
{"step": 639704, "time": 20943.88414478302, "episode/length": 640.0, "episode/score": 0.17755881289659214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17755881289659214}
{"step": 640016, "time": 20965.074357509613, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.083193063736, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.091409921646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.099059581757, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.106477499008, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.113967895508, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.121300458908, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20965.128877401352, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640408, "time": 20977.066353082657, "episode/length": 640.0, "episode/score": 0.11217724237167204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11217724237167204}
{"step": 641168, "time": 21000.857320308685, "episode/length": 640.0, "episode/score": 0.15786917991934502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15786917991934502}
{"step": 641976, "time": 21025.70330262184, "episode/length": 640.0, "episode/score": 0.16638259890987683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16638259890987683}
{"step": 642808, "time": 21051.58802127838, "episode/length": 640.0, "episode/score": 0.13345978403356185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13345978403356185}
{"step": 643224, "time": 21064.46673297882, "episode/length": 439.0, "episode/score": 0.18011492037649646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18011492037649646}
{"step": 643416, "time": 21070.40269088745, "episode/length": 640.0, "episode/score": 0.1580217941946387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1580217941946387}
{"step": 644160, "time": 21093.719551563263, "episode/length": 640.0, "episode/score": 0.173424557591062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.173424557591062}
{"step": 644424, "time": 21101.65010213852, "episode/length": 640.0, "episode/score": 0.12062144374087325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12062144374087325}
{"step": 645536, "time": 21136.505053043365, "episode/length": 640.0, "episode/score": 0.1858209759068643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1858209759068643}
{"step": 646296, "time": 21159.824913978577, "episode/length": 640.0, "episode/score": 0.047284797387504796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047284797387504796}
{"step": 647104, "time": 21185.20644903183, "episode/length": 640.0, "episode/score": 0.17779012717232945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17779012717232945}
{"step": 647936, "time": 21211.543573141098, "episode/length": 640.0, "episode/score": 0.14414869740214442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14414869740214442}
{"step": 648352, "time": 21224.413674116135, "episode/length": 640.0, "episode/score": 0.0798729393334554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0798729393334554}
{"step": 648544, "time": 21230.411972999573, "episode/length": 640.0, "episode/score": 0.10914223865239592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10914223865239592}
{"step": 649129, "time": 21249.234843730927, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.233296187882571, "train/action_min": 0.0, "train/action_std": 1.8542596089471246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007220680497469112, "train/actor_opt_grad_steps": 39505.0, "train/actor_opt_loss": -6.071839831999896, "train/adv_mag": 0.07424913212349735, "train/adv_max": 0.004748838886464994, "train/adv_mean": 1.9214009698677645e-05, "train/adv_min": -0.07404774942041673, "train/adv_std": 0.0019895507070144696, "train/cont_avg": 0.9985200547680413, "train/cont_loss_mean": 0.0029407227606891855, "train/cont_loss_std": 0.07134849430867783, "train/cont_neg_acc": 0.7433114067504281, "train/cont_neg_loss": 1.4342775195220479, "train/cont_pos_acc": 0.9999596538002958, "train/cont_pos_loss": 0.0004970264946921853, "train/cont_pred": 0.9985244556800607, "train/cont_rate": 0.9985200547680413, "train/dyn_loss_mean": 1.0000007484377045, "train/dyn_loss_std": 2.394990340540109e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.025896702129327806, "train/extr_critic_critic_opt_grad_steps": 39505.0, "train/extr_critic_critic_opt_loss": 13502.140715608892, "train/extr_critic_mag": 0.09006786407883634, "train/extr_critic_max": 0.09006786407883634, "train/extr_critic_mean": 0.0869299335424433, "train/extr_critic_min": 0.0817140568162977, "train/extr_critic_std": 0.0011692833207600471, "train/extr_return_normed_mag": 0.07252558712492284, "train/extr_return_normed_max": 0.008410495158630548, "train/extr_return_normed_mean": 0.0026143212363450336, "train/extr_return_normed_min": -0.07167696726230002, "train/extr_return_normed_std": 0.0023422070296442847, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09274530910032312, "train/extr_return_raw_max": 0.09274530910032312, "train/extr_return_raw_mean": 0.08694913971823515, "train/extr_return_raw_min": 0.01265784667939255, "train/extr_return_raw_std": 0.0023422070344449163, "train/extr_reward_mag": 0.0012345338605113864, "train/extr_reward_max": 0.0012345338605113864, "train/extr_reward_mean": 0.0002653271696601092, "train/extr_reward_min": 2.8038762279392518e-06, "train/extr_reward_std": 0.0002722231898193977, "train/image_loss_mean": 0.11115098640937165, "train/image_loss_std": 0.12026677964274417, "train/model_loss_mean": 0.7236358345169382, "train/model_loss_std": 0.16425791390470623, "train/model_opt_grad_norm": 21.54441900351613, "train/model_opt_grad_steps": 39469.63917525773, "train/model_opt_loss": 3395.5877156995007, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4690.721649484536, "train/policy_entropy_mag": 1.94069644655149, "train/policy_entropy_max": 1.94069644655149, "train/policy_entropy_mean": 1.720800483964153, "train/policy_entropy_min": 0.7378352958824217, "train/policy_entropy_std": 0.13647748053688363, "train/policy_logprob_mag": 4.211683994715976, "train/policy_logprob_max": -0.19103220758057132, "train/policy_logprob_mean": -1.7207895277701701, "train/policy_logprob_min": -4.211683994715976, "train/policy_logprob_std": 0.6676095705671409, "train/policy_randomness_mag": 0.99732074571639, "train/policy_randomness_max": 0.99732074571639, "train/policy_randomness_mean": 0.8843165731307158, "train/policy_randomness_min": 0.3791723570872828, "train/policy_randomness_std": 0.07013555477882169, "train/post_ent_mag": 21.577159055729503, "train/post_ent_max": 21.577159055729503, "train/post_ent_mean": 20.341677282274382, "train/post_ent_min": 19.54115638536276, "train/post_ent_std": 0.3651074195645519, "train/prior_ent_mag": 21.169347291140213, "train/prior_ent_max": 21.169347291140213, "train/prior_ent_mean": 19.44219215629027, "train/prior_ent_min": 18.187875354412906, "train/prior_ent_std": 0.4301158341857576, "train/rep_loss_mean": 1.0000007484377045, "train/rep_loss_std": 2.394990340540109e-05, "train/reward_avg": 0.0002190390368923545, "train/reward_loss_mean": 0.009543655603432778, "train/reward_loss_std": 0.014029420691436714, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0011971168911334166, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009543655615434358, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022067976563439233, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7259034015694443, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0007339990115724504, "report/cont_loss_std": 0.008206481114029884, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02667130157351494, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0006577875465154648, "report/cont_pred": 0.9965187907218933, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09237603843212128, "report/image_loss_std": 0.11195753514766693, "report/model_loss_mean": 0.7013047933578491, "report/model_loss_std": 0.1150030791759491, "report/post_ent_mag": 22.397066116333008, "report/post_ent_max": 22.397066116333008, "report/post_ent_mean": 20.146709442138672, "report/post_ent_min": 18.66168212890625, "report/post_ent_std": 0.6680546998977661, "report/prior_ent_mag": 21.322179794311523, "report/prior_ent_max": 21.322179794311523, "report/prior_ent_mean": 19.64444351196289, "report/prior_ent_min": 18.11684799194336, "report/prior_ent_std": 0.437931090593338, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018563865160103887, "report/reward_loss_mean": 0.008194752037525177, "report/reward_loss_std": 0.012742020189762115, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011441707611083984, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008194752037525177, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001999473897740245, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.029769167304039, "eval/cont_loss_std": 0.5396621227264404, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.94018268585205, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006494444678537548, "eval/cont_pred": 0.9993631839752197, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2756950259208679, "eval/image_loss_std": 0.13837753236293793, "eval/model_loss_mean": 0.9069616794586182, "eval/model_loss_std": 0.5516166687011719, "eval/post_ent_mag": 22.243553161621094, "eval/post_ent_max": 22.243553161621094, "eval/post_ent_mean": 20.074310302734375, "eval/post_ent_min": 18.6812686920166, "eval/post_ent_std": 0.6379891037940979, "eval/prior_ent_mag": 21.849285125732422, "eval/prior_ent_max": 21.849285125732422, "eval/prior_ent_mean": 19.604795455932617, "eval/prior_ent_min": 18.57851791381836, "eval/prior_ent_std": 0.40206459164619446, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014974242076277733, "eval/reward_loss_std": 0.0014078710228204727, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010627508163452148, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014974242076277733, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023554451763629913, "eval/reward_rate": 0.0, "replay/size": 648625.0, "replay/inserts": 30960.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.298449452225244e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.559383688046951e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0408340985739039e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0856590270996, "timer/env.step_count": 3870.0, "timer/env.step_total": 33.499289751052856, "timer/env.step_frac": 0.033496420480263196, "timer/env.step_avg": 0.008656147222494278, "timer/env.step_min": 0.007233381271362305, "timer/env.step_max": 0.03439903259277344, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.388580322265625, "timer/replay._sample_frac": 0.015387262264350334, "timer/replay._sample_avg": 0.0004970471680318354, "timer/replay._sample_min": 0.00037598609924316406, "timer/replay._sample_max": 0.010363101959228516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5793.0, "timer/agent.policy_total": 57.31631827354431, "timer/agent.policy_frac": 0.05731140903400475, "timer/agent.policy_avg": 0.009894064953140741, "timer/agent.policy_min": 0.00863194465637207, "timer/agent.policy_max": 0.08063530921936035, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.21026062965393066, "timer/dataset_train_frac": 0.00021024262047560584, "timer/dataset_train_avg": 0.00010866182411055848, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.00047969818115234375, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 855.3875486850739, "timer/agent.train_frac": 0.8553142832957024, "timer/agent.train_avg": 0.44206074867445677, "timer/agent.train_min": 0.4336059093475342, "timer/agent.train_max": 0.5924203395843506, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745516777038574, "timer/agent.report_frac": 0.0004745110315505468, "timer/agent.report_avg": 0.2372758388519287, "timer/agent.report_min": 0.23095440864562988, "timer/agent.report_max": 0.24359726905822754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.12301587172928e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 30.956807812423772}
{"step": 649288, "time": 21253.94988965988, "episode/length": 640.0, "episode/score": 0.1717743550621691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1717743550621691}
{"step": 649552, "time": 21262.467401504517, "episode/length": 640.0, "episode/score": 0.10948260799247578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10948260799247578}
{"step": 650000, "time": 21288.307196378708, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.31614923477, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.323709726334, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.335459709167, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.345432281494, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.353949785233, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.36886405945, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21288.37692141533, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650664, "time": 21308.884154081345, "episode/length": 640.0, "episode/score": 0.0853788852637507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0853788852637507}
{"step": 651424, "time": 21333.104625940323, "episode/length": 640.0, "episode/score": 0.09593778775818862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09593778775818862}
{"step": 652232, "time": 21357.919406414032, "episode/length": 640.0, "episode/score": 0.0884950547338974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0884950547338974}
{"step": 653064, "time": 21383.837221860886, "episode/length": 640.0, "episode/score": 0.05577194761607984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05577194761607984}
{"step": 653480, "time": 21396.723029375076, "episode/length": 640.0, "episode/score": 0.13186169839843842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13186169839843842}
{"step": 653672, "time": 21402.682274103165, "episode/length": 640.0, "episode/score": 0.04728665101151819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04728665101151819}
{"step": 654416, "time": 21426.129229068756, "episode/length": 640.0, "episode/score": 0.1120555777452239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1120555777452239}
{"step": 654680, "time": 21434.125935792923, "episode/length": 640.0, "episode/score": 0.06479112356890937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06479112356890937}
{"step": 655736, "time": 21467.547820091248, "episode/length": 437.0, "episode/score": 0.15037771245420117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15037771245420117}
{"step": 655792, "time": 21469.527540683746, "episode/length": 640.0, "episode/score": 0.09141616732233615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09141616732233615}
{"step": 656552, "time": 21492.900842905045, "episode/length": 640.0, "episode/score": 0.07525485155701972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07525485155701972}
{"step": 658192, "time": 21544.33113694191, "episode/length": 640.0, "episode/score": 0.14088602524503813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14088602524503813}
{"step": 658608, "time": 21557.38640999794, "episode/length": 640.0, "episode/score": 0.10471055960158537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10471055960158537}
{"step": 658800, "time": 21563.483170986176, "episode/length": 640.0, "episode/score": 0.08906135658519077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08906135658519077}
{"step": 659544, "time": 21586.643290758133, "episode/length": 640.0, "episode/score": 0.05923967958717924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05923967958717924}
{"step": 659808, "time": 21595.083689689636, "episode/length": 640.0, "episode/score": 0.08593786480996357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08593786480996357}
{"step": 660088, "time": 21615.035628795624, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.044181108475, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.05195403099, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.059403657913, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.06672692299, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.07414484024, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.081917762756, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21615.089061021805, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660864, "time": 21639.485422611237, "episode/length": 640.0, "episode/score": 0.09982200161907429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09982200161907429}
{"step": 660920, "time": 21641.050600528717, "episode/length": 640.0, "episode/score": 0.070821021781029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.070821021781029}
{"step": 661680, "time": 21664.87262558937, "episode/length": 640.0, "episode/score": 0.13703315998147048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13703315998147048}
{"step": 662808, "time": 21699.68938589096, "episode/length": 407.0, "episode/score": 0.11448980126510833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11448980126510833}
{"step": 663320, "time": 21715.657384634018, "episode/length": 640.0, "episode/score": 0.06797597879267414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06797597879267414}
{"step": 663736, "time": 21729.016209840775, "episode/length": 640.0, "episode/score": 0.06306173337077325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06306173337077325}
{"step": 663928, "time": 21734.98073410988, "episode/length": 640.0, "episode/score": 0.0812130188600122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0812130188600122}
{"step": 664936, "time": 21766.32074022293, "episode/length": 640.0, "episode/score": 0.16136606317786573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16136606317786573}
{"step": 665992, "time": 21799.00977087021, "episode/length": 640.0, "episode/score": 0.03306531071956442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03306531071956442}
{"step": 666048, "time": 21800.979995012283, "episode/length": 640.0, "episode/score": 0.07430876909097606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07430876909097606}
{"step": 666808, "time": 21824.368552446365, "episode/length": 640.0, "episode/score": 0.09811137680190996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09811137680190996}
{"step": 667936, "time": 21859.86554980278, "episode/length": 640.0, "episode/score": 0.04831027791379938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04831027791379938}
{"step": 668448, "time": 21875.681748867035, "episode/length": 640.0, "episode/score": 0.0754374692733677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0754374692733677}
{"step": 668864, "time": 21888.661273002625, "episode/length": 640.0, "episode/score": 0.02902953799309671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02902953799309671}
{"step": 669056, "time": 21894.610013484955, "episode/length": 640.0, "episode/score": 0.06378265327197141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06378265327197141}
{"step": 670064, "time": 21926.07538676262, "episode/length": 640.0, "episode/score": 0.09361409476537119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09361409476537119}
{"step": 670072, "time": 21936.64750099182, "eval_episode/length": 595.0, "eval_episode/score": 0.16328124701976776, "eval_episode/reward_rate": 0.0016778523489932886}
{"step": 670072, "time": 21937.44927597046, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21937.45821928978, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21937.466593503952, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21937.474403381348, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21937.482214927673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21937.489949703217, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21937.497659921646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 671120, "time": 21970.339878320694, "episode/length": 640.0, "episode/score": 0.11981405696809588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11981405696809588}
{"step": 671176, "time": 21971.87345957756, "episode/length": 640.0, "episode/score": 0.09912037777939986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09912037777939986}
{"step": 671936, "time": 21996.185997724533, "episode/length": 640.0, "episode/score": 0.06407547568068139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06407547568068139}
{"step": 673064, "time": 22030.942559957504, "episode/length": 640.0, "episode/score": 0.11112834674554506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11112834674554506}
{"step": 673576, "time": 22047.007598161697, "episode/length": 640.0, "episode/score": 0.09091529306670054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09091529306670054}
{"step": 673992, "time": 22059.920615673065, "episode/length": 640.0, "episode/score": 0.1531525965272067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1531525965272067}
{"step": 674184, "time": 22065.9723072052, "episode/length": 640.0, "episode/score": 0.11536478181744769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11536478181744769}
{"step": 675192, "time": 22097.456071853638, "episode/length": 640.0, "episode/score": 0.13479596268530258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13479596268530258}
{"step": 676248, "time": 22130.262332201004, "episode/length": 640.0, "episode/score": 0.15730409898787912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15730409898787912}
{"step": 676304, "time": 22132.244926691055, "episode/length": 640.0, "episode/score": 0.10005817963269692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10005817963269692}
{"step": 677064, "time": 22155.73697924614, "episode/length": 640.0, "episode/score": 0.029197681887637827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029197681887637827}
{"step": 678192, "time": 22190.950977563858, "episode/length": 640.0, "episode/score": 0.09707719890627686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09707719890627686}
{"step": 678704, "time": 22206.80105829239, "episode/length": 640.0, "episode/score": 0.15482547536117863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15482547536117863}
{"step": 679120, "time": 22219.83872294426, "episode/length": 640.0, "episode/score": 0.07700917807210317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07700917807210317}
{"step": 679312, "time": 22225.821226119995, "episode/length": 640.0, "episode/score": 0.09485592651691377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09485592651691377}
{"step": 680025, "time": 22249.303522109985, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2348465203003562, "train/action_min": 0.0, "train/action_std": 1.852502690695728, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007140984854641626, "train/actor_opt_grad_steps": 41440.0, "train/actor_opt_loss": -6.748822162709551, "train/adv_mag": 0.0664685734504245, "train/adv_max": 0.0046646166882366715, "train/adv_mean": -2.0618994568585113e-05, "train/adv_min": -0.06614467737124992, "train/adv_std": 0.0019659617218463995, "train/cont_avg": 0.9984010686528497, "train/cont_loss_mean": 0.003559804187787195, "train/cont_loss_std": 0.08955331367499031, "train/cont_neg_acc": 0.6783950637888025, "train/cont_neg_loss": 1.8574526027055802, "train/cont_pos_acc": 0.9999695877337085, "train/cont_pos_loss": 0.0004931346298746736, "train/cont_pred": 0.9984717671735299, "train/cont_rate": 0.9984010686528497, "train/dyn_loss_mean": 1.0000366355471042, "train/dyn_loss_std": 0.0002906096609396175, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.027900028876704525, "train/extr_critic_critic_opt_grad_steps": 41440.0, "train/extr_critic_critic_opt_loss": 13502.22055132772, "train/extr_critic_mag": 0.08984488403241252, "train/extr_critic_max": 0.08984488403241252, "train/extr_critic_mean": 0.08676825278472407, "train/extr_critic_min": 0.08168027190964457, "train/extr_critic_std": 0.0011533390901924878, "train/extr_return_normed_mag": 0.0652441924794968, "train/extr_return_normed_max": 0.008127386783071133, "train/extr_return_normed_mean": 0.002466573197167811, "train/extr_return_normed_min": -0.06396235487004018, "train/extr_return_normed_std": 0.0023300674215557507, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09240835847169006, "train/extr_return_raw_max": 0.09240835847169006, "train/extr_return_raw_mean": 0.08674754831611801, "train/extr_return_raw_min": 0.02031861681857875, "train/extr_return_raw_std": 0.0023300674215557507, "train/extr_reward_mag": 0.0012361373308409063, "train/extr_reward_max": 0.0012361373308409063, "train/extr_reward_mean": 0.000260829027314487, "train/extr_reward_min": 2.680047188398134e-06, "train/extr_reward_std": 0.00027227371430731443, "train/image_loss_mean": 0.11120568316217531, "train/image_loss_std": 0.12152120231655596, "train/model_loss_mean": 0.7243220231693643, "train/model_loss_std": 0.177668015110678, "train/model_opt_grad_norm": 21.446428442248408, "train/model_opt_grad_steps": 41403.0, "train/model_opt_loss": 2674.8824930932237, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3704.663212435233, "train/policy_entropy_mag": 1.9406739522756074, "train/policy_entropy_max": 1.9406739522756074, "train/policy_entropy_mean": 1.7194278116670916, "train/policy_entropy_min": 0.7614962497214579, "train/policy_entropy_std": 0.13689245391694993, "train/policy_logprob_mag": 4.188816857461485, "train/policy_logprob_max": -0.20018891936139122, "train/policy_logprob_mean": -1.7200716554809727, "train/policy_logprob_min": -4.188816857461485, "train/policy_logprob_std": 0.6684632505159922, "train/policy_randomness_mag": 0.9973091841361683, "train/policy_randomness_max": 0.9973091841361683, "train/policy_randomness_mean": 0.883611150973819, "train/policy_randomness_min": 0.39133168378642186, "train/policy_randomness_std": 0.07034880969036428, "train/post_ent_mag": 22.987477959746524, "train/post_ent_max": 22.987477959746524, "train/post_ent_mean": 20.6138904848247, "train/post_ent_min": 18.974852092525502, "train/post_ent_std": 0.7287703943993761, "train/prior_ent_mag": 23.23890319389383, "train/prior_ent_max": 23.23890319389383, "train/prior_ent_mean": 20.406173113096564, "train/prior_ent_min": 18.24657958035642, "train/prior_ent_std": 0.8004402794677359, "train/rep_loss_mean": 1.0000366355471042, "train/rep_loss_std": 0.0002906096609396175, "train/reward_avg": 0.00021905720537320899, "train/reward_loss_mean": 0.009534533818401976, "train/reward_loss_std": 0.014008764833829564, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012018032024561432, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009534533837703998, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022103689512035235, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7271160276568667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.027024798095226288, "report/cont_loss_std": 0.4909852147102356, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 9.075645446777344, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00043727265438064933, "report/cont_pred": 0.9995656609535217, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1037774309515953, "report/image_loss_std": 0.12616609036922455, "report/model_loss_mean": 0.7408270835876465, "report/model_loss_std": 0.5117405652999878, "report/post_ent_mag": 21.96194839477539, "report/post_ent_max": 21.96194839477539, "report/post_ent_mean": 20.49086570739746, "report/post_ent_min": 19.390953063964844, "report/post_ent_std": 0.4958130717277527, "report/prior_ent_mag": 23.002710342407227, "report/prior_ent_max": 23.002710342407227, "report/prior_ent_mean": 20.764305114746094, "report/prior_ent_min": 18.8764591217041, "report/prior_ent_std": 0.6551686525344849, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002296150487381965, "report/reward_loss_mean": 0.010024821385741234, "report/reward_loss_std": 0.013600779697299004, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012412071228027344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010024821385741234, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00024454796221107244, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.027115413919091225, "eval/cont_loss_std": 0.4512096345424652, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.23991584777832, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0029837770853191614, "eval/cont_pred": 0.9982068538665771, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3255698084831238, "eval/image_loss_std": 0.14438922703266144, "eval/model_loss_mean": 0.9542698860168457, "eval/model_loss_std": 0.4738449156284332, "eval/post_ent_mag": 21.842464447021484, "eval/post_ent_max": 21.842464447021484, "eval/post_ent_mean": 20.399169921875, "eval/post_ent_min": 19.400218963623047, "eval/post_ent_std": 0.47063353657722473, "eval/prior_ent_mag": 22.791301727294922, "eval/prior_ent_max": 22.791301727294922, "eval/prior_ent_mean": 20.733869552612305, "eval/prior_ent_min": 19.113752365112305, "eval/prior_ent_std": 0.6569579839706421, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001584645826369524, "eval/reward_loss_std": 0.0016319620190188289, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011441707611083984, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001584645826369524, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002492117928341031, "eval/reward_rate": 0.0, "replay/size": 679521.0, "replay/inserts": 30896.0, "replay/samples": 30896.0, "replay/insert_wait_avg": 1.3015790037513704e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.438199493194849e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0659095835574146e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0476706027985, "timer/env.step_count": 3862.0, "timer/env.step_total": 33.365681886672974, "timer/env.step_frac": 0.0333640914003241, "timer/env.step_avg": 0.008639482622131791, "timer/env.step_min": 0.0072479248046875, "timer/env.step_max": 0.033349037170410156, "timer/replay._sample_count": 30896.0, "timer/replay._sample_total": 15.36708116531372, "timer/replay._sample_frac": 0.015366348642211135, "timer/replay._sample_avg": 0.0004973809284474922, "timer/replay._sample_min": 0.0003712177276611328, "timer/replay._sample_max": 0.01057124137878418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5785.0, "timer/agent.policy_total": 57.800373554229736, "timer/agent.policy_frac": 0.05779761830692473, "timer/agent.policy_avg": 0.009991421530549651, "timer/agent.policy_min": 0.008427858352661133, "timer/agent.policy_max": 0.09925270080566406, "timer/dataset_train_count": 1931.0, "timer/dataset_train_total": 0.2074141502380371, "timer/dataset_train_frac": 0.0002074042631517897, "timer/dataset_train_avg": 0.00010741281731643558, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0002491474151611328, "timer/agent.train_count": 1931.0, "timer/agent.train_total": 854.2736384868622, "timer/agent.train_frac": 0.8542329166887933, "timer/agent.train_avg": 0.44239960563794, "timer/agent.train_min": 0.433194637298584, "timer/agent.train_max": 0.5770540237426758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745159149169922, "timer/agent.report_frac": 0.0004744932955355702, "timer/agent.report_avg": 0.2372579574584961, "timer/agent.report_min": 0.23054027557373047, "timer/agent.report_max": 0.24397563934326172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 3.886037589601075e-08, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05, "fps": 30.893960623419854}
{"step": 680056, "time": 22261.565495967865, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.57397198677, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.581585645676, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.58896589279, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.596287727356, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.60455751419, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.61177110672, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22261.619009017944, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680320, "time": 22270.031759738922, "episode/length": 640.0, "episode/score": 0.036153269721694414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036153269721694414}
{"step": 681376, "time": 22303.045012950897, "episode/length": 640.0, "episode/score": 0.08420332967185118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08420332967185118}
{"step": 681432, "time": 22304.593275547028, "episode/length": 640.0, "episode/score": 0.03376241346586539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03376241346586539}
{"step": 682192, "time": 22328.588136434555, "episode/length": 640.0, "episode/score": 0.0317971477692538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0317971477692538}
{"step": 682896, "time": 22350.61759376526, "episode/length": 182.0, "episode/score": 0.028166466634871767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028166466634871767}
{"step": 683320, "time": 22363.587836027145, "episode/length": 640.0, "episode/score": 0.05988785964288468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05988785964288468}
{"step": 683832, "time": 22379.747933864594, "episode/length": 640.0, "episode/score": 0.13239076038533426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13239076038533426}
{"step": 684248, "time": 22392.62770152092, "episode/length": 640.0, "episode/score": 0.08839785366063779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08839785366063779}
{"step": 684440, "time": 22398.735778570175, "episode/length": 640.0, "episode/score": 0.05900961612795186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05900961612795186}
{"step": 685448, "time": 22430.28695487976, "episode/length": 640.0, "episode/score": 0.08698607635705002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08698607635705002}
{"step": 686504, "time": 22463.188580036163, "episode/length": 640.0, "episode/score": 0.1274889894541218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1274889894541218}
{"step": 687320, "time": 22488.740836381912, "episode/length": 640.0, "episode/score": 0.09064573113801089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09064573113801089}
{"step": 688024, "time": 22510.675441026688, "episode/length": 640.0, "episode/score": 0.12168695367887494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12168695367887494}
{"step": 688448, "time": 22524.68606042862, "episode/length": 640.0, "episode/score": 0.12163919015696933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12163919015696933}
{"step": 688960, "time": 22540.619259119034, "episode/length": 640.0, "episode/score": 0.13141778557903194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13141778557903194}
{"step": 689376, "time": 22553.73360323906, "episode/length": 640.0, "episode/score": 0.15756359674725218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15756359674725218}
{"step": 689568, "time": 22559.71933555603, "episode/length": 640.0, "episode/score": 0.09084641387531178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09084641387531178}
{"step": 690040, "time": 22585.901755809784, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.91032266617, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.917939662933, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.925525188446, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.93305206299, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.940407037735, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.947896003723, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22585.955395698547, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690576, "time": 22602.738849401474, "episode/length": 640.0, "episode/score": 0.16710498236457738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16710498236457738}
{"step": 691632, "time": 22635.442451953888, "episode/length": 640.0, "episode/score": 0.1813569874740324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1813569874740324}
{"step": 692448, "time": 22660.756124973297, "episode/length": 640.0, "episode/score": 0.12905092211192937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12905092211192937}
{"step": 693152, "time": 22682.61527609825, "episode/length": 640.0, "episode/score": 0.14194151483818018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14194151483818018}
{"step": 693576, "time": 22695.605740070343, "episode/length": 640.0, "episode/score": 0.19397518804350966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19397518804350966}
{"step": 694088, "time": 22711.423624515533, "episode/length": 640.0, "episode/score": 0.19056164841626355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19056164841626355}
{"step": 694504, "time": 22724.33847975731, "episode/length": 640.0, "episode/score": 0.12887556983059767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12887556983059767}
{"step": 694696, "time": 22730.415692090988, "episode/length": 640.0, "episode/score": 0.1359334542275974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1359334542275974}
{"step": 695704, "time": 22761.767281532288, "episode/length": 640.0, "episode/score": 0.16753894400756053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16753894400756053}
{"step": 696760, "time": 22795.08624601364, "episode/length": 640.0, "episode/score": 0.15828099861840883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15828099861840883}
{"step": 697576, "time": 22820.60065317154, "episode/length": 640.0, "episode/score": 0.05358113185371849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05358113185371849}
{"step": 698280, "time": 22842.47951245308, "episode/length": 640.0, "episode/score": 0.18000158719644332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18000158719644332}
{"step": 698704, "time": 22856.142875432968, "episode/length": 640.0, "episode/score": 0.14142822654031306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14142822654031306}
{"step": 699216, "time": 22872.09919643402, "episode/length": 640.0, "episode/score": 0.08284391273258507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08284391273258507}
{"step": 699632, "time": 22885.16113638878, "episode/length": 640.0, "episode/score": 0.13433401688109825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13433401688109825}
{"step": 699824, "time": 22891.15148115158, "episode/length": 640.0, "episode/score": 0.10200523591032606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10200523591032606}
{"step": 700024, "time": 22902.3741440773, "eval_episode/length": 300.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.0033222591362126247}
{"step": 700024, "time": 22908.52447128296, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22908.533394813538, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22908.541271686554, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22908.549908399582, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22908.55797767639, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22908.566009283066, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22908.573734998703, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700832, "time": 22933.96146297455, "episode/length": 640.0, "episode/score": 0.15783658815848867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15783658815848867}
{"step": 701888, "time": 22966.936673402786, "episode/length": 640.0, "episode/score": 0.2113833615684939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2113833615684939}
{"step": 702704, "time": 22992.27907848358, "episode/length": 640.0, "episode/score": 0.1419730709662872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1419730709662872}
{"step": 703408, "time": 23014.2248878479, "episode/length": 640.0, "episode/score": 0.2431070726300959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2431070726300959}
{"step": 703832, "time": 23027.29316997528, "episode/length": 640.0, "episode/score": 0.1948642714959874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1948642714959874}
{"step": 704344, "time": 23043.278270483017, "episode/length": 640.0, "episode/score": 0.23830982097268816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23830982097268816}
{"step": 704760, "time": 23056.929344654083, "episode/length": 640.0, "episode/score": 0.16912828952274594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16912828952274594}
{"step": 704952, "time": 23062.88540315628, "episode/length": 640.0, "episode/score": 0.23475315908325456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23475315908325456}
{"step": 705960, "time": 23094.221336364746, "episode/length": 640.0, "episode/score": 0.3230498668510222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3230498668510222}
{"step": 707016, "time": 23127.069908618927, "episode/length": 640.0, "episode/score": 0.24397043133831176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24397043133831176}
{"step": 707832, "time": 23152.43416595459, "episode/length": 640.0, "episode/score": 0.2057063637396368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2057063637396368}
{"step": 708536, "time": 23174.228050231934, "episode/length": 640.0, "episode/score": 0.2580255689324531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2580255689324531}
{"step": 708960, "time": 23189.539400815964, "episode/length": 640.0, "episode/score": 0.1623301130591699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1623301130591699}
{"step": 709472, "time": 23205.43731355667, "episode/length": 640.0, "episode/score": 0.21870014475030075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21870014475030075}
{"step": 709888, "time": 23218.3713927269, "episode/length": 640.0, "episode/score": 0.19408262573904267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19408262573904267}
{"step": 710008, "time": 23230.69256424904, "eval_episode/length": 483.0, "eval_episode/score": 0.32078126072883606, "eval_episode/reward_rate": 0.002066115702479339}
{"step": 710008, "time": 23233.48194551468, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23233.490557193756, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23233.498865365982, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23233.50692176819, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23233.514911413193, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23233.52260041237, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23233.530037403107, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710080, "time": 23236.111718416214, "episode/length": 640.0, "episode/score": 0.18438269550085806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18438269550085806}
{"step": 710489, "time": 23249.546936750412, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2410092002467104, "train/action_min": 0.0, "train/action_std": 1.8504859315721611, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000704399098666679, "train/actor_opt_grad_steps": 43355.0, "train/actor_opt_loss": -7.578199240643727, "train/adv_mag": 0.06760354842010298, "train/adv_max": 0.004665219940637288, "train/adv_mean": -7.02107922973626e-05, "train/adv_min": -0.06735836000818955, "train/adv_std": 0.0019427587223043174, "train/cont_avg": 0.9984375, "train/cont_loss_mean": 0.0028321595296514905, "train/cont_loss_std": 0.0702378849315114, "train/cont_neg_acc": 0.7139433569767896, "train/cont_neg_loss": 1.5678442322532646, "train/cont_pos_acc": 0.9999536438992149, "train/cont_pos_loss": 0.0005024443315433976, "train/cont_pred": 0.9984321857753553, "train/cont_rate": 0.9984375, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02922494253955512, "train/extr_critic_critic_opt_grad_steps": 43355.0, "train/extr_critic_critic_opt_loss": 13525.008645148026, "train/extr_critic_mag": 0.08762854149467067, "train/extr_critic_max": 0.08762854149467067, "train/extr_critic_mean": 0.0843544241237013, "train/extr_critic_min": 0.0791827214391608, "train/extr_critic_std": 0.0011949495623795022, "train/extr_return_normed_mag": 0.06632617253221963, "train/extr_return_normed_max": 0.008294217994338588, "train/extr_return_normed_mean": 0.0024146064956623472, "train/extr_return_normed_min": -0.0651948317493263, "train/extr_return_normed_std": 0.002321225132082442, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09016378098412564, "train/extr_return_raw_max": 0.09016378098412564, "train/extr_return_raw_mean": 0.08428417330509738, "train/extr_return_raw_min": 0.016674731240460747, "train/extr_return_raw_std": 0.002321225118602773, "train/extr_reward_mag": 0.0012505531311035156, "train/extr_reward_max": 0.0012505531311035156, "train/extr_reward_mean": 0.0002500292613771499, "train/extr_reward_min": 2.6495833145944696e-06, "train/extr_reward_std": 0.000267295717984732, "train/image_loss_mean": 0.11058953663236216, "train/image_loss_std": 0.12190777682944348, "train/model_loss_mean": 0.7230230180840743, "train/model_loss_std": 0.16414388571130603, "train/model_opt_grad_norm": 20.781826245157344, "train/model_opt_grad_steps": 43316.426315789475, "train/model_opt_loss": 2797.6122102436266, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3868.4210526315787, "train/policy_entropy_mag": 1.9410213727700083, "train/policy_entropy_max": 1.9410213727700083, "train/policy_entropy_mean": 1.7290969246312191, "train/policy_entropy_min": 0.7458243906497956, "train/policy_entropy_std": 0.13364357520875178, "train/policy_logprob_mag": 4.1374916377820465, "train/policy_logprob_max": -0.19329956793471387, "train/policy_logprob_mean": -1.7288487886127673, "train/policy_logprob_min": -4.1374916377820465, "train/policy_logprob_std": 0.656026628142909, "train/policy_randomness_mag": 0.9974877235136534, "train/policy_randomness_max": 0.9974877235136534, "train/policy_randomness_mean": 0.8885800948268489, "train/policy_randomness_min": 0.38327794075012206, "train/policy_randomness_std": 0.0686792158178593, "train/post_ent_mag": 23.13799003801848, "train/post_ent_max": 23.13799003801848, "train/post_ent_mean": 21.046436400162545, "train/post_ent_min": 19.476933439154372, "train/post_ent_std": 0.6691133290529251, "train/prior_ent_mag": 22.22771698801141, "train/prior_ent_max": 22.22771698801141, "train/prior_ent_mean": 20.202648192957827, "train/prior_ent_min": 18.513042269254985, "train/prior_ent_std": 0.5994963915724504, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00022067671035122324, "train/reward_loss_mean": 0.009601298891203968, "train/reward_loss_std": 0.014096750608204226, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012147282299242522, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009601298839736141, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002194517022488933, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7347610726648448, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0004679372359532863, "report/cont_loss_std": 0.0017975261434912682, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004679372359532863, "report/cont_pred": 0.9995337128639221, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0906314104795456, "report/image_loss_std": 0.10545222461223602, "report/model_loss_mean": 0.7012595534324646, "report/model_loss_std": 0.10877007991075516, "report/post_ent_mag": 23.045997619628906, "report/post_ent_max": 23.045997619628906, "report/post_ent_mean": 21.3362979888916, "report/post_ent_min": 19.93022346496582, "report/post_ent_std": 0.6066444516181946, "report/prior_ent_mag": 21.403898239135742, "report/prior_ent_max": 21.403898239135742, "report/prior_ent_mean": 19.367149353027344, "report/prior_ent_min": 17.78240966796875, "report/prior_ent_std": 0.6332672834396362, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023700518067926168, "report/reward_loss_mean": 0.010160213336348534, "report/reward_loss_std": 0.014532750472426414, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001253366470336914, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010160213336348534, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002574286190792918, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.054727643728256226, "eval/cont_loss_std": 0.6918514966964722, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.053516387939453, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016895948210731149, "eval/cont_pred": 0.9983595609664917, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3093322813510895, "eval/image_loss_std": 0.14291392266750336, "eval/model_loss_mean": 0.9655564427375793, "eval/model_loss_std": 0.705398440361023, "eval/post_ent_mag": 23.20258903503418, "eval/post_ent_max": 23.20258903503418, "eval/post_ent_mean": 21.216278076171875, "eval/post_ent_min": 19.78076934814453, "eval/post_ent_std": 0.6365301012992859, "eval/prior_ent_mag": 21.070392608642578, "eval/prior_ent_max": 21.070392608642578, "eval/prior_ent_mean": 19.3931941986084, "eval/prior_ent_min": 17.83346176147461, "eval/prior_ent_std": 0.6077414155006409, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014965636655688286, "eval/reward_loss_std": 0.0014974235091358423, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011309385299682617, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014965636655688286, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023539166431874037, "eval/reward_rate": 0.0, "replay/size": 709985.0, "replay/inserts": 30464.0, "replay/samples": 30464.0, "replay/insert_wait_avg": 1.315528354724916e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0561276258540755e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 20512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.028424213159475e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2277126312256, "timer/env.step_count": 3808.0, "timer/env.step_total": 33.192267179489136, "timer/env.step_frac": 0.03318471060172156, "timer/env.step_avg": 0.008716456717302819, "timer/env.step_min": 0.007317781448364258, "timer/env.step_max": 0.03482699394226074, "timer/replay._sample_count": 30464.0, "timer/replay._sample_total": 15.306426048278809, "timer/replay._sample_frac": 0.015302941375232764, "timer/replay._sample_avg": 0.0005024430819419251, "timer/replay._sample_min": 0.0004131793975830078, "timer/replay._sample_max": 0.030608415603637695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 6372.0, "timer/agent.policy_total": 63.66898465156555, "timer/agent.policy_frac": 0.06365448972022204, "timer/agent.policy_avg": 0.009991993824790575, "timer/agent.policy_min": 0.008579254150390625, "timer/agent.policy_max": 0.08589053153991699, "timer/dataset_train_count": 1904.0, "timer/dataset_train_total": 0.208021879196167, "timer/dataset_train_frac": 0.0002079745207708144, "timer/dataset_train_avg": 0.00010925518865344905, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0006356239318847656, "timer/agent.train_count": 1904.0, "timer/agent.train_total": 844.429529428482, "timer/agent.train_frac": 0.8442372859347231, "timer/agent.train_avg": 0.4435029041115977, "timer/agent.train_min": 0.4333076477050781, "timer/agent.train_max": 2.2332427501678467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783158302307129, "timer/agent.report_frac": 0.0004782069364709388, "timer/agent.report_avg": 0.23915791511535645, "timer/agent.report_min": 0.23201298713684082, "timer/agent.report_max": 0.24630284309387207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027226616851604e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 30.456500249178443}
{"step": 711088, "time": 23268.204349040985, "episode/length": 640.0, "episode/score": 0.17999614823463617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17999614823463617}
{"step": 712144, "time": 23300.949907064438, "episode/length": 640.0, "episode/score": 0.15028642212769228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15028642212769228}
{"step": 712960, "time": 23326.80542898178, "episode/length": 640.0, "episode/score": 0.21464408805474022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21464408805474022}
{"step": 713664, "time": 23348.67536997795, "episode/length": 640.0, "episode/score": 0.09644854767367406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09644854767367406}
{"step": 714088, "time": 23361.69078040123, "episode/length": 640.0, "episode/score": 0.11751655293096519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11751655293096519}
{"step": 714600, "time": 23377.633599996567, "episode/length": 640.0, "episode/score": 0.14216839663879455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14216839663879455}
{"step": 715016, "time": 23390.801894426346, "episode/length": 640.0, "episode/score": 0.1331531047131307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1331531047131307}
{"step": 715208, "time": 23396.852075576782, "episode/length": 640.0, "episode/score": 0.16324449275168718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16324449275168718}
{"step": 716216, "time": 23428.16472196579, "episode/length": 640.0, "episode/score": 0.2402057418679533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2402057418679533}
{"step": 717272, "time": 23460.902163267136, "episode/length": 640.0, "episode/score": 0.1315422370574879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1315422370574879}
{"step": 718088, "time": 23486.20062303543, "episode/length": 640.0, "episode/score": 0.12768732354726353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12768732354726353}
{"step": 718792, "time": 23508.063759326935, "episode/length": 640.0, "episode/score": 0.1819895016912767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1819895016912767}
{"step": 719216, "time": 23521.457406282425, "episode/length": 640.0, "episode/score": 0.18014311956258666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18014311956258666}
{"step": 719728, "time": 23537.662584781647, "episode/length": 640.0, "episode/score": 0.2343094147603324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2343094147603324}
{"step": 720096, "time": 23551.7754175663, "eval_episode/length": 160.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 720096, "time": 23559.94802093506, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23559.957939863205, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23559.96575808525, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23559.973571538925, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23559.980945825577, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23559.988234758377, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23559.995195627213, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720144, "time": 23561.503854751587, "episode/length": 640.0, "episode/score": 0.13158004213534014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13158004213534014}
{"step": 720336, "time": 23567.509759426117, "episode/length": 640.0, "episode/score": 0.05919720927639105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05919720927639105}
{"step": 721344, "time": 23599.496351242065, "episode/length": 640.0, "episode/score": 0.1697968418159519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1697968418159519}
{"step": 722400, "time": 23632.359140396118, "episode/length": 640.0, "episode/score": 0.09442101376293977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09442101376293977}
{"step": 723216, "time": 23657.94168162346, "episode/length": 640.0, "episode/score": 0.1675215098755416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1675215098755416}
{"step": 723920, "time": 23679.674946308136, "episode/length": 640.0, "episode/score": 0.147294246495278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.147294246495278}
{"step": 724344, "time": 23692.669281244278, "episode/length": 640.0, "episode/score": 0.11306275549790712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11306275549790712}
{"step": 724856, "time": 23708.50469136238, "episode/length": 640.0, "episode/score": 0.20423529476875046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20423529476875046}
{"step": 725272, "time": 23721.654536008835, "episode/length": 640.0, "episode/score": 0.13324508337160523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13324508337160523}
{"step": 725464, "time": 23727.622695684433, "episode/length": 640.0, "episode/score": 0.19920836664266517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19920836664266517}
{"step": 726472, "time": 23759.00158715248, "episode/length": 640.0, "episode/score": 0.1271213078726987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1271213078726987}
{"step": 727528, "time": 23791.85529732704, "episode/length": 640.0, "episode/score": 0.04143807982498515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04143807982498515}
{"step": 728344, "time": 23817.233721733093, "episode/length": 640.0, "episode/score": 0.12645766197363173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12645766197363173}
{"step": 729048, "time": 23839.1165702343, "episode/length": 640.0, "episode/score": 0.10167060039248099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10167060039248099}
{"step": 729472, "time": 23852.99166059494, "episode/length": 640.0, "episode/score": 0.14470580347202144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14470580347202144}
{"step": 729984, "time": 23868.929781913757, "episode/length": 640.0, "episode/score": 0.15721718569571408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15721718569571408}
{"step": 730080, "time": 23883.676575899124, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.686504125595, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.694905281067, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.703056812286, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.710682868958, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.718419075012, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.726052999496, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 23883.733681440353, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730400, "time": 23893.646947145462, "episode/length": 640.0, "episode/score": 0.1349830063879267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1349830063879267}
{"step": 730592, "time": 23899.680681467056, "episode/length": 640.0, "episode/score": 0.12274802353505265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12274802353505265}
{"step": 731328, "time": 23922.42940044403, "episode/length": 231.0, "episode/score": 0.07956899116408067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07956899116408067}
{"step": 731600, "time": 23930.898198127747, "episode/length": 640.0, "episode/score": 0.17452201338443274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17452201338443274}
{"step": 732656, "time": 23963.6416079998, "episode/length": 640.0, "episode/score": 0.09831103671191954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09831103671191954}
{"step": 733472, "time": 23988.942556858063, "episode/length": 640.0, "episode/score": 0.12008210829549171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12008210829549171}
{"step": 734176, "time": 24010.767740249634, "episode/length": 640.0, "episode/score": 0.16127534273822164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16127534273822164}
{"step": 735112, "time": 24039.619078159332, "episode/length": 640.0, "episode/score": 0.16186069532129466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16186069532129466}
{"step": 735528, "time": 24052.68726825714, "episode/length": 640.0, "episode/score": 0.13591141334067913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13591141334067913}
{"step": 735720, "time": 24058.646961450577, "episode/length": 640.0, "episode/score": 0.07998821789682609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07998821789682609}
{"step": 736456, "time": 24081.724680900574, "episode/length": 640.0, "episode/score": 0.13996426480386503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13996426480386503}
{"step": 736728, "time": 24090.13854598999, "episode/length": 640.0, "episode/score": 0.10343274124606694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10343274124606694}
{"step": 737784, "time": 24123.40539598465, "episode/length": 640.0, "episode/score": 0.11598410236629775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11598410236629775}
{"step": 738600, "time": 24148.83833169937, "episode/length": 640.0, "episode/score": 0.16497418089331006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16497418089331006}
{"step": 739304, "time": 24170.70617222786, "episode/length": 640.0, "episode/score": 0.09198680773938861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09198680773938861}
{"step": 740064, "time": 24203.063801527023, "eval_episode/length": 493.0, "eval_episode/score": 0.30671873688697815, "eval_episode/reward_rate": 0.0020242914979757085}
{"step": 740064, "time": 24206.152856111526, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24206.16149163246, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24206.16964817047, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24206.177592754364, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24206.185480594635, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24206.19325852394, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24206.20114326477, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740240, "time": 24211.645067691803, "episode/length": 640.0, "episode/score": 0.08719830819585184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08719830819585184}
{"step": 740656, "time": 24224.527322530746, "episode/length": 640.0, "episode/score": 0.12656175999563857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12656175999563857}
{"step": 740848, "time": 24230.57563519478, "episode/length": 640.0, "episode/score": 0.0916706474893374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0916706474893374}
{"step": 741449, "time": 24249.940175771713, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.210670077923647, "train/action_min": 0.0, "train/action_std": 1.8520898499439673, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007422491450513204, "train/actor_opt_grad_steps": 45275.0, "train/actor_opt_loss": -6.954749953193763, "train/adv_mag": 0.07045654057688319, "train/adv_max": 0.004964682744028642, "train/adv_mean": -3.118886272237507e-05, "train/adv_min": -0.07020631970204029, "train/adv_std": 0.002111411934296034, "train/cont_avg": 0.9983539384664949, "train/cont_loss_mean": 0.002712858961514058, "train/cont_loss_std": 0.06670762573941323, "train/cont_neg_acc": 0.7602083355188369, "train/cont_neg_loss": 1.339785173752898, "train/cont_pos_acc": 0.9999596350586292, "train/cont_pos_loss": 0.0005345952892273943, "train/cont_pred": 0.9982921849821031, "train/cont_rate": 0.9983539384664949, "train/dyn_loss_mean": 1.000005133987702, "train/dyn_loss_std": 0.0001414290634728008, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.030024140799590916, "train/extr_critic_critic_opt_grad_steps": 45275.0, "train/extr_critic_critic_opt_loss": 13526.808810204575, "train/extr_critic_mag": 0.0867297741555676, "train/extr_critic_max": 0.0867297741555676, "train/extr_critic_mean": 0.08323024340050737, "train/extr_critic_min": 0.0780257883760118, "train/extr_critic_std": 0.0012698792165370908, "train/extr_return_normed_mag": 0.0685777718719748, "train/extr_return_normed_max": 0.008792382386541859, "train/extr_return_normed_mean": 0.0026604762833719094, "train/extr_return_normed_min": -0.06763679718541116, "train/extr_return_normed_std": 0.0025049900970921, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08933094170751031, "train/extr_return_raw_max": 0.08933094170751031, "train/extr_return_raw_mean": 0.08319903975448657, "train/extr_return_raw_min": 0.012901762135557293, "train/extr_return_raw_std": 0.0025049900970921, "train/extr_reward_mag": 0.0012369659758105721, "train/extr_reward_max": 0.0012369659758105721, "train/extr_reward_mean": 0.00025558588095009327, "train/extr_reward_min": 2.6336650258487032e-06, "train/extr_reward_std": 0.0002676417816942798, "train/image_loss_mean": 0.1083936204308087, "train/image_loss_std": 0.12121972975503538, "train/model_loss_mean": 0.7206023842403569, "train/model_loss_std": 0.16132230008232226, "train/model_opt_grad_norm": 19.44318940959026, "train/model_opt_grad_steps": 45234.89175257732, "train/model_opt_loss": 2702.2116869110423, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3775.773195876289, "train/policy_entropy_mag": 1.94105026894009, "train/policy_entropy_max": 1.94105026894009, "train/policy_entropy_mean": 1.7122342807730448, "train/policy_entropy_min": 0.7018670813017285, "train/policy_entropy_std": 0.14326654589667762, "train/policy_logprob_mag": 4.19701883350451, "train/policy_logprob_max": -0.17644371103841006, "train/policy_logprob_mean": -1.7114391941385172, "train/policy_logprob_min": -4.19701883350451, "train/policy_logprob_std": 0.679646692017919, "train/policy_randomness_mag": 0.9975025727576816, "train/policy_randomness_max": 0.9975025727576816, "train/policy_randomness_mean": 0.8799144158658293, "train/policy_randomness_min": 0.3606883516323935, "train/policy_randomness_std": 0.07362444456858733, "train/post_ent_mag": 24.75441098950573, "train/post_ent_max": 24.75441098950573, "train/post_ent_mean": 21.68079770471632, "train/post_ent_min": 19.34955064046014, "train/post_ent_std": 0.9831480841661236, "train/prior_ent_mag": 23.971440669187565, "train/prior_ent_max": 23.971440669187565, "train/prior_ent_mean": 21.154252878169423, "train/prior_ent_min": 18.98435108932023, "train/prior_ent_std": 0.7824180527138955, "train/rep_loss_mean": 1.000005133987702, "train/rep_loss_std": 0.0001414290634728008, "train/reward_avg": 0.00021808906363805794, "train/reward_loss_mean": 0.009492804841186428, "train/reward_loss_std": 0.013990521334956601, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012064139867566295, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009492804872390535, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021865710342475742, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.720108690361182, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.00023812093422748148, "report/cont_loss_std": 0.0008769728592596948, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003898864146322012, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002309570409124717, "report/cont_pred": 0.9978243112564087, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09840697795152664, "report/image_loss_std": 0.11197313666343689, "report/model_loss_mean": 0.709155797958374, "report/model_loss_std": 0.11519799381494522, "report/post_ent_mag": 26.474609375, "report/post_ent_max": 26.474609375, "report/post_ent_mean": 22.47565460205078, "report/post_ent_min": 19.104366302490234, "report/post_ent_std": 1.4149179458618164, "report/prior_ent_mag": 25.060211181640625, "report/prior_ent_max": 25.060211181640625, "report/prior_ent_mean": 21.490352630615234, "report/prior_ent_min": 18.934642791748047, "report/prior_ent_std": 1.0220218896865845, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000245365547016263, "report/reward_loss_mean": 0.010510720312595367, "report/reward_loss_std": 0.014730707742273808, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013180971145629883, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010510720312595367, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002692275447770953, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.026927858591079712, "eval/cont_loss_std": 0.4875490963459015, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.015752792358398, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005160340806469321, "eval/cont_pred": 0.9995003938674927, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.30019694566726685, "eval/image_loss_std": 0.1303427815437317, "eval/model_loss_mean": 0.94884192943573, "eval/model_loss_std": 1.0079673528671265, "eval/post_ent_mag": 27.391183853149414, "eval/post_ent_max": 27.391183853149414, "eval/post_ent_mean": 22.212005615234375, "eval/post_ent_min": 18.810558319091797, "eval/post_ent_std": 1.4236918687820435, "eval/prior_ent_mag": 25.116413116455078, "eval/prior_ent_max": 25.116413116455078, "eval/prior_ent_mean": 21.438838958740234, "eval/prior_ent_min": 18.80729866027832, "eval/prior_ent_std": 1.114498257637024, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006112671107985079, "eval/reward_loss_mean": 0.021717127412557602, "eval/reward_loss_std": 0.6369877457618713, "eval/reward_max_data": 0.6259375214576721, "eval/reward_max_pred": 0.0012388229370117188, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018015970708802342, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.395299911499023, "eval/reward_pred": 0.00028376257978379726, "eval/reward_rate": 0.0009765625, "replay/size": 740945.0, "replay/inserts": 30960.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.2982800333382855e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.515719820362653e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.027227005980874e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3740928173065, "timer/env.step_count": 3870.0, "timer/env.step_total": 33.50641179084778, "timer/env.step_frac": 0.033493881970179024, "timer/env.step_avg": 0.008657987542854724, "timer/env.step_min": 0.007248401641845703, "timer/env.step_max": 0.03383636474609375, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.369923114776611, "timer/replay._sample_frac": 0.015364175487083057, "timer/replay._sample_avg": 0.0004964445450509242, "timer/replay._sample_min": 0.0003857612609863281, "timer/replay._sample_max": 0.03176617622375488, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5793.0, "timer/agent.policy_total": 57.598464012145996, "timer/agent.policy_frac": 0.05757692489809902, "timer/agent.policy_avg": 0.009942769551552908, "timer/agent.policy_min": 0.008627891540527344, "timer/agent.policy_max": 0.08722615242004395, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.2075190544128418, "timer/dataset_train_frac": 0.00020744145205561616, "timer/dataset_train_avg": 0.00010724498936064176, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0002560615539550781, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 855.3113861083984, "timer/agent.train_frac": 0.8549915399144586, "timer/agent.train_avg": 0.442021388169715, "timer/agent.train_min": 0.4318578243255615, "timer/agent.train_max": 0.5803163051605225, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778401851654053, "timer/agent.report_frac": 0.0004776614954308607, "timer/agent.report_avg": 0.23892009258270264, "timer/agent.report_min": 0.23304152488708496, "timer/agent.report_max": 0.2447986602783203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.3604448470517946e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 30.947879500299663}
{"step": 741584, "time": 24254.16484594345, "episode/length": 640.0, "episode/score": 0.14917119421970426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14917119421970426}
{"step": 741856, "time": 24262.686373233795, "episode/length": 640.0, "episode/score": 0.10947200252627454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10947200252627454}
{"step": 742912, "time": 24295.55566716194, "episode/length": 640.0, "episode/score": 0.16798243448664607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16798243448664607}
{"step": 743728, "time": 24320.96622276306, "episode/length": 640.0, "episode/score": 0.17021690865603034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17021690865603034}
{"step": 744432, "time": 24342.889577150345, "episode/length": 640.0, "episode/score": 0.04938882322683469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04938882322683469}
{"step": 744608, "time": 24348.425862312317, "episode/length": 469.0, "episode/score": 0.20875686523768877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20875686523768877}
{"step": 745368, "time": 24371.85563993454, "episode/length": 640.0, "episode/score": 0.20312741323184014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20312741323184014}
{"step": 745784, "time": 24385.36591720581, "episode/length": 640.0, "episode/score": 0.15187787377900008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15187787377900008}
{"step": 746712, "time": 24414.274495601654, "episode/length": 640.0, "episode/score": 0.16572093216664996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16572093216664996}
{"step": 746984, "time": 24422.711936473846, "episode/length": 640.0, "episode/score": 0.21886553914208662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21886553914208662}
{"step": 748040, "time": 24455.888213157654, "episode/length": 640.0, "episode/score": 0.16729103527120515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16729103527120515}
{"step": 748856, "time": 24481.287209033966, "episode/length": 640.0, "episode/score": 0.1971222572010447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1971222572010447}
{"step": 749560, "time": 24503.193499326706, "episode/length": 640.0, "episode/score": 0.06477949165650898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06477949165650898}
{"step": 749736, "time": 24508.614067316055, "episode/length": 640.0, "episode/score": 0.1435981380307112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1435981380307112}
{"step": 750048, "time": 24529.721126317978, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.730675935745, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.738796949387, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.746559619904, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.754186868668, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.762674093246, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.770367383957, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24529.778267145157, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750496, "time": 24543.68999147415, "episode/length": 640.0, "episode/score": 0.0811292044290326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0811292044290326}
{"step": 750912, "time": 24556.70373725891, "episode/length": 640.0, "episode/score": 0.13563125599551995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13563125599551995}
{"step": 751112, "time": 24562.65776348114, "episode/length": 515.0, "episode/score": 0.13317910981612613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13317910981612613}
{"step": 751840, "time": 24585.72491168976, "episode/length": 640.0, "episode/score": 0.13774322486057144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13774322486057144}
{"step": 753168, "time": 24626.942175388336, "episode/length": 640.0, "episode/score": 0.16964023770680114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16964023770680114}
{"step": 753984, "time": 24652.75203371048, "episode/length": 640.0, "episode/score": 0.20941472151002927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20941472151002927}
{"step": 754688, "time": 24674.444947242737, "episode/length": 640.0, "episode/score": 0.09796567757479124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09796567757479124}
{"step": 754864, "time": 24679.958600759506, "episode/length": 640.0, "episode/score": 0.18989902788570134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18989902788570134}
{"step": 755624, "time": 24703.22456383705, "episode/length": 640.0, "episode/score": 0.1321618373815454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1321618373815454}
{"step": 756040, "time": 24716.185784578323, "episode/length": 640.0, "episode/score": 0.07849554246570278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07849554246570278}
{"step": 756240, "time": 24722.641766548157, "episode/length": 640.0, "episode/score": 0.1853499091272397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1853499091272397}
{"step": 756968, "time": 24745.237001419067, "episode/length": 640.0, "episode/score": 0.2129937814679579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2129937814679579}
{"step": 758296, "time": 24786.50523209572, "episode/length": 640.0, "episode/score": 0.23867154661945733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23867154661945733}
{"step": 759112, "time": 24812.012146234512, "episode/length": 640.0, "episode/score": 0.16443798315151525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16443798315151525}
{"step": 759816, "time": 24833.879879951477, "episode/length": 640.0, "episode/score": 0.30422729726103626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30422729726103626}
{"step": 759992, "time": 24839.396032571793, "episode/length": 640.0, "episode/score": 0.2877786126725823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2877786126725823}
{"step": 760032, "time": 24852.862770080566, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.87174463272, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.879554271698, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.887205839157, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.89471554756, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.902402877808, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.909832954407, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24852.917330265045, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760752, "time": 24875.386865854263, "episode/length": 640.0, "episode/score": 0.24354725102921293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24354725102921293}
{"step": 761168, "time": 24888.468724250793, "episode/length": 640.0, "episode/score": 0.10054721394612898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10054721394612898}
{"step": 761368, "time": 24894.481172800064, "episode/length": 640.0, "episode/score": 0.1990485072607271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1990485072607271}
{"step": 761520, "time": 24899.451130628586, "episode/length": 300.0, "episode/score": 0.10474845177384395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10474845177384395}
{"step": 762096, "time": 24917.911402225494, "episode/length": 640.0, "episode/score": 0.21171218692006732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21171218692006732}
{"step": 763424, "time": 24959.310528755188, "episode/length": 640.0, "episode/score": 0.11766851222762398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11766851222762398}
{"step": 764944, "time": 25006.71927833557, "episode/length": 640.0, "episode/score": 0.14366639290187777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14366639290187777}
{"step": 765120, "time": 25012.195297002792, "episode/length": 640.0, "episode/score": 0.16818034159246054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16818034159246054}
{"step": 765880, "time": 25035.662924051285, "episode/length": 640.0, "episode/score": 0.03680281846084199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03680281846084199}
{"step": 766296, "time": 25048.59305691719, "episode/length": 640.0, "episode/score": 0.12617720282548817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12617720282548817}
{"step": 766496, "time": 25055.154686927795, "episode/length": 640.0, "episode/score": 0.056465063711812036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056465063711812036}
{"step": 766648, "time": 25059.66024160385, "episode/length": 640.0, "episode/score": 0.1168708995477914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1168708995477914}
{"step": 767224, "time": 25077.719324588776, "episode/length": 640.0, "episode/score": 0.085222548465822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.085222548465822}
{"step": 768552, "time": 25119.141753911972, "episode/length": 640.0, "episode/score": 0.1929808708487144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1929808708487144}
{"step": 770016, "time": 25177.470186948776, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.478330135345, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.509237527847, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.516836166382, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.524538755417, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.532253980637, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.540593624115, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25177.549244880676, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770072, "time": 25179.61135482788, "episode/length": 640.0, "episode/score": 0.05523697388792925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05523697388792925}
{"step": 770248, "time": 25185.174847602844, "episode/length": 640.0, "episode/score": 0.08727665371321791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08727665371321791}
{"step": 771008, "time": 25209.229541778564, "episode/length": 640.0, "episode/score": 0.1477746531398907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1477746531398907}
{"step": 771424, "time": 25222.451700925827, "episode/length": 640.0, "episode/score": 0.11974437850386721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11974437850386721}
{"step": 771624, "time": 25228.45794248581, "episode/length": 640.0, "episode/score": 0.12220335490928846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12220335490928846}
{"step": 771776, "time": 25233.395871162415, "episode/length": 640.0, "episode/score": 0.04250392297308281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04250392297308281}
{"step": 772297, "time": 25250.38532423973, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.180738063673899, "train/action_min": 0.0, "train/action_std": 1.857260659568668, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000723999290252973, "train/actor_opt_grad_steps": 47210.0, "train/actor_opt_loss": -6.807992684679019, "train/adv_mag": 0.07080133448456236, "train/adv_max": 0.004904173777819915, "train/adv_mean": -2.3189964434748267e-05, "train/adv_min": -0.07057240921907475, "train/adv_std": 0.0020497397418915647, "train/cont_avg": 0.9983858889248705, "train/cont_loss_mean": 0.002819247505283152, "train/cont_loss_std": 0.07225556184152875, "train/cont_neg_acc": 0.7610766071340312, "train/cont_neg_loss": 1.4670648945934575, "train/cont_pos_acc": 0.9999493289487967, "train/cont_pos_loss": 0.0004753382062814512, "train/cont_pred": 0.9983593157536007, "train/cont_rate": 0.9983858889248705, "train/dyn_loss_mean": 1.0000062958564164, "train/dyn_loss_std": 0.00016905937025352464, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.027815263124829438, "train/extr_critic_critic_opt_grad_steps": 47210.0, "train/extr_critic_critic_opt_loss": 13530.266267608484, "train/extr_critic_mag": 0.0856634884918292, "train/extr_critic_max": 0.0856634884918292, "train/extr_critic_mean": 0.08211334949175929, "train/extr_critic_min": 0.07701426651811352, "train/extr_critic_std": 0.0012807823525177113, "train/extr_return_normed_mag": 0.0687625443302288, "train/extr_return_normed_max": 0.008913493951676423, "train/extr_return_normed_mean": 0.0026296004514243703, "train/extr_return_normed_min": -0.06782644269071095, "train/extr_return_normed_std": 0.0024574215335703884, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08837406927903081, "train/extr_return_raw_max": 0.08837406927903081, "train/extr_return_raw_mean": 0.08209018011630508, "train/extr_return_raw_min": 0.011634132636643445, "train/extr_return_raw_std": 0.0024574215389990823, "train/extr_reward_mag": 0.0012382028016401697, "train/extr_reward_max": 0.0012382028016401697, "train/extr_reward_mean": 0.0002584273138546766, "train/extr_reward_min": 2.634339999658456e-06, "train/extr_reward_std": 0.00026868359433665604, "train/image_loss_mean": 0.10879853757706331, "train/image_loss_std": 0.1219332112395084, "train/model_loss_mean": 0.721241210408779, "train/model_loss_std": 0.16665058922736756, "train/model_opt_grad_norm": 19.67486814884324, "train/model_opt_grad_steps": 47168.538860103625, "train/model_opt_loss": 3653.4190066639007, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5064.766839378239, "train/policy_entropy_mag": 1.9411759086223463, "train/policy_entropy_max": 1.9411759086223463, "train/policy_entropy_mean": 1.7066340749127877, "train/policy_entropy_min": 0.6979049180146943, "train/policy_entropy_std": 0.14348756135899787, "train/policy_logprob_mag": 4.205748559279763, "train/policy_logprob_max": -0.1751801660332655, "train/policy_logprob_mean": -1.7068977862442096, "train/policy_logprob_min": -4.205748559279763, "train/policy_logprob_std": 0.6854935686823, "train/policy_randomness_mag": 0.9975671388324678, "train/policy_randomness_max": 0.9975671388324678, "train/policy_randomness_mean": 0.8770364736028285, "train/policy_randomness_min": 0.35865220226772093, "train/policy_randomness_std": 0.07373802433359808, "train/post_ent_mag": 28.397644013320843, "train/post_ent_max": 28.397644013320843, "train/post_ent_mean": 22.485867910434546, "train/post_ent_min": 18.161892594451114, "train/post_ent_std": 1.8788438528930584, "train/prior_ent_mag": 26.631027103088062, "train/prior_ent_max": 26.631027103088062, "train/prior_ent_mean": 22.313018156456824, "train/prior_ent_min": 18.69190274372002, "train/prior_ent_std": 1.3686816633674148, "train/rep_loss_mean": 1.0000062958564164, "train/rep_loss_std": 0.00016905937025352464, "train/reward_avg": 0.0002211671334044728, "train/reward_loss_mean": 0.009619622582984712, "train/reward_loss_std": 0.014058921901132776, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012095394529826901, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00961962263365252, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021990559394398964, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7193260717391967, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.006198478396981955, "report/cont_loss_std": 0.1891820877790451, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.5172532796859741, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0002727740502450615, "report/cont_pred": 0.9968081712722778, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09123066812753677, "report/image_loss_std": 0.1045653447508812, "report/model_loss_mean": 0.7043105363845825, "report/model_loss_std": 0.22353176772594452, "report/post_ent_mag": 28.676769256591797, "report/post_ent_max": 28.676769256591797, "report/post_ent_mean": 22.241825103759766, "report/post_ent_min": 17.40436553955078, "report/post_ent_std": 2.241006374359131, "report/prior_ent_mag": 28.292964935302734, "report/prior_ent_max": 28.292964935302734, "report/prior_ent_mean": 23.262592315673828, "report/prior_ent_min": 18.531967163085938, "report/prior_ent_std": 1.7946479320526123, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015004127635620534, "report/reward_loss_mean": 0.006881332956254482, "report/reward_loss_std": 0.011230834759771824, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011363029479980469, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006881332956254482, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017243821639567614, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.030148450285196304, "eval/cont_loss_std": 0.5261321067810059, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.700584411621094, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0017338512698188424, "eval/cont_pred": 0.9988763928413391, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.29310595989227295, "eval/image_loss_std": 0.14606168866157532, "eval/model_loss_mean": 0.9246870875358582, "eval/model_loss_std": 0.5465690493583679, "eval/post_ent_mag": 29.522245407104492, "eval/post_ent_max": 29.522245407104492, "eval/post_ent_mean": 22.238969802856445, "eval/post_ent_min": 17.6597900390625, "eval/post_ent_std": 2.1722028255462646, "eval/prior_ent_mag": 29.069047927856445, "eval/prior_ent_max": 29.069047927856445, "eval/prior_ent_mean": 23.50448989868164, "eval/prior_ent_min": 18.16295051574707, "eval/prior_ent_std": 1.7515910863876343, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014326609671115875, "eval/reward_loss_std": 0.001375850522890687, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010669231414794922, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014326609671115875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022536038886755705, "eval/reward_rate": 0.0, "replay/size": 771793.0, "replay/inserts": 30848.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.2981013638349984e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.54895469657613e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0865681876878346e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4275414943695, "timer/env.step_count": 3856.0, "timer/env.step_total": 33.599661350250244, "timer/env.step_frac": 0.03358530223994173, "timer/env.step_avg": 0.008713605121952864, "timer/env.step_min": 0.007260322570800781, "timer/env.step_max": 0.042452096939086914, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.41197681427002, "timer/replay._sample_frac": 0.015405390370649606, "timer/replay._sample_avg": 0.000499610244238525, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.028789043426513672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5779.0, "timer/agent.policy_total": 58.15787672996521, "timer/agent.policy_frac": 0.058133022450674435, "timer/agent.policy_avg": 0.010063657506482991, "timer/agent.policy_min": 0.008644819259643555, "timer/agent.policy_max": 0.10328531265258789, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.2095341682434082, "timer/dataset_train_frac": 0.0002094446219767406, "timer/dataset_train_avg": 0.00010867954784409139, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0005316734313964844, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 854.1048846244812, "timer/agent.train_frac": 0.8537398754023489, "timer/agent.train_avg": 0.4430004588301251, "timer/agent.train_min": 0.43268251419067383, "timer/agent.train_max": 0.6048228740692139, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769299030303955, "timer/agent.report_frac": 0.00047672608284852954, "timer/agent.report_avg": 0.23846495151519775, "timer/agent.report_min": 0.23279333114624023, "timer/agent.report_max": 0.24413657188415527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.835968597056623e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 30.83430633316418}
{"step": 772352, "time": 25252.081122159958, "episode/length": 640.0, "episode/score": 0.15634117937037217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15634117937037217}
{"step": 773680, "time": 25293.5905854702, "episode/length": 640.0, "episode/score": 0.19449395256009439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19449395256009439}
{"step": 775200, "time": 25340.9249958992, "episode/length": 640.0, "episode/score": 0.06368547452944995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06368547452944995}
{"step": 775376, "time": 25346.41328716278, "episode/length": 640.0, "episode/score": 0.1733894822801858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733894822801858}
{"step": 776136, "time": 25369.950878858566, "episode/length": 640.0, "episode/score": 0.1859952820828994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1859952820828994}
{"step": 776552, "time": 25382.844441652298, "episode/length": 640.0, "episode/score": 0.11005216205302304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11005216205302304}
{"step": 776752, "time": 25389.24297118187, "episode/length": 640.0, "episode/score": 0.12302800133306846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12302800133306846}
{"step": 776904, "time": 25393.752940654755, "episode/length": 640.0, "episode/score": 0.19214325044077896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19214325044077896}
{"step": 777480, "time": 25411.712641000748, "episode/length": 640.0, "episode/score": 0.0797938811607537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0797938811607537}
{"step": 778808, "time": 25453.520035266876, "episode/length": 640.0, "episode/score": 0.06168423631288533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06168423631288533}
{"step": 780000, "time": 25501.927115678787, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.936061620712, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.94407081604, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.951504945755, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.958921432495, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.966146469116, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.973412036896, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25501.980716228485, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780328, "time": 25512.005860328674, "episode/length": 640.0, "episode/score": 0.1721491399939623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1721491399939623}
{"step": 780504, "time": 25517.574773311615, "episode/length": 640.0, "episode/score": 0.16987157745984405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16987157745984405}
{"step": 781264, "time": 25541.48664879799, "episode/length": 640.0, "episode/score": 0.2198425252548759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2198425252548759}
{"step": 781680, "time": 25554.6062207222, "episode/length": 640.0, "episode/score": 0.07658268672324198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07658268672324198}
{"step": 781880, "time": 25560.752501487732, "episode/length": 640.0, "episode/score": 0.19296540258164896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19296540258164896}
{"step": 782032, "time": 25565.794376850128, "episode/length": 640.0, "episode/score": 0.1742246795334097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742246795334097}
{"step": 782608, "time": 25583.868182182312, "episode/length": 640.0, "episode/score": 0.12658419403757648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12658419403757648}
{"step": 783936, "time": 25625.197692632675, "episode/length": 640.0, "episode/score": 0.17773287622364364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17773287622364364}
{"step": 785456, "time": 25672.40051150322, "episode/length": 640.0, "episode/score": 0.26887308325066783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26887308325066783}
{"step": 785632, "time": 25677.84782385826, "episode/length": 640.0, "episode/score": 0.1547702069156287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1547702069156287}
{"step": 786392, "time": 25701.218115091324, "episode/length": 640.0, "episode/score": 0.20090482322018488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20090482322018488}
{"step": 786808, "time": 25714.68480205536, "episode/length": 640.0, "episode/score": 0.21007942033293148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21007942033293148}
{"step": 787008, "time": 25721.1077773571, "episode/length": 640.0, "episode/score": 0.22919016848015872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22919016848015872}
{"step": 787160, "time": 25725.72802233696, "episode/length": 640.0, "episode/score": 0.10811310590554513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10811310590554513}
{"step": 787736, "time": 25743.783381700516, "episode/length": 640.0, "episode/score": 0.23160585124111321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23160585124111321}
{"step": 789064, "time": 25785.158140659332, "episode/length": 640.0, "episode/score": 0.07417743578668023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07417743578668023}
{"step": 790088, "time": 25829.191851854324, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.20079255104, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.20901274681, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.216749191284, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.224940538406, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.232968568802, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.240987300873, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25829.24869441986, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790584, "time": 25844.748589992523, "episode/length": 640.0, "episode/score": 0.22130811104835857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22130811104835857}
{"step": 790760, "time": 25850.318167686462, "episode/length": 640.0, "episode/score": 0.04717377552464086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04717377552464086}
{"step": 791520, "time": 25874.382636785507, "episode/length": 640.0, "episode/score": 0.22936959916677324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22936959916677324}
{"step": 791936, "time": 25887.48899626732, "episode/length": 640.0, "episode/score": 0.17606830354344538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17606830354344538}
{"step": 792136, "time": 25893.55132842064, "episode/length": 640.0, "episode/score": 0.10701207625464804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10701207625464804}
{"step": 792288, "time": 25898.493997335434, "episode/length": 640.0, "episode/score": 0.2351868563220023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2351868563220023}
{"step": 792864, "time": 25916.43078994751, "episode/length": 640.0, "episode/score": 0.18853890920274807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18853890920274807}
{"step": 794192, "time": 25957.697687625885, "episode/length": 640.0, "episode/score": 0.19666003616555372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19666003616555372}
{"step": 795712, "time": 26005.394713401794, "episode/length": 640.0, "episode/score": 0.08787935933577273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08787935933577273}
{"step": 795888, "time": 26010.842647075653, "episode/length": 640.0, "episode/score": 0.12996355431664597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12996355431664597}
{"step": 795976, "time": 26013.35619187355, "episode/length": 556.0, "episode/score": 0.18941561597705459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18941561597705459}
{"step": 797064, "time": 26047.476895093918, "episode/length": 640.0, "episode/score": 0.17830449531504655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17830449531504655}
{"step": 797264, "time": 26053.933448076248, "episode/length": 640.0, "episode/score": 0.12248194717022898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12248194717022898}
{"step": 797416, "time": 26058.48945069313, "episode/length": 640.0, "episode/score": 0.04873808182588846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04873808182588846}
{"step": 797992, "time": 26076.35941338539, "episode/length": 640.0, "episode/score": 0.18166445920201113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18166445920201113}
{"step": 799320, "time": 26117.872813224792, "episode/length": 640.0, "episode/score": 0.12657064591854805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12657064591854805}
{"step": 800072, "time": 26152.487979888916, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.497136116028, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.50533223152, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.513222694397, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.52099919319, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.528342962265, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.535865306854, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26152.543786287308, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800840, "time": 26176.499306678772, "episode/length": 640.0, "episode/score": 0.060093617430766244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060093617430766244}
{"step": 801016, "time": 26181.919768095016, "episode/length": 640.0, "episode/score": 0.15127690982467357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15127690982467357}
{"step": 801104, "time": 26184.85906100273, "episode/length": 640.0, "episode/score": 0.04925080704862239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04925080704862239}
{"step": 802192, "time": 26218.94852042198, "episode/length": 640.0, "episode/score": 0.18326141426462073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18326141426462073}
{"step": 802392, "time": 26224.960889816284, "episode/length": 640.0, "episode/score": 0.21160698119206245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21160698119206245}
{"step": 802544, "time": 26229.895998954773, "episode/length": 640.0, "episode/score": 0.17031739513583943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17031739513583943}
{"step": 803120, "time": 26248.26084446907, "episode/length": 640.0, "episode/score": 0.10593896556733284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10593896556733284}
{"step": 803177, "time": 26250.79621219635, "train_stats/mean_log_entropy": 1.7475430357212922, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.281564030622571, "train/action_min": 0.0, "train/action_std": 1.8705798554296937, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007245534033589355, "train/actor_opt_grad_steps": 49140.0, "train/actor_opt_loss": -7.604381984842874, "train/adv_mag": 0.0688024026587837, "train/adv_max": 0.004778009390583928, "train/adv_mean": -7.431243635093563e-05, "train/adv_min": -0.06855838464022918, "train/adv_std": 0.002107117971082078, "train/cont_avg": 0.9983555294689119, "train/cont_loss_mean": 0.0027461172916342555, "train/cont_loss_std": 0.06877397974456029, "train/cont_neg_acc": 0.7560416689142585, "train/cont_neg_loss": 1.3311630721943402, "train/cont_pos_acc": 0.9999543684751876, "train/cont_pos_loss": 0.0004786345086825307, "train/cont_pred": 0.9983844744726784, "train/cont_rate": 0.9983555294689119, "train/dyn_loss_mean": 1.0000015274848344, "train/dyn_loss_std": 4.8862284859473494e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03048165869408099, "train/extr_critic_critic_opt_grad_steps": 49140.0, "train/extr_critic_critic_opt_loss": 13524.923711747086, "train/extr_critic_mag": 0.08384199896007004, "train/extr_critic_max": 0.08384199896007004, "train/extr_critic_mean": 0.08034703316929427, "train/extr_critic_min": 0.07554298176048951, "train/extr_critic_std": 0.0012140683485967123, "train/extr_return_normed_mag": 0.06709152622235254, "train/extr_return_normed_max": 0.00854184324105169, "train/extr_return_normed_mean": 0.0024158566438597794, "train/extr_return_normed_min": -0.06611680633200265, "train/extr_return_normed_std": 0.00246404585672224, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08639865650414186, "train/extr_return_raw_max": 0.08639865650414186, "train/extr_return_raw_mean": 0.08027267409729834, "train/extr_return_raw_min": 0.011740006931087513, "train/extr_return_raw_std": 0.002464045869389192, "train/extr_reward_mag": 0.0012401750050678154, "train/extr_reward_max": 0.0012401750050678154, "train/extr_reward_mean": 0.000247061707699488, "train/extr_reward_min": 2.59172113448227e-06, "train/extr_reward_std": 0.0002685105357979004, "train/image_loss_mean": 0.10636178133864477, "train/image_loss_std": 0.12052209740938918, "train/model_loss_mean": 0.7187630997420592, "train/model_loss_std": 0.16184522003089827, "train/model_opt_grad_norm": 18.942112492773816, "train/model_opt_grad_steps": 49096.56994818653, "train/model_opt_loss": 3500.696722317236, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4870.466321243523, "train/policy_entropy_mag": 1.9416758242048748, "train/policy_entropy_max": 1.9416758242048748, "train/policy_entropy_mean": 1.7333035635824647, "train/policy_entropy_min": 0.7306166342194216, "train/policy_entropy_std": 0.13420657944802794, "train/policy_logprob_mag": 4.179626840383896, "train/policy_logprob_max": -0.18651640627513896, "train/policy_logprob_mean": -1.7333420447117307, "train/policy_logprob_min": -4.179626840383896, "train/policy_logprob_std": 0.650140378759315, "train/policy_randomness_mag": 0.9978240459694145, "train/policy_randomness_max": 0.9978240459694145, "train/policy_randomness_mean": 0.8907418874878957, "train/policy_randomness_min": 0.375462698426889, "train/policy_randomness_std": 0.06896854286598418, "train/post_ent_mag": 28.56106271892014, "train/post_ent_max": 28.56106271892014, "train/post_ent_mean": 22.529508047153296, "train/post_ent_min": 17.610827510221018, "train/post_ent_std": 2.0910260072026228, "train/prior_ent_mag": 27.59787132579428, "train/prior_ent_max": 27.59787132579428, "train/prior_ent_mean": 22.35776337934899, "train/prior_ent_min": 17.4715685869128, "train/prior_ent_std": 1.8124813107011233, "train/rep_loss_mean": 1.0000015274848344, "train/rep_loss_std": 4.8862284859473494e-05, "train/reward_avg": 0.0002220431550820913, "train/reward_loss_mean": 0.00965426187392884, "train/reward_loss_std": 0.01404384025155417, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012156469216618514, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009654261878754344, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022116384271126955, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00020293491252232343, "report/cont_loss_std": 0.0005799345672130585, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001811851398088038, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.000201362170628272, "report/cont_pred": 0.9988242387771606, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10359100252389908, "report/image_loss_std": 0.12935630977153778, "report/model_loss_mean": 0.7143382430076599, "report/model_loss_std": 0.13270968198776245, "report/post_ent_mag": 30.85331153869629, "report/post_ent_max": 30.85331153869629, "report/post_ent_mean": 24.156185150146484, "report/post_ent_min": 18.07697296142578, "report/post_ent_std": 2.531684160232544, "report/prior_ent_mag": 29.124942779541016, "report/prior_ent_max": 29.124942779541016, "report/prior_ent_mean": 23.131893157958984, "report/prior_ent_min": 17.03558349609375, "report/prior_ent_std": 2.4161198139190674, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00024738709907978773, "report/reward_loss_mean": 0.010544298216700554, "report/reward_loss_std": 0.014435895718634129, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013477802276611328, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010544298216700554, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00028245081193745136, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03179096803069115, "eval/cont_loss_std": 0.577296257019043, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.671900749206543, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005271785194054246, "eval/cont_pred": 0.9994825124740601, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.30196234583854675, "eval/image_loss_std": 0.15545213222503662, "eval/model_loss_mean": 0.9354867935180664, "eval/model_loss_std": 0.5977352857589722, "eval/post_ent_mag": 31.405582427978516, "eval/post_ent_max": 31.405582427978516, "eval/post_ent_mean": 23.328092575073242, "eval/post_ent_min": 16.718463897705078, "eval/post_ent_std": 2.4897429943084717, "eval/prior_ent_mag": 29.23019790649414, "eval/prior_ent_max": 29.23019790649414, "eval/prior_ent_mean": 22.496196746826172, "eval/prior_ent_min": 15.439678192138672, "eval/prior_ent_std": 2.586419105529785, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0017334632575511932, "eval/reward_loss_std": 0.0016902177594602108, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011699199676513672, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017334632575511932, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00027260417118668556, "eval/reward_rate": 0.0, "replay/size": 802673.0, "replay/inserts": 30880.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.292262670289667e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.662978389720226e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0655996270063204e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3969850540161, "timer/env.step_count": 3860.0, "timer/env.step_total": 33.4790997505188, "timer/env.step_frac": 0.03346581432241232, "timer/env.step_avg": 0.008673341904279482, "timer/env.step_min": 0.007255077362060547, "timer/env.step_max": 0.03508329391479492, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 15.40964651107788, "timer/replay._sample_frac": 0.015403531539277721, "timer/replay._sample_avg": 0.000499017050229206, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.028113842010498047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5783.0, "timer/agent.policy_total": 57.31723070144653, "timer/agent.policy_frac": 0.057294485646967146, "timer/agent.policy_avg": 0.009911331610141195, "timer/agent.policy_min": 0.008140325546264648, "timer/agent.policy_max": 0.08571338653564453, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.20830202102661133, "timer/dataset_train_frac": 0.00020821936105231678, "timer/dataset_train_avg": 0.0001079285083039437, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0003871917724609375, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 855.4488589763641, "timer/agent.train_frac": 0.8551093933276642, "timer/agent.train_avg": 0.44323775076495553, "timer/agent.train_min": 0.42850828170776367, "timer/agent.train_max": 0.5920712947845459, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741859436035156, "timer/agent.report_frac": 0.0004739977735717707, "timer/agent.report_avg": 0.2370929718017578, "timer/agent.report_min": 0.23010492324829102, "timer/agent.report_max": 0.2440810203552246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3365355526752696e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 30.86722243335739}
{"step": 804448, "time": 26291.064974308014, "episode/length": 640.0, "episode/score": 0.15672076001393975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15672076001393975}
{"step": 805968, "time": 26338.662290096283, "episode/length": 640.0, "episode/score": 0.0955292978758564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0955292978758564}
{"step": 806144, "time": 26344.157633066177, "episode/length": 640.0, "episode/score": 0.18436196772907465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18436196772907465}
{"step": 806232, "time": 26346.67277789116, "episode/length": 640.0, "episode/score": 0.22098651690012616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22098651690012616}
{"step": 807320, "time": 26380.656574487686, "episode/length": 640.0, "episode/score": 0.10442685694718534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10442685694718534}
{"step": 807520, "time": 26387.243669509888, "episode/length": 640.0, "episode/score": 0.1967655736434324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1967655736434324}
{"step": 807672, "time": 26391.76865005493, "episode/length": 640.0, "episode/score": 0.15591030011916018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15591030011916018}
{"step": 808248, "time": 26409.8637342453, "episode/length": 640.0, "episode/score": 0.17100593521277574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17100593521277574}
{"step": 809576, "time": 26451.411389112473, "episode/length": 640.0, "episode/score": 0.18449425543207099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18449425543207099}
{"step": 810056, "time": 26478.059252500534, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.0683054924, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.076097249985, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.083552598953, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.09134864807, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.09868645668, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.105746507645, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26478.112820386887, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 811096, "time": 26511.162974119186, "episode/length": 640.0, "episode/score": 0.13878807299292362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13878807299292362}
{"step": 811272, "time": 26516.60866689682, "episode/length": 640.0, "episode/score": 0.16770646699947633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16770646699947633}
{"step": 811360, "time": 26519.56569504738, "episode/length": 640.0, "episode/score": 0.13402416496214187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13402416496214187}
{"step": 812448, "time": 26554.0220618248, "episode/length": 640.0, "episode/score": 0.14665072827352787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14665072827352787}
{"step": 812648, "time": 26560.113406181335, "episode/length": 640.0, "episode/score": 0.09100950343585623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09100950343585623}
{"step": 812800, "time": 26565.154761075974, "episode/length": 640.0, "episode/score": 0.09086479211134701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09086479211134701}
{"step": 813376, "time": 26583.367181777954, "episode/length": 640.0, "episode/score": 0.07731740481338534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07731740481338534}
{"step": 814704, "time": 26624.63580942154, "episode/length": 640.0, "episode/score": 0.14097741475944758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14097741475944758}
{"step": 815056, "time": 26635.644691705704, "episode/length": 461.0, "episode/score": 0.16702356528421092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16702356528421092}
{"step": 816224, "time": 26672.128962278366, "episode/length": 640.0, "episode/score": 0.21571116485756647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21571116485756647}
{"step": 816400, "time": 26677.589868545532, "episode/length": 640.0, "episode/score": 0.1570306918328157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1570306918328157}
{"step": 817576, "time": 26714.423981428146, "episode/length": 640.0, "episode/score": 0.10786706456792672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10786706456792672}
{"step": 817776, "time": 26720.975300312042, "episode/length": 640.0, "episode/score": 0.047531507681839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047531507681839}
{"step": 817928, "time": 26725.484637498856, "episode/length": 640.0, "episode/score": 0.07148207588633682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07148207588633682}
{"step": 818504, "time": 26743.433060646057, "episode/length": 640.0, "episode/score": 0.15831770342423113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15831770342423113}
{"step": 819832, "time": 26785.33252596855, "episode/length": 640.0, "episode/score": 0.21665923872086523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21665923872086523}
{"step": 820040, "time": 26803.259905338287, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.268510580063, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.276082992554, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.284127235413, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.291631937027, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.298726558685, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.305678844452, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 26803.3127951622, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820184, "time": 26808.00063920021, "episode/length": 640.0, "episode/score": 0.14062758724955415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14062758724955415}
{"step": 821352, "time": 26844.69797348976, "episode/length": 640.0, "episode/score": 0.21270966063593733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21270966063593733}
{"step": 821528, "time": 26850.165167808533, "episode/length": 640.0, "episode/score": 0.08638183690425194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08638183690425194}
{"step": 822704, "time": 26887.226004123688, "episode/length": 640.0, "episode/score": 0.2478868875932676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2478868875932676}
{"step": 822904, "time": 26893.24695611, "episode/length": 640.0, "episode/score": 0.24736255397135665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24736255397135665}
{"step": 823056, "time": 26898.28569126129, "episode/length": 640.0, "episode/score": 0.22308077500508716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22308077500508716}
{"step": 823632, "time": 26916.221923828125, "episode/length": 640.0, "episode/score": 0.15219017171045834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15219017171045834}
{"step": 824960, "time": 26957.74461746216, "episode/length": 640.0, "episode/score": 0.21913877431086348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21913877431086348}
{"step": 825312, "time": 26968.729204177856, "episode/length": 640.0, "episode/score": 0.21517814361413912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21517814361413912}
{"step": 826480, "time": 27005.148563861847, "episode/length": 640.0, "episode/score": 0.1953331206002531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1953331206002531}
{"step": 826656, "time": 27010.62350177765, "episode/length": 640.0, "episode/score": 0.2400045240746067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2400045240746067}
{"step": 827832, "time": 27047.792672634125, "episode/length": 640.0, "episode/score": 0.2303209620617963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2303209620617963}
{"step": 828032, "time": 27054.22684955597, "episode/length": 640.0, "episode/score": 0.1362273295758314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1362273295758314}
{"step": 828184, "time": 27058.73622727394, "episode/length": 640.0, "episode/score": 0.18865766634053216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18865766634053216}
{"step": 828464, "time": 27067.663167238235, "episode/length": 437.0, "episode/score": 0.1692381861555532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1692381861555532}
{"step": 828760, "time": 27076.779267072678, "episode/length": 640.0, "episode/score": 0.13034294928104373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13034294928104373}
{"step": 829616, "time": 27105.76878094673, "episode/length": 537.0, "episode/score": 0.17705641865154575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17705641865154575}
{"step": 830024, "time": 27129.404406309128, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.41321492195, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.421176433563, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.428735733032, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.436441898346, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.444053649902, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.451805114746, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27129.45987892151, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 831608, "time": 27179.265639066696, "episode/length": 640.0, "episode/score": 0.1479883157318227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1479883157318227}
{"step": 831784, "time": 27184.735827684402, "episode/length": 640.0, "episode/score": 0.21438763258458948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21438763258458948}
{"step": 832960, "time": 27221.78111410141, "episode/length": 640.0, "episode/score": 0.18702092512080526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18702092512080526}
{"step": 833160, "time": 27227.92671895027, "episode/length": 640.0, "episode/score": 0.27835090180974476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27835090180974476}
{"step": 833312, "time": 27232.889107704163, "episode/length": 640.0, "episode/score": 0.23998186980259106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23998186980259106}
{"step": 833592, "time": 27241.588179588318, "episode/length": 640.0, "episode/score": 0.13796353793861726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13796353793861726}
{"step": 833865, "time": 27251.241905927658, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2636585235595703, "train/action_min": 0.0, "train/action_std": 1.8612329692890246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007513685513913515, "train/actor_opt_grad_steps": 51065.0, "train/actor_opt_loss": -6.859025890938938, "train/adv_mag": 0.06572634843178093, "train/adv_max": 0.004937001426393787, "train/adv_mean": -2.608568262492857e-05, "train/adv_min": -0.0654640404197077, "train/adv_std": 0.002102428973557835, "train/cont_avg": 0.9984486897786459, "train/cont_loss_mean": 0.0028262688952054305, "train/cont_loss_std": 0.07045765868815579, "train/cont_neg_acc": 0.7528322465669096, "train/cont_neg_loss": 1.4746917355230216, "train/cont_pos_acc": 0.9999694305782517, "train/cont_pos_loss": 0.00043527489450904494, "train/cont_pred": 0.9984665432324012, "train/cont_rate": 0.9984486897786459, "train/dyn_loss_mean": 1.0000042660782735, "train/dyn_loss_std": 0.000126168079608154, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03032790017869047, "train/extr_critic_critic_opt_grad_steps": 51065.0, "train/extr_critic_critic_opt_loss": 13514.84122212728, "train/extr_critic_mag": 0.08235306416948636, "train/extr_critic_max": 0.08235306416948636, "train/extr_critic_mean": 0.07846546751291801, "train/extr_critic_min": 0.07340735631684463, "train/extr_critic_std": 0.0013481814494298305, "train/extr_return_normed_mag": 0.06386846082750708, "train/extr_return_normed_max": 0.009205759386532009, "train/extr_return_normed_mean": 0.002723089299252024, "train/extr_return_normed_min": -0.06273882960279782, "train/extr_return_normed_std": 0.0025391540590741593, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08492205784811328, "train/extr_return_raw_max": 0.08492205784811328, "train/extr_return_raw_mean": 0.07843939063604921, "train/extr_return_raw_min": 0.012977468858783444, "train/extr_return_raw_std": 0.002539154051191872, "train/extr_reward_mag": 0.001251465951402982, "train/extr_reward_max": 0.001251465951402982, "train/extr_reward_mean": 0.0002515070628608858, "train/extr_reward_min": 2.612049380938212e-06, "train/extr_reward_std": 0.00027103624756819045, "train/image_loss_mean": 0.10630814315906416, "train/image_loss_std": 0.12110893284746756, "train/model_loss_mean": 0.7186996030310789, "train/model_loss_std": 0.1649667249682049, "train/model_opt_grad_norm": 19.084558781528973, "train/model_opt_grad_steps": 51019.989583333336, "train/model_opt_loss": 3050.967985788981, "train/model_opt_model_opt_grad_overflow": 0.005208333333333333, "train/model_opt_model_opt_grad_scale": 4218.75, "train/policy_entropy_mag": 1.9417815301567316, "train/policy_entropy_max": 1.9417815301567316, "train/policy_entropy_mean": 1.727696079139908, "train/policy_entropy_min": 0.6993605558139583, "train/policy_entropy_std": 0.1395233728302022, "train/policy_logprob_mag": 4.181448833396037, "train/policy_logprob_max": -0.17603323818184435, "train/policy_logprob_mean": -1.7280841941634815, "train/policy_logprob_min": -4.181448833396037, "train/policy_logprob_std": 0.6598196045185128, "train/policy_randomness_mag": 0.997878366149962, "train/policy_randomness_max": 0.997878366149962, "train/policy_randomness_mean": 0.8878602059558034, "train/policy_randomness_min": 0.3594002507937451, "train/policy_randomness_std": 0.07170083428112169, "train/post_ent_mag": 29.65947945912679, "train/post_ent_max": 29.65947945912679, "train/post_ent_mean": 23.05785509943962, "train/post_ent_min": 17.214587142070133, "train/post_ent_std": 2.4286190743247666, "train/prior_ent_mag": 28.464128345251083, "train/prior_ent_max": 28.464128345251083, "train/prior_ent_mean": 22.751460045576096, "train/prior_ent_min": 17.14269978304704, "train/prior_ent_std": 2.1535150750229755, "train/rep_loss_mean": 1.0000042660782735, "train/rep_loss_std": 0.000126168079608154, "train/reward_avg": 0.0002196746423427006, "train/reward_loss_mean": 0.009562606113225533, "train/reward_loss_std": 0.013953857046241561, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012136114140351613, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00956260606229383, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022223869139755456, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7459420015414555, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0002199058944825083, "report/cont_loss_std": 0.00054154236568138, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004316479898989201, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00021188909886404872, "report/cont_pred": 0.9978439807891846, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09312162548303604, "report/image_loss_std": 0.10205809026956558, "report/model_loss_mean": 0.7032214403152466, "report/model_loss_std": 0.10496912896633148, "report/post_ent_mag": 31.16294288635254, "report/post_ent_max": 31.16294288635254, "report/post_ent_mean": 24.742422103881836, "report/post_ent_min": 18.695117950439453, "report/post_ent_std": 2.279853582382202, "report/prior_ent_mag": 29.609352111816406, "report/prior_ent_max": 29.609352111816406, "report/prior_ent_mean": 22.16999053955078, "report/prior_ent_min": 16.38695526123047, "report/prior_ent_std": 2.2574381828308105, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00022760350839234889, "report/reward_loss_mean": 0.009879952296614647, "report/reward_loss_std": 0.013744447380304337, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012125968933105469, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009879952296614647, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002595713594928384, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.020765207707881927, "eval/cont_loss_std": 0.4452572762966156, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.867369651794434, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.001495923032052815, "eval/cont_pred": 0.9989494681358337, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0001250505447388, "eval/dyn_loss_std": 0.004000495653599501, "eval/image_loss_mean": 0.31998682022094727, "eval/image_loss_std": 0.14392976462841034, "eval/model_loss_mean": 0.9678055644035339, "eval/model_loss_std": 1.2106537818908691, "eval/post_ent_mag": 31.318471908569336, "eval/post_ent_max": 31.318471908569336, "eval/post_ent_mean": 24.008628845214844, "eval/post_ent_min": 19.401287078857422, "eval/post_ent_std": 2.183652400970459, "eval/prior_ent_mag": 29.537342071533203, "eval/prior_ent_max": 29.537342071533203, "eval/prior_ent_mean": 21.570110321044922, "eval/prior_ent_min": 16.93189239501953, "eval/prior_ent_std": 2.315211772918701, "eval/rep_loss_mean": 1.0001250505447388, "eval/rep_loss_std": 0.004000495653599501, "eval/reward_avg": 0.0004341125604696572, "eval/reward_loss_mean": 0.026978513225913048, "eval/reward_loss_std": 0.8149963617324829, "eval/reward_max_data": 0.44453126192092896, "eval/reward_max_pred": 0.0011687278747558594, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014974724035710096, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 26.094085693359375, "eval/reward_pred": 0.00023536954540759325, "eval/reward_rate": 0.0009765625, "replay/size": 833361.0, "replay/inserts": 30688.0, "replay/samples": 30688.0, "replay/insert_wait_avg": 1.3155130449997124e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.78364561596056e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0303730649744788e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4217631816864, "timer/env.step_count": 3836.0, "timer/env.step_total": 33.69724202156067, "timer/env.step_frac": 0.03368303575723084, "timer/env.step_avg": 0.008784473936798922, "timer/env.step_min": 0.00731968879699707, "timer/env.step_max": 0.04909014701843262, "timer/replay._sample_count": 30688.0, "timer/replay._sample_total": 15.485015153884888, "timer/replay._sample_frac": 0.015478486898003095, "timer/replay._sample_avg": 0.0005045951236276358, "timer/replay._sample_min": 0.00037026405334472656, "timer/replay._sample_max": 0.030709505081176758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5759.0, "timer/agent.policy_total": 57.51655888557434, "timer/agent.policy_frac": 0.057492310745671744, "timer/agent.policy_avg": 0.009987247592563699, "timer/agent.policy_min": 0.008352279663085938, "timer/agent.policy_max": 0.09390664100646973, "timer/dataset_train_count": 1918.0, "timer/dataset_train_total": 0.2100362777709961, "timer/dataset_train_frac": 0.00020994772954859383, "timer/dataset_train_avg": 0.00010950796546975813, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.00038361549377441406, "timer/agent.train_count": 1918.0, "timer/agent.train_total": 855.4749283790588, "timer/agent.train_frac": 0.8551142726627151, "timer/agent.train_avg": 0.446024467350917, "timer/agent.train_min": 0.43216824531555176, "timer/agent.train_max": 2.498767852783203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784412384033203, "timer/agent.report_frac": 0.00047823953457560946, "timer/agent.report_avg": 0.23922061920166016, "timer/agent.report_min": 0.2309122085571289, "timer/agent.report_max": 0.2475290298461914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3364529144251405e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 30.674487039464896}
{"step": 833888, "time": 27251.949551582336, "episode/length": 640.0, "episode/score": 0.20194339427519026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20194339427519026}
{"step": 834744, "time": 27278.660721063614, "episode/length": 640.0, "episode/score": 0.2238451013060967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2238451013060967}
{"step": 836736, "time": 27341.429042577744, "episode/length": 640.0, "episode/score": 0.09723092277062051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09723092277062051}
{"step": 836912, "time": 27346.98432612419, "episode/length": 640.0, "episode/score": 0.19260895167815306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19260895167815306}
{"step": 838088, "time": 27383.336594820023, "episode/length": 640.0, "episode/score": 0.18136457556073537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18136457556073537}
{"step": 838288, "time": 27389.77650117874, "episode/length": 640.0, "episode/score": 0.1782673016785452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1782673016785452}
{"step": 838440, "time": 27394.357970237732, "episode/length": 640.0, "episode/score": 0.14945902723752624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14945902723752624}
{"step": 838720, "time": 27403.330732107162, "episode/length": 640.0, "episode/score": 0.13386486056526792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13386486056526792}
{"step": 839016, "time": 27412.4193277359, "episode/length": 640.0, "episode/score": 0.16246108372428125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16246108372428125}
{"step": 839872, "time": 27439.226134300232, "episode/length": 640.0, "episode/score": 0.15427060353147226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15427060353147226}
{"step": 840008, "time": 27454.723407506943, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.731807231903, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.740283966064, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.747704029083, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.754868745804, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.761700868607, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.76899576187, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27454.776136159897, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 841864, "time": 27512.420011758804, "episode/length": 640.0, "episode/score": 0.11334701606915587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11334701606915587}
{"step": 842040, "time": 27517.893425941467, "episode/length": 640.0, "episode/score": 0.16421647898198444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16421647898198444}
{"step": 843216, "time": 27554.721127986908, "episode/length": 640.0, "episode/score": 0.16742762999362526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16742762999362526}
{"step": 843416, "time": 27560.76693892479, "episode/length": 640.0, "episode/score": 0.1701590367190704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1701590367190704}
{"step": 843568, "time": 27565.698929071426, "episode/length": 640.0, "episode/score": 0.16020578359652404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16020578359652404}
{"step": 843848, "time": 27574.63228201866, "episode/length": 640.0, "episode/score": 0.1122284151702786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1122284151702786}
{"step": 844144, "time": 27584.071611881256, "episode/length": 640.0, "episode/score": 0.12353011419475024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12353011419475024}
{"step": 845000, "time": 27610.603045463562, "episode/length": 640.0, "episode/score": 0.15977930118964423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15977930118964423}
{"step": 846992, "time": 27672.948138952255, "episode/length": 640.0, "episode/score": 0.04220455671486434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04220455671486434}
{"step": 847168, "time": 27678.480701446533, "episode/length": 640.0, "episode/score": 0.08566207132835757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08566207132835757}
{"step": 848344, "time": 27715.038380146027, "episode/length": 640.0, "episode/score": 0.1635841449634654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1635841449634654}
{"step": 848544, "time": 27721.57684993744, "episode/length": 640.0, "episode/score": 0.19198009842889974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19198009842889974}
{"step": 848696, "time": 27726.16806960106, "episode/length": 640.0, "episode/score": 0.1313681974111205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313681974111205}
{"step": 848976, "time": 27735.231761455536, "episode/length": 640.0, "episode/score": 0.11844666844135077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11844666844135077}
{"step": 849272, "time": 27744.438939094543, "episode/length": 640.0, "episode/score": 0.189736079873569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.189736079873569}
{"step": 850096, "time": 27782.051827907562, "eval_episode/length": 621.0, "eval_episode/score": 0.12671874463558197, "eval_episode/reward_rate": 0.001607717041800643}
{"step": 850096, "time": 27782.42728281021, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 27782.436441659927, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 27782.44486093521, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 27782.453109264374, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 27782.461178064346, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 27782.469123601913, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 27782.47707080841, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850128, "time": 27783.511575698853, "episode/length": 640.0, "episode/score": 0.2198870922777303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2198870922777303}
{"step": 852120, "time": 27845.894572257996, "episode/length": 640.0, "episode/score": 0.20812199680852927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20812199680852927}
{"step": 852296, "time": 27851.37277340889, "episode/length": 640.0, "episode/score": 0.09636335503415694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09636335503415694}
{"step": 853472, "time": 27888.235774993896, "episode/length": 640.0, "episode/score": 0.20555206180495134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20555206180495134}
{"step": 853672, "time": 27894.19945526123, "episode/length": 640.0, "episode/score": 0.1569347683607134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1569347683607134}
{"step": 853824, "time": 27899.130301237106, "episode/length": 640.0, "episode/score": 0.17777362728452317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17777362728452317}
{"step": 854104, "time": 27907.59664082527, "episode/length": 640.0, "episode/score": 0.16740098461272623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16740098461272623}
{"step": 854400, "time": 27917.106388807297, "episode/length": 640.0, "episode/score": 0.220425981530866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.220425981530866}
{"step": 855256, "time": 27943.49192428589, "episode/length": 640.0, "episode/score": 0.1706730686313449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706730686313449}
{"step": 857248, "time": 28005.825247764587, "episode/length": 640.0, "episode/score": 0.12817498427995133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12817498427995133}
{"step": 857424, "time": 28011.299468517303, "episode/length": 640.0, "episode/score": 0.15942598508524952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15942598508524952}
{"step": 858120, "time": 28032.701548337936, "episode/length": 580.0, "episode/score": 0.19451731181834475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19451731181834475}
{"step": 858800, "time": 28054.035443544388, "episode/length": 640.0, "episode/score": 0.21180756070140205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21180756070140205}
{"step": 858952, "time": 28058.51450586319, "episode/length": 640.0, "episode/score": 0.2420781041955138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2420781041955138}
{"step": 859232, "time": 28067.474725723267, "episode/length": 640.0, "episode/score": 0.16974591442749443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16974591442749443}
{"step": 859528, "time": 28076.43823838234, "episode/length": 640.0, "episode/score": 0.08212392480152175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08212392480152175}
{"step": 860080, "time": 28104.920568227768, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.928941965103, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.936532735825, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.944406032562, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.95184659958, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.959260463715, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.966685056686, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28104.974261045456, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860384, "time": 28114.92610836029, "episode/length": 640.0, "episode/score": 0.1261275242026727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1261275242026727}
{"step": 862376, "time": 28176.95855808258, "episode/length": 640.0, "episode/score": 0.17597221405497976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17597221405497976}
{"step": 862552, "time": 28182.41261768341, "episode/length": 640.0, "episode/score": 0.2011423824745293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2011423824745293}
{"step": 863248, "time": 28204.324392080307, "episode/length": 640.0, "episode/score": 0.18164467495086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18164467495086}
{"step": 863928, "time": 28225.33136820793, "episode/length": 640.0, "episode/score": 0.20897424843343515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20897424843343515}
{"step": 864080, "time": 28230.303909301758, "episode/length": 640.0, "episode/score": 0.20631667394826536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20631667394826536}
{"step": 864248, "time": 28235.31372833252, "episode/length": 211.0, "episode/score": 0.07081280968736792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07081280968736792}
{"step": 864360, "time": 28238.801409244537, "episode/length": 640.0, "episode/score": 0.21197699314762986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21197699314762986}
{"step": 864656, "time": 28248.31205010414, "episode/length": 640.0, "episode/score": 0.19038620950232144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19038620950232144}
{"step": 864729, "time": 28251.31585073471, "train_stats/mean_log_entropy": 1.7182167601585387, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.209717114766439, "train/action_min": 0.0, "train/action_std": 1.8491986611237128, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007303967178510599, "train/actor_opt_grad_steps": 52985.0, "train/actor_opt_loss": -5.991290912342568, "train/adv_mag": 0.06759727051636825, "train/adv_max": 0.00521298098222663, "train/adv_mean": 2.9023750375500867e-05, "train/adv_min": -0.06729020717709015, "train/adv_std": 0.002028608157161216, "train/cont_avg": 0.998504638671875, "train/cont_loss_mean": 0.0026001619056993754, "train/cont_loss_std": 0.06458256517104626, "train/cont_neg_acc": 0.7223356031641668, "train/cont_neg_loss": 1.5425400271335439, "train/cont_pos_acc": 0.9999592266976833, "train/cont_pos_loss": 0.0004489632560762402, "train/cont_pred": 0.9985017251844207, "train/cont_rate": 0.998504638671875, "train/dyn_loss_mean": 1.0000046417117119, "train/dyn_loss_std": 0.00012115324064628415, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.028321810558736615, "train/extr_critic_critic_opt_grad_steps": 52985.0, "train/extr_critic_critic_opt_loss": 13519.924641927084, "train/extr_critic_mag": 0.08291329070925713, "train/extr_critic_max": 0.08291329070925713, "train/extr_critic_mean": 0.07889547125281145, "train/extr_critic_min": 0.07363191557427247, "train/extr_critic_std": 0.0013969773299322696, "train/extr_return_normed_mag": 0.06554726526762049, "train/extr_return_normed_max": 0.00962767715100199, "train/extr_return_normed_mean": 0.0029791562859221208, "train/extr_return_normed_min": -0.06438274316800137, "train/extr_return_normed_std": 0.0025034766252550376, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08557304922336091, "train/extr_return_raw_max": 0.08557304922336091, "train/extr_return_raw_mean": 0.0789245319319889, "train/extr_return_raw_min": 0.011562628904357553, "train/extr_return_raw_std": 0.0025034766216170587, "train/extr_reward_mag": 0.001254548008243243, "train/extr_reward_max": 0.001254548008243243, "train/extr_reward_mean": 0.0002605070429429664, "train/extr_reward_min": 2.651164929072062e-06, "train/extr_reward_std": 0.00027343376564203936, "train/image_loss_mean": 0.10441201587673277, "train/image_loss_std": 0.12034831459944446, "train/model_loss_mean": 0.7168186012034615, "train/model_loss_std": 0.16070647782180458, "train/model_opt_grad_norm": 18.73806415994962, "train/model_opt_grad_steps": 52938.53125, "train/model_opt_loss": 3639.7169342041016, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5078.125, "train/policy_entropy_mag": 1.9413196338961523, "train/policy_entropy_max": 1.9413196338961523, "train/policy_entropy_mean": 1.7028389237821102, "train/policy_entropy_min": 0.664673558746775, "train/policy_entropy_std": 0.15086393019494912, "train/policy_logprob_mag": 4.285655764242013, "train/policy_logprob_max": -0.16299311319986978, "train/policy_logprob_mean": -1.7033949320514996, "train/policy_logprob_min": -4.285655764242013, "train/policy_logprob_std": 0.6916085574775934, "train/policy_randomness_mag": 0.9976410005862514, "train/policy_randomness_max": 0.9976410005862514, "train/policy_randomness_mean": 0.8750861519947648, "train/policy_randomness_min": 0.34157465926061076, "train/policy_randomness_std": 0.07752872817218304, "train/post_ent_mag": 30.8624485929807, "train/post_ent_max": 30.8624485929807, "train/post_ent_mean": 23.586311240990955, "train/post_ent_min": 16.95495144526164, "train/post_ent_std": 2.7265971365074315, "train/prior_ent_mag": 29.379726429780323, "train/prior_ent_max": 29.379726429780323, "train/prior_ent_mean": 23.164106637239456, "train/prior_ent_min": 16.96906119088332, "train/prior_ent_std": 2.4102925894161067, "train/rep_loss_mean": 1.0000046417117119, "train/rep_loss_std": 0.00012115324064628415, "train/reward_avg": 0.00022619065627319893, "train/reward_loss_mean": 0.00980361701658694, "train/reward_loss_std": 0.014144318702165037, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012223732968171437, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009803617028713537, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022492985832892978, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0059204394929111, "report/cont_loss_std": 0.17264243960380554, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.527421474456787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005230779061093926, "report/cont_pred": 0.9994755983352661, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1304096281528473, "report/image_loss_std": 0.1505068838596344, "report/model_loss_mean": 0.7460023164749146, "report/model_loss_std": 0.2370901107788086, "report/post_ent_mag": 29.946931838989258, "report/post_ent_max": 29.946931838989258, "report/post_ent_mean": 23.258230209350586, "report/post_ent_min": 17.398418426513672, "report/post_ent_std": 2.345679998397827, "report/prior_ent_mag": 29.74252700805664, "report/prior_ent_max": 29.74252700805664, "report/prior_ent_mean": 23.249347686767578, "report/prior_ent_min": 17.26438331604004, "report/prior_ent_std": 2.5438199043273926, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00022323051234707236, "report/reward_loss_mean": 0.009672235697507858, "report/reward_loss_std": 0.014475615695118904, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001175522804260254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009672235697507858, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020798121113330126, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01106654666364193, "eval/cont_loss_std": 0.30945977568626404, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.906299591064453, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013937863986939192, "eval/cont_pred": 0.9986330270767212, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.30154067277908325, "eval/image_loss_std": 0.14438378810882568, "eval/model_loss_mean": 0.9140357971191406, "eval/model_loss_std": 0.33997344970703125, "eval/post_ent_mag": 29.507431030273438, "eval/post_ent_max": 29.507431030273438, "eval/post_ent_mean": 22.779621124267578, "eval/post_ent_min": 16.30339813232422, "eval/post_ent_std": 2.342890501022339, "eval/prior_ent_mag": 29.749792098999023, "eval/prior_ent_max": 29.749792098999023, "eval/prior_ent_mean": 22.737844467163086, "eval/prior_ent_min": 16.987014770507812, "eval/prior_ent_std": 2.524510383605957, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014285747893154621, "eval/reward_loss_std": 0.0013867990346625447, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.002056598663330078, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014285747893154621, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022471928969025612, "eval/reward_rate": 0.0, "replay/size": 864225.0, "replay/inserts": 30864.0, "replay/samples": 30864.0, "replay/insert_wait_avg": 1.2985176221888074e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.656245996446544e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.035859295928844e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5944242477416992e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0611500740051, "timer/env.step_count": 3858.0, "timer/env.step_total": 33.53463912010193, "timer/env.step_frac": 0.03353258859982747, "timer/env.step_avg": 0.008692234090228597, "timer/env.step_min": 0.007250547409057617, "timer/env.step_max": 0.03547787666320801, "timer/replay._sample_count": 30864.0, "timer/replay._sample_total": 15.39428448677063, "timer/replay._sample_frac": 0.015393343182695822, "timer/replay._sample_avg": 0.0004987780095506296, "timer/replay._sample_min": 0.0004086494445800781, "timer/replay._sample_max": 0.0112457275390625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5781.0, "timer/agent.policy_total": 57.63280415534973, "timer/agent.policy_frac": 0.057629280120605496, "timer/agent.policy_avg": 0.009969348582485682, "timer/agent.policy_min": 0.008519172668457031, "timer/agent.policy_max": 0.09549641609191895, "timer/dataset_train_count": 1929.0, "timer/dataset_train_total": 0.20757412910461426, "timer/dataset_train_frac": 0.000207561436707399, "timer/dataset_train_avg": 0.00010760711721338219, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0004839897155761719, "timer/agent.train_count": 1929.0, "timer/agent.train_total": 854.9090900421143, "timer/agent.train_frac": 0.8548568154845836, "timer/agent.train_avg": 0.44318770867916757, "timer/agent.train_min": 0.43236470222473145, "timer/agent.train_max": 0.5879232883453369, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748256206512451, "timer/agent.report_frac": 0.0004747965868048246, "timer/agent.report_avg": 0.23741281032562256, "timer/agent.report_min": 0.23046112060546875, "timer/agent.report_max": 0.24436450004577637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.942054748535156e-05, "timer/dataset_eval_frac": 9.941446828325887e-08, "timer/dataset_eval_avg": 9.942054748535156e-05, "timer/dataset_eval_min": 9.942054748535156e-05, "timer/dataset_eval_max": 9.942054748535156e-05, "fps": 30.861564077724932}
{"step": 865512, "time": 28275.547711372375, "episode/length": 640.0, "episode/score": 0.18723683453663398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18723683453663398}
{"step": 867504, "time": 28337.927167892456, "episode/length": 640.0, "episode/score": 0.16229549892557316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16229549892557316}
{"step": 868376, "time": 28365.380752801895, "episode/length": 640.0, "episode/score": 0.14875413615231992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14875413615231992}
{"step": 869056, "time": 28386.704837560654, "episode/length": 640.0, "episode/score": 0.06381548470358211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06381548470358211}
{"step": 869208, "time": 28391.211652994156, "episode/length": 640.0, "episode/score": 0.13197452841711765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13197452841711765}
{"step": 869376, "time": 28396.72207903862, "episode/length": 640.0, "episode/score": 0.1253280328934352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1253280328934352}
{"step": 869488, "time": 28400.201704263687, "episode/length": 640.0, "episode/score": 0.06791285729752872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06791285729752872}
{"step": 869784, "time": 28409.178391218185, "episode/length": 640.0, "episode/score": 0.19625998414960577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19625998414960577}
{"step": 870064, "time": 28429.82395195961, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.83254814148, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.84035873413, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.84775185585, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.8549451828, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.8622610569, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.870078086853, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28429.877425670624, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870640, "time": 28447.73010659218, "episode/length": 640.0, "episode/score": 0.15421193520205634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15421193520205634}
{"step": 872632, "time": 28509.303686380386, "episode/length": 640.0, "episode/score": 0.17801919507860475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17801919507860475}
{"step": 873504, "time": 28536.618725061417, "episode/length": 640.0, "episode/score": 0.04766982101176609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04766982101176609}
{"step": 874184, "time": 28557.575110912323, "episode/length": 640.0, "episode/score": 0.14874416706868487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14874416706868487}
{"step": 874336, "time": 28562.51448249817, "episode/length": 640.0, "episode/score": 0.12379623060206768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12379623060206768}
{"step": 874504, "time": 28567.513432502747, "episode/length": 640.0, "episode/score": 0.04781377734587977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04781377734587977}
{"step": 874616, "time": 28570.979620695114, "episode/length": 640.0, "episode/score": 0.152047619023449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.152047619023449}
{"step": 874912, "time": 28580.452052354813, "episode/length": 640.0, "episode/score": 0.14093389246426113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14093389246426113}
{"step": 875768, "time": 28606.897620677948, "episode/length": 640.0, "episode/score": 0.07480013495626281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07480013495626281}
{"step": 877760, "time": 28669.825316905975, "episode/length": 640.0, "episode/score": 0.12697083835064404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12697083835064404}
{"step": 878632, "time": 28697.037979125977, "episode/length": 640.0, "episode/score": 0.15056556678206334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15056556678206334}
{"step": 879312, "time": 28718.772443532944, "episode/length": 640.0, "episode/score": 0.08160518834881714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08160518834881714}
{"step": 879464, "time": 28723.284616470337, "episode/length": 640.0, "episode/score": 0.16987950161217213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16987950161217213}
{"step": 879632, "time": 28728.849933624268, "episode/length": 640.0, "episode/score": 0.11826272269246374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11826272269246374}
{"step": 879744, "time": 28732.325273275375, "episode/length": 640.0, "episode/score": 0.175420504334852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.175420504334852}
{"step": 880040, "time": 28741.375370025635, "episode/length": 640.0, "episode/score": 0.08170336305829551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08170336305829551}
{"step": 880048, "time": 28752.836480379105, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.84503889084, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.85284590721, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.86034488678, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.867786884308, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.875072956085, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.882408618927, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 28752.88973379135, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880896, "time": 28779.474594831467, "episode/length": 640.0, "episode/score": 0.09681907102026344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09681907102026344}
{"step": 882888, "time": 28841.80835700035, "episode/length": 640.0, "episode/score": 0.08930383246996598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08930383246996598}
{"step": 883760, "time": 28869.249542474747, "episode/length": 640.0, "episode/score": 0.11181733390731097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11181733390731097}
{"step": 884440, "time": 28890.490666389465, "episode/length": 640.0, "episode/score": 0.22226327036577231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22226327036577231}
{"step": 884592, "time": 28895.55828332901, "episode/length": 640.0, "episode/score": 0.20560631838145582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20560631838145582}
{"step": 884760, "time": 28901.15202975273, "episode/length": 640.0, "episode/score": 0.1296307126162901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1296307126162901}
{"step": 884872, "time": 28904.635957479477, "episode/length": 640.0, "episode/score": 0.07328857923027954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07328857923027954}
{"step": 885168, "time": 28914.20022058487, "episode/length": 640.0, "episode/score": 0.20474676148381832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20474676148381832}
{"step": 886024, "time": 28940.682540655136, "episode/length": 640.0, "episode/score": 0.06338746521078065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06338746521078065}
{"step": 887144, "time": 28975.593967437744, "episode/length": 297.0, "episode/score": 0.1265188340395298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1265188340395298}
{"step": 888016, "time": 29003.083529233932, "episode/length": 640.0, "episode/score": 0.2397626224847329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2397626224847329}
{"step": 888888, "time": 29029.985594511032, "episode/length": 640.0, "episode/score": 0.15794415412906915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15794415412906915}
{"step": 889568, "time": 29051.43158841133, "episode/length": 640.0, "episode/score": 0.1999024018232376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1999024018232376}
{"step": 889720, "time": 29056.03224349022, "episode/length": 640.0, "episode/score": 0.239357640052134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.239357640052134}
{"step": 890000, "time": 29064.9398727417, "episode/length": 640.0, "episode/score": 0.2602664107315036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2602664107315036}
{"step": 890032, "time": 29077.67716693878, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.685537815094, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.693453788757, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.70127105713, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.70878624916, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.716767787933, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.72422504425, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29077.731382608414, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890296, "time": 29085.787509202957, "episode/length": 640.0, "episode/score": 0.10928454939633525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10928454939633525}
{"step": 891152, "time": 29112.91406440735, "episode/length": 640.0, "episode/score": 0.20094790190097456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20094790190097456}
{"step": 892272, "time": 29147.919114112854, "episode/length": 640.0, "episode/score": 0.1507839599313172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1507839599313172}
{"step": 893144, "time": 29175.21036338806, "episode/length": 640.0, "episode/score": 0.1689042569058472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1689042569058472}
{"step": 894016, "time": 29202.58017063141, "episode/length": 640.0, "episode/score": 0.12422295244169845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12422295244169845}
{"step": 894696, "time": 29223.54731297493, "episode/length": 640.0, "episode/score": 0.13356871143423632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13356871143423632}
{"step": 894848, "time": 29228.479686021805, "episode/length": 640.0, "episode/score": 0.2094576798278922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2094576798278922}
{"step": 895128, "time": 29236.995523929596, "episode/length": 640.0, "episode/score": 0.06906279804081805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06906279804081805}
{"step": 895424, "time": 29246.36731815338, "episode/length": 640.0, "episode/score": 0.21731944088026012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21731944088026012}
{"step": 895561, "time": 29251.34416937828, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2340530632691062, "train/action_min": 0.0, "train/action_std": 1.8355950512416621, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006727783696742854, "train/actor_opt_grad_steps": 54910.0, "train/actor_opt_loss": -6.259379074672343, "train/adv_mag": 0.06083245019529768, "train/adv_max": 0.005168446180425159, "train/adv_mean": 1.1773911754279054e-05, "train/adv_min": -0.06047463529004952, "train/adv_std": 0.001829062248616349, "train/cont_avg": 0.9984972069300518, "train/cont_loss_mean": 0.0028271277462568983, "train/cont_loss_std": 0.07177018448743618, "train/cont_neg_acc": 0.7363057349138199, "train/cont_neg_loss": 1.5466323736408105, "train/cont_pos_acc": 0.99993917454092, "train/cont_pos_loss": 0.0004769105105247672, "train/cont_pred": 0.9985106726384534, "train/cont_rate": 0.9984972069300518, "train/dyn_loss_mean": 1.0000051408234039, "train/dyn_loss_std": 0.00012256070118580844, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.028341656792492707, "train/extr_critic_critic_opt_grad_steps": 54910.0, "train/extr_critic_critic_opt_loss": 13530.249666045984, "train/extr_critic_mag": 0.08378659567067043, "train/extr_critic_max": 0.08378659567067043, "train/extr_critic_mean": 0.0797075016588127, "train/extr_critic_min": 0.07443107595097834, "train/extr_critic_std": 0.0014226654625299913, "train/extr_return_normed_mag": 0.05959340798731295, "train/extr_return_normed_max": 0.009617614506748674, "train/extr_return_normed_mean": 0.0029408852979926864, "train/extr_return_normed_min": -0.05788583466734911, "train/extr_return_normed_std": 0.0023558822350692333, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08639604277870198, "train/extr_return_raw_max": 0.08639604277870198, "train/extr_return_raw_mean": 0.07971931789359898, "train/extr_return_raw_min": 0.018892593604604196, "train/extr_return_raw_std": 0.00235588224291068, "train/extr_reward_mag": 0.0012612898732714084, "train/extr_reward_max": 0.0012612898732714084, "train/extr_reward_mean": 0.0002579134596400735, "train/extr_reward_min": 2.6133393994267122e-06, "train/extr_reward_std": 0.00027275345785244143, "train/image_loss_mean": 0.1043352806274755, "train/image_loss_std": 0.12048516889619086, "train/model_loss_mean": 0.7169845907181656, "train/model_loss_std": 0.16431544404573392, "train/model_opt_grad_norm": 17.766787499189377, "train/model_opt_grad_steps": 54861.637305699485, "train/model_opt_loss": 3640.4798134917423, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 5051.813471502591, "train/policy_entropy_mag": 1.9415333505739203, "train/policy_entropy_max": 1.9415333505739203, "train/policy_entropy_mean": 1.702051516641607, "train/policy_entropy_min": 0.632581459734724, "train/policy_entropy_std": 0.153605831642225, "train/policy_logprob_mag": 4.314376299863034, "train/policy_logprob_max": -0.15324113765065533, "train/policy_logprob_mean": -1.7017244038804207, "train/policy_logprob_min": -4.314376299863034, "train/policy_logprob_std": 0.6913733284708132, "train/policy_randomness_mag": 0.9977508298473655, "train/policy_randomness_max": 0.9977508298473655, "train/policy_randomness_mean": 0.8746815030438913, "train/policy_randomness_min": 0.32508258282211777, "train/policy_randomness_std": 0.07893778650099749, "train/post_ent_mag": 31.174809984592574, "train/post_ent_max": 31.174809984592574, "train/post_ent_mean": 23.933330773071923, "train/post_ent_min": 16.684991416535848, "train/post_ent_std": 2.8716148978070275, "train/prior_ent_mag": 29.98826621851155, "train/prior_ent_max": 29.98826621851155, "train/prior_ent_mean": 23.810876955022465, "train/prior_ent_min": 17.17186859605226, "train/prior_ent_std": 2.548112427014761, "train/rep_loss_mean": 1.0000051408234039, "train/rep_loss_std": 0.00012256070118580844, "train/reward_avg": 0.0002264337501985653, "train/reward_loss_mean": 0.009819071686831472, "train/reward_loss_std": 0.014147288962194957, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012251743998552232, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009819071674767707, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002244527335881878, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7115647345781326, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00028643652331084013, "report/cont_loss_std": 0.0017380425706505775, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009664417593739927, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002857718209270388, "report/cont_pred": 0.9987404346466064, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09316633641719818, "report/image_loss_std": 0.11597806215286255, "report/model_loss_mean": 0.7044756412506104, "report/model_loss_std": 0.11848092824220657, "report/post_ent_mag": 30.814260482788086, "report/post_ent_max": 30.814260482788086, "report/post_ent_mean": 24.100622177124023, "report/post_ent_min": 16.425092697143555, "report/post_ent_std": 2.971168041229248, "report/prior_ent_mag": 31.490903854370117, "report/prior_ent_max": 31.490903854370117, "report/prior_ent_mean": 23.830013275146484, "report/prior_ent_min": 15.086925506591797, "report/prior_ent_std": 3.21427059173584, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00025927776005119085, "report/reward_loss_mean": 0.011022815480828285, "report/reward_loss_std": 0.015129423700273037, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012339353561401367, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011022815480828285, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002546559553593397, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.010658792220056057, "eval/cont_loss_std": 0.3135673701763153, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.039106369018555, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0008558123372495174, "eval/cont_pred": 0.9991530776023865, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2971647381782532, "eval/image_loss_std": 0.15528734028339386, "eval/model_loss_mean": 0.9092470407485962, "eval/model_loss_std": 0.34648358821868896, "eval/post_ent_mag": 30.53396987915039, "eval/post_ent_max": 30.53396987915039, "eval/post_ent_mean": 22.835063934326172, "eval/post_ent_min": 16.31673240661621, "eval/post_ent_std": 2.982389450073242, "eval/prior_ent_mag": 31.46072769165039, "eval/prior_ent_max": 31.46072769165039, "eval/prior_ent_mean": 22.366262435913086, "eval/prior_ent_min": 15.023477554321289, "eval/prior_ent_std": 3.2456917762756348, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00142343295738101, "eval/reward_loss_std": 0.00137300172355026, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011665821075439453, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00142343295738101, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022391288075596094, "eval/reward_rate": 0.0, "replay/size": 895057.0, "replay/inserts": 30832.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.302076920240607e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.759139321786972e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0335346217956384e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0097563266754, "timer/env.step_count": 3854.0, "timer/env.step_total": 33.35561490058899, "timer/env.step_frac": 0.03335528947548851, "timer/env.step_avg": 0.008654804073842498, "timer/env.step_min": 0.007276058197021484, "timer/env.step_max": 0.0343470573425293, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 15.407661437988281, "timer/replay._sample_frac": 0.015407511117276566, "timer/replay._sample_avg": 0.0004997295484557694, "timer/replay._sample_min": 0.0003542900085449219, "timer/replay._sample_max": 0.01021122932434082, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5777.0, "timer/agent.policy_total": 57.546650409698486, "timer/agent.policy_frac": 0.05754608897125559, "timer/agent.policy_avg": 0.009961338135658384, "timer/agent.policy_min": 0.00857996940612793, "timer/agent.policy_max": 0.08574843406677246, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.20697689056396484, "timer/dataset_train_frac": 0.00020697487124950734, "timer/dataset_train_avg": 0.0001074088690005007, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0005044937133789062, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 854.9197061061859, "timer/agent.train_frac": 0.8549113653116274, "timer/agent.train_avg": 0.44365319465811415, "timer/agent.train_min": 0.43257665634155273, "timer/agent.train_max": 0.5892925262451172, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4719889163970947, "timer/agent.report_frac": 0.00047198431156396544, "timer/agent.report_avg": 0.23599445819854736, "timer/agent.report_min": 0.229461669921875, "timer/agent.report_max": 0.24252724647521973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2186194159686274e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 30.8311575338924}
{"step": 895720, "time": 29256.032250881195, "episode/length": 570.0, "episode/score": 0.18759671819373125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18759671819373125}
{"step": 897400, "time": 29308.703423023224, "episode/length": 640.0, "episode/score": 0.08958746648596616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08958746648596616}
{"step": 898272, "time": 29336.149826049805, "episode/length": 640.0, "episode/score": 0.20517336632212846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20517336632212846}
{"step": 899144, "time": 29363.530536413193, "episode/length": 640.0, "episode/score": 0.09681261324243451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09681261324243451}
{"step": 899824, "time": 29384.969745397568, "episode/length": 640.0, "episode/score": 0.23099276034270133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23099276034270133}
{"step": 899976, "time": 29389.581690311432, "episode/length": 640.0, "episode/score": 0.09010274431307153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09010274431307153}
{"step": 900016, "time": 29402.205923318863, "eval_episode/length": 597.0, "eval_episode/score": 0.16046875715255737, "eval_episode/reward_rate": 0.0016722408026755853}
{"step": 900016, "time": 29402.971894025803, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29402.98075246811, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29402.988885879517, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29402.996710777283, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29403.004530906677, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29403.01231265068, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29403.020775079727, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900256, "time": 29410.567965745926, "episode/length": 640.0, "episode/score": 0.19267506666545842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19267506666545842}
{"step": 900552, "time": 29419.686957597733, "episode/length": 640.0, "episode/score": 0.05346428739460407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05346428739460407}
{"step": 900848, "time": 29429.125257492065, "episode/length": 640.0, "episode/score": 0.24044345163974867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24044345163974867}
{"step": 901168, "time": 29439.565645456314, "episode/length": 470.0, "episode/score": 0.10900517124576936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10900517124576936}
{"step": 903400, "time": 29509.1635992527, "episode/length": 640.0, "episode/score": 0.039251092508436614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039251092508436614}
{"step": 904272, "time": 29536.632033348083, "episode/length": 640.0, "episode/score": 0.10441627344712856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10441627344712856}
{"step": 904952, "time": 29557.540644407272, "episode/length": 640.0, "episode/score": 0.20898165332795315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20898165332795315}
{"step": 905104, "time": 29562.501247644424, "episode/length": 640.0, "episode/score": 0.14770181163399343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14770181163399343}
{"step": 905384, "time": 29571.027458190918, "episode/length": 640.0, "episode/score": 0.060646457387946384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060646457387946384}
{"step": 905680, "time": 29580.441182613373, "episode/length": 640.0, "episode/score": 0.16974535036473526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16974535036473526}
{"step": 905976, "time": 29589.42182660103, "episode/length": 640.0, "episode/score": 0.04957189147600616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04957189147600616}
{"step": 906296, "time": 29599.424600601196, "episode/length": 640.0, "episode/score": 0.12369853600358738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12369853600358738}
{"step": 908528, "time": 29668.92113018036, "episode/length": 640.0, "episode/score": 0.14075909883240456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14075909883240456}
{"step": 909400, "time": 29696.300499916077, "episode/length": 640.0, "episode/score": 0.11377532011866265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11377532011866265}
{"step": 910000, "time": 29724.786430358887, "eval_episode/length": 560.0, "eval_episode/score": 0.21250000596046448, "eval_episode/reward_rate": 0.0017825311942959}
{"step": 910000, "time": 29726.16189813614, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 29726.170528173447, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 29726.17859864235, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 29726.186793088913, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 29726.194469690323, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 29726.20234298706, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 29726.209861516953, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910080, "time": 29728.71980404854, "episode/length": 640.0, "episode/score": 0.19813882168571695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19813882168571695}
{"step": 910232, "time": 29733.233001470566, "episode/length": 640.0, "episode/score": 0.11315249061360078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11315249061360078}
{"step": 910512, "time": 29742.143112897873, "episode/length": 640.0, "episode/score": 0.1529194281730497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1529194281730497}
{"step": 910808, "time": 29751.193667650223, "episode/length": 640.0, "episode/score": 0.18214989306991924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18214989306991924}
{"step": 911104, "time": 29760.58846092224, "episode/length": 640.0, "episode/score": 0.04969443362307402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04969443362307402}
{"step": 911424, "time": 29770.510174036026, "episode/length": 640.0, "episode/score": 0.07686080413981244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07686080413981244}
{"step": 913656, "time": 29840.27608537674, "episode/length": 640.0, "episode/score": 0.07231176773973402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07231176773973402}
{"step": 914528, "time": 29867.75611639023, "episode/length": 640.0, "episode/score": 0.024738307763243483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024738307763243483}
{"step": 915208, "time": 29888.659562587738, "episode/length": 640.0, "episode/score": 0.09246207581327326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09246207581327326}
{"step": 915360, "time": 29893.60173559189, "episode/length": 640.0, "episode/score": 0.1683287252892285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1683287252892285}
{"step": 915640, "time": 29902.209322452545, "episode/length": 640.0, "episode/score": 0.17044622095565387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17044622095565387}
{"step": 915936, "time": 29911.714231967926, "episode/length": 640.0, "episode/score": 0.09684137188068576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09684137188068576}
{"step": 916232, "time": 29920.68479657173, "episode/length": 640.0, "episode/score": 0.1377541664762134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1377541664762134}
{"step": 916552, "time": 29930.910170555115, "episode/length": 640.0, "episode/score": 0.1529497752790263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1529497752790263}
{"step": 918784, "time": 30001.26496887207, "episode/length": 640.0, "episode/score": 0.21775560229212942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21775560229212942}
{"step": 919656, "time": 30028.36859202385, "episode/length": 640.0, "episode/score": 0.2074733838354632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2074733838354632}
{"step": 920088, "time": 30053.743917942047, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.752333402634, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.75993156433, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.76734995842, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.774564266205, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.78156542778, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.7885055542, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30053.79554796219, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920336, "time": 30061.753084897995, "episode/length": 640.0, "episode/score": 0.07884585657029675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07884585657029675}
{"step": 920488, "time": 30066.23253917694, "episode/length": 640.0, "episode/score": 0.11464459371342173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11464459371342173}
{"step": 920768, "time": 30075.144877433777, "episode/length": 640.0, "episode/score": 0.17618711659775954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17618711659775954}
{"step": 921064, "time": 30084.217620372772, "episode/length": 640.0, "episode/score": 0.18359508637024646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18359508637024646}
{"step": 921360, "time": 30093.625324487686, "episode/length": 640.0, "episode/score": 0.17161067852430278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17161067852430278}
{"step": 921680, "time": 30103.695981025696, "episode/length": 640.0, "episode/score": 0.1510110094926631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1510110094926631}
{"step": 923912, "time": 30173.447917222977, "episode/length": 640.0, "episode/score": 0.18149995112185024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18149995112185024}
{"step": 924752, "time": 30199.916278362274, "episode/length": 551.0, "episode/score": 0.21042889295642908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21042889295642908}
{"step": 924784, "time": 30200.91789317131, "episode/length": 640.0, "episode/score": 0.14743820768615024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14743820768615024}
{"step": 925616, "time": 30227.00216293335, "episode/length": 640.0, "episode/score": 0.11597058233411417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11597058233411417}
{"step": 925896, "time": 30236.098241090775, "episode/length": 640.0, "episode/score": 0.18523232617599206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18523232617599206}
{"step": 926192, "time": 30245.480022192, "episode/length": 640.0, "episode/score": 0.07392913232564524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07392913232564524}
{"step": 926361, "time": 30251.435039043427, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2130721492470853, "train/action_min": 0.0, "train/action_std": 1.839008400477276, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007626719555969548, "train/actor_opt_grad_steps": 56840.0, "train/actor_opt_loss": -6.261903218654771, "train/adv_mag": 0.06802085034279008, "train/adv_max": 0.005224736899600745, "train/adv_mean": 1.3253328934073476e-05, "train/adv_min": -0.06777644817538829, "train/adv_std": 0.0020855833469272393, "train/cont_avg": 0.9983605893782384, "train/cont_loss_mean": 0.0027356819398073875, "train/cont_loss_std": 0.068238698621944, "train/cont_neg_acc": 0.7672877872582549, "train/cont_neg_loss": 1.201704134094917, "train/cont_pos_acc": 0.9999391930708613, "train/cont_pos_loss": 0.0004959302390243984, "train/cont_pred": 0.9983829825035648, "train/cont_rate": 0.9983605893782384, "train/dyn_loss_mean": 1.0000132099952104, "train/dyn_loss_std": 0.000325106409766803, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.028290265585703613, "train/extr_critic_critic_opt_grad_steps": 56840.0, "train/extr_critic_critic_opt_loss": 13525.54785662241, "train/extr_critic_mag": 0.084693060020091, "train/extr_critic_max": 0.084693060020091, "train/extr_critic_mean": 0.08029957490109409, "train/extr_critic_min": 0.07474225605090047, "train/extr_critic_std": 0.0015304951329590086, "train/extr_return_normed_mag": 0.06597915542712483, "train/extr_return_normed_max": 0.010147975130402363, "train/extr_return_normed_mean": 0.003131654123785312, "train/extr_return_normed_min": -0.06476699618786728, "train/extr_return_normed_std": 0.0026410313189232366, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08732910763105581, "train/extr_return_raw_max": 0.08732910763105581, "train/extr_return_raw_mean": 0.08031279014645464, "train/extr_return_raw_min": 0.01241413631278616, "train/extr_return_raw_std": 0.0026410312996212144, "train/extr_reward_mag": 0.001244592543093034, "train/extr_reward_max": 0.001244592543093034, "train/extr_reward_mean": 0.0002605121940437106, "train/extr_reward_min": 2.5089540629806914e-06, "train/extr_reward_std": 0.00027320920807910224, "train/image_loss_mean": 0.10341623359856827, "train/image_loss_std": 0.11883494856289631, "train/model_loss_mean": 0.715898639179882, "train/model_loss_std": 0.16032700186566368, "train/model_opt_grad_norm": 17.439630108176118, "train/model_opt_grad_steps": 56789.74093264249, "train/model_opt_loss": 3616.4266970935882, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5051.813471502591, "train/policy_entropy_mag": 1.9411818524098767, "train/policy_entropy_max": 1.9411818524098767, "train/policy_entropy_mean": 1.6916902658235224, "train/policy_entropy_min": 0.6004400608453109, "train/policy_entropy_std": 0.1597050236914442, "train/policy_logprob_mag": 4.384725868393103, "train/policy_logprob_max": -0.1411464839710473, "train/policy_logprob_mean": -1.6919588134696446, "train/policy_logprob_min": -4.384725868393103, "train/policy_logprob_std": 0.7037554565488984, "train/policy_randomness_mag": 0.9975701931844722, "train/policy_randomness_max": 0.9975701931844722, "train/policy_randomness_mean": 0.8693568752837305, "train/policy_randomness_min": 0.3085651697272464, "train/policy_randomness_std": 0.08207215164146275, "train/post_ent_mag": 32.470648810035826, "train/post_ent_max": 32.470648810035826, "train/post_ent_mean": 24.708960903740916, "train/post_ent_min": 16.05065544405132, "train/post_ent_std": 3.3169997603164436, "train/prior_ent_mag": 31.429316011735196, "train/prior_ent_max": 31.429316011735196, "train/prior_ent_mean": 24.250059503347764, "train/prior_ent_min": 16.45840229271607, "train/prior_ent_std": 2.9603299724005665, "train/rep_loss_mean": 1.0000132099952104, "train/rep_loss_std": 0.000325106409766803, "train/reward_avg": 0.0002245477365584407, "train/reward_loss_mean": 0.009738774815757658, "train/reward_loss_std": 0.014107341207370857, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012263374625092343, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009738774786804624, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022528017026618354, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7152363608280818, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0004483612719923258, "report/cont_loss_std": 0.002054227516055107, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03178451582789421, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00038703810423612595, "report/cont_pred": 0.9977220892906189, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10007339715957642, "report/image_loss_std": 0.12081842869520187, "report/model_loss_mean": 0.7128437757492065, "report/model_loss_std": 0.12382213771343231, "report/post_ent_mag": 33.46196746826172, "report/post_ent_max": 33.46196746826172, "report/post_ent_mean": 24.965486526489258, "report/post_ent_min": 15.048450469970703, "report/post_ent_std": 3.7106502056121826, "report/prior_ent_mag": 31.823827743530273, "report/prior_ent_max": 31.823827743530273, "report/prior_ent_mean": 24.917640686035156, "report/prior_ent_min": 16.520999908447266, "report/prior_ent_std": 3.0315611362457275, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00029337871819734573, "report/reward_loss_mean": 0.01232193224132061, "report/reward_loss_std": 0.01599966175854206, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012161731719970703, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01232193224132061, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00026885978877544403, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.018471447750926018, "eval/cont_loss_std": 0.38912928104400635, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.767794609069824, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001349486643448472, "eval/cont_pred": 0.9987360835075378, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3095446825027466, "eval/image_loss_std": 0.15908294916152954, "eval/model_loss_mean": 0.9294106960296631, "eval/model_loss_std": 0.4263983964920044, "eval/post_ent_mag": 32.94148635864258, "eval/post_ent_max": 32.94148635864258, "eval/post_ent_mean": 23.632272720336914, "eval/post_ent_min": 14.63474178314209, "eval/post_ent_std": 3.5924603939056396, "eval/prior_ent_mag": 31.84579086303711, "eval/prior_ent_max": 31.84579086303711, "eval/prior_ent_mean": 23.82912254333496, "eval/prior_ent_min": 16.09314727783203, "eval/prior_ent_std": 2.9704935550689697, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013945670798420906, "eval/reward_loss_std": 0.0014396428596228361, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011824369430541992, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013945670798420906, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000219360226765275, "eval/reward_rate": 0.0, "replay/size": 925857.0, "replay/inserts": 30800.0, "replay/samples": 30800.0, "replay/insert_wait_avg": 1.3025472690532734e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.618254451008587e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0649797139041322e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0692327022552, "timer/env.step_count": 3850.0, "timer/env.step_total": 33.35091471672058, "timer/env.step_frac": 0.0333486059026175, "timer/env.step_avg": 0.008662575251096255, "timer/env.step_min": 0.007314443588256836, "timer/env.step_max": 0.03425145149230957, "timer/replay._sample_count": 30800.0, "timer/replay._sample_total": 15.45581865310669, "timer/replay._sample_frac": 0.01545474867909296, "timer/replay._sample_avg": 0.0005018122939320354, "timer/replay._sample_min": 0.00036978721618652344, "timer/replay._sample_max": 0.03460097312927246, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5773.0, "timer/agent.policy_total": 57.778136253356934, "timer/agent.policy_frac": 0.05777413639377393, "timer/agent.policy_avg": 0.010008338169644368, "timer/agent.policy_min": 0.008560419082641602, "timer/agent.policy_max": 0.08864426612854004, "timer/dataset_train_count": 1925.0, "timer/dataset_train_total": 0.20815443992614746, "timer/dataset_train_frac": 0.00020814002982943487, "timer/dataset_train_avg": 0.00010813217658501167, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0003147125244140625, "timer/agent.train_count": 1925.0, "timer/agent.train_total": 854.9456684589386, "timer/agent.train_frac": 0.8548864823576435, "timer/agent.train_avg": 0.4441276199786694, "timer/agent.train_min": 0.4322171211242676, "timer/agent.train_max": 0.6026103496551514, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4773294925689697, "timer/agent.report_frac": 0.0004772964480460947, "timer/agent.report_avg": 0.23866474628448486, "timer/agent.report_min": 0.23205280303955078, "timer/agent.report_max": 0.24527668952941895, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 3.88595380427276e-08, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05, "fps": 30.79720022782429}
{"step": 926488, "time": 30255.172321796417, "episode/length": 640.0, "episode/score": 0.18307468787827474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18307468787827474}
{"step": 926808, "time": 30265.21999692917, "episode/length": 640.0, "episode/score": 0.1953564129369738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1953564129369738}
{"step": 927456, "time": 30285.719176054, "episode/length": 333.0, "episode/score": 0.06120931729901713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06120931729901713}
{"step": 929040, "time": 30334.858319997787, "episode/length": 640.0, "episode/score": 0.17596755225704896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17596755225704896}
{"step": 929880, "time": 30360.962204694748, "episode/length": 640.0, "episode/score": 0.036222449159964754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036222449159964754}
{"step": 930072, "time": 30376.43157029152, "eval_episode/length": 538.0, "eval_episode/score": 0.2434374988079071, "eval_episode/reward_rate": 0.0018552875695732839}
{"step": 930072, "time": 30378.788231134415, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30378.796776771545, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30378.80442214012, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30378.811945199966, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30378.81925868988, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30378.826474666595, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30378.833528757095, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930744, "time": 30399.730511665344, "episode/length": 640.0, "episode/score": 0.04248184070010552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04248184070010552}
{"step": 931024, "time": 30408.751987218857, "episode/length": 640.0, "episode/score": 0.11429529662510163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11429529662510163}
{"step": 931320, "time": 30417.739014863968, "episode/length": 640.0, "episode/score": 0.10582361775851723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10582361775851723}
{"step": 931616, "time": 30427.30468559265, "episode/length": 640.0, "episode/score": 0.11498159261782348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11498159261782348}
{"step": 931936, "time": 30437.383498191833, "episode/length": 640.0, "episode/score": 0.1143236478259837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1143236478259837}
{"step": 932584, "time": 30457.310081481934, "episode/length": 640.0, "episode/score": 0.14010899210700245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14010899210700245}
{"step": 934168, "time": 30507.206558704376, "episode/length": 640.0, "episode/score": 0.041843805182679716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041843805182679716}
{"step": 935008, "time": 30533.780697107315, "episode/length": 640.0, "episode/score": 0.043648778244886444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043648778244886444}
{"step": 935872, "time": 30561.045764684677, "episode/length": 640.0, "episode/score": 0.09304559880945362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09304559880945362}
{"step": 936152, "time": 30569.671638727188, "episode/length": 640.0, "episode/score": 0.15243422897097503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15243422897097503}
{"step": 936448, "time": 30579.118622779846, "episode/length": 640.0, "episode/score": 0.17115792160967658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17115792160967658}
{"step": 936744, "time": 30588.206555843353, "episode/length": 640.0, "episode/score": 0.06738936516953231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06738936516953231}
{"step": 937064, "time": 30598.13554096222, "episode/length": 640.0, "episode/score": 0.058307725292849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058307725292849}
{"step": 937712, "time": 30618.609057426453, "episode/length": 640.0, "episode/score": 0.25637902566788284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25637902566788284}
{"step": 939296, "time": 30668.024235248566, "episode/length": 640.0, "episode/score": 0.142835469305723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.142835469305723}
{"step": 940056, "time": 30702.388382196426, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.396995782852, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.40499472618, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.412479162216, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.42011642456, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.427640914917, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.43524622917, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 30702.44274520874, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940136, "time": 30704.94147348404, "episode/length": 640.0, "episode/score": 0.19024031834554478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19024031834554478}
{"step": 941000, "time": 30731.883363485336, "episode/length": 640.0, "episode/score": 0.04812370113062059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04812370113062059}
{"step": 941280, "time": 30741.012243270874, "episode/length": 640.0, "episode/score": 0.10283552017381226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10283552017381226}
{"step": 941576, "time": 30750.043576478958, "episode/length": 640.0, "episode/score": 0.04202643937321682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04202643937321682}
{"step": 941872, "time": 30759.455743312836, "episode/length": 640.0, "episode/score": 0.2114351912855028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2114351912855028}
{"step": 942192, "time": 30769.957262277603, "episode/length": 640.0, "episode/score": 0.16634215989316203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16634215989316203}
{"step": 942840, "time": 30789.83253121376, "episode/length": 640.0, "episode/score": 0.14388487536152184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14388487536152184}
{"step": 944424, "time": 30839.39753842354, "episode/length": 640.0, "episode/score": 0.12003101936137739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12003101936137739}
{"step": 945264, "time": 30865.929998636246, "episode/length": 640.0, "episode/score": 0.1881521078772863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1881521078772863}
{"step": 946128, "time": 30892.9025118351, "episode/length": 640.0, "episode/score": 0.14410488232643104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14410488232643104}
{"step": 946408, "time": 30901.39990210533, "episode/length": 640.0, "episode/score": 0.11123500077346193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11123500077346193}
{"step": 946704, "time": 30910.82976436615, "episode/length": 640.0, "episode/score": 0.17270297469011098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17270297469011098}
{"step": 947000, "time": 30919.92864227295, "episode/length": 640.0, "episode/score": 0.11325559941124652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11325559941124652}
{"step": 947320, "time": 30929.833593845367, "episode/length": 640.0, "episode/score": 0.10481116097983545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10481116097983545}
{"step": 947968, "time": 30950.236186742783, "episode/length": 640.0, "episode/score": 0.11802260577719892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11802260577719892}
{"step": 949552, "time": 30999.518478393555, "episode/length": 640.0, "episode/score": 0.15493134388765384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15493134388765384}
{"step": 950040, "time": 31026.09369134903, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.102257966995, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.110062122345, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.117611408234, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.12478685379, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.13197374344, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.13912463188, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31026.14637184143, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950392, "time": 31037.67291355133, "episode/length": 640.0, "episode/score": 0.10751581696484891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10751581696484891}
{"step": 951256, "time": 31064.658103466034, "episode/length": 640.0, "episode/score": 0.03855458619574392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03855458619574392}
{"step": 951536, "time": 31073.82060265541, "episode/length": 640.0, "episode/score": 0.0293644287440884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0293644287440884}
{"step": 951832, "time": 31082.947749853134, "episode/length": 640.0, "episode/score": 0.07147643440089269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07147643440089269}
{"step": 952128, "time": 31092.39050579071, "episode/length": 640.0, "episode/score": 0.20602116351591349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20602116351591349}
{"step": 952448, "time": 31102.503069400787, "episode/length": 640.0, "episode/score": 0.22489532024309256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22489532024309256}
{"step": 953096, "time": 31122.544516801834, "episode/length": 640.0, "episode/score": 0.040849723316853215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040849723316853215}
{"step": 954344, "time": 31161.694578170776, "episode/length": 598.0, "episode/score": 0.122856991244646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.122856991244646}
{"step": 955520, "time": 31198.435588121414, "episode/length": 640.0, "episode/score": 0.1281864674755866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1281864674755866}
{"step": 956384, "time": 31225.348728895187, "episode/length": 640.0, "episode/score": 0.0964413000013451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0964413000013451}
{"step": 956664, "time": 31233.845155239105, "episode/length": 640.0, "episode/score": 0.023700991335147137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023700991335147137}
{"step": 956960, "time": 31243.264083862305, "episode/length": 640.0, "episode/score": 0.10535187087731401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10535187087731401}
{"step": 957209, "time": 31251.834030389786, "train_stats/mean_log_entropy": 1.7206094016631444, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.221137364705404, "train/action_min": 0.0, "train/action_std": 1.8461421032746632, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007542803759861272, "train/actor_opt_grad_steps": 58765.0, "train/actor_opt_loss": -6.957691458791184, "train/adv_mag": 0.06629760039504617, "train/adv_max": 0.005517976242117584, "train/adv_mean": -2.641900019136519e-05, "train/adv_min": -0.06596258748322725, "train/adv_std": 0.002052938364310345, "train/cont_avg": 0.9984944661458334, "train/cont_loss_mean": 0.0026543854357896635, "train/cont_loss_std": 0.06528018203774384, "train/cont_neg_acc": 0.7413288306545567, "train/cont_neg_loss": 1.4223976536805403, "train/cont_pos_acc": 0.9999694190919399, "train/cont_pos_loss": 0.0004640026885833019, "train/cont_pred": 0.9984795780231556, "train/cont_rate": 0.9984944661458334, "train/dyn_loss_mean": 1.0000041499733925, "train/dyn_loss_std": 0.00011892100413509372, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02737829012949078, "train/extr_critic_critic_opt_grad_steps": 58765.0, "train/extr_critic_critic_opt_loss": 13527.605484008789, "train/extr_critic_mag": 0.08491230507691701, "train/extr_critic_max": 0.08491230507691701, "train/extr_critic_mean": 0.07997381194339444, "train/extr_critic_min": 0.0740293599665165, "train/extr_critic_std": 0.0016858963893658558, "train/extr_return_normed_mag": 0.06413857960918297, "train/extr_return_normed_max": 0.010782422303843001, "train/extr_return_normed_mean": 0.003353891802059176, "train/extr_return_normed_min": -0.06266805913764983, "train/extr_return_normed_std": 0.002700177922937049, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08737599182253082, "train/extr_return_raw_max": 0.08737599182253082, "train/extr_return_raw_mean": 0.07994746537103008, "train/extr_return_raw_min": 0.01392551038103799, "train/extr_return_raw_std": 0.002700177908385134, "train/extr_reward_mag": 0.0012567142645517986, "train/extr_reward_max": 0.0012567142645517986, "train/extr_reward_mean": 0.0002587749605330221, "train/extr_reward_min": 2.417092521985372e-06, "train/extr_reward_std": 0.0002712303677678089, "train/image_loss_mean": 0.1054088919578741, "train/image_loss_std": 0.12150221069653828, "train/model_loss_mean": 0.7177020398279031, "train/model_loss_std": 0.1614543345834439, "train/model_opt_grad_norm": 17.94042673955361, "train/model_opt_grad_steps": 58712.875, "train/model_opt_loss": 3700.7680117289224, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5156.25, "train/policy_entropy_mag": 1.9414833188056946, "train/policy_entropy_max": 1.9414833188056946, "train/policy_entropy_mean": 1.685186921308438, "train/policy_entropy_min": 0.58255271660164, "train/policy_entropy_std": 0.16542022201853493, "train/policy_logprob_mag": 4.424736466258764, "train/policy_logprob_max": -0.13550511980429292, "train/policy_logprob_mean": -1.6850774517903726, "train/policy_logprob_min": -4.424736466258764, "train/policy_logprob_std": 0.7121659542123476, "train/policy_randomness_mag": 0.9977251173307499, "train/policy_randomness_max": 0.9977251173307499, "train/policy_randomness_mean": 0.8660148161773881, "train/policy_randomness_min": 0.29937289267157513, "train/policy_randomness_std": 0.08500918319138388, "train/post_ent_mag": 33.47244648138682, "train/post_ent_max": 33.47244648138682, "train/post_ent_mean": 24.921908636887867, "train/post_ent_min": 15.369028394420942, "train/post_ent_std": 3.695301881680886, "train/prior_ent_mag": 32.12252985437711, "train/prior_ent_max": 32.12252985437711, "train/prior_ent_mean": 24.65177696943283, "train/prior_ent_min": 16.20761793355147, "train/prior_ent_std": 3.323535537968079, "train/rep_loss_mean": 1.0000041499733925, "train/rep_loss_std": 0.00011892100413509372, "train/reward_avg": 0.0002216544662587694, "train/reward_loss_mean": 0.009636247513602333, "train/reward_loss_std": 0.01394875141462156, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012288608898719151, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009636247482073182, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022378160368437724, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00015499307482969016, "report/cont_loss_std": 0.001035109511576593, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.028516823425889015, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0001272688969038427, "report/cont_pred": 0.9989238977432251, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07238803803920746, "report/image_loss_std": 0.10231994837522507, "report/model_loss_mean": 0.6818690299987793, "report/model_loss_std": 0.10516408830881119, "report/post_ent_mag": 34.49189758300781, "report/post_ent_max": 34.49189758300781, "report/post_ent_mean": 26.82150650024414, "report/post_ent_min": 16.778364181518555, "report/post_ent_std": 3.544891357421875, "report/prior_ent_mag": 32.01637268066406, "report/prior_ent_max": 32.01637268066406, "report/prior_ent_mean": 25.490478515625, "report/prior_ent_min": 17.820838928222656, "report/prior_ent_std": 3.0440897941589355, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021921118604950607, "report/reward_loss_mean": 0.009325958788394928, "report/reward_loss_std": 0.013965633697807789, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012766122817993164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009325958788394928, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00022475561127066612, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0003224764368496835, "eval/cont_loss_std": 0.00181914574932307, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003224764368496835, "eval/cont_pred": 0.9996792078018188, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3294314742088318, "eval/image_loss_std": 0.1625417023897171, "eval/model_loss_mean": 0.9311952590942383, "eval/model_loss_std": 0.16260692477226257, "eval/post_ent_mag": 34.4537467956543, "eval/post_ent_max": 34.4537467956543, "eval/post_ent_mean": 24.864675521850586, "eval/post_ent_min": 17.34065055847168, "eval/post_ent_std": 3.338181734085083, "eval/prior_ent_mag": 31.853126525878906, "eval/prior_ent_max": 31.853126525878906, "eval/prior_ent_mean": 23.88058090209961, "eval/prior_ent_min": 17.560644149780273, "eval/prior_ent_std": 2.8724875450134277, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014412757009267807, "eval/reward_loss_std": 0.0014137233374640346, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011101961135864258, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014412757009267807, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022671243641525507, "eval/reward_rate": 0.0, "replay/size": 956705.0, "replay/inserts": 30848.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.308117912023394e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.641159495872085e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0235850165055187e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3825318813324, "timer/env.step_count": 3856.0, "timer/env.step_total": 33.423086643218994, "timer/env.step_frac": 0.03341030613595691, "timer/env.step_avg": 0.008667812926146004, "timer/env.step_min": 0.007260322570800781, "timer/env.step_max": 0.03535270690917969, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.420233488082886, "timer/replay._sample_frac": 0.015414337012745909, "timer/replay._sample_avg": 0.0004998779009362968, "timer/replay._sample_min": 0.000415802001953125, "timer/replay._sample_max": 0.008749246597290039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5779.0, "timer/agent.policy_total": 57.60619497299194, "timer/agent.policy_frac": 0.057584167193180574, "timer/agent.policy_avg": 0.009968194319604074, "timer/agent.policy_min": 0.00850367546081543, "timer/agent.policy_max": 0.08962154388427734, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.21086764335632324, "timer/dataset_train_frac": 0.00021078701060459623, "timer/dataset_train_avg": 0.00010937118431344567, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010826587677001953, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 855.1796073913574, "timer/agent.train_frac": 0.8548525990183931, "timer/agent.train_avg": 0.443557887651119, "timer/agent.train_min": 0.43170905113220215, "timer/agent.train_max": 0.5771868228912354, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4796600341796875, "timer/agent.report_frac": 0.00047947661908653345, "timer/agent.report_avg": 0.23983001708984375, "timer/agent.report_min": 0.23331546783447266, "timer/agent.report_max": 0.24634456634521484, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.4795802045209304e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 30.835667031514554}
{"step": 957256, "time": 31253.097507953644, "episode/length": 640.0, "episode/score": 0.11137430620595978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11137430620595978}
{"step": 957576, "time": 31263.039124011993, "episode/length": 640.0, "episode/score": 0.15352468634313254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15352468634313254}
{"step": 958224, "time": 31283.466914892197, "episode/length": 640.0, "episode/score": 0.15045552083847724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15045552083847724}
{"step": 959472, "time": 31322.778913497925, "episode/length": 640.0, "episode/score": 0.12314230732943088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12314230732943088}
{"step": 960024, "time": 31350.815891981125, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.8246178627, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.832182645798, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.839560508728, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.846888780594, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.854572296143, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.861773490906, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31350.868822336197, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960648, "time": 31372.588714838028, "episode/length": 640.0, "episode/score": 0.1463993785272919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1463993785272919}
{"step": 961512, "time": 31399.397308826447, "episode/length": 640.0, "episode/score": 0.1431482378770852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1431482378770852}
{"step": 961576, "time": 31401.398443222046, "episode/length": 613.0, "episode/score": 0.1764185266072218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1764185266072218}
{"step": 962088, "time": 31417.232508420944, "episode/length": 640.0, "episode/score": 0.16037255983354726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16037255983354726}
{"step": 962384, "time": 31426.873923778534, "episode/length": 640.0, "episode/score": 0.07091800042366003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07091800042366003}
{"step": 962704, "time": 31436.842411518097, "episode/length": 640.0, "episode/score": 0.15205663694030136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15205663694030136}
{"step": 963352, "time": 31456.783703804016, "episode/length": 640.0, "episode/score": 0.16073204603901559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16073204603901559}
{"step": 964600, "time": 31495.669981956482, "episode/length": 640.0, "episode/score": 0.13161644880551648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13161644880551648}
{"step": 965776, "time": 31532.608739852905, "episode/length": 640.0, "episode/score": 0.15629588238550696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15629588238550696}
{"step": 966640, "time": 31559.429852485657, "episode/length": 640.0, "episode/score": 0.2305478567661794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2305478567661794}
{"step": 966704, "time": 31561.911682367325, "episode/length": 640.0, "episode/score": 0.1751138965811947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1751138965811947}
{"step": 967216, "time": 31578.030921936035, "episode/length": 640.0, "episode/score": 0.22385328300970286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22385328300970286}
{"step": 967512, "time": 31587.159516096115, "episode/length": 640.0, "episode/score": 0.18725551515632333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18725551515632333}
{"step": 967832, "time": 31597.27876329422, "episode/length": 640.0, "episode/score": 0.24807147485205405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24807147485205405}
{"step": 968480, "time": 31617.64952659607, "episode/length": 640.0, "episode/score": 0.15349521178887926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15349521178887926}
{"step": 969728, "time": 31656.36488175392, "episode/length": 640.0, "episode/score": 0.14355920811561873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14355920811561873}
{"step": 970008, "time": 31676.80959033966, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.81808233261, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.827204227448, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.835021972656, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.842448711395, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.849602222443, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.856803655624, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 31676.864111185074, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970904, "time": 31704.734581947327, "episode/length": 640.0, "episode/score": 0.10959043470757024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10959043470757024}
{"step": 971768, "time": 31731.741190195084, "episode/length": 640.0, "episode/score": 0.19570700538258734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19570700538258734}
{"step": 971832, "time": 31733.767789125443, "episode/length": 640.0, "episode/score": 0.11579542991893277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11579542991893277}
{"step": 972344, "time": 31749.67336320877, "episode/length": 640.0, "episode/score": 0.15447922338074704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15447922338074704}
{"step": 972640, "time": 31759.20918416977, "episode/length": 640.0, "episode/score": 0.2414023971740562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2414023971740562}
{"step": 972960, "time": 31769.14216542244, "episode/length": 640.0, "episode/score": 0.2242985994822675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2242985994822675}
{"step": 973608, "time": 31789.32869887352, "episode/length": 640.0, "episode/score": 0.18883310677063037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18883310677063037}
{"step": 974856, "time": 31828.632872343063, "episode/length": 640.0, "episode/score": 0.1846984993062506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846984993062506}
{"step": 976032, "time": 31865.576302289963, "episode/length": 640.0, "episode/score": 0.07352269259166633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07352269259166633}
{"step": 976896, "time": 31892.66247534752, "episode/length": 640.0, "episode/score": 0.23834274163692726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23834274163692726}
{"step": 976960, "time": 31894.685998678207, "episode/length": 640.0, "episode/score": 0.15008752732001085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15008752732001085}
{"step": 977472, "time": 31910.68131685257, "episode/length": 640.0, "episode/score": 0.12907473644298761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12907473644298761}
{"step": 977768, "time": 31919.776492595673, "episode/length": 640.0, "episode/score": 0.13055341681058508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13055341681058508}
{"step": 978088, "time": 31929.689725875854, "episode/length": 640.0, "episode/score": 0.195656445893178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.195656445893178}
{"step": 978736, "time": 31950.108098745346, "episode/length": 640.0, "episode/score": 0.16998044873463414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16998044873463414}
{"step": 979984, "time": 31988.820579767227, "episode/length": 640.0, "episode/score": 0.21074686942321819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21074686942321819}
{"step": 980096, "time": 32003.840448379517, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.849420547485, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.85710120201, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.86463022232, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.87183713913, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.878832101822, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.885822296143, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32003.892869710922, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 981160, "time": 32036.78194975853, "episode/length": 640.0, "episode/score": 0.19642556972925718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19642556972925718}
{"step": 982024, "time": 32063.75498318672, "episode/length": 640.0, "episode/score": 0.18631810604424004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18631810604424004}
{"step": 982088, "time": 32065.762530088425, "episode/length": 640.0, "episode/score": 0.06389024343820893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06389024343820893}
{"step": 982600, "time": 32081.647493124008, "episode/length": 640.0, "episode/score": 0.24390712383663526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24390712383663526}
{"step": 982896, "time": 32091.20958662033, "episode/length": 640.0, "episode/score": 0.23276596520616977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23276596520616977}
{"step": 983216, "time": 32101.64733862877, "episode/length": 640.0, "episode/score": 0.21578407940071997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21578407940071997}
{"step": 983864, "time": 32121.615888357162, "episode/length": 640.0, "episode/score": 0.15536985913837498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15536985913837498}
{"step": 985112, "time": 32160.451923131943, "episode/length": 640.0, "episode/score": 0.1187969221004721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1187969221004721}
{"step": 986288, "time": 32197.209483861923, "episode/length": 640.0, "episode/score": 0.18632021760097928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18632021760097928}
{"step": 987152, "time": 32224.17296743393, "episode/length": 640.0, "episode/score": 0.08235923262540723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08235923262540723}
{"step": 987216, "time": 32226.156243801117, "episode/length": 640.0, "episode/score": 0.18352955854211928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18352955854211928}
{"step": 987728, "time": 32242.165451288223, "episode/length": 640.0, "episode/score": 0.1592560140414605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1592560140414605}
{"step": 988024, "time": 32251.149884939194, "episode/length": 640.0, "episode/score": 0.06638236679762599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06638236679762599}
{"step": 988025, "time": 32252.15689086914, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.220230339722312, "train/action_min": 0.0, "train/action_std": 1.8597685055411541, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007845137807856666, "train/actor_opt_grad_steps": 60690.0, "train/actor_opt_loss": -6.756309587720763, "train/adv_mag": 0.06725074817942832, "train/adv_max": 0.005561775725740225, "train/adv_mean": -1.545974420340534e-05, "train/adv_min": -0.06702226763253386, "train/adv_std": 0.002078183402772993, "train/cont_avg": 0.9985680456606217, "train/cont_loss_mean": 0.0023293213274449332, "train/cont_loss_std": 0.05829424758163073, "train/cont_neg_acc": 0.7558498917431231, "train/cont_neg_loss": 1.3485175443430903, "train/cont_pos_acc": 0.9999493147425084, "train/cont_pos_loss": 0.00043278104092423934, "train/cont_pred": 0.998536758781097, "train/cont_rate": 0.9985680456606217, "train/dyn_loss_mean": 1.000005097586874, "train/dyn_loss_std": 0.00013791685191060326, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.027348596141540924, "train/extr_critic_critic_opt_grad_steps": 60690.0, "train/extr_critic_critic_opt_loss": 13522.907039345855, "train/extr_critic_mag": 0.08444789592466206, "train/extr_critic_max": 0.08444789592466206, "train/extr_critic_mean": 0.07924570143222809, "train/extr_critic_min": 0.07305821235933452, "train/extr_critic_std": 0.0017890450671324844, "train/extr_return_normed_mag": 0.06486156868502266, "train/extr_return_normed_max": 0.011256674333557563, "train/extr_return_normed_mean": 0.003558263567474145, "train/extr_return_normed_min": -0.0635284601561146, "train/extr_return_normed_std": 0.0027816395753019834, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08692868605950954, "train/extr_return_raw_max": 0.08692868605950954, "train/extr_return_raw_mean": 0.07923027903922482, "train/extr_return_raw_min": 0.012143551569837362, "train/extr_return_raw_std": 0.0027816395668573486, "train/extr_reward_mag": 0.001254273819799868, "train/extr_reward_max": 0.001254273819799868, "train/extr_reward_mean": 0.000257715174413788, "train/extr_reward_min": 2.502777415853708e-06, "train/extr_reward_std": 0.00027152192783409275, "train/image_loss_mean": 0.10463901813783794, "train/image_loss_std": 0.12226370776101098, "train/model_loss_mean": 0.7166738346450687, "train/model_loss_std": 0.15822072327136993, "train/model_opt_grad_norm": 17.409933579400413, "train/model_opt_grad_steps": 60635.974093264245, "train/model_opt_loss": 3601.9078843507123, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.906735751295, "train/policy_entropy_mag": 1.9416221448176882, "train/policy_entropy_max": 1.9416221448176882, "train/policy_entropy_mean": 1.6781066810528849, "train/policy_entropy_min": 0.5586084721928434, "train/policy_entropy_std": 0.17284592206305172, "train/policy_logprob_mag": 4.4946508864664665, "train/policy_logprob_max": -0.12773931267734018, "train/policy_logprob_mean": -1.678557055601802, "train/policy_logprob_min": -4.4946508864664665, "train/policy_logprob_std": 0.7196170002067644, "train/policy_randomness_mag": 0.9977964604456808, "train/policy_randomness_max": 0.9977964604456808, "train/policy_randomness_mean": 0.8623762946054725, "train/policy_randomness_min": 0.2870679852876021, "train/policy_randomness_std": 0.08882523783593597, "train/post_ent_mag": 33.32248086879908, "train/post_ent_max": 33.32248086879908, "train/post_ent_mean": 25.05436129397061, "train/post_ent_min": 14.692944976332274, "train/post_ent_std": 3.905282587585054, "train/prior_ent_mag": 33.10793066271846, "train/prior_ent_max": 33.10793066271846, "train/prior_ent_mean": 24.880685074959395, "train/prior_ent_min": 15.722609885616006, "train/prior_ent_std": 3.6141422980807607, "train/rep_loss_mean": 1.000005097586874, "train/rep_loss_std": 0.00013791685191060326, "train/reward_avg": 0.00022328605987264298, "train/reward_loss_mean": 0.009702414476886932, "train/reward_loss_std": 0.013996552647009415, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012290551872451072, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009702414426219124, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022320870980813406, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7126719781330653, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00687692454084754, "report/cont_loss_std": 0.2094004601240158, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 2.234943389892578, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003302055993117392, "report/cont_pred": 0.9977173805236816, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11404728889465332, "report/image_loss_std": 0.12954992055892944, "report/model_loss_mean": 0.7311306595802307, "report/model_loss_std": 0.2597901225090027, "report/post_ent_mag": 32.238677978515625, "report/post_ent_max": 32.238677978515625, "report/post_ent_mean": 23.68433952331543, "report/post_ent_min": 12.981771469116211, "report/post_ent_std": 4.25801944732666, "report/prior_ent_mag": 34.388153076171875, "report/prior_ent_max": 34.388153076171875, "report/prior_ent_mean": 23.789859771728516, "report/prior_ent_min": 13.40242862701416, "report/prior_ent_std": 4.278419494628906, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023902833345346153, "report/reward_loss_mean": 0.010206413455307484, "report/reward_loss_std": 0.015373597852885723, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0014891624450683594, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010206413455307484, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00024084176402539015, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.020453736186027527, "eval/cont_loss_std": 0.4481659233570099, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.128955841064453, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006719303783029318, "eval/cont_pred": 0.9993376731872559, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3000982105731964, "eval/image_loss_std": 0.15567505359649658, "eval/model_loss_mean": 0.9221724271774292, "eval/model_loss_std": 0.4722818434238434, "eval/post_ent_mag": 32.837982177734375, "eval/post_ent_max": 32.837982177734375, "eval/post_ent_mean": 22.985267639160156, "eval/post_ent_min": 13.576684951782227, "eval/post_ent_std": 3.9594380855560303, "eval/prior_ent_mag": 34.267459869384766, "eval/prior_ent_max": 34.267459869384766, "eval/prior_ent_mean": 23.194406509399414, "eval/prior_ent_min": 14.712202072143555, "eval/prior_ent_std": 4.057377338409424, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016204426065087318, "eval/reward_loss_std": 0.001594768138602376, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011563301086425781, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016204426065087318, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025485281366854906, "eval/reward_rate": 0.0, "replay/size": 987521.0, "replay/inserts": 30816.0, "replay/samples": 30816.0, "replay/insert_wait_avg": 1.2946757076932881e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.501231050936975e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0341545348978266e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3032476902008, "timer/env.step_count": 3852.0, "timer/env.step_total": 33.28584957122803, "timer/env.step_frac": 0.033275758774240057, "timer/env.step_avg": 0.008641186285365532, "timer/env.step_min": 0.00727081298828125, "timer/env.step_max": 0.03452014923095703, "timer/replay._sample_count": 30816.0, "timer/replay._sample_total": 15.367860555648804, "timer/replay._sample_frac": 0.015363201700219124, "timer/replay._sample_avg": 0.0004986974479377208, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.01108098030090332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5775.0, "timer/agent.policy_total": 57.33647322654724, "timer/agent.policy_frac": 0.05731909134449262, "timer/agent.policy_avg": 0.009928393632302553, "timer/agent.policy_min": 0.008339166641235352, "timer/agent.policy_max": 0.08754777908325195, "timer/dataset_train_count": 1926.0, "timer/dataset_train_total": 0.2081742286682129, "timer/dataset_train_frac": 0.000208111119451934, "timer/dataset_train_avg": 0.0001080863077197367, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0004012584686279297, "timer/agent.train_count": 1926.0, "timer/agent.train_total": 855.898321390152, "timer/agent.train_frac": 0.855638850884975, "timer/agent.train_avg": 0.4443916518121246, "timer/agent.train_min": 0.434237003326416, "timer/agent.train_max": 2.7154626846313477, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786648750305176, "timer/agent.report_frac": 0.0004785197650170607, "timer/agent.report_avg": 0.2393324375152588, "timer/agent.report_min": 0.23313236236572266, "timer/agent.report_max": 0.24553251266479492, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003163394317065e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 30.80610372397252}
{"step": 988344, "time": 32261.864181518555, "episode/length": 640.0, "episode/score": 0.14761306853864653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14761306853864653}
{"step": 988992, "time": 32282.28583598137, "episode/length": 640.0, "episode/score": 0.08338451945789416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08338451945789416}
{"step": 990080, "time": 32327.581690073013, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.590767860413, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.5991666317, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.607171058655, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.61471104622, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.62229347229, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.630546808243, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32327.63796377182, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990240, "time": 32332.65944647789, "episode/length": 640.0, "episode/score": 0.16194313446504793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16194313446504793}
{"step": 991416, "time": 32369.882858514786, "episode/length": 640.0, "episode/score": 0.21513267644769485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21513267644769485}
{"step": 992280, "time": 32397.0395693779, "episode/length": 640.0, "episode/score": 0.2487122945112219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2487122945112219}
{"step": 992344, "time": 32399.035968780518, "episode/length": 640.0, "episode/score": 0.13717200272185437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13717200272185437}
{"step": 992856, "time": 32414.935512065887, "episode/length": 640.0, "episode/score": 0.233658044092806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.233658044092806}
{"step": 993152, "time": 32424.46506023407, "episode/length": 640.0, "episode/score": 0.23523284874733008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23523284874733008}
{"step": 993472, "time": 32434.37452697754, "episode/length": 640.0, "episode/score": 0.20258802605439996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20258802605439996}
{"step": 994120, "time": 32454.363429307938, "episode/length": 640.0, "episode/score": 0.18948273418646977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18948273418646977}
{"step": 995368, "time": 32493.188636541367, "episode/length": 640.0, "episode/score": 0.25189608397090524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25189608397090524}
{"step": 996544, "time": 32530.032951831818, "episode/length": 640.0, "episode/score": 0.1357074765278412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1357074765278412}
{"step": 996848, "time": 32539.5699198246, "episode/length": 498.0, "episode/score": 0.16398805512199033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16398805512199033}
{"step": 997408, "time": 32556.954850673676, "episode/length": 640.0, "episode/score": 0.16964033910073795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16964033910073795}
{"step": 997472, "time": 32558.929262161255, "episode/length": 640.0, "episode/score": 0.06064461317350833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06064461317350833}
{"step": 998280, "time": 32584.008928775787, "episode/length": 640.0, "episode/score": 0.1385425815826693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1385425815826693}
{"step": 998600, "time": 32594.095044851303, "episode/length": 640.0, "episode/score": 0.1611480696409444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1611480696409444}
{"step": 999248, "time": 32614.638053894043, "episode/length": 640.0, "episode/score": 0.1585962773352776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1585962773352776}
{"step": 1000064, "time": 32646.67732810974, "eval_episode/length": 314.0, "eval_episode/score": 0.5584375262260437, "eval_episode/reward_rate": 0.0031746031746031746}
{"step": 1000064, "time": 32652.241752147675, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 32652.250304460526, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 32652.258255958557, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 32652.266705274582, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 32652.27427124977, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 32652.281670570374, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 32652.289073705673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000496, "time": 32665.811067581177, "episode/length": 640.0, "episode/score": 0.17752194881438754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17752194881438754}
{"step": 1001672, "time": 32702.1678712368, "episode/length": 640.0, "episode/score": 0.1079729541152119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1079729541152119}
{"step": 1001976, "time": 32711.585349798203, "episode/length": 640.0, "episode/score": 0.21149134537517966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21149134537517966}
{"step": 1002536, "time": 32729.09299135208, "episode/length": 640.0, "episode/score": 0.06471702517740141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06471702517740141}
{"step": 1002600, "time": 32731.082107067108, "episode/length": 640.0, "episode/score": 0.06883051070292368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06883051070292368}
{"step": 1003408, "time": 32756.869545698166, "episode/length": 640.0, "episode/score": 0.10844735084344848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10844735084344848}
{"step": 1003728, "time": 32766.947762966156, "episode/length": 640.0, "episode/score": 0.0703632857306502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0703632857306502}
{"step": 1004376, "time": 32786.97573828697, "episode/length": 640.0, "episode/score": 0.1464358868301474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1464358868301474}
{"step": 1005624, "time": 32825.82033491135, "episode/length": 640.0, "episode/score": 0.16046363759727456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16046363759727456}
{"step": 1006800, "time": 32862.63345503807, "episode/length": 640.0, "episode/score": 0.14045338187935386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14045338187935386}
{"step": 1007104, "time": 32872.20271945, "episode/length": 640.0, "episode/score": 0.07949161199979926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07949161199979926}
{"step": 1007664, "time": 32890.087421417236, "episode/length": 640.0, "episode/score": 0.15642277540621308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15642277540621308}
{"step": 1007728, "time": 32892.08060717583, "episode/length": 640.0, "episode/score": 0.15289614626505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15289614626505}
{"step": 1008536, "time": 32917.100360155106, "episode/length": 640.0, "episode/score": 0.12486963815882746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12486963815882746}
{"step": 1008856, "time": 32927.12522006035, "episode/length": 640.0, "episode/score": 0.07006118973373532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07006118973373532}
{"step": 1009504, "time": 32947.3341023922, "episode/length": 640.0, "episode/score": 0.12548414255900298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12548414255900298}
{"step": 1010048, "time": 32975.55036115646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.558668375015, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.56631684303, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.57376718521, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.580959796906, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.58813691139, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.59584736824, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 32975.603056669235, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010752, "time": 32997.401955127716, "episode/length": 640.0, "episode/score": 0.1535031468605439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1535031468605439}
{"step": 1011928, "time": 33033.787741184235, "episode/length": 640.0, "episode/score": 0.11498936916427738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11498936916427738}
{"step": 1012232, "time": 33043.20175290108, "episode/length": 640.0, "episode/score": 0.1837361280162213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1837361280162213}
{"step": 1012792, "time": 33060.800822257996, "episode/length": 640.0, "episode/score": 0.21073364281926388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21073364281926388}
{"step": 1012856, "time": 33062.78399372101, "episode/length": 640.0, "episode/score": 0.16917159041338437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16917159041338437}
{"step": 1013664, "time": 33088.08560013771, "episode/length": 640.0, "episode/score": 0.07765913982393613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07765913982393613}
{"step": 1013984, "time": 33097.990563869476, "episode/length": 640.0, "episode/score": 0.14527511926928582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14527511926928582}
{"step": 1014632, "time": 33117.82257556915, "episode/length": 640.0, "episode/score": 0.12461637834985595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12461637834985595}
{"step": 1015880, "time": 33157.36927008629, "episode/length": 640.0, "episode/score": 0.22865369064447805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22865369064447805}
{"step": 1017056, "time": 33194.82183289528, "episode/length": 640.0, "episode/score": 0.25444569295257224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25444569295257224}
{"step": 1017360, "time": 33204.55195236206, "episode/length": 640.0, "episode/score": 0.2458130967578427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2458130967578427}
{"step": 1017920, "time": 33222.03486895561, "episode/length": 640.0, "episode/score": 0.21289743075800516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21289743075800516}
{"step": 1017984, "time": 33224.043360471725, "episode/length": 640.0, "episode/score": 0.24766091038674176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24766091038674176}
{"step": 1018792, "time": 33249.023775577545, "episode/length": 640.0, "episode/score": 0.06856764994984132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06856764994984132}
{"step": 1018873, "time": 33252.51847100258, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.206100226683938, "train/action_min": 0.0, "train/action_std": 1.8713819412369803, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007467729618852485, "train/actor_opt_grad_steps": 62620.0, "train/actor_opt_loss": -6.24446090492251, "train/adv_mag": 0.06511723856234179, "train/adv_max": 0.005499344222595037, "train/adv_mean": 1.8548793249879926e-05, "train/adv_min": -0.0648216098701398, "train/adv_std": 0.0020425424418277034, "train/cont_avg": 0.9985528659326425, "train/cont_loss_mean": 0.002447231637342312, "train/cont_loss_std": 0.062458145075237594, "train/cont_neg_acc": 0.7181306328322437, "train/cont_neg_loss": 1.4582479892165252, "train/cont_pos_acc": 0.9999543826814761, "train/cont_pos_loss": 0.0004846412041423591, "train/cont_pred": 0.9985597164519711, "train/cont_rate": 0.9985528659326425, "train/dyn_loss_mean": 1.0000041142646512, "train/dyn_loss_std": 0.00010894961342085249, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02820100411311289, "train/extr_critic_critic_opt_grad_steps": 62620.0, "train/extr_critic_critic_opt_loss": 13520.806240892163, "train/extr_critic_mag": 0.08385401068573789, "train/extr_critic_max": 0.08385401068573789, "train/extr_critic_mean": 0.07893760703079442, "train/extr_critic_min": 0.07290945213693412, "train/extr_critic_std": 0.0017049100287403391, "train/extr_return_normed_mag": 0.06300986604523783, "train/extr_return_normed_max": 0.011032883058557857, "train/extr_return_normed_mean": 0.003498512167613857, "train/extr_return_normed_min": -0.06139585564945646, "train/extr_return_normed_std": 0.0027122883532688484, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08649048525743534, "train/extr_return_raw_max": 0.08649048525743534, "train/extr_return_raw_mean": 0.07895611867385825, "train/extr_return_raw_min": 0.014061746549421024, "train/extr_return_raw_std": 0.002712288342411461, "train/extr_reward_mag": 0.0012671848652894015, "train/extr_reward_max": 0.0012671848652894015, "train/extr_reward_mean": 0.00026222103751274165, "train/extr_reward_min": 2.389127108717212e-06, "train/extr_reward_std": 0.00027370794602052113, "train/image_loss_mean": 0.10344302719893234, "train/image_loss_std": 0.12100076131098012, "train/model_loss_mean": 0.7156196360143355, "train/model_loss_std": 0.15772987794073134, "train/model_opt_grad_norm": 16.50770145623795, "train/model_opt_grad_steps": 62564.04663212435, "train/model_opt_loss": 3578.0981723607515, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9416041516269427, "train/policy_entropy_max": 1.9416041516269427, "train/policy_entropy_mean": 1.6754315263866761, "train/policy_entropy_min": 0.5648931203110849, "train/policy_entropy_std": 0.17122065202559833, "train/policy_logprob_mag": 4.516597217846411, "train/policy_logprob_max": -0.13189314475640115, "train/policy_logprob_mean": -1.675521432426927, "train/policy_logprob_min": -4.516597217846411, "train/policy_logprob_std": 0.7210949112714263, "train/policy_randomness_mag": 0.9977872152402611, "train/policy_randomness_max": 0.9977872152402611, "train/policy_randomness_mean": 0.8610015323125019, "train/policy_randomness_min": 0.2902976553983639, "train/policy_randomness_std": 0.08799001447122949, "train/post_ent_mag": 33.49332273809404, "train/post_ent_max": 33.49332273809404, "train/post_ent_mean": 25.219823560566482, "train/post_ent_min": 14.593910311170193, "train/post_ent_std": 3.988735395391988, "train/prior_ent_mag": 32.70870383662881, "train/prior_ent_max": 32.70870383662881, "train/prior_ent_mean": 24.9382026652598, "train/prior_ent_min": 15.738767426248659, "train/prior_ent_std": 3.6582471496700624, "train/rep_loss_mean": 1.0000041142646512, "train/rep_loss_std": 0.00010894961342085249, "train/reward_avg": 0.00022418687529946374, "train/reward_loss_mean": 0.00972688588473, "train/reward_loss_std": 0.014022744622641277, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001234534490911454, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009726885882317248, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002259307829277117, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.713725318511327, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.003684392897412181, "report/cont_loss_std": 0.10140712559223175, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.634030818939209, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004938915371894836, "report/cont_pred": 0.9985143542289734, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09642918407917023, "report/image_loss_std": 0.11232808232307434, "report/model_loss_mean": 0.7108074426651001, "report/model_loss_std": 0.15393473207950592, "report/post_ent_mag": 32.56543731689453, "report/post_ent_max": 32.56543731689453, "report/post_ent_mean": 25.752429962158203, "report/post_ent_min": 12.924802780151367, "report/post_ent_std": 3.9917073249816895, "report/prior_ent_mag": 33.70726776123047, "report/prior_ent_max": 33.70726776123047, "report/prior_ent_mean": 26.453861236572266, "report/prior_ent_min": 14.329699516296387, "report/prior_ent_std": 3.7798264026641846, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00024600172764621675, "report/reward_loss_mean": 0.010693822987377644, "report/reward_loss_std": 0.013702762313187122, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011309385299682617, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010693822987377644, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002352996962144971, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.006733458489179611, "eval/cont_loss_std": 0.17357638478279114, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.554657936096191, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013102669036015868, "eval/cont_pred": 0.9987078905105591, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2893376350402832, "eval/image_loss_std": 0.13072678446769714, "eval/model_loss_mean": 0.9177826642990112, "eval/model_loss_std": 0.8253692984580994, "eval/post_ent_mag": 33.04022979736328, "eval/post_ent_max": 33.04022979736328, "eval/post_ent_mean": 23.020938873291016, "eval/post_ent_min": 14.847920417785645, "eval/post_ent_std": 3.792609453201294, "eval/prior_ent_mag": 33.20073699951172, "eval/prior_ent_max": 33.20073699951172, "eval/prior_ent_mean": 23.76012420654297, "eval/prior_ent_min": 16.006275177001953, "eval/prior_ent_std": 3.616891860961914, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00031326294993050396, "eval/reward_loss_mean": 0.02171153575181961, "eval/reward_loss_std": 0.6482071280479431, "eval/reward_max_data": 0.32078126072883606, "eval/reward_max_pred": 0.0009747743606567383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014452076284214854, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.754167556762695, "eval/reward_pred": 0.00022726773750036955, "eval/reward_rate": 0.0009765625, "replay/size": 1000000.0, "replay/inserts": 30848.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.276700266663959e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.42328411513839e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0435617162235317e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3388359546661, "timer/env.step_count": 3856.0, "timer/env.step_total": 33.73030066490173, "timer/env.step_frac": 0.03371887549753226, "timer/env.step_avg": 0.008747484612267048, "timer/env.step_min": 0.007242918014526367, "timer/env.step_max": 0.035300493240356445, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.325551748275757, "timer/replay._sample_frac": 0.015320360659245951, "timer/replay._sample_avg": 0.0004968086017983583, "timer/replay._sample_min": 0.0004031658172607422, "timer/replay._sample_max": 0.010955572128295898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5779.0, "timer/agent.policy_total": 57.59616756439209, "timer/agent.policy_frac": 0.057576658522335185, "timer/agent.policy_avg": 0.009966459173627287, "timer/agent.policy_min": 0.008628368377685547, "timer/agent.policy_max": 0.07849597930908203, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.21399617195129395, "timer/dataset_train_frac": 0.00021392368691461254, "timer/dataset_train_avg": 0.00011099386511996574, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0008692741394042969, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 854.9118866920471, "timer/agent.train_frac": 0.8546223099257845, "timer/agent.train_avg": 0.44341902836724434, "timer/agent.train_min": 0.43054676055908203, "timer/agent.train_max": 0.5913054943084717, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47306180000305176, "timer/agent.report_frac": 0.0004729015639501676, "timer/agent.report_avg": 0.23653090000152588, "timer/agent.report_min": 0.2305011749267578, "timer/agent.report_max": 0.24256062507629395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8600538601386534e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 30.837000428983735}
{"step": 1019112, "time": 33259.78927898407, "episode/length": 640.0, "episode/score": 0.15869903106482752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15869903106482752}
{"step": 1019760, "time": 33280.10631942749, "episode/length": 640.0, "episode/score": 0.21708784186864705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21708784186864705}
