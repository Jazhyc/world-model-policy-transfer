{"step": 544, "time": 149.05162954330444, "episode/length": 67.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9117647058823529, "episode/intrinsic_return": 0.0}
{"step": 680, "time": 150.95344161987305, "episode/length": 84.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1128, "time": 153.87549996376038, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 1192, "time": 155.75354266166687, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 1232, "time": 157.1869375705719, "episode/length": 153.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 1272, "time": 158.75045228004456, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 1376, "time": 160.37978196144104, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1376, "time": 160.38748598098755, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 177.86954951286316, "eval_episode/length": 141.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 1560, "time": 179.3681616783142, "eval_episode/length": 147.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 179.3744022846222, "eval_episode/length": 147.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 182.36456203460693, "eval_episode/length": 149.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 1560, "time": 184.28865385055542, "eval_episode/length": 168.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9585798816568047}
{"step": 1560, "time": 186.17896032333374, "eval_episode/length": 172.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 1560, "time": 188.0587031841278, "eval_episode/length": 179.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 1560, "time": 190.19162797927856, "train_stats/sum_log_reward": 0.5999999800696969, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_sapling": 0.3333333333333333, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/sum_log_reward": 0.9571428107363837, "eval_stats/max_log_achievement_collect_sapling": 0.7142857142857143, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5714285714285714, "eval_stats/max_log_achievement_wake_up": 2.0}
{"step": 1560, "time": 235.37696647644043, "eval_episode/length": 144.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.993103448275862}
{"step": 1560, "time": 237.61562705039978, "eval_episode/length": 154.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 1560, "time": 240.09842491149902, "eval_episode/length": 171.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 1560, "time": 242.10238361358643, "eval_episode/length": 177.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 1560, "time": 244.40171003341675, "eval_episode/length": 189.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 1560, "time": 246.58043098449707, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 1560, "time": 250.74158883094788, "eval_episode/length": 95.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9375}
{"step": 1560, "time": 252.50567603111267, "eval_episode/length": 253.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9881889763779528}
{"step": 1561, "time": 369.7651574611664, "eval_stats/sum_log_reward": 1.8499999642372131, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/max_log_achievement_collect_drink": 2.142857142857143, "eval_stats/max_log_achievement_eat_cow": 0.2, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.3594970703125, "train/action_min": 0.0, "train/action_std": 4.876868724822998, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003096561413258314, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.0342323780059814, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9921875, "train/cont_loss_mean": 0.6668047904968262, "train/cont_loss_std": 0.2946283221244812, "train/cont_neg_acc": 0.125, "train/cont_neg_loss": 1.0787618160247803, "train/cont_pos_acc": 0.586614191532135, "train/cont_pos_loss": 0.6635610461235046, "train/cont_pred": 0.5364883542060852, "train/cont_rate": 0.9921875, "train/dyn_loss_mean": 10.901180267333984, "train/dyn_loss_std": 0.49351420998573303, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 7.073273658752441, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 29125.703125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3659.79736328125, "train/image_loss_std": 148.6142120361328, "train/model_loss_mean": 3672.5458984375, "train/model_loss_std": 148.51744079589844, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36725460.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7768805027008057, "train/policy_entropy_max": 2.7768805027008057, "train/policy_entropy_mean": 2.5786802768707275, "train/policy_entropy_min": 1.969637155532837, "train/policy_entropy_std": 0.08199885487556458, "train/policy_logprob_mag": 5.636483669281006, "train/policy_logprob_max": -0.707955539226532, "train/policy_logprob_mean": -2.57338547706604, "train/policy_logprob_min": -5.636483669281006, "train/policy_logprob_std": 0.6687191128730774, "train/policy_randomness_mag": 0.9801169633865356, "train/policy_randomness_max": 0.9801169633865356, "train/policy_randomness_mean": 0.910161018371582, "train/policy_randomness_min": 0.6951954960823059, "train/policy_randomness_std": 0.02894199639558792, "train/post_ent_mag": 106.18049621582031, "train/post_ent_max": 106.18049621582031, "train/post_ent_mean": 105.60311889648438, "train/post_ent_min": 104.9586410522461, "train/post_ent_std": 0.23226286470890045, "train/prior_ent_mag": 106.33757019042969, "train/prior_ent_max": 106.33757019042969, "train/prior_ent_mean": 105.55056762695312, "train/prior_ent_min": 104.36531066894531, "train/prior_ent_std": 0.3106934726238251, "train/rep_loss_mean": 10.901180267333984, "train/rep_loss_std": 0.49351420998573303, "train/reward_avg": 0.005078124813735485, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.01171875, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.6436691284179688, "report/cont_loss_std": 0.2776555120944977, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.558215856552124, "report/cont_pos_acc": 0.6377952694892883, "report/cont_pos_loss": 0.6443420052528381, "report/cont_pred": 0.5427706241607666, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 10.858413696289062, "report/dyn_loss_std": 0.5388320088386536, "report/image_loss_mean": 3661.048828125, "report/image_loss_std": 151.5460968017578, "report/model_loss_mean": 3673.74853515625, "report/model_loss_std": 151.44317626953125, "report/post_ent_mag": 106.09081268310547, "report/post_ent_max": 106.09081268310547, "report/post_ent_mean": 105.59880065917969, "report/post_ent_min": 104.92437744140625, "report/post_ent_std": 0.2318355292081833, "report/prior_ent_mag": 106.58415222167969, "report/prior_ent_max": 106.58415222167969, "report/prior_ent_mean": 105.55705261230469, "report/prior_ent_min": 104.69325256347656, "report/prior_ent_std": 0.2978002727031708, "report/rep_loss_mean": 10.858413696289062, "report/rep_loss_std": 0.5388320088386536, "report/reward_avg": 0.005078124813735485, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.01171875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.6836617588996887, "eval/cont_loss_std": 0.30880263447761536, "eval/cont_neg_acc": 0.25, "eval/cont_neg_loss": 0.9061398506164551, "eval/cont_pos_acc": 0.5794117450714111, "eval/cont_pos_loss": 0.6827892661094666, "eval/cont_pred": 0.5281524062156677, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 10.926054000854492, "eval/dyn_loss_std": 0.5061531662940979, "eval/image_loss_mean": 3638.0146484375, "eval/image_loss_std": 161.53004455566406, "eval/model_loss_mean": 3650.794921875, "eval/model_loss_std": 161.40902709960938, "eval/post_ent_mag": 106.16630554199219, "eval/post_ent_max": 106.16630554199219, "eval/post_ent_mean": 105.59953308105469, "eval/post_ent_min": 104.68476867675781, "eval/post_ent_std": 0.24670113623142242, "eval/prior_ent_mag": 106.58944702148438, "eval/prior_ent_max": 106.58944702148438, "eval/prior_ent_mean": 105.56532287597656, "eval/prior_ent_min": 104.40614318847656, "eval/prior_ent_std": 0.2990871071815491, "eval/rep_loss_mean": 10.926054000854492, "eval/rep_loss_std": 0.5061531662940979, "eval/reward_avg": 0.01103515550494194, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.565802656652522e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541263103485107, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.015625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 2.0316330576800126e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.047133581978934e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3088.0, "eval_replay/inserts": 3088.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5688683702538051e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 233.5474681854248, "timer/env.step_count": 196.0, "timer/env.step_total": 27.283336877822876, "timer/env.step_frac": 0.11682137721211046, "timer/env.step_avg": 0.13920069835623916, "timer/env.step_min": 0.019598960876464844, "timer/env.step_max": 11.320656061172485, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.11675310134887695, "timer/replay._sample_frac": 0.0004999116550310061, "timer/replay._sample_avg": 0.0010424384049006871, "timer/replay._sample_min": 0.00039768218994140625, "timer/replay._sample_max": 0.011278152465820312, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.866553544998169, "timer/agent.save_frac": 0.037964674221852734, "timer/agent.save_avg": 8.866553544998169, "timer/agent.save_min": 8.866553544998169, "timer/agent.save_max": 8.866553544998169, "timer/agent.policy_count": 255.0, "timer/agent.policy_total": 24.792393922805786, "timer/agent.policy_frac": 0.10615569552277007, "timer/agent.policy_avg": 0.09722507420708151, "timer/agent.policy_min": 0.010737895965576172, "timer/agent.policy_max": 17.901009798049927, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.00543212890625e-05, "timer/dataset_train_frac": 1.715039841804725e-07, "timer/dataset_train_avg": 4.00543212890625e-05, "timer/dataset_train_min": 4.00543212890625e-05, "timer/dataset_train_max": 4.00543212890625e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.18066906929016, "timer/agent.train_frac": 0.3904160031265993, "timer/agent.train_avg": 91.18066906929016, "timer/agent.train_min": 91.18066906929016, "timer/agent.train_max": 91.18066906929016, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.835477828979492, "timer/agent.report_frac": 0.10205838673470584, "timer/agent.report_avg": 11.917738914489746, "timer/agent.report_min": 0.24433445930480957, "timer/agent.report_max": 23.591143369674683, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 1.5823284254745975e-07, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05}
{"step": 1728, "time": 375.3523015975952, "episode/length": 56.0, "episode/score": -0.8999999985098839, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1808, "time": 379.7993538379669, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 2064, "time": 390.4942886829376, "episode/length": 172.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 2240, "time": 398.1067316532135, "episode/length": 125.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 2304, "time": 401.8729920387268, "episode/length": 146.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 2392, "time": 406.09759616851807, "episode/length": 149.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 2600, "time": 414.55130100250244, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 2968, "time": 428.91280150413513, "episode/length": 154.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 3320, "time": 442.8075695037842, "episode/length": 242.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 3536, "time": 451.96112632751465, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 3560, "time": 454.1498649120331, "episode/length": 218.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 3712, "time": 461.22314858436584, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 3768, "time": 464.5006778240204, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 3816, "time": 467.7990708351135, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 3840, "time": 470.54576206207275, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 4616, "time": 497.8489489555359, "episode/length": 205.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 4784, "time": 505.25756454467773, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 4904, "time": 510.6696982383728, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 5064, "time": 517.6918461322784, "episode/length": 168.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 5232, "time": 525.1315100193024, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 5264, "time": 527.8052055835724, "episode/length": 212.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 5664, "time": 542.9292011260986, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 5872, "time": 551.515233039856, "episode/length": 100.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 5896, "time": 553.6524848937988, "episode/length": 265.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 6088, "time": 561.8131840229034, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 6376, "time": 573.0016486644745, "episode/length": 198.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 6448, "time": 577.3034942150116, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 6984, "time": 596.6230273246765, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 7152, "time": 604.0815126895905, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 7184, "time": 606.9571120738983, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 7200, "time": 609.2241175174713, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 7800, "time": 630.7852354049683, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 7936, "time": 637.286712884903, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 7952, "time": 639.4469637870789, "episode/length": 232.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 7976, "time": 641.6612720489502, "episode/length": 419.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 8280, "time": 654.5733432769775, "episode/length": 161.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 8392, "time": 659.8600010871887, "episode/length": 150.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 8552, "time": 667.088826417923, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 8936, "time": 681.6483638286591, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 9016, "time": 686.0284008979797, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 9632, "time": 708.7511923313141, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 9648, "time": 711.0608417987823, "episode/length": 211.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 9672, "time": 713.1861574649811, "episode/length": 211.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 9680, "time": 715.3729627132416, "episode/length": 140.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 9840, "time": 722.3460922241211, "episode/length": 237.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 9864, "time": 724.4937567710876, "episode/length": 26.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 9968, "time": 729.8759384155273, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 750.9187769889832, "eval_episode/length": 57.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9310344827586207}
{"step": 10088, "time": 753.9593057632446, "eval_episode/length": 90.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.945054945054945}
{"step": 10088, "time": 758.1662664413452, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 10088, "time": 759.8664305210114, "eval_episode/length": 154.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.967741935483871}
{"step": 10088, "time": 761.6589109897614, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 10088, "time": 763.7374217510223, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 10088, "time": 766.3032321929932, "eval_episode/length": 187.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.973404255319149}
{"step": 10088, "time": 768.9742228984833, "eval_episode/length": 212.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 10432, "time": 780.7489328384399, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 10488, "time": 784.1392555236816, "episode/length": 193.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 10936, "time": 801.0985059738159, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 11184, "time": 811.4435112476349, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 11240, "time": 814.7615211009979, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 11288, "time": 817.9302322864532, "episode/length": 201.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 11320, "time": 820.5987348556519, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 11488, "time": 828.1199386119843, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 11528, "time": 830.9116759300232, "episode/length": 136.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 11896, "time": 845.0153238773346, "episode/length": 175.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 11920, "time": 847.6234860420227, "episode/length": 122.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 12040, "time": 853.2438657283783, "episode/length": 93.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 12672, "time": 876.4708456993103, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 12720, "time": 879.7124750614166, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 12872, "time": 886.2276365756989, "episode/length": 210.0, "episode/score": 1.1000000163912773, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 12960, "time": 891.0092520713806, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 13184, "time": 900.1437604427338, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 13240, "time": 903.3340313434601, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 13488, "time": 913.5474858283997, "episode/length": 180.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 13944, "time": 930.2851891517639, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 14128, "time": 938.2276787757874, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 14240, "time": 943.5243580341339, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 14272, "time": 946.1792304515839, "episode/length": 40.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 14376, "time": 951.1416490077972, "episode/length": 306.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 14496, "time": 957.3396651744843, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 14600, "time": 962.2827887535095, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 14664, "time": 966.0492236614227, "episode/length": 177.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 15312, "time": 989.8719239234924, "episode/length": 80.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 15336, "time": 992.0250990390778, "episode/length": 132.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 15344, "time": 994.1228110790253, "episode/length": 120.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9504132231404959, "episode/intrinsic_return": 0.0}
{"step": 15360, "time": 996.5479943752289, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 15432, "time": 1000.2451314926147, "episode/length": 242.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 15488, "time": 1004.0156724452972, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 15832, "time": 1017.0868654251099, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 15912, "time": 1021.7687573432922, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 16544, "time": 1046.8099110126495, "episode/length": 138.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 16584, "time": 1049.600976228714, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 16616, "time": 1052.5227408409119, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 16616, "time": 1052.530303478241, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 16832, "time": 1063.567176580429, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 17008, "time": 1070.9799444675446, "episode/length": 208.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 17232, "time": 1080.0664892196655, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 17864, "time": 1102.7634272575378, "episode/length": 128.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 18040, "time": 1110.2422738075256, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 18064, "time": 1113.0620024204254, "episode/length": 184.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 18336, "time": 1124.122116804123, "episode/length": 223.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 18336, "time": 1124.1305937767029, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 18344, "time": 1127.5624811649323, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 18704, "time": 1141.6223204135895, "episode/length": 358.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9749303621169917, "episode/intrinsic_return": 0.0}
{"step": 18816, "time": 1147.0598912239075, "episode/length": 197.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 19344, "time": 1166.5043222904205, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 19584, "time": 1176.259955406189, "episode/length": 214.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 19616, "time": 1178.9434390068054, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 19632, "time": 1181.1506972312927, "episode/length": 195.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 19848, "time": 1189.9745609760284, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 19944, "time": 1194.8607909679413, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 20032, "time": 1199.5659577846527, "episode/length": 51.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1217.6808590888977, "eval_episode/length": 49.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9}
{"step": 20072, "time": 1220.0166840553284, "eval_episode/length": 67.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9264705882352942}
{"step": 20072, "time": 1225.0191776752472, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 20072, "time": 1226.9984426498413, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 20072, "time": 1229.0056126117706, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 20072, "time": 1231.0774490833282, "eval_episode/length": 178.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 20072, "time": 1234.0569205284119, "eval_episode/length": 207.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 20072, "time": 1236.029626607895, "eval_episode/length": 160.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 20248, "time": 1241.9182856082916, "episode/length": 178.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 20584, "time": 1255.139258146286, "episode/length": 234.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 20856, "time": 1266.0095880031586, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 20896, "time": 1269.6213870048523, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 21152, "time": 1280.013876914978, "episode/length": 150.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 21408, "time": 1290.131119966507, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 21480, "time": 1293.8463888168335, "episode/length": 203.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 21712, "time": 1303.5123088359833, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 21888, "time": 1311.1586997509003, "episode/length": 287.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 21920, "time": 1313.7111086845398, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 22224, "time": 1325.4538116455078, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 22496, "time": 1336.200186252594, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 22729, "time": 1346.4420456886292, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.745193943832859, "train/action_min": 0.0, "train/action_std": 1.7367490715149678, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006118317689415011, "train/actor_opt_grad_steps": 665.0, "train/actor_opt_loss": 121.47470030386114, "train/adv_mag": 2.150776720893301, "train/adv_max": 2.1479003727206765, "train/adv_mean": 0.01888039881525787, "train/adv_min": -0.43723706463634066, "train/adv_std": 0.1561342271558136, "train/cont_avg": 0.9945253314393939, "train/cont_loss_mean": 0.026515364692772204, "train/cont_loss_std": 0.23530839615021693, "train/cont_neg_acc": 0.04541874518900207, "train/cont_neg_loss": 3.0450301585775432, "train/cont_pos_acc": 0.9968148090622642, "train/cont_pos_loss": 0.010127830696574441, "train/cont_pred": 0.9909871030937542, "train/cont_rate": 0.9945253314393939, "train/dyn_loss_mean": 5.636892804593751, "train/dyn_loss_std": 7.551786331290549, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.54097574317094, "train/extr_critic_critic_opt_grad_steps": 665.0, "train/extr_critic_critic_opt_loss": 21738.309821851326, "train/extr_critic_mag": 0.29965185848149384, "train/extr_critic_max": 0.2996518566752925, "train/extr_critic_mean": 0.05967669184854712, "train/extr_critic_min": -0.0624474874048522, "train/extr_critic_std": 0.0824220272127111, "train/extr_return_normed_mag": 2.5180376783263814, "train/extr_return_normed_max": 2.5176330249329717, "train/extr_return_normed_mean": 0.19287533602486787, "train/extr_return_normed_min": -0.3286347545343398, "train/extr_return_normed_std": 0.20820024746353738, "train/extr_return_rate": 0.033306701562347975, "train/extr_return_raw_mag": 2.4033147888875455, "train/extr_return_raw_max": 2.4033147888875455, "train/extr_return_raw_mean": 0.07855708908049785, "train/extr_return_raw_min": -0.44295299561891815, "train/extr_return_raw_std": 0.20820024695157455, "train/extr_reward_mag": 0.6246188057191444, "train/extr_reward_max": 0.6245047088825342, "train/extr_reward_mean": 0.006148771284890906, "train/extr_reward_min": -0.0996716230204611, "train/extr_reward_std": 0.03956755441413062, "train/image_loss_mean": 91.47912518183391, "train/image_loss_std": 48.33662194916696, "train/model_loss_mean": 95.19361890446056, "train/model_loss_std": 50.03745339856003, "train/model_opt_grad_norm": 369.78140559340966, "train/model_opt_grad_steps": 656.0, "train/model_opt_loss": 1983.0689798990886, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 24.266098484848484, "train/policy_entropy_mag": 1.0360049476677722, "train/policy_entropy_max": 1.0360049476677722, "train/policy_entropy_mean": 0.741493567203482, "train/policy_entropy_min": 0.6130718718085325, "train/policy_entropy_std": 0.06846706872932952, "train/policy_logprob_mag": 6.870102441672123, "train/policy_logprob_max": -0.27658107083742367, "train/policy_logprob_mean": -0.7407584896480496, "train/policy_logprob_min": -6.870102441672123, "train/policy_logprob_std": 0.7698082190119859, "train/policy_randomness_mag": 0.36566428137435153, "train/policy_randomness_max": 0.36566428137435153, "train/policy_randomness_mean": 0.261714690985779, "train/policy_randomness_min": 0.21638746721895807, "train/policy_randomness_std": 0.024165870739538645, "train/post_ent_mag": 49.719692374720715, "train/post_ent_max": 49.719692374720715, "train/post_ent_mean": 32.21022861654108, "train/post_ent_min": 17.19090886549516, "train/post_ent_std": 6.012242025723963, "train/prior_ent_mag": 57.39860401731549, "train/prior_ent_max": 57.39860401731549, "train/prior_ent_mean": 38.529539267222084, "train/prior_ent_min": 21.44051277998722, "train/prior_ent_std": 6.213319967190425, "train/rep_loss_mean": 5.636892804593751, "train/rep_loss_std": 7.551786331290549, "train/reward_avg": 0.007558741693642471, "train/reward_loss_mean": 0.305841620080173, "train/reward_loss_std": 0.6296724575769269, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.7408518339648391, "train/reward_neg_acc": 0.9975874365279169, "train/reward_neg_loss": 0.2724904436335871, "train/reward_pos_acc": 0.5311101517555389, "train/reward_pos_loss": 2.8263288993727076, "train/reward_pred": 0.005348474466397117, "train/reward_rate": 0.012510357481060606, "train_stats/sum_log_reward": 0.9275861776851374, "train_stats/max_log_achievement_collect_drink": 0.6206896551724138, "train_stats/max_log_achievement_collect_sapling": 12.094827586206897, "train_stats/max_log_achievement_collect_wood": 0.1896551724137931, "train_stats/max_log_achievement_eat_cow": 0.11206896551724138, "train_stats/max_log_achievement_place_plant": 0.29310344827586204, "train_stats/max_log_achievement_wake_up": 0.5517241379310345, "train_stats/mean_log_entropy": 0.7944094172582544, "train_stats/max_log_achievement_place_table": 0.030303030303030304, "train_stats/max_log_achievement_defeat_zombie": 0.2328767123287671, "eval_stats/sum_log_reward": 0.41249998146668077, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 12.0625, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.02009892836213112, "report/cont_loss_std": 0.14844942092895508, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 1.242033839225769, "report/cont_pos_acc": 0.9990138411521912, "report/cont_pos_loss": 0.008048289455473423, "report/cont_pred": 0.989448070526123, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 6.633674621582031, "report/dyn_loss_std": 5.471169471740723, "report/image_loss_mean": 20.952335357666016, "report/image_loss_std": 13.235153198242188, "report/model_loss_mean": 25.08733367919922, "report/model_loss_std": 14.745363235473633, "report/post_ent_mag": 43.68461608886719, "report/post_ent_max": 43.68461608886719, "report/post_ent_mean": 31.671154022216797, "report/post_ent_min": 15.735445022583008, "report/post_ent_std": 3.7098817825317383, "report/prior_ent_mag": 50.76245880126953, "report/prior_ent_max": 50.76245880126953, "report/prior_ent_mean": 37.61476516723633, "report/prior_ent_min": 18.31001853942871, "report/prior_ent_std": 3.9364025592803955, "report/rep_loss_mean": 6.633674621582031, "report/rep_loss_std": 5.471169471740723, "report/reward_avg": 0.0006835936801508069, "report/reward_loss_mean": 0.134693443775177, "report/reward_loss_std": 0.46813446283340454, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.989060640335083, "report/reward_neg_acc": 0.9990147948265076, "report/reward_neg_loss": 0.12325337529182434, "report/reward_pos_acc": 0.7777777910232544, "report/reward_pos_loss": 1.4248791933059692, "report/reward_pred": 0.0014765290543437004, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.006412366405129433, "eval/cont_loss_std": 0.10502269119024277, "eval/cont_neg_acc": 0.3333333432674408, "eval/cont_neg_loss": 1.7028353214263916, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014277736190706491, "eval/cont_pred": 0.9979397654533386, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 10.164793014526367, "eval/dyn_loss_std": 7.8664021492004395, "eval/image_loss_mean": 58.39171600341797, "eval/image_loss_std": 61.649051666259766, "eval/model_loss_mean": 64.65176391601562, "eval/model_loss_std": 63.28750991821289, "eval/post_ent_mag": 49.59883117675781, "eval/post_ent_max": 49.59883117675781, "eval/post_ent_mean": 30.708965301513672, "eval/post_ent_min": 12.386402130126953, "eval/post_ent_std": 7.195764064788818, "eval/prior_ent_mag": 53.375709533691406, "eval/prior_ent_max": 53.375709533691406, "eval/prior_ent_mean": 36.97336196899414, "eval/prior_ent_min": 15.467364311218262, "eval/prior_ent_std": 7.373164176940918, "eval/rep_loss_mean": 10.164793014526367, "eval/rep_loss_std": 7.8664021492004395, "eval/reward_avg": 0.01376953162252903, "eval/reward_loss_mean": 0.15476185083389282, "eval/reward_loss_std": 0.7827650308609009, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9821717739105225, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.10165262967348099, "eval/reward_pos_acc": 0.4117647111415863, "eval/reward_pos_loss": 3.3007025718688965, "eval/reward_pred": -0.0012359211686998606, "eval/reward_rate": 0.0166015625, "replay/size": 22225.0, "replay/inserts": 21168.0, "replay/samples": 21168.0, "replay/insert_wait_avg": 1.5035418065677335e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.006915275562197e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6480.0, "eval_replay/inserts": 3392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3504528774405426e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.385807991027832e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.6690690517426, "timer/env.step_count": 2646.0, "timer/env.step_total": 262.5996253490448, "timer/env.step_frac": 0.26887267516724506, "timer/env.step_avg": 0.09924400050984308, "timer/env.step_min": 0.022984743118286133, "timer/env.step_max": 3.576342821121216, "timer/replay._sample_count": 21168.0, "timer/replay._sample_total": 11.558775901794434, "timer/replay._sample_frac": 0.01183489502029276, "timer/replay._sample_avg": 0.0005460495040530251, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.011516809463500977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3070.0, "timer/agent.policy_total": 52.66141438484192, "timer/agent.policy_frac": 0.05391940428293833, "timer/agent.policy_avg": 0.017153555174215608, "timer/agent.policy_min": 0.009805679321289062, "timer/agent.policy_max": 0.08995652198791504, "timer/dataset_train_count": 1323.0, "timer/dataset_train_total": 0.1509389877319336, "timer/dataset_train_frac": 0.00015454465848752815, "timer/dataset_train_avg": 0.00011408842610123476, "timer/dataset_train_min": 8.082389831542969e-05, "timer/dataset_train_max": 0.00035834312438964844, "timer/agent.train_count": 1323.0, "timer/agent.train_total": 595.7753486633301, "timer/agent.train_frac": 0.6100073889324397, "timer/agent.train_avg": 0.4503215031468859, "timer/agent.train_min": 0.43652772903442383, "timer/agent.train_max": 1.225257158279419, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47478318214416504, "timer/agent.report_frac": 0.00048612492930193504, "timer/agent.report_avg": 0.23739159107208252, "timer/agent.report_min": 0.2298123836517334, "timer/agent.report_max": 0.24497079849243164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.0001785755157470703, "timer/dataset_eval_frac": 1.8284137524745308e-07, "timer/dataset_eval_avg": 0.0001785755157470703, "timer/dataset_eval_min": 0.0001785755157470703, "timer/dataset_eval_max": 0.0001785755157470703, "fps": 21.67340773976676}
{"step": 22752, "time": 1347.1517000198364, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 22888, "time": 1353.1696066856384, "episode/length": 146.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 23136, "time": 1363.409744977951, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 23168, "time": 1366.1748082637787, "episode/length": 251.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 23288, "time": 1371.5976421833038, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 23328, "time": 1374.79198884964, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 23528, "time": 1382.8033936023712, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 23704, "time": 1390.520536184311, "episode/length": 286.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9930313588850174, "episode/intrinsic_return": 0.0}
{"step": 23784, "time": 1394.7278141975403, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 24424, "time": 1417.805608034134, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 24440, "time": 1420.0695440769196, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 24560, "time": 1425.8398084640503, "episode/length": 153.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 24664, "time": 1431.8311522006989, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 24832, "time": 1439.2973802089691, "episode/length": 242.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 24832, "time": 1439.3067116737366, "episode/length": 140.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 24880, "time": 1444.2528958320618, "episode/length": 168.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 24912, "time": 1447.1513457298279, "episode/length": 202.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 25400, "time": 1464.7469685077667, "episode/length": 91.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 25624, "time": 1473.7886228561401, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 25904, "time": 1485.1852419376373, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 26128, "time": 1494.3159217834473, "episode/length": 151.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 26200, "time": 1498.0022304058075, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 26296, "time": 1502.8575570583344, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 26312, "time": 1505.0183544158936, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 26312, "time": 1505.0282821655273, "episode/length": 233.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 26384, "time": 1511.1161091327667, "episode/length": 122.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 26504, "time": 1516.488486289978, "episode/length": 242.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 26536, "time": 1519.1929166316986, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 27408, "time": 1550.6048350334167, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 27584, "time": 1558.0505540370941, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 27624, "time": 1560.8327267169952, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 27696, "time": 1565.174991607666, "episode/length": 35.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 27776, "time": 1569.446206331253, "episode/length": 182.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 27816, "time": 1572.1307311058044, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 27832, "time": 1574.1648199558258, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 28152, "time": 1586.5089325904846, "episode/length": 205.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 28304, "time": 1593.4759006500244, "episode/length": 65.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 28352, "time": 1596.8435213565826, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 28592, "time": 1606.6601943969727, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 28928, "time": 1619.5404376983643, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 29048, "time": 1625.0177369117737, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 29192, "time": 1632.2003684043884, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 29200, "time": 1634.861516237259, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 29216, "time": 1637.4636268615723, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 29448, "time": 1647.1641819477081, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 29544, "time": 1652.133320569992, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 30040, "time": 1670.3817620277405, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1691.4386041164398, "eval_episode/length": 129.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 30056, "time": 1694.1700842380524, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 30056, "time": 1696.7483298778534, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 30056, "time": 1699.4747097492218, "eval_episode/length": 176.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 30056, "time": 1701.1212439537048, "eval_episode/length": 177.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 30056, "time": 1703.0592620372772, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 30056, "time": 1705.2571244239807, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 30056, "time": 1708.8710193634033, "eval_episode/length": 245.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9796747967479674}
{"step": 30168, "time": 1712.5975978374481, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 30408, "time": 1722.3436696529388, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 30472, "time": 1726.010359287262, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 30744, "time": 1736.6875436306, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 30896, "time": 1743.5288999080658, "episode/length": 106.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 30992, "time": 1748.5539157390594, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 31040, "time": 1751.8394210338593, "episode/length": 227.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 31336, "time": 1763.2840065956116, "episode/length": 223.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 31632, "time": 1775.337729215622, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 31840, "time": 1784.1085073947906, "episode/length": 178.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 31984, "time": 1790.435427904129, "episode/length": 188.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 32072, "time": 1794.7222201824188, "episode/length": 165.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 32312, "time": 1804.3698709011078, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 32512, "time": 1812.990981578827, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 32584, "time": 1816.72780585289, "episode/length": 210.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 33104, "time": 1837.4946324825287, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 33136, "time": 1840.6372380256653, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 33144, "time": 1842.607050895691, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 33608, "time": 1860.5308718681335, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 33648, "time": 1863.6684019565582, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 33704, "time": 1867.1001257896423, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 34056, "time": 1880.7441515922546, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 34200, "time": 1887.108925819397, "episode/length": 131.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 34560, "time": 1901.0230853557587, "episode/length": 181.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 34632, "time": 1904.8027818202972, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 34696, "time": 1908.5337433815002, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 34792, "time": 1913.2411415576935, "episode/length": 431.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 34864, "time": 1917.6068258285522, "episode/length": 156.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 34864, "time": 1917.6181194782257, "episode/length": 37.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 34984, "time": 1925.00914144516, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 35472, "time": 1943.2015850543976, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 35520, "time": 1946.3628544807434, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 35704, "time": 1953.905236005783, "episode/length": 104.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 35832, "time": 1959.924968957901, "episode/length": 141.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 35856, "time": 1962.5930910110474, "episode/length": 152.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 36000, "time": 1968.9618511199951, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 36368, "time": 1982.8981492519379, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 36544, "time": 1990.4911420345306, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 36840, "time": 2001.7906708717346, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 36976, "time": 2008.1543517112732, "episode/length": 187.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 37112, "time": 2014.1061975955963, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 37120, "time": 2016.430438041687, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 37344, "time": 2025.4124422073364, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 37648, "time": 2037.3854384422302, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 37912, "time": 2047.713996887207, "episode/length": 256.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 38080, "time": 2055.1087124347687, "episode/length": 53.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 38272, "time": 2063.646158695221, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 38296, "time": 2065.7886090278625, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 38328, "time": 2068.3519134521484, "episode/length": 151.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 38392, "time": 2072.0364599227905, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 38432, "time": 2075.2096297740936, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 38592, "time": 2082.1700558662415, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 39296, "time": 2107.5964109897614, "episode/length": 172.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 39448, "time": 2113.9678950309753, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 39624, "time": 2121.4705333709717, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 39624, "time": 2121.478507041931, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 39712, "time": 2128.023821115494, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 39728, "time": 2130.091356277466, "episode/length": 141.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2161.219159603119, "eval_episode/length": 139.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 40040, "time": 2163.1340160369873, "eval_episode/length": 145.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 40040, "time": 2165.0229823589325, "eval_episode/length": 146.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 40040, "time": 2166.8634741306305, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 40040, "time": 2168.4619657993317, "eval_episode/length": 156.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 40040, "time": 2171.8872668743134, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 40040, "time": 2174.521229505539, "eval_episode/length": 222.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9910313901345291}
{"step": 40040, "time": 2176.305698156357, "eval_episode/length": 225.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9867256637168141}
{"step": 40112, "time": 2178.9498155117035, "episode/length": 82.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 40232, "time": 2184.331670999527, "episode/length": 75.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 40352, "time": 2190.1525297164917, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 40440, "time": 2194.3743216991425, "episode/length": 142.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 40512, "time": 2198.7328259944916, "episode/length": 276.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 40968, "time": 2215.4883432388306, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 41024, "time": 2220.0871810913086, "episode/length": 161.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 41552, "time": 2239.4355008602142, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 41648, "time": 2244.186333656311, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 41656, "time": 2245.9354209899902, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 41736, "time": 2250.1529495716095, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 41816, "time": 2254.4232218265533, "episode/length": 273.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 41840, "time": 2257.1869356632233, "episode/length": 165.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 42288, "time": 2273.6580123901367, "episode/length": 157.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 42416, "time": 2279.7019975185394, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 42648, "time": 2288.8418028354645, "episode/length": 103.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 43056, "time": 2304.188380241394, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 43296, "time": 2313.776793718338, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 43432, "time": 2319.893491268158, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 43480, "time": 2323.0395636558533, "episode/length": 227.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 43664, "time": 2330.974125623703, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 44065, "time": 2346.482357263565, "train_stats/sum_log_reward": 2.1476189962455203, "train_stats/max_log_achievement_collect_drink": 5.428571428571429, "train_stats/max_log_achievement_collect_sapling": 3.992063492063492, "train_stats/max_log_achievement_collect_wood": 0.2222222222222222, "train_stats/max_log_achievement_defeat_zombie": 0.09523809523809523, "train_stats/max_log_achievement_eat_cow": 0.15079365079365079, "train_stats/max_log_achievement_place_plant": 1.9126984126984128, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.5555555555555556, "train_stats/mean_log_entropy": 0.3210040701641923, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.460123850886983, "train/action_min": 0.0, "train/action_std": 2.647925775750239, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03766178498412237, "train/actor_opt_grad_steps": 1990.0, "train/actor_opt_loss": 74.05324459434452, "train/adv_mag": 1.695138362565435, "train/adv_max": 1.686640409150518, "train/adv_mean": 0.02759995520466333, "train/adv_min": -0.5620808883717185, "train/adv_std": 0.1459141011468898, "train/cont_avg": 0.9942507636278195, "train/cont_loss_mean": 0.0033634149527194965, "train/cont_loss_std": 0.05045041930774241, "train/cont_neg_acc": 0.8676840990109551, "train/cont_neg_loss": 0.3424488570970808, "train/cont_pos_acc": 0.9995564531562919, "train/cont_pos_loss": 0.0014277435456107096, "train/cont_pred": 0.9940914780573737, "train/cont_rate": 0.9942507636278195, "train/dyn_loss_mean": 6.6442723166673705, "train/dyn_loss_std": 5.908171158984191, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5818520932269275, "train/extr_critic_critic_opt_grad_steps": 1990.0, "train/extr_critic_critic_opt_loss": 18446.154194078947, "train/extr_critic_mag": 1.987670470001106, "train/extr_critic_max": 1.987670470001106, "train/extr_critic_mean": 0.4457301936931628, "train/extr_critic_min": -0.33740133271181494, "train/extr_critic_std": 0.7401519220574457, "train/extr_return_normed_mag": 2.4578361762197396, "train/extr_return_normed_max": 2.4578361762197396, "train/extr_return_normed_mean": 0.3585099378474673, "train/extr_return_normed_min": -0.21980721806000947, "train/extr_return_normed_std": 0.3762275786104059, "train/extr_return_rate": 0.3246211388841608, "train/extr_return_raw_mag": 5.061028973500531, "train/extr_return_raw_max": 5.061028973500531, "train/extr_return_raw_mean": 0.503252831385716, "train/extr_return_raw_min": -0.7688937561404436, "train/extr_return_raw_std": 0.8728316518148982, "train/extr_reward_mag": 0.995288910722374, "train/extr_reward_max": 0.995288910722374, "train/extr_reward_mean": 0.01770360629237082, "train/extr_reward_min": -0.35706749267147897, "train/extr_reward_std": 0.10190630754581968, "train/image_loss_mean": 18.49913719722203, "train/image_loss_std": 18.116285152005073, "train/model_loss_mean": 22.568905694144114, "train/model_loss_std": 19.901604759962037, "train/model_opt_grad_norm": 140.34910497450292, "train/model_opt_grad_steps": 1981.0, "train/model_opt_loss": 1254.3602473897145, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 57.859492481203006, "train/policy_entropy_mag": 1.9923770075902008, "train/policy_entropy_max": 1.9923770075902008, "train/policy_entropy_mean": 0.36604576255369903, "train/policy_entropy_min": 0.08138968134508993, "train/policy_entropy_std": 0.3319248105784444, "train/policy_logprob_mag": 7.436752451989884, "train/policy_logprob_max": -0.009812339174008011, "train/policy_logprob_mean": -0.36588685287344724, "train/policy_logprob_min": -7.436752451989884, "train/policy_logprob_std": 0.9814752568875936, "train/policy_randomness_mag": 0.7032216496597555, "train/policy_randomness_max": 0.7032216496597555, "train/policy_randomness_mean": 0.12919809225302442, "train/policy_randomness_min": 0.028726985846134954, "train/policy_randomness_std": 0.11715489159044075, "train/post_ent_mag": 41.88831406786926, "train/post_ent_max": 41.88831406786926, "train/post_ent_mean": 30.61390070807665, "train/post_ent_min": 13.641464089988766, "train/post_ent_std": 4.478737571185693, "train/prior_ent_mag": 53.03965853927727, "train/prior_ent_max": 53.03965853927727, "train/prior_ent_mean": 37.469278034410976, "train/prior_ent_min": 17.162801871622417, "train/prior_ent_std": 5.284714618123564, "train/rep_loss_mean": 6.6442723166673705, "train/rep_loss_std": 5.908171158984191, "train/reward_avg": 0.007040061005408687, "train/reward_loss_mean": 0.07984176594623946, "train/reward_loss_std": 0.3875468842741242, "train/reward_max_data": 1.0007518798785102, "train/reward_max_pred": 0.9933819797702301, "train/reward_neg_acc": 0.9956765340683156, "train/reward_neg_loss": 0.062234370304005485, "train/reward_pos_acc": 0.8422415030181856, "train/reward_pos_loss": 1.4854605484725838, "train/reward_pred": 0.00641097479212777, "train/reward_rate": 0.012210702537593985, "eval_stats/sum_log_reward": 2.59999992698431, "eval_stats/max_log_achievement_collect_drink": 0.5625, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00012791657354682684, "report/cont_loss_std": 0.001613825443200767, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00024187879171222448, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0001270192296942696, "report/cont_pred": 0.9920645952224731, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 7.878603935241699, "report/dyn_loss_std": 6.364687442779541, "report/image_loss_mean": 22.53820037841797, "report/image_loss_std": 22.533357620239258, "report/model_loss_mean": 27.334047317504883, "report/model_loss_std": 24.254981994628906, "report/post_ent_mag": 41.72957229614258, "report/post_ent_max": 41.72957229614258, "report/post_ent_mean": 31.39271354675293, "report/post_ent_min": 14.344048500061035, "report/post_ent_std": 4.723996162414551, "report/prior_ent_mag": 52.62283706665039, "report/prior_ent_max": 52.62283706665039, "report/prior_ent_mean": 39.07381820678711, "report/prior_ent_min": 18.729942321777344, "report/prior_ent_std": 5.682895183563232, "report/rep_loss_mean": 7.878603935241699, "report/rep_loss_std": 6.364687442779541, "report/reward_avg": 0.0044921874068677425, "report/reward_loss_mean": 0.06855584681034088, "report/reward_loss_std": 0.29858213663101196, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9911792278289795, "report/reward_neg_acc": 0.9980257153511047, "report/reward_neg_loss": 0.052858445793390274, "report/reward_pos_acc": 0.8181818723678589, "report/reward_pos_loss": 1.5141440629959106, "report/reward_pred": 0.003491815645247698, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 5.4624732001684606e-05, "eval/cont_loss_std": 0.0003858267155010253, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0019974829629063606, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.317370621720329e-05, "eval/cont_pred": 0.9941093921661377, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 11.396134376525879, "eval/dyn_loss_std": 7.347922325134277, "eval/image_loss_mean": 66.05258178710938, "eval/image_loss_std": 101.9230728149414, "eval/model_loss_mean": 73.02151489257812, "eval/model_loss_std": 103.38029479980469, "eval/post_ent_mag": 44.58277893066406, "eval/post_ent_max": 44.58277893066406, "eval/post_ent_mean": 30.480966567993164, "eval/post_ent_min": 14.122430801391602, "eval/post_ent_std": 5.819462299346924, "eval/prior_ent_mag": 55.369049072265625, "eval/prior_ent_max": 55.369049072265625, "eval/prior_ent_mean": 38.87084197998047, "eval/prior_ent_min": 16.415279388427734, "eval/prior_ent_std": 7.50822639465332, "eval/rep_loss_mean": 11.396134376525879, "eval/rep_loss_std": 7.347922325134277, "eval/reward_avg": 0.00869140587747097, "eval/reward_loss_mean": 0.13119491934776306, "eval/reward_loss_std": 0.6728824377059937, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9968880414962769, "eval/reward_neg_acc": 0.9930693507194519, "eval/reward_neg_loss": 0.0954146757721901, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.712484836578369, "eval/reward_pred": 0.002471866086125374, "eval/reward_rate": 0.013671875, "replay/size": 43561.0, "replay/inserts": 21336.0, "replay/samples": 21328.0, "replay/insert_wait_avg": 1.4246448757141595e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0414380197317548e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10256.0, "eval_replay/inserts": 3776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.250182167958405e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5348196029663086e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0292131900787, "timer/env.step_count": 2667.0, "timer/env.step_total": 278.69829058647156, "timer/env.step_frac": 0.27869014915817114, "timer/env.step_avg": 0.10449879662034929, "timer/env.step_min": 0.02293872833251953, "timer/env.step_max": 3.551701545715332, "timer/replay._sample_count": 21328.0, "timer/replay._sample_total": 11.683760404586792, "timer/replay._sample_frac": 0.01168341909464401, "timer/replay._sample_avg": 0.0005478132222705736, "timer/replay._sample_min": 0.0003879070281982422, "timer/replay._sample_max": 0.028231143951416016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3139.0, "timer/agent.policy_total": 52.74419665336609, "timer/agent.policy_frac": 0.052742655872134836, "timer/agent.policy_avg": 0.016802866088998437, "timer/agent.policy_min": 0.009753227233886719, "timer/agent.policy_max": 0.10069680213928223, "timer/dataset_train_count": 1333.0, "timer/dataset_train_total": 0.1561293601989746, "timer/dataset_train_frac": 0.0001561247992955368, "timer/dataset_train_avg": 0.00011712630172466212, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0004303455352783203, "timer/agent.train_count": 1333.0, "timer/agent.train_total": 600.0516657829285, "timer/agent.train_frac": 0.6000341368716343, "timer/agent.train_avg": 0.4501512871589861, "timer/agent.train_min": 0.437206506729126, "timer/agent.train_max": 1.3476545810699463, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755268096923828, "timer/agent.report_frac": 0.0004755129184431114, "timer/agent.report_avg": 0.2377634048461914, "timer/agent.report_min": 0.23098182678222656, "timer/agent.report_max": 0.24454498291015625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170874470692153e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 21.335126137099362}
{"step": 44104, "time": 2347.836507320404, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 44104, "time": 2347.8450632095337, "episode/length": 318.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 44296, "time": 2357.6818132400513, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 44552, "time": 2367.7059020996094, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 44824, "time": 2378.5427248477936, "episode/length": 173.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 45104, "time": 2389.7068231105804, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 45352, "time": 2399.3888103961945, "episode/length": 233.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 45608, "time": 2409.6247227191925, "episode/length": 97.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 45752, "time": 2416.059984922409, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 45800, "time": 2419.3769590854645, "episode/length": 155.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 45872, "time": 2423.5782794952393, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 46136, "time": 2433.6890680789948, "episode/length": 435.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 46632, "time": 2452.125232696533, "episode/length": 190.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 46808, "time": 2459.3805944919586, "episode/length": 149.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 46832, "time": 2462.0125756263733, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 46864, "time": 2464.5862095355988, "episode/length": 344.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 47064, "time": 2472.739645242691, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 47184, "time": 2478.5696568489075, "episode/length": 178.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 47416, "time": 2487.8713150024414, "episode/length": 201.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 47896, "time": 2505.5664389133453, "episode/length": 219.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 48040, "time": 2511.941870689392, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 48064, "time": 2514.5444679260254, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 48208, "time": 2520.981701850891, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 48520, "time": 2532.9926512241364, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 48608, "time": 2537.690770626068, "episode/length": 88.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 48632, "time": 2539.884367465973, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 48680, "time": 2543.040544271469, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 49056, "time": 2557.51962351799, "episode/length": 105.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 49080, "time": 2559.6471128463745, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 49184, "time": 2566.4740600585938, "episode/length": 139.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 49496, "time": 2578.737772703171, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 49664, "time": 2586.209096431732, "episode/length": 59.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 49760, "time": 2590.8569185733795, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2617.1291031837463, "eval_episode/length": 59.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 50024, "time": 2623.2013528347015, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 50024, "time": 2625.4614481925964, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 50024, "time": 2627.1767671108246, "eval_episode/length": 185.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 50024, "time": 2629.178232192993, "eval_episode/length": 193.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 50024, "time": 2632.2177028656006, "eval_episode/length": 224.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 50024, "time": 2633.81125497818, "eval_episode/length": 226.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 50024, "time": 2637.621277332306, "eval_episode/length": 52.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9245283018867925}
{"step": 50080, "time": 2639.7419714927673, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 50328, "time": 2649.462322950363, "episode/length": 211.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 50336, "time": 2651.5001447200775, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 50376, "time": 2654.303510904312, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 50704, "time": 2667.053026199341, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 50776, "time": 2670.789153814316, "episode/length": 159.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 50792, "time": 2672.995203256607, "episode/length": 140.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 50824, "time": 2675.799097299576, "episode/length": 55.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 51072, "time": 2685.889039039612, "episode/length": 91.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 51144, "time": 2689.68172454834, "episode/length": 257.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 51288, "time": 2696.1891593933105, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 51592, "time": 2708.246759414673, "episode/length": 99.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 51896, "time": 2720.068692445755, "episode/length": 75.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 52016, "time": 2725.8860981464386, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 52048, "time": 2728.523703098297, "episode/length": 152.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 52080, "time": 2731.2555360794067, "episode/length": 249.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 52080, "time": 2731.2636737823486, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 52176, "time": 2737.961315870285, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 52248, "time": 2741.7188453674316, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 52944, "time": 2767.1945400238037, "episode/length": 224.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 53232, "time": 2778.481627225876, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 53432, "time": 2786.613095998764, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 53464, "time": 2789.2786264419556, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 53520, "time": 2792.984297513962, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 53560, "time": 2795.7907285690308, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 53648, "time": 2800.498603820801, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 53800, "time": 2806.9321587085724, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 54208, "time": 2822.413243532181, "episode/length": 50.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 54512, "time": 2834.8688044548035, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 54544, "time": 2838.0475883483887, "episode/length": 199.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 54648, "time": 2843.392897129059, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 54696, "time": 2846.5462086200714, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 54720, "time": 2849.05348277092, "episode/length": 63.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 54800, "time": 2853.3242526054382, "episode/length": 159.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 54808, "time": 2855.1395349502563, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 54848, "time": 2858.3964676856995, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 54848, "time": 2858.4022138118744, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 56056, "time": 2902.1699655056, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 56176, "time": 2908.1189296245575, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 56288, "time": 2913.5449900627136, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 56304, "time": 2915.7675216197968, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 56304, "time": 2915.7746987342834, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 56320, "time": 2919.5403695106506, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 56648, "time": 2931.7978892326355, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 56696, "time": 2935.20961022377, "episode/length": 236.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 57552, "time": 2967.201267719269, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 57560, "time": 2968.7748470306396, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 57568, "time": 2970.8097715377808, "episode/length": 157.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 57696, "time": 2976.7320392131805, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 57920, "time": 2985.9312176704407, "episode/length": 45.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9347826086956522, "episode/intrinsic_return": 0.0}
{"step": 57960, "time": 2988.674471616745, "episode/length": 222.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 57992, "time": 2991.345808029175, "episode/length": 212.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 58232, "time": 3000.9661140441895, "episode/length": 82.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 58328, "time": 3005.9359726905823, "episode/length": 209.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 58576, "time": 3016.2102766036987, "episode/length": 234.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 58800, "time": 3025.19402885437, "episode/length": 154.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 59152, "time": 3038.683674097061, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 59176, "time": 3041.0144913196564, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 59256, "time": 3045.1900136470795, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 59280, "time": 3047.7263736724854, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 59480, "time": 3055.746530532837, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 59488, "time": 3057.8464167118073, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 59904, "time": 3073.625811100006, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3093.0499901771545, "eval_episode/length": 43.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8863636363636364}
{"step": 60008, "time": 3096.940638065338, "eval_episode/length": 97.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9489795918367347}
{"step": 60008, "time": 3100.7169575691223, "eval_episode/length": 150.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 60008, "time": 3104.164850473404, "eval_episode/length": 186.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 60008, "time": 3106.3261983394623, "eval_episode/length": 191.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 60008, "time": 3108.467432498932, "eval_episode/length": 192.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 60008, "time": 3110.879729270935, "eval_episode/length": 203.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 60008, "time": 3112.699634075165, "eval_episode/length": 208.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 60400, "time": 3126.136504173279, "episode/length": 113.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 60744, "time": 3139.190229654312, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 60760, "time": 3141.3376038074493, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 60888, "time": 3147.188217163086, "episode/length": 175.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 61072, "time": 3155.3235387802124, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 61112, "time": 3158.092121362686, "episode/length": 150.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 61120, "time": 3160.2308275699615, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 61592, "time": 3177.499747991562, "episode/length": 301.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 61616, "time": 3180.59379029274, "episode/length": 151.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 62032, "time": 3197.0318372249603, "episode/length": 51.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 62368, "time": 3210.01734995842, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 62376, "time": 3211.5870077610016, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 62384, "time": 3213.6850004196167, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 62456, "time": 3217.5285272598267, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 62568, "time": 3222.891271829605, "episode/length": 23.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 62744, "time": 3230.387875318527, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 62992, "time": 3240.589189052582, "episode/length": 119.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 63168, "time": 3248.312893152237, "episode/length": 52.0, "episode/score": -0.8999999985098839, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 63256, "time": 3252.6209099292755, "episode/length": 313.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904458598726115, "episode/intrinsic_return": 0.0}
{"step": 63712, "time": 3269.629369735718, "episode/length": 156.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 63808, "time": 3274.417650461197, "episode/length": 276.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9927797833935018, "episode/intrinsic_return": 0.0}
{"step": 63856, "time": 3277.620290517807, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 64240, "time": 3292.0826437473297, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 64312, "time": 3295.8259258270264, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 64400, "time": 3300.8841021060944, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 64920, "time": 3320.0804586410522, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 64928, "time": 3322.1933164596558, "episode/length": 133.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 65040, "time": 3327.610429048538, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 65328, "time": 3338.837702035904, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 65497, "time": 3346.808466911316, "train_stats/sum_log_reward": 2.6439999418258666, "train_stats/max_log_achievement_collect_drink": 14.024, "train_stats/max_log_achievement_collect_sapling": 1.52, "train_stats/max_log_achievement_collect_wood": 0.856, "train_stats/max_log_achievement_defeat_zombie": 0.128, "train_stats/max_log_achievement_eat_cow": 0.04, "train_stats/max_log_achievement_place_plant": 1.16, "train_stats/max_log_achievement_place_table": 0.064, "train_stats/max_log_achievement_wake_up": 1.976, "train_stats/mean_log_entropy": 0.6628703248500823, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.333195472831156, "train/action_min": 0.0, "train/action_std": 3.5497079571681236, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049200115030381214, "train/actor_opt_grad_steps": 3325.0, "train/actor_opt_loss": 35.90433232808736, "train/adv_mag": 1.4434810369762021, "train/adv_max": 1.4428835359971914, "train/adv_mean": 0.010146974384612682, "train/adv_min": -0.5659543502686629, "train/adv_std": 0.11241776268206426, "train/cont_avg": 0.9942426539179104, "train/cont_loss_mean": 0.0009733162328166824, "train/cont_loss_std": 0.02314273197463257, "train/cont_neg_acc": 0.9707859558845634, "train/cont_neg_loss": 0.07423440760617472, "train/cont_pos_acc": 0.9998608663010953, "train/cont_pos_loss": 0.0005116425496447364, "train/cont_pred": 0.9941884728509989, "train/cont_rate": 0.9942426539179104, "train/dyn_loss_mean": 7.4209187884828935, "train/dyn_loss_std": 6.616977716559794, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2718197512092875, "train/extr_critic_critic_opt_grad_steps": 3325.0, "train/extr_critic_critic_opt_loss": 15443.032590951492, "train/extr_critic_mag": 2.2386437743457397, "train/extr_critic_max": 2.2386437743457397, "train/extr_critic_mean": 0.5716023813210317, "train/extr_critic_min": -0.17698980356330302, "train/extr_critic_std": 0.6423742101708455, "train/extr_return_normed_mag": 2.1786203793625334, "train/extr_return_normed_max": 2.1786203793625334, "train/extr_return_normed_mean": 0.34971340901371256, "train/extr_return_normed_min": -0.21907477066921655, "train/extr_return_normed_std": 0.35490155831646564, "train/extr_return_rate": 0.358959615341763, "train/extr_return_raw_mag": 4.1228542505805175, "train/extr_return_raw_max": 4.1228542505805175, "train/extr_return_raw_mean": 0.5909080176211116, "train/extr_return_raw_min": -0.5071209330500951, "train/extr_return_raw_std": 0.685916629522594, "train/extr_reward_mag": 1.000033395503884, "train/extr_reward_max": 1.000033395503884, "train/extr_reward_mean": 0.011937997402943004, "train/extr_reward_min": -0.3588033816707668, "train/extr_reward_std": 0.08787429710822318, "train/image_loss_mean": 18.16658325337652, "train/image_loss_std": 21.241616768623466, "train/model_loss_mean": 22.67913160039418, "train/model_loss_std": 23.549132532148217, "train/model_opt_grad_norm": 145.29655715600768, "train/model_opt_grad_steps": 3316.0, "train/model_opt_loss": 3085.2350281672693, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 135.26119402985074, "train/policy_entropy_mag": 2.2965423082237812, "train/policy_entropy_max": 2.2965423082237812, "train/policy_entropy_mean": 0.6567332026228976, "train/policy_entropy_min": 0.07954000714999526, "train/policy_entropy_std": 0.46524598571791576, "train/policy_logprob_mag": 7.4371851842794845, "train/policy_logprob_max": -0.00947868682916707, "train/policy_logprob_mean": -0.6554912815787899, "train/policy_logprob_min": -7.4371851842794845, "train/policy_logprob_std": 1.154880899991562, "train/policy_randomness_mag": 0.8105786540615025, "train/policy_randomness_max": 0.8105786540615025, "train/policy_randomness_mean": 0.2317980025241624, "train/policy_randomness_min": 0.028074131972754178, "train/policy_randomness_std": 0.16421141497679612, "train/post_ent_mag": 44.27494567187864, "train/post_ent_max": 44.27494567187864, "train/post_ent_mean": 31.588919724991072, "train/post_ent_min": 14.731538452319246, "train/post_ent_std": 4.91400393977094, "train/prior_ent_mag": 56.416861605288375, "train/prior_ent_max": 56.416861605288375, "train/prior_ent_mean": 39.16429553814788, "train/prior_ent_min": 16.86241014679866, "train/prior_ent_std": 6.435847396281228, "train/rep_loss_mean": 7.4209187884828935, "train/rep_loss_std": 6.616977716559794, "train/reward_avg": 0.010200705339284197, "train/reward_loss_mean": 0.05902377874659958, "train/reward_loss_std": 0.3095253105483838, "train/reward_max_data": 1.0037313441732036, "train/reward_max_pred": 0.998159075850871, "train/reward_neg_acc": 0.9941383524617152, "train/reward_neg_loss": 0.040292329571918764, "train/reward_pos_acc": 0.888528652600388, "train/reward_pos_loss": 1.2676483486125718, "train/reward_pred": 0.009431733893154106, "train/reward_rate": 0.015413654384328358, "eval_stats/sum_log_reward": 1.849999944679439, "eval_stats/max_log_achievement_collect_drink": 9.4375, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_wood": 0.6875, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.6875, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 2.3125, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.07142857142857142, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.09090909090909091, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.7846780691761523e-05, "report/cont_loss_std": 0.0010799048468470573, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003097882494330406, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.8914258513832465e-05, "report/cont_pred": 0.9970311522483826, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 7.757252216339111, "report/dyn_loss_std": 7.172624111175537, "report/image_loss_mean": 13.571328163146973, "report/image_loss_std": 14.183051109313965, "report/model_loss_mean": 18.268253326416016, "report/model_loss_std": 17.22713851928711, "report/post_ent_mag": 46.111366271972656, "report/post_ent_max": 46.111366271972656, "report/post_ent_mean": 32.353851318359375, "report/post_ent_min": 16.078392028808594, "report/post_ent_std": 5.124467372894287, "report/prior_ent_mag": 58.07273864746094, "report/prior_ent_max": 58.07273864746094, "report/prior_ent_mean": 40.512855529785156, "report/prior_ent_min": 19.994125366210938, "report/prior_ent_std": 7.13581657409668, "report/rep_loss_mean": 7.757252216339111, "report/rep_loss_std": 7.172624111175537, "report/reward_avg": 0.014160157181322575, "report/reward_loss_mean": 0.04251609742641449, "report/reward_loss_std": 0.2708679437637329, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9982703924179077, "report/reward_neg_acc": 0.9970149993896484, "report/reward_neg_loss": 0.020587841048836708, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 1.2024054527282715, "report/reward_pred": 0.011768387630581856, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.001879616524092853, "eval/cont_loss_std": 0.042182594537734985, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 0.14205381274223328, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.000914798816666007, "eval/cont_pred": 0.9931922554969788, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 12.26732063293457, "eval/dyn_loss_std": 7.599461555480957, "eval/image_loss_mean": 31.861696243286133, "eval/image_loss_std": 41.46146011352539, "eval/model_loss_mean": 39.289764404296875, "eval/model_loss_std": 43.50679397583008, "eval/post_ent_mag": 42.381744384765625, "eval/post_ent_max": 42.381744384765625, "eval/post_ent_mean": 30.082448959350586, "eval/post_ent_min": 16.63933563232422, "eval/post_ent_std": 4.495737075805664, "eval/prior_ent_mag": 57.822879791259766, "eval/prior_ent_max": 57.822879791259766, "eval/prior_ent_mean": 39.94431686401367, "eval/prior_ent_min": 17.679973602294922, "eval/prior_ent_std": 6.921806812286377, "eval/rep_loss_mean": 12.26732063293457, "eval/rep_loss_std": 7.599461555480957, "eval/reward_avg": 0.004003905691206455, "eval/reward_loss_mean": 0.06579357385635376, "eval/reward_loss_std": 0.4624786376953125, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9988338947296143, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.037426333874464035, "eval/reward_pos_acc": 0.4545454680919647, "eval/reward_pos_loss": 2.678159713745117, "eval/reward_pred": -0.00097595842089504, "eval/reward_rate": 0.0107421875, "replay/size": 64993.0, "replay/inserts": 21432.0, "replay/samples": 21440.0, "replay/insert_wait_avg": 1.42766362297397e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.035697424589698e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14168.0, "eval_replay/inserts": 3912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2409101965968594e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.310715675354, "timer/env.step_count": 2679.0, "timer/env.step_total": 273.42970633506775, "timer/env.step_frac": 0.27334477382906297, "timer/env.step_avg": 0.10206409344347434, "timer/env.step_min": 0.02254319190979004, "timer/env.step_max": 3.4721271991729736, "timer/replay._sample_count": 21440.0, "timer/replay._sample_total": 11.930673122406006, "timer/replay._sample_frac": 0.011926967226729228, "timer/replay._sample_avg": 0.0005564679627987876, "timer/replay._sample_min": 0.0003972053527832031, "timer/replay._sample_max": 0.008940458297729492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3168.0, "timer/agent.policy_total": 53.876667976379395, "timer/agent.policy_frac": 0.053859932850969086, "timer/agent.policy_avg": 0.01700652398244299, "timer/agent.policy_min": 0.009865045547485352, "timer/agent.policy_max": 0.09849357604980469, "timer/dataset_train_count": 1340.0, "timer/dataset_train_total": 0.15882062911987305, "timer/dataset_train_frac": 0.00015877129638928862, "timer/dataset_train_avg": 0.00011852285755214407, "timer/dataset_train_min": 0.00010466575622558594, "timer/dataset_train_max": 0.0007255077362060547, "timer/agent.train_count": 1340.0, "timer/agent.train_total": 604.7773008346558, "timer/agent.train_frac": 0.6045894454168111, "timer/agent.train_avg": 0.45132634390645954, "timer/agent.train_min": 0.4368288516998291, "timer/agent.train_max": 1.4116699695587158, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47835850715637207, "timer/agent.report_frac": 0.0004782099198381686, "timer/agent.report_avg": 0.23917925357818604, "timer/agent.report_min": 0.23049473762512207, "timer/agent.report_max": 0.24786376953125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1699821389096296e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 21.425071626883632}
{"step": 65520, "time": 3347.514352083206, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 65584, "time": 3352.9310534000397, "episode/length": 399.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 66080, "time": 3371.3601179122925, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 66152, "time": 3375.2070519924164, "episode/length": 78.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9493670886075949, "episode/intrinsic_return": 0.0}
{"step": 66200, "time": 3378.4177942276, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 66232, "time": 3381.231934785843, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 66232, "time": 3381.2395923137665, "episode/length": 228.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 66432, "time": 3391.668046236038, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 66528, "time": 3397.0541644096375, "episode/length": 55.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 66832, "time": 3408.939504623413, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 66848, "time": 3411.0308673381805, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 67304, "time": 3427.5382628440857, "episode/length": 108.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 67328, "time": 3430.218031167984, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 67440, "time": 3435.569381713867, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 67592, "time": 3441.9258918762207, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 67768, "time": 3449.3987262248993, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 68312, "time": 3469.0912747383118, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 68456, "time": 3475.6113963127136, "episode/length": 277.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 68528, "time": 3479.8229715824127, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 68576, "time": 3483.0329933166504, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 68944, "time": 3497.2765641212463, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 68952, "time": 3499.2837517261505, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 69384, "time": 3516.00790309906, "episode/length": 201.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 69864, "time": 3534.015683889389, "episode/length": 166.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 69984, "time": 3539.8298346996307, "episode/length": 190.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 70064, "time": 3544.035290002823, "episode/length": 24.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.84, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3566.625655412674, "eval_episode/length": 161.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 70096, "time": 3568.283551454544, "eval_episode/length": 163.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 70096, "time": 3569.9336783885956, "eval_episode/length": 165.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 70096, "time": 3572.39972114563, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 70096, "time": 3574.619253396988, "eval_episode/length": 197.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 70096, "time": 3578.118498802185, "eval_episode/length": 219.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 70096, "time": 3582.628228187561, "eval_episode/length": 251.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 70096, "time": 3584.9281284809113, "eval_episode/length": 254.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9882352941176471}
{"step": 70264, "time": 3590.545889854431, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 70288, "time": 3593.553792953491, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 70480, "time": 3601.5460731983185, "episode/length": 237.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 70640, "time": 3608.7655210494995, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 70872, "time": 3617.8548271656036, "episode/length": 428.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 71488, "time": 3640.5185816287994, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 71512, "time": 3642.587131023407, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 71584, "time": 3646.684643268585, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 71616, "time": 3649.2138426303864, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 71720, "time": 3654.1554901599884, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 71848, "time": 3660.0204219818115, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 72208, "time": 3673.9898619651794, "episode/length": 44.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 72248, "time": 3676.676368713379, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 72392, "time": 3683.076061964035, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 73032, "time": 3706.2896399497986, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 73032, "time": 3706.309136867523, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 73152, "time": 3714.1558582782745, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 73232, "time": 3718.388816356659, "episode/length": 217.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 73336, "time": 3723.1565811634064, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 73688, "time": 3736.6615149974823, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 73992, "time": 3749.6657123565674, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 74024, "time": 3752.333674430847, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 74320, "time": 3763.9583525657654, "episode/length": 145.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 74536, "time": 3772.548403978348, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 74688, "time": 3779.42848610878, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 74856, "time": 3786.5619888305664, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 74864, "time": 3789.004012107849, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 75152, "time": 3800.8346889019012, "episode/length": 35.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 75248, "time": 3805.693720817566, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 75304, "time": 3808.90767288208, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 75888, "time": 3830.607747077942, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 75944, "time": 3834.2849538326263, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 76088, "time": 3841.232406616211, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 76336, "time": 3852.064201116562, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 76400, "time": 3855.7835097312927, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 76408, "time": 3857.3156723976135, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 76640, "time": 3866.8552889823914, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 76928, "time": 3878.127884864807, "episode/length": 221.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 77376, "time": 3895.3153054714203, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 77424, "time": 3899.103097677231, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 77656, "time": 3908.246971130371, "episode/length": 155.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 77960, "time": 3920.151228904724, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 78016, "time": 3924.4999916553497, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 78016, "time": 3924.5086858272552, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 78032, "time": 3929.2745904922485, "episode/length": 267.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 78824, "time": 3957.7709934711456, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 78984, "time": 3965.079509973526, "episode/length": 165.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 79240, "time": 3975.3479838371277, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 79384, "time": 3982.3171825408936, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 79544, "time": 3989.2741169929504, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 79696, "time": 3996.2159581184387, "episode/length": 283.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 79720, "time": 3998.3690190315247, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 80024, "time": 4010.058942079544, "episode/length": 79.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4029.38751912117, "eval_episode/length": 58.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9152542372881356}
{"step": 80080, "time": 4032.7695524692535, "eval_episode/length": 85.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9418604651162791}
{"step": 80080, "time": 4036.957098722458, "eval_episode/length": 143.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 80080, "time": 4039.2108273506165, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 80080, "time": 4041.1217036247253, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 80080, "time": 4043.0619509220123, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 80080, "time": 4044.611814260483, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 80080, "time": 4046.643585205078, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 80176, "time": 4049.8479764461517, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 80384, "time": 4058.875121116638, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 80584, "time": 4067.21874666214, "episode/length": 167.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 80760, "time": 4075.3653588294983, "episode/length": 422.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 81184, "time": 4091.5264110565186, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 81472, "time": 4103.19171500206, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 81608, "time": 4110.087803840637, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 81880, "time": 4120.91459441185, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 82024, "time": 4128.730466127396, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 82168, "time": 4135.158983707428, "episode/length": 86.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 82208, "time": 4138.423441886902, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 82392, "time": 4146.017634868622, "episode/length": 150.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 82568, "time": 4153.460494995117, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 82672, "time": 4158.726252317429, "episode/length": 390.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9872122762148338, "episode/intrinsic_return": 0.0}
{"step": 83152, "time": 4176.663672685623, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 83160, "time": 4178.267101049423, "episode/length": 159.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 83552, "time": 4193.257256746292, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 83768, "time": 4201.873371601105, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 83824, "time": 4205.675964832306, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 83848, "time": 4208.018151760101, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 84280, "time": 4224.0480744838715, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 84664, "time": 4238.711493968964, "episode/length": 248.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 85024, "time": 4252.773902177811, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 85024, "time": 4252.781754732132, "episode/length": 232.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 85168, "time": 4260.912887096405, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 85232, "time": 4265.011116981506, "episode/length": 259.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 85368, "time": 4270.789958238602, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 85640, "time": 4281.5311443805695, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 85920, "time": 4293.340459108353, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 86016, "time": 4298.1451733112335, "episode/length": 46.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 86072, "time": 4301.466066837311, "episode/length": 223.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 86272, "time": 4309.978209257126, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 86496, "time": 4319.135924577713, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 86544, "time": 4322.278573036194, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 86624, "time": 4326.620951414108, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 86688, "time": 4330.2658751010895, "episode/length": 189.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 87113, "time": 4347.004723548889, "train_stats/sum_log_reward": 3.4999999673470206, "train_stats/max_log_achievement_collect_drink": 10.08695652173913, "train_stats/max_log_achievement_collect_sapling": 2.643478260869565, "train_stats/max_log_achievement_collect_wood": 1.6347826086956523, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "train_stats/max_log_achievement_defeat_zombie": 0.2956521739130435, "train_stats/max_log_achievement_eat_cow": 0.0782608695652174, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.382608695652174, "train_stats/max_log_achievement_place_table": 0.1565217391304348, "train_stats/max_log_achievement_wake_up": 2.1913043478260867, "train_stats/mean_log_entropy": 0.8198834178240403, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.657215259693287, "train/action_min": 0.0, "train/action_std": 3.173812569512261, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051230258053099664, "train/actor_opt_grad_steps": 4670.0, "train/actor_opt_loss": 34.66705369805848, "train/adv_mag": 1.1319801551324349, "train/adv_max": 1.13169177947221, "train/adv_mean": 0.00909773197194294, "train/adv_min": -0.5286093561737626, "train/adv_std": 0.09695264341102706, "train/cont_avg": 0.9942708333333333, "train/cont_loss_mean": 0.0007546972588805282, "train/cont_loss_std": 0.020249600405777866, "train/cont_neg_acc": 0.9796472703969037, "train/cont_neg_loss": 0.06289463176324682, "train/cont_pos_acc": 0.9998689859001725, "train/cont_pos_loss": 0.00035430042929438687, "train/cont_pred": 0.9942328144002843, "train/cont_rate": 0.9942708333333333, "train/dyn_loss_mean": 9.347810540375885, "train/dyn_loss_std": 7.605026707825838, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2131641860361453, "train/extr_critic_critic_opt_grad_steps": 4670.0, "train/extr_critic_critic_opt_loss": 14590.931221064815, "train/extr_critic_mag": 2.6052228256508156, "train/extr_critic_max": 2.6052228256508156, "train/extr_critic_mean": 0.7804788443777296, "train/extr_critic_min": -0.09974146242494937, "train/extr_critic_std": 0.7376735417931168, "train/extr_return_normed_mag": 1.9929541128653068, "train/extr_return_normed_max": 1.9929541128653068, "train/extr_return_normed_mean": 0.3527353955639733, "train/extr_return_normed_min": -0.21179383490924483, "train/extr_return_normed_std": 0.35491524117964285, "train/extr_return_rate": 0.45079670636742203, "train/extr_return_raw_mag": 4.430538809740985, "train/extr_return_raw_max": 4.430538809740985, "train/extr_return_raw_mean": 0.8005535337660048, "train/extr_return_raw_min": -0.44822836882538264, "train/extr_return_raw_std": 0.7859551858018946, "train/extr_reward_mag": 1.0026890710548118, "train/extr_reward_max": 1.0026890710548118, "train/extr_reward_mean": 0.013971018473859186, "train/extr_reward_min": -0.31909131473965113, "train/extr_reward_std": 0.097666618945422, "train/image_loss_mean": 17.761984252929686, "train/image_loss_std": 19.147726362722892, "train/model_loss_mean": 23.426911460028755, "train/model_loss_std": 22.40944909696226, "train/model_opt_grad_norm": 108.25961145471643, "train/model_opt_grad_steps": 4661.0, "train/model_opt_loss": 9032.553311270254, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 386.5740740740741, "train/policy_entropy_mag": 2.4892562124464246, "train/policy_entropy_max": 2.4892562124464246, "train/policy_entropy_mean": 0.8098289335215533, "train/policy_entropy_min": 0.07942141752552104, "train/policy_entropy_std": 0.5488332170027274, "train/policy_logprob_mag": 7.437870170451976, "train/policy_logprob_max": -0.009462613343364663, "train/policy_logprob_mean": -0.8092310958438449, "train/policy_logprob_min": -7.437870170451976, "train/policy_logprob_std": 1.224487829208374, "train/policy_randomness_mag": 0.8785982048069989, "train/policy_randomness_max": 0.8785982048069989, "train/policy_randomness_mean": 0.2858340725854591, "train/policy_randomness_min": 0.028032275040944417, "train/policy_randomness_std": 0.1937140425046285, "train/post_ent_mag": 46.52179689760561, "train/post_ent_max": 46.52179689760561, "train/post_ent_mean": 33.38083301120334, "train/post_ent_min": 17.180948363410103, "train/post_ent_std": 4.976478645536635, "train/prior_ent_mag": 59.11020225242332, "train/prior_ent_max": 59.11020225242332, "train/prior_ent_mean": 42.958281170880355, "train/prior_ent_min": 20.11929362261737, "train/prior_ent_std": 7.332044364787914, "train/rep_loss_mean": 9.347810540375885, "train/rep_loss_std": 7.605026707825838, "train/reward_avg": 0.012586082106766601, "train/reward_loss_mean": 0.05548617314133379, "train/reward_loss_std": 0.2903867425741973, "train/reward_max_data": 1.0037037045867354, "train/reward_max_pred": 1.0006953380726002, "train/reward_neg_acc": 0.9936641975685402, "train/reward_neg_loss": 0.035953258336694154, "train/reward_pos_acc": 0.9126821416395682, "train/reward_pos_loss": 1.1500995428473861, "train/reward_pred": 0.011582897138712859, "train/reward_rate": 0.01775173611111111, "eval_stats/sum_log_reward": 3.1624999111518264, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_sapling": 3.1875, "eval_stats/max_log_achievement_collect_wood": 1.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_table": 0.3125, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03333333333333333, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.570065771578811e-05, "report/cont_loss_std": 0.0007905105012468994, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0037122212816029787, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.2637782965139195e-07, "report/cont_pred": 0.9931888580322266, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 10.156705856323242, "report/dyn_loss_std": 7.5936503410339355, "report/image_loss_mean": 14.397924423217773, "report/image_loss_std": 15.702895164489746, "report/model_loss_mean": 20.554054260253906, "report/model_loss_std": 18.870105743408203, "report/post_ent_mag": 43.472900390625, "report/post_ent_max": 43.472900390625, "report/post_ent_mean": 32.40498352050781, "report/post_ent_min": 18.45763397216797, "report/post_ent_std": 4.3229875564575195, "report/prior_ent_mag": 60.881343841552734, "report/prior_ent_max": 60.881343841552734, "report/prior_ent_mean": 43.72028732299805, "report/prior_ent_min": 21.624080657958984, "report/prior_ent_std": 7.1802802085876465, "report/rep_loss_mean": 10.156705856323242, "report/rep_loss_std": 7.5936503410339355, "report/reward_avg": 0.02255859225988388, "report/reward_loss_mean": 0.06208072602748871, "report/reward_loss_std": 0.31141966581344604, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0019402503967285, "report/reward_neg_acc": 0.991959810256958, "report/reward_neg_loss": 0.027761632576584816, "report/reward_pos_acc": 0.8620689511299133, "report/reward_pos_loss": 1.2395806312561035, "report/reward_pred": 0.018993504345417023, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00023173798399511725, "eval/cont_loss_std": 0.006595495622605085, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00022333413653541356, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00023177922412287444, "eval/cont_pred": 0.9949080348014832, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 13.416640281677246, "eval/dyn_loss_std": 7.928301811218262, "eval/image_loss_mean": 26.710044860839844, "eval/image_loss_std": 31.983341217041016, "eval/model_loss_mean": 34.81767272949219, "eval/model_loss_std": 34.414066314697266, "eval/post_ent_mag": 41.97380065917969, "eval/post_ent_max": 41.97380065917969, "eval/post_ent_mean": 30.565387725830078, "eval/post_ent_min": 16.203392028808594, "eval/post_ent_std": 4.563305854797363, "eval/prior_ent_mag": 59.71412658691406, "eval/prior_ent_max": 59.71412658691406, "eval/prior_ent_mean": 41.84452819824219, "eval/prior_ent_min": 18.396495819091797, "eval/prior_ent_std": 7.4794020652771, "eval/rep_loss_mean": 13.416640281677246, "eval/rep_loss_std": 7.928301811218262, "eval/reward_avg": 0.01318359375, "eval/reward_loss_mean": 0.057412564754486084, "eval/reward_loss_std": 0.4166584610939026, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9952273368835449, "eval/reward_neg_acc": 0.9990060329437256, "eval/reward_neg_loss": 0.023757580667734146, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 1.938352346420288, "eval/reward_pred": 0.006204546429216862, "eval/reward_rate": 0.017578125, "replay/size": 86609.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.4370631324547824e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.04908145506412e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17680.0, "eval_replay/inserts": 3512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3227750608752692e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1847579479218, "timer/env.step_count": 2702.0, "timer/env.step_total": 265.026437997818, "timer/env.step_frac": 0.2649774813021271, "timer/env.step_avg": 0.09808528423309326, "timer/env.step_min": 0.02264571189880371, "timer/env.step_max": 4.224963903427124, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 12.053082704544067, "timer/replay._sample_frac": 0.012050856213079438, "timer/replay._sample_avg": 0.0005576000510984487, "timer/replay._sample_min": 0.0004279613494873047, "timer/replay._sample_max": 0.011452913284301758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3141.0, "timer/agent.policy_total": 54.157039165496826, "timer/agent.policy_frac": 0.05414703507041117, "timer/agent.policy_avg": 0.017241973627983707, "timer/agent.policy_min": 0.009719133377075195, "timer/agent.policy_max": 0.13777542114257812, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.15976905822753906, "timer/dataset_train_frac": 0.0001597395450769887, "timer/dataset_train_avg": 0.00011825985064954778, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.001070261001586914, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 612.0792472362518, "timer/agent.train_frac": 0.6119661816203381, "timer/agent.train_avg": 0.4530564376286098, "timer/agent.train_min": 0.43619489669799805, "timer/agent.train_max": 1.4493117332458496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47655701637268066, "timer/agent.report_frac": 0.00047646898494077463, "timer/agent.report_avg": 0.23827850818634033, "timer/agent.report_min": 0.231903076171875, "timer/agent.report_max": 0.24465394020080566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051194080143042e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.611730003770386}
{"step": 87368, "time": 4355.458993911743, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 87688, "time": 4367.81382727623, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 87704, "time": 4369.890462875366, "episode/length": 203.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 87872, "time": 4377.39479970932, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 88056, "time": 4384.959844827652, "episode/length": 222.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 88256, "time": 4393.429981946945, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 88344, "time": 4397.788155078888, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 88384, "time": 4400.941964864731, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 88656, "time": 4411.727728128433, "episode/length": 33.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 88952, "time": 4423.38015627861, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 89144, "time": 4431.466550827026, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 89224, "time": 4435.725490808487, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 89440, "time": 4444.7783987522125, "episode/length": 195.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 89520, "time": 4449.13577246666, "episode/length": 146.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 89848, "time": 4461.524572610855, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 89952, "time": 4466.761220693588, "episode/length": 161.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4491.910974740982, "eval_episode/length": 141.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 90064, "time": 4493.769961833954, "eval_episode/length": 148.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 90064, "time": 4496.042551040649, "eval_episode/length": 163.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 90064, "time": 4499.647550344467, "eval_episode/length": 208.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 90064, "time": 4501.372149944305, "eval_episode/length": 211.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 90064, "time": 4503.30059170723, "eval_episode/length": 220.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 90064, "time": 4505.966917514801, "eval_episode/length": 242.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 90064, "time": 4507.627304553986, "eval_episode/length": 36.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.972972972972973}
{"step": 90352, "time": 4518.761592626572, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 90760, "time": 4533.9209949970245, "episode/length": 154.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 90944, "time": 4541.958252191544, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 90952, "time": 4543.595725774765, "episode/length": 225.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 91088, "time": 4549.963662624359, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 91512, "time": 4565.789948225021, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 91744, "time": 4576.090104103088, "episode/length": 460.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9978308026030369, "episode/intrinsic_return": 0.0}
{"step": 91840, "time": 4581.037015914917, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 91896, "time": 4584.31893658638, "episode/length": 306.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993485342019544, "episode/intrinsic_return": 0.0}
{"step": 92104, "time": 4592.9390115737915, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 92240, "time": 4599.794394016266, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 92528, "time": 4611.05751991272, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 92840, "time": 4622.872547388077, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 93096, "time": 4633.201436758041, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 93272, "time": 4640.695542573929, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 93312, "time": 4643.817722082138, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 93440, "time": 4649.694995641708, "episode/length": 211.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 93480, "time": 4652.446450948715, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 93696, "time": 4661.5350704193115, "episode/length": 272.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 93824, "time": 4667.550604343414, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 94440, "time": 4689.779752969742, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 94552, "time": 4695.207168102264, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 94672, "time": 4701.01211476326, "episode/length": 196.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 94752, "time": 4705.354022741318, "episode/length": 131.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 95240, "time": 4723.390833377838, "episode/length": 245.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 95328, "time": 4728.154781341553, "episode/length": 235.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 95464, "time": 4734.0032370090485, "episode/length": 247.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 95608, "time": 4740.484324455261, "episode/length": 222.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 95976, "time": 4754.500049591064, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 95984, "time": 4756.508125782013, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 96000, "time": 4758.674320936203, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 96072, "time": 4762.381802082062, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 96536, "time": 4779.75665807724, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 96784, "time": 4789.844651460648, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 96896, "time": 4795.222270011902, "episode/length": 160.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 97360, "time": 4812.377197504044, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 97488, "time": 4818.42609667778, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 97688, "time": 4826.546179294586, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 97880, "time": 4834.537944316864, "episode/length": 301.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 97984, "time": 4839.998083353043, "episode/length": 149.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 98088, "time": 4844.862515449524, "episode/length": 148.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 98168, "time": 4849.074774980545, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 98296, "time": 4855.067219257355, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 98776, "time": 4874.319296598434, "episode/length": 176.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 98912, "time": 4880.922944784164, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 99056, "time": 4887.31157207489, "episode/length": 381.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 99296, "time": 4897.024666547775, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 99496, "time": 4905.10114979744, "episode/length": 250.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 99720, "time": 4914.18820643425, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 99816, "time": 4918.877668142319, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 99880, "time": 4922.548414230347, "episode/length": 47.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 99944, "time": 4926.354823112488, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4946.407916545868, "eval_episode/length": 39.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 100048, "time": 4952.466772317886, "eval_episode/length": 140.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 100048, "time": 4954.535112380981, "eval_episode/length": 150.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 100048, "time": 4957.129220962524, "eval_episode/length": 171.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 100048, "time": 4959.5723078250885, "eval_episode/length": 192.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 100048, "time": 4961.234814405441, "eval_episode/length": 54.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 100048, "time": 4963.86572098732, "eval_episode/length": 218.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 100048, "time": 4965.541426897049, "eval_episode/length": 179.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 100544, "time": 4982.1437292099, "episode/length": 185.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 100568, "time": 4984.377627849579, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 100576, "time": 4986.534333229065, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 100608, "time": 4989.2871742248535, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 100816, "time": 4997.7257425785065, "episode/length": 29.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 100992, "time": 5005.300844669342, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 101256, "time": 5015.495698451996, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 101832, "time": 5036.345424413681, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 101864, "time": 5039.030212163925, "episode/length": 255.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 102240, "time": 5053.641286611557, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 102256, "time": 5055.757881402969, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 102352, "time": 5060.597889184952, "episode/length": 300.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 102512, "time": 5067.665589570999, "episode/length": 211.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 102864, "time": 5081.322169780731, "episode/length": 281.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 102872, "time": 5082.957752466202, "episode/length": 201.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 103248, "time": 5097.314627408981, "episode/length": 46.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 103672, "time": 5113.0088765621185, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 103696, "time": 5115.879034996033, "episode/length": 179.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 103920, "time": 5124.952333688736, "episode/length": 260.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 103992, "time": 5128.688461303711, "episode/length": 265.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 104040, "time": 5131.9368369579315, "episode/length": 210.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 104088, "time": 5135.22626376152, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 104232, "time": 5141.683255910873, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 104440, "time": 5150.180904150009, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 104888, "time": 5166.9702661037445, "episode/length": 151.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 105232, "time": 5180.4661257267, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 105240, "time": 5182.087687730789, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 105360, "time": 5187.9573402404785, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 105632, "time": 5198.767470121384, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 105632, "time": 5198.8738758563995, "episode/length": 198.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 105744, "time": 5205.803994417191, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 106072, "time": 5218.14172244072, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 106536, "time": 5236.735275506973, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 106624, "time": 5241.973228216171, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 106784, "time": 5249.242214441299, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 106968, "time": 5256.766609430313, "episode/length": 53.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 106984, "time": 5259.051884174347, "episode/length": 154.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 107152, "time": 5266.500679969788, "episode/length": 189.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 107224, "time": 5270.30025935173, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 107240, "time": 5272.406626462936, "episode/length": 250.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 107248, "time": 5274.435641288757, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 107624, "time": 5288.56680226326, "episode/length": 46.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 107888, "time": 5299.177240610123, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 108336, "time": 5315.712797164917, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 108352, "time": 5318.029355049133, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 108624, "time": 5328.742886543274, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 109056, "time": 5344.908912420273, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 109057, "time": 5347.152626514435, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.799193444913321, "train/action_min": 0.0, "train/action_std": 3.4963723656034817, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05101058515210221, "train/actor_opt_grad_steps": 6030.0, "train/actor_opt_loss": 5.250560963240853, "train/adv_mag": 0.9451751769894231, "train/adv_max": 0.9443074173300806, "train/adv_mean": 0.0049701938036524175, "train/adv_min": -0.5179785918580354, "train/adv_std": 0.08902643860256584, "train/cont_avg": 0.9943829835766423, "train/cont_loss_mean": 0.0006020062369191817, "train/cont_loss_std": 0.016534082952115118, "train/cont_neg_acc": 0.9873278500402675, "train/cont_neg_loss": 0.05315471340358404, "train/cont_pos_acc": 0.9999139274123812, "train/cont_pos_loss": 0.0002932605518514469, "train/cont_pred": 0.9943555667452568, "train/cont_rate": 0.9943829835766423, "train/dyn_loss_mean": 11.07996681658891, "train/dyn_loss_std": 8.190599298825228, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1478261595224812, "train/extr_critic_critic_opt_grad_steps": 6030.0, "train/extr_critic_critic_opt_loss": 15039.313654767337, "train/extr_critic_mag": 3.2021959193431546, "train/extr_critic_max": 3.2021959193431546, "train/extr_critic_mean": 0.8662146477803697, "train/extr_critic_min": -0.12907279320876963, "train/extr_critic_std": 0.8372162619646448, "train/extr_return_normed_mag": 1.9174636045511622, "train/extr_return_normed_max": 1.9174636045511622, "train/extr_return_normed_mean": 0.3372177428355182, "train/extr_return_normed_min": -0.20104647416920557, "train/extr_return_normed_std": 0.3476092378153418, "train/extr_return_rate": 0.46795546790979203, "train/extr_return_raw_mag": 4.88273805945459, "train/extr_return_raw_max": 4.88273805945459, "train/extr_return_raw_mean": 0.8788105375575324, "train/extr_return_raw_min": -0.4848780909376423, "train/extr_return_raw_std": 0.8806715068155831, "train/extr_reward_mag": 1.0037350428365444, "train/extr_reward_max": 1.0037350428365444, "train/extr_reward_mean": 0.016332969528344208, "train/extr_reward_min": -0.390866712932169, "train/extr_reward_std": 0.10905713239943024, "train/image_loss_mean": 16.231332027129014, "train/image_loss_std": 17.98217820077047, "train/model_loss_mean": 22.933943101089366, "train/model_loss_std": 21.53716296871213, "train/model_opt_grad_norm": 95.30756194400091, "train/model_opt_grad_steps": 6020.56204379562, "train/model_opt_loss": 15399.391608690694, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 670.6204379562043, "train/policy_entropy_mag": 2.5787444915214595, "train/policy_entropy_max": 2.5787444915214595, "train/policy_entropy_mean": 0.8824378339043499, "train/policy_entropy_min": 0.0793815468893434, "train/policy_entropy_std": 0.6669233471807772, "train/policy_logprob_mag": 7.438220400009712, "train/policy_logprob_max": -0.009457154804500786, "train/policy_logprob_mean": -0.8819989079106463, "train/policy_logprob_min": -7.438220400009712, "train/policy_logprob_std": 1.2560770172272286, "train/policy_randomness_mag": 0.9101836411622319, "train/policy_randomness_max": 0.9101836411622319, "train/policy_randomness_mean": 0.31146183011740664, "train/policy_randomness_min": 0.028018202387938534, "train/policy_randomness_std": 0.2353946735171506, "train/post_ent_mag": 48.66139808710474, "train/post_ent_max": 48.66139808710474, "train/post_ent_mean": 34.66620173767535, "train/post_ent_min": 18.918843032669848, "train/post_ent_std": 5.1005246517432, "train/prior_ent_mag": 60.74671420911803, "train/prior_ent_max": 60.74671420911803, "train/prior_ent_mean": 45.89360310909522, "train/prior_ent_min": 22.566173985056633, "train/prior_ent_std": 7.458306201183013, "train/rep_loss_mean": 11.07996681658891, "train/rep_loss_std": 8.190599298825228, "train/reward_avg": 0.013877879602181977, "train/reward_loss_mean": 0.05402897795947799, "train/reward_loss_std": 0.28238338242917166, "train/reward_max_data": 1.0058394174506193, "train/reward_max_pred": 1.0019654505444269, "train/reward_neg_acc": 0.9931589003897061, "train/reward_neg_loss": 0.0337324698938288, "train/reward_pos_acc": 0.9181446237285642, "train/reward_pos_loss": 1.1052177609318363, "train/reward_pred": 0.013172732655937871, "train/reward_rate": 0.018960994525547444, "train_stats/sum_log_reward": 4.11739124007847, "train_stats/max_log_achievement_collect_drink": 5.48695652173913, "train_stats/max_log_achievement_collect_sapling": 3.017391304347826, "train_stats/max_log_achievement_collect_wood": 1.9130434782608696, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3565217391304348, "train_stats/max_log_achievement_eat_cow": 0.09565217391304348, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0782608695652174, "train_stats/max_log_achievement_make_wood_sword": 0.017391304347826087, "train_stats/max_log_achievement_place_plant": 2.860869565217391, "train_stats/max_log_achievement_place_table": 0.3217391304347826, "train_stats/max_log_achievement_wake_up": 2.5217391304347827, "train_stats/mean_log_entropy": 0.8675059652846793, "eval_stats/sum_log_reward": 3.8499999418854713, "eval_stats/max_log_achievement_collect_drink": 4.6875, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_wood": 1.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.010752688172043012, "eval_stats/max_log_achievement_eat_plant": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.002859914442524314, "report/cont_loss_std": 0.0736265555024147, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.045333970338106155, "report/cont_pos_acc": 0.9990147948265076, "report/cont_pos_loss": 0.002483297372236848, "report/cont_pred": 0.9904859662055969, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 10.832334518432617, "report/dyn_loss_std": 7.708764553070068, "report/image_loss_mean": 10.652048110961914, "report/image_loss_std": 12.070953369140625, "report/model_loss_mean": 17.203594207763672, "report/model_loss_std": 15.462859153747559, "report/post_ent_mag": 52.10080337524414, "report/post_ent_max": 52.10080337524414, "report/post_ent_mean": 35.88231658935547, "report/post_ent_min": 17.627180099487305, "report/post_ent_std": 6.213017463684082, "report/prior_ent_mag": 62.21959686279297, "report/prior_ent_max": 62.21959686279297, "report/prior_ent_mean": 47.702056884765625, "report/prior_ent_min": 23.81537628173828, "report/prior_ent_std": 7.761195182800293, "report/rep_loss_mean": 10.832334518432617, "report/rep_loss_std": 7.708764553070068, "report/reward_avg": 0.0078125, "report/reward_loss_mean": 0.04928320646286011, "report/reward_loss_std": 0.21256129443645477, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0003092288970947, "report/reward_neg_acc": 0.9960318207740784, "report/reward_neg_loss": 0.03213227540254593, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.1297919750213623, "report/reward_pred": 0.005610926542431116, "report/reward_rate": 0.015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.1999476555502042e-05, "eval/cont_loss_std": 0.00019850945682264864, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0029908150900155306, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.1784836096449e-07, "eval/cont_pred": 0.9961050748825073, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.80783462524414, "eval/dyn_loss_std": 8.1535062789917, "eval/image_loss_mean": 22.025293350219727, "eval/image_loss_std": 28.088956832885742, "eval/model_loss_mean": 30.352161407470703, "eval/model_loss_std": 31.045120239257812, "eval/post_ent_mag": 46.56580352783203, "eval/post_ent_max": 46.56580352783203, "eval/post_ent_mean": 32.2901611328125, "eval/post_ent_min": 17.992151260375977, "eval/post_ent_std": 4.5177812576293945, "eval/prior_ent_mag": 62.12975311279297, "eval/prior_ent_max": 62.12975311279297, "eval/prior_ent_mean": 43.96063995361328, "eval/prior_ent_min": 23.183549880981445, "eval/prior_ent_std": 8.054283142089844, "eval/rep_loss_mean": 13.80783462524414, "eval/rep_loss_std": 8.1535062789917, "eval/reward_avg": 0.008007812313735485, "eval/reward_loss_mean": 0.042156536132097244, "eval/reward_loss_std": 0.3831412196159363, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001258373260498, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.023671625182032585, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.601050853729248, "eval/reward_pred": 0.005007810425013304, "eval/reward_rate": 0.01171875, "replay/size": 108553.0, "replay/inserts": 21944.0, "replay/samples": 21936.0, "replay/insert_wait_avg": 1.4616936347452428e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0537979465431753e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21408.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.27427311925929e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1316707134247, "timer/env.step_count": 2743.0, "timer/env.step_total": 258.994247674942, "timer/env.step_frac": 0.2589601502072157, "timer/env.step_avg": 0.09442006841959243, "timer/env.step_min": 0.022925615310668945, "timer/env.step_max": 3.2037973403930664, "timer/replay._sample_count": 21936.0, "timer/replay._sample_total": 12.290130376815796, "timer/replay._sample_frac": 0.01228851233962911, "timer/replay._sample_avg": 0.0005602721725390134, "timer/replay._sample_min": 0.000339508056640625, "timer/replay._sample_max": 0.011869192123413086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3209.0, "timer/agent.policy_total": 54.6046929359436, "timer/agent.policy_frac": 0.05459750404363497, "timer/agent.policy_avg": 0.01701610873666052, "timer/agent.policy_min": 0.00977635383605957, "timer/agent.policy_max": 0.10863733291625977, "timer/dataset_train_count": 1371.0, "timer/dataset_train_total": 0.16288089752197266, "timer/dataset_train_frac": 0.00016285945370151582, "timer/dataset_train_avg": 0.00011880444749961536, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.000644683837890625, "timer/agent.train_count": 1371.0, "timer/agent.train_total": 619.4600203037262, "timer/agent.train_frac": 0.6193784662991887, "timer/agent.train_avg": 0.45183079526165293, "timer/agent.train_min": 0.4364049434661865, "timer/agent.train_max": 1.5181715488433838, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46875619888305664, "timer/agent.report_frac": 0.0004686944855457666, "timer/agent.report_avg": 0.23437809944152832, "timer/agent.report_min": 0.2219867706298828, "timer/agent.report_max": 0.24676942825317383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.364418029785156e-05, "timer/dataset_eval_frac": 5.3637117860276857e-08, "timer/dataset_eval_avg": 5.364418029785156e-05, "timer/dataset_eval_min": 5.364418029785156e-05, "timer/dataset_eval_max": 5.364418029785156e-05, "fps": 21.940828032953295}
{"step": 109064, "time": 5347.1804139614105, "episode/length": 284.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 109192, "time": 5353.514632225037, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 109288, "time": 5358.271635770798, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 109376, "time": 5362.993795633316, "episode/length": 127.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 109680, "time": 5374.543471813202, "episode/length": 77.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 109896, "time": 5383.163773536682, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 109968, "time": 5387.553666591644, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5411.126457691193, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 110032, "time": 5413.0962080955505, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 110032, "time": 5414.9051861763, "eval_episode/length": 168.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 110032, "time": 5416.608293056488, "eval_episode/length": 172.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 110032, "time": 5418.655421733856, "eval_episode/length": 182.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 110032, "time": 5420.356555700302, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 110032, "time": 5422.266110658646, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 110032, "time": 5425.847289800644, "eval_episode/length": 240.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.995850622406639}
{"step": 110360, "time": 5436.818769454956, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 110520, "time": 5443.751863479614, "episode/length": 165.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 110768, "time": 5453.708961248398, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 110832, "time": 5457.39088177681, "episode/length": 450.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 111080, "time": 5467.021439313889, "episode/length": 223.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 111096, "time": 5469.201719045639, "episode/length": 40.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 111208, "time": 5474.60334777832, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 111224, "time": 5476.878116846085, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 111256, "time": 5479.56093788147, "episode/length": 234.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 111448, "time": 5487.432108402252, "episode/length": 135.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 111904, "time": 5504.417840957642, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 112208, "time": 5516.0826597213745, "episode/length": 122.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 112304, "time": 5520.845785617828, "episode/length": 183.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 112344, "time": 5523.458441495895, "episode/length": 141.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 112392, "time": 5526.9706881046295, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 112416, "time": 5529.581702470779, "episode/length": 144.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 112928, "time": 5548.142468690872, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 113344, "time": 5563.716351032257, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 113592, "time": 5573.345382452011, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 113624, "time": 5575.952313184738, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 113752, "time": 5581.737104415894, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 113768, "time": 5583.797052621841, "episode/length": 333.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 113928, "time": 5590.868386268616, "episode/length": 197.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 114272, "time": 5604.334792375565, "episode/length": 42.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 114432, "time": 5611.472729682922, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 114464, "time": 5614.091825723648, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 114672, "time": 5622.656517505646, "episode/length": 134.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9481481481481482, "episode/intrinsic_return": 0.0}
{"step": 115104, "time": 5639.860279798508, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 115280, "time": 5647.293779850006, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 115328, "time": 5651.114179849625, "episode/length": 212.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 115560, "time": 5660.877644777298, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 115712, "time": 5668.034709692001, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 115848, "time": 5674.402472019196, "episode/length": 261.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 116248, "time": 5689.364418029785, "episode/length": 226.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 116376, "time": 5695.2209730148315, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 116440, "time": 5698.933374404907, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 117008, "time": 5719.657931089401, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 117072, "time": 5723.360960006714, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 117232, "time": 5730.444290161133, "episode/length": 319.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 117408, "time": 5737.932509422302, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 117480, "time": 5742.201439619064, "episode/length": 203.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 117648, "time": 5749.577383518219, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 117976, "time": 5761.820659637451, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 118040, "time": 5765.642576217651, "episode/length": 207.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 118256, "time": 5774.602819442749, "episode/length": 34.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 118480, "time": 5783.498496294022, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 118688, "time": 5791.853038549423, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 118696, "time": 5793.562573194504, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 118704, "time": 5796.132788181305, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 118792, "time": 5800.983583688736, "episode/length": 214.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 119240, "time": 5817.525299549103, "episode/length": 66.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 119256, "time": 5819.5500202178955, "episode/length": 57.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 119552, "time": 5831.414192438126, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 119912, "time": 5844.779235839844, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 120000, "time": 5849.489613056183, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5866.683707237244, "eval_episode/length": 51.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 120016, "time": 5872.741994380951, "eval_episode/length": 121.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9590163934426229}
{"step": 120016, "time": 5875.028489112854, "eval_episode/length": 140.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 120016, "time": 5876.845595359802, "eval_episode/length": 146.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 120016, "time": 5879.035818099976, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 120016, "time": 5881.378874063492, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 120016, "time": 5883.947972536087, "eval_episode/length": 201.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.995049504950495}
{"step": 120016, "time": 5885.817403793335, "eval_episode/length": 205.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 120112, "time": 5889.038908004761, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 120160, "time": 5892.232409238815, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9660377358490566, "episode/intrinsic_return": 0.0}
{"step": 120392, "time": 5901.163335561752, "episode/length": 238.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 120400, "time": 5903.174807310104, "episode/length": 142.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 120544, "time": 5909.706634283066, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 121152, "time": 5931.442204713821, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 121496, "time": 5944.401004552841, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 121616, "time": 5950.345187187195, "episode/length": 257.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 121640, "time": 5952.571713685989, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 121640, "time": 5952.604697704315, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 121704, "time": 5957.907038927078, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 121840, "time": 5964.299161672592, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 122032, "time": 5972.352125167847, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 122664, "time": 5994.672296524048, "episode/length": 188.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 123080, "time": 6011.978004932404, "episode/length": 51.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 123136, "time": 6015.694683790207, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 123192, "time": 6018.916995763779, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 123336, "time": 6025.192234277725, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 123400, "time": 6029.361469507217, "episode/length": 222.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 123416, "time": 6031.457762718201, "episode/length": 221.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 123456, "time": 6034.60310959816, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 124416, "time": 6068.458256483078, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 124464, "time": 6071.648905515671, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 124488, "time": 6073.768025398254, "episode/length": 135.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 124512, "time": 6076.387417554855, "episode/length": 309.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 124528, "time": 6078.536420583725, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 124600, "time": 6082.391692399979, "episode/length": 22.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8260869565217391, "episode/intrinsic_return": 0.0}
{"step": 125000, "time": 6097.328912973404, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 125208, "time": 6105.888524055481, "episode/length": 223.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 125384, "time": 6113.305956363678, "episode/length": 280.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 125696, "time": 6125.958068609238, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 125736, "time": 6128.581016778946, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 125784, "time": 6131.75280380249, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 126032, "time": 6141.718581199646, "episode/length": 192.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 126176, "time": 6148.008566856384, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 126368, "time": 6156.025208473206, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 126720, "time": 6169.457671403885, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 127056, "time": 6182.1545124053955, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 127080, "time": 6184.286976099014, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 127168, "time": 6189.219017982483, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 127240, "time": 6192.847194910049, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 127472, "time": 6202.293153047562, "episode/length": 161.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 127528, "time": 6205.573894500732, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 127904, "time": 6219.905235290527, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 128384, "time": 6237.653928279877, "episode/length": 165.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 128392, "time": 6239.307698249817, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 128488, "time": 6244.122895479202, "episode/length": 126.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 128568, "time": 6248.457440376282, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 128768, "time": 6256.839150190353, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 128976, "time": 6265.171189546585, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 129464, "time": 6282.881296157837, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 129488, "time": 6285.639412879944, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 129624, "time": 6291.469034194946, "episode/length": 131.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 129656, "time": 6294.114327669144, "episode/length": 157.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 129824, "time": 6301.469790935516, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 129944, "time": 6306.825223445892, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6329.789685726166, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 130000, "time": 6335.19278216362, "eval_episode/length": 218.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 130000, "time": 6337.3572034835815, "eval_episode/length": 228.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 130000, "time": 6339.178807258606, "eval_episode/length": 232.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 130000, "time": 6340.741042137146, "eval_episode/length": 234.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 130000, "time": 6343.629883527756, "eval_episode/length": 45.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9130434782608695}
{"step": 130000, "time": 6345.72522521019, "eval_episode/length": 272.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9853479853479854}
{"step": 130000, "time": 6349.231334686279, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 130001, "time": 6349.812647819519, "train_stats/sum_log_reward": 4.108474526933189, "train_stats/max_log_achievement_collect_drink": 5.559322033898305, "train_stats/max_log_achievement_collect_sapling": 2.305084745762712, "train_stats/max_log_achievement_collect_wood": 1.9067796610169492, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3474576271186441, "train_stats/max_log_achievement_eat_cow": 0.06779661016949153, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0423728813559322, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.1864406779661016, "train_stats/max_log_achievement_place_table": 0.6779661016949152, "train_stats/max_log_achievement_wake_up": 2.5, "train_stats/mean_log_entropy": 0.7390150079282664, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.459581680880248, "train/action_min": 0.0, "train/action_std": 3.0541428263860806, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05140900805251289, "train/actor_opt_grad_steps": 7370.0, "train/actor_opt_loss": 5.938745423053029, "train/adv_mag": 0.8902505822764099, "train/adv_max": 0.8854218216342781, "train/adv_mean": 0.0053150286128876, "train/adv_min": -0.5141227773127665, "train/adv_std": 0.0876406800030297, "train/cont_avg": 0.9948413645038168, "train/cont_loss_mean": 0.0004603005721064237, "train/cont_loss_std": 0.012761893045431403, "train/cont_neg_acc": 0.9819580780640813, "train/cont_neg_loss": 0.04754603518457569, "train/cont_pos_acc": 0.9999174657668776, "train/cont_pos_loss": 0.00023912376079642217, "train/cont_pred": 0.9948037671678849, "train/cont_rate": 0.9948413645038168, "train/dyn_loss_mean": 12.33477748987329, "train/dyn_loss_std": 8.555658784531454, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1277568085503031, "train/extr_critic_critic_opt_grad_steps": 7370.0, "train/extr_critic_critic_opt_loss": 14982.238795622614, "train/extr_critic_mag": 3.433827265528322, "train/extr_critic_max": 3.433827265528322, "train/extr_critic_mean": 0.898547102021807, "train/extr_critic_min": -0.14335892764666608, "train/extr_critic_std": 0.8364098417849941, "train/extr_return_normed_mag": 1.8861682788106322, "train/extr_return_normed_max": 1.8861682788106322, "train/extr_return_normed_mean": 0.34283367595599806, "train/extr_return_normed_min": -0.19193070546816324, "train/extr_return_normed_std": 0.33848388299687215, "train/extr_return_rate": 0.5204988952356441, "train/extr_return_raw_mag": 4.922395984635099, "train/extr_return_raw_max": 4.922395984635099, "train/extr_return_raw_mean": 0.9123418954492525, "train/extr_return_raw_min": -0.47589930823741067, "train/extr_return_raw_std": 0.8794913583129417, "train/extr_reward_mag": 1.0050628804068529, "train/extr_reward_max": 1.0050628804068529, "train/extr_reward_mean": 0.01763052840269249, "train/extr_reward_min": -0.40968062586456766, "train/extr_reward_std": 0.11635445325656701, "train/image_loss_mean": 14.418717741056254, "train/image_loss_std": 16.080311957206433, "train/model_loss_mean": 21.873542727404878, "train/model_loss_std": 19.84863487272772, "train/model_opt_grad_norm": 94.28398385666709, "train/model_opt_grad_steps": 7359.335877862595, "train/model_opt_loss": 14071.418445849236, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 644.0839694656488, "train/policy_entropy_mag": 2.575949439565644, "train/policy_entropy_max": 2.575949439565644, "train/policy_entropy_mean": 0.7849762389678081, "train/policy_entropy_min": 0.07937879769401696, "train/policy_entropy_std": 0.629711743074519, "train/policy_logprob_mag": 7.438317025890787, "train/policy_logprob_max": -0.00945666450864941, "train/policy_logprob_mean": -0.7853199721292685, "train/policy_logprob_min": -7.438317025890787, "train/policy_logprob_std": 1.2207160387330382, "train/policy_randomness_mag": 0.9091971111661605, "train/policy_randomness_max": 0.9091971111661605, "train/policy_randomness_mean": 0.2770621626431705, "train/policy_randomness_min": 0.028017232151886888, "train/policy_randomness_std": 0.22226061234037384, "train/post_ent_mag": 50.675040237776194, "train/post_ent_max": 50.675040237776194, "train/post_ent_mean": 35.76153095623919, "train/post_ent_min": 19.577490886659113, "train/post_ent_std": 5.310650257663872, "train/prior_ent_mag": 62.043093062539135, "train/prior_ent_max": 62.043093062539135, "train/prior_ent_mean": 48.240268095759035, "train/prior_ent_min": 24.911276620762948, "train/prior_ent_std": 7.137408831647334, "train/rep_loss_mean": 12.33477748987329, "train/rep_loss_std": 8.555658784531454, "train/reward_avg": 0.015894113670153018, "train/reward_loss_mean": 0.05349828968293794, "train/reward_loss_std": 0.2800342599854215, "train/reward_max_data": 1.0030534358424994, "train/reward_max_pred": 1.002349586887214, "train/reward_neg_acc": 0.9938008712448236, "train/reward_neg_loss": 0.031994868923007076, "train/reward_pos_acc": 0.919020120879166, "train/reward_pos_loss": 1.0927836681140288, "train/reward_pred": 0.01455497431199116, "train/reward_rate": 0.02057490458015267, "eval_stats/sum_log_reward": 4.599999967962503, "eval_stats/max_log_achievement_collect_drink": 3.6666666666666665, "eval_stats/max_log_achievement_collect_sapling": 2.8333333333333335, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 2.2916666666666665, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_collect_stone": 0.058823529411764705, "train_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.300006836885586e-05, "report/cont_loss_std": 0.0016011391999199986, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003912400861736387, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.143853872548789e-05, "report/cont_pred": 0.9950492978096008, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.976309776306152, "report/dyn_loss_std": 8.836400032043457, "report/image_loss_mean": 11.225281715393066, "report/image_loss_std": 14.656005859375, "report/model_loss_mean": 17.861759185791016, "report/model_loss_std": 18.67641830444336, "report/post_ent_mag": 50.6287956237793, "report/post_ent_max": 50.6287956237793, "report/post_ent_mean": 35.32341766357422, "report/post_ent_min": 18.977954864501953, "report/post_ent_std": 5.075411796569824, "report/prior_ent_mag": 62.63739013671875, "report/prior_ent_max": 62.63739013671875, "report/prior_ent_mean": 47.61927795410156, "report/prior_ent_min": 25.373851776123047, "report/prior_ent_std": 7.5379862785339355, "report/rep_loss_mean": 10.976309776306152, "report/rep_loss_std": 8.836400032043457, "report/reward_avg": 0.01914062350988388, "report/reward_loss_mean": 0.05061700940132141, "report/reward_loss_std": 0.23624908924102783, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017173290252686, "report/reward_neg_acc": 0.9929929971694946, "report/reward_neg_loss": 0.031010771170258522, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.834082305431366, "report/reward_pred": 0.01831415854394436, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0055977776646614075, "eval/cont_loss_std": 0.17799639701843262, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.9518733024597168, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0516381482593715e-05, "eval/cont_pred": 0.9951058626174927, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 15.427116394042969, "eval/dyn_loss_std": 9.615303993225098, "eval/image_loss_mean": 27.958385467529297, "eval/image_loss_std": 52.17142868041992, "eval/model_loss_mean": 37.328433990478516, "eval/model_loss_std": 55.091522216796875, "eval/post_ent_mag": 49.177669525146484, "eval/post_ent_max": 49.177669525146484, "eval/post_ent_mean": 34.72591781616211, "eval/post_ent_min": 18.8995361328125, "eval/post_ent_std": 5.699411869049072, "eval/prior_ent_mag": 62.63739013671875, "eval/prior_ent_max": 62.63739013671875, "eval/prior_ent_mean": 47.574249267578125, "eval/prior_ent_min": 24.773151397705078, "eval/prior_ent_std": 8.55477523803711, "eval/rep_loss_mean": 15.427116394042969, "eval/rep_loss_std": 9.615303993225098, "eval/reward_avg": 0.008593750186264515, "eval/reward_loss_mean": 0.10817928612232208, "eval/reward_loss_std": 0.7632375359535217, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004760503768921, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.05793048068881035, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 3.733271360397339, "eval/reward_pred": 0.001692356658168137, "eval/reward_rate": 0.013671875, "replay/size": 129497.0, "replay/inserts": 20944.0, "replay/samples": 20944.0, "replay/insert_wait_avg": 1.4164071669553052e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0708687048635926e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27400.0, "eval_replay/inserts": 5992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2547215409527156e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.6496074199677, "timer/env.step_count": 2618.0, "timer/env.step_total": 261.44500637054443, "timer/env.step_frac": 0.2607541103449873, "timer/env.step_avg": 0.09986440273893982, "timer/env.step_min": 0.022665977478027344, "timer/env.step_max": 3.209933280944824, "timer/replay._sample_count": 20944.0, "timer/replay._sample_total": 11.04876708984375, "timer/replay._sample_frac": 0.01101956955658178, "timer/replay._sample_avg": 0.0005275385356113326, "timer/replay._sample_min": 0.0003941059112548828, "timer/replay._sample_max": 0.009673357009887695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3367.0, "timer/agent.policy_total": 57.317198514938354, "timer/agent.policy_frac": 0.05716573176787831, "timer/agent.policy_avg": 0.017023224982161675, "timer/agent.policy_min": 0.009279489517211914, "timer/agent.policy_max": 0.6064937114715576, "timer/dataset_train_count": 1309.0, "timer/dataset_train_total": 0.14880681037902832, "timer/dataset_train_frac": 0.00014841357267564304, "timer/dataset_train_avg": 0.0001136797634675541, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0006909370422363281, "timer/agent.train_count": 1309.0, "timer/agent.train_total": 585.0373787879944, "timer/agent.train_frac": 0.5834913557622796, "timer/agent.train_avg": 0.44693459036516, "timer/agent.train_min": 0.4335489273071289, "timer/agent.train_max": 1.5148983001708984, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475111722946167, "timer/agent.report_frac": 0.00047385619006896267, "timer/agent.report_avg": 0.2375558614730835, "timer/agent.report_min": 0.23034000396728516, "timer/agent.report_max": 0.24477171897888184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.519270286040361e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 20.88839315141524}
{"step": 130016, "time": 6350.482136726379, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 130296, "time": 6361.340523958206, "episode/length": 103.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 130784, "time": 6379.658308029175, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 130808, "time": 6381.838726758957, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 131000, "time": 6389.909082651138, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 131208, "time": 6399.820751190186, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 131312, "time": 6405.134499788284, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 131392, "time": 6409.484272003174, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 131632, "time": 6419.111496448517, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 131976, "time": 6432.309630870819, "episode/length": 244.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 132056, "time": 6436.958085775375, "episode/length": 92.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.0}
{"step": 132120, "time": 6440.699084043503, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 132256, "time": 6446.894668340683, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 132504, "time": 6456.621492624283, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 132552, "time": 6459.769139289856, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 132744, "time": 6467.719154834747, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 133184, "time": 6484.118374109268, "episode/length": 140.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 133256, "time": 6487.949642896652, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 133488, "time": 6497.850082159042, "episode/length": 231.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 133856, "time": 6512.361067771912, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 133856, "time": 6512.369362831116, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 133992, "time": 6520.112933397293, "episode/length": 233.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 134104, "time": 6525.481302976608, "episode/length": 169.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 134384, "time": 6536.616669654846, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 134560, "time": 6544.079640626907, "episode/length": 162.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 135136, "time": 6564.95986700058, "episode/length": 322.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 135624, "time": 6582.699371814728, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 135648, "time": 6585.241077184677, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 135792, "time": 6591.6457695961, "episode/length": 287.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 135800, "time": 6593.459804773331, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 135824, "time": 6595.909557342529, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 136032, "time": 6604.403499364853, "episode/length": 254.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 136400, "time": 6618.364725351334, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 136456, "time": 6621.637796640396, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 136808, "time": 6635.040287733078, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 136824, "time": 6637.137400865555, "episode/length": 304.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 137208, "time": 6651.580708742142, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 137248, "time": 6654.904793977737, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 137328, "time": 6659.276399850845, "episode/length": 62.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 137464, "time": 6665.413864135742, "episode/length": 207.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 137824, "time": 6679.374492406845, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 137856, "time": 6682.037531137466, "episode/length": 181.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 138160, "time": 6693.741772651672, "episode/length": 316.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 138512, "time": 6707.268877029419, "episode/length": 212.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 138536, "time": 6709.542100191116, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 138616, "time": 6714.020143985748, "episode/length": 143.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 138648, "time": 6716.5951335430145, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 138808, "time": 6723.447350263596, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 139280, "time": 6742.420072793961, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 139656, "time": 6756.28765463829, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 139928, "time": 6767.008857727051, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 140024, "time": 6771.961904287338, "episode/length": 270.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6793.534265756607, "eval_episode/length": 113.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 140088, "time": 6796.7835030555725, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 140088, "time": 6799.021267652512, "eval_episode/length": 171.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 140088, "time": 6800.916608810425, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 140088, "time": 6803.614963769913, "eval_episode/length": 205.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 140088, "time": 6805.985152006149, "eval_episode/length": 221.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 140088, "time": 6808.551707029343, "eval_episode/length": 244.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9836734693877551}
{"step": 140088, "time": 6810.380746126175, "eval_episode/length": 248.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 140176, "time": 6813.53976726532, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 140568, "time": 6827.958852052689, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 140656, "time": 6832.713160991669, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 140776, "time": 6838.0919806957245, "episode/length": 245.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 140952, "time": 6845.731301307678, "episode/length": 390.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 141016, "time": 6849.4924492836, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 141072, "time": 6853.2911903858185, "episode/length": 142.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 141544, "time": 6870.40668797493, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 141752, "time": 6879.019265651703, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 142024, "time": 6889.650305271149, "episode/length": 133.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 142160, "time": 6896.089861631393, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 142456, "time": 6907.475307703018, "episode/length": 172.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 142536, "time": 6911.919528007507, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 142808, "time": 6922.621294975281, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 142888, "time": 6926.857349395752, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 143136, "time": 6936.948059082031, "episode/length": 388.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 143640, "time": 6955.241646051407, "episode/length": 327.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 143720, "time": 6959.4707062244415, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 143736, "time": 6961.810676574707, "episode/length": 105.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 143768, "time": 6964.379065752029, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 143912, "time": 6970.977688550949, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 144040, "time": 6977.394135951996, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 144576, "time": 6997.049635410309, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 144840, "time": 7007.195526838303, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 144904, "time": 7011.057278871536, "episode/length": 147.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 145192, "time": 7022.290403842926, "episode/length": 395.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 145272, "time": 7026.626548290253, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 145288, "time": 7028.788807153702, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 145760, "time": 7046.194769144058, "episode/length": 147.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 145960, "time": 7054.122630357742, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 146144, "time": 7062.164622545242, "episode/length": 162.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 146408, "time": 7072.261835813522, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 146448, "time": 7075.602467775345, "episode/length": 156.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 146448, "time": 7075.612574100494, "episode/length": 350.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 146640, "time": 7085.3965747356415, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 146664, "time": 7087.4777455329895, "episode/length": 31.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 146920, "time": 7097.714893102646, "episode/length": 31.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 146968, "time": 7100.991693496704, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 147544, "time": 7123.2715537548065, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 147552, "time": 7125.342748165131, "episode/length": 284.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 147616, "time": 7129.164834499359, "episode/length": 206.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 147768, "time": 7135.682444810867, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 148008, "time": 7145.197866678238, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 148248, "time": 7154.711153745651, "episode/length": 159.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 148616, "time": 7168.584423780441, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 148696, "time": 7172.698344230652, "episode/length": 280.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 148704, "time": 7174.6745982170105, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 148712, "time": 7176.388121128082, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 148784, "time": 7180.735682964325, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 149104, "time": 7192.882266044617, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 149160, "time": 7196.368698358536, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 149408, "time": 7206.486079454422, "episode/length": 174.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 149520, "time": 7211.8573269844055, "episode/length": 51.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 149720, "time": 7220.0515995025635, "episode/length": 38.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 149808, "time": 7224.8417246341705, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 149840, "time": 7227.364562749863, "episode/length": 152.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 149928, "time": 7231.561865329742, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 149976, "time": 7234.782313585281, "episode/length": 56.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9298245614035088, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7255.089466571808, "eval_episode/length": 47.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 150072, "time": 7257.687838077545, "eval_episode/length": 72.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9452054794520548}
{"step": 150072, "time": 7260.239232540131, "eval_episode/length": 98.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9494949494949495}
{"step": 150072, "time": 7263.394324302673, "eval_episode/length": 136.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 150072, "time": 7265.890657424927, "eval_episode/length": 157.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 150072, "time": 7267.767805337906, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 150072, "time": 7270.104720830917, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 150072, "time": 7274.318302154541, "eval_episode/length": 244.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 150240, "time": 7280.14693903923, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 150752, "time": 7298.8873970508575, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 151168, "time": 7314.266802072525, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 151184, "time": 7316.438777446747, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 151200, "time": 7318.534406661987, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 151296, "time": 7323.288451433182, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 151504, "time": 7332.140633821487, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 151776, "time": 7342.770456314087, "episode/length": 75.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 151929, "time": 7350.243977069855, "train_stats/sum_log_reward": 4.388135533337876, "train_stats/max_log_achievement_collect_drink": 5.296610169491525, "train_stats/max_log_achievement_collect_sapling": 2.3983050847457625, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.135593220338983, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.17796610169491525, "train_stats/max_log_achievement_eat_cow": 0.13559322033898305, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00847457627118644, "train_stats/max_log_achievement_make_wood_sword": 0.025423728813559324, "train_stats/max_log_achievement_place_plant": 2.2288135593220337, "train_stats/max_log_achievement_place_table": 1.2372881355932204, "train_stats/max_log_achievement_wake_up": 2.2711864406779663, "train_stats/mean_log_entropy": 0.6901841022200503, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4263916015625, "train/action_min": 0.0, "train/action_std": 2.989534720887233, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.053593550829121664, "train/actor_opt_grad_steps": 8710.0, "train/actor_opt_loss": 12.764411785741792, "train/adv_mag": 0.8828321034020751, "train/adv_max": 0.8778083511512645, "train/adv_mean": 0.006441841410889578, "train/adv_min": -0.5134756304051754, "train/adv_std": 0.0881357269946241, "train/cont_avg": 0.9944899064781022, "train/cont_loss_mean": 0.0006355022063280786, "train/cont_loss_std": 0.016925492230033024, "train/cont_neg_acc": 0.9715762973701867, "train/cont_neg_loss": 0.07410580517461625, "train/cont_pos_acc": 0.9999139400294227, "train/cont_pos_loss": 0.000223077827537939, "train/cont_pred": 0.9945386961428788, "train/cont_rate": 0.9944899064781022, "train/dyn_loss_mean": 13.32383298525845, "train/dyn_loss_std": 8.781708264872975, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.126205118468208, "train/extr_critic_critic_opt_grad_steps": 8710.0, "train/extr_critic_critic_opt_loss": 15554.833250171077, "train/extr_critic_mag": 3.7877731949743563, "train/extr_critic_max": 3.7877731949743563, "train/extr_critic_mean": 0.9813359601654276, "train/extr_critic_min": -0.15215936281385212, "train/extr_critic_std": 0.9276417876682143, "train/extr_return_normed_mag": 1.8854451144698763, "train/extr_return_normed_max": 1.8854451144698763, "train/extr_return_normed_mean": 0.336566738294859, "train/extr_return_normed_min": -0.19927265495061874, "train/extr_return_normed_std": 0.34318381025843375, "train/extr_return_rate": 0.5415545456165815, "train/extr_return_raw_mag": 5.394025176110929, "train/extr_return_raw_max": 5.394025176110929, "train/extr_return_raw_mean": 0.9995984765734985, "train/extr_return_raw_min": -0.5238345294755741, "train/extr_return_raw_std": 0.9761706930007378, "train/extr_reward_mag": 1.0056654467199841, "train/extr_reward_max": 1.0056654467199841, "train/extr_reward_mean": 0.019145958247954828, "train/extr_reward_min": -0.4082581483534653, "train/extr_reward_std": 0.1194506229384102, "train/image_loss_mean": 12.999908544721395, "train/image_loss_std": 15.433388480304801, "train/model_loss_mean": 21.04748004022306, "train/model_loss_std": 19.237642879903753, "train/model_opt_grad_norm": 87.36980143715354, "train/model_opt_grad_steps": 8698.014598540147, "train/model_opt_loss": 14116.71116560219, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 666.0583941605839, "train/policy_entropy_mag": 2.439238198482207, "train/policy_entropy_max": 2.439238198482207, "train/policy_entropy_mean": 0.7079024371439523, "train/policy_entropy_min": 0.0793776729681196, "train/policy_entropy_std": 0.5846488425766465, "train/policy_logprob_mag": 7.438351046429934, "train/policy_logprob_max": -0.009456310033743833, "train/policy_logprob_mean": -0.7079316260170763, "train/policy_logprob_min": -7.438351046429934, "train/policy_logprob_std": 1.1580386657784456, "train/policy_randomness_mag": 0.8609440391951234, "train/policy_randomness_max": 0.8609440391951234, "train/policy_randomness_mean": 0.24985849563657803, "train/policy_randomness_min": 0.02801683521999495, "train/policy_randomness_std": 0.20635538640683584, "train/post_ent_mag": 52.39813719700723, "train/post_ent_max": 52.39813719700723, "train/post_ent_mean": 36.51127797147653, "train/post_ent_min": 19.943869235741833, "train/post_ent_std": 5.5340814451231575, "train/prior_ent_mag": 63.32448279944649, "train/prior_ent_max": 63.32448279944649, "train/prior_ent_mean": 50.007305200952686, "train/prior_ent_min": 27.296335721538014, "train/prior_ent_std": 6.90782804558747, "train/rep_loss_mean": 13.32383298525845, "train/rep_loss_std": 8.781708264872975, "train/reward_avg": 0.016836079962578784, "train/reward_loss_mean": 0.05263619500137594, "train/reward_loss_std": 0.2630330886501465, "train/reward_max_data": 1.0072992718132743, "train/reward_max_pred": 1.0026161270420046, "train/reward_neg_acc": 0.9932277694235753, "train/reward_neg_loss": 0.03146234218602198, "train/reward_pos_acc": 0.941029994157109, "train/reward_pos_loss": 1.0038989612655917, "train/reward_pred": 0.015967072845083138, "train/reward_rate": 0.02183365647810219, "eval_stats/sum_log_reward": 4.2874999940395355, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_table": 0.6875, "eval_stats/max_log_achievement_wake_up": 2.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.558907287195325e-05, "report/cont_loss_std": 0.0010565040865913033, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013718142872676253, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.0427399401087314e-05, "report/cont_pred": 0.9960494637489319, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.124316215515137, "report/dyn_loss_std": 9.38284969329834, "report/image_loss_mean": 9.854999542236328, "report/image_loss_std": 12.384847640991211, "report/model_loss_mean": 17.170608520507812, "report/model_loss_std": 16.65323829650879, "report/post_ent_mag": 54.86565399169922, "report/post_ent_max": 54.86565399169922, "report/post_ent_mean": 36.096527099609375, "report/post_ent_min": 19.158206939697266, "report/post_ent_std": 6.038873195648193, "report/prior_ent_mag": 63.73146057128906, "report/prior_ent_max": 63.73146057128906, "report/prior_ent_mean": 48.533260345458984, "report/prior_ent_min": 26.07845115661621, "report/prior_ent_std": 7.925950050354004, "report/rep_loss_mean": 12.124316215515137, "report/rep_loss_std": 9.38284969329834, "report/reward_avg": 0.012011718936264515, "report/reward_loss_mean": 0.04096430167555809, "report/reward_loss_std": 0.17075848579406738, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0019707679748535, "report/reward_neg_acc": 0.9890764355659485, "report/reward_neg_loss": 0.026156088337302208, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.9181331396102905, "report/reward_pred": 0.010830412618815899, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.004743432160466909, "eval/cont_loss_std": 0.13425461947917938, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010127988643944263, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.004747078754007816, "eval/cont_pred": 0.9976138472557068, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 13.239946365356445, "eval/dyn_loss_std": 8.075174331665039, "eval/image_loss_mean": 11.42086410522461, "eval/image_loss_std": 13.599591255187988, "eval/model_loss_mean": 19.41647720336914, "eval/model_loss_std": 16.944988250732422, "eval/post_ent_mag": 55.92789840698242, "eval/post_ent_max": 55.92789840698242, "eval/post_ent_mean": 37.68040466308594, "eval/post_ent_min": 20.789173126220703, "eval/post_ent_std": 5.436556339263916, "eval/prior_ent_mag": 64.97109985351562, "eval/prior_ent_max": 64.97109985351562, "eval/prior_ent_mean": 48.70034408569336, "eval/prior_ent_min": 31.40410804748535, "eval/prior_ent_std": 5.798356056213379, "eval/rep_loss_mean": 13.239946365356445, "eval/rep_loss_std": 8.075174331665039, "eval/reward_avg": 0.0010742188896983862, "eval/reward_loss_mean": 0.04690127074718475, "eval/reward_loss_std": 0.41068753600120544, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026493072509766, "eval/reward_neg_acc": 0.9970530867576599, "eval/reward_neg_loss": 0.030460210517048836, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 2.8364017009735107, "eval/reward_pred": -0.0010247969767078757, "eval/reward_rate": 0.005859375, "replay/size": 151425.0, "replay/inserts": 21928.0, "replay/samples": 21936.0, "replay/insert_wait_avg": 1.4560299170186859e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0582324277737295e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31352.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2253942759896096e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4180042743683, "timer/env.step_count": 2741.0, "timer/env.step_total": 263.16640877723694, "timer/env.step_frac": 0.2630564500567131, "timer/env.step_avg": 0.09601109404496058, "timer/env.step_min": 0.02276158332824707, "timer/env.step_max": 3.4005191326141357, "timer/replay._sample_count": 21936.0, "timer/replay._sample_total": 11.411715745925903, "timer/replay._sample_frac": 0.011406947593074503, "timer/replay._sample_avg": 0.0005202277418821072, "timer/replay._sample_min": 0.00039386749267578125, "timer/replay._sample_max": 0.011327505111694336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3235.0, "timer/agent.policy_total": 53.294896364212036, "timer/agent.policy_frac": 0.05327262817792683, "timer/agent.policy_avg": 0.01647446564581516, "timer/agent.policy_min": 0.009346485137939453, "timer/agent.policy_max": 0.1048891544342041, "timer/dataset_train_count": 1371.0, "timer/dataset_train_total": 0.15703248977661133, "timer/dataset_train_frac": 0.00015696687695111153, "timer/dataset_train_avg": 0.00011453865045704691, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0010807514190673828, "timer/agent.train_count": 1371.0, "timer/agent.train_total": 617.2223556041718, "timer/agent.train_frac": 0.6169644618219968, "timer/agent.train_avg": 0.45019865470763804, "timer/agent.train_min": 0.4367823600769043, "timer/agent.train_max": 1.5435259342193604, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48049449920654297, "timer/agent.report_frac": 0.0004802937343726229, "timer/agent.report_avg": 0.24024724960327148, "timer/agent.report_min": 0.23504400253295898, "timer/agent.report_max": 0.24545049667358398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.100799560546875e-05, "timer/dataset_eval_frac": 4.099086125025611e-08, "timer/dataset_eval_avg": 4.100799560546875e-05, "timer/dataset_eval_min": 4.100799560546875e-05, "timer/dataset_eval_max": 4.100799560546875e-05, "fps": 21.918552659736907}
{"step": 152016, "time": 7353.2767741680145, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 152168, "time": 7359.981188058853, "episode/length": 433.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 152384, "time": 7369.038514375687, "episode/length": 147.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 152568, "time": 7376.682980060577, "episode/length": 158.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 152648, "time": 7380.881731510162, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 152744, "time": 7385.8074831962585, "episode/length": 120.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 152832, "time": 7390.681884765625, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 152992, "time": 7397.662203550339, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 153320, "time": 7410.153542280197, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 153544, "time": 7419.456459283829, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 154224, "time": 7444.326894044876, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 154464, "time": 7454.134959936142, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 154480, "time": 7456.297499895096, "episode/length": 261.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 154608, "time": 7462.202172756195, "episode/length": 221.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 154632, "time": 7464.389922618866, "episode/length": 247.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 155056, "time": 7480.704704999924, "episode/length": 188.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 155360, "time": 7492.551222324371, "episode/length": 295.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 155512, "time": 7499.040786266327, "episode/length": 273.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 155792, "time": 7511.915752649307, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 155800, "time": 7513.607489109039, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 156040, "time": 7523.23074054718, "episode/length": 178.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 156152, "time": 7528.590894699097, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 156344, "time": 7536.78980755806, "episode/length": 234.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 156624, "time": 7548.160221576691, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 156680, "time": 7551.591030836105, "episode/length": 109.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 157032, "time": 7565.245498180389, "episode/length": 350.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 157064, "time": 7567.967192173004, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 157424, "time": 7581.886799812317, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 157496, "time": 7585.693917989731, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 157864, "time": 7599.759935617447, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 157984, "time": 7605.7287657260895, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 158144, "time": 7612.769755363464, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 158408, "time": 7623.002059936523, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 158736, "time": 7635.903434753418, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 158736, "time": 7635.933716773987, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 158840, "time": 7642.649753570557, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 159008, "time": 7650.086678981781, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 159840, "time": 7680.030054330826, "episode/length": 246.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 159888, "time": 7683.4110515117645, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 160008, "time": 7688.977220058441, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7712.856305599213, "eval_episode/length": 141.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 160056, "time": 7714.999913692474, "eval_episode/length": 149.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 160056, "time": 7716.9607145786285, "eval_episode/length": 157.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 160056, "time": 7718.721529960632, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 160056, "time": 7721.178107500076, "eval_episode/length": 180.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 160056, "time": 7723.6959092617035, "eval_episode/length": 59.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 160056, "time": 7725.567641019821, "eval_episode/length": 207.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 160056, "time": 7727.472479104996, "eval_episode/length": 215.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 160176, "time": 7731.786530256271, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 160184, "time": 7733.374679327011, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 160368, "time": 7741.540065050125, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 160856, "time": 7759.608561515808, "episode/length": 358.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 161008, "time": 7766.428202390671, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 161048, "time": 7769.318748950958, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 161608, "time": 7790.0171847343445, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 161712, "time": 7795.451348543167, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 162000, "time": 7806.830233573914, "episode/length": 263.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 162096, "time": 7811.774526357651, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 162112, "time": 7813.887539148331, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 162176, "time": 7817.733062744141, "episode/length": 249.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 162312, "time": 7823.900741100311, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 162696, "time": 7838.657288074493, "episode/length": 210.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 163296, "time": 7860.818663358688, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 163336, "time": 7863.583971977234, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 163376, "time": 7866.822776794434, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 163568, "time": 7874.906835794449, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 163624, "time": 7878.191306114197, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 163784, "time": 7885.023856878281, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 163912, "time": 7892.282208442688, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 163984, "time": 7896.755358219147, "episode/length": 296.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 164008, "time": 7898.888974189758, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 164520, "time": 7917.658761024475, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 164648, "time": 7923.5322597026825, "episode/length": 168.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 165032, "time": 7938.126197576523, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 165032, "time": 7938.143778324127, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 165152, "time": 7945.951351642609, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 165528, "time": 7960.136733531952, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 165704, "time": 7967.707784414291, "episode/length": 131.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 165760, "time": 7971.4464910030365, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 165928, "time": 7978.495244026184, "episode/length": 49.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 166168, "time": 7988.157683610916, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 166200, "time": 7991.074506521225, "episode/length": 130.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 166296, "time": 7995.950985431671, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 166856, "time": 8016.505126953125, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 166992, "time": 8023.039590597153, "episode/length": 400.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 167176, "time": 8030.704808712006, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 167384, "time": 8039.334568977356, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 167472, "time": 8044.163249731064, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 167576, "time": 8049.067875385284, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 167808, "time": 8058.73104763031, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 168056, "time": 8068.384256362915, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 168208, "time": 8075.396402359009, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 168488, "time": 8086.394939422607, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 168736, "time": 8096.537630081177, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 168936, "time": 8104.92595410347, "episode/length": 140.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 168984, "time": 8108.6489498615265, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 169240, "time": 8118.889055490494, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 169352, "time": 8124.223862171173, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 169528, "time": 8131.722300291061, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 169624, "time": 8136.520012378693, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 169856, "time": 8146.217235088348, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8172.512095689774, "eval_episode/length": 139.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 170040, "time": 8174.394146680832, "eval_episode/length": 144.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 170040, "time": 8177.160267353058, "eval_episode/length": 168.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 170040, "time": 8179.383689165115, "eval_episode/length": 169.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 170040, "time": 8181.535444974899, "eval_episode/length": 173.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 170040, "time": 8185.637887954712, "eval_episode/length": 217.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 170040, "time": 8188.004743814468, "eval_episode/length": 222.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 170040, "time": 8190.528720378876, "eval_episode/length": 231.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 170200, "time": 8196.132626056671, "episode/length": 151.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 170560, "time": 8210.723937749863, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 170792, "time": 8219.85811471939, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 170800, "time": 8221.902652025223, "episode/length": 180.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 170912, "time": 8227.23106431961, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 170928, "time": 8229.365572452545, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 171088, "time": 8236.344128847122, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 171128, "time": 8239.110131978989, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 171240, "time": 8244.47283744812, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 171840, "time": 8266.417108774185, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 172272, "time": 8283.934460878372, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 172280, "time": 8285.831364393234, "episode/length": 143.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 172288, "time": 8287.916704654694, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 172320, "time": 8290.496007680893, "episode/length": 219.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 172528, "time": 8299.077120780945, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 172560, "time": 8301.66855096817, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 172904, "time": 8314.505098581314, "episode/length": 42.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 173096, "time": 8322.65697145462, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 173136, "time": 8325.822802305222, "episode/length": 107.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 173576, "time": 8342.009915351868, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 173736, "time": 8349.090933084488, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 173737, "time": 8351.56558728218, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.579861160612454, "train/action_min": 0.0, "train/action_std": 3.2798523781073357, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04815823699000978, "train/actor_opt_grad_steps": 10080.0, "train/actor_opt_loss": -2.9605434034427587, "train/adv_mag": 0.8025269808560392, "train/adv_max": 0.7950032823277215, "train/adv_mean": 0.004004731817773448, "train/adv_min": -0.49741316015702963, "train/adv_std": 0.08152123467221747, "train/cont_avg": 0.9944970346715328, "train/cont_loss_mean": 0.0005693626925623545, "train/cont_loss_std": 0.016698321967745153, "train/cont_neg_acc": 0.9853983025481231, "train/cont_neg_loss": 0.04756943206663715, "train/cont_pos_acc": 0.9998924040446316, "train/cont_pos_loss": 0.00025201259250415053, "train/cont_pred": 0.9944755561160346, "train/cont_rate": 0.9944970346715328, "train/dyn_loss_mean": 13.951146696605822, "train/dyn_loss_std": 9.100143007988477, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0507117292306718, "train/extr_critic_critic_opt_grad_steps": 10080.0, "train/extr_critic_critic_opt_loss": 15179.6025390625, "train/extr_critic_mag": 4.110299803044674, "train/extr_critic_max": 4.110299803044674, "train/extr_critic_mean": 1.0341433934921767, "train/extr_critic_min": -0.16375887219923257, "train/extr_critic_std": 1.0124761001036986, "train/extr_return_normed_mag": 1.8424730509737113, "train/extr_return_normed_max": 1.8424730509737113, "train/extr_return_normed_mean": 0.33065210902777903, "train/extr_return_normed_min": -0.1815333621454065, "train/extr_return_normed_std": 0.3386959762033755, "train/extr_return_rate": 0.5355773176590022, "train/extr_return_raw_mag": 5.759418111648003, "train/extr_return_raw_max": 5.759418111648003, "train/extr_return_raw_mean": 1.0466176140917478, "train/extr_return_raw_min": -0.5506944660722775, "train/extr_return_raw_std": 1.0561251888309953, "train/extr_reward_mag": 1.0077507643804062, "train/extr_reward_max": 1.0077507643804062, "train/extr_reward_mean": 0.02097664487949253, "train/extr_reward_min": -0.4387954847656027, "train/extr_reward_std": 0.12667621188137654, "train/image_loss_mean": 11.980085320716357, "train/image_loss_std": 15.447078857978765, "train/model_loss_mean": 20.40412484468335, "train/model_loss_std": 19.35482267393683, "train/model_opt_grad_norm": 78.63492027338404, "train/model_opt_grad_steps": 10066.722627737227, "train/model_opt_loss": 14001.111363765967, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 684.3065693430657, "train/policy_entropy_mag": 2.436825767920835, "train/policy_entropy_max": 2.436825767920835, "train/policy_entropy_mean": 0.701800959388705, "train/policy_entropy_min": 0.07937635606440314, "train/policy_entropy_std": 0.6227410818538527, "train/policy_logprob_mag": 7.438372601557822, "train/policy_logprob_max": -0.009456060860768287, "train/policy_logprob_mean": -0.7035707365857423, "train/policy_logprob_min": -7.438372601557822, "train/policy_logprob_std": 1.1546434799250025, "train/policy_randomness_mag": 0.8600925572597198, "train/policy_randomness_max": 0.8600925572597198, "train/policy_randomness_mean": 0.24770494044697197, "train/policy_randomness_min": 0.02801637033367679, "train/policy_randomness_std": 0.21980027354111636, "train/post_ent_mag": 54.13949506996322, "train/post_ent_max": 54.13949506996322, "train/post_ent_mean": 37.08642767467638, "train/post_ent_min": 20.259982686843315, "train/post_ent_std": 5.81286267468529, "train/prior_ent_mag": 64.12878133954793, "train/prior_ent_max": 64.12878133954793, "train/prior_ent_mean": 51.18666795048401, "train/prior_ent_min": 29.02919543746614, "train/prior_ent_std": 6.735136731697695, "train/rep_loss_mean": 13.951146696605822, "train/rep_loss_std": 9.100143007988477, "train/reward_avg": 0.018129847083838968, "train/reward_loss_mean": 0.05278230521039371, "train/reward_loss_std": 0.2637087303574068, "train/reward_max_data": 1.0116788349012389, "train/reward_max_pred": 1.003070618984473, "train/reward_neg_acc": 0.9933883373754738, "train/reward_neg_loss": 0.03126952052796191, "train/reward_pos_acc": 0.9440178945116753, "train/reward_pos_loss": 0.9708556545911914, "train/reward_pred": 0.017361792113740733, "train/reward_rate": 0.023002680200729927, "train_stats/sum_log_reward": 4.845613958804231, "train_stats/max_log_achievement_collect_drink": 5.350877192982456, "train_stats/max_log_achievement_collect_sapling": 2.9210526315789473, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.824561403508772, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.39473684210526316, "train_stats/max_log_achievement_eat_cow": 0.10526315789473684, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017543859649122806, "train_stats/max_log_achievement_make_wood_sword": 0.008771929824561403, "train_stats/max_log_achievement_place_plant": 2.710526315789474, "train_stats/max_log_achievement_place_table": 1.5701754385964912, "train_stats/max_log_achievement_wake_up": 2.2982456140350878, "train_stats/mean_log_entropy": 0.6590177526599482, "eval_stats/sum_log_reward": 5.037499934434891, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.0260056114930194e-05, "report/cont_loss_std": 0.00023115324438549578, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003553334390744567, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.226224053942133e-06, "report/cont_pred": 0.9941346049308777, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.994853973388672, "report/dyn_loss_std": 8.494711875915527, "report/image_loss_mean": 10.569028854370117, "report/image_loss_std": 13.289774894714355, "report/model_loss_mean": 17.819726943969727, "report/model_loss_std": 16.38311195373535, "report/post_ent_mag": 57.4971923828125, "report/post_ent_max": 57.4971923828125, "report/post_ent_mean": 40.623104095458984, "report/post_ent_min": 18.58066749572754, "report/post_ent_std": 6.940939426422119, "report/prior_ent_mag": 64.62980651855469, "report/prior_ent_max": 64.62980651855469, "report/prior_ent_mean": 52.164329528808594, "report/prior_ent_min": 31.338438034057617, "report/prior_ent_std": 6.494766712188721, "report/rep_loss_mean": 11.994853973388672, "report/rep_loss_std": 8.494711875915527, "report/reward_avg": 0.013867187313735485, "report/reward_loss_mean": 0.053775936365127563, "report/reward_loss_std": 0.24364714324474335, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009889602661133, "report/reward_neg_acc": 0.9880359172821045, "report/reward_neg_loss": 0.03228679299354553, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 1.0801384449005127, "report/reward_pred": 0.013240810483694077, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.31397810037015e-05, "eval/cont_loss_std": 0.0003261111269239336, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00040301354601979256, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1226758942939341e-05, "eval/cont_pred": 0.9951081275939941, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 12.380209922790527, "eval/dyn_loss_std": 8.196702003479004, "eval/image_loss_mean": 9.507193565368652, "eval/image_loss_std": 13.661413192749023, "eval/model_loss_mean": 17.017274856567383, "eval/model_loss_std": 17.082857131958008, "eval/post_ent_mag": 51.925716400146484, "eval/post_ent_max": 51.925716400146484, "eval/post_ent_mean": 38.14128875732422, "eval/post_ent_min": 19.85135269165039, "eval/post_ent_std": 4.976321697235107, "eval/prior_ent_mag": 64.62980651855469, "eval/prior_ent_max": 64.62980651855469, "eval/prior_ent_mean": 48.21492004394531, "eval/prior_ent_min": 28.19991683959961, "eval/prior_ent_std": 6.183419704437256, "eval/rep_loss_mean": 12.380209922790527, "eval/rep_loss_std": 8.196702003479004, "eval/reward_avg": 0.0087890625, "eval/reward_loss_mean": 0.08194241672754288, "eval/reward_loss_std": 0.5931409597396851, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023958683013916, "eval/reward_neg_acc": 0.9980178475379944, "eval/reward_neg_loss": 0.04527110233902931, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 2.5487000942230225, "eval/reward_pred": 0.00519500533118844, "eval/reward_rate": 0.0146484375, "replay/size": 173233.0, "replay/inserts": 21808.0, "replay/samples": 21808.0, "replay/insert_wait_avg": 1.4729737710707867e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.969456267549288e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34936.0, "eval_replay/inserts": 3584.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.289216535431998e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3073148727417, "timer/env.step_count": 2726.0, "timer/env.step_total": 258.34136605262756, "timer/env.step_frac": 0.258004073490126, "timer/env.step_avg": 0.0947693932694892, "timer/env.step_min": 0.023128509521484375, "timer/env.step_max": 3.5334689617156982, "timer/replay._sample_count": 21808.0, "timer/replay._sample_total": 11.538116216659546, "timer/replay._sample_frac": 0.011523051959453577, "timer/replay._sample_avg": 0.0005290772293039043, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.012112140655517578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3174.0, "timer/agent.policy_total": 55.772658348083496, "timer/agent.policy_frac": 0.055699841117381396, "timer/agent.policy_avg": 0.017571726007587742, "timer/agent.policy_min": 0.00961756706237793, "timer/agent.policy_max": 0.12827062606811523, "timer/dataset_train_count": 1363.0, "timer/dataset_train_total": 0.16272854804992676, "timer/dataset_train_frac": 0.00016251608835056626, "timer/dataset_train_avg": 0.00011938998389576432, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.00041174888610839844, "timer/agent.train_count": 1363.0, "timer/agent.train_total": 618.7082228660583, "timer/agent.train_frac": 0.6179004324408549, "timer/agent.train_avg": 0.4539311979941734, "timer/agent.train_min": 0.4386868476867676, "timer/agent.train_max": 1.5624969005584717, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47585272789001465, "timer/agent.report_frac": 0.0004752314507464592, "timer/agent.report_avg": 0.23792636394500732, "timer/agent.report_min": 0.23061823844909668, "timer/agent.report_max": 0.24523448944091797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1430163321443425e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 21.779251923750138}
{"step": 174056, "time": 8362.023245334625, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 174064, "time": 8364.543176651001, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 174400, "time": 8377.795719146729, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 174632, "time": 8386.854479312897, "episode/length": 131.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 174896, "time": 8397.305129528046, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 175272, "time": 8411.3957529068, "episode/length": 559.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 175368, "time": 8416.100449323654, "episode/length": 162.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 175472, "time": 8421.429143190384, "episode/length": 296.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 175552, "time": 8425.64519071579, "episode/length": 226.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 175824, "time": 8436.423770666122, "episode/length": 220.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 175968, "time": 8442.782039165497, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 175992, "time": 8444.98187828064, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 176200, "time": 8453.474296808243, "episode/length": 28.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.8275862068965517, "episode/intrinsic_return": 0.0}
{"step": 176512, "time": 8465.677295446396, "episode/length": 154.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 176528, "time": 8467.81499671936, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 177016, "time": 8485.452512979507, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 177080, "time": 8489.24180150032, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 177144, "time": 8492.953511476517, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 177464, "time": 8505.250761985779, "episode/length": 261.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 177504, "time": 8508.39895248413, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 177736, "time": 8517.434415340424, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 178376, "time": 8540.376967430115, "episode/length": 297.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 178392, "time": 8542.424114704132, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 178472, "time": 8546.607669115067, "episode/length": 165.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 178664, "time": 8554.493272304535, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 178704, "time": 8557.763809919357, "episode/length": 271.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 178776, "time": 8561.711758852005, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 179136, "time": 8575.436174631119, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 179472, "time": 8588.363715410233, "episode/length": 41.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 179640, "time": 8595.264679670334, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 179768, "time": 8601.272356033325, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8631.224436044693, "eval_episode/length": 150.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 180024, "time": 8633.799757242203, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 180024, "time": 8635.728179693222, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 180024, "time": 8637.503489255905, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 180024, "time": 8639.286040306091, "eval_episode/length": 38.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 180024, "time": 8641.142114162445, "eval_episode/length": 195.0, "eval_episode/score": 5.100000016391277, "eval_episode/reward_rate": 0.9897959183673469}
{"step": 180024, "time": 8643.685680389404, "eval_episode/length": 216.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 180024, "time": 8645.73963546753, "eval_episode/length": 225.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 180216, "time": 8652.116861343384, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 180248, "time": 8656.273950099945, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 180392, "time": 8662.671932935715, "episode/length": 249.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 180632, "time": 8672.160582304, "episode/length": 281.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 180720, "time": 8677.024714946747, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 180744, "time": 8679.272093057632, "episode/length": 158.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 181152, "time": 8694.586215496063, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 181176, "time": 8696.754542589188, "episode/length": 191.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 181224, "time": 8699.989584445953, "episode/length": 125.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 182008, "time": 8727.716079473495, "episode/length": 160.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 182040, "time": 8730.504231214523, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 182480, "time": 8747.130329608917, "episode/length": 278.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 182488, "time": 8748.689198493958, "episode/length": 231.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 182512, "time": 8751.26973938942, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 182656, "time": 8757.582478523254, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 182920, "time": 8767.742357254028, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 183280, "time": 8781.40040898323, "episode/length": 154.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 183312, "time": 8783.971638679504, "episode/length": 260.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 183360, "time": 8787.039009094238, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 183496, "time": 8793.141414403915, "episode/length": 126.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.952755905511811, "episode/intrinsic_return": 0.0}
{"step": 183816, "time": 8805.396854877472, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 184168, "time": 8818.942560195923, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 184232, "time": 8823.109986305237, "episode/length": 118.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 184272, "time": 8826.697165250778, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 184392, "time": 8831.976932287216, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 184952, "time": 8852.103853940964, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 185160, "time": 8860.578152418137, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 185160, "time": 8860.586674451828, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 185288, "time": 8868.202984333038, "episode/length": 139.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 185320, "time": 8870.710412979126, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 186016, "time": 8895.497543096542, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 186320, "time": 8907.088455200195, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 186376, "time": 8910.305494070053, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 186400, "time": 8912.96800327301, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 186424, "time": 8915.170578241348, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 186672, "time": 8925.36586689949, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 186728, "time": 8928.665392875671, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 187192, "time": 8945.718042612076, "episode/length": 279.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 187544, "time": 8959.575221061707, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 187648, "time": 8964.853528499603, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 187696, "time": 8967.982589244843, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 187720, "time": 8970.304456233978, "episode/length": 130.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 187848, "time": 8976.213431596756, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 187864, "time": 8978.27627158165, "episode/length": 83.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 188016, "time": 8985.076664209366, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 188224, "time": 8993.602583408356, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 188768, "time": 9014.610837459564, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 188936, "time": 9021.469868183136, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 189160, "time": 9030.2514128685, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 189360, "time": 9038.814488649368, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 189376, "time": 9040.93265414238, "episode/length": 54.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 189400, "time": 9043.124841928482, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 189432, "time": 9045.887009382248, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 189528, "time": 9050.55632686615, "episode/length": 207.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 189536, "time": 9052.62302517891, "episode/length": 226.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 189736, "time": 9060.448474168777, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9085.73794221878, "eval_episode/length": 41.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 190008, "time": 9091.453981876373, "eval_episode/length": 142.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 190008, "time": 9093.193787574768, "eval_episode/length": 146.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 190008, "time": 9096.245957374573, "eval_episode/length": 178.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.994413407821229}
{"step": 190008, "time": 9098.102264881134, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 190008, "time": 9099.953548908234, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 190008, "time": 9102.067494869232, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 190008, "time": 9105.221410274506, "eval_episode/length": 243.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 190632, "time": 9125.986679553986, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 190856, "time": 9134.998742341995, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 190904, "time": 9138.167993068695, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 190960, "time": 9141.964453220367, "episode/length": 197.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 191232, "time": 9152.59411072731, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 191360, "time": 9158.473290681839, "episode/length": 202.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 191848, "time": 9175.97054862976, "episode/length": 289.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 191936, "time": 9180.717805862427, "episode/length": 299.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 192080, "time": 9187.01870751381, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 192176, "time": 9191.802846193314, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 192448, "time": 9202.298153400421, "episode/length": 151.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 192608, "time": 9209.404002904892, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 192800, "time": 9217.964255571365, "episode/length": 270.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 193008, "time": 9226.411608934402, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 193432, "time": 9241.715165138245, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 193488, "time": 9245.475200653076, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 193904, "time": 9260.723166704178, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 193912, "time": 9262.317739486694, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 194000, "time": 9266.954972743988, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 194320, "time": 9279.088877677917, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 194648, "time": 9291.442895650864, "episode/length": 230.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 194736, "time": 9296.261127710342, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 194856, "time": 9301.699160337448, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 194944, "time": 9306.439451932907, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 195080, "time": 9312.267985343933, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 195680, "time": 9333.918184757233, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 195936, "time": 9344.05934715271, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 196105, "time": 9352.063731431961, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.596402849469866, "train/action_min": 0.0, "train/action_std": 3.39855295249394, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05001642274271165, "train/actor_opt_grad_steps": 11465.0, "train/actor_opt_loss": -4.6634298175573345, "train/adv_mag": 0.8038107203585761, "train/adv_max": 0.7910270748393876, "train/adv_mean": 0.0035461656653784043, "train/adv_min": -0.5063301846385002, "train/adv_std": 0.08067144908543145, "train/cont_avg": 0.9944545200892857, "train/cont_loss_mean": 0.00041957628469171075, "train/cont_loss_std": 0.011909109121516995, "train/cont_neg_acc": 0.9837953541960035, "train/cont_neg_loss": 0.03873090701027634, "train/cont_pos_acc": 0.9999438839299338, "train/cont_pos_loss": 0.00019243979396501893, "train/cont_pred": 0.9944834347282138, "train/cont_rate": 0.9944545200892857, "train/dyn_loss_mean": 14.391718850817, "train/dyn_loss_std": 9.123859650748116, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0058206536940166, "train/extr_critic_critic_opt_grad_steps": 11465.0, "train/extr_critic_critic_opt_loss": 15143.39462890625, "train/extr_critic_mag": 4.314571472576686, "train/extr_critic_max": 4.314571472576686, "train/extr_critic_mean": 0.948276755639485, "train/extr_critic_min": -0.1763505152293614, "train/extr_critic_std": 1.0099874070712498, "train/extr_return_normed_mag": 1.8711288690567016, "train/extr_return_normed_max": 1.8711288690567016, "train/extr_return_normed_mean": 0.3127055067036833, "train/extr_return_normed_min": -0.16409436650574208, "train/extr_return_normed_std": 0.338958237107311, "train/extr_return_rate": 0.4813932546547481, "train/extr_return_raw_mag": 5.780793333053589, "train/extr_return_raw_max": 5.780793333053589, "train/extr_return_raw_mean": 0.959265044757298, "train/extr_return_raw_min": -0.5166003506098474, "train/extr_return_raw_std": 1.0488384830100195, "train/extr_reward_mag": 1.0086406060627529, "train/extr_reward_max": 1.0086406060627529, "train/extr_reward_mean": 0.0217861048544624, "train/extr_reward_min": -0.370475686447961, "train/extr_reward_std": 0.13147942572832108, "train/image_loss_mean": 11.022976091929845, "train/image_loss_std": 14.046500362668718, "train/model_loss_mean": 19.71124654497419, "train/model_loss_std": 17.859383296966552, "train/model_opt_grad_norm": 76.14945635114397, "train/model_opt_grad_steps": 11450.492857142857, "train/model_opt_loss": 12840.614760044642, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 656.25, "train/policy_entropy_mag": 2.497669289793287, "train/policy_entropy_max": 2.497669289793287, "train/policy_entropy_mean": 0.733181654555457, "train/policy_entropy_min": 0.07937586983399732, "train/policy_entropy_std": 0.6779974856546946, "train/policy_logprob_mag": 7.438376000949314, "train/policy_logprob_max": -0.009455935171406185, "train/policy_logprob_mean": -0.732280096411705, "train/policy_logprob_min": -7.438376000949314, "train/policy_logprob_std": 1.177706129210336, "train/policy_randomness_mag": 0.8815676540136337, "train/policy_randomness_max": 0.8815676540136337, "train/policy_randomness_mean": 0.25878094817910874, "train/policy_randomness_min": 0.028016198772404875, "train/policy_randomness_std": 0.23930335949574197, "train/post_ent_mag": 54.980938584463935, "train/post_ent_max": 54.980938584463935, "train/post_ent_mean": 37.53935519627162, "train/post_ent_min": 20.41800389971052, "train/post_ent_std": 6.1050327198846, "train/prior_ent_mag": 64.8152693612235, "train/prior_ent_max": 64.8152693612235, "train/prior_ent_mean": 52.104059846060615, "train/prior_ent_min": 30.68546987261091, "train/prior_ent_std": 6.390047703470502, "train/rep_loss_mean": 14.391718850817, "train/rep_loss_std": 9.123859650748116, "train/reward_avg": 0.018630022229626775, "train/reward_loss_mean": 0.052819441564913305, "train/reward_loss_std": 0.26501709084425656, "train/reward_max_data": 1.0064285729612623, "train/reward_max_pred": 1.0037115395069123, "train/reward_neg_acc": 0.9936962651354926, "train/reward_neg_loss": 0.030900647877050297, "train/reward_pos_acc": 0.945508662717683, "train/reward_pos_loss": 0.9675078783716474, "train/reward_pred": 0.017776130509030607, "train/reward_rate": 0.023549107142857142, "train_stats/sum_log_reward": 5.0561402867499154, "train_stats/max_log_achievement_collect_drink": 5.868421052631579, "train_stats/max_log_achievement_collect_sapling": 2.4473684210526314, "train_stats/max_log_achievement_collect_stone": 0.07017543859649122, "train_stats/max_log_achievement_collect_wood": 4.43859649122807, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.37719298245614036, "train_stats/max_log_achievement_eat_cow": 0.12280701754385964, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.14912280701754385, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.1140350877192984, "train_stats/max_log_achievement_place_table": 1.7280701754385965, "train_stats/max_log_achievement_wake_up": 2.473684210526316, "train_stats/mean_log_entropy": 0.6756373387679719, "eval_stats/sum_log_reward": 4.4749999195337296, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 1.5625, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_stone": 0.012658227848101266, "eval_stats/max_log_achievement_place_stone": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.684225016011624e-06, "report/cont_loss_std": 0.00017339781334158033, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011527043534442782, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.606043629313717e-08, "report/cont_pred": 0.9951227903366089, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.1444091796875, "report/dyn_loss_std": 9.01707935333252, "report/image_loss_mean": 9.619386672973633, "report/image_loss_std": 12.972378730773926, "report/model_loss_mean": 18.17153549194336, "report/model_loss_std": 17.094024658203125, "report/post_ent_mag": 51.229591369628906, "report/post_ent_max": 51.229591369628906, "report/post_ent_mean": 37.4808464050293, "report/post_ent_min": 21.021099090576172, "report/post_ent_std": 5.426409721374512, "report/prior_ent_mag": 64.95182800292969, "report/prior_ent_max": 64.95182800292969, "report/prior_ent_mean": 51.6950798034668, "report/prior_ent_min": 29.934906005859375, "report/prior_ent_std": 6.090822219848633, "report/rep_loss_mean": 14.1444091796875, "report/rep_loss_std": 9.01707935333252, "report/reward_avg": 0.01621093600988388, "report/reward_loss_mean": 0.06549718230962753, "report/reward_loss_std": 0.3562175929546356, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0026774406433105, "report/reward_neg_acc": 0.9920239448547363, "report/reward_neg_loss": 0.0469164177775383, "report/reward_pos_acc": 0.9047619104385376, "report/reward_pos_loss": 0.9529500603675842, "report/reward_pred": 0.01509898528456688, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.3227838735474506e-06, "eval/cont_loss_std": 3.673733590403572e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.9686362065840513e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2326778460192145e-06, "eval/cont_pred": 0.995116114616394, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.423718452453613, "eval/dyn_loss_std": 10.064894676208496, "eval/image_loss_mean": 12.594330787658691, "eval/image_loss_std": 15.870725631713867, "eval/model_loss_mean": 21.298614501953125, "eval/model_loss_std": 20.41549301147461, "eval/post_ent_mag": 56.13862609863281, "eval/post_ent_max": 56.13862609863281, "eval/post_ent_mean": 38.60280227661133, "eval/post_ent_min": 22.16706085205078, "eval/post_ent_std": 5.849599361419678, "eval/prior_ent_mag": 64.95182800292969, "eval/prior_ent_max": 64.95182800292969, "eval/prior_ent_mean": 50.524009704589844, "eval/prior_ent_min": 32.995384216308594, "eval/prior_ent_std": 5.787398338317871, "eval/rep_loss_mean": 14.423718452453613, "eval/rep_loss_std": 10.064894676208496, "eval/reward_avg": 0.00986328162252903, "eval/reward_loss_mean": 0.05005069822072983, "eval/reward_loss_std": 0.4026486277580261, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023722648620605, "eval/reward_neg_acc": 0.9950495362281799, "eval/reward_neg_loss": 0.02671346440911293, "eval/reward_pos_acc": 0.785714328289032, "eval/reward_pos_loss": 1.7336655855178833, "eval/reward_pred": 0.009572386741638184, "eval/reward_rate": 0.013671875, "replay/size": 195601.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.400741128962439e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.268671487363452e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38696.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2511902667106467e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4833843708038, "timer/env.step_count": 2796.0, "timer/env.step_total": 257.920449256897, "timer/env.step_frac": 0.25779583477950624, "timer/env.step_avg": 0.09224622648672996, "timer/env.step_min": 0.022394657135009766, "timer/env.step_max": 3.411531925201416, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 11.3949613571167, "timer/replay._sample_frac": 0.011389455872156139, "timer/replay._sample_avg": 0.0005094313911443445, "timer/replay._sample_min": 0.00039649009704589844, "timer/replay._sample_max": 0.008848190307617188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3266.0, "timer/agent.policy_total": 53.52415609359741, "timer/agent.policy_frac": 0.05349829585351718, "timer/agent.policy_avg": 0.01638829029197716, "timer/agent.policy_min": 0.009526491165161133, "timer/agent.policy_max": 0.10709786415100098, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.15516185760498047, "timer/dataset_train_frac": 0.00015508689102574207, "timer/dataset_train_avg": 0.00011098845322244669, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.00044918060302734375, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 623.5162372589111, "timer/agent.train_frac": 0.6232149848755716, "timer/agent.train_avg": 0.4460058921737562, "timer/agent.train_min": 0.43415141105651855, "timer/agent.train_max": 1.489454746246338, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47526073455810547, "timer/agent.report_frac": 0.00047503111194294667, "timer/agent.report_avg": 0.23763036727905273, "timer/agent.report_min": 0.2310183048248291, "timer/agent.report_max": 0.24424242973327637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026453014503661e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 22.35691417293141}
{"step": 196176, "time": 9354.520455360413, "episode/length": 164.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 196208, "time": 9357.138407230377, "episode/length": 235.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 196216, "time": 9358.699064016342, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 196256, "time": 9361.947885036469, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 196856, "time": 9384.985002040863, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 197072, "time": 9394.796184062958, "episode/length": 395.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823232323232324, "episode/intrinsic_return": 0.0}
{"step": 197296, "time": 9403.923490285873, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 197344, "time": 9407.17391705513, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 197456, "time": 9412.50725698471, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 197592, "time": 9418.369453907013, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 198152, "time": 9438.59167098999, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 198592, "time": 9455.21755361557, "episode/length": 363.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 198832, "time": 9464.796016216278, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 198856, "time": 9466.93237733841, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 198912, "time": 9470.61050081253, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 198968, "time": 9473.748260498047, "episode/length": 236.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 199328, "time": 9487.495349407196, "episode/length": 308.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 199824, "time": 9505.754643678665, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 199912, "time": 9509.965346336365, "episode/length": 306.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 200040, "time": 9515.922650814056, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9533.961928606033, "eval_episode/length": 28.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8620689655172413}
{"step": 200096, "time": 9536.154480934143, "eval_episode/length": 45.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 200096, "time": 9538.884388446808, "eval_episode/length": 72.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9315068493150684}
{"step": 200096, "time": 9544.099172115326, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 200096, "time": 9546.09882736206, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 200096, "time": 9547.79379415512, "eval_episode/length": 170.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 200096, "time": 9549.701732635498, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 200096, "time": 9551.600472927094, "eval_episode/length": 182.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 200296, "time": 9558.096319198608, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 200320, "time": 9561.057558774948, "episode/length": 185.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 200472, "time": 9567.793313264847, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 200784, "time": 9580.721335887909, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 200816, "time": 9583.305894851685, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 201120, "time": 9594.909637928009, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 201568, "time": 9611.473114728928, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 201600, "time": 9614.089971542358, "episode/length": 140.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 201768, "time": 9621.147488594055, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 201992, "time": 9630.194837331772, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 202104, "time": 9635.878518819809, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 202216, "time": 9641.11152625084, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 202376, "time": 9648.010943889618, "episode/length": 259.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 202688, "time": 9660.045167684555, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 202736, "time": 9663.312355279922, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 202840, "time": 9668.18502998352, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 203240, "time": 9683.100257873535, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 203920, "time": 9707.719139575958, "episode/length": 226.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 204096, "time": 9715.084907770157, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 204104, "time": 9716.69117307663, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 204152, "time": 9719.759767770767, "episode/length": 241.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 204152, "time": 9719.81119799614, "episode/length": 269.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 204176, "time": 9724.379412412643, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 204344, "time": 9731.512627840042, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 204376, "time": 9734.104023694992, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 204776, "time": 9749.081178188324, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 205440, "time": 9774.315009355545, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 205504, "time": 9778.060002326965, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 205616, "time": 9783.320794343948, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 205736, "time": 9788.891513824463, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 205760, "time": 9791.61958026886, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 206024, "time": 9801.728600978851, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 206024, "time": 9801.737948656082, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 206040, "time": 9805.63121342659, "episode/length": 235.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 207080, "time": 9841.953955888748, "episode/length": 164.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 207176, "time": 9846.748521089554, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 207376, "time": 9855.387585163116, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 207512, "time": 9861.226214170456, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 207632, "time": 9867.055155277252, "episode/length": 273.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 207712, "time": 9871.268542289734, "episode/length": 261.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 207952, "time": 9880.924301862717, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 208184, "time": 9889.903929710388, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 208360, "time": 9897.503336906433, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 208440, "time": 9901.858143806458, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 208616, "time": 9909.355026960373, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 208768, "time": 9916.185079574585, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 208816, "time": 9919.292832612991, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 209144, "time": 9931.33477473259, "episode/length": 40.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 209152, "time": 9933.399168729782, "episode/length": 179.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 209288, "time": 9939.482781887054, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 209664, "time": 9953.69751381874, "episode/length": 162.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 209912, "time": 9963.214460134506, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 209912, "time": 9963.22140789032, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 9992.267921447754, "eval_episode/length": 128.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9689922480620154}
{"step": 210080, "time": 9995.32016992569, "eval_episode/length": 158.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 210080, "time": 9998.003503799438, "eval_episode/length": 184.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 210080, "time": 10000.762246608734, "eval_episode/length": 212.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 210080, "time": 10003.89500951767, "eval_episode/length": 247.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 210080, "time": 10005.564410448074, "eval_episode/length": 249.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.996}
{"step": 210080, "time": 10009.263025283813, "eval_episode/length": 301.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9834437086092715}
{"step": 210080, "time": 10011.126211881638, "eval_episode/length": 308.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9838187702265372}
{"step": 210256, "time": 10016.895021915436, "episode/length": 185.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 210440, "time": 10024.427187681198, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 210496, "time": 10028.24197602272, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 210896, "time": 10043.089083194733, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 210984, "time": 10047.354968070984, "episode/length": 133.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 211168, "time": 10055.379422426224, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 211368, "time": 10063.580205917358, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 211552, "time": 10071.951849222183, "episode/length": 282.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 211608, "time": 10075.202172279358, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 211664, "time": 10078.800657272339, "episode/length": 434.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 212040, "time": 10092.810282468796, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 212136, "time": 10097.507355928421, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 212424, "time": 10108.802974700928, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 212544, "time": 10115.375566959381, "episode/length": 262.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 212864, "time": 10128.172811746597, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 212936, "time": 10131.963938951492, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 213112, "time": 10140.81319141388, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 213336, "time": 10149.934291124344, "episode/length": 27.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 213576, "time": 10159.544036388397, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 213776, "time": 10168.053569316864, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 213848, "time": 10171.742445707321, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 213920, "time": 10176.03343963623, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 213928, "time": 10177.562398910522, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 214328, "time": 10192.388084888458, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 214480, "time": 10199.324063062668, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 215016, "time": 10218.451693058014, "episode/length": 268.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 215032, "time": 10220.434746980667, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 215120, "time": 10225.0822763443, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 215208, "time": 10229.317422151566, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 215312, "time": 10234.522324085236, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 215696, "time": 10249.10430264473, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 215840, "time": 10255.73732495308, "episode/length": 257.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 215976, "time": 10261.484741449356, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 216576, "time": 10283.474112272263, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 216664, "time": 10287.753658771515, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 216840, "time": 10295.33950471878, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 217032, "time": 10303.204844236374, "episode/length": 166.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 217040, "time": 10305.51069521904, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 217096, "time": 10308.739565134048, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 217128, "time": 10311.372256994247, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9656488549618321, "episode/intrinsic_return": 0.0}
{"step": 217520, "time": 10326.163100004196, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 218088, "time": 10346.543594360352, "episode/length": 155.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 218185, "time": 10352.432335615158, "train_stats/sum_log_reward": 5.030434730130693, "train_stats/max_log_achievement_collect_drink": 6.460869565217391, "train_stats/max_log_achievement_collect_sapling": 2.652173913043478, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.034782608695652, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.45217391304347826, "train_stats/max_log_achievement_eat_cow": 0.06956521739130435, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.19130434782608696, "train_stats/max_log_achievement_make_wood_sword": 0.017391304347826087, "train_stats/max_log_achievement_place_plant": 2.1739130434782608, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0869565217391304, "train_stats/max_log_achievement_wake_up": 2.4, "train_stats/mean_log_entropy": 0.6880098674608314, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.803909965183424, "train/action_min": 0.0, "train/action_std": 3.6667869712995445, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05091032488406568, "train/actor_opt_grad_steps": 12855.0, "train/actor_opt_loss": 1.0477290408469844, "train/adv_mag": 0.8020460126192673, "train/adv_max": 0.7849414784839188, "train/adv_mean": 0.00415839439884239, "train/adv_min": -0.5323532089806985, "train/adv_std": 0.08290133341822935, "train/cont_avg": 0.9942538496376812, "train/cont_loss_mean": 0.0005392332689275232, "train/cont_loss_std": 0.015054420269859913, "train/cont_neg_acc": 0.9890499205692954, "train/cont_neg_loss": 0.040846316454405125, "train/cont_pos_acc": 0.9999287996603095, "train/cont_pos_loss": 0.0003035557013067965, "train/cont_pred": 0.9942202891992487, "train/cont_rate": 0.9942538496376812, "train/dyn_loss_mean": 14.381853884544926, "train/dyn_loss_std": 9.15007203558217, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.988672049149223, "train/extr_critic_critic_opt_grad_steps": 12855.0, "train/extr_critic_critic_opt_loss": 15326.527662194294, "train/extr_critic_mag": 4.42916724992835, "train/extr_critic_max": 4.42916724992835, "train/extr_critic_mean": 0.9400839211716168, "train/extr_critic_min": -0.1825954050257586, "train/extr_critic_std": 0.9824021670265474, "train/extr_return_normed_mag": 1.9010353390721306, "train/extr_return_normed_max": 1.9010353390721306, "train/extr_return_normed_mean": 0.3185166217710661, "train/extr_return_normed_min": -0.1852981993469639, "train/extr_return_normed_std": 0.3462132139914278, "train/extr_return_rate": 0.4806343673363976, "train/extr_return_raw_mag": 5.6078497119571855, "train/extr_return_raw_max": 5.6078497119571855, "train/extr_return_raw_mean": 0.9523133812607198, "train/extr_return_raw_min": -0.5299237449316011, "train/extr_return_raw_std": 1.01873463521833, "train/extr_reward_mag": 1.0087899919869243, "train/extr_reward_max": 1.0087899919869243, "train/extr_reward_mean": 0.022828732509219993, "train/extr_reward_min": -0.382923752501391, "train/extr_reward_std": 0.13627513147134712, "train/image_loss_mean": 10.214127913765285, "train/image_loss_std": 13.776614721270574, "train/model_loss_mean": 18.897115493166275, "train/model_loss_std": 17.600159237350244, "train/model_opt_grad_norm": 72.48386023862518, "train/model_opt_grad_steps": 12839.297101449276, "train/model_opt_loss": 12899.674036882925, "train/model_opt_model_opt_grad_overflow": 0.007246376811594203, "train/model_opt_model_opt_grad_scale": 679.3478260869565, "train/policy_entropy_mag": 2.4913309933482735, "train/policy_entropy_max": 2.4913309933482735, "train/policy_entropy_mean": 0.7559936076834581, "train/policy_entropy_min": 0.07937550069629282, "train/policy_entropy_std": 0.7060297416604083, "train/policy_logprob_mag": 7.43837891454282, "train/policy_logprob_max": -0.009455831545958485, "train/policy_logprob_mean": -0.7557691482530124, "train/policy_logprob_min": -7.43837891454282, "train/policy_logprob_std": 1.188426054906154, "train/policy_randomness_mag": 0.8793305102465809, "train/policy_randomness_max": 0.8793305102465809, "train/policy_randomness_mean": 0.26683256710353104, "train/policy_randomness_min": 0.02801606850023719, "train/policy_randomness_std": 0.24919751729222311, "train/post_ent_mag": 55.645163771035016, "train/post_ent_max": 55.645163771035016, "train/post_ent_mean": 38.0228658206221, "train/post_ent_min": 20.289490713589434, "train/post_ent_std": 6.300795057545537, "train/prior_ent_mag": 65.46262420433155, "train/prior_ent_max": 65.46262420433155, "train/prior_ent_mean": 52.568792260211445, "train/prior_ent_min": 31.55530991761581, "train/prior_ent_std": 6.136133885038072, "train/rep_loss_mean": 14.381853884544926, "train/rep_loss_std": 9.15007203558217, "train/reward_avg": 0.020186537508920268, "train/reward_loss_mean": 0.053336023204568504, "train/reward_loss_std": 0.2605483744671379, "train/reward_max_data": 1.0108695678088977, "train/reward_max_pred": 1.0057561907215395, "train/reward_neg_acc": 0.9930404126644135, "train/reward_neg_loss": 0.030282641059138637, "train/reward_pos_acc": 0.9512695000655409, "train/reward_pos_loss": 0.943069022634755, "train/reward_pred": 0.019287859778041424, "train/reward_rate": 0.025348165760869564, "eval_stats/sum_log_reward": 4.474999949336052, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 3.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.3125, "eval_stats/max_log_achievement_wake_up": 2.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.1109664885443635e-05, "report/cont_loss_std": 0.0005694339633919299, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.3086037951288745e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.101570862578228e-05, "report/cont_pred": 0.9970496892929077, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 15.512157440185547, "report/dyn_loss_std": 8.895308494567871, "report/image_loss_mean": 10.014699935913086, "report/image_loss_std": 17.44623565673828, "report/model_loss_mean": 19.36404800415039, "report/model_loss_std": 21.032678604125977, "report/post_ent_mag": 58.63932800292969, "report/post_ent_max": 58.63932800292969, "report/post_ent_mean": 36.272361755371094, "report/post_ent_min": 20.41693687438965, "report/post_ent_std": 5.372437953948975, "report/prior_ent_mag": 65.26082611083984, "report/prior_ent_max": 65.26082611083984, "report/prior_ent_mean": 52.562225341796875, "report/prior_ent_min": 35.760658264160156, "report/prior_ent_std": 5.607895374298096, "report/rep_loss_mean": 15.512157440185547, "report/rep_loss_std": 8.895308494567871, "report/reward_avg": 0.02070312388241291, "report/reward_loss_mean": 0.042032573372125626, "report/reward_loss_std": 0.20712170004844666, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024466514587402, "report/reward_neg_acc": 0.9929929971694946, "report/reward_neg_loss": 0.021964583545923233, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8439494371414185, "report/reward_pred": 0.02052944526076317, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.157983870660246e-07, "eval/cont_loss_std": 7.673304025956895e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.048125967732631e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.186056905084115e-07, "eval/cont_pred": 0.9980462789535522, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.106029510498047, "eval/dyn_loss_std": 11.058847427368164, "eval/image_loss_mean": 16.468841552734375, "eval/image_loss_std": 22.40561294555664, "eval/model_loss_mean": 26.79709815979004, "eval/model_loss_std": 27.382049560546875, "eval/post_ent_mag": 51.56467819213867, "eval/post_ent_max": 51.56467819213867, "eval/post_ent_mean": 37.77959442138672, "eval/post_ent_min": 20.983356475830078, "eval/post_ent_std": 5.208578109741211, "eval/prior_ent_mag": 65.26082611083984, "eval/prior_ent_max": 65.26082611083984, "eval/prior_ent_mean": 51.257755279541016, "eval/prior_ent_min": 30.031341552734375, "eval/prior_ent_std": 5.542787551879883, "eval/rep_loss_mean": 17.106029510498047, "eval/rep_loss_std": 11.058847427368164, "eval/reward_avg": 0.01816406100988388, "eval/reward_loss_mean": 0.06463783979415894, "eval/reward_loss_std": 0.5043299794197083, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0031487941741943, "eval/reward_neg_acc": 0.9950149655342102, "eval/reward_neg_loss": 0.03235961124300957, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.6063075065612793, "eval/reward_pred": 0.01773959957063198, "eval/reward_rate": 0.0205078125, "replay/size": 217681.0, "replay/inserts": 22080.0, "replay/samples": 22080.0, "replay/insert_wait_avg": 1.3744593530461408e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.944044078605762e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42632.0, "eval_replay/inserts": 3936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2620556645277069e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.360445022583, "timer/env.step_count": 2760.0, "timer/env.step_total": 258.8806929588318, "timer/env.step_frac": 0.2587874143234318, "timer/env.step_avg": 0.09379735252131587, "timer/env.step_min": 0.022696971893310547, "timer/env.step_max": 3.52772855758667, "timer/replay._sample_count": 22080.0, "timer/replay._sample_total": 11.392482042312622, "timer/replay._sample_frac": 0.01138837715845056, "timer/replay._sample_avg": 0.0005159638606119847, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.01026010513305664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3252.0, "timer/agent.policy_total": 54.263166189193726, "timer/agent.policy_frac": 0.05424361434839493, "timer/agent.policy_avg": 0.01668609046408171, "timer/agent.policy_min": 0.009380817413330078, "timer/agent.policy_max": 0.1191558837890625, "timer/dataset_train_count": 1380.0, "timer/dataset_train_total": 0.15241074562072754, "timer/dataset_train_frac": 0.00015235582972024337, "timer/dataset_train_avg": 0.00011044256929038227, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010750293731689453, "timer/agent.train_count": 1380.0, "timer/agent.train_total": 620.3530197143555, "timer/agent.train_frac": 0.6201294971237603, "timer/agent.train_avg": 0.44953117370605467, "timer/agent.train_min": 0.43379735946655273, "timer/agent.train_max": 1.5630214214324951, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47521233558654785, "timer/agent.report_frac": 0.00047504110938314837, "timer/agent.report_avg": 0.23760616779327393, "timer/agent.report_min": 0.22891974449157715, "timer/agent.report_max": 0.2462925910949707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074491485257321e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.071753040450176}
{"step": 218272, "time": 10355.525817394257, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 218376, "time": 10360.362255334854, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 218448, "time": 10364.497898101807, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 218472, "time": 10366.620471477509, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 218784, "time": 10378.908779621124, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 218992, "time": 10388.23670911789, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 219448, "time": 10405.288728952408, "episode/length": 82.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 219608, "time": 10412.135355472565, "episode/length": 166.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 219616, "time": 10414.163621902466, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 219664, "time": 10417.55414557457, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 219696, "time": 10420.230929136276, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 219992, "time": 10431.449658632278, "episode/length": 308.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 220056, "time": 10434.937265634537, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10456.836771965027, "eval_episode/length": 158.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 220064, "time": 10458.389578580856, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 220064, "time": 10460.118303537369, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 220064, "time": 10462.015372276306, "eval_episode/length": 164.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 220064, "time": 10463.709811925888, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 220064, "time": 10465.339047670364, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 220064, "time": 10471.494549512863, "eval_episode/length": 277.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9820143884892086}
{"step": 220064, "time": 10474.134908437729, "eval_episode/length": 142.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 220448, "time": 10486.879429340363, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 220728, "time": 10497.698377609253, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 220872, "time": 10504.016254901886, "episode/length": 157.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 220912, "time": 10507.224757194519, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 220936, "time": 10509.314054250717, "episode/length": 164.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 220992, "time": 10512.852005004883, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 221512, "time": 10533.090554714203, "episode/length": 64.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 221664, "time": 10540.008488178253, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 221872, "time": 10548.509736299515, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 221896, "time": 10550.850601434708, "episode/length": 47.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 221968, "time": 10555.035076141357, "episode/length": 246.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 221976, "time": 10556.67154765129, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 222112, "time": 10562.987888097763, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 222168, "time": 10566.302176713943, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 222656, "time": 10584.221248149872, "episode/length": 222.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 222784, "time": 10590.04739356041, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 222856, "time": 10593.772278547287, "episode/length": 122.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 223072, "time": 10603.351449489594, "episode/length": 26.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 223224, "time": 10609.873733758926, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 223264, "time": 10612.976180315018, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 223624, "time": 10626.438293218613, "episode/length": 44.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 223792, "time": 10633.753017187119, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 223936, "time": 10640.11047077179, "episode/length": 143.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 224064, "time": 10645.921131134033, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 224088, "time": 10647.996750116348, "episode/length": 239.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 224296, "time": 10656.52447962761, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 224888, "time": 10677.934632778168, "episode/length": 226.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 224896, "time": 10680.174437046051, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 224920, "time": 10682.275889158249, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 224936, "time": 10684.214156150818, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 225248, "time": 10696.527584552765, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 225368, "time": 10701.948138713837, "episode/length": 133.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 225440, "time": 10706.668448209763, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 225608, "time": 10713.474719524384, "episode/length": 44.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 226176, "time": 10734.691344738007, "episode/length": 159.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 226192, "time": 10736.769479513168, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 226240, "time": 10739.988739013672, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 226328, "time": 10744.236280918121, "episode/length": 179.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 226656, "time": 10757.152230739594, "episode/length": 51.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 226672, "time": 10759.294554710388, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 226696, "time": 10761.381158590317, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 227176, "time": 10779.10403084755, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 227384, "time": 10787.706959486008, "episode/length": 242.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 227704, "time": 10799.906116962433, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 227888, "time": 10808.0635201931, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 227960, "time": 10811.869817733765, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 227984, "time": 10814.429155826569, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 228056, "time": 10818.084034204483, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 228504, "time": 10834.67073750496, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 228576, "time": 10838.92274260521, "episode/length": 280.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 228720, "time": 10845.479712247849, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 229008, "time": 10856.703521251678, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 229216, "time": 10865.436002016068, "episode/length": 153.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 229248, "time": 10868.461184978485, "episode/length": 169.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 229616, "time": 10884.148785114288, "episode/length": 138.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 229624, "time": 10885.904334783554, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10917.185707330704, "eval_episode/length": 47.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 230048, "time": 10922.231849908829, "eval_episode/length": 131.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 230048, "time": 10924.174322128296, "eval_episode/length": 140.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 230048, "time": 10926.6721534729, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 230048, "time": 10928.489709854126, "eval_episode/length": 166.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 230048, "time": 10930.878957509995, "eval_episode/length": 186.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 230048, "time": 10933.73784327507, "eval_episode/length": 167.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 230048, "time": 10939.211454153061, "eval_episode/length": 305.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9901960784313726}
{"step": 230080, "time": 10940.277014017105, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 230336, "time": 10950.345890283585, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 230360, "time": 10952.459646701813, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 230504, "time": 10958.854395866394, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 230768, "time": 10969.403676748276, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 230824, "time": 10972.653491258621, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 231064, "time": 10982.211253404617, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 231224, "time": 10989.216145992279, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 231256, "time": 10991.828633785248, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 231584, "time": 11004.668598413467, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 231608, "time": 11006.801775455475, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 232304, "time": 11031.911640882492, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 232456, "time": 11038.273132562637, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 232656, "time": 11046.745684862137, "episode/length": 178.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 232776, "time": 11052.21518945694, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 232784, "time": 11054.30597281456, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 232936, "time": 11060.723422050476, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 233400, "time": 11077.853333711624, "episode/length": 92.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 233408, "time": 11079.806761026382, "episode/length": 137.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 233480, "time": 11083.504350662231, "episode/length": 424.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 233544, "time": 11087.38523721695, "episode/length": 285.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 233920, "time": 11102.306959629059, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 234136, "time": 11110.882438898087, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 234208, "time": 11115.075136899948, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 234360, "time": 11121.50993013382, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 234944, "time": 11142.64326286316, "episode/length": 191.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 235208, "time": 11152.95180273056, "episode/length": 283.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 235304, "time": 11158.277492761612, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 235672, "time": 11173.110158205032, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 235928, "time": 11183.211956739426, "episode/length": 250.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 235944, "time": 11185.271124124527, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 236016, "time": 11189.384790420532, "episode/length": 326.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938837920489296, "episode/intrinsic_return": 0.0}
{"step": 236032, "time": 11191.498484611511, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 236464, "time": 11207.638032197952, "episode/length": 55.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 236584, "time": 11213.061641216278, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 236880, "time": 11224.724769592285, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 237040, "time": 11231.67348742485, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 237144, "time": 11236.672692537308, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 237256, "time": 11242.052900075912, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 237448, "time": 11249.972651720047, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 237624, "time": 11259.007784128189, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 237656, "time": 11261.6604886055, "episode/length": 148.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 238144, "time": 11279.753234386444, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 238184, "time": 11282.38137125969, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 238184, "time": 11282.397786140442, "episode/length": 142.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 238592, "time": 11299.79345202446, "episode/length": 166.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 239000, "time": 11315.421227931976, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 239048, "time": 11318.576258659363, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 239272, "time": 11328.063648700714, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 239392, "time": 11333.882503509521, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 239576, "time": 11341.340044736862, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 239640, "time": 11345.184053659439, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 239728, "time": 11349.965592384338, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 239737, "time": 11352.725737810135, "train_stats/sum_log_reward": 4.7885245347365, "train_stats/max_log_achievement_collect_drink": 5.909836065573771, "train_stats/max_log_achievement_collect_sapling": 2.1475409836065573, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.549180327868853, "train_stats/max_log_achievement_defeat_skeleton": 0.00819672131147541, "train_stats/max_log_achievement_defeat_zombie": 0.3524590163934426, "train_stats/max_log_achievement_eat_cow": 0.07377049180327869, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3442622950819672, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7540983606557377, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.098360655737705, "train_stats/mean_log_entropy": 0.6494809738436683, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5633130429395985, "train/action_min": 0.0, "train/action_std": 3.3176249212293483, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0496752046660256, "train/actor_opt_grad_steps": 14215.0, "train/actor_opt_loss": -1.3078509995074414, "train/adv_mag": 0.8089342969122217, "train/adv_max": 0.7999292778879848, "train/adv_mean": 0.004565657189395192, "train/adv_min": -0.5147069401260632, "train/adv_std": 0.08108012870287717, "train/cont_avg": 0.9943592583955224, "train/cont_loss_mean": 0.0002684317919781971, "train/cont_loss_std": 0.007773839385697387, "train/cont_neg_acc": 0.991355722075078, "train/cont_neg_loss": 0.023559576000065842, "train/cont_pos_acc": 0.9999486875178208, "train/cont_pos_loss": 0.00013972433737811907, "train/cont_pred": 0.9943397565564113, "train/cont_rate": 0.9943592583955224, "train/dyn_loss_mean": 14.538894603501506, "train/dyn_loss_std": 9.270164461278204, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.947415275805032, "train/extr_critic_critic_opt_grad_steps": 14215.0, "train/extr_critic_critic_opt_loss": 15298.671415869869, "train/extr_critic_mag": 4.647196260850821, "train/extr_critic_max": 4.647196260850821, "train/extr_critic_mean": 0.9677705996072115, "train/extr_critic_min": -0.2093335025346101, "train/extr_critic_std": 1.0051341350398846, "train/extr_return_normed_mag": 1.9299550928286653, "train/extr_return_normed_max": 1.9299550928286653, "train/extr_return_normed_mean": 0.31603801261578035, "train/extr_return_normed_min": -0.18478656565742707, "train/extr_return_normed_std": 0.33912256860466145, "train/extr_return_rate": 0.5123931389691224, "train/extr_return_raw_mag": 5.972240003187265, "train/extr_return_raw_max": 5.972240003187265, "train/extr_return_raw_mean": 0.9818688248520466, "train/extr_return_raw_min": -0.5663867513857671, "train/extr_return_raw_std": 1.0483435588096506, "train/extr_reward_mag": 1.007574325177207, "train/extr_reward_max": 1.007574325177207, "train/extr_reward_mean": 0.02306887061237844, "train/extr_reward_min": -0.43359193161352355, "train/extr_reward_std": 0.1380076530153182, "train/image_loss_mean": 9.917978977089497, "train/image_loss_std": 13.456404917275728, "train/model_loss_mean": 18.695164815703436, "train/model_loss_std": 17.35203773583939, "train/model_opt_grad_norm": 72.43045109421459, "train/model_opt_grad_steps": 14198.119402985074, "train/model_opt_loss": 13896.053907707555, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 746.2686567164179, "train/policy_entropy_mag": 2.50289857565467, "train/policy_entropy_max": 2.50289857565467, "train/policy_entropy_mean": 0.7012886936540035, "train/policy_entropy_min": 0.07937541187031945, "train/policy_entropy_std": 0.6795645271664235, "train/policy_logprob_mag": 7.43838052963143, "train/policy_logprob_max": -0.00945579879152686, "train/policy_logprob_mean": -0.7019084976680243, "train/policy_logprob_min": -7.43838052963143, "train/policy_logprob_std": 1.1735655843321957, "train/policy_randomness_mag": 0.883413361524468, "train/policy_randomness_max": 0.883413361524468, "train/policy_randomness_mean": 0.24752413525955, "train/policy_randomness_min": 0.028016037126975275, "train/policy_randomness_std": 0.23985645441866632, "train/post_ent_mag": 56.51367554735781, "train/post_ent_max": 56.51367554735781, "train/post_ent_mean": 38.43871367155616, "train/post_ent_min": 20.42743625925548, "train/post_ent_std": 6.577948712590915, "train/prior_ent_mag": 65.81516539160884, "train/prior_ent_max": 65.81516539160884, "train/prior_ent_mean": 53.06935970818819, "train/prior_ent_min": 32.08679318783888, "train/prior_ent_std": 6.0721660905809545, "train/rep_loss_mean": 14.538894603501506, "train/rep_loss_std": 9.270164461278204, "train/reward_avg": 0.020385377602512713, "train/reward_loss_mean": 0.053580621924640526, "train/reward_loss_std": 0.2633825054586823, "train/reward_max_data": 1.0089552260156889, "train/reward_max_pred": 1.005048820331915, "train/reward_neg_acc": 0.9932557402262047, "train/reward_neg_loss": 0.03065711921497957, "train/reward_pos_acc": 0.9494482363337902, "train/reward_pos_loss": 0.9446864426136017, "train/reward_pred": 0.01944269989825674, "train/reward_rate": 0.025244869402985076, "eval_stats/sum_log_reward": 4.974999949336052, "eval_stats/max_log_achievement_collect_drink": 6.4375, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.041666666666666664, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0006850495701655746, "report/cont_loss_std": 0.020392179489135742, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.14024566113948822, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5753513455128996e-07, "report/cont_pred": 0.9956320524215698, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.522401809692383, "report/dyn_loss_std": 9.527091026306152, "report/image_loss_mean": 10.069686889648438, "report/image_loss_std": 13.830638885498047, "report/model_loss_mean": 19.449748992919922, "report/model_loss_std": 18.06252098083496, "report/post_ent_mag": 53.23713302612305, "report/post_ent_max": 53.23713302612305, "report/post_ent_mean": 37.65347671508789, "report/post_ent_min": 21.52052116394043, "report/post_ent_std": 5.672519683837891, "report/prior_ent_mag": 66.92373657226562, "report/prior_ent_max": 66.92373657226562, "report/prior_ent_mean": 53.243003845214844, "report/prior_ent_min": 36.23207092285156, "report/prior_ent_std": 5.5650410652160645, "report/rep_loss_mean": 15.522401809692383, "report/rep_loss_std": 9.527091026306152, "report/reward_avg": 0.03154296800494194, "report/reward_loss_mean": 0.06593422591686249, "report/reward_loss_std": 0.2913070321083069, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0028975009918213, "report/reward_neg_acc": 0.9898785948753357, "report/reward_neg_loss": 0.0346309132874012, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.9250363111495972, "report/reward_pred": 0.027325425297021866, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00010704263695515692, "eval/cont_loss_std": 0.0025637641083449125, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.020625248551368713, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.6579069526633248e-05, "eval/cont_pred": 0.9961453676223755, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.716232299804688, "eval/dyn_loss_std": 10.41840934753418, "eval/image_loss_mean": 22.752029418945312, "eval/image_loss_std": 28.201553344726562, "eval/model_loss_mean": 34.0803337097168, "eval/model_loss_std": 32.271209716796875, "eval/post_ent_mag": 58.111846923828125, "eval/post_ent_max": 58.111846923828125, "eval/post_ent_mean": 39.631256103515625, "eval/post_ent_min": 20.886369705200195, "eval/post_ent_std": 6.492436408996582, "eval/prior_ent_mag": 66.92373657226562, "eval/prior_ent_max": 66.92373657226562, "eval/prior_ent_mean": 55.305885314941406, "eval/prior_ent_min": 34.37936019897461, "eval/prior_ent_std": 5.4863433837890625, "eval/rep_loss_mean": 18.716232299804688, "eval/rep_loss_std": 10.41840934753418, "eval/reward_avg": 0.01982421800494194, "eval/reward_loss_mean": 0.09845767170190811, "eval/reward_loss_std": 0.6922576427459717, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022499561309814, "eval/reward_neg_acc": 0.9950000643730164, "eval/reward_neg_loss": 0.025093430653214455, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 3.155301094055176, "eval/reward_pred": 0.008654787205159664, "eval/reward_rate": 0.0234375, "replay/size": 239233.0, "replay/inserts": 21552.0, "replay/samples": 21552.0, "replay/insert_wait_avg": 1.3648445905361162e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.01791282999312e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47544.0, "eval_replay/inserts": 4912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1826279885605802e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3113021850585938e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2806253433228, "timer/env.step_count": 2694.0, "timer/env.step_total": 269.65827894210815, "timer/env.step_frac": 0.2695826272247894, "timer/env.step_avg": 0.10009587191615002, "timer/env.step_min": 0.022593259811401367, "timer/env.step_max": 3.402238368988037, "timer/replay._sample_count": 21552.0, "timer/replay._sample_total": 11.205407857894897, "timer/replay._sample_frac": 0.011202264218652546, "timer/replay._sample_avg": 0.0005199242695756727, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.011356115341186523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3308.0, "timer/agent.policy_total": 53.411736488342285, "timer/agent.policy_frac": 0.05339675200647815, "timer/agent.policy_avg": 0.016146232312074453, "timer/agent.policy_min": 0.009366273880004883, "timer/agent.policy_max": 0.09460592269897461, "timer/dataset_train_count": 1347.0, "timer/dataset_train_total": 0.1458749771118164, "timer/dataset_train_frac": 0.0001458340523807989, "timer/dataset_train_avg": 0.00010829619681649325, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.00020313262939453125, "timer/agent.train_count": 1347.0, "timer/agent.train_total": 607.5045480728149, "timer/agent.train_frac": 0.6073341147283576, "timer/agent.train_avg": 0.4510056036175315, "timer/agent.train_min": 0.4341468811035156, "timer/agent.train_max": 1.6168148517608643, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714353084564209, "timer/agent.report_frac": 0.00047130304887652084, "timer/agent.report_avg": 0.23571765422821045, "timer/agent.report_min": 0.22614574432373047, "timer/agent.report_max": 0.24528956413269043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313088512910325e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 21.54567604215581}
{"step": 239840, "time": 11356.277544021606, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 239968, "time": 11362.109014987946, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11385.745272397995, "eval_episode/length": 60.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 240032, "time": 11388.684069156647, "eval_episode/length": 82.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9518072289156626}
{"step": 240032, "time": 11396.866250038147, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 240032, "time": 11400.51817202568, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 240032, "time": 11402.636167526245, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 240032, "time": 11404.465945720673, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 240032, "time": 11406.476247787476, "eval_episode/length": 243.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9795081967213115}
{"step": 240032, "time": 11413.716797828674, "eval_episode/length": 198.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 240312, "time": 11422.76746726036, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 240392, "time": 11426.937273025513, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 240760, "time": 11440.928503990173, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 241216, "time": 11457.888652324677, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 241272, "time": 11461.146404027939, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 241336, "time": 11464.84230709076, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 241424, "time": 11469.587126016617, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 241616, "time": 11477.521039485931, "episode/length": 34.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.0}
{"step": 241712, "time": 11482.327153921127, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 241832, "time": 11487.625206708908, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 241968, "time": 11493.993003845215, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 242032, "time": 11497.78060221672, "episode/length": 24.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.84, "episode/intrinsic_return": 0.0}
{"step": 242304, "time": 11508.530504226685, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 242392, "time": 11512.99957370758, "episode/length": 374.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 242728, "time": 11526.52441072464, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 242752, "time": 11529.020755529404, "episode/length": 129.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 243160, "time": 11543.992601633072, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 243232, "time": 11548.221512556076, "episode/length": 244.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 243720, "time": 11566.163745164871, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 244016, "time": 11577.962416410446, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 244096, "time": 11582.271955490112, "episode/length": 265.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 244104, "time": 11583.896127462387, "episode/length": 213.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 244120, "time": 11586.122334480286, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 244536, "time": 11601.608095645905, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 244536, "time": 11601.616442203522, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 244760, "time": 11613.425421953201, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 245160, "time": 11628.421020507812, "episode/length": 49.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 245288, "time": 11634.266075134277, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 245640, "time": 11647.79767537117, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 245784, "time": 11655.75823879242, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 245848, "time": 11659.990014076233, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 246000, "time": 11666.858813285828, "episode/length": 237.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 246040, "time": 11669.610476255417, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 246240, "time": 11678.327137231827, "episode/length": 277.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 246328, "time": 11682.631112575531, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 246568, "time": 11692.179126262665, "episode/length": 159.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 246680, "time": 11697.460540771484, "episode/length": 54.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 246872, "time": 11705.448443174362, "episode/length": 135.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 247384, "time": 11724.312192440033, "episode/length": 217.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 247392, "time": 11726.549523591995, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 247440, "time": 11729.69808268547, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 247448, "time": 11731.225030183792, "episode/length": 175.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 247656, "time": 11739.74103975296, "episode/length": 165.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 247768, "time": 11744.982134342194, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 247872, "time": 11750.24351143837, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 248376, "time": 11768.384006977081, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 249000, "time": 11790.687752962112, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 249040, "time": 11793.75821352005, "episode/length": 172.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 249096, "time": 11797.090789079666, "episode/length": 205.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 249160, "time": 11800.754140377045, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 249472, "time": 11812.972736358643, "episode/length": 260.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 249544, "time": 11816.946259975433, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 249880, "time": 11829.857444047928, "episode/length": 310.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11854.194792747498, "eval_episode/length": 120.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9669421487603306}
{"step": 250016, "time": 11856.934576511383, "eval_episode/length": 146.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 250016, "time": 11858.738693237305, "eval_episode/length": 154.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 250016, "time": 11860.643727064133, "eval_episode/length": 163.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 250016, "time": 11863.329046726227, "eval_episode/length": 191.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9635416666666666}
{"step": 250016, "time": 11863.348524570465, "eval_episode/length": 191.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 250016, "time": 11868.852780103683, "eval_episode/length": 242.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 250016, "time": 11871.448052167892, "eval_episode/length": 263.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 250224, "time": 11878.382011175156, "episode/length": 293.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 250240, "time": 11880.528128623962, "episode/length": 154.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 250384, "time": 11886.962183237076, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 250608, "time": 11896.897049188614, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 250656, "time": 11900.068333387375, "episode/length": 53.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 250840, "time": 11907.555947303772, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 251016, "time": 11915.148402929306, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 251024, "time": 11917.125989198685, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 251512, "time": 11935.020468235016, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 252104, "time": 11956.3427464962, "episode/length": 180.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 252312, "time": 11964.873121500015, "episode/length": 240.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 252328, "time": 11966.972359895706, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 252360, "time": 11969.624532222748, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 252440, "time": 11973.810514211655, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 252576, "time": 11980.251066684723, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 252592, "time": 11982.53427696228, "episode/length": 436.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 252784, "time": 11990.494294404984, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 252824, "time": 11993.219594955444, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 253432, "time": 12015.305413246155, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 253616, "time": 12023.414552688599, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 253808, "time": 12031.361108541489, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 253992, "time": 12040.326646327972, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 254128, "time": 12046.669647455215, "episode/length": 226.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 254184, "time": 12049.952909708023, "episode/length": 46.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 254328, "time": 12056.25159406662, "episode/length": 218.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 254464, "time": 12062.72407746315, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 254480, "time": 12064.903225898743, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 254536, "time": 12068.211359739304, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 254856, "time": 12080.445515155792, "episode/length": 48.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 254992, "time": 12086.69395327568, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 255112, "time": 12091.942527294159, "episode/length": 139.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 255504, "time": 12106.837013483047, "episode/length": 146.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 255520, "time": 12109.566962718964, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 255768, "time": 12119.749958753586, "episode/length": 81.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.926829268292683, "episode/intrinsic_return": 0.0}
{"step": 255936, "time": 12127.236601114273, "episode/length": 289.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 255992, "time": 12130.408172369003, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 256096, "time": 12135.64181804657, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 256224, "time": 12141.586285352707, "episode/length": 153.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 256320, "time": 12146.259860754013, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 256872, "time": 12166.082456111908, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 257032, "time": 12173.161139726639, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 257504, "time": 12190.794338464737, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 257520, "time": 12192.90024971962, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 257520, "time": 12192.911969661713, "episode/length": 197.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 257608, "time": 12198.97898888588, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 257704, "time": 12203.844623327255, "episode/length": 241.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.0}
{"step": 258320, "time": 12226.21428656578, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 258448, "time": 12232.116000652313, "episode/length": 265.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 258552, "time": 12236.92445731163, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 258872, "time": 12249.332300901413, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 259424, "time": 12270.138866186142, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 259488, "time": 12273.848957538605, "episode/length": 222.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 259808, "time": 12286.147151231766, "episode/length": 287.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12310.946835756302, "eval_episode/length": 86.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9425287356321839}
{"step": 260000, "time": 12314.504695415497, "eval_episode/length": 133.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 260000, "time": 12316.618520975113, "eval_episode/length": 145.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 260000, "time": 12318.400526046753, "eval_episode/length": 153.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 260000, "time": 12321.395627737045, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 260000, "time": 12323.56090760231, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 260000, "time": 12325.528888702393, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 260000, "time": 12328.523807048798, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 260064, "time": 12330.683060884476, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 260144, "time": 12335.15041565895, "episode/length": 198.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 260601, "time": 12352.734977722168, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.442425676884542, "train/action_min": 0.0, "train/action_std": 3.2066728158761526, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04871172611495011, "train/actor_opt_grad_steps": 15540.0, "train/actor_opt_loss": -5.099313428042499, "train/adv_mag": 0.7582769039023014, "train/adv_max": 0.744360400065211, "train/adv_mean": 0.003918719301245732, "train/adv_min": -0.5177851819810066, "train/adv_std": 0.07802349266432623, "train/cont_avg": 0.994714635019084, "train/cont_loss_mean": 0.00040012681746433987, "train/cont_loss_std": 0.01104169850510214, "train/cont_neg_acc": 0.9907579076199131, "train/cont_neg_loss": 0.026215738970934075, "train/cont_pos_acc": 0.9999100151862806, "train/cont_pos_loss": 0.0002454567577763274, "train/cont_pred": 0.9946809993445418, "train/cont_rate": 0.994714635019084, "train/dyn_loss_mean": 14.72939454144194, "train/dyn_loss_std": 9.16620518051031, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9541453773738774, "train/extr_critic_critic_opt_grad_steps": 15540.0, "train/extr_critic_critic_opt_loss": 15441.73432281727, "train/extr_critic_mag": 4.695420658315411, "train/extr_critic_max": 4.695420658315411, "train/extr_critic_mean": 0.9450188056203245, "train/extr_critic_min": -0.22529933743804464, "train/extr_critic_std": 1.0295674414125107, "train/extr_return_normed_mag": 1.8791054523628177, "train/extr_return_normed_max": 1.8791054523628177, "train/extr_return_normed_mean": 0.30683919116285924, "train/extr_return_normed_min": -0.17799193554252157, "train/extr_return_normed_std": 0.3330975921099423, "train/extr_return_rate": 0.48832153181993326, "train/extr_return_raw_mag": 6.016430574519034, "train/extr_return_raw_max": 6.016430574519034, "train/extr_return_raw_mean": 0.9576185532198608, "train/extr_return_raw_min": -0.6021141867146237, "train/extr_return_raw_std": 1.0717080767828089, "train/extr_reward_mag": 1.0113925970237674, "train/extr_reward_max": 1.0113925970237674, "train/extr_reward_mean": 0.024377553432269862, "train/extr_reward_min": -0.4478790532541639, "train/extr_reward_std": 0.14201357704765014, "train/image_loss_mean": 9.61345220886114, "train/image_loss_std": 13.70054260283026, "train/model_loss_mean": 18.504790335211133, "train/model_loss_std": 17.47737165261771, "train/model_opt_grad_norm": 66.81041504954564, "train/model_opt_grad_steps": 15521.954198473282, "train/model_opt_loss": 13992.920585341126, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 763.3587786259542, "train/policy_entropy_mag": 2.5193729200435957, "train/policy_entropy_max": 2.5193729200435957, "train/policy_entropy_mean": 0.6938933416177299, "train/policy_entropy_min": 0.07937534233085981, "train/policy_entropy_std": 0.6810049491984244, "train/policy_logprob_mag": 7.43838134430747, "train/policy_logprob_max": -0.009455785773808265, "train/policy_logprob_mean": -0.6927507210323829, "train/policy_logprob_min": -7.43838134430747, "train/policy_logprob_std": 1.1671631500011181, "train/policy_randomness_mag": 0.889228081885185, "train/policy_randomness_max": 0.889228081885185, "train/policy_randomness_mean": 0.24491390028527674, "train/policy_randomness_min": 0.0280160125458741, "train/policy_randomness_std": 0.24036486196608944, "train/post_ent_mag": 56.70083117303047, "train/post_ent_max": 56.70083117303047, "train/post_ent_mean": 38.71354436510392, "train/post_ent_min": 20.575611070822212, "train/post_ent_std": 6.696898966345168, "train/prior_ent_mag": 66.17222257424856, "train/prior_ent_max": 66.17222257424856, "train/prior_ent_mean": 53.56317546349445, "train/prior_ent_min": 33.54293318013198, "train/prior_ent_std": 5.624463172359321, "train/rep_loss_mean": 14.72939454144194, "train/rep_loss_std": 9.16620518051031, "train/reward_avg": 0.02106840403053824, "train/reward_loss_mean": 0.05330136591810306, "train/reward_loss_std": 0.2684128533565361, "train/reward_max_data": 1.0099236664881233, "train/reward_max_pred": 1.0037776641263307, "train/reward_neg_acc": 0.9927855579907657, "train/reward_neg_loss": 0.029322650048967083, "train/reward_pos_acc": 0.9458528916344388, "train/reward_pos_loss": 0.961256425344307, "train/reward_pred": 0.020214759993530413, "train/reward_rate": 0.02587517891221374, "train_stats/sum_log_reward": 5.009090882201086, "train_stats/max_log_achievement_collect_coal": 0.00909090909090909, "train_stats/max_log_achievement_collect_drink": 6.527272727272727, "train_stats/max_log_achievement_collect_sapling": 2.3545454545454545, "train_stats/max_log_achievement_collect_stone": 0.01818181818181818, "train_stats/max_log_achievement_collect_wood": 5.654545454545454, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3090909090909091, "train_stats/max_log_achievement_eat_cow": 0.10909090909090909, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.36363636363636365, "train_stats/max_log_achievement_make_wood_sword": 0.00909090909090909, "train_stats/max_log_achievement_place_plant": 1.981818181818182, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0636363636363635, "train_stats/max_log_achievement_wake_up": 2.1454545454545455, "train_stats/mean_log_entropy": 0.6435244859619574, "eval_stats/sum_log_reward": 4.975000003973643, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.416666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.2083333333333335, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.666666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0416666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.2083333333333335, "eval_stats/max_log_achievement_wake_up": 2.2083333333333335, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0004913710872642696, "report/cont_loss_std": 0.01557407807558775, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.10002591460943222, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.9778695989080006e-06, "report/cont_pred": 0.9954991340637207, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.346854209899902, "report/dyn_loss_std": 8.669894218444824, "report/image_loss_mean": 10.181676864624023, "report/image_loss_std": 13.963995933532715, "report/model_loss_mean": 19.446826934814453, "report/model_loss_std": 17.031658172607422, "report/post_ent_mag": 57.65342712402344, "report/post_ent_max": 57.65342712402344, "report/post_ent_mean": 38.26000213623047, "report/post_ent_min": 21.007957458496094, "report/post_ent_std": 7.06782865524292, "report/prior_ent_mag": 65.79080200195312, "report/prior_ent_max": 65.79080200195312, "report/prior_ent_mean": 54.15277862548828, "report/prior_ent_min": 36.72721862792969, "report/prior_ent_std": 5.363376140594482, "report/rep_loss_mean": 15.346854209899902, "report/rep_loss_std": 8.669894218444824, "report/reward_avg": 0.02519531175494194, "report/reward_loss_mean": 0.05654556304216385, "report/reward_loss_std": 0.21153946220874786, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0048387050628662, "report/reward_neg_acc": 0.9949748516082764, "report/reward_neg_loss": 0.036222368478775024, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7538414001464844, "report/reward_pred": 0.025713885203003883, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.00022514206648338586, "eval/cont_loss_std": 0.007121189031749964, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03268381208181381, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.729426685415092e-06, "eval/cont_pred": 0.993362307548523, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.70386505126953, "eval/dyn_loss_std": 11.008201599121094, "eval/image_loss_mean": 16.16538429260254, "eval/image_loss_std": 25.950397491455078, "eval/model_loss_mean": 26.27899742126465, "eval/model_loss_std": 29.760765075683594, "eval/post_ent_mag": 58.716819763183594, "eval/post_ent_max": 58.716819763183594, "eval/post_ent_mean": 39.50371551513672, "eval/post_ent_min": 22.478004455566406, "eval/post_ent_std": 6.824635028839111, "eval/prior_ent_mag": 65.79080200195312, "eval/prior_ent_max": 65.79080200195312, "eval/prior_ent_mean": 53.61744689941406, "eval/prior_ent_min": 31.085609436035156, "eval/prior_ent_std": 6.0143513679504395, "eval/rep_loss_mean": 16.70386505126953, "eval/rep_loss_std": 11.008201599121094, "eval/reward_avg": 0.015625, "eval/reward_loss_mean": 0.09106884151697159, "eval/reward_loss_std": 0.5297785401344299, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011413097381592, "eval/reward_neg_acc": 0.9950049519538879, "eval/reward_neg_loss": 0.047351907938718796, "eval/reward_pos_acc": 0.695652186870575, "eval/reward_pos_loss": 1.9937057495117188, "eval/reward_pred": 0.010955720208585262, "eval/reward_rate": 0.0224609375, "replay/size": 260097.0, "replay/inserts": 20864.0, "replay/samples": 20864.0, "replay/insert_wait_avg": 1.3625992039229973e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0664729070078375e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54632.0, "eval_replay/inserts": 7088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2076331584232925e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9950828552246, "timer/env.step_count": 2608.0, "timer/env.step_total": 246.73034477233887, "timer/env.step_frac": 0.24673155798713015, "timer/env.step_avg": 0.09460519354767595, "timer/env.step_min": 0.02287745475769043, "timer/env.step_max": 4.2926554679870605, "timer/replay._sample_count": 20864.0, "timer/replay._sample_total": 10.965173244476318, "timer/replay._sample_frac": 0.01096522716208577, "timer/replay._sample_avg": 0.0005255546992176149, "timer/replay._sample_min": 0.0004067420959472656, "timer/replay._sample_max": 0.011167049407958984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3494.0, "timer/agent.policy_total": 57.53042984008789, "timer/agent.policy_frac": 0.0575307127269314, "timer/agent.policy_avg": 0.016465492226699453, "timer/agent.policy_min": 0.00919032096862793, "timer/agent.policy_max": 0.12415766716003418, "timer/dataset_train_count": 1304.0, "timer/dataset_train_total": 0.1418142318725586, "timer/dataset_train_frac": 0.00014181492919709677, "timer/dataset_train_avg": 0.00010875324530104187, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010750293731689453, "timer/agent.train_count": 1304.0, "timer/agent.train_total": 589.3649847507477, "timer/agent.train_frac": 0.5893678827579532, "timer/agent.train_avg": 0.4519670128456654, "timer/agent.train_min": 0.4393043518066406, "timer/agent.train_max": 1.5054214000701904, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769277572631836, "timer/agent.report_frac": 0.00047693010239754485, "timer/agent.report_avg": 0.2384638786315918, "timer/agent.report_min": 0.23221755027770996, "timer/agent.report_max": 0.24471020698547363, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170982694231769e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 20.863831783247132}
{"step": 260608, "time": 12352.763041496277, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 260816, "time": 12361.924315214157, "episode/length": 242.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 260832, "time": 12364.04037976265, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 261024, "time": 12372.101998090744, "episode/length": 437.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 261224, "time": 12380.229562044144, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 261568, "time": 12393.600692749023, "episode/length": 119.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 261672, "time": 12398.554964542389, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 262000, "time": 12411.502159833908, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 262384, "time": 12428.39930343628, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 262520, "time": 12434.333274364471, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 262912, "time": 12449.336862802505, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 262936, "time": 12451.447007894516, "episode/length": 438.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 263184, "time": 12461.714964151382, "episode/length": 295.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 263256, "time": 12465.498948812485, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 263560, "time": 12477.909676790237, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 264584, "time": 12514.100372552872, "episode/length": 257.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 264616, "time": 12517.413224458694, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 264624, "time": 12519.49508857727, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 12521.594634771347, "episode/length": 427.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 264880, "time": 12531.272622346878, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 264992, "time": 12536.618928670883, "episode/length": 42.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 265248, "time": 12546.735377550125, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 265528, "time": 12557.827817678452, "episode/length": 323.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 265776, "time": 12568.441493034363, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 265848, "time": 12572.156991004944, "episode/length": 432.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 265912, "time": 12575.957385778427, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9506172839506173, "episode/intrinsic_return": 0.0}
{"step": 266296, "time": 12590.293716669083, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 266408, "time": 12595.535358190536, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 266496, "time": 12600.300991773605, "episode/length": 187.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 266512, "time": 12602.459466934204, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 266808, "time": 12613.815973043442, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 266888, "time": 12618.236390590668, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 267456, "time": 12639.231180906296, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 267584, "time": 12645.055068731308, "episode/length": 225.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 267664, "time": 12649.42920422554, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 267728, "time": 12653.114093542099, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 268040, "time": 12665.15498971939, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 268168, "time": 12671.192601442337, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 268320, "time": 12678.041910409927, "episode/length": 348.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9914040114613181, "episode/intrinsic_return": 0.0}
{"step": 268416, "time": 12682.773114681244, "episode/length": 239.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 268728, "time": 12694.497458696365, "episode/length": 50.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 268792, "time": 12698.34724521637, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 269064, "time": 12708.986468791962, "episode/length": 166.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 269128, "time": 12712.710918664932, "episode/length": 49.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 269392, "time": 12723.40398812294, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 269528, "time": 12729.695042133331, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 269840, "time": 12741.999388694763, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 270008, "time": 12749.076947689056, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12773.625801324844, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 270088, "time": 12775.413691997528, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 270088, "time": 12777.422624111176, "eval_episode/length": 189.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 270088, "time": 12779.301457881927, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 270088, "time": 12779.308431863785, "eval_episode/length": 197.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 270088, "time": 12782.717183589935, "eval_episode/length": 199.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.965}
{"step": 270088, "time": 12785.974723815918, "eval_episode/length": 237.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9873949579831933}
{"step": 270088, "time": 12788.187144517899, "eval_episode/length": 52.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 270168, "time": 12790.853817224503, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 270344, "time": 12798.577054023743, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 270464, "time": 12805.781059741974, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 270632, "time": 12812.676941156387, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 270632, "time": 12812.686396598816, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 271312, "time": 12839.103974342346, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 271352, "time": 12841.717540502548, "episode/length": 319.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978125, "episode/intrinsic_return": 0.0}
{"step": 271416, "time": 12845.568706035614, "episode/length": 97.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 271584, "time": 12853.104507684708, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 271832, "time": 12862.675971269608, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 271960, "time": 12868.450391292572, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 272048, "time": 12873.261653661728, "episode/length": 254.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 272216, "time": 12880.333201408386, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 272456, "time": 12889.87197637558, "episode/length": 50.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 272752, "time": 12901.572127342224, "episode/length": 166.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 272928, "time": 12909.762082576752, "episode/length": 201.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 273128, "time": 12917.765331745148, "episode/length": 46.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 273232, "time": 12923.276558637619, "episode/length": 205.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 273464, "time": 12933.017234563828, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 273608, "time": 12939.544864416122, "episode/length": 281.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 273784, "time": 12947.062490940094, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 273952, "time": 12954.410921573639, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 274072, "time": 12959.847342729568, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 274168, "time": 12964.522725582123, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 274464, "time": 12976.319184541702, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 274696, "time": 12985.556276082993, "episode/length": 153.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 274904, "time": 12994.307047367096, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 275224, "time": 13006.592513799667, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 275296, "time": 13010.746663570404, "episode/length": 167.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 275472, "time": 13018.23451757431, "episode/length": 210.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 275560, "time": 13022.457628011703, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 275664, "time": 13027.820424318314, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 275912, "time": 13037.68688583374, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 276080, "time": 13045.030606269836, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 276640, "time": 13065.592633485794, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 276720, "time": 13069.938352108002, "episode/length": 144.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 276816, "time": 13074.726463079453, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 276856, "time": 13077.940537691116, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 277008, "time": 13085.40299654007, "episode/length": 167.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 277216, "time": 13094.271962881088, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 277296, "time": 13098.43606042862, "episode/length": 227.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 277632, "time": 13111.175684452057, "episode/length": 193.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 277840, "time": 13119.854944229126, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 277896, "time": 13123.055448055267, "episode/length": 110.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 277912, "time": 13125.448105573654, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 278200, "time": 13136.674667596817, "episode/length": 194.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 278216, "time": 13138.864596128464, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 278568, "time": 13153.757848501205, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 278672, "time": 13159.298662900925, "episode/length": 171.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 278912, "time": 13168.85323047638, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 279216, "time": 13180.728699207306, "episode/length": 171.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 279336, "time": 13186.125437259674, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 279392, "time": 13189.923686742783, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 279472, "time": 13194.160675287247, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 279640, "time": 13201.080435752869, "episode/length": 179.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 279752, "time": 13206.458319664001, "episode/length": 134.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 279808, "time": 13210.274176359177, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 279976, "time": 13217.210101366043, "episode/length": 79.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13243.681123971939, "eval_episode/length": 147.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 280072, "time": 13245.598919391632, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 280072, "time": 13247.234800100327, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 280072, "time": 13249.218449354172, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9640718562874252}
{"step": 280072, "time": 13251.602743148804, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 280072, "time": 13255.126788854599, "eval_episode/length": 231.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 280072, "time": 13258.162407159805, "eval_episode/length": 265.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 280072, "time": 13260.479365110397, "eval_episode/length": 51.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 280696, "time": 13281.555475473404, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 280768, "time": 13285.754523992538, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 280872, "time": 13290.469085931778, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 280920, "time": 13293.668758153915, "episode/length": 159.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 280920, "time": 13293.67746424675, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 281232, "time": 13307.632223844528, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 281304, "time": 13311.471989393234, "episode/length": 186.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 281920, "time": 13334.023970842361, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 281984, "time": 13337.980989456177, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 282361, "time": 13352.937159538269, "train_stats/sum_log_reward": 5.004347777172275, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.121739130434783, "train_stats/max_log_achievement_collect_sapling": 2.4521739130434783, "train_stats/max_log_achievement_collect_stone": 0.10434782608695652, "train_stats/max_log_achievement_collect_wood": 5.51304347826087, "train_stats/max_log_achievement_defeat_skeleton": 0.034782608695652174, "train_stats/max_log_achievement_defeat_zombie": 0.33043478260869563, "train_stats/max_log_achievement_eat_cow": 0.09565217391304348, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.23478260869565218, "train_stats/max_log_achievement_make_wood_sword": 0.034782608695652174, "train_stats/max_log_achievement_place_plant": 2.1826086956521737, "train_stats/max_log_achievement_place_stone": 0.034782608695652174, "train_stats/max_log_achievement_place_table": 2.0869565217391304, "train_stats/max_log_achievement_wake_up": 2.226086956521739, "train_stats/mean_log_entropy": 0.6575239050647487, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.824127197265625, "train/action_min": 0.0, "train/action_std": 3.59225491215201, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04950921357992817, "train/actor_opt_grad_steps": 16875.0, "train/actor_opt_loss": -4.846563534263303, "train/adv_mag": 0.7857555532280136, "train/adv_max": 0.7708668792072464, "train/adv_mean": 0.003641864989303405, "train/adv_min": -0.5135699591654188, "train/adv_std": 0.07785626333754729, "train/cont_avg": 0.9944278492647058, "train/cont_loss_mean": 0.0004218077799332613, "train/cont_loss_std": 0.012245454874355995, "train/cont_neg_acc": 0.993024691828975, "train/cont_neg_loss": 0.015200090827366458, "train/cont_pos_acc": 0.9999059802469086, "train/cont_pos_loss": 0.00034406998868827417, "train/cont_pred": 0.9943608987857314, "train/cont_rate": 0.9944278492647058, "train/dyn_loss_mean": 14.550478598650765, "train/dyn_loss_std": 9.143971057499156, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.893091631724554, "train/extr_critic_critic_opt_grad_steps": 16875.0, "train/extr_critic_critic_opt_loss": 15317.126680261948, "train/extr_critic_mag": 4.704577421440797, "train/extr_critic_max": 4.704577421440797, "train/extr_critic_mean": 0.9354474875418579, "train/extr_critic_min": -0.22443219668724956, "train/extr_critic_std": 1.0376184223329319, "train/extr_return_normed_mag": 1.8805052681880838, "train/extr_return_normed_max": 1.8805052681880838, "train/extr_return_normed_mean": 0.30836527159108834, "train/extr_return_normed_min": -0.17700085652006023, "train/extr_return_normed_std": 0.33804204501211643, "train/extr_return_rate": 0.4733968349721502, "train/extr_return_raw_mag": 5.942940841702854, "train/extr_return_raw_max": 5.942940841702854, "train/extr_return_raw_mean": 0.9469839387080249, "train/extr_return_raw_min": -0.5954271317185724, "train/extr_return_raw_std": 1.0743546547258602, "train/extr_reward_mag": 1.0095862886484932, "train/extr_reward_max": 1.0095862886484932, "train/extr_reward_mean": 0.024092449255369824, "train/extr_reward_min": -0.4366740847335142, "train/extr_reward_std": 0.14204070793793483, "train/image_loss_mean": 9.100686434437247, "train/image_loss_std": 12.8485269055647, "train/model_loss_mean": 17.884001219973843, "train/model_loss_std": 16.64401431644664, "train/model_opt_grad_norm": 65.27882606842938, "train/model_opt_grad_steps": 16856.0, "train/model_opt_loss": 14602.792063993566, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 818.0147058823529, "train/policy_entropy_mag": 2.514228473691379, "train/policy_entropy_max": 2.514228473691379, "train/policy_entropy_mean": 0.7207330859759274, "train/policy_entropy_min": 0.07937527847859789, "train/policy_entropy_std": 0.7099202963359216, "train/policy_logprob_mag": 7.438381671905518, "train/policy_logprob_max": -0.009455736705978565, "train/policy_logprob_mean": -0.7210014181978562, "train/policy_logprob_min": -7.438381671905518, "train/policy_logprob_std": 1.1842335515162523, "train/policy_randomness_mag": 0.8874123184119954, "train/policy_randomness_max": 0.8874123184119954, "train/policy_randomness_mean": 0.25438714969684095, "train/policy_randomness_min": 0.02801598991979571, "train/policy_randomness_std": 0.250570709214491, "train/post_ent_mag": 56.94523354137645, "train/post_ent_max": 56.94523354137645, "train/post_ent_mean": 39.09006155238432, "train/post_ent_min": 20.617722875931683, "train/post_ent_std": 6.800482655272765, "train/prior_ent_mag": 66.54119659872616, "train/prior_ent_max": 66.54119659872616, "train/prior_ent_mean": 53.73241999570061, "train/prior_ent_min": 33.912820255055145, "train/prior_ent_std": 5.59164684309679, "train/rep_loss_mean": 14.550478598650765, "train/rep_loss_std": 9.143971057499156, "train/reward_avg": 0.021241670316906974, "train/reward_loss_mean": 0.05260577945805648, "train/reward_loss_std": 0.25263802641454863, "train/reward_max_data": 1.0110294143943226, "train/reward_max_pred": 1.0065630314981235, "train/reward_neg_acc": 0.9931708929293296, "train/reward_neg_loss": 0.030091785918236438, "train/reward_pos_acc": 0.9590791634777013, "train/reward_pos_loss": 0.8933131453745505, "train/reward_pred": 0.020580995848457163, "train/reward_rate": 0.02617331112132353, "eval_stats/sum_log_reward": 5.162499889731407, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 5.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 8.095709199551493e-05, "report/cont_loss_std": 0.001366929616779089, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002689697779715061, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.300114910118282e-05, "report/cont_pred": 0.993120551109314, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.798514366149902, "report/dyn_loss_std": 8.48646068572998, "report/image_loss_mean": 6.023695945739746, "report/image_loss_std": 8.43492603302002, "report/model_loss_mean": 14.357881546020508, "report/model_loss_std": 11.877907752990723, "report/post_ent_mag": 56.324195861816406, "report/post_ent_max": 56.324195861816406, "report/post_ent_mean": 38.05895233154297, "report/post_ent_min": 20.422855377197266, "report/post_ent_std": 6.666931629180908, "report/prior_ent_mag": 67.02883911132812, "report/prior_ent_max": 67.02883911132812, "report/prior_ent_mean": 52.78571701049805, "report/prior_ent_min": 31.400941848754883, "report/prior_ent_std": 5.911062240600586, "report/rep_loss_mean": 13.798514366149902, "report/rep_loss_std": 8.48646068572998, "report/reward_avg": 0.02353515475988388, "report/reward_loss_mean": 0.05499700456857681, "report/reward_loss_std": 0.2660050392150879, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.092559814453125, "report/reward_neg_acc": 0.995979905128479, "report/reward_neg_loss": 0.03130653128027916, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8678253293037415, "report/reward_pred": 0.023429682478308678, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.00017165043391287327, "eval/cont_loss_std": 0.004826159682124853, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0024385973811149597, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00015604702639393508, "eval/cont_pred": 0.9930366277694702, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.555131912231445, "eval/dyn_loss_std": 10.673498153686523, "eval/image_loss_mean": 17.242324829101562, "eval/image_loss_std": 22.18962860107422, "eval/model_loss_mean": 28.499881744384766, "eval/model_loss_std": 26.34476661682129, "eval/post_ent_mag": 52.63491439819336, "eval/post_ent_max": 52.63491439819336, "eval/post_ent_mean": 38.581787109375, "eval/post_ent_min": 21.02457046508789, "eval/post_ent_std": 6.421375274658203, "eval/prior_ent_mag": 67.02883911132812, "eval/prior_ent_max": 67.02883911132812, "eval/prior_ent_mean": 54.16520690917969, "eval/prior_ent_min": 36.47062683105469, "eval/prior_ent_std": 5.073358058929443, "eval/rep_loss_mean": 18.555131912231445, "eval/rep_loss_std": 10.673498153686523, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.12430818378925323, "eval/reward_loss_std": 0.700444757938385, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011622905731201, "eval/reward_neg_acc": 0.9909547567367554, "eval/reward_neg_loss": 0.0647643432021141, "eval/reward_pos_acc": 0.7241379022598267, "eval/reward_pos_loss": 2.1672780513763428, "eval/reward_pred": 0.019808372482657433, "eval/reward_rate": 0.0283203125, "replay/size": 281857.0, "replay/inserts": 21760.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.3700631611487444e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.329441715689267e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58912.0, "eval_replay/inserts": 4280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1987218232912437e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1880202293396, "timer/env.step_count": 2720.0, "timer/env.step_total": 262.70673847198486, "timer/env.step_frac": 0.26265735357612774, "timer/env.step_avg": 0.09658335973234737, "timer/env.step_min": 0.022758007049560547, "timer/env.step_max": 3.5553228855133057, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.311432123184204, "timer/replay._sample_frac": 0.011309305744924373, "timer/replay._sample_avg": 0.000519826843896333, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.026256084442138672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3255.0, "timer/agent.policy_total": 54.26721978187561, "timer/agent.policy_frac": 0.05425701836483937, "timer/agent.policy_avg": 0.01667195692223521, "timer/agent.policy_min": 0.00931239128112793, "timer/agent.policy_max": 0.11784815788269043, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.14964914321899414, "timer/dataset_train_frac": 0.00014962101144210877, "timer/dataset_train_avg": 0.00011003613471984863, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0004258155822753906, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 614.5802290439606, "timer/agent.train_frac": 0.6144646972506624, "timer/agent.train_avg": 0.4518972272382063, "timer/agent.train_min": 0.4393894672393799, "timer/agent.train_max": 1.618546962738037, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4801363945007324, "timer/agent.report_frac": 0.00048004613611612627, "timer/agent.report_avg": 0.2400681972503662, "timer/agent.report_min": 0.23316097259521484, "timer/agent.report_max": 0.24697542190551758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051184128160466e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.755611395840866}
{"step": 282376, "time": 13353.041917085648, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 282728, "time": 13367.494681119919, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 282872, "time": 13374.046155452728, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 283528, "time": 13398.037491559982, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 283888, "time": 13411.752956867218, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 283904, "time": 13413.925302505493, "episode/length": 400.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 283992, "time": 13418.420520305634, "episode/length": 383.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 284128, "time": 13424.826713562012, "episode/length": 29.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 284424, "time": 13436.3353369236, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 284472, "time": 13439.579978466034, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 284632, "time": 13446.606959819794, "episode/length": 237.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 284784, "time": 13453.437803268433, "episode/length": 434.0, "episode/score": 7.1000000461936, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 285208, "time": 13469.361270904541, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 285440, "time": 13479.028882265091, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 285472, "time": 13481.57644200325, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 285720, "time": 13491.243820667267, "episode/length": 161.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 286120, "time": 13506.241391420364, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 286280, "time": 13513.15400671959, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 286320, "time": 13516.248303413391, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 286560, "time": 13525.83173251152, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 286600, "time": 13528.55009818077, "episode/length": 265.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 286968, "time": 13543.937740564346, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 287240, "time": 13554.643930912018, "episode/length": 224.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 287368, "time": 13560.450917243958, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 287512, "time": 13566.863481760025, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 287640, "time": 13572.702006340027, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 287712, "time": 13576.932467460632, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 287888, "time": 13584.333143234253, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 288128, "time": 13594.087664842606, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 288184, "time": 13597.475975036621, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 288224, "time": 13600.847456216812, "episode/length": 63.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 288472, "time": 13610.583654165268, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 288480, "time": 13612.595164060593, "episode/length": 239.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 288872, "time": 13627.140335559845, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 289160, "time": 13638.215220451355, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 289464, "time": 13649.911061048508, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 289584, "time": 13655.72379565239, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 289728, "time": 13662.190428256989, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13689.937136888504, "eval_episode/length": 48.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 290056, "time": 13694.814726352692, "eval_episode/length": 123.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9516129032258065}
{"step": 290056, "time": 13697.776888847351, "eval_episode/length": 156.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 290056, "time": 13699.672306537628, "eval_episode/length": 165.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 290056, "time": 13701.13162946701, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 290056, "time": 13704.092067480087, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 290056, "time": 13706.031667232513, "eval_episode/length": 207.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 290056, "time": 13708.04438996315, "eval_episode/length": 53.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 290144, "time": 13711.192297935486, "episode/length": 207.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 290176, "time": 13713.745149850845, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 290696, "time": 13732.460576295853, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 290840, "time": 13738.647941827774, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 290864, "time": 13741.345036506653, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 290920, "time": 13744.605134487152, "episode/length": 378.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 291064, "time": 13750.923759937286, "episode/length": 273.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 291128, "time": 13754.625405311584, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 291400, "time": 13765.146744251251, "episode/length": 41.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 291424, "time": 13767.755093336105, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 291568, "time": 13774.084703445435, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 291984, "time": 13789.600526809692, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 292168, "time": 13797.154344320297, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 292512, "time": 13810.528366327286, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 292664, "time": 13817.051982164383, "episode/length": 191.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 292720, "time": 13820.69878077507, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 292760, "time": 13823.321299314499, "episode/length": 236.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 293200, "time": 13839.979511260986, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 293304, "time": 13844.735564947128, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 293448, "time": 13851.155762672424, "episode/length": 325.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 293488, "time": 13854.397962331772, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 293728, "time": 13863.923148155212, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 294264, "time": 13883.388914108276, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 294392, "time": 13889.329720973969, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 294608, "time": 13898.375596523285, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 294760, "time": 13904.695710659027, "episode/length": 261.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 294760, "time": 13904.70458316803, "episode/length": 163.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 294840, "time": 13910.971731901169, "episode/length": 204.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9902439024390244, "episode/intrinsic_return": 0.0}
{"step": 295352, "time": 13930.942109107971, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 295512, "time": 13937.850907087326, "episode/length": 252.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 296064, "time": 13958.26428771019, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 296296, "time": 13967.67472577095, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 296344, "time": 13970.864928722382, "episode/length": 216.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 296448, "time": 13976.215921640396, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 296872, "time": 13991.849112987518, "episode/length": 65.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 296936, "time": 13995.51148724556, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 297080, "time": 14001.950442790985, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 297408, "time": 14014.852463245392, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 297408, "time": 14014.860362291336, "episode/length": 256.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 297768, "time": 14030.13704419136, "episode/length": 103.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 297856, "time": 14034.871703624725, "episode/length": 376.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 298200, "time": 14047.82600235939, "episode/length": 98.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 298216, "time": 14049.969756603241, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 298256, "time": 14053.112259149551, "episode/length": 342.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941690962099126, "episode/intrinsic_return": 0.0}
{"step": 298352, "time": 14057.831014871597, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 298968, "time": 14079.626115560532, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 299112, "time": 14085.923345804214, "episode/length": 332.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 299272, "time": 14092.850299835205, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 299568, "time": 14104.600584983826, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 299656, "time": 14108.922069072723, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 14111.530328273773, "episode/length": 182.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 299832, "time": 14117.958354711533, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14145.72094297409, "eval_episode/length": 141.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 300040, "time": 14147.757302761078, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 300040, "time": 14149.384300470352, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 300040, "time": 14151.849489450455, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 300040, "time": 14153.464961767197, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 300040, "time": 14155.788278102875, "eval_episode/length": 194.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 300040, "time": 14158.173500537872, "eval_episode/length": 213.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 300040, "time": 14159.677169561386, "eval_episode/length": 63.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.984375}
{"step": 300104, "time": 14161.784780025482, "episode/length": 55.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 300264, "time": 14168.720222711563, "episode/length": 257.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 300456, "time": 14176.64167380333, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 300672, "time": 14185.491217136383, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 300784, "time": 14190.865932703018, "episode/length": 188.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 300832, "time": 14194.283502578735, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 301024, "time": 14202.31206703186, "episode/length": 238.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 301504, "time": 14219.860411643982, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 301552, "time": 14223.040484189987, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 301736, "time": 14230.459012508392, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 301824, "time": 14235.155311346054, "episode/length": 267.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 302192, "time": 14248.948807239532, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 302296, "time": 14253.849505901337, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 302320, "time": 14256.709534168243, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 302672, "time": 14269.88866019249, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 303024, "time": 14283.127310037613, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 303072, "time": 14286.441548347473, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 303072, "time": 14286.448287725449, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 303232, "time": 14296.433185815811, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 303280, "time": 14299.505280017853, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 303736, "time": 14315.940667629242, "episode/length": 176.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 304152, "time": 14331.411083221436, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 304424, "time": 14342.231088161469, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 304440, "time": 14344.36918926239, "episode/length": 170.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 304576, "time": 14350.845957756042, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 304577, "time": 14352.970366239548, "train_stats/sum_log_reward": 5.352173852920532, "train_stats/max_log_achievement_collect_coal": 0.034782608695652174, "train_stats/max_log_achievement_collect_drink": 4.643478260869565, "train_stats/max_log_achievement_collect_sapling": 2.8086956521739133, "train_stats/max_log_achievement_collect_stone": 0.2782608695652174, "train_stats/max_log_achievement_collect_wood": 5.6869565217391305, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "train_stats/max_log_achievement_defeat_zombie": 0.4, "train_stats/max_log_achievement_eat_cow": 0.06956521739130435, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.48695652173913045, "train_stats/max_log_achievement_make_wood_sword": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 2.608695652173913, "train_stats/max_log_achievement_place_stone": 0.008695652173913044, "train_stats/max_log_achievement_place_table": 1.9478260869565218, "train_stats/max_log_achievement_wake_up": 2.4, "train_stats/mean_log_entropy": 0.6623396238555079, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.952069710994112, "train/action_min": 0.0, "train/action_std": 3.6178595345953237, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048705770134709885, "train/actor_opt_grad_steps": 18245.0, "train/actor_opt_loss": -7.911380229011664, "train/adv_mag": 0.7636999721112459, "train/adv_max": 0.7381118773550227, "train/adv_mean": 0.0030473263966047416, "train/adv_min": -0.5286456320596777, "train/adv_std": 0.07599402062486911, "train/cont_avg": 0.9944944519927537, "train/cont_loss_mean": 0.0004524755149631893, "train/cont_loss_std": 0.013142943731785952, "train/cont_neg_acc": 0.9898809548737346, "train/cont_neg_loss": 0.04015074992279868, "train/cont_pos_acc": 0.9999358960683795, "train/cont_pos_loss": 0.0002143874203712598, "train/cont_pred": 0.9944873037545577, "train/cont_rate": 0.9944944519927537, "train/dyn_loss_mean": 14.442696709563767, "train/dyn_loss_std": 9.121662025866302, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8697389584520588, "train/extr_critic_critic_opt_grad_steps": 18245.0, "train/extr_critic_critic_opt_loss": 15343.452870244566, "train/extr_critic_mag": 4.753659497136655, "train/extr_critic_max": 4.753659497136655, "train/extr_critic_mean": 0.9153556249279907, "train/extr_critic_min": -0.2500369626542796, "train/extr_critic_std": 1.0541840476402338, "train/extr_return_normed_mag": 1.8456001324930054, "train/extr_return_normed_max": 1.8456001324930054, "train/extr_return_normed_mean": 0.2973904748973639, "train/extr_return_normed_min": -0.1782386981598709, "train/extr_return_normed_std": 0.3359101495665053, "train/extr_return_rate": 0.4568260538837184, "train/extr_return_raw_mag": 5.957616415576658, "train/extr_return_raw_max": 5.957616415576658, "train/extr_return_raw_mean": 0.9252523270206175, "train/extr_return_raw_min": -0.6208593070075132, "train/extr_return_raw_std": 1.0919278778027797, "train/extr_reward_mag": 1.0114811296048372, "train/extr_reward_max": 1.0114811296048372, "train/extr_reward_mean": 0.02406433677179334, "train/extr_reward_min": -0.4568905294805333, "train/extr_reward_std": 0.14245445572811624, "train/image_loss_mean": 8.605564611545507, "train/image_loss_std": 12.53798322746719, "train/model_loss_mean": 17.3238476946734, "train/model_loss_std": 16.287418344746467, "train/model_opt_grad_norm": 65.71354588218357, "train/model_opt_grad_steps": 18225.420289855072, "train/model_opt_loss": 15360.002805848053, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 887.6811594202899, "train/policy_entropy_mag": 2.507602142251056, "train/policy_entropy_max": 2.507602142251056, "train/policy_entropy_mean": 0.7137108233527861, "train/policy_entropy_min": 0.07937526621896288, "train/policy_entropy_std": 0.696679981722348, "train/policy_logprob_mag": 7.438382003618323, "train/policy_logprob_max": -0.009455746701122194, "train/policy_logprob_mean": -0.7132277652837228, "train/policy_logprob_min": -7.438382003618323, "train/policy_logprob_std": 1.1843783311221912, "train/policy_randomness_mag": 0.8850735145202582, "train/policy_randomness_max": 0.8850735145202582, "train/policy_randomness_mean": 0.25190860065429105, "train/policy_randomness_min": 0.028015985639522904, "train/policy_randomness_std": 0.2458974609988323, "train/post_ent_mag": 57.33183238817298, "train/post_ent_max": 57.33183238817298, "train/post_ent_mean": 39.457348284514055, "train/post_ent_min": 20.641076861948207, "train/post_ent_std": 6.9188768241716465, "train/prior_ent_mag": 66.7678862861965, "train/prior_ent_max": 66.7678862861965, "train/prior_ent_mean": 53.983250908229664, "train/prior_ent_min": 34.92556075773378, "train/prior_ent_std": 5.374401610830556, "train/rep_loss_mean": 14.442696709563767, "train/rep_loss_std": 9.121662025866302, "train/reward_avg": 0.021265709671475317, "train/reward_loss_mean": 0.052212757112431354, "train/reward_loss_std": 0.2484743628596914, "train/reward_max_data": 1.013043481370677, "train/reward_max_pred": 1.0066855091979539, "train/reward_neg_acc": 0.9932023312734521, "train/reward_neg_loss": 0.029935950946494722, "train/reward_pos_acc": 0.9607987792595573, "train/reward_pos_loss": 0.8798832694689432, "train/reward_pred": 0.020725824613718018, "train/reward_rate": 0.02631057518115942, "eval_stats/sum_log_reward": 4.599999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.9638974815024994e-06, "report/cont_loss_std": 8.146416075760499e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00027417970704846084, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.90814875572687e-06, "report/cont_pred": 0.9960910081863403, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.74588394165039, "report/dyn_loss_std": 8.832587242126465, "report/image_loss_mean": 9.529680252075195, "report/image_loss_std": 14.105445861816406, "report/model_loss_mean": 17.80852508544922, "report/model_loss_std": 17.676889419555664, "report/post_ent_mag": 57.694480895996094, "report/post_ent_max": 57.694480895996094, "report/post_ent_mean": 39.72083282470703, "report/post_ent_min": 16.082782745361328, "report/post_ent_std": 6.6630682945251465, "report/prior_ent_mag": 66.56293487548828, "report/prior_ent_max": 66.56293487548828, "report/prior_ent_mean": 53.734222412109375, "report/prior_ent_min": 37.084266662597656, "report/prior_ent_std": 5.352417469024658, "report/rep_loss_mean": 13.74588394165039, "report/rep_loss_std": 8.832587242126465, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.03130809962749481, "report/reward_loss_std": 0.18038371205329895, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9999018907546997, "report/reward_neg_acc": 0.999000072479248, "report/reward_neg_loss": 0.012998752295970917, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7941975593566895, "report/reward_pred": 0.019105669111013412, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.240778253006283e-06, "eval/cont_loss_std": 9.786650480236858e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001182918669655919, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.774737582622038e-07, "eval/cont_pred": 0.9970730543136597, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.188922882080078, "eval/dyn_loss_std": 9.494942665100098, "eval/image_loss_mean": 13.555451393127441, "eval/image_loss_std": 15.879937171936035, "eval/model_loss_mean": 24.554039001464844, "eval/model_loss_std": 19.316877365112305, "eval/post_ent_mag": 54.465572357177734, "eval/post_ent_max": 54.465572357177734, "eval/post_ent_mean": 38.54987335205078, "eval/post_ent_min": 21.33443260192871, "eval/post_ent_std": 5.684863567352295, "eval/prior_ent_mag": 66.56293487548828, "eval/prior_ent_max": 66.56293487548828, "eval/prior_ent_mean": 53.78839874267578, "eval/prior_ent_min": 32.34260559082031, "eval/prior_ent_std": 5.036421775817871, "eval/rep_loss_mean": 18.188922882080078, "eval/rep_loss_std": 9.494942665100098, "eval/reward_avg": 0.02587890625, "eval/reward_loss_mean": 0.08522885292768478, "eval/reward_loss_std": 0.6038838624954224, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001342535018921, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.031082073226571083, "eval/reward_pos_acc": 0.7931034564971924, "eval/reward_pos_loss": 1.943023443222046, "eval/reward_pred": 0.017691155895590782, "eval/reward_rate": 0.0283203125, "replay/size": 304073.0, "replay/inserts": 22216.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3728707567324173e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.158953637829432e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 62392.0, "eval_replay/inserts": 3480.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2120981326048402e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0209412574768, "timer/env.step_count": 2777.0, "timer/env.step_total": 259.7589590549469, "timer/env.step_frac": 0.2597535194896148, "timer/env.step_avg": 0.09353941629634387, "timer/env.step_min": 0.023179054260253906, "timer/env.step_max": 3.652921676635742, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.384724378585815, "timer/replay._sample_frac": 0.011384485973133811, "timer/replay._sample_avg": 0.0005126406870760904, "timer/replay._sample_min": 0.0003960132598876953, "timer/replay._sample_max": 0.011868953704833984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3212.0, "timer/agent.policy_total": 52.275229692459106, "timer/agent.policy_frac": 0.05227413500633856, "timer/agent.policy_avg": 0.016274978110977306, "timer/agent.policy_min": 0.009219884872436523, "timer/agent.policy_max": 0.19147634506225586, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.15401601791381836, "timer/dataset_train_frac": 0.00015401279269227188, "timer/dataset_train_avg": 0.00011096254892926395, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0010237693786621094, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 622.5716707706451, "timer/agent.train_frac": 0.6225586336100043, "timer/agent.train_avg": 0.4485386677021939, "timer/agent.train_min": 0.43346381187438965, "timer/agent.train_max": 1.5318372249603271, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472764253616333, "timer/agent.report_frac": 0.0004727543535456921, "timer/agent.report_avg": 0.2363821268081665, "timer/agent.report_min": 0.2278294563293457, "timer/agent.report_max": 0.2449347972869873, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.385472927181939e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 22.21522509758647}
{"step": 304600, "time": 14353.697947740555, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 304664, "time": 14357.59779214859, "episode/length": 365.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 305008, "time": 14370.787231683731, "episode/length": 215.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 305264, "time": 14380.979420661926, "episode/length": 190.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 305312, "time": 14384.09295964241, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 305624, "time": 14395.919566392899, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 305808, "time": 14403.727550983429, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 305936, "time": 14409.637959003448, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 306320, "time": 14423.900764465332, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 306560, "time": 14433.478902816772, "episode/length": 155.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 306872, "time": 14445.521218061447, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 306960, "time": 14450.190397500992, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 307200, "time": 14459.67333483696, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 307424, "time": 14468.69644832611, "episode/length": 224.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 307440, "time": 14470.718152284622, "episode/length": 357.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 307512, "time": 14474.426702260971, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808306709265175, "episode/intrinsic_return": 0.0}
{"step": 307600, "time": 14479.006014108658, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 308112, "time": 14497.533472061157, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 308272, "time": 14504.471550703049, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 308600, "time": 14516.777580022812, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 308720, "time": 14523.036974906921, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 308784, "time": 14526.769411563873, "episode/length": 147.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 308848, "time": 14530.4369597435, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 308872, "time": 14532.541255235672, "episode/length": 208.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 309104, "time": 14542.11123919487, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 309248, "time": 14548.49745130539, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 309480, "time": 14557.861652374268, "episode/length": 150.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 309816, "time": 14570.42293715477, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 310000, "time": 14578.432691335678, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 310000, "time": 14578.442512989044, "episode/length": 174.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14597.249227285385, "eval_episode/length": 39.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 310024, "time": 14599.666350126266, "eval_episode/length": 47.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8958333333333334}
{"step": 310024, "time": 14606.194254636765, "eval_episode/length": 153.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 310024, "time": 14609.168005228043, "eval_episode/length": 146.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 310024, "time": 14612.469146490097, "eval_episode/length": 223.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 310024, "time": 14614.184335947037, "eval_episode/length": 226.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 310024, "time": 14617.165920734406, "eval_episode/length": 258.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9806949806949807}
{"step": 310024, "time": 14619.506194114685, "eval_episode/length": 276.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 310120, "time": 14622.673005580902, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 310432, "time": 14634.653337717056, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 310680, "time": 14644.277611732483, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 310856, "time": 14651.826117753983, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 310968, "time": 14657.253440856934, "episode/length": 185.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 310968, "time": 14657.265299081802, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 311672, "time": 14686.698136091232, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 311696, "time": 14689.7451441288, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 311768, "time": 14694.001258611679, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 312248, "time": 14711.622761964798, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 312376, "time": 14717.486525058746, "episode/length": 175.0, "episode/score": 6.0999999567866325, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 312464, "time": 14722.318913459778, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 312552, "time": 14726.553657054901, "episode/length": 264.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 312936, "time": 14741.133500814438, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 312976, "time": 14744.369708776474, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 313016, "time": 14746.969569683075, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 313192, "time": 14754.378942489624, "episode/length": 189.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 313624, "time": 14770.368220567703, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 313840, "time": 14779.268151521683, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 314016, "time": 14786.66124677658, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 314024, "time": 14788.33765077591, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 314056, "time": 14790.988609313965, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 314400, "time": 14804.267830848694, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 314448, "time": 14807.585847854614, "episode/length": 178.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 314696, "time": 14817.067744255066, "episode/length": 79.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 314784, "time": 14821.722241640091, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 315224, "time": 14837.740344762802, "episode/length": 172.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 315616, "time": 14852.621768712997, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 315736, "time": 14858.085145950317, "episode/length": 166.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 315768, "time": 14860.925510883331, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 315984, "time": 14869.937817573547, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 316128, "time": 14876.30453467369, "episode/length": 167.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 316360, "time": 14885.435186624527, "episode/length": 207.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 316392, "time": 14888.055814027786, "episode/length": 242.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 316456, "time": 14891.869659423828, "episode/length": 434.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 316600, "time": 14898.167699575424, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 316888, "time": 14909.187543153763, "episode/length": 53.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 317216, "time": 14921.9215362072, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 317224, "time": 14923.705976009369, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 317384, "time": 14930.731827259064, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 317584, "time": 14939.199300050735, "episode/length": 148.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 317632, "time": 14942.417285203934, "episode/length": 205.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 317640, "time": 14944.131205558777, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 317928, "time": 14955.407885313034, "episode/length": 42.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 318160, "time": 14964.96706032753, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 318176, "time": 14967.11749625206, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 318648, "time": 14984.80018568039, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 318768, "time": 14990.60330247879, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 318960, "time": 14998.551224470139, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 319352, "time": 15013.378646850586, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 319648, "time": 15026.660466194153, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 319808, "time": 15033.55690574646, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 319824, "time": 15035.849252223969, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15059.27581524849, "eval_episode/length": 54.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 320008, "time": 15064.421774148941, "eval_episode/length": 100.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9405940594059405}
{"step": 320008, "time": 15067.920218229294, "eval_episode/length": 141.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 320008, "time": 15069.807381629944, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9527027027027027}
{"step": 320008, "time": 15071.671692848206, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 320008, "time": 15073.30813741684, "eval_episode/length": 154.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 320008, "time": 15076.195495128632, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 320008, "time": 15079.435718774796, "eval_episode/length": 222.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 320232, "time": 15086.938694477081, "episode/length": 323.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 320376, "time": 15093.416080713272, "episode/length": 215.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 320504, "time": 15099.444301843643, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 320632, "time": 15105.327164888382, "episode/length": 208.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 320888, "time": 15115.667051076889, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 321008, "time": 15121.448119878769, "episode/length": 279.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 321472, "time": 15138.699246168137, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 321552, "time": 15142.97546172142, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 321584, "time": 15145.632627725601, "episode/length": 219.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 321968, "time": 15160.120187997818, "episode/length": 47.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 322072, "time": 15165.006330013275, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 322296, "time": 15174.028608560562, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 322736, "time": 15190.754856348038, "episode/length": 215.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 322832, "time": 15195.601517677307, "episode/length": 290.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 322912, "time": 15199.850820064545, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 322936, "time": 15201.984671115875, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 323304, "time": 15215.921112060547, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 323320, "time": 15217.995581388474, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 323320, "time": 15218.005065441132, "episode/length": 220.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 324024, "time": 15245.034183979034, "episode/length": 135.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 324168, "time": 15251.478698253632, "episode/length": 166.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 324168, "time": 15251.502462148666, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 324248, "time": 15257.46915102005, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 324352, "time": 15262.7577855587, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 324592, "time": 15273.469046354294, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 324704, "time": 15278.914576768875, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 325120, "time": 15294.311712026596, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 325344, "time": 15303.282131671906, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 325416, "time": 15307.178400039673, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 325792, "time": 15321.585723876953, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 325832, "time": 15324.336241722107, "episode/length": 207.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 325896, "time": 15328.078455924988, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 325936, "time": 15331.878770828247, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 326248, "time": 15344.303500652313, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 326256, "time": 15346.292521715164, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 326272, "time": 15348.348885059357, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 326345, "time": 15353.318876981735, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6448974609375, "train/action_min": 0.0, "train/action_std": 3.430072211871182, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04917144772671435, "train/actor_opt_grad_steps": 19620.0, "train/actor_opt_loss": -4.997724121885143, "train/adv_mag": 0.7419032128187861, "train/adv_max": 0.7294567172979787, "train/adv_mean": 0.0035991873756378427, "train/adv_min": -0.5188879083542928, "train/adv_std": 0.07639223073412033, "train/cont_avg": 0.9943473426094891, "train/cont_loss_mean": 0.00033324948226004877, "train/cont_loss_std": 0.009779971416407475, "train/cont_neg_acc": 0.9846686394545283, "train/cont_neg_loss": 0.03810888462417462, "train/cont_pos_acc": 0.9999569006209826, "train/cont_pos_loss": 9.746698491372866e-05, "train/cont_pred": 0.9943877523832948, "train/cont_rate": 0.9943473426094891, "train/dyn_loss_mean": 14.594918278882103, "train/dyn_loss_std": 9.060400336328215, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8644706102183265, "train/extr_critic_critic_opt_grad_steps": 19620.0, "train/extr_critic_critic_opt_loss": 15431.7299270073, "train/extr_critic_mag": 4.80023735283065, "train/extr_critic_max": 4.80023735283065, "train/extr_critic_mean": 0.9279391182600146, "train/extr_critic_min": -0.2395973901679046, "train/extr_critic_std": 1.061773145285836, "train/extr_return_normed_mag": 1.8835197739357497, "train/extr_return_normed_max": 1.8835197739357497, "train/extr_return_normed_mean": 0.300324838961998, "train/extr_return_normed_min": -0.16568150961377326, "train/extr_return_normed_std": 0.34049922478024974, "train/extr_return_rate": 0.4612269282993609, "train/extr_return_raw_mag": 6.034977460429616, "train/extr_return_raw_max": 6.034977460429616, "train/extr_return_raw_mean": 0.9395133126391112, "train/extr_return_raw_min": -0.5608747166438695, "train/extr_return_raw_std": 1.0962798003732723, "train/extr_reward_mag": 1.0104184046278906, "train/extr_reward_max": 1.0104184046278906, "train/extr_reward_mean": 0.024964320092686336, "train/extr_reward_min": -0.4137417739325196, "train/extr_reward_std": 0.1455073397960106, "train/image_loss_mean": 8.529885459120257, "train/image_loss_std": 12.358269677545032, "train/model_loss_mean": 17.339303984259168, "train/model_loss_std": 16.124184002841478, "train/model_opt_grad_norm": 68.19168867682018, "train/model_opt_grad_steps": 19599.73722627737, "train/model_opt_loss": 17239.87452241104, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 994.5255474452555, "train/policy_entropy_mag": 2.541569088497301, "train/policy_entropy_max": 2.541569088497301, "train/policy_entropy_mean": 0.7091676614580363, "train/policy_entropy_min": 0.07937520780485041, "train/policy_entropy_std": 0.7176028424805968, "train/policy_logprob_mag": 7.438382865738695, "train/policy_logprob_max": -0.009455707637987433, "train/policy_logprob_mean": -0.7092829714291287, "train/policy_logprob_min": -7.438382865738695, "train/policy_logprob_std": 1.1897554467194271, "train/policy_randomness_mag": 0.8970623564546125, "train/policy_randomness_max": 0.8970623564546125, "train/policy_randomness_mean": 0.25030506288048127, "train/policy_randomness_min": 0.02801596510638721, "train/policy_randomness_std": 0.2532823123853572, "train/post_ent_mag": 57.45923764862283, "train/post_ent_max": 57.45923764862283, "train/post_ent_mean": 39.540710755508314, "train/post_ent_min": 20.935234153357737, "train/post_ent_std": 6.943749017088953, "train/prior_ent_mag": 66.98751753090072, "train/prior_ent_max": 66.98751753090072, "train/prior_ent_mean": 54.20920938644966, "train/prior_ent_min": 35.631544670049294, "train/prior_ent_std": 5.1992631759086665, "train/rep_loss_mean": 14.594918278882103, "train/rep_loss_std": 9.060400336328215, "train/reward_avg": 0.022456660567626466, "train/reward_loss_mean": 0.052134436494025, "train/reward_loss_std": 0.24633792020978718, "train/reward_max_data": 1.0175182523518582, "train/reward_max_pred": 1.0060945488240598, "train/reward_neg_acc": 0.9935244239159744, "train/reward_neg_loss": 0.02876606811327438, "train/reward_pos_acc": 0.9597431917260163, "train/reward_pos_loss": 0.8811261362402979, "train/reward_pred": 0.0216720819908337, "train/reward_rate": 0.027429288321167884, "train_stats/sum_log_reward": 5.326890711899565, "train_stats/max_log_achievement_collect_coal": 0.01680672268907563, "train_stats/max_log_achievement_collect_drink": 4.8655462184873945, "train_stats/max_log_achievement_collect_sapling": 2.361344537815126, "train_stats/max_log_achievement_collect_stone": 0.15126050420168066, "train_stats/max_log_achievement_collect_wood": 5.915966386554622, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4117647058823529, "train_stats/max_log_achievement_eat_cow": 0.058823529411764705, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.31932773109243695, "train_stats/max_log_achievement_make_wood_sword": 0.01680672268907563, "train_stats/max_log_achievement_place_plant": 2.2521008403361344, "train_stats/max_log_achievement_place_stone": 0.025210084033613446, "train_stats/max_log_achievement_place_table": 2.176470588235294, "train_stats/max_log_achievement_wake_up": 2.1596638655462184, "train_stats/mean_log_entropy": 0.6414968161021962, "eval_stats/sum_log_reward": 4.53749992698431, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.6875, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.7967134858263307e-07, "report/cont_loss_std": 1.4242561974242562e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5411847673240118e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.061194036035886e-07, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.350826263427734, "report/dyn_loss_std": 9.38014030456543, "report/image_loss_mean": 8.486661911010742, "report/image_loss_std": 11.697724342346191, "report/model_loss_mean": 16.533061981201172, "report/model_loss_std": 15.941217422485352, "report/post_ent_mag": 58.59331512451172, "report/post_ent_max": 58.59331512451172, "report/post_ent_mean": 40.64092254638672, "report/post_ent_min": 20.748294830322266, "report/post_ent_std": 7.4211249351501465, "report/prior_ent_mag": 66.72634887695312, "report/prior_ent_max": 66.72634887695312, "report/prior_ent_mean": 54.13165283203125, "report/prior_ent_min": 31.176515579223633, "report/prior_ent_std": 5.657992362976074, "report/rep_loss_mean": 13.350826263427734, "report/rep_loss_std": 9.38014030456543, "report/reward_avg": 0.01162109337747097, "report/reward_loss_mean": 0.03590197116136551, "report/reward_loss_std": 0.20997990667819977, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034918785095215, "report/reward_neg_acc": 0.9960356950759888, "report/reward_neg_loss": 0.021454306319355965, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.0077484846115112, "report/reward_pred": 0.01142074353992939, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.2940936105442233e-05, "eval/cont_loss_std": 0.0006766610313206911, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005767109338194132, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.147858874148369e-07, "eval/cont_pred": 0.9961158037185669, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.515127182006836, "eval/dyn_loss_std": 11.148396492004395, "eval/image_loss_mean": 16.085063934326172, "eval/image_loss_std": 23.58434295654297, "eval/model_loss_mean": 25.486709594726562, "eval/model_loss_std": 28.522274017333984, "eval/post_ent_mag": 57.829071044921875, "eval/post_ent_max": 57.829071044921875, "eval/post_ent_mean": 40.40294647216797, "eval/post_ent_min": 21.858627319335938, "eval/post_ent_std": 6.7954277992248535, "eval/prior_ent_mag": 66.72634887695312, "eval/prior_ent_max": 66.72634887695312, "eval/prior_ent_mean": 53.98554229736328, "eval/prior_ent_min": 36.01233673095703, "eval/prior_ent_std": 5.026163101196289, "eval/rep_loss_mean": 15.515127182006836, "eval/rep_loss_std": 11.148396492004395, "eval/reward_avg": 0.0302734375, "eval/reward_loss_mean": 0.09254509210586548, "eval/reward_loss_std": 0.631294310092926, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0050201416015625, "eval/reward_neg_acc": 0.9949494004249573, "eval/reward_neg_loss": 0.032129086554050446, "eval/reward_pos_acc": 0.7352941036224365, "eval/reward_pos_loss": 1.8517167568206787, "eval/reward_pred": 0.02469676360487938, "eval/reward_rate": 0.033203125, "replay/size": 325841.0, "replay/inserts": 21768.0, "replay/samples": 21776.0, "replay/insert_wait_avg": 1.3494066612022146e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.330798386651571e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66392.0, "eval_replay/inserts": 4000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.217663288116455e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3325004577637, "timer/env.step_count": 2721.0, "timer/env.step_total": 267.07864332199097, "timer/env.step_frac": 0.2669898690683075, "timer/env.step_avg": 0.09815459144505365, "timer/env.step_min": 0.022809982299804688, "timer/env.step_max": 4.326555013656616, "timer/replay._sample_count": 21776.0, "timer/replay._sample_total": 11.180020093917847, "timer/replay._sample_frac": 0.011176303967732469, "timer/replay._sample_avg": 0.000513410180653832, "timer/replay._sample_min": 0.0004024505615234375, "timer/replay._sample_max": 0.03188896179199219, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3221.0, "timer/agent.policy_total": 52.304296255111694, "timer/agent.policy_frac": 0.05228691083332457, "timer/agent.policy_avg": 0.016238527244679196, "timer/agent.policy_min": 0.009332656860351562, "timer/agent.policy_max": 0.15232491493225098, "timer/dataset_train_count": 1361.0, "timer/dataset_train_total": 0.14862895011901855, "timer/dataset_train_frac": 0.00014857954735150985, "timer/dataset_train_avg": 0.00010920569442984464, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.00020456314086914062, "timer/agent.train_count": 1361.0, "timer/agent.train_total": 610.7573368549347, "timer/agent.train_frac": 0.6105543272616306, "timer/agent.train_avg": 0.4487563092247867, "timer/agent.train_min": 0.4353959560394287, "timer/agent.train_max": 1.5582716464996338, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47557950019836426, "timer/agent.report_frac": 0.00047542142235779963, "timer/agent.report_avg": 0.23778975009918213, "timer/agent.report_min": 0.22974920272827148, "timer/agent.report_max": 0.24583029747009277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9792416395605888e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 21.760483989020496}
{"step": 326440, "time": 15356.274546384811, "episode/length": 164.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 326600, "time": 15363.081609487534, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 327048, "time": 15379.66072511673, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 327280, "time": 15389.18691778183, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 327448, "time": 15396.102371931076, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 327664, "time": 15405.145363807678, "episode/length": 152.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 327672, "time": 15406.79354095459, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 327680, "time": 15409.248520851135, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 327824, "time": 15416.998819589615, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 327928, "time": 15421.83485341072, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 328088, "time": 15428.735035657883, "episode/length": 50.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 328624, "time": 15448.251535654068, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 329032, "time": 15463.356206178665, "episode/length": 218.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 329160, "time": 15469.212189674377, "episode/length": 186.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 329168, "time": 15471.267533302307, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 329376, "time": 15480.076324224472, "episode/length": 26.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 329464, "time": 15484.311494112015, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 329848, "time": 15498.948503732681, "episode/length": 299.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 329872, "time": 15501.561392068863, "episode/length": 50.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 329888, "time": 15503.617160320282, "episode/length": 63.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15512.09693479538, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15527.173640727997, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9}
{"step": 330096, "time": 15533.017845869064, "eval_episode/length": 145.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 330096, "time": 15535.016209125519, "eval_episode/length": 154.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 330096, "time": 15537.225243806839, "eval_episode/length": 168.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 330096, "time": 15538.946262836456, "eval_episode/length": 172.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 330096, "time": 15540.678976774216, "eval_episode/length": 176.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 330096, "time": 15543.071439504623, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 330096, "time": 15545.01082611084, "eval_episode/length": 198.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 330472, "time": 15558.770033359528, "episode/length": 330.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 330512, "time": 15562.065290689468, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 331048, "time": 15581.669515609741, "episode/length": 369.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9918918918918919, "episode/intrinsic_return": 0.0}
{"step": 331344, "time": 15593.38419175148, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 331408, "time": 15597.17498254776, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 331560, "time": 15603.580396175385, "episode/length": 315.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 331616, "time": 15607.3793592453, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 331712, "time": 15612.190655469894, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 331832, "time": 15617.594251155853, "episode/length": 164.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 332344, "time": 15636.31034874916, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 332592, "time": 15646.359552145004, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 332880, "time": 15657.486470222473, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 333024, "time": 15663.896757125854, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 333160, "time": 15669.792628526688, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 333176, "time": 15671.939514875412, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 333240, "time": 15675.724132537842, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 333392, "time": 15682.626624822617, "episode/length": 194.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 333624, "time": 15691.892066955566, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 333912, "time": 15703.08345913887, "episode/length": 91.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 333912, "time": 15703.091323852539, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 334144, "time": 15714.38992023468, "episode/length": 303.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 334368, "time": 15723.54407453537, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 334416, "time": 15726.867716550827, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 335000, "time": 15747.817435741425, "episode/length": 229.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 335128, "time": 15753.774225711823, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 335168, "time": 15757.359789609909, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 335280, "time": 15762.736986160278, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 335648, "time": 15776.753248214722, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 335760, "time": 15782.090530395508, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 335936, "time": 15791.251049518585, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 336168, "time": 15800.45927286148, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 336480, "time": 15812.705580949783, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 336504, "time": 15814.954448699951, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 336792, "time": 15826.225581645966, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 336912, "time": 15831.968956232071, "episode/length": 53.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 336992, "time": 15836.213973283768, "episode/length": 232.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 337160, "time": 15843.414229631424, "episode/length": 174.0, "episode/score": 5.100000061094761, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 337256, "time": 15848.29069018364, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 337448, "time": 15856.197908878326, "episode/length": 384.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 337496, "time": 15859.305603981018, "episode/length": 123.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 337512, "time": 15861.422344446182, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 337560, "time": 15864.741384267807, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 337744, "time": 15872.718406677246, "episode/length": 60.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 337824, "time": 15877.00226354599, "episode/length": 46.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 338240, "time": 15892.526359558105, "episode/length": 51.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 338808, "time": 15912.974713087082, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 338928, "time": 15918.75184082985, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 338984, "time": 15922.052926063538, "episode/length": 273.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 339032, "time": 15925.184446334839, "episode/length": 160.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 339264, "time": 15934.700285196304, "episode/length": 283.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 339328, "time": 15938.772927761078, "episode/length": 301.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 339608, "time": 15949.471960067749, "episode/length": 255.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 339704, "time": 15954.312584400177, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 15987.361944437027, "eval_episode/length": 131.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 340080, "time": 15989.894756317139, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 340080, "time": 15992.246156215668, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 340080, "time": 15994.124574661255, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9832402234636871}
{"step": 340080, "time": 15996.23568868637, "eval_episode/length": 187.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9680851063829787}
{"step": 340080, "time": 15998.581046819687, "eval_episode/length": 206.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 340080, "time": 16000.447095155716, "eval_episode/length": 215.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 340080, "time": 16002.550254821777, "eval_episode/length": 230.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 340160, "time": 16005.212057590485, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 340200, "time": 16007.838468551636, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 340760, "time": 16027.940509080887, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 340784, "time": 16030.502059936523, "episode/length": 218.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 340960, "time": 16038.02819776535, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 340968, "time": 16039.838159322739, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 341352, "time": 16054.114752054214, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 341440, "time": 16058.99938082695, "episode/length": 313.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 341456, "time": 16061.076129674911, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 342040, "time": 16081.75692653656, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 342104, "time": 16085.501641750336, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 342112, "time": 16087.575797080994, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 342224, "time": 16092.87849020958, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 342232, "time": 16095.14624619484, "episode/length": 183.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 342672, "time": 16112.041768312454, "episode/length": 164.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 342720, "time": 16115.237706422806, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 343176, "time": 16131.636278390884, "episode/length": 56.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 343248, "time": 16135.733498096466, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 343568, "time": 16148.016954421997, "episode/length": 166.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 343608, "time": 16150.587186336517, "episode/length": 186.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 343616, "time": 16152.635444164276, "episode/length": 188.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 343672, "time": 16155.848690986633, "episode/length": 278.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.992831541218638, "episode/intrinsic_return": 0.0}
{"step": 344056, "time": 16170.198413133621, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 344504, "time": 16188.395054101944, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 344696, "time": 16196.437776088715, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 344928, "time": 16205.934463977814, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 345000, "time": 16209.63232588768, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 345280, "time": 16220.806416988373, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 345288, "time": 16222.321774721146, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 345304, "time": 16224.344505310059, "episode/length": 210.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 345320, "time": 16226.463366746902, "episode/length": 386.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948320413436692, "episode/intrinsic_return": 0.0}
{"step": 345720, "time": 16241.449560880661, "episode/length": 53.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 345824, "time": 16246.691177845001, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 346000, "time": 16254.025979280472, "episode/length": 290.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 346080, "time": 16258.240876674652, "episode/length": 44.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 346216, "time": 16264.066712379456, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 346624, "time": 16279.957397460938, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 346896, "time": 16290.750418424606, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 347192, "time": 16301.983610153198, "episode/length": 235.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 347368, "time": 16309.554041147232, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 347384, "time": 16312.090852737427, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 347416, "time": 16315.21770787239, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9548022598870056, "episode/intrinsic_return": 0.0}
{"step": 347840, "time": 16331.738372564316, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 347992, "time": 16338.1087372303, "episode/length": 136.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 348128, "time": 16344.376270532608, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 348144, "time": 16346.644591093063, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 348281, "time": 16353.507285833359, "train_stats/sum_log_reward": 4.974999941264589, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.225, "train_stats/max_log_achievement_collect_sapling": 2.375, "train_stats/max_log_achievement_collect_stone": 0.058333333333333334, "train_stats/max_log_achievement_collect_wood": 5.65, "train_stats/max_log_achievement_defeat_skeleton": 0.008333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.5166666666666667, "train_stats/max_log_achievement_eat_cow": 0.09166666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.31666666666666665, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.25, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.066666666666667, "train_stats/max_log_achievement_wake_up": 2.091666666666667, "train_stats/mean_log_entropy": 0.631426561375459, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.640678015938641, "train/action_min": 0.0, "train/action_std": 3.5198167936645284, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050335297510571725, "train/actor_opt_grad_steps": 20990.0, "train/actor_opt_loss": -3.7470709803330635, "train/adv_mag": 0.7334000503059721, "train/adv_max": 0.7173292221379106, "train/adv_mean": 0.0035750104823049048, "train/adv_min": -0.519558294193588, "train/adv_std": 0.07609783284311747, "train/cont_avg": 0.9947607778284672, "train/cont_loss_mean": 0.0002200843892127196, "train/cont_loss_std": 0.006606702307985073, "train/cont_neg_acc": 0.9888686137477847, "train/cont_neg_loss": 0.03746465180489249, "train/cont_pos_acc": 0.9999784922947849, "train/cont_pos_loss": 5.761275029908409e-05, "train/cont_pred": 0.9947690550428238, "train/cont_rate": 0.9947607778284672, "train/dyn_loss_mean": 14.26126136222895, "train/dyn_loss_std": 9.055353095061587, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8325569644896653, "train/extr_critic_critic_opt_grad_steps": 20990.0, "train/extr_critic_critic_opt_loss": 15451.225158245894, "train/extr_critic_mag": 4.806944105746973, "train/extr_critic_max": 4.806944105746973, "train/extr_critic_mean": 0.9361204261327312, "train/extr_critic_min": -0.24489552087157312, "train/extr_critic_std": 1.0562771188951756, "train/extr_return_normed_mag": 1.89754340944499, "train/extr_return_normed_max": 1.89754340944499, "train/extr_return_normed_mean": 0.30206409966858633, "train/extr_return_normed_min": -0.1749926727727382, "train/extr_return_normed_std": 0.3392533012767778, "train/extr_return_rate": 0.4678704035978248, "train/extr_return_raw_mag": 6.080930581058029, "train/extr_return_raw_max": 6.080930581058029, "train/extr_return_raw_mean": 0.9476339886658383, "train/extr_return_raw_min": -0.5872827172279358, "train/extr_return_raw_std": 1.0914366497610608, "train/extr_reward_mag": 1.012645716214702, "train/extr_reward_max": 1.012645716214702, "train/extr_reward_mean": 0.025054126311718983, "train/extr_reward_min": -0.4296734567976346, "train/extr_reward_std": 0.14657249655166682, "train/image_loss_mean": 8.16745547482567, "train/image_loss_std": 12.371718991411864, "train/model_loss_mean": 16.77654762685734, "train/model_loss_std": 16.09623989745648, "train/model_opt_grad_norm": 63.162922253573896, "train/model_opt_grad_steps": 20968.58394160584, "train/model_opt_loss": 11679.568002965329, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 697.992700729927, "train/policy_entropy_mag": 2.5282723834044742, "train/policy_entropy_max": 2.5282723834044742, "train/policy_entropy_mean": 0.7011374887758798, "train/policy_entropy_min": 0.07937520601018502, "train/policy_entropy_std": 0.717699384602317, "train/policy_logprob_mag": 7.438382883141511, "train/policy_logprob_max": -0.009455722314815451, "train/policy_logprob_mean": -0.7006435490002597, "train/policy_logprob_min": -7.438382883141511, "train/policy_logprob_std": 1.1846823935961202, "train/policy_randomness_mag": 0.8923691998433022, "train/policy_randomness_max": 0.8923691998433022, "train/policy_randomness_mean": 0.24747076391303627, "train/policy_randomness_min": 0.02801596430422616, "train/policy_randomness_std": 0.25331638644646554, "train/post_ent_mag": 57.90322522351342, "train/post_ent_max": 57.90322522351342, "train/post_ent_mean": 39.9787254055051, "train/post_ent_min": 20.66199582510621, "train/post_ent_std": 7.085865208702366, "train/prior_ent_mag": 67.15534427392221, "train/prior_ent_max": 67.15534427392221, "train/prior_ent_mean": 54.295568257352734, "train/prior_ent_min": 35.86996362505168, "train/prior_ent_std": 5.151358479130877, "train/rep_loss_mean": 14.26126136222895, "train/rep_loss_std": 9.055353095061587, "train/reward_avg": 0.022822336844392936, "train/reward_loss_mean": 0.052115365346200274, "train/reward_loss_std": 0.24778656041535146, "train/reward_max_data": 1.0131386892638938, "train/reward_max_pred": 1.0073263218803128, "train/reward_neg_acc": 0.9934327589334363, "train/reward_neg_loss": 0.02864701783515676, "train/reward_pos_acc": 0.9623240067140899, "train/reward_pos_loss": 0.8852666968846843, "train/reward_pred": 0.022056707262612173, "train/reward_rate": 0.027578980383211677, "eval_stats/sum_log_reward": 5.1624999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.1875, "eval_stats/max_log_achievement_collect_wood": 5.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.2262433301657438e-05, "report/cont_loss_std": 0.0001992374745896086, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0012840392300859094, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.248441887786612e-06, "report/cont_pred": 0.9921952486038208, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.986202239990234, "report/dyn_loss_std": 9.121183395385742, "report/image_loss_mean": 8.566020965576172, "report/image_loss_std": 13.207497596740723, "report/model_loss_mean": 17.026187896728516, "report/model_loss_std": 16.8414306640625, "report/post_ent_mag": 57.698089599609375, "report/post_ent_max": 57.698089599609375, "report/post_ent_mean": 40.18125915527344, "report/post_ent_min": 20.49652862548828, "report/post_ent_std": 7.629873275756836, "report/prior_ent_mag": 67.3826904296875, "report/prior_ent_max": 67.3826904296875, "report/prior_ent_mean": 54.3402099609375, "report/prior_ent_min": 32.10166549682617, "report/prior_ent_std": 4.574817180633545, "report/rep_loss_mean": 13.986202239990234, "report/rep_loss_std": 9.121183395385742, "report/reward_avg": 0.01904296875, "report/reward_loss_mean": 0.06843183934688568, "report/reward_loss_std": 0.36560845375061035, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015299320220947, "report/reward_neg_acc": 0.9959879517555237, "report/reward_neg_loss": 0.0437808483839035, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 0.9786925315856934, "report/reward_pred": 0.01799515075981617, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.3969545761938207e-05, "eval/cont_loss_std": 0.000266309711150825, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003157595172524452, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.6416013295383891e-06, "eval/cont_pred": 0.9961044192314148, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.14669418334961, "eval/dyn_loss_std": 9.548130989074707, "eval/image_loss_mean": 14.607738494873047, "eval/image_loss_std": 19.05807113647461, "eval/model_loss_mean": 24.986385345458984, "eval/model_loss_std": 22.816078186035156, "eval/post_ent_mag": 58.916954040527344, "eval/post_ent_max": 58.916954040527344, "eval/post_ent_mean": 40.701026916503906, "eval/post_ent_min": 21.860424041748047, "eval/post_ent_std": 7.283798694610596, "eval/prior_ent_mag": 67.3826904296875, "eval/prior_ent_max": 67.3826904296875, "eval/prior_ent_mean": 55.67306137084961, "eval/prior_ent_min": 36.72722625732422, "eval/prior_ent_std": 5.636977195739746, "eval/rep_loss_mean": 17.14669418334961, "eval/rep_loss_std": 9.548130989074707, "eval/reward_avg": 0.02412109449505806, "eval/reward_loss_mean": 0.09061579406261444, "eval/reward_loss_std": 0.5407335758209229, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005528926849365, "eval/reward_neg_acc": 0.9929719567298889, "eval/reward_neg_loss": 0.03259802982211113, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.154390811920166, "eval/reward_pred": 0.01486697793006897, "eval/reward_rate": 0.02734375, "replay/size": 347777.0, "replay/inserts": 21936.0, "replay/samples": 21936.0, "replay/insert_wait_avg": 1.3671136093696133e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.298933239247484e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 69832.0, "eval_replay/inserts": 3440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1692906534949015e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1763353347778, "timer/env.step_count": 2742.0, "timer/env.step_total": 268.67555713653564, "timer/env.step_frac": 0.2686281884949866, "timer/env.step_avg": 0.09798525059684013, "timer/env.step_min": 0.022883176803588867, "timer/env.step_max": 3.4081807136535645, "timer/replay._sample_count": 21936.0, "timer/replay._sample_total": 11.347702503204346, "timer/replay._sample_frac": 0.011345701855069442, "timer/replay._sample_avg": 0.0005173095597740858, "timer/replay._sample_min": 0.0003552436828613281, "timer/replay._sample_max": 0.03385519981384277, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3172.0, "timer/agent.policy_total": 51.27132320404053, "timer/agent.policy_frac": 0.051262283852056, "timer/agent.policy_avg": 0.01616372106054241, "timer/agent.policy_min": 0.009400606155395508, "timer/agent.policy_max": 0.09021759033203125, "timer/dataset_train_count": 1371.0, "timer/dataset_train_total": 0.1511976718902588, "timer/dataset_train_frac": 0.00015117101509870266, "timer/dataset_train_avg": 0.00011028276578428796, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0004353523254394531, "timer/agent.train_count": 1371.0, "timer/agent.train_total": 614.8981759548187, "timer/agent.train_frac": 0.6147897667954728, "timer/agent.train_avg": 0.44850341061620624, "timer/agent.train_min": 0.436784029006958, "timer/agent.train_max": 1.5545399188995361, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4793713092803955, "timer/agent.report_frac": 0.0004792867940831063, "timer/agent.report_avg": 0.23968565464019775, "timer/agent.report_min": 0.2341146469116211, "timer/agent.report_max": 0.24525666236877441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122732738107673e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.93183108932974}
{"step": 348528, "time": 16361.856603860855, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 348552, "time": 16363.942333936691, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 348920, "time": 16377.713347911835, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 349160, "time": 16387.369629621506, "episode/length": 164.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 349176, "time": 16389.377998113632, "episode/length": 77.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 349512, "time": 16402.279548883438, "episode/length": 172.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 349520, "time": 16404.876406669617, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 349624, "time": 16409.642077684402, "episode/length": 275.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 349728, "time": 16415.11217737198, "episode/length": 216.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 349888, "time": 16422.03626203537, "episode/length": 46.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16446.349672555923, "eval_episode/length": 80.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9382716049382716}
{"step": 350064, "time": 16451.626475811005, "eval_episode/length": 164.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 350064, "time": 16453.52814722061, "eval_episode/length": 173.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 350064, "time": 16456.071459054947, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 350064, "time": 16458.008689641953, "eval_episode/length": 204.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 350064, "time": 16460.47079706192, "eval_episode/length": 225.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 350064, "time": 16462.97748017311, "eval_episode/length": 235.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 350064, "time": 16465.60956788063, "eval_episode/length": 164.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 350512, "time": 16480.730029582977, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 350560, "time": 16484.00625896454, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 350656, "time": 16488.742486715317, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 350904, "time": 16498.47222185135, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 351048, "time": 16504.83631515503, "episode/length": 164.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 351520, "time": 16522.37673830986, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 351568, "time": 16525.549715280533, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 351608, "time": 16528.3452398777, "episode/length": 335.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 351736, "time": 16534.100039720535, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 351952, "time": 16543.15718650818, "episode/length": 130.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 351992, "time": 16545.787344932556, "episode/length": 52.0, "episode/score": 2.1000000461935997, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 352336, "time": 16560.487248897552, "episode/length": 221.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 352368, "time": 16563.096494436264, "episode/length": 164.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 352800, "time": 16579.062962055206, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 352832, "time": 16581.705246686935, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 353048, "time": 16590.16186618805, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 353088, "time": 16593.297213554382, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 353304, "time": 16601.86551475525, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 353432, "time": 16607.660957813263, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 354176, "time": 16634.37182688713, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 354224, "time": 16637.60543179512, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 354392, "time": 16644.619884729385, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 354408, "time": 16646.63397693634, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 354712, "time": 16658.398250579834, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 354816, "time": 16663.747233629227, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9638009049773756, "episode/intrinsic_return": 0.0}
{"step": 354872, "time": 16667.06038594246, "episode/length": 195.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 355376, "time": 16685.697398662567, "episode/length": 62.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 355376, "time": 16685.70617556572, "episode/length": 149.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 355648, "time": 16698.146106481552, "episode/length": 413.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 355744, "time": 16702.98638868332, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 356208, "time": 16720.236847400665, "episode/length": 103.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 356576, "time": 16734.17102766037, "episode/length": 293.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 356752, "time": 16741.81796145439, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 356816, "time": 16745.64984726906, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 356888, "time": 16749.403208494186, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 356928, "time": 16752.535216093063, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 356952, "time": 16754.81942009926, "episode/length": 196.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 357056, "time": 16760.04864025116, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 357800, "time": 16786.122215509415, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 358056, "time": 16796.14198899269, "episode/length": 140.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 358112, "time": 16799.856528520584, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 358200, "time": 16804.17477083206, "episode/length": 172.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 358272, "time": 16808.351071357727, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 358400, "time": 16814.265853643417, "episode/length": 167.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 358512, "time": 16819.98211956024, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 358688, "time": 16827.436017513275, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 359120, "time": 16843.374352693558, "episode/length": 295.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 359384, "time": 16853.532488822937, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 359664, "time": 16864.56272506714, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 359720, "time": 16867.92186164856, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 360008, "time": 16879.13995695114, "episode/length": 200.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16897.280129909515, "eval_episode/length": 44.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 360048, "time": 16902.722163677216, "eval_episode/length": 138.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712230215827338}
{"step": 360048, "time": 16904.74658226967, "eval_episode/length": 146.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 360048, "time": 16906.33834338188, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 360048, "time": 16908.517431735992, "eval_episode/length": 160.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 360048, "time": 16910.659934043884, "eval_episode/length": 172.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 360048, "time": 16914.58936548233, "eval_episode/length": 192.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 360048, "time": 16914.613686561584, "eval_episode/length": 147.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 360096, "time": 16916.2373855114, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 360192, "time": 16920.920775175095, "episode/length": 133.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 360336, "time": 16927.436083078384, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 360344, "time": 16929.051387548447, "episode/length": 258.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 360552, "time": 16938.850783586502, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 361136, "time": 16960.120177030563, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 361296, "time": 16966.974249839783, "episode/length": 160.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 361328, "time": 16969.586453199387, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 361480, "time": 16976.01660180092, "episode/length": 219.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 361624, "time": 16982.416632413864, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 361776, "time": 16989.3358335495, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 361856, "time": 16993.522183179855, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 361976, "time": 16999.013782262802, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 362040, "time": 17002.66998243332, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 362336, "time": 17014.151355981827, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 362400, "time": 17017.969247341156, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 362600, "time": 17025.982161283493, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 363176, "time": 17046.779113292694, "episode/length": 96.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 363312, "time": 17053.13230419159, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 363328, "time": 17055.272896289825, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 363456, "time": 17061.104379177094, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 363624, "time": 17068.050991773605, "episode/length": 230.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 363824, "time": 17076.991800308228, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 363856, "time": 17079.660227298737, "episode/length": 226.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 364672, "time": 17108.801961183548, "episode/length": 186.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 364928, "time": 17119.429053783417, "episode/length": 199.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 365032, "time": 17124.162469625473, "episode/length": 303.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 365096, "time": 17127.849492549896, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 365312, "time": 17136.755574464798, "episode/length": 431.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 365352, "time": 17139.61314702034, "episode/length": 190.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 365968, "time": 17161.735498905182, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 366032, "time": 17165.430163383484, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 366320, "time": 17176.538423776627, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 366528, "time": 17184.942774295807, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 366592, "time": 17188.587326526642, "episode/length": 159.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 366616, "time": 17190.97330403328, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 366784, "time": 17198.52533531189, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 366808, "time": 17200.67009949684, "episode/length": 436.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 367632, "time": 17230.07265138626, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 367728, "time": 17234.79621052742, "episode/length": 175.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 368008, "time": 17245.48667693138, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 368128, "time": 17251.245030641556, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 368256, "time": 17257.30882716179, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 368488, "time": 17266.550034999847, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 368760, "time": 17278.93222618103, "episode/length": 267.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 368848, "time": 17284.293370246887, "episode/length": 359.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 368944, "time": 17289.234574079514, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 369192, "time": 17298.81132555008, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 369328, "time": 17305.199139118195, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 369520, "time": 17313.230902671814, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 369752, "time": 17322.640391349792, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 369928, "time": 17330.242071390152, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17354.903631448746, "eval_episode/length": 145.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 370032, "time": 17356.478424072266, "eval_episode/length": 147.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 370032, "time": 17356.546918153763, "eval_episode/length": 147.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 370032, "time": 17359.85216808319, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 370032, "time": 17362.69432401657, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 370032, "time": 17364.71057486534, "eval_episode/length": 45.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8913043478260869}
{"step": 370032, "time": 17366.437828063965, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9844559585492227}
{"step": 370032, "time": 17368.174592733383, "eval_episode/length": 193.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 370033, "time": 17368.753173828125, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.729841793284697, "train/action_min": 0.0, "train/action_std": 3.571210566688986, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04947330427410848, "train/actor_opt_grad_steps": 22355.0, "train/actor_opt_loss": -3.710960844928837, "train/adv_mag": 0.7198358009404996, "train/adv_max": 0.7098903875140583, "train/adv_mean": 0.003478449156265175, "train/adv_min": -0.521678785848267, "train/adv_std": 0.07538057493922465, "train/cont_avg": 0.9945283777573529, "train/cont_loss_mean": 0.00040978225176000735, "train/cont_loss_std": 0.011755297484186526, "train/cont_neg_acc": 0.9857842997268395, "train/cont_neg_loss": 0.036033798246390455, "train/cont_pos_acc": 0.9999494605204639, "train/cont_pos_loss": 0.0001717211004317843, "train/cont_pred": 0.9945483190171859, "train/cont_rate": 0.9945283777573529, "train/dyn_loss_mean": 14.05998877918019, "train/dyn_loss_std": 9.080348042880788, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8510390480651575, "train/extr_critic_critic_opt_grad_steps": 22355.0, "train/extr_critic_critic_opt_loss": 15362.930563534008, "train/extr_critic_mag": 4.810656337177052, "train/extr_critic_max": 4.810656337177052, "train/extr_critic_mean": 0.9609409053536022, "train/extr_critic_min": -0.21536105082315557, "train/extr_critic_std": 1.0544472301707548, "train/extr_return_normed_mag": 1.8659550722907572, "train/extr_return_normed_max": 1.8659550722907572, "train/extr_return_normed_mean": 0.3047564002301763, "train/extr_return_normed_min": -0.1659726673079764, "train/extr_return_normed_std": 0.33570108748972416, "train/extr_return_rate": 0.4706701169557431, "train/extr_return_raw_mag": 6.043356699102065, "train/extr_return_raw_max": 6.043356699102065, "train/extr_return_raw_mean": 0.9722261698368717, "train/extr_return_raw_min": -0.556704843088108, "train/extr_return_raw_std": 1.0903765809010058, "train/extr_reward_mag": 1.0143348732415367, "train/extr_reward_max": 1.0143348732415367, "train/extr_reward_mean": 0.025454839629888096, "train/extr_reward_min": -0.44929346091607036, "train/extr_reward_std": 0.14740115327431874, "train/image_loss_mean": 7.704775550786187, "train/image_loss_std": 11.785163753172931, "train/model_loss_mean": 16.19331583556007, "train/model_loss_std": 15.490009104504304, "train/model_opt_grad_norm": 67.73357471297768, "train/model_opt_grad_steps": 22332.54411764706, "train/model_opt_loss": 12426.024015538833, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 767.4632352941177, "train/policy_entropy_mag": 2.5413109221879173, "train/policy_entropy_max": 2.5413109221879173, "train/policy_entropy_mean": 0.7162190693266252, "train/policy_entropy_min": 0.07937516063890036, "train/policy_entropy_std": 0.7327453222344903, "train/policy_logprob_mag": 7.438383165527792, "train/policy_logprob_max": -0.00945568539421348, "train/policy_logprob_mean": -0.7166165420237709, "train/policy_logprob_min": -7.438383165527792, "train/policy_logprob_std": 1.1914441568009995, "train/policy_randomness_mag": 0.8969712349421838, "train/policy_randomness_max": 0.8969712349421838, "train/policy_randomness_mean": 0.25279390220256415, "train/policy_randomness_min": 0.028015948380069697, "train/policy_randomness_std": 0.2586269402766929, "train/post_ent_mag": 58.115513296688306, "train/post_ent_max": 58.115513296688306, "train/post_ent_mean": 40.285539991715375, "train/post_ent_min": 20.51489325831918, "train/post_ent_std": 7.216161044204936, "train/prior_ent_mag": 67.29951084361358, "train/prior_ent_max": 67.29951084361358, "train/prior_ent_mean": 54.42010851467357, "train/prior_ent_min": 36.175421826979694, "train/prior_ent_std": 5.036868358359618, "train/rep_loss_mean": 14.05998877918019, "train/rep_loss_std": 9.080348042880788, "train/reward_avg": 0.022473862557329565, "train/reward_loss_mean": 0.05213732113513876, "train/reward_loss_std": 0.25172561801531734, "train/reward_max_data": 1.013235297273187, "train/reward_max_pred": 1.0082141958615358, "train/reward_neg_acc": 0.9935435915694517, "train/reward_neg_loss": 0.02867531418279909, "train/reward_pos_acc": 0.9584706403753337, "train/reward_pos_loss": 0.8932559569092358, "train/reward_pred": 0.02157558795999434, "train/reward_rate": 0.02734375, "train_stats/sum_log_reward": 5.161946869529454, "train_stats/max_log_achievement_collect_coal": 0.008849557522123894, "train_stats/max_log_achievement_collect_drink": 5.575221238938053, "train_stats/max_log_achievement_collect_sapling": 2.3893805309734515, "train_stats/max_log_achievement_collect_stone": 0.1504424778761062, "train_stats/max_log_achievement_collect_wood": 5.646017699115045, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.36283185840707965, "train_stats/max_log_achievement_eat_cow": 0.08849557522123894, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.25663716814159293, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.230088495575221, "train_stats/max_log_achievement_place_stone": 0.008849557522123894, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.3893805309734515, "train_stats/mean_log_entropy": 0.6731511457303984, "eval_stats/sum_log_reward": 5.016666615381837, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 2.1666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.041666666666666664, "eval_stats/max_log_achievement_collect_wood": 5.791666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 2.1666666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.8333333333333333, "eval_stats/max_log_achievement_wake_up": 1.7916666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.452254405710846e-06, "report/cont_loss_std": 0.00010721562284743413, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004105338011868298, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.479332569142571e-06, "report/cont_pred": 0.9951127767562866, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.550188064575195, "report/dyn_loss_std": 9.475179672241211, "report/image_loss_mean": 7.123621463775635, "report/image_loss_std": 12.87302017211914, "report/model_loss_mean": 15.310707092285156, "report/model_loss_std": 17.014352798461914, "report/post_ent_mag": 60.499366760253906, "report/post_ent_max": 60.499366760253906, "report/post_ent_mean": 41.476417541503906, "report/post_ent_min": 19.942928314208984, "report/post_ent_std": 7.615025043487549, "report/prior_ent_mag": 67.0900650024414, "report/prior_ent_max": 67.0900650024414, "report/prior_ent_mean": 54.82398986816406, "report/prior_ent_min": 36.419219970703125, "report/prior_ent_std": 4.653552532196045, "report/rep_loss_mean": 13.550188064575195, "report/rep_loss_std": 9.475179672241211, "report/reward_avg": 0.01201171986758709, "report/reward_loss_mean": 0.05696360766887665, "report/reward_loss_std": 0.39381667971611023, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009231567382812, "report/reward_neg_acc": 0.996023952960968, "report/reward_neg_loss": 0.04566556215286255, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6883987188339233, "report/reward_pred": 0.013569358736276627, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0005100277485325933, "eval/cont_loss_std": 0.00918879359960556, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.056613534688949585, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0001238679833477363, "eval/cont_pred": 0.9934026598930359, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.276111602783203, "eval/dyn_loss_std": 9.992412567138672, "eval/image_loss_mean": 15.109549522399902, "eval/image_loss_std": 24.431238174438477, "eval/model_loss_mean": 26.197662353515625, "eval/model_loss_std": 27.772817611694336, "eval/post_ent_mag": 56.82312774658203, "eval/post_ent_max": 56.82312774658203, "eval/post_ent_mean": 39.38121032714844, "eval/post_ent_min": 19.20810317993164, "eval/post_ent_std": 6.830047607421875, "eval/prior_ent_mag": 67.0900650024414, "eval/prior_ent_max": 67.0900650024414, "eval/prior_ent_mean": 55.02007293701172, "eval/prior_ent_min": 39.32069396972656, "eval/prior_ent_std": 4.681556224822998, "eval/rep_loss_mean": 18.276111602783203, "eval/rep_loss_std": 9.992412567138672, "eval/reward_avg": 0.03671874850988388, "eval/reward_loss_mean": 0.12193681299686432, "eval/reward_loss_std": 0.7071003317832947, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041584968566895, "eval/reward_neg_acc": 0.9979612231254578, "eval/reward_neg_loss": 0.05661165714263916, "eval/reward_pos_acc": 0.8604651093482971, "eval/reward_pos_loss": 1.6122617721557617, "eval/reward_pred": 0.03216920047998428, "eval/reward_rate": 0.0419921875, "replay/size": 369529.0, "replay/inserts": 21752.0, "replay/samples": 21744.0, "replay/insert_wait_avg": 1.3603516123057202e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.334661927268819e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74896.0, "eval_replay/inserts": 5064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1848894905705022e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1015.2337625026703, "timer/env.step_count": 2719.0, "timer/env.step_total": 255.65631580352783, "timer/env.step_frac": 0.2518201474833786, "timer/env.step_avg": 0.09402586090604187, "timer/env.step_min": 0.02214670181274414, "timer/env.step_max": 3.406370162963867, "timer/replay._sample_count": 21744.0, "timer/replay._sample_total": 11.229154348373413, "timer/replay._sample_frac": 0.011060658897604263, "timer/replay._sample_avg": 0.0005164254207309333, "timer/replay._sample_min": 0.0003879070281982422, "timer/replay._sample_max": 0.008994579315185547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3352.0, "timer/agent.policy_total": 55.55994367599487, "timer/agent.policy_frac": 0.05472625687608448, "timer/agent.policy_avg": 0.016575162194509212, "timer/agent.policy_min": 0.009383201599121094, "timer/agent.policy_max": 0.12111401557922363, "timer/dataset_train_count": 1359.0, "timer/dataset_train_total": 0.14916443824768066, "timer/dataset_train_frac": 0.00014692619942029196, "timer/dataset_train_avg": 0.00010976044021168555, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0005917549133300781, "timer/agent.train_count": 1359.0, "timer/agent.train_total": 609.8269634246826, "timer/agent.train_frac": 0.6006764017790225, "timer/agent.train_avg": 0.4487321290836517, "timer/agent.train_min": 0.432584285736084, "timer/agent.train_max": 1.5169072151184082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47661328315734863, "timer/agent.report_frac": 0.0004694616163891565, "timer/agent.report_avg": 0.23830664157867432, "timer/agent.report_min": 0.23365211486816406, "timer/agent.report_max": 0.24296116828918457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.193838498621367e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 21.425337754955773}
{"step": 370040, "time": 17368.77696275711, "episode/length": 193.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 370088, "time": 17372.988190174103, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 370208, "time": 17379.37194776535, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 370488, "time": 17390.023893117905, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 370776, "time": 17401.156157255173, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 370984, "time": 17409.706127405167, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 371152, "time": 17417.129901885986, "episode/length": 138.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 371200, "time": 17420.387378931046, "episode/length": 180.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 371224, "time": 17422.689485311508, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 371416, "time": 17430.55991792679, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 371472, "time": 17434.213846683502, "episode/length": 157.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 371768, "time": 17445.527421951294, "episode/length": 43.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 371984, "time": 17454.523046970367, "episode/length": 103.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 372312, "time": 17466.847403526306, "episode/length": 227.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 372600, "time": 17478.029095888138, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 372712, "time": 17483.354602098465, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 372800, "time": 17488.252583265305, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 373056, "time": 17498.924949645996, "episode/length": 133.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 373096, "time": 17502.12744307518, "episode/length": 289.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9758620689655172, "episode/intrinsic_return": 0.0}
{"step": 373464, "time": 17515.859173059464, "episode/length": 143.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 373944, "time": 17533.370788812637, "episode/length": 271.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 17535.95916414261, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 374168, "time": 17543.89854502678, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 374208, "time": 17547.146423339844, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 374456, "time": 17557.00572538376, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 374544, "time": 17561.66922235489, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 374808, "time": 17571.744346141815, "episode/length": 416.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 375104, "time": 17584.072704076767, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 375320, "time": 17592.778914928436, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 375368, "time": 17595.90575361252, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 375424, "time": 17599.509595632553, "episode/length": 120.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 375840, "time": 17615.118266820908, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 376048, "time": 17623.644770145416, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 376480, "time": 17639.69389462471, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 376568, "time": 17643.95028090477, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 376648, "time": 17648.32929968834, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 376672, "time": 17650.873808145523, "episode/length": 162.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 376872, "time": 17660.25676727295, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 377112, "time": 17669.745139837265, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 377224, "time": 17675.138927936554, "episode/length": 92.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 377224, "time": 17675.14773631096, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 377632, "time": 17691.977739095688, "episode/length": 427.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 377808, "time": 17699.58764719963, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 377832, "time": 17701.719353675842, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 378032, "time": 17710.547525405884, "episode/length": 182.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 378168, "time": 17716.485253095627, "episode/length": 131.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.0}
{"step": 378944, "time": 17744.287770986557, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 379104, "time": 17751.246597528458, "episode/length": 303.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 379112, "time": 17752.978257894516, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 379640, "time": 17772.397077560425, "episode/length": 183.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 379712, "time": 17776.7034573555, "episode/length": 75.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 379760, "time": 17779.940644025803, "episode/length": 243.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 379920, "time": 17786.945370435715, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 379952, "time": 17790.226781845093, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17814.603866815567, "eval_episode/length": 84.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 380016, "time": 17817.847558498383, "eval_episode/length": 38.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8974358974358975}
{"step": 380016, "time": 17821.220220804214, "eval_episode/length": 163.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 380016, "time": 17823.130254983902, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 380016, "time": 17823.14071536064, "eval_episode/length": 47.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 380016, "time": 17827.85239505768, "eval_episode/length": 198.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 380016, "time": 17829.662957191467, "eval_episode/length": 204.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 380016, "time": 17832.856487989426, "eval_episode/length": 241.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9669421487603306}
{"step": 380136, "time": 17836.61039185524, "episode/length": 287.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 380152, "time": 17838.71034860611, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 380328, "time": 17846.07120013237, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 380336, "time": 17848.218111753464, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 380952, "time": 17870.152526140213, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 381192, "time": 17879.750081062317, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 381280, "time": 17884.390043973923, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 381424, "time": 17890.966069221497, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 381664, "time": 17901.268106222153, "episode/length": 188.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 382152, "time": 17918.95014810562, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 382200, "time": 17922.654584884644, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 382488, "time": 17934.008998394012, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 382576, "time": 17938.631479263306, "episode/length": 161.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 383008, "time": 17954.681325674057, "episode/length": 226.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 383080, "time": 17958.460988759995, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 383280, "time": 17966.89751791954, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 383568, "time": 17978.201687812805, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 383696, "time": 17984.061700820923, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 383824, "time": 17990.035662412643, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 383912, "time": 17994.92572593689, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 383936, "time": 17997.508722305298, "episode/length": 222.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 384440, "time": 18015.632051467896, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 384800, "time": 18029.385898828506, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 385144, "time": 18043.84041452408, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 385272, "time": 18049.64689016342, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 385344, "time": 18053.81094121933, "episode/length": 189.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 385352, "time": 18055.41906619072, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 385848, "time": 18073.8766477108, "episode/length": 130.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 385928, "time": 18078.088267564774, "episode/length": 294.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 386344, "time": 18093.49852991104, "episode/length": 300.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 386472, "time": 18099.435774326324, "episode/length": 253.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 386592, "time": 18105.144884109497, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 386800, "time": 18113.52676677704, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 387184, "time": 18127.929098129272, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 387184, "time": 18127.93947505951, "episode/length": 238.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 387192, "time": 18131.60478401184, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 387328, "time": 18137.877007961273, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 387504, "time": 18145.270307779312, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 387728, "time": 18154.30640912056, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 387832, "time": 18159.27902197838, "episode/length": 62.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 388120, "time": 18170.483677625656, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 388192, "time": 18174.575407743454, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 388256, "time": 18178.207810163498, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 388400, "time": 18184.528542757034, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 388448, "time": 18187.855228424072, "episode/length": 157.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 388752, "time": 18199.417704343796, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 389112, "time": 18212.768460035324, "episode/length": 44.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 389224, "time": 18218.097605228424, "episode/length": 186.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 389376, "time": 18224.868433475494, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 389416, "time": 18227.455896139145, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 389760, "time": 18240.703117370605, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 389816, "time": 18243.884341955185, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 389824, "time": 18246.03409910202, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18272.846997261047, "eval_episode/length": 151.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993421052631579}
{"step": 390000, "time": 18274.66282272339, "eval_episode/length": 153.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 390000, "time": 18277.009214878082, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 390000, "time": 18279.012784957886, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.994413407821229}
{"step": 390000, "time": 18281.52752637863, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 390000, "time": 18283.470361471176, "eval_episode/length": 34.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 390000, "time": 18285.626755952835, "eval_episode/length": 219.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 390000, "time": 18287.45858645439, "eval_episode/length": 225.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 390088, "time": 18290.160059690475, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 390392, "time": 18301.80770611763, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 390680, "time": 18312.90103840828, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 390792, "time": 18318.162721157074, "episode/length": 171.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 390792, "time": 18318.17194533348, "episode/length": 298.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 390944, "time": 18327.176426649094, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 391080, "time": 18333.05844783783, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 391400, "time": 18345.41571378708, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 391536, "time": 18351.755417585373, "episode/length": 214.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 391864, "time": 18364.00511789322, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 391929, "time": 18368.808557271957, "train_stats/sum_log_reward": 5.382051269213359, "train_stats/max_log_achievement_collect_coal": 0.05982905982905983, "train_stats/max_log_achievement_collect_drink": 4.6752136752136755, "train_stats/max_log_achievement_collect_sapling": 2.3846153846153846, "train_stats/max_log_achievement_collect_stone": 0.6153846153846154, "train_stats/max_log_achievement_collect_wood": 6.3760683760683765, "train_stats/max_log_achievement_defeat_skeleton": 0.017094017094017096, "train_stats/max_log_achievement_defeat_zombie": 0.38461538461538464, "train_stats/max_log_achievement_eat_cow": 0.05128205128205128, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4017094017094017, "train_stats/max_log_achievement_make_wood_sword": 0.017094017094017096, "train_stats/max_log_achievement_place_plant": 2.2905982905982905, "train_stats/max_log_achievement_place_stone": 0.017094017094017096, "train_stats/max_log_achievement_place_table": 2.1452991452991452, "train_stats/max_log_achievement_wake_up": 2.1880341880341883, "train_stats/mean_log_entropy": 0.6491389261861132, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.495182710535386, "train/action_min": 0.0, "train/action_std": 3.469022708780625, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04947943597867647, "train/actor_opt_grad_steps": 23715.0, "train/actor_opt_loss": -1.5762258768081665, "train/adv_mag": 0.7370829100117964, "train/adv_max": 0.725085231311181, "train/adv_mean": 0.004101938693565899, "train/adv_min": -0.5020443753284567, "train/adv_std": 0.0752664573271485, "train/cont_avg": 0.9947007123161765, "train/cont_loss_mean": 0.00023785579452581038, "train/cont_loss_std": 0.007083171921237863, "train/cont_neg_acc": 0.9950892863904729, "train/cont_neg_loss": 0.012100044911572723, "train/cont_pos_acc": 0.9999350094619919, "train/cont_pos_loss": 0.00016304155218668955, "train/cont_pred": 0.9946730934521731, "train/cont_rate": 0.9947007123161765, "train/dyn_loss_mean": 13.997349668951596, "train/dyn_loss_std": 9.094600389985477, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8180718329899451, "train/extr_critic_critic_opt_grad_steps": 23715.0, "train/extr_critic_critic_opt_loss": 15437.981251436122, "train/extr_critic_mag": 4.9047746342771195, "train/extr_critic_max": 4.9047746342771195, "train/extr_critic_mean": 0.9599102634717437, "train/extr_critic_min": -0.21953335492049947, "train/extr_critic_std": 1.0682966152534765, "train/extr_return_normed_mag": 1.8519754138062983, "train/extr_return_normed_max": 1.8519754138062983, "train/extr_return_normed_mean": 0.2973640873370802, "train/extr_return_normed_min": -0.16894457587862716, "train/extr_return_normed_std": 0.333697212202584, "train/extr_return_rate": 0.4690765013151309, "train/extr_return_raw_mag": 6.114438649486093, "train/extr_return_raw_max": 6.114438649486093, "train/extr_return_raw_mean": 0.9734642917619032, "train/extr_return_raw_min": -0.5688773127382293, "train/extr_return_raw_std": 1.1036447751171448, "train/extr_reward_mag": 1.015895764617359, "train/extr_reward_max": 1.015895764617359, "train/extr_reward_mean": 0.026089103447328156, "train/extr_reward_min": -0.4496919398798662, "train/extr_reward_std": 0.1491308090660502, "train/image_loss_mean": 7.631221778252545, "train/image_loss_std": 11.877915193052853, "train/model_loss_mean": 16.082605453098523, "train/model_loss_std": 15.629036391482634, "train/model_opt_grad_norm": 60.85784128132988, "train/model_opt_grad_steps": 23692.0, "train/model_opt_loss": 17419.479528090535, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1075.3676470588234, "train/policy_entropy_mag": 2.5463992918238922, "train/policy_entropy_max": 2.5463992918238922, "train/policy_entropy_mean": 0.7069150941336856, "train/policy_entropy_min": 0.07937514206723255, "train/policy_entropy_std": 0.74225482651416, "train/policy_logprob_mag": 7.438383039306192, "train/policy_logprob_max": -0.009455683654831612, "train/policy_logprob_mean": -0.7071872888242497, "train/policy_logprob_min": -7.438383039306192, "train/policy_logprob_std": 1.1879437241484136, "train/policy_randomness_mag": 0.8987672052839223, "train/policy_randomness_max": 0.8987672052839223, "train/policy_randomness_mean": 0.24951000588343425, "train/policy_randomness_min": 0.028015941778636155, "train/policy_randomness_std": 0.26198337884510264, "train/post_ent_mag": 57.84060335159302, "train/post_ent_max": 57.84060335159302, "train/post_ent_mean": 40.46458996043486, "train/post_ent_min": 20.46286514226128, "train/post_ent_std": 7.1759308296091415, "train/prior_ent_mag": 67.34405315623565, "train/prior_ent_max": 67.34405315623565, "train/prior_ent_mean": 54.508241064408246, "train/prior_ent_min": 37.07635412496679, "train/prior_ent_std": 4.9233583843006805, "train/rep_loss_mean": 13.997349668951596, "train/rep_loss_std": 9.094600389985477, "train/reward_avg": 0.023721133673782733, "train/reward_loss_mean": 0.052736165385474175, "train/reward_loss_std": 0.2454882974133772, "train/reward_max_data": 1.0154411801520515, "train/reward_max_pred": 1.0090245122418684, "train/reward_neg_acc": 0.9933598584988538, "train/reward_neg_loss": 0.0287043208749417, "train/reward_pos_acc": 0.9662583614973461, "train/reward_pos_loss": 0.871085305862567, "train/reward_pred": 0.022786097347681576, "train/reward_rate": 0.02853573069852941, "eval_stats/sum_log_reward": 4.912499970756471, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.945743861142546e-06, "report/cont_loss_std": 2.5477695089648478e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000322087638778612, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.748806989278819e-07, "report/cont_pred": 0.9951184988021851, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.504199981689453, "report/dyn_loss_std": 8.584569931030273, "report/image_loss_mean": 5.491634368896484, "report/image_loss_std": 8.725383758544922, "report/model_loss_mean": 13.646293640136719, "report/model_loss_std": 12.401782035827637, "report/post_ent_mag": 58.01593017578125, "report/post_ent_max": 58.01593017578125, "report/post_ent_mean": 40.30801773071289, "report/post_ent_min": 20.064308166503906, "report/post_ent_std": 7.485973358154297, "report/prior_ent_mag": 67.1526870727539, "report/prior_ent_max": 67.1526870727539, "report/prior_ent_mean": 54.5692138671875, "report/prior_ent_min": 39.37070083618164, "report/prior_ent_std": 4.19333028793335, "report/rep_loss_mean": 13.504199981689453, "report/rep_loss_std": 8.584569931030273, "report/reward_avg": 0.03105468675494194, "report/reward_loss_mean": 0.052137959748506546, "report/reward_loss_std": 0.24686527252197266, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017545223236084, "report/reward_neg_acc": 0.9979776740074158, "report/reward_neg_loss": 0.025325456634163857, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.8097825646400452, "report/reward_pred": 0.029758602380752563, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.7401353034074418e-06, "eval/cont_loss_std": 2.8584592655533925e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000500953639857471, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.732986388309655e-07, "eval/cont_pred": 0.9970716238021851, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.472885131835938, "eval/dyn_loss_std": 10.653264999389648, "eval/image_loss_mean": 17.158660888671875, "eval/image_loss_std": 24.611637115478516, "eval/model_loss_mean": 28.349803924560547, "eval/model_loss_std": 28.57452964782715, "eval/post_ent_mag": 55.27083969116211, "eval/post_ent_max": 55.27083969116211, "eval/post_ent_mean": 39.09398651123047, "eval/post_ent_min": 21.133148193359375, "eval/post_ent_std": 6.8998942375183105, "eval/prior_ent_mag": 67.1526870727539, "eval/prior_ent_max": 67.1526870727539, "eval/prior_ent_mean": 55.11752700805664, "eval/prior_ent_min": 38.57225799560547, "eval/prior_ent_std": 4.038009166717529, "eval/rep_loss_mean": 18.472885131835938, "eval/rep_loss_std": 10.653264999389648, "eval/reward_avg": 0.02978515438735485, "eval/reward_loss_mean": 0.10741044580936432, "eval/reward_loss_std": 0.7517834901809692, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023977756500244, "eval/reward_neg_acc": 0.9939454793930054, "eval/reward_neg_loss": 0.031054053455591202, "eval/reward_pos_acc": 0.7575757503509521, "eval/reward_pos_loss": 2.4004158973693848, "eval/reward_pred": 0.021250955760478973, "eval/reward_rate": 0.0322265625, "replay/size": 391425.0, "replay/inserts": 21896.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.3652773812865096e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.472632251402337e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78640.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2565372336624016e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0392560958862, "timer/env.step_count": 2737.0, "timer/env.step_total": 264.3435525894165, "timer/env.step_frac": 0.2643331759009174, "timer/env.step_avg": 0.09658149528294355, "timer/env.step_min": 0.02263474464416504, "timer/env.step_max": 3.7532896995544434, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 11.249659061431885, "timer/replay._sample_frac": 0.011249217461072589, "timer/replay._sample_avg": 0.0005135892559090525, "timer/replay._sample_min": 0.0003724098205566406, "timer/replay._sample_max": 0.00796365737915039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3205.0, "timer/agent.policy_total": 51.51291751861572, "timer/agent.policy_frac": 0.051510895401966635, "timer/agent.policy_avg": 0.016072673172735016, "timer/agent.policy_min": 0.009251832962036133, "timer/agent.policy_max": 0.10743451118469238, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.14974474906921387, "timer/dataset_train_frac": 0.0001497388709057397, "timer/dataset_train_avg": 0.0001093825778445682, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0004909038543701172, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 613.6979293823242, "timer/agent.train_frac": 0.6136738389432598, "timer/agent.train_avg": 0.44828190604990814, "timer/agent.train_min": 0.4342327117919922, "timer/agent.train_max": 1.5676329135894775, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769456386566162, "timer/agent.report_frac": 0.00047692691636785656, "timer/agent.report_avg": 0.2384728193283081, "timer/agent.report_min": 0.23038864135742188, "timer/agent.report_max": 0.24655699729919434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908592485053575e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.894853772115333}
{"step": 392024, "time": 18371.8705098629, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 392240, "time": 18380.771319389343, "episode/length": 144.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 392272, "time": 18383.439208507538, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 392448, "time": 18390.84529685974, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 392568, "time": 18396.28932571411, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 392712, "time": 18402.60855960846, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 393352, "time": 18427.153239011765, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 393520, "time": 18434.964933395386, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 393760, "time": 18444.602508544922, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 393808, "time": 18447.776763677597, "episode/length": 283.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 393832, "time": 18449.961380958557, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 393976, "time": 18456.510994672775, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 394160, "time": 18464.385122537613, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 394272, "time": 18469.905276298523, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 395096, "time": 18498.869590759277, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 395352, "time": 18509.0861120224, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 395384, "time": 18511.67800474167, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 395448, "time": 18515.501646995544, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 395456, "time": 18517.627369880676, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 395888, "time": 18533.703245401382, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 395896, "time": 18535.361109018326, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 396512, "time": 18558.213659763336, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 396576, "time": 18561.92297887802, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 396792, "time": 18570.50738811493, "episode/length": 351.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 396824, "time": 18573.65240573883, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 396880, "time": 18577.975708961487, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 397040, "time": 18584.85724258423, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 397296, "time": 18594.95833325386, "episode/length": 89.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 397352, "time": 18598.17848587036, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 397832, "time": 18616.053710222244, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 398032, "time": 18624.82396006584, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 398064, "time": 18627.46804356575, "episode/length": 193.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 398184, "time": 18632.758174419403, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9721254355400697, "episode/intrinsic_return": 0.0}
{"step": 398400, "time": 18641.81674194336, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 398440, "time": 18644.402494192123, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 398472, "time": 18647.061445713043, "episode/length": 146.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 398648, "time": 18654.54363965988, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 399336, "time": 18679.34511256218, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 399384, "time": 18682.731988191605, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 399704, "time": 18694.934412002563, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 399808, "time": 18700.21929383278, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 399848, "time": 18702.93072795868, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 399896, "time": 18706.04460978508, "episode/length": 213.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 399992, "time": 18710.764023780823, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18730.739718675613, "eval_episode/length": 50.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 400088, "time": 18737.37610220909, "eval_episode/length": 172.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 400088, "time": 18739.555378198624, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 400088, "time": 18741.631937026978, "eval_episode/length": 193.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 400088, "time": 18743.275270462036, "eval_episode/length": 195.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 400088, "time": 18746.017656087875, "eval_episode/length": 219.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 400088, "time": 18747.553853988647, "eval_episode/length": 221.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 400088, "time": 18750.512989759445, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 400480, "time": 18763.84844493866, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 400752, "time": 18774.407427310944, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 401040, "time": 18785.663492679596, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 401104, "time": 18789.328277111053, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 401296, "time": 18797.23816895485, "episode/length": 162.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 401392, "time": 18802.042002677917, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 401504, "time": 18808.828887224197, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 401536, "time": 18811.760362625122, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 401936, "time": 18826.758219242096, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 402464, "time": 18845.855894804, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 402488, "time": 18848.03123164177, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 402888, "time": 18862.850606441498, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 403072, "time": 18870.75595521927, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 403136, "time": 18874.41864824295, "episode/length": 217.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 403264, "time": 18880.39829683304, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 403312, "time": 18883.590965032578, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 403408, "time": 18888.5063560009, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 403656, "time": 18898.04919075966, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 403944, "time": 18909.11113023758, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 404424, "time": 18926.716768980026, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 404560, "time": 18933.02433180809, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 404624, "time": 18936.943075418472, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 404808, "time": 18944.412879228592, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 404848, "time": 18947.527334928513, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 405232, "time": 18961.88843894005, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 405376, "time": 18968.51682972908, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 405720, "time": 18981.242915153503, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 405992, "time": 18991.818964242935, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 406248, "time": 19003.20830631256, "episode/length": 287.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 406488, "time": 19012.720708608627, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 406544, "time": 19016.27225279808, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 406592, "time": 19019.3918261528, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 406824, "time": 19028.57102751732, "episode/length": 103.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 406856, "time": 19031.246375322342, "episode/length": 202.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 407312, "time": 19048.56886291504, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 407632, "time": 19060.985752105713, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 407864, "time": 19069.984461784363, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 408064, "time": 19078.378775835037, "episode/length": 196.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 408104, "time": 19081.094874858856, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 408104, "time": 19081.10415649414, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 408152, "time": 19086.291981697083, "episode/length": 165.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 408256, "time": 19091.57883644104, "episode/length": 430.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9930394431554525, "episode/intrinsic_return": 0.0}
{"step": 408904, "time": 19114.62649154663, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 408992, "time": 19120.019102573395, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 409352, "time": 19133.369605064392, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 409416, "time": 19137.17965912819, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 409424, "time": 19139.301986455917, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 409536, "time": 19144.593077898026, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 409712, "time": 19154.192115545273, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 409800, "time": 19158.692811012268, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19190.714401245117, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 410072, "time": 19192.715264081955, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 410072, "time": 19194.906814575195, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 410072, "time": 19197.198838710785, "eval_episode/length": 40.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 410072, "time": 19199.42184662819, "eval_episode/length": 211.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 410072, "time": 19201.211144208908, "eval_episode/length": 217.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.981651376146789}
{"step": 410072, "time": 19203.151140213013, "eval_episode/length": 224.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 410072, "time": 19205.327035427094, "eval_episode/length": 235.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 410672, "time": 19225.74651837349, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 410672, "time": 19225.767210006714, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 410920, "time": 19237.23582959175, "episode/length": 139.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 411152, "time": 19246.776770830154, "episode/length": 215.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 411176, "time": 19248.888454675674, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 411184, "time": 19251.01243662834, "episode/length": 205.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 411248, "time": 19254.685653448105, "episode/length": 292.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 411272, "time": 19256.803431272507, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 411760, "time": 19274.899789571762, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 412072, "time": 19286.553743124008, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 412104, "time": 19289.229298114777, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 412624, "time": 19308.4641122818, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 412648, "time": 19311.028133630753, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 413064, "time": 19327.08860230446, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 413256, "time": 19335.09789276123, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 413472, "time": 19344.327692508698, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 413576, "time": 19349.29902291298, "episode/length": 226.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 413728, "time": 19356.22465634346, "episode/length": 381.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9869109947643979, "episode/intrinsic_return": 0.0}
{"step": 413752, "time": 19358.344820976257, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 413993, "time": 19368.99999332428, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.637054443359375, "train/action_min": 0.0, "train/action_std": 3.4584990549778594, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0505567505226835, "train/actor_opt_grad_steps": 25085.0, "train/actor_opt_loss": -5.578193752014118, "train/adv_mag": 0.7155025778473287, "train/adv_max": 0.7050532396288886, "train/adv_mean": 0.0036470838627146672, "train/adv_min": -0.49349602905736456, "train/adv_std": 0.07643187429377998, "train/cont_avg": 0.9943953804347826, "train/cont_loss_mean": 0.00019130851076227742, "train/cont_loss_std": 0.005402074102506418, "train/cont_neg_acc": 0.9932280899821848, "train/cont_neg_loss": 0.01971712820319964, "train/cont_pos_acc": 0.9999786688797716, "train/cont_pos_loss": 7.25701863048424e-05, "train/cont_pred": 0.9944156874781069, "train/cont_rate": 0.9943953804347826, "train/dyn_loss_mean": 13.747372931328373, "train/dyn_loss_std": 9.111309445422629, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8351262147011964, "train/extr_critic_critic_opt_grad_steps": 25085.0, "train/extr_critic_critic_opt_loss": 15571.54782325634, "train/extr_critic_mag": 4.98726427036783, "train/extr_critic_max": 4.98726427036783, "train/extr_critic_mean": 0.9659588449243186, "train/extr_critic_min": -0.23558422707129215, "train/extr_critic_std": 1.0830430457557456, "train/extr_return_normed_mag": 1.872784101444742, "train/extr_return_normed_max": 1.872784101444742, "train/extr_return_normed_mean": 0.30168684550385544, "train/extr_return_normed_min": -0.1624943093545195, "train/extr_return_normed_std": 0.33948410399582074, "train/extr_return_rate": 0.46724838277567987, "train/extr_return_raw_mag": 6.167434626731319, "train/extr_return_raw_max": 6.167434626731319, "train/extr_return_raw_mean": 0.9779816619727922, "train/extr_return_raw_min": -0.5553260854836823, "train/extr_return_raw_std": 1.1214124404865762, "train/extr_reward_mag": 1.0167145331700642, "train/extr_reward_max": 1.0167145331700642, "train/extr_reward_mean": 0.026681613946414513, "train/extr_reward_min": -0.40947534899780713, "train/extr_reward_std": 0.15134303644299507, "train/image_loss_mean": 7.374621128690416, "train/image_loss_std": 11.631708666898202, "train/model_loss_mean": 15.676225157751553, "train/model_loss_std": 15.34629992471225, "train/model_opt_grad_norm": 60.26650828209476, "train/model_opt_grad_steps": 25060.478260869564, "train/model_opt_loss": 14388.159558282383, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 919.3840579710145, "train/policy_entropy_mag": 2.532106584396915, "train/policy_entropy_max": 2.532106584396915, "train/policy_entropy_mean": 0.6476621489593948, "train/policy_entropy_min": 0.07937511429190636, "train/policy_entropy_std": 0.6877238638159158, "train/policy_logprob_mag": 7.438383347746255, "train/policy_logprob_max": -0.009455672991664513, "train/policy_logprob_mean": -0.6480012970126193, "train/policy_logprob_min": -7.438383347746255, "train/policy_logprob_std": 1.1548977027768674, "train/policy_randomness_mag": 0.8937225039454474, "train/policy_randomness_max": 0.8937225039454474, "train/policy_randomness_mean": 0.2285963159756384, "train/policy_randomness_min": 0.028015932000741577, "train/policy_randomness_std": 0.2427363425925158, "train/post_ent_mag": 58.35178297844486, "train/post_ent_max": 58.35178297844486, "train/post_ent_mean": 40.79750326405401, "train/post_ent_min": 20.49562244829924, "train/post_ent_std": 7.300970257192418, "train/prior_ent_mag": 67.52852923628213, "train/prior_ent_max": 67.52852923628213, "train/prior_ent_mean": 54.61822473830071, "train/prior_ent_min": 37.33090820865355, "train/prior_ent_std": 4.892030867977419, "train/rep_loss_mean": 13.747372931328373, "train/rep_loss_std": 9.111309445422629, "train/reward_avg": 0.02331790650614362, "train/reward_loss_mean": 0.052989059573282364, "train/reward_loss_std": 0.2447281416127647, "train/reward_max_data": 1.01449275707853, "train/reward_max_pred": 1.0078790464263032, "train/reward_neg_acc": 0.9932057010954705, "train/reward_neg_loss": 0.02957571434882888, "train/reward_pos_acc": 0.964199752047442, "train/reward_pos_loss": 0.8645687232846799, "train/reward_pred": 0.022682589485539473, "train/reward_rate": 0.0283203125, "train_stats/sum_log_reward": 5.843362800842892, "train_stats/max_log_achievement_collect_coal": 0.07079646017699115, "train_stats/max_log_achievement_collect_drink": 4.893805309734513, "train_stats/max_log_achievement_collect_sapling": 2.725663716814159, "train_stats/max_log_achievement_collect_stone": 0.5309734513274337, "train_stats/max_log_achievement_collect_wood": 6.442477876106195, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.4336283185840708, "train_stats/max_log_achievement_eat_cow": 0.061946902654867256, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7256637168141593, "train_stats/max_log_achievement_make_wood_sword": 0.02654867256637168, "train_stats/max_log_achievement_place_plant": 2.6283185840707963, "train_stats/max_log_achievement_place_stone": 0.008849557522123894, "train_stats/max_log_achievement_place_table": 2.1415929203539825, "train_stats/max_log_achievement_wake_up": 1.9115044247787611, "train_stats/mean_log_entropy": 0.6182728000974234, "eval_stats/sum_log_reward": 5.224999971687794, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.875, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.25, "eval_stats/max_log_achievement_collect_wood": 4.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.018518518518518517, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0050579095259308815, "report/cont_loss_std": 0.16171880066394806, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 0.8631143569946289, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.034945272404002e-07, "report/cont_pred": 0.9951122999191284, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.675131797790527, "report/dyn_loss_std": 9.130515098571777, "report/image_loss_mean": 7.8525166511535645, "report/image_loss_std": 11.30487060546875, "report/model_loss_mean": 16.112661361694336, "report/model_loss_std": 14.748745918273926, "report/post_ent_mag": 61.14949417114258, "report/post_ent_max": 61.14949417114258, "report/post_ent_mean": 41.64189910888672, "report/post_ent_min": 20.399757385253906, "report/post_ent_std": 8.171143531799316, "report/prior_ent_mag": 67.20523071289062, "report/prior_ent_max": 67.20523071289062, "report/prior_ent_mean": 55.427581787109375, "report/prior_ent_min": 37.83979034423828, "report/prior_ent_std": 5.509044170379639, "report/rep_loss_mean": 13.675131797790527, "report/rep_loss_std": 9.130515098571777, "report/reward_avg": 0.013867187313735485, "report/reward_loss_mean": 0.05000823736190796, "report/reward_loss_std": 0.33691954612731934, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0049889087677002, "report/reward_neg_acc": 0.9950199723243713, "report/reward_neg_loss": 0.024400265887379646, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 1.3355286121368408, "report/reward_pred": 0.011964745819568634, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.3349155778996646e-05, "eval/cont_loss_std": 0.00026586779858917, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001777605852112174, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.9507853014365537e-06, "eval/cont_pred": 0.9941481351852417, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.563533782958984, "eval/dyn_loss_std": 10.604263305664062, "eval/image_loss_mean": 22.237991333007812, "eval/image_loss_std": 33.09737014770508, "eval/model_loss_mean": 33.4764289855957, "eval/model_loss_std": 37.26536178588867, "eval/post_ent_mag": 55.06865310668945, "eval/post_ent_max": 55.06865310668945, "eval/post_ent_mean": 39.395713806152344, "eval/post_ent_min": 20.942665100097656, "eval/post_ent_std": 6.5125932693481445, "eval/prior_ent_mag": 67.20523071289062, "eval/prior_ent_max": 67.20523071289062, "eval/prior_ent_mean": 54.92033386230469, "eval/prior_ent_min": 39.39976501464844, "eval/prior_ent_std": 4.419055938720703, "eval/rep_loss_mean": 18.563533782958984, "eval/rep_loss_std": 10.604263305664062, "eval/reward_avg": 0.02197265625, "eval/reward_loss_mean": 0.10030435025691986, "eval/reward_loss_std": 0.599927544593811, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000193119049072, "eval/reward_neg_acc": 0.9859719276428223, "eval/reward_neg_loss": 0.04177728295326233, "eval/reward_pos_acc": 0.7307692766189575, "eval/reward_pos_loss": 2.3468434810638428, "eval/reward_pred": 0.015544346533715725, "eval/reward_rate": 0.025390625, "replay/size": 413489.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.3671788380922314e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.481309547728607e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82552.0, "eval_replay/inserts": 3912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1824635152680254e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1806797981262, "timer/env.step_count": 2758.0, "timer/env.step_total": 257.776486158371, "timer/env.step_frac": 0.25772991956853225, "timer/env.step_avg": 0.09346500585872769, "timer/env.step_min": 0.022815227508544922, "timer/env.step_max": 3.5283546447753906, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.475392580032349, "timer/replay._sample_frac": 0.011473319582966261, "timer/replay._sample_avg": 0.0005200957478259766, "timer/replay._sample_min": 0.0003955364227294922, "timer/replay._sample_max": 0.032889604568481445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3247.0, "timer/agent.policy_total": 53.810258865356445, "timer/agent.policy_frac": 0.053800538194976294, "timer/agent.policy_avg": 0.016572300235711872, "timer/agent.policy_min": 0.009340524673461914, "timer/agent.policy_max": 0.11993241310119629, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.15000271797180176, "timer/dataset_train_frac": 0.00014997562040698276, "timer/dataset_train_avg": 0.00010877644522973297, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0006530284881591797, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 621.7086751461029, "timer/agent.train_frac": 0.6215963652403153, "timer/agent.train_avg": 0.4508402285323444, "timer/agent.train_min": 0.434842586517334, "timer/agent.train_max": 1.651498794555664, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47522926330566406, "timer/agent.report_frac": 0.0004751434144894531, "timer/agent.report_avg": 0.23761463165283203, "timer/agent.report_min": 0.23137688636779785, "timer/agent.report_max": 0.2438523769378662, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765155909766561e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.059725099372944}
{"step": 414008, "time": 19369.079571723938, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 414632, "time": 19392.165773630142, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 414712, "time": 19396.565234184265, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 414784, "time": 19400.83610892296, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 414832, "time": 19404.61962556839, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 415344, "time": 19423.56580066681, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 415656, "time": 19435.514033794403, "episode/length": 240.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 415728, "time": 19439.770027399063, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 415896, "time": 19446.813434123993, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 416176, "time": 19458.032770872116, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 416304, "time": 19463.926134824753, "episode/length": 80.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 416312, "time": 19465.54808449745, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 416704, "time": 19480.675713777542, "episode/length": 403.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9925742574257426, "episode/intrinsic_return": 0.0}
{"step": 416768, "time": 19484.448204517365, "episode/length": 57.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 416784, "time": 19486.535748243332, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 417112, "time": 19499.085408449173, "episode/length": 220.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 417464, "time": 19512.547158002853, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 417640, "time": 19520.02379512787, "episode/length": 106.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 417856, "time": 19530.663948059082, "episode/length": 209.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 418072, "time": 19539.366253376007, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 418416, "time": 19552.80802297592, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 418528, "time": 19558.15335392952, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 418576, "time": 19561.309921741486, "episode/length": 334.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 418824, "time": 19571.044271469116, "episode/length": 50.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 419120, "time": 19582.828929424286, "episode/length": 206.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 419256, "time": 19588.70726132393, "episode/length": 201.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 419304, "time": 19592.041579008102, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 419704, "time": 19607.15964436531, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 419712, "time": 19609.178188323975, "episode/length": 204.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 419720, "time": 19610.794772863388, "episode/length": 148.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19638.513489961624, "eval_episode/length": 33.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8529411764705882}
{"step": 420056, "time": 19640.80531525612, "eval_episode/length": 50.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 420056, "time": 19646.048879384995, "eval_episode/length": 136.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 420056, "time": 19649.154425621033, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 420056, "time": 19652.40682220459, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 420056, "time": 19654.46466779709, "eval_episode/length": 184.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 420056, "time": 19657.315894842148, "eval_episode/length": 198.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 420056, "time": 19659.336468458176, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 420184, "time": 19663.668370962143, "episode/length": 290.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 420320, "time": 19669.908777713776, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 420544, "time": 19679.01363158226, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 420656, "time": 19684.40215611458, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 420712, "time": 19687.768139600754, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 420784, "time": 19692.01682639122, "episode/length": 74.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 420928, "time": 19698.41909480095, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 421144, "time": 19707.15688443184, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 421152, "time": 19709.63669371605, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 421312, "time": 19716.730404138565, "episode/length": 81.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 421608, "time": 19728.05451774597, "episode/length": 160.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 421608, "time": 19728.06418466568, "episode/length": 84.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 421792, "time": 19737.957468509674, "episode/length": 59.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 422216, "time": 19753.792887687683, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 422448, "time": 19763.361951112747, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 422496, "time": 19766.70641207695, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 422656, "time": 19773.63435983658, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 423032, "time": 19788.190163612366, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 423072, "time": 19791.402809858322, "episode/length": 77.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 423424, "time": 19805.078023195267, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719298245614035, "episode/intrinsic_return": 0.0}
{"step": 423536, "time": 19810.373952150345, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 423752, "time": 19818.880666971207, "episode/length": 267.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 424088, "time": 19831.73564863205, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 424216, "time": 19837.671195030212, "episode/length": 325.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 424456, "time": 19847.369329214096, "episode/length": 45.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 424472, "time": 19849.49641609192, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 425112, "time": 19872.55375933647, "episode/length": 326.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 425352, "time": 19882.190288066864, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 425416, "time": 19885.88707756996, "episode/length": 297.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 425584, "time": 19893.337480783463, "episode/length": 255.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 425760, "time": 19900.918928861618, "episode/length": 291.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 425768, "time": 19902.578847169876, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 426184, "time": 19919.52558708191, "episode/length": 245.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 426568, "time": 19933.955668449402, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 426616, "time": 19937.095715999603, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 426648, "time": 19939.71923160553, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 426920, "time": 19950.517704963684, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 427016, "time": 19955.199741840363, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 427040, "time": 19957.67317032814, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 427336, "time": 19968.87247776985, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 427512, "time": 19976.37860941887, "episode/length": 218.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 427992, "time": 19993.991373300552, "episode/length": 167.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 428360, "time": 20008.02975320816, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 428408, "time": 20011.275372982025, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 428424, "time": 20013.32113480568, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 428592, "time": 20020.90783762932, "episode/length": 252.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 428776, "time": 20028.375217437744, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 429288, "time": 20047.03080224991, "episode/length": 295.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 429632, "time": 20060.23152399063, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 429928, "time": 20071.587312221527, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 429992, "time": 20075.36487531662, "episode/length": 195.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 430024, "time": 20077.97306060791, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20099.177525758743, "eval_episode/length": 137.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 430040, "time": 20101.470973968506, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 430040, "time": 20103.58044195175, "eval_episode/length": 165.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9819277108433735}
{"step": 430040, "time": 20105.28453731537, "eval_episode/length": 167.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 430040, "time": 20107.092040538788, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 430040, "time": 20109.064319849014, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 430040, "time": 20111.287893533707, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 430040, "time": 20116.981173992157, "eval_episode/length": 120.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9586776859504132}
{"step": 430088, "time": 20118.580825805664, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 430296, "time": 20127.00705933571, "episode/length": 347.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.985632183908046, "episode/intrinsic_return": 0.0}
{"step": 430560, "time": 20137.708148241043, "episode/length": 158.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 431088, "time": 20156.90165066719, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 431392, "time": 20168.751402139664, "episode/length": 162.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 431464, "time": 20172.49542927742, "episode/length": 335.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 431576, "time": 20177.88215327263, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 431632, "time": 20181.537510871887, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 431704, "time": 20185.280734300613, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 432072, "time": 20199.196976184845, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 432248, "time": 20206.543375253677, "episode/length": 144.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 432456, "time": 20215.23806142807, "episode/length": 123.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 432576, "time": 20220.92746782303, "episode/length": 251.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 432992, "time": 20236.52039694786, "episode/length": 176.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 433024, "time": 20239.119696617126, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 433304, "time": 20249.825246095657, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 433440, "time": 20256.35334968567, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 433936, "time": 20274.412135124207, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 434104, "time": 20281.420236587524, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 434200, "time": 20287.797081708908, "episode/length": 146.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 434432, "time": 20297.212047100067, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 434592, "time": 20304.25715136528, "episode/length": 314.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 434592, "time": 20304.266582250595, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 434976, "time": 20320.3982026577, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 435088, "time": 20325.69374537468, "episode/length": 261.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 435376, "time": 20336.863691568375, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 435472, "time": 20341.684092760086, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9532163742690059, "episode/intrinsic_return": 0.0}
{"step": 435496, "time": 20343.78884100914, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 435528, "time": 20346.588866233826, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 435752, "time": 20355.597425460815, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 436056, "time": 20367.280210971832, "episode/length": 202.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 436057, "time": 20370.019517183304, "train_stats/sum_log_reward": 5.949557504822723, "train_stats/max_log_achievement_collect_coal": 0.061946902654867256, "train_stats/max_log_achievement_collect_drink": 5.716814159292035, "train_stats/max_log_achievement_collect_sapling": 2.5398230088495577, "train_stats/max_log_achievement_collect_stone": 0.7787610619469026, "train_stats/max_log_achievement_collect_wood": 6.6371681415929205, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.504424778761062, "train_stats/max_log_achievement_eat_cow": 0.07079646017699115, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.831858407079646, "train_stats/max_log_achievement_make_wood_sword": 0.008849557522123894, "train_stats/max_log_achievement_place_plant": 2.433628318584071, "train_stats/max_log_achievement_place_stone": 0.017699115044247787, "train_stats/max_log_achievement_place_table": 2.1238938053097347, "train_stats/max_log_achievement_wake_up": 1.8938053097345133, "train_stats/mean_log_entropy": 0.6192970096537497, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.525314552196558, "train/action_min": 0.0, "train/action_std": 3.417177148487257, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05215320323148499, "train/actor_opt_grad_steps": 26465.0, "train/actor_opt_loss": -0.42650588099723274, "train/adv_mag": 0.739964065776355, "train/adv_max": 0.7262052789978359, "train/adv_mean": 0.004813491219742307, "train/adv_min": -0.5040825696095176, "train/adv_std": 0.07851734641345515, "train/cont_avg": 0.9944944519927537, "train/cont_loss_mean": 0.00024276129076229302, "train/cont_loss_std": 0.006937057760710295, "train/cont_neg_acc": 0.9878680714662524, "train/cont_neg_loss": 0.026180555689767272, "train/cont_pos_acc": 0.9999643689480381, "train/cont_pos_loss": 8.170687684135821e-05, "train/cont_pred": 0.9945097068945566, "train/cont_rate": 0.9944944519927537, "train/dyn_loss_mean": 13.802316389222076, "train/dyn_loss_std": 9.079213612321494, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8167260388533274, "train/extr_critic_critic_opt_grad_steps": 26465.0, "train/extr_critic_critic_opt_loss": 15597.500927026722, "train/extr_critic_mag": 5.086736475211986, "train/extr_critic_max": 5.086736475211986, "train/extr_critic_mean": 1.0060388415619947, "train/extr_critic_min": -0.23271384619284366, "train/extr_critic_std": 1.0709198169086291, "train/extr_return_normed_mag": 1.9380348843076955, "train/extr_return_normed_max": 1.9380348843076955, "train/extr_return_normed_mean": 0.31379789038412814, "train/extr_return_normed_min": -0.16494722000282744, "train/extr_return_normed_std": 0.3378037669952365, "train/extr_return_rate": 0.5121320455834486, "train/extr_return_raw_mag": 6.350765888241754, "train/extr_return_raw_max": 6.350765888241754, "train/extr_return_raw_mean": 1.0218427263308263, "train/extr_return_raw_min": -0.5489877947214721, "train/extr_return_raw_std": 1.1083874896816586, "train/extr_reward_mag": 1.0157532847445945, "train/extr_reward_max": 1.0157532847445945, "train/extr_reward_mean": 0.027584551928052002, "train/extr_reward_min": -0.41575628778208856, "train/extr_reward_std": 0.15410861718481866, "train/image_loss_mean": 7.363138589306154, "train/image_loss_std": 11.549634663955025, "train/model_loss_mean": 15.69848534680795, "train/model_loss_std": 15.274637540181478, "train/model_opt_grad_norm": 59.73074221088938, "train/model_opt_grad_steps": 26439.27536231884, "train/model_opt_loss": 10774.488935829937, "train/model_opt_model_opt_grad_overflow": 0.007246376811594203, "train/model_opt_model_opt_grad_scale": 683.8768115942029, "train/policy_entropy_mag": 2.5091050811435864, "train/policy_entropy_max": 2.5091050811435864, "train/policy_entropy_mean": 0.6354295270166536, "train/policy_entropy_min": 0.07937510273810747, "train/policy_entropy_std": 0.6797841739827308, "train/policy_logprob_mag": 7.438383454861849, "train/policy_logprob_max": -0.00945566784914421, "train/policy_logprob_mean": -0.6366043272225753, "train/policy_logprob_min": -7.438383454861849, "train/policy_logprob_std": 1.1488195726836936, "train/policy_randomness_mag": 0.8856039829012277, "train/policy_randomness_max": 0.8856039829012277, "train/policy_randomness_mean": 0.22427873810132345, "train/policy_randomness_min": 0.028015928059492424, "train/policy_randomness_std": 0.23993398119574008, "train/post_ent_mag": 58.414851478908375, "train/post_ent_max": 58.414851478908375, "train/post_ent_mean": 40.876113421675086, "train/post_ent_min": 20.376825740371924, "train/post_ent_std": 7.320614856222401, "train/prior_ent_mag": 67.62633702374887, "train/prior_ent_max": 67.62633702374887, "train/prior_ent_mean": 54.76320982670438, "train/prior_ent_min": 37.721646350363024, "train/prior_ent_std": 4.716333301171012, "train/rep_loss_mean": 13.802316389222076, "train/rep_loss_std": 9.079213612321494, "train/reward_avg": 0.024189028180325808, "train/reward_loss_mean": 0.05371411239215429, "train/reward_loss_std": 0.24772135978159698, "train/reward_max_data": 1.0108695678088977, "train/reward_max_pred": 1.0068126770033352, "train/reward_neg_acc": 0.9927010385022648, "train/reward_neg_loss": 0.02974687530186729, "train/reward_pos_acc": 0.9676931016687034, "train/reward_pos_loss": 0.8553126648716305, "train/reward_pred": 0.023463325041845656, "train/reward_rate": 0.0290916553442029, "eval_stats/sum_log_reward": 5.099999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 7.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.024096385542168676, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.849604116927367e-06, "report/cont_loss_std": 0.00015717267524451017, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010646448936313391, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.365723377006361e-06, "report/cont_pred": 0.9951103925704956, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.079980850219727, "report/dyn_loss_std": 8.68220043182373, "report/image_loss_mean": 6.401611804962158, "report/image_loss_std": 10.164414405822754, "report/model_loss_mean": 14.89664077758789, "report/model_loss_std": 13.643174171447754, "report/post_ent_mag": 56.02880096435547, "report/post_ent_max": 56.02880096435547, "report/post_ent_mean": 40.90760040283203, "report/post_ent_min": 21.993179321289062, "report/post_ent_std": 7.498302459716797, "report/prior_ent_mag": 67.64214324951172, "report/prior_ent_max": 67.64214324951172, "report/prior_ent_mean": 54.84434127807617, "report/prior_ent_min": 38.92908477783203, "report/prior_ent_std": 4.439249515533447, "report/rep_loss_mean": 14.079980850219727, "report/rep_loss_std": 8.68220043182373, "report/reward_avg": 0.02285156026482582, "report/reward_loss_mean": 0.047031890600919724, "report/reward_loss_std": 0.17886784672737122, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0014910697937012, "report/reward_neg_acc": 0.9939698576927185, "report/reward_neg_loss": 0.027959782630205154, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.701402485370636, "report/reward_pred": 0.022721409797668457, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00011012486356776208, "eval/cont_loss_std": 0.003517467761412263, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0563504584133625, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.549899467245268e-08, "eval/cont_pred": 0.9981509447097778, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.784244537353516, "eval/dyn_loss_std": 10.396018028259277, "eval/image_loss_mean": 15.310922622680664, "eval/image_loss_std": 21.44158172607422, "eval/model_loss_mean": 26.07056427001953, "eval/model_loss_std": 25.550338745117188, "eval/post_ent_mag": 61.15003204345703, "eval/post_ent_max": 61.15003204345703, "eval/post_ent_mean": 41.28608703613281, "eval/post_ent_min": 20.44033432006836, "eval/post_ent_std": 7.949429035186768, "eval/prior_ent_mag": 67.64214324951172, "eval/prior_ent_max": 67.64214324951172, "eval/prior_ent_mean": 56.410667419433594, "eval/prior_ent_min": 41.96589660644531, "eval/prior_ent_std": 4.843267440795898, "eval/rep_loss_mean": 17.784244537353516, "eval/rep_loss_std": 10.396018028259277, "eval/reward_avg": 0.02822265587747097, "eval/reward_loss_mean": 0.08898307383060455, "eval/reward_loss_std": 0.5280425548553467, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010910034179688, "eval/reward_neg_acc": 0.9939515590667725, "eval/reward_neg_loss": 0.03120645135641098, "eval/reward_pos_acc": 0.71875, "eval/reward_pos_loss": 1.8800584077835083, "eval/reward_pred": 0.021138139069080353, "eval/reward_rate": 0.03125, "replay/size": 435553.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.3877422244242779e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.511889885784146e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86480.0, "eval_replay/inserts": 3928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.212365758394758e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.0032455921173, "timer/env.step_count": 2758.0, "timer/env.step_total": 255.1598882675171, "timer/env.step_frac": 0.2549041567957993, "timer/env.step_avg": 0.09251627565899823, "timer/env.step_min": 0.02284693717956543, "timer/env.step_max": 3.4508421421051025, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.550553560256958, "timer/replay._sample_frac": 0.011538977132311425, "timer/replay._sample_avg": 0.0005235022462045394, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.011433601379394531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3249.0, "timer/agent.policy_total": 52.87768030166626, "timer/agent.policy_frac": 0.0528246841701176, "timer/agent.policy_avg": 0.01627506318918629, "timer/agent.policy_min": 0.009237289428710938, "timer/agent.policy_max": 0.11816167831420898, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.15172243118286133, "timer/dataset_train_frac": 0.0001515703688783885, "timer/dataset_train_avg": 0.00011002351789910176, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0004279613494873047, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 622.7778112888336, "timer/agent.train_frac": 0.6221536383934956, "timer/agent.train_avg": 0.4516155266779069, "timer/agent.train_min": 0.4354672431945801, "timer/agent.train_max": 1.5693590641021729, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4648299217224121, "timer/agent.report_frac": 0.0004643640505355746, "timer/agent.report_avg": 0.23241496086120605, "timer/agent.report_min": 0.22183823585510254, "timer/agent.report_max": 0.24299168586730957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0725171810915215e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.04158308027547}
{"step": 436648, "time": 20389.561265707016, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 436720, "time": 20393.78127670288, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 436952, "time": 20402.797201633453, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 437008, "time": 20406.581780195236, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 437032, "time": 20408.72051715851, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 437144, "time": 20414.02438879013, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 437360, "time": 20422.964006900787, "episode/length": 26.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 437392, "time": 20425.65130329132, "episode/length": 232.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 437576, "time": 20433.130741357803, "episode/length": 189.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 437960, "time": 20447.897672891617, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 438160, "time": 20456.294739484787, "episode/length": 143.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 438824, "time": 20479.958554267883, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 439088, "time": 20490.657136678696, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 439096, "time": 20492.229892253876, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 439256, "time": 20499.30134510994, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 439320, "time": 20503.68545269966, "episode/length": 324.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 439408, "time": 20508.499347925186, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 439520, "time": 20513.852734565735, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20546.65119075775, "eval_episode/length": 40.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 440024, "time": 20550.919993638992, "eval_episode/length": 108.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9541284403669725}
{"step": 440024, "time": 20554.2899889946, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 440024, "time": 20557.093222618103, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 440024, "time": 20559.406411409378, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 440024, "time": 20561.461307287216, "eval_episode/length": 203.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 440024, "time": 20563.123698949814, "eval_episode/length": 208.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 440024, "time": 20564.98233628273, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 440168, "time": 20569.772115707397, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 440672, "time": 20588.16551709175, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 440808, "time": 20594.124242305756, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 440840, "time": 20596.710742473602, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 440848, "time": 20598.730061769485, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 440952, "time": 20603.60426735878, "episode/length": 231.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 441536, "time": 20624.927000761032, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 441632, "time": 20629.644107818604, "episode/length": 263.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 441848, "time": 20638.21240758896, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 442072, "time": 20647.331921100616, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 442344, "time": 20658.240013837814, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 442352, "time": 20660.281401395798, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 442824, "time": 20678.860676050186, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 443032, "time": 20687.367400169373, "episode/length": 174.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 443176, "time": 20693.63928604126, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 443240, "time": 20697.414541721344, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 443528, "time": 20708.588885307312, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 443840, "time": 20720.662997961044, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 443872, "time": 20723.277587413788, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 444392, "time": 20741.942643404007, "episode/length": 442.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954853273137697, "episode/intrinsic_return": 0.0}
{"step": 444584, "time": 20749.908037900925, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 444616, "time": 20752.546015501022, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 444632, "time": 20754.71303844452, "episode/length": 284.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 444752, "time": 20760.54132080078, "episode/length": 240.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 445456, "time": 20785.599158763885, "episode/length": 276.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 445472, "time": 20787.7132461071, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 445784, "time": 20799.542316913605, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 445864, "time": 20803.802275180817, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 446112, "time": 20813.947699069977, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 446128, "time": 20816.12113571167, "episode/length": 192.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 446352, "time": 20825.389433145523, "episode/length": 214.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 447120, "time": 20852.52543258667, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 447288, "time": 20859.525570631027, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 447504, "time": 20868.532752513885, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 447584, "time": 20872.849452018738, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 447800, "time": 20881.465185642242, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 447984, "time": 20889.40433573723, "episode/length": 420.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 448144, "time": 20896.441677331924, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 448608, "time": 20913.692188739777, "episode/length": 185.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 448696, "time": 20918.037558078766, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 448800, "time": 20923.313008785248, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 448912, "time": 20928.60957479477, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 449176, "time": 20939.110867023468, "episode/length": 352.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801699716713881, "episode/intrinsic_return": 0.0}
{"step": 449272, "time": 20943.885462284088, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 449288, "time": 20946.031059026718, "episode/length": 84.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 449464, "time": 20953.40608215332, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 449912, "time": 20969.985929250717, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 449960, "time": 20973.791987895966, "episode/length": 226.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 21000.838328123093, "eval_episode/length": 159.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 450008, "time": 21003.548248767853, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 450008, "time": 21007.386588811874, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 450008, "time": 21009.30992269516, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 450008, "time": 21011.336721420288, "eval_episode/length": 209.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 450008, "time": 21012.99647808075, "eval_episode/length": 214.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 450008, "time": 21014.94217801094, "eval_episode/length": 223.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 450008, "time": 21018.518564224243, "eval_episode/length": 50.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 450152, "time": 21023.248772621155, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 450224, "time": 21027.41805624962, "episode/length": 177.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 450696, "time": 21046.13051891327, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 450696, "time": 21046.165625572205, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 450904, "time": 21056.335935354233, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 451016, "time": 21061.54736304283, "episode/length": 215.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 451368, "time": 21075.02551651001, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 451456, "time": 21080.516315460205, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 451864, "time": 21096.12383365631, "episode/length": 50.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 451960, "time": 21100.908541679382, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 451992, "time": 21103.584195375443, "episode/length": 229.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 452392, "time": 21118.34912443161, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 452696, "time": 21130.13322210312, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 452736, "time": 21133.19487810135, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 452928, "time": 21141.056065797806, "episode/length": 194.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 453544, "time": 21163.042320013046, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 453832, "time": 21174.23522377014, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 454208, "time": 21188.5578083992, "episode/length": 183.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 454216, "time": 21190.161737203598, "episode/length": 439.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 454240, "time": 21192.707985401154, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 454280, "time": 21195.303136348724, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 454560, "time": 21206.55848956108, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781931464174455, "episode/intrinsic_return": 0.0}
{"step": 454896, "time": 21220.28843474388, "episode/length": 312.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9808306709265175, "episode/intrinsic_return": 0.0}
{"step": 455040, "time": 21227.250802993774, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 455104, "time": 21230.950998306274, "episode/length": 107.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 455352, "time": 21240.40931868553, "episode/length": 56.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 455456, "time": 21245.73144340515, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 455456, "time": 21245.739117383957, "episode/length": 146.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 455472, "time": 21249.908999204636, "episode/length": 204.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 455496, "time": 21252.007276773453, "episode/length": 48.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 455736, "time": 21261.540730953217, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 455888, "time": 21268.321311235428, "episode/length": 51.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 456264, "time": 21282.34348964691, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 456576, "time": 21294.535719156265, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 456864, "time": 21305.977537870407, "episode/length": 188.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 456960, "time": 21310.725093841553, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 457032, "time": 21314.78292822838, "episode/length": 161.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 457104, "time": 21319.0014629364, "episode/length": 205.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 457528, "time": 21334.35004377365, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 457976, "time": 21351.12049460411, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 458200, "time": 21360.099472522736, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 458256, "time": 21364.338049411774, "episode/length": 248.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 458345, "time": 21370.414693832397, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.465054757254464, "train/action_min": 0.0, "train/action_std": 3.299959051609039, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05057847247059856, "train/actor_opt_grad_steps": 27855.0, "train/actor_opt_loss": -0.5851345226567771, "train/adv_mag": 0.7203106641769409, "train/adv_max": 0.7088537301336016, "train/adv_mean": 0.004483461313793668, "train/adv_min": -0.48048253208398817, "train/adv_std": 0.07500470498842852, "train/cont_avg": 0.9947684151785714, "train/cont_loss_mean": 0.00021973029543035847, "train/cont_loss_std": 0.0065939737859139315, "train/cont_neg_acc": 0.9954081637518747, "train/cont_neg_loss": 0.013001227330408125, "train/cont_pos_acc": 0.9999508759805135, "train/cont_pos_loss": 0.00015680484844844095, "train/cont_pred": 0.9947372768606458, "train/cont_rate": 0.9947684151785714, "train/dyn_loss_mean": 13.808476747785296, "train/dyn_loss_std": 9.030345760072981, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8177409487111228, "train/extr_critic_critic_opt_grad_steps": 27855.0, "train/extr_critic_critic_opt_loss": 15586.505531529017, "train/extr_critic_mag": 5.236400951657976, "train/extr_critic_max": 5.236400951657976, "train/extr_critic_mean": 1.041758725472859, "train/extr_critic_min": -0.21494524478912352, "train/extr_critic_std": 1.07450654315097, "train/extr_return_normed_mag": 1.9048101408141, "train/extr_return_normed_max": 1.9048101408141, "train/extr_return_normed_mean": 0.3082235575786659, "train/extr_return_normed_min": -0.15826078818312714, "train/extr_return_normed_std": 0.328072573776756, "train/extr_return_rate": 0.551381167769432, "train/extr_return_raw_mag": 6.481756237574986, "train/extr_return_raw_max": 6.481756237574986, "train/extr_return_raw_mean": 1.0569141158035824, "train/extr_return_raw_min": -0.5274831825069018, "train/extr_return_raw_std": 1.114669042825699, "train/extr_reward_mag": 1.0152094466345651, "train/extr_reward_max": 1.0152094466345651, "train/extr_reward_mean": 0.02634490889364055, "train/extr_reward_min": -0.3957023773874555, "train/extr_reward_std": 0.14969873066459383, "train/image_loss_mean": 7.358889171055385, "train/image_loss_std": 11.421982254300799, "train/model_loss_mean": 15.696320329393659, "train/model_loss_std": 15.11443338394165, "train/model_opt_grad_norm": 62.114154472625515, "train/model_opt_grad_steps": 27828.60714285714, "train/model_opt_loss": 15751.231863839286, "train/model_opt_model_opt_grad_overflow": 0.007142857142857143, "train/model_opt_model_opt_grad_scale": 1000.0, "train/policy_entropy_mag": 2.5029928343636647, "train/policy_entropy_max": 2.5029928343636647, "train/policy_entropy_mean": 0.5920282219137464, "train/policy_entropy_min": 0.07937510801213128, "train/policy_entropy_std": 0.6399343052080699, "train/policy_logprob_mag": 7.438383436203003, "train/policy_logprob_max": -0.009455672771270787, "train/policy_logprob_mean": -0.5923243222492082, "train/policy_logprob_min": -7.438383436203003, "train/policy_logprob_std": 1.122376457282475, "train/policy_randomness_mag": 0.8834466261523111, "train/policy_randomness_max": 0.8834466261523111, "train/policy_randomness_mean": 0.20895997935107777, "train/policy_randomness_min": 0.028015929726617678, "train/policy_randomness_std": 0.22586872577667236, "train/post_ent_mag": 58.33801443917411, "train/post_ent_max": 58.33801443917411, "train/post_ent_mean": 41.026014818464006, "train/post_ent_min": 20.44806934084211, "train/post_ent_std": 7.320174380711147, "train/prior_ent_mag": 67.79534552437919, "train/prior_ent_max": 67.79534552437919, "train/prior_ent_mean": 54.87327093396868, "train/prior_ent_min": 38.11159657069615, "train/prior_ent_std": 4.700814540045602, "train/rep_loss_mean": 13.808476747785296, "train/rep_loss_std": 9.030345760072981, "train/reward_avg": 0.02278459797879415, "train/reward_loss_mean": 0.052125485161585466, "train/reward_loss_std": 0.24690569075090543, "train/reward_max_data": 1.014285717691694, "train/reward_max_pred": 1.0091524524348123, "train/reward_neg_acc": 0.9933908534901482, "train/reward_neg_loss": 0.02884388222758259, "train/reward_pos_acc": 0.9646498211792537, "train/reward_pos_loss": 0.8682941130229405, "train/reward_pred": 0.022038464048611265, "train/reward_rate": 0.027692522321428572, "train_stats/sum_log_reward": 6.1648148066467705, "train_stats/max_log_achievement_collect_coal": 0.23148148148148148, "train_stats/max_log_achievement_collect_drink": 5.037037037037037, "train_stats/max_log_achievement_collect_sapling": 2.6574074074074074, "train_stats/max_log_achievement_collect_stone": 1.3888888888888888, "train_stats/max_log_achievement_collect_wood": 8.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5648148148148148, "train_stats/max_log_achievement_eat_cow": 0.09259259259259259, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1481481481481481, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.6481481481481484, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.361111111111111, "train_stats/max_log_achievement_wake_up": 1.8333333333333333, "train_stats/mean_log_entropy": 0.563957695055891, "eval_stats/sum_log_reward": 5.725000001490116, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 6.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 3.285062575741904e-06, "report/cont_loss_std": 6.097632285673171e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000775547290686518, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7737863799993647e-06, "report/cont_pred": 0.9980467557907104, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 14.1290283203125, "report/dyn_loss_std": 9.335062980651855, "report/image_loss_mean": 7.607891082763672, "report/image_loss_std": 15.457941055297852, "report/model_loss_mean": 16.118858337402344, "report/model_loss_std": 19.263521194458008, "report/post_ent_mag": 55.810585021972656, "report/post_ent_max": 55.810585021972656, "report/post_ent_mean": 40.358985900878906, "report/post_ent_min": 20.988231658935547, "report/post_ent_std": 6.948898792266846, "report/prior_ent_mag": 67.86051940917969, "report/prior_ent_max": 67.86051940917969, "report/prior_ent_mean": 54.6429443359375, "report/prior_ent_min": 35.351036071777344, "report/prior_ent_std": 4.224030494689941, "report/rep_loss_mean": 14.1290283203125, "report/rep_loss_std": 9.335062980651855, "report/reward_avg": 0.01386718824505806, "report/reward_loss_mean": 0.033547382801771164, "report/reward_loss_std": 0.15997126698493958, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.021559476852417, "report/reward_neg_acc": 0.995029866695404, "report/reward_neg_loss": 0.02191690169274807, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.683562159538269, "report/reward_pred": 0.015356604941189289, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0002477362286299467, "eval/cont_loss_std": 0.006374708842486143, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.06314659863710403, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.0740187690316816e-06, "eval/cont_pred": 0.9963203072547913, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.517473220825195, "eval/dyn_loss_std": 10.191057205200195, "eval/image_loss_mean": 17.99802017211914, "eval/image_loss_std": 26.255786895751953, "eval/model_loss_mean": 29.83165740966797, "eval/model_loss_std": 29.735992431640625, "eval/post_ent_mag": 55.387115478515625, "eval/post_ent_max": 55.387115478515625, "eval/post_ent_mean": 38.61204528808594, "eval/post_ent_min": 18.269500732421875, "eval/post_ent_std": 6.629141807556152, "eval/prior_ent_mag": 67.86051940917969, "eval/prior_ent_max": 67.86051940917969, "eval/prior_ent_mean": 55.58448791503906, "eval/prior_ent_min": 41.600502014160156, "eval/prior_ent_std": 3.812652349472046, "eval/rep_loss_mean": 19.517473220825195, "eval/rep_loss_std": 10.191057205200195, "eval/reward_avg": 0.03085937350988388, "eval/reward_loss_mean": 0.1229066252708435, "eval/reward_loss_std": 0.786481499671936, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008420944213867, "eval/reward_neg_acc": 0.9959554076194763, "eval/reward_neg_loss": 0.028805827721953392, "eval/reward_pos_acc": 0.6571428775787354, "eval/reward_pos_loss": 2.781926155090332, "eval/reward_pred": 0.018279660493135452, "eval/reward_rate": 0.0341796875, "replay/size": 457841.0, "replay/inserts": 22288.0, "replay/samples": 22288.0, "replay/insert_wait_avg": 1.3684892688649898e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.616223155211307e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90392.0, "eval_replay/inserts": 3912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.231341761801628e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.381103515625, "timer/env.step_count": 2786.0, "timer/env.step_total": 251.69869804382324, "timer/env.step_frac": 0.25160281132788503, "timer/env.step_avg": 0.0903441127221189, "timer/env.step_min": 0.02248859405517578, "timer/env.step_max": 3.6355485916137695, "timer/replay._sample_count": 22288.0, "timer/replay._sample_total": 11.601041316986084, "timer/replay._sample_frac": 0.011596621803647341, "timer/replay._sample_avg": 0.0005205061610277317, "timer/replay._sample_min": 0.0004172325134277344, "timer/replay._sample_max": 0.01041412353515625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3275.0, "timer/agent.policy_total": 53.05953121185303, "timer/agent.policy_frac": 0.05303931774139543, "timer/agent.policy_avg": 0.016201383576138328, "timer/agent.policy_min": 0.009360790252685547, "timer/agent.policy_max": 0.11018919944763184, "timer/dataset_train_count": 1393.0, "timer/dataset_train_total": 0.1513385772705078, "timer/dataset_train_frac": 0.00015128092357868497, "timer/dataset_train_avg": 0.00010864219473834014, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.00041174888610839844, "timer/agent.train_count": 1393.0, "timer/agent.train_total": 624.1438567638397, "timer/agent.train_frac": 0.623906083961822, "timer/agent.train_avg": 0.4480573271815073, "timer/agent.train_min": 0.4346592426300049, "timer/agent.train_max": 1.62764310836792, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47569990158081055, "timer/agent.report_frac": 0.0004755186797402162, "timer/agent.report_avg": 0.23784995079040527, "timer/agent.report_min": 0.23053264617919922, "timer/agent.report_max": 0.24516725540161133, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193591870871477e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.27918405299836}
{"step": 458368, "time": 21371.129014015198, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 458472, "time": 21376.04586482048, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 458888, "time": 21392.97184085846, "episode/length": 288.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 459208, "time": 21405.275464773178, "episode/length": 280.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 459424, "time": 21414.55608177185, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 459440, "time": 21416.62134718895, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 459624, "time": 21424.224772691727, "episode/length": 261.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 459632, "time": 21426.373773097992, "episode/length": 25.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8461538461538461, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21458.99325323105, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 460096, "time": 21463.782265663147, "eval_episode/length": 136.0, "eval_episode/score": 4.1000000312924385, "eval_episode/reward_rate": 0.9562043795620438}
{"step": 460096, "time": 21466.676480054855, "eval_episode/length": 165.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 460096, "time": 21466.69225883484, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 460096, "time": 21470.69596338272, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 460096, "time": 21472.335908412933, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 460096, "time": 21474.168843269348, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 460096, "time": 21477.485068321228, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 460304, "time": 21484.43696165085, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 460344, "time": 21487.34108233452, "episode/length": 295.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 460640, "time": 21499.20931506157, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 460808, "time": 21506.977417469025, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 460928, "time": 21512.751870393753, "episode/length": 319.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 461088, "time": 21519.7505338192, "episode/length": 326.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938837920489296, "episode/intrinsic_return": 0.0}
{"step": 461376, "time": 21530.821004390717, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 461408, "time": 21533.39565396309, "episode/length": 132.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 461568, "time": 21540.293251276016, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 461768, "time": 21548.377576828003, "episode/length": 266.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 461800, "time": 21551.01715517044, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 462416, "time": 21573.09546136856, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 462560, "time": 21579.529022693634, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 462584, "time": 21581.601637363434, "episode/length": 242.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 463048, "time": 21599.612686395645, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 463136, "time": 21604.245471715927, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 463216, "time": 21608.878440380096, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 463296, "time": 21613.256113290787, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 463440, "time": 21619.5253534317, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 463912, "time": 21636.984813451767, "episode/length": 186.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 464424, "time": 21655.66538786888, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 464736, "time": 21668.012949228287, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 464760, "time": 21670.09822702408, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 464872, "time": 21675.40610575676, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 465040, "time": 21682.729744672775, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 465248, "time": 21691.288371801376, "episode/length": 253.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 465424, "time": 21698.816838264465, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 466016, "time": 21720.122284173965, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 466120, "time": 21725.256756067276, "episode/length": 108.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 466160, "time": 21728.315416574478, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 466344, "time": 21735.905843257904, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 466400, "time": 21739.66725420952, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 466568, "time": 21746.67338991165, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 467096, "time": 21767.563401460648, "episode/length": 208.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 467312, "time": 21776.742156267166, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 467352, "time": 21779.633582353592, "episode/length": 125.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 467384, "time": 21782.36165881157, "episode/length": 369.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9918918918918919, "episode/intrinsic_return": 0.0}
{"step": 467664, "time": 21793.493808984756, "episode/length": 192.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 467680, "time": 21795.596672296524, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 467696, "time": 21797.710651874542, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 467768, "time": 21801.39764714241, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 468136, "time": 21815.35692501068, "episode/length": 246.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 468816, "time": 21839.89444565773, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 468960, "time": 21846.47041606903, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 469016, "time": 21849.691039562225, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 469128, "time": 21855.044284820557, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 469280, "time": 21861.878332853317, "episode/length": 32.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 469352, "time": 21865.607335567474, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 469424, "time": 21869.826193094254, "episode/length": 206.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 470064, "time": 21893.273021697998, "episode/length": 297.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21915.79317831993, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 470080, "time": 21917.4449133873, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 470080, "time": 21919.79305958748, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 470080, "time": 21921.451310634613, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 470080, "time": 21923.595638036728, "eval_episode/length": 191.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 470080, "time": 21926.671568870544, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 470080, "time": 21930.88397026062, "eval_episode/length": 282.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9964664310954063}
{"step": 470080, "time": 21933.191428661346, "eval_episode/length": 301.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 470296, "time": 21940.286712169647, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 470448, "time": 21947.278653144836, "episode/length": 418.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9880668257756563, "episode/intrinsic_return": 0.0}
{"step": 470704, "time": 21957.4573905468, "episode/length": 159.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 470856, "time": 21963.821724176407, "episode/length": 50.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 470880, "time": 21966.558460474014, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 470968, "time": 21970.872950077057, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 471488, "time": 21990.026515960693, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 471544, "time": 21993.384697914124, "episode/length": 82.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 471776, "time": 22003.047835826874, "episode/length": 454.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736263736263736, "episode/intrinsic_return": 0.0}
{"step": 472032, "time": 22013.17889213562, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 472200, "time": 22020.270577907562, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 472288, "time": 22025.106194496155, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 472712, "time": 22040.61114668846, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 472912, "time": 22049.13872385025, "episode/length": 472.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9873150105708245, "episode/intrinsic_return": 0.0}
{"step": 472920, "time": 22050.79192996025, "episode/length": 178.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 473168, "time": 22061.073881149292, "episode/length": 274.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 473808, "time": 22084.03714990616, "episode/length": 221.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 473864, "time": 22087.50647687912, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 474064, "time": 22095.973970413208, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 474136, "time": 22099.760672807693, "episode/length": 294.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 474168, "time": 22102.383917570114, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 474296, "time": 22108.3408203125, "episode/length": 172.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 474576, "time": 22119.611087322235, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 475136, "time": 22141.2865524292, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 475256, "time": 22148.614178419113, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 475408, "time": 22155.45365834236, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 475544, "time": 22161.327842712402, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 475608, "time": 22165.001180171967, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 475640, "time": 22167.655485391617, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 476064, "time": 22183.50149011612, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 476376, "time": 22195.278091192245, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 476544, "time": 22202.6559009552, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 476712, "time": 22209.74044895172, "episode/length": 181.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 476920, "time": 22218.368402004242, "episode/length": 188.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 477016, "time": 22223.083830833435, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 477224, "time": 22231.810727119446, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 477344, "time": 22237.76696705818, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 477400, "time": 22241.03587245941, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 477808, "time": 22256.719707489014, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 477968, "time": 22263.62770318985, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 478304, "time": 22276.50115442276, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 478488, "time": 22284.07881450653, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 478616, "time": 22290.148772716522, "episode/length": 258.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 478720, "time": 22295.543167352676, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 479152, "time": 22311.500700473785, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9601769911504425, "episode/intrinsic_return": 0.0}
{"step": 479192, "time": 22314.12442946434, "episode/length": 110.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 479264, "time": 22318.268570661545, "episode/length": 232.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 479464, "time": 22326.211364746094, "episode/length": 121.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 479480, "time": 22328.435689926147, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 479480, "time": 22328.445179462433, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22370.99003481865, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 480064, "time": 22373.543088674545, "eval_episode/length": 185.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 480064, "time": 22375.440348625183, "eval_episode/length": 192.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 480064, "time": 22377.364564180374, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 480064, "time": 22380.114148139954, "eval_episode/length": 225.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.995575221238938}
{"step": 480064, "time": 22381.820359945297, "eval_episode/length": 228.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 480064, "time": 22383.559088230133, "eval_episode/length": 39.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.975}
{"step": 480064, "time": 22386.285935401917, "eval_episode/length": 253.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9724409448818898}
{"step": 480065, "time": 22386.86711359024, "train_stats/sum_log_reward": 6.211111106806332, "train_stats/max_log_achievement_collect_coal": 0.1111111111111111, "train_stats/max_log_achievement_collect_drink": 5.657407407407407, "train_stats/max_log_achievement_collect_sapling": 2.4814814814814814, "train_stats/max_log_achievement_collect_stone": 0.8703703703703703, "train_stats/max_log_achievement_collect_wood": 7.648148148148148, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5370370370370371, "train_stats/max_log_achievement_eat_cow": 0.05555555555555555, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1111111111111112, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.018518518518518517, "train_stats/max_log_achievement_place_plant": 2.3796296296296298, "train_stats/max_log_achievement_place_stone": 0.009259259259259259, "train_stats/max_log_achievement_place_table": 2.462962962962963, "train_stats/max_log_achievement_wake_up": 1.5925925925925926, "train_stats/mean_log_entropy": 0.5721731506012104, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.520828812210648, "train/action_min": 0.0, "train/action_std": 3.4658990542093915, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05090729677014881, "train/actor_opt_grad_steps": 29230.0, "train/actor_opt_loss": -2.4096648262054834, "train/adv_mag": 0.735525463687049, "train/adv_max": 0.7251051765901071, "train/adv_mean": 0.0034742045010506006, "train/adv_min": -0.5158610072400834, "train/adv_std": 0.07514380382166969, "train/cont_avg": 0.9947410300925926, "train/cont_loss_mean": 0.00012304002367752927, "train/cont_loss_std": 0.003439464508188326, "train/cont_neg_acc": 0.9974603180532102, "train/cont_neg_loss": 0.011360396700749537, "train/cont_pos_acc": 0.9999708559778001, "train/cont_pos_loss": 6.164730134735741e-05, "train/cont_pred": 0.9947379911387408, "train/cont_rate": 0.9947410300925926, "train/dyn_loss_mean": 13.646596456457067, "train/dyn_loss_std": 9.081996875339085, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7953036970562405, "train/extr_critic_critic_opt_grad_steps": 29230.0, "train/extr_critic_critic_opt_loss": 15710.424074074073, "train/extr_critic_mag": 5.371452151404487, "train/extr_critic_max": 5.371452151404487, "train/extr_critic_mean": 1.0746302127838134, "train/extr_critic_min": -0.22420768914399325, "train/extr_critic_std": 1.136647137006124, "train/extr_return_normed_mag": 1.8886647153783727, "train/extr_return_normed_max": 1.8886647153783727, "train/extr_return_normed_mean": 0.3039298208775344, "train/extr_return_normed_min": -0.1631669534025369, "train/extr_return_normed_std": 0.33434029784467484, "train/extr_return_rate": 0.5344888400148462, "train/extr_return_raw_mag": 6.642174286312527, "train/extr_return_raw_max": 6.642174286312527, "train/extr_return_raw_mean": 1.0868139324364838, "train/extr_return_raw_min": -0.5508361558119456, "train/extr_return_raw_std": 1.1721770758982057, "train/extr_reward_mag": 1.0145317731080232, "train/extr_reward_max": 1.0145317731080232, "train/extr_reward_mean": 0.027441357979895893, "train/extr_reward_min": -0.4250919854199445, "train/extr_reward_std": 0.15374100622203615, "train/image_loss_mean": 7.2208210132740165, "train/image_loss_std": 11.824701182047527, "train/model_loss_mean": 15.46155224552861, "train/model_loss_std": 15.522332297431099, "train/model_opt_grad_norm": 61.92136777242025, "train/model_opt_grad_steps": 29202.437037037038, "train/model_opt_loss": 10671.47144458912, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 685.1851851851852, "train/policy_entropy_mag": 2.522512359972353, "train/policy_entropy_max": 2.522512359972353, "train/policy_entropy_mean": 0.6203535393432335, "train/policy_entropy_min": 0.07937510272970906, "train/policy_entropy_std": 0.6758918356012416, "train/policy_logprob_mag": 7.438383476822464, "train/policy_logprob_max": -0.009455669829966845, "train/policy_logprob_mean": -0.6192054894235399, "train/policy_logprob_min": -7.438383476822464, "train/policy_logprob_std": 1.1352842410405477, "train/policy_randomness_mag": 0.8903361647217362, "train/policy_randomness_max": 0.8903361647217362, "train/policy_randomness_mean": 0.2189575763764205, "train/policy_randomness_min": 0.02801592795661202, "train/policy_randomness_std": 0.23856015768316058, "train/post_ent_mag": 58.97117959481699, "train/post_ent_max": 58.97117959481699, "train/post_ent_mean": 41.29019337406865, "train/post_ent_min": 20.555167120474355, "train/post_ent_std": 7.44612125467371, "train/prior_ent_mag": 67.80643282289859, "train/prior_ent_max": 67.80643282289859, "train/prior_ent_mean": 55.00212241278754, "train/prior_ent_min": 38.993914173267505, "train/prior_ent_std": 4.62318819363912, "train/rep_loss_mean": 13.646596456457067, "train/rep_loss_std": 9.081996875339085, "train/reward_avg": 0.02475911443018251, "train/reward_loss_mean": 0.05265030325562866, "train/reward_loss_std": 0.24147108815334462, "train/reward_max_data": 1.016296300181636, "train/reward_max_pred": 1.0082662449942694, "train/reward_neg_acc": 0.9929235758604826, "train/reward_neg_loss": 0.028341634219719303, "train/reward_pos_acc": 0.9652237980454056, "train/reward_pos_loss": 0.8509915356282834, "train/reward_pred": 0.02403708174134846, "train/reward_rate": 0.02955005787037037, "eval_stats/sum_log_reward": 5.933333337306976, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 5.333333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.5416666666666665, "eval_stats/max_log_achievement_collect_stone": 0.9583333333333334, "eval_stats/max_log_achievement_collect_wood": 7.291666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5416666666666666, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8333333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.5706673366366886e-06, "report/cont_loss_std": 1.737217462505214e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.511391256935894e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3839585335517768e-06, "report/cont_pred": 0.9970691204071045, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.913885116577148, "report/dyn_loss_std": 9.083303451538086, "report/image_loss_mean": 5.712604999542236, "report/image_loss_std": 9.14665699005127, "report/model_loss_mean": 13.50186824798584, "report/model_loss_std": 12.982773780822754, "report/post_ent_mag": 58.812400817871094, "report/post_ent_max": 58.812400817871094, "report/post_ent_mean": 42.001705169677734, "report/post_ent_min": 21.61627960205078, "report/post_ent_std": 7.474369525909424, "report/prior_ent_mag": 67.72879791259766, "report/prior_ent_max": 67.72879791259766, "report/prior_ent_mean": 54.98461151123047, "report/prior_ent_min": 38.829627990722656, "report/prior_ent_std": 4.37440299987793, "report/rep_loss_mean": 12.913885116577148, "report/rep_loss_std": 9.083303451538086, "report/reward_avg": 0.01806640625, "report/reward_loss_mean": 0.04093041270971298, "report/reward_loss_std": 0.23223626613616943, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0030970573425293, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.022552968934178352, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.9186721444129944, "report/reward_pred": 0.015812743455171585, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.896550424542511e-06, "eval/cont_loss_std": 8.102815627353266e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005589014035649598, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1732684015441919e-06, "eval/cont_pred": 0.9951187372207642, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.641328811645508, "eval/dyn_loss_std": 10.280473709106445, "eval/image_loss_mean": 14.316198348999023, "eval/image_loss_std": 20.366304397583008, "eval/model_loss_mean": 23.79644203186035, "eval/model_loss_std": 24.27692985534668, "eval/post_ent_mag": 61.61394119262695, "eval/post_ent_max": 61.61394119262695, "eval/post_ent_mean": 41.898250579833984, "eval/post_ent_min": 20.919870376586914, "eval/post_ent_std": 7.807703971862793, "eval/prior_ent_mag": 67.72879791259766, "eval/prior_ent_max": 67.72879791259766, "eval/prior_ent_mean": 55.540130615234375, "eval/prior_ent_min": 39.49247360229492, "eval/prior_ent_std": 4.757874488830566, "eval/rep_loss_mean": 15.641328811645508, "eval/rep_loss_std": 10.280473709106445, "eval/reward_avg": 0.02128906361758709, "eval/reward_loss_mean": 0.09544184803962708, "eval/reward_loss_std": 0.6249027252197266, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0025653839111328, "eval/reward_neg_acc": 0.9909729361534119, "eval/reward_neg_loss": 0.06209219619631767, "eval/reward_pos_acc": 0.9259259104728699, "eval/reward_pos_loss": 1.326908826828003, "eval/reward_pred": 0.022547466680407524, "eval/reward_rate": 0.0263671875, "replay/size": 479561.0, "replay/inserts": 21720.0, "replay/samples": 21712.0, "replay/insert_wait_avg": 1.426065824308448e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.306692075623953e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96696.0, "eval_replay/inserts": 6304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2192856236762806e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1016.4404621124268, "timer/env.step_count": 2715.0, "timer/env.step_total": 248.69532775878906, "timer/env.step_frac": 0.24467279395975217, "timer/env.step_avg": 0.0916004890455945, "timer/env.step_min": 0.02322244644165039, "timer/env.step_max": 3.541008472442627, "timer/replay._sample_count": 21712.0, "timer/replay._sample_total": 11.417029619216919, "timer/replay._sample_frac": 0.01123236435854725, "timer/replay._sample_avg": 0.0005258396103176547, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.008474588394165039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3503.0, "timer/agent.policy_total": 57.21726059913635, "timer/agent.policy_frac": 0.05629179743614698, "timer/agent.policy_avg": 0.016333788352593876, "timer/agent.policy_min": 0.009424924850463867, "timer/agent.policy_max": 0.09780287742614746, "timer/dataset_train_count": 1357.0, "timer/dataset_train_total": 0.15157747268676758, "timer/dataset_train_frac": 0.00014912577601618722, "timer/dataset_train_avg": 0.00011170042202414708, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.00028324127197265625, "timer/agent.train_count": 1357.0, "timer/agent.train_total": 610.9327774047852, "timer/agent.train_frac": 0.6010512176336511, "timer/agent.train_avg": 0.4502083842334452, "timer/agent.train_min": 0.4356803894042969, "timer/agent.train_max": 1.5723843574523926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47756075859069824, "timer/agent.report_frac": 0.00046983643055511896, "timer/agent.report_avg": 0.23878037929534912, "timer/agent.report_min": 0.2338731288909912, "timer/agent.report_max": 0.24368762969970703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9320283379666294e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 21.368417187440233}
{"step": 480120, "time": 22388.758961200714, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 480152, "time": 22391.445739507675, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 480760, "time": 22413.129079818726, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 480848, "time": 22418.56342434883, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 480856, "time": 22420.216950654984, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 481328, "time": 22437.647231578827, "episode/length": 230.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 481392, "time": 22441.408262968063, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 481528, "time": 22447.543229818344, "episode/length": 282.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 481616, "time": 22452.226471185684, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 481640, "time": 22454.305376529694, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 482384, "time": 22480.76285481453, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 482768, "time": 22495.06766319275, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 482776, "time": 22496.673680067062, "episode/length": 251.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 483016, "time": 22506.31366610527, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 483288, "time": 22517.12358736992, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 483480, "time": 22526.68537569046, "episode/length": 327.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 483536, "time": 22530.303347826004, "episode/length": 143.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 483640, "time": 22535.448728322983, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 483832, "time": 22543.295179605484, "episode/length": 287.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 484120, "time": 22554.667392015457, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 484400, "time": 22565.95228266716, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 484600, "time": 22574.130832910538, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 484736, "time": 22580.350470542908, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 484768, "time": 22583.124086141586, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 484784, "time": 22585.159673929214, "episode/length": 118.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 484816, "time": 22587.669282913208, "episode/length": 255.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 485072, "time": 22597.817509412766, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 485120, "time": 22600.946557998657, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 485136, "time": 22602.9988155365, "episode/length": 49.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 485432, "time": 22614.301612615585, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 485536, "time": 22619.417392730713, "episode/length": 49.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 486040, "time": 22637.76531124115, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 486424, "time": 22652.017391204834, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 486528, "time": 22657.411937475204, "episode/length": 213.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 486552, "time": 22659.60491991043, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 486632, "time": 22663.843643665314, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 486648, "time": 22665.816606283188, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 486800, "time": 22672.648243427277, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 487000, "time": 22680.65203666687, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 487264, "time": 22691.43488430977, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 487632, "time": 22705.327396392822, "episode/length": 150.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 488096, "time": 22722.33357644081, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 488136, "time": 22725.490108966827, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 488344, "time": 22734.506631612778, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 488376, "time": 22737.261704206467, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 489088, "time": 22763.035868883133, "episode/length": 285.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 489392, "time": 22774.617980480194, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 489392, "time": 22774.634876966476, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 489576, "time": 22784.05921959877, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 489624, "time": 22787.745121002197, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 489760, "time": 22794.803411006927, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 490008, "time": 22804.319343090057, "episode/length": 419.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22829.78014397621, "eval_episode/length": 174.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 490048, "time": 22831.602283477783, "eval_episode/length": 180.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 490048, "time": 22834.125293016434, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 490048, "time": 22836.705559253693, "eval_episode/length": 200.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 490048, "time": 22839.132180452347, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.961352657004831}
{"step": 490048, "time": 22841.46462893486, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9669811320754716}
{"step": 490048, "time": 22843.827160835266, "eval_episode/length": 218.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 490048, "time": 22846.339814424515, "eval_episode/length": 229.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739130434782609}
{"step": 490256, "time": 22853.326835393906, "episode/length": 327.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 490584, "time": 22865.583820343018, "episode/length": 119.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 490752, "time": 22873.06747198105, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 490784, "time": 22875.717764616013, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 490848, "time": 22879.416410446167, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 490968, "time": 22884.602874994278, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 491256, "time": 22895.933966636658, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 491624, "time": 22911.213581323624, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 491832, "time": 22919.588130950928, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 492048, "time": 22928.563186883926, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 492112, "time": 22932.300185203552, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 492120, "time": 22933.802443265915, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 492304, "time": 22941.73855996132, "episode/length": 255.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 492304, "time": 22941.748155593872, "episode/length": 214.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.986046511627907, "episode/intrinsic_return": 0.0}
{"step": 492832, "time": 22962.74944639206, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 493200, "time": 22976.66660785675, "episode/length": 196.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 493312, "time": 22982.033467292786, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 493632, "time": 22994.435373306274, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 493648, "time": 22996.555995464325, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 493760, "time": 23001.84685111046, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 493920, "time": 23008.747408866882, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 493944, "time": 23010.7965631485, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 493976, "time": 23013.47016978264, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 494592, "time": 23035.83514070511, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 494680, "time": 23040.351343154907, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 494912, "time": 23049.89949798584, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 495072, "time": 23056.774524450302, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 495360, "time": 23068.334025859833, "episode/length": 176.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 495656, "time": 23080.47752928734, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 495664, "time": 23082.950469732285, "episode/length": 217.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 495928, "time": 23093.562197208405, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 496376, "time": 23110.238252162933, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 496536, "time": 23117.71325492859, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 496544, "time": 23119.732063531876, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 497032, "time": 23137.236023426056, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 497248, "time": 23146.223046779633, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 497336, "time": 23151.840245246887, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 497712, "time": 23166.246024131775, "episode/length": 329.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 497936, "time": 23175.212607383728, "episode/length": 174.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 497992, "time": 23178.33213853836, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 498336, "time": 23191.488307476044, "episode/length": 371.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 498480, "time": 23198.009562969208, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 498712, "time": 23207.114917993546, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 498832, "time": 23212.90580511093, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 499024, "time": 23220.941958665848, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 499120, "time": 23225.758378744125, "episode/length": 342.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 499256, "time": 23231.691341638565, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 499896, "time": 23255.9784784317, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 499904, "time": 23258.129279136658, "episode/length": 195.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23282.45900774002, "eval_episode/length": 131.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 500032, "time": 23285.618318796158, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 500032, "time": 23287.729816913605, "eval_episode/length": 174.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 500032, "time": 23290.13791370392, "eval_episode/length": 194.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 500032, "time": 23293.552326202393, "eval_episode/length": 235.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 500032, "time": 23296.178047418594, "eval_episode/length": 262.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 500032, "time": 23298.819903850555, "eval_episode/length": 288.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9965397923875432}
{"step": 500032, "time": 23301.40399456024, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 500192, "time": 23306.709362983704, "episode/length": 169.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 500408, "time": 23315.474100351334, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 500424, "time": 23317.740612745285, "episode/length": 303.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 500448, "time": 23320.429265022278, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 500496, "time": 23323.51297712326, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 500640, "time": 23329.774176836014, "episode/length": 240.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 501312, "time": 23353.850635528564, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 501592, "time": 23364.511694908142, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 501728, "time": 23371.09928393364, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 501784, "time": 23374.30628299713, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 501912, "time": 23380.16029071808, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 502041, "time": 23387.133254289627, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.423936484516531, "train/action_min": 0.0, "train/action_std": 3.3871407405189844, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.052177493716927544, "train/actor_opt_grad_steps": 30595.0, "train/actor_opt_loss": 0.19583851217791653, "train/adv_mag": 0.7418301597885464, "train/adv_max": 0.7190257211526235, "train/adv_mean": 0.0046643824602722525, "train/adv_min": -0.5202682925307233, "train/adv_std": 0.07641667160003082, "train/cont_avg": 0.9946572124094203, "train/cont_loss_mean": 0.00016882695295599706, "train/cont_loss_std": 0.004920829528500229, "train/cont_neg_acc": 0.9940794815112205, "train/cont_neg_loss": 0.01423418274864998, "train/cont_pos_acc": 0.9999643637650255, "train/cont_pos_loss": 8.851775576547004e-05, "train/cont_pred": 0.9946397318356279, "train/cont_rate": 0.9946572124094203, "train/dyn_loss_mean": 13.543198592420937, "train/dyn_loss_std": 8.98474255161009, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8294176295183707, "train/extr_critic_critic_opt_grad_steps": 30595.0, "train/extr_critic_critic_opt_loss": 15699.17287279212, "train/extr_critic_mag": 5.360928445622541, "train/extr_critic_max": 5.360928445622541, "train/extr_critic_mean": 1.1152770631555198, "train/extr_critic_min": -0.21745321888854538, "train/extr_critic_std": 1.1100836318472158, "train/extr_return_normed_mag": 1.8783990213836448, "train/extr_return_normed_max": 1.8783990213836448, "train/extr_return_normed_mean": 0.31397249247284903, "train/extr_return_normed_min": -0.17097061235403668, "train/extr_return_normed_std": 0.3318493627551673, "train/extr_return_rate": 0.5913520291231681, "train/extr_return_raw_mag": 6.546924235164255, "train/extr_return_raw_max": 6.546924235164255, "train/extr_return_raw_mean": 1.1314253858897998, "train/extr_return_raw_min": -0.5474662680340849, "train/extr_return_raw_std": 1.1489163300265437, "train/extr_reward_mag": 1.0173071000887, "train/extr_reward_max": 1.0173071000887, "train/extr_reward_mean": 0.02813176601531281, "train/extr_reward_min": -0.39833889750466833, "train/extr_reward_std": 0.15574548971177876, "train/image_loss_mean": 6.807629111884297, "train/image_loss_std": 11.190171411071999, "train/model_loss_mean": 14.986434798309768, "train/model_loss_std": 14.888774885647539, "train/model_opt_grad_norm": 57.228343521339305, "train/model_opt_grad_steps": 30566.86231884058, "train/model_opt_loss": 15816.447431923687, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1055.2536231884058, "train/policy_entropy_mag": 2.549872146136519, "train/policy_entropy_max": 2.549872146136519, "train/policy_entropy_mean": 0.6095406145289324, "train/policy_entropy_min": 0.07937509010451427, "train/policy_entropy_std": 0.6689803297968878, "train/policy_logprob_mag": 7.438383503236633, "train/policy_logprob_max": -0.009455669563317644, "train/policy_logprob_mean": -0.6102030324763146, "train/policy_logprob_min": -7.438383503236633, "train/policy_logprob_std": 1.1356938282648723, "train/policy_randomness_mag": 0.8999929713166278, "train/policy_randomness_max": 0.8999929713166278, "train/policy_randomness_mean": 0.21514108636672946, "train/policy_randomness_min": 0.02801592349736155, "train/policy_randomness_std": 0.23612070148405823, "train/post_ent_mag": 58.939843191616774, "train/post_ent_max": 58.939843191616774, "train/post_ent_mean": 41.39034555960393, "train/post_ent_min": 20.41150092387545, "train/post_ent_std": 7.410685414853304, "train/prior_ent_mag": 67.91180674235027, "train/prior_ent_max": 67.91180674235027, "train/prior_ent_mean": 55.01715463831805, "train/prior_ent_min": 39.55903072633605, "train/prior_ent_std": 4.547428735788317, "train/rep_loss_mean": 13.543198592420937, "train/rep_loss_std": 8.98474255161009, "train/reward_avg": 0.023758067256784525, "train/reward_loss_mean": 0.05271785461978204, "train/reward_loss_std": 0.24548163448554883, "train/reward_max_data": 1.013043481370677, "train/reward_max_pred": 1.007578842881797, "train/reward_neg_acc": 0.9933282214662303, "train/reward_neg_loss": 0.029418206874929045, "train/reward_pos_acc": 0.9657302900500919, "train/reward_pos_loss": 0.8501922859661821, "train/reward_pred": 0.023173374764999186, "train/reward_rate": 0.028596297554347828, "train_stats/sum_log_reward": 6.091071421546595, "train_stats/max_log_achievement_collect_coal": 0.0625, "train_stats/max_log_achievement_collect_drink": 4.678571428571429, "train_stats/max_log_achievement_collect_sapling": 2.3214285714285716, "train_stats/max_log_achievement_collect_stone": 1.0, "train_stats/max_log_achievement_collect_wood": 7.410714285714286, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6875, "train_stats/max_log_achievement_eat_cow": 0.05357142857142857, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0, "train_stats/max_log_achievement_make_wood_sword": 0.008928571428571428, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.267857142857143, "train_stats/max_log_achievement_place_stone": 0.017857142857142856, "train_stats/max_log_achievement_place_table": 2.3660714285714284, "train_stats/max_log_achievement_wake_up": 1.6428571428571428, "train_stats/mean_log_entropy": 0.5639551594587309, "train_stats/max_log_achievement_make_stone_sword": 0.010309278350515464, "eval_stats/sum_log_reward": 6.412500023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.9375, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.4765980672091246e-06, "report/cont_loss_std": 6.109228706918657e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006141769699752331, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.800309056918195e-07, "report/cont_pred": 0.9951197504997253, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.12932300567627, "report/dyn_loss_std": 8.988795280456543, "report/image_loss_mean": 5.564578533172607, "report/image_loss_std": 11.8751802444458, "report/model_loss_mean": 13.499732971191406, "report/model_loss_std": 15.587547302246094, "report/post_ent_mag": 57.76799774169922, "report/post_ent_max": 57.76799774169922, "report/post_ent_mean": 41.20042419433594, "report/post_ent_min": 18.726634979248047, "report/post_ent_std": 7.090638637542725, "report/prior_ent_mag": 67.81301879882812, "report/prior_ent_max": 67.81301879882812, "report/prior_ent_mean": 54.64313507080078, "report/prior_ent_min": 38.084747314453125, "report/prior_ent_std": 4.388390064239502, "report/rep_loss_mean": 13.12932300567627, "report/rep_loss_std": 8.988795280456543, "report/reward_avg": 0.03847656399011612, "report/reward_loss_mean": 0.057558029890060425, "report/reward_loss_std": 0.25342366099357605, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034847259521484, "report/reward_neg_acc": 0.9887869358062744, "report/reward_neg_loss": 0.023150991648435593, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.8425186276435852, "report/reward_pred": 0.03762422874569893, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.865759486463503e-06, "eval/cont_loss_std": 2.554941238486208e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00028094497974961996, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0457421240062104e-06, "eval/cont_pred": 0.9970701932907104, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.02245330810547, "eval/dyn_loss_std": 10.62091064453125, "eval/image_loss_mean": 11.342424392700195, "eval/image_loss_std": 15.867058753967285, "eval/model_loss_mean": 22.24222755432129, "eval/model_loss_std": 19.90960693359375, "eval/post_ent_mag": 53.715171813964844, "eval/post_ent_max": 53.715171813964844, "eval/post_ent_mean": 38.81084442138672, "eval/post_ent_min": 19.42878532409668, "eval/post_ent_std": 7.3656744956970215, "eval/prior_ent_mag": 67.81301879882812, "eval/prior_ent_max": 67.81301879882812, "eval/prior_ent_mean": 54.73036193847656, "eval/prior_ent_min": 44.489112854003906, "eval/prior_ent_std": 3.654724597930908, "eval/rep_loss_mean": 18.02245330810547, "eval/rep_loss_std": 10.62091064453125, "eval/reward_avg": 0.0458984375, "eval/reward_loss_mean": 0.08632916212081909, "eval/reward_loss_std": 0.5010841488838196, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016274452209473, "eval/reward_neg_acc": 0.989733099937439, "eval/reward_neg_loss": 0.029633741825819016, "eval/reward_pos_acc": 0.9199999570846558, "eval/reward_pos_loss": 1.19075608253479, "eval/reward_pred": 0.04134911298751831, "eval/reward_rate": 0.048828125, "replay/size": 501537.0, "replay/inserts": 21976.0, "replay/samples": 21984.0, "replay/insert_wait_avg": 1.39683604370606e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.47015427779596e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4352.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2978253995670992e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2511966228485, "timer/env.step_count": 2747.0, "timer/env.step_total": 256.3864448070526, "timer/env.step_frac": 0.25632205757182897, "timer/env.step_avg": 0.0933332525690035, "timer/env.step_min": 0.02306818962097168, "timer/env.step_max": 3.4504048824310303, "timer/replay._sample_count": 21984.0, "timer/replay._sample_total": 11.427470922470093, "timer/replay._sample_frac": 0.011424601101256066, "timer/replay._sample_avg": 0.0005198085390497677, "timer/replay._sample_min": 0.0004134178161621094, "timer/replay._sample_max": 0.008998870849609375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3291.0, "timer/agent.policy_total": 55.18751358985901, "timer/agent.policy_frac": 0.05517365415426525, "timer/agent.policy_avg": 0.016769223211746887, "timer/agent.policy_min": 0.009426593780517578, "timer/agent.policy_max": 0.12984228134155273, "timer/dataset_train_count": 1374.0, "timer/dataset_train_total": 0.154541015625, "timer/dataset_train_frac": 0.0001545022051928329, "timer/dataset_train_avg": 0.00011247526610262009, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0010786056518554688, "timer/agent.train_count": 1374.0, "timer/agent.train_total": 617.48024725914, "timer/agent.train_frac": 0.617325177259413, "timer/agent.train_avg": 0.4494033822846725, "timer/agent.train_min": 0.4340953826904297, "timer/agent.train_max": 1.832686185836792, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795835018157959, "timer/agent.report_frac": 0.0004794630623137621, "timer/agent.report_avg": 0.23979175090789795, "timer/agent.report_min": 0.2327873706817627, "timer/agent.report_max": 0.2467961311340332, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.907976191240499e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.97016884628223}
{"step": 502072, "time": 23387.88191318512, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 502184, "time": 23393.371339321136, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 502432, "time": 23403.529695034027, "episode/length": 104.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 502536, "time": 23408.856317043304, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 502560, "time": 23411.714870929718, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 503184, "time": 23434.50919651985, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 503272, "time": 23439.403824090958, "episode/length": 169.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 503560, "time": 23450.630561113358, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 503864, "time": 23462.617819547653, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 503888, "time": 23465.41799402237, "episode/length": 165.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 504024, "time": 23471.406329631805, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 504088, "time": 23475.181334733963, "episode/length": 287.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 504648, "time": 23495.421935796738, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 504704, "time": 23499.066645383835, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 504904, "time": 23507.17273736, "episode/length": 353.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 505104, "time": 23515.650595903397, "episode/length": 151.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 505240, "time": 23521.542420625687, "episode/length": 151.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 505408, "time": 23528.9660923481, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 505488, "time": 23533.41898202896, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 505696, "time": 23542.0174369812, "episode/length": 266.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 505872, "time": 23549.890630960464, "episode/length": 152.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 506120, "time": 23559.467606306076, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 506568, "time": 23575.906851768494, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 506704, "time": 23582.17985200882, "episode/length": 224.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 506720, "time": 23584.31031394005, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 506760, "time": 23587.350597143173, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 506864, "time": 23592.697922945023, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 507240, "time": 23606.367586135864, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9585492227979274, "episode/intrinsic_return": 0.0}
{"step": 507304, "time": 23610.04193997383, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 507720, "time": 23626.023641109467, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 508480, "time": 23654.701240301132, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 508808, "time": 23667.048843622208, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 508880, "time": 23671.196341514587, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 508920, "time": 23673.978167772293, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 509048, "time": 23680.003848075867, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 509400, "time": 23693.310391426086, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 509488, "time": 23697.97726368904, "episode/length": 345.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 509720, "time": 23707.251475811005, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 509792, "time": 23711.38334274292, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 23735.733342170715, "eval_episode/length": 49.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9}
{"step": 510016, "time": 23739.541499853134, "eval_episode/length": 47.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 510016, "time": 23743.46426844597, "eval_episode/length": 145.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.958904109589041}
{"step": 510016, "time": 23745.40292429924, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 510016, "time": 23747.989295721054, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 510016, "time": 23749.683420419693, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 510016, "time": 23752.08158802986, "eval_episode/length": 198.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 510016, "time": 23755.268768787384, "eval_episode/length": 235.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 510216, "time": 23761.73153948784, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 510312, "time": 23766.558752775192, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 510328, "time": 23768.624839305878, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 510664, "time": 23781.34608387947, "episode/length": 108.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 510840, "time": 23788.878360271454, "episode/length": 168.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 510872, "time": 23791.5570833683, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 511056, "time": 23799.543896198273, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 511584, "time": 23818.561656951904, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 511800, "time": 23827.102383375168, "episode/length": 299.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 511944, "time": 23833.50597190857, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 512160, "time": 23842.514889478683, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 512320, "time": 23849.48854136467, "episode/length": 46.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 512328, "time": 23851.110912799835, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 512864, "time": 23870.934288740158, "episode/length": 316.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 512944, "time": 23875.283183574677, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 513560, "time": 23897.343376636505, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 513576, "time": 23899.40042567253, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 513640, "time": 23903.211550951004, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 513840, "time": 23912.15930724144, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 513848, "time": 23913.72708749771, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 514008, "time": 23920.687574625015, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 514720, "time": 23946.158057689667, "episode/length": 319.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 514792, "time": 23949.906626939774, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 514848, "time": 23953.533236265182, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 514864, "time": 23955.66599559784, "episode/length": 126.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 514904, "time": 23958.449626922607, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 515176, "time": 23969.48691511154, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 515536, "time": 23983.15912461281, "episode/length": 323.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783950617283951, "episode/intrinsic_return": 0.0}
{"step": 516104, "time": 24003.94773864746, "episode/length": 172.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 516120, "time": 24007.801889896393, "episode/length": 158.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 516216, "time": 24012.624430179596, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 516424, "time": 24021.208114385605, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 516592, "time": 24028.699659585953, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 517424, "time": 24058.145052194595, "episode/length": 426.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 517544, "time": 24063.469671964645, "episode/length": 329.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 517576, "time": 24066.227167129517, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 517784, "time": 24074.816151857376, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 518016, "time": 24084.39463353157, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 518112, "time": 24089.07826900482, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 518288, "time": 24096.524121046066, "episode/length": 211.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 518432, "time": 24102.880225658417, "episode/length": 361.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861878453038674, "episode/intrinsic_return": 0.0}
{"step": 519136, "time": 24128.349594593048, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 519424, "time": 24139.517856121063, "episode/length": 204.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 519440, "time": 24141.58320069313, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 519520, "time": 24145.759263515472, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 519600, "time": 24150.061652183533, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 519784, "time": 24157.622576475143, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 519928, "time": 24164.238953590393, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 519952, "time": 24166.98189640045, "episode/length": 296.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 519984, "time": 24169.685851097107, "episode/length": 304.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24191.79759502411, "eval_episode/length": 160.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 520000, "time": 24193.77083683014, "eval_episode/length": 170.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 520000, "time": 24195.639823913574, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 520000, "time": 24197.563242197037, "eval_episode/length": 185.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 520000, "time": 24199.598894119263, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 520000, "time": 24201.765070438385, "eval_episode/length": 210.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.966824644549763}
{"step": 520000, "time": 24203.345787763596, "eval_episode/length": 211.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 520000, "time": 24205.5569999218, "eval_episode/length": 226.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 520896, "time": 24235.676376342773, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 521064, "time": 24242.739290952682, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 521592, "time": 24262.502906560898, "episode/length": 268.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 24265.132464408875, "episode/length": 262.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 521704, "time": 24269.38443684578, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 521712, "time": 24271.44927763939, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 521944, "time": 24280.72455739975, "episode/length": 39.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 522128, "time": 24288.759590387344, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 522208, "time": 24293.164244890213, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 522648, "time": 24309.40771007538, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 523136, "time": 24327.49506545067, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 523352, "time": 24336.161679506302, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 523464, "time": 24341.364015340805, "episode/length": 434.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954022988505747, "episode/intrinsic_return": 0.0}
{"step": 523520, "time": 24345.000235319138, "episode/length": 196.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 523552, "time": 24348.271900892258, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 523608, "time": 24351.921591043472, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 523648, "time": 24354.986380815506, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 524240, "time": 24376.23884320259, "episode/length": 198.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 524457, "time": 24387.503482341766, "train_stats/sum_log_reward": 6.651401891886631, "train_stats/max_log_achievement_collect_coal": 0.14953271028037382, "train_stats/max_log_achievement_collect_drink": 6.485981308411215, "train_stats/max_log_achievement_collect_sapling": 2.6261682242990654, "train_stats/max_log_achievement_collect_stone": 1.2897196261682242, "train_stats/max_log_achievement_collect_wood": 7.906542056074766, "train_stats/max_log_achievement_defeat_skeleton": 0.009345794392523364, "train_stats/max_log_achievement_defeat_zombie": 0.6542056074766355, "train_stats/max_log_achievement_eat_cow": 0.11214953271028037, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2616822429906542, "train_stats/max_log_achievement_make_wood_sword": 0.028037383177570093, "train_stats/max_log_achievement_place_furnace": 0.009345794392523364, "train_stats/max_log_achievement_place_plant": 2.5233644859813085, "train_stats/max_log_achievement_place_stone": 0.04672897196261682, "train_stats/max_log_achievement_place_table": 2.439252336448598, "train_stats/max_log_achievement_wake_up": 1.8224299065420562, "train_stats/mean_log_entropy": 0.5173476963678253, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.329621669224331, "train/action_min": 0.0, "train/action_std": 3.2028979931558883, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05193441041878292, "train/actor_opt_grad_steps": 31985.0, "train/actor_opt_loss": -2.968900425060253, "train/adv_mag": 0.6872062672461782, "train/adv_max": 0.6678797353591238, "train/adv_mean": 0.003917858608266604, "train/adv_min": -0.5076926493218967, "train/adv_std": 0.07492853474936315, "train/cont_avg": 0.9948521205357143, "train/cont_loss_mean": 0.00016480409332757516, "train/cont_loss_std": 0.004856897480250768, "train/cont_neg_acc": 0.9947070925355815, "train/cont_neg_loss": 0.015734530341721027, "train/cont_pos_acc": 0.999985933303833, "train/cont_pos_loss": 6.490123991775525e-05, "train/cont_pred": 0.9948611659663064, "train/cont_rate": 0.9948521205357143, "train/dyn_loss_mean": 13.366484417234147, "train/dyn_loss_std": 9.11082844734192, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8472892297165734, "train/extr_critic_critic_opt_grad_steps": 31985.0, "train/extr_critic_critic_opt_loss": 15717.497984095982, "train/extr_critic_mag": 5.510669786589486, "train/extr_critic_max": 5.510669786589486, "train/extr_critic_mean": 1.2042258709669114, "train/extr_critic_min": -0.21013976335525514, "train/extr_critic_std": 1.1416190977607454, "train/extr_return_normed_mag": 1.888209239074162, "train/extr_return_normed_max": 1.888209239074162, "train/extr_return_normed_mean": 0.33341692888310975, "train/extr_return_normed_min": -0.15321652407624892, "train/extr_return_normed_std": 0.3291895944092955, "train/extr_return_rate": 0.6503432248319898, "train/extr_return_raw_mag": 6.784634304046631, "train/extr_return_raw_max": 6.784634304046631, "train/extr_return_raw_mean": 1.2182386551584516, "train/extr_return_raw_min": -0.5230397443686213, "train/extr_return_raw_std": 1.1784967320305961, "train/extr_reward_mag": 1.0218005350657873, "train/extr_reward_max": 1.0218005350657873, "train/extr_reward_mean": 0.02883754691907338, "train/extr_reward_min": -0.4020721827234541, "train/extr_reward_std": 0.15822603298085078, "train/image_loss_mean": 6.712239061083112, "train/image_loss_std": 11.440655827522278, "train/model_loss_mean": 14.78588536807469, "train/model_loss_std": 15.191196720940725, "train/model_opt_grad_norm": 57.601408331734795, "train/model_opt_grad_steps": 31956.0, "train/model_opt_loss": 13115.162527901786, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 888.3928571428571, "train/policy_entropy_mag": 2.5729521938732693, "train/policy_entropy_max": 2.5729521938732693, "train/policy_entropy_mean": 0.5387175621730941, "train/policy_entropy_min": 0.07937505644346987, "train/policy_entropy_std": 0.6116241540227617, "train/policy_logprob_mag": 7.438383511134556, "train/policy_logprob_max": -0.009455659253788846, "train/policy_logprob_mean": -0.5394214617354529, "train/policy_logprob_min": -7.438383511134556, "train/policy_logprob_std": 1.0963256738015583, "train/policy_randomness_mag": 0.908139215196882, "train/policy_randomness_max": 0.908139215196882, "train/policy_randomness_mean": 0.19014365864651545, "train/policy_randomness_min": 0.02801591157913208, "train/policy_randomness_std": 0.2158764867910317, "train/post_ent_mag": 58.71418966565813, "train/post_ent_max": 58.71418966565813, "train/post_ent_mean": 41.585193388802665, "train/post_ent_min": 20.34068031311035, "train/post_ent_std": 7.44873354775565, "train/prior_ent_mag": 67.95776824951172, "train/prior_ent_max": 67.95776824951172, "train/prior_ent_mean": 55.02321308680943, "train/prior_ent_min": 39.677279690333776, "train/prior_ent_std": 4.453779424939837, "train/rep_loss_mean": 13.366484417234147, "train/rep_loss_std": 9.11082844734192, "train/reward_avg": 0.025744279966290508, "train/reward_loss_mean": 0.05359097340011171, "train/reward_loss_std": 0.2500784555716174, "train/reward_max_data": 1.0121428600379399, "train/reward_max_pred": 1.0092649740832194, "train/reward_neg_acc": 0.993303953749793, "train/reward_neg_loss": 0.028690408522795353, "train/reward_pos_acc": 0.9650462631668363, "train/reward_pos_loss": 0.8533350514514105, "train/reward_pred": 0.025011633183541042, "train/reward_rate": 0.030336216517857142, "eval_stats/sum_log_reward": 5.912499941885471, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.75, "eval_stats/max_log_achievement_collect_wood": 8.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.2446348591765855e-06, "report/cont_loss_std": 1.9697352399816737e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002001668035518378, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.601426889574213e-07, "report/cont_pred": 0.9970703125, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.288322448730469, "report/dyn_loss_std": 8.620207786560059, "report/image_loss_mean": 4.258581161499023, "report/image_loss_std": 7.798788547515869, "report/model_loss_mean": 11.663115501403809, "report/model_loss_std": 11.413278579711914, "report/post_ent_mag": 58.79267883300781, "report/post_ent_max": 58.79267883300781, "report/post_ent_mean": 42.6602897644043, "report/post_ent_min": 17.794551849365234, "report/post_ent_std": 7.145895481109619, "report/prior_ent_mag": 68.0155258178711, "report/prior_ent_max": 68.0155258178711, "report/prior_ent_mean": 55.23800277709961, "report/prior_ent_min": 39.44508361816406, "report/prior_ent_std": 4.407406806945801, "report/rep_loss_mean": 12.288322448730469, "report/rep_loss_std": 8.620207786560059, "report/reward_avg": 0.01503906212747097, "report/reward_loss_mean": 0.031540192663669586, "report/reward_loss_std": 0.183660626411438, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0051312446594238, "report/reward_neg_acc": 0.9970149993896484, "report/reward_neg_loss": 0.016165653243660927, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.844772458076477, "report/reward_pred": 0.015250317752361298, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 5.195356789045036e-05, "eval/cont_loss_std": 0.001119394670240581, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004310866352170706, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.685192521312274e-05, "eval/cont_pred": 0.9941393136978149, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.83323097229004, "eval/dyn_loss_std": 10.76852035522461, "eval/image_loss_mean": 15.937353134155273, "eval/image_loss_std": 26.51384735107422, "eval/model_loss_mean": 26.14876937866211, "eval/model_loss_std": 31.02796173095703, "eval/post_ent_mag": 59.485870361328125, "eval/post_ent_max": 59.485870361328125, "eval/post_ent_mean": 39.97696304321289, "eval/post_ent_min": 21.993526458740234, "eval/post_ent_std": 7.057486534118652, "eval/prior_ent_mag": 68.0155258178711, "eval/prior_ent_max": 68.0155258178711, "eval/prior_ent_mean": 54.710269927978516, "eval/prior_ent_min": 39.33837127685547, "eval/prior_ent_std": 4.675102233886719, "eval/rep_loss_mean": 16.83323097229004, "eval/rep_loss_std": 10.76852035522461, "eval/reward_avg": 0.02958984300494194, "eval/reward_loss_mean": 0.111424520611763, "eval/reward_loss_std": 0.6979759335517883, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001796007156372, "eval/reward_neg_acc": 0.9868553280830383, "eval/reward_neg_loss": 0.03999336063861847, "eval/reward_pos_acc": 0.7428571581840515, "eval/reward_pos_loss": 2.1298649311065674, "eval/reward_pred": 0.025895338505506516, "eval/reward_rate": 0.0341796875, "replay/size": 523953.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.4005708830599953e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.37050108736026e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1702721886191976e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.359299659729, "timer/env.step_count": 2802.0, "timer/env.step_total": 251.96253848075867, "timer/env.step_frac": 0.2518720409421529, "timer/env.step_avg": 0.08992239060698025, "timer/env.step_min": 0.02273416519165039, "timer/env.step_max": 3.332984685897827, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.685766458511353, "timer/replay._sample_frac": 0.011681569274645871, "timer/replay._sample_avg": 0.00052131363572945, "timer/replay._sample_min": 0.00042176246643066406, "timer/replay._sample_max": 0.033768415451049805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3265.0, "timer/agent.policy_total": 53.22799611091614, "timer/agent.policy_frac": 0.053208878179091826, "timer/agent.policy_avg": 0.016302602177922246, "timer/agent.policy_min": 0.00931859016418457, "timer/agent.policy_max": 0.12438082695007324, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.15496492385864258, "timer/dataset_train_frac": 0.00015490926501243474, "timer/dataset_train_avg": 0.00011061022402472703, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.00028014183044433594, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 628.805428981781, "timer/agent.train_frac": 0.628579580552376, "timer/agent.train_avg": 0.4488261448834982, "timer/agent.train_min": 0.43446969985961914, "timer/agent.train_max": 1.5700130462646484, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47794437408447266, "timer/agent.report_frac": 0.00047777271051215785, "timer/agent.report_avg": 0.23897218704223633, "timer/agent.report_min": 0.23247981071472168, "timer/agent.report_max": 0.24546456336975098, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010156631469726562, "timer/dataset_eval_frac": 1.0152983506207548e-07, "timer/dataset_eval_avg": 0.00010156631469726562, "timer/dataset_eval_min": 0.00010156631469726562, "timer/dataset_eval_max": 0.00010156631469726562, "fps": 22.407685823168954}
{"step": 524608, "time": 24392.614147424698, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 524832, "time": 24401.75288796425, "episode/length": 170.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 524832, "time": 24401.762536764145, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 524920, "time": 24407.75789666176, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 524960, "time": 24410.91593170166, "episode/length": 200.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 525112, "time": 24417.461552858353, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 525360, "time": 24427.829399824142, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 526008, "time": 24450.862196207047, "episode/length": 80.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 526152, "time": 24457.48099541664, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 526176, "time": 24460.20574593544, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 526336, "time": 24467.266727924347, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 526344, "time": 24468.873517036438, "episode/length": 188.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 526584, "time": 24478.38922071457, "episode/length": 50.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 526960, "time": 24492.81135725975, "episode/length": 254.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 527032, "time": 24496.505426883698, "episode/length": 258.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 527104, "time": 24500.72990655899, "episode/length": 283.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 527416, "time": 24512.447931289673, "episode/length": 103.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 527440, "time": 24515.130429029465, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 528008, "time": 24535.36727809906, "episode/length": 112.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 528144, "time": 24541.775416612625, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 528216, "time": 24545.682860851288, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 528296, "time": 24549.941729784012, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 528488, "time": 24557.9016225338, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 528616, "time": 24563.663078546524, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 528728, "time": 24569.095037698746, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 528800, "time": 24573.353795051575, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 529384, "time": 24594.060184955597, "episode/length": 95.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 529656, "time": 24604.909920454025, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 529720, "time": 24608.651772260666, "episode/length": 177.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 529920, "time": 24617.063364982605, "episode/length": 221.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 529920, "time": 24617.07398581505, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 530016, "time": 24623.370165348053, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24641.983154058456, "eval_episode/length": 45.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 530088, "time": 24645.52981352806, "eval_episode/length": 92.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.956989247311828}
{"step": 530088, "time": 24652.555857658386, "eval_episode/length": 168.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 530088, "time": 24656.225478172302, "eval_episode/length": 153.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.974025974025974}
{"step": 530088, "time": 24660.3601770401, "eval_episode/length": 245.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 530088, "time": 24662.39251613617, "eval_episode/length": 153.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 530088, "time": 24664.419115781784, "eval_episode/length": 249.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 530088, "time": 24667.56037092209, "eval_episode/length": 271.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 530176, "time": 24670.76756834984, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 530416, "time": 24680.710361480713, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 530944, "time": 24699.866894721985, "episode/length": 194.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 531008, "time": 24703.79173350334, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 531448, "time": 24719.88438463211, "episode/length": 62.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 531520, "time": 24724.290669202805, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 531592, "time": 24728.189244031906, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 531744, "time": 24735.056132793427, "episode/length": 227.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 531840, "time": 24739.80812907219, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 532368, "time": 24759.131402254105, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 532424, "time": 24762.389269590378, "episode/length": 250.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 532744, "time": 24776.193851947784, "episode/length": 39.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 533064, "time": 24788.58162689209, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 533184, "time": 24794.441937208176, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 533248, "time": 24798.153760910034, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 533344, "time": 24802.919433116913, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 533608, "time": 24812.936382055283, "episode/length": 428.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 534184, "time": 24833.731496810913, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 534240, "time": 24837.351136922836, "episode/length": 348.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9914040114613181, "episode/intrinsic_return": 0.0}
{"step": 534664, "time": 24852.98313498497, "episode/length": 239.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 534736, "time": 24857.15152978897, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 534944, "time": 24865.708408117294, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 535016, "time": 24869.541714906693, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 535168, "time": 24876.505979776382, "episode/length": 27.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 535424, "time": 24886.576748609543, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 535632, "time": 24895.146137714386, "episode/length": 180.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 536000, "time": 24909.049100399017, "episode/length": 219.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 536320, "time": 24921.48357987404, "episode/length": 206.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 536336, "time": 24923.589624881744, "episode/length": 393.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 536488, "time": 24929.99303126335, "episode/length": 183.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 536560, "time": 24934.14981198311, "episode/length": 173.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 536848, "time": 24945.456036806107, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 537232, "time": 24959.83078432083, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 537248, "time": 24961.9764919281, "episode/length": 313.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 537568, "time": 24974.351023435593, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 537712, "time": 24980.908905029297, "episode/length": 143.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 537848, "time": 24986.787778377533, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 538056, "time": 24995.480129003525, "episode/length": 195.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 538248, "time": 25003.456384181976, "episode/length": 174.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 538400, "time": 25010.260729312897, "episode/length": 145.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 538672, "time": 25020.784138202667, "episode/length": 291.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 539064, "time": 25035.29553413391, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 539160, "time": 25040.210691928864, "episode/length": 180.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 539560, "time": 25055.178894519806, "episode/length": 288.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 539592, "time": 25057.745245456696, "episode/length": 217.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 25089.904860973358, "eval_episode/length": 28.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8275862068965517}
{"step": 540072, "time": 25096.73974466324, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 540072, "time": 25099.262610435486, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 540072, "time": 25101.163417577744, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 540072, "time": 25103.51793050766, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 540072, "time": 25105.52408671379, "eval_episode/length": 202.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 540072, "time": 25107.903843402863, "eval_episode/length": 220.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 540072, "time": 25111.14593243599, "eval_episode/length": 254.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.996078431372549}
{"step": 540088, "time": 25111.68629050255, "episode/length": 253.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 540232, "time": 25118.128175258636, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 540416, "time": 25125.97244620323, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 540584, "time": 25133.24170255661, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 540752, "time": 25142.135267019272, "episode/length": 259.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 540840, "time": 25146.53733897209, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 541120, "time": 25158.120980024338, "episode/length": 339.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9911764705882353, "episode/intrinsic_return": 0.0}
{"step": 541368, "time": 25167.74784564972, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 541512, "time": 25174.05151462555, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 542064, "time": 25194.288231372833, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 542088, "time": 25196.418580293655, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 542248, "time": 25203.516763210297, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 542376, "time": 25209.55583882332, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 542656, "time": 25220.531226873398, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 542816, "time": 25227.350739717484, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 542944, "time": 25233.234335184097, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 543048, "time": 25238.05017709732, "episode/length": 48.0, "episode/score": 3.0999999567866325, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 543424, "time": 25252.318648576736, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 543576, "time": 25258.98705649376, "episode/length": 188.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 543928, "time": 25272.28567838669, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 544160, "time": 25281.73159456253, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 544208, "time": 25284.835592985153, "episode/length": 34.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 544232, "time": 25286.956687927246, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 544264, "time": 25289.585743188858, "episode/length": 438.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9977220956719818, "episode/intrinsic_return": 0.0}
{"step": 544368, "time": 25294.842891931534, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 544504, "time": 25300.837342500687, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 544872, "time": 25314.550418138504, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 544960, "time": 25319.470729351044, "episode/length": 90.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9340659340659341, "episode/intrinsic_return": 0.0}
{"step": 545488, "time": 25338.777287244797, "episode/length": 165.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 545504, "time": 25340.923054218292, "episode/length": 124.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.944, "episode/intrinsic_return": 0.0}
{"step": 545528, "time": 25343.06971669197, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 545608, "time": 25347.37671160698, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 545792, "time": 25355.284118175507, "episode/length": 177.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 546312, "time": 25373.919043302536, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 546552, "time": 25383.540865182877, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 546601, "time": 25387.801436185837, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.197281989498415, "train/action_min": 0.0, "train/action_std": 2.9951281962187393, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05251385679171569, "train/actor_opt_grad_steps": 33375.0, "train/actor_opt_loss": 6.1698078867048025, "train/adv_mag": 0.6873840808436491, "train/adv_max": 0.6601050820039667, "train/adv_mean": 0.005971308432231455, "train/adv_min": -0.5033493804326956, "train/adv_std": 0.0745494249344304, "train/cont_avg": 0.9948128962862319, "train/cont_loss_mean": 0.00012655066187320423, "train/cont_loss_std": 0.0036588011719271003, "train/cont_neg_acc": 0.9952731101828463, "train/cont_neg_loss": 0.010273083317850465, "train/cont_pos_acc": 0.9999786179134811, "train/cont_pos_loss": 7.34024010587122e-05, "train/cont_pred": 0.9948158173457436, "train/cont_rate": 0.9948128962862319, "train/dyn_loss_mean": 13.480594655741816, "train/dyn_loss_std": 9.057087504345438, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8275289125200631, "train/extr_critic_critic_opt_grad_steps": 33375.0, "train/extr_critic_critic_opt_loss": 15953.604598335598, "train/extr_critic_mag": 5.59205236642257, "train/extr_critic_max": 5.59205236642257, "train/extr_critic_mean": 1.3343831460545028, "train/extr_critic_min": -0.205765830433887, "train/extr_critic_std": 1.2028637195842853, "train/extr_return_normed_mag": 1.827397506306137, "train/extr_return_normed_max": 1.827397506306137, "train/extr_return_normed_mean": 0.3436284662372824, "train/extr_return_normed_min": -0.1506221252830996, "train/extr_return_normed_std": 0.32903771091630496, "train/extr_return_rate": 0.6933617701996928, "train/extr_return_raw_mag": 6.966220631115679, "train/extr_return_raw_max": 6.966220631115679, "train/extr_return_raw_mean": 1.3569910478764686, "train/extr_return_raw_min": -0.5126661991943484, "train/extr_return_raw_std": 1.2442991660125013, "train/extr_reward_mag": 1.0247665384541387, "train/extr_reward_max": 1.0247665384541387, "train/extr_reward_mean": 0.02972785256587077, "train/extr_reward_min": -0.41050209515336633, "train/extr_reward_std": 0.1607795784762804, "train/image_loss_mean": 6.708765375441399, "train/image_loss_std": 11.278536060582036, "train/model_loss_mean": 14.84927269341289, "train/model_loss_std": 15.00095502189968, "train/model_opt_grad_norm": 58.92758919536204, "train/model_opt_grad_steps": 33345.32608695652, "train/model_opt_loss": 18966.274116847828, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1286.231884057971, "train/policy_entropy_mag": 2.570077113483263, "train/policy_entropy_max": 2.570077113483263, "train/policy_entropy_mean": 0.521255749291268, "train/policy_entropy_min": 0.07937505047606386, "train/policy_entropy_std": 0.5968877027432123, "train/policy_logprob_mag": 7.438383572343467, "train/policy_logprob_max": -0.00945566184953719, "train/policy_logprob_mean": -0.521648575430331, "train/policy_logprob_min": -7.438383572343467, "train/policy_logprob_std": 1.0869346459706624, "train/policy_randomness_mag": 0.9071244377156963, "train/policy_randomness_max": 0.9071244377156963, "train/policy_randomness_mean": 0.18398040522267853, "train/policy_randomness_min": 0.028015909500528072, "train/policy_randomness_std": 0.21067516678485318, "train/post_ent_mag": 58.69673386172972, "train/post_ent_max": 58.69673386172972, "train/post_ent_mean": 41.59498739933622, "train/post_ent_min": 20.421441603397977, "train/post_ent_std": 7.463775810988053, "train/prior_ent_mag": 67.92070781320766, "train/prior_ent_max": 67.92070781320766, "train/prior_ent_mean": 55.101457098255985, "train/prior_ent_min": 39.669635523920476, "train/prior_ent_std": 4.4156241987062534, "train/rep_loss_mean": 13.480594655741816, "train/rep_loss_std": 9.057087504345438, "train/reward_avg": 0.024760812682949978, "train/reward_loss_mean": 0.052024090878557465, "train/reward_loss_std": 0.24203530137521634, "train/reward_max_data": 1.0202898599099421, "train/reward_max_pred": 1.0126293120176897, "train/reward_neg_acc": 0.9933033823103145, "train/reward_neg_loss": 0.027922710720989584, "train/reward_pos_acc": 0.9670806997928066, "train/reward_pos_loss": 0.840615700552429, "train/reward_pred": 0.024178435209382704, "train/reward_rate": 0.02955870697463768, "train_stats/sum_log_reward": 6.63571435213089, "train_stats/max_log_achievement_collect_coal": 0.16071428571428573, "train_stats/max_log_achievement_collect_drink": 5.678571428571429, "train_stats/max_log_achievement_collect_sapling": 2.125, "train_stats/max_log_achievement_collect_stone": 1.3392857142857142, "train_stats/max_log_achievement_collect_wood": 9.026785714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6964285714285714, "train_stats/max_log_achievement_eat_cow": 0.10714285714285714, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.008928571428571428, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.875, "train_stats/max_log_achievement_make_wood_sword": 0.008928571428571428, "train_stats/max_log_achievement_place_furnace": 0.008928571428571428, "train_stats/max_log_achievement_place_plant": 2.0625, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.4464285714285716, "train_stats/max_log_achievement_wake_up": 1.4285714285714286, "train_stats/mean_log_entropy": 0.4843716447108558, "eval_stats/sum_log_reward": 6.162500038743019, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 4.8125, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 1.8125, "eval_stats/max_log_achievement_collect_wood": 8.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.764581262861611e-06, "report/cont_loss_std": 0.00011777307372540236, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011240257881581783, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.7532197438849835e-07, "report/cont_pred": 0.9960978031158447, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.757933616638184, "report/dyn_loss_std": 8.437070846557617, "report/image_loss_mean": 5.259425640106201, "report/image_loss_std": 12.255905151367188, "report/model_loss_mean": 13.562459945678711, "report/model_loss_std": 15.474050521850586, "report/post_ent_mag": 55.77837371826172, "report/post_ent_max": 55.77837371826172, "report/post_ent_mean": 40.154998779296875, "report/post_ent_min": 20.671939849853516, "report/post_ent_std": 6.772306442260742, "report/prior_ent_mag": 67.99630737304688, "report/prior_ent_max": 67.99630737304688, "report/prior_ent_mean": 54.038116455078125, "report/prior_ent_min": 39.131874084472656, "report/prior_ent_std": 4.151583671569824, "report/rep_loss_mean": 13.757933616638184, "report/rep_loss_std": 8.437070846557617, "report/reward_avg": 0.03681640326976776, "report/reward_loss_mean": 0.04827021062374115, "report/reward_loss_std": 0.19146494567394257, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011813640594482, "report/reward_neg_acc": 0.9888097643852234, "report/reward_neg_loss": 0.017376458272337914, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.788966715335846, "report/reward_pred": 0.0364665761590004, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.438675548750325e-06, "eval/cont_loss_std": 7.620669930474833e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0017258476000279188, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.801207774742579e-08, "eval/cont_pred": 0.9980502128601074, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.41400909423828, "eval/dyn_loss_std": 10.142990112304688, "eval/image_loss_mean": 11.668684959411621, "eval/image_loss_std": 17.810514450073242, "eval/model_loss_mean": 22.755699157714844, "eval/model_loss_std": 21.7645206451416, "eval/post_ent_mag": 57.53999328613281, "eval/post_ent_max": 57.53999328613281, "eval/post_ent_mean": 38.857582092285156, "eval/post_ent_min": 14.932062149047852, "eval/post_ent_std": 6.490058898925781, "eval/prior_ent_mag": 67.99630737304688, "eval/prior_ent_max": 67.99630737304688, "eval/prior_ent_mean": 54.450111389160156, "eval/prior_ent_min": 38.66505432128906, "eval/prior_ent_std": 4.466396808624268, "eval/rep_loss_mean": 18.41400909423828, "eval/rep_loss_std": 10.142990112304688, "eval/reward_avg": 0.02490234375, "eval/reward_loss_mean": 0.03860524296760559, "eval/reward_loss_std": 0.19240114092826843, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011541843414307, "eval/reward_neg_acc": 0.9939759969711304, "eval/reward_neg_loss": 0.01702549308538437, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 0.8062278032302856, "eval/reward_pred": 0.023897387087345123, "eval/reward_rate": 0.02734375, "replay/size": 546097.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.382362635838503e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.058484796843777e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.225966882434244e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2877368927002, "timer/env.step_count": 2768.0, "timer/env.step_total": 255.2015244960785, "timer/env.step_frac": 0.25512811472510705, "timer/env.step_avg": 0.0921970825491613, "timer/env.step_min": 0.022258758544921875, "timer/env.step_max": 3.301511526107788, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 10.984925985336304, "timer/replay._sample_frac": 0.010981766126074826, "timer/replay._sample_avg": 0.0004960678280950282, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.008795738220214844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3295.0, "timer/agent.policy_total": 54.8307409286499, "timer/agent.policy_frac": 0.0548149686399, "timer/agent.policy_avg": 0.016640589052701032, "timer/agent.policy_min": 0.009158134460449219, "timer/agent.policy_max": 0.12967824935913086, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.1517484188079834, "timer/dataset_train_frac": 0.00015170476774950336, "timer/dataset_train_avg": 0.00010964481127744465, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.00041747093200683594, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 618.9781060218811, "timer/agent.train_frac": 0.6188000544170205, "timer/agent.train_avg": 0.4472385159117638, "timer/agent.train_min": 0.4343578815460205, "timer/agent.train_max": 1.6077861785888672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48078346252441406, "timer/agent.report_frac": 0.00048064516317866966, "timer/agent.report_avg": 0.24039173126220703, "timer/agent.report_min": 0.23432660102844238, "timer/agent.report_max": 0.24645686149597168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193889959988224e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.137357669549807}
{"step": 546848, "time": 25396.131789922714, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 547016, "time": 25403.00195503235, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 547200, "time": 25410.826858520508, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 547488, "time": 25422.069375276566, "episode/length": 146.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 547672, "time": 25429.76017689705, "episode/length": 425.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 547680, "time": 25431.777330636978, "episode/length": 140.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 548016, "time": 25444.429230213165, "episode/length": 313.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777070063694268, "episode/intrinsic_return": 0.0}
{"step": 548128, "time": 25449.719978570938, "episode/length": 314.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 548312, "time": 25457.150047779083, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 548328, "time": 25459.233003377914, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 548680, "time": 25472.511736392975, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 549304, "time": 25496.628440380096, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 549456, "time": 25503.545474767685, "episode/length": 281.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 549552, "time": 25508.433643579483, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 549784, "time": 25517.62713599205, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 549912, "time": 25523.45385503769, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 549936, "time": 25526.034755945206, "episode/length": 281.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 550040, "time": 25530.877203941345, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 25551.998972177505, "eval_episode/length": 131.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 550056, "time": 25554.428909540176, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.993421052631579}
{"step": 550056, "time": 25556.06534934044, "eval_episode/length": 152.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 550056, "time": 25558.791838169098, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 550056, "time": 25561.177632570267, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 550056, "time": 25563.1867249012, "eval_episode/length": 201.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.995049504950495}
{"step": 550056, "time": 25567.621024131775, "eval_episode/length": 266.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 550056, "time": 25570.691299200058, "eval_episode/length": 146.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 550400, "time": 25582.30753326416, "episode/length": 260.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 550432, "time": 25584.907317638397, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 550456, "time": 25587.238063097, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 550584, "time": 25593.037225723267, "episode/length": 99.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 550816, "time": 25602.588003873825, "episode/length": 47.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 550968, "time": 25609.11585330963, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 551640, "time": 25633.136510849, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 551712, "time": 25637.313944339752, "episode/length": 300.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 552256, "time": 25656.976094722748, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 552592, "time": 25669.71306324005, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 552760, "time": 25676.55193257332, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 552928, "time": 25683.980900287628, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 552936, "time": 25685.63495349884, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 552992, "time": 25689.236481666565, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 553224, "time": 25698.297579050064, "episode/length": 410.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 553368, "time": 25705.20727777481, "episode/length": 53.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 553384, "time": 25707.729644298553, "episode/length": 56.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 553800, "time": 25723.553994894028, "episode/length": 269.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 554016, "time": 25732.568174123764, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 554048, "time": 25735.142914533615, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 554424, "time": 25749.10591363907, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 554640, "time": 25758.38720703125, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 554720, "time": 25762.643229484558, "episode/length": 166.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 555096, "time": 25776.554121494293, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 555392, "time": 25788.14580321312, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 555456, "time": 25791.785504341125, "episode/length": 260.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 555728, "time": 25802.433848381042, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 555872, "time": 25809.108851909637, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 556112, "time": 25818.627487421036, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 556872, "time": 25845.27660536766, "episode/length": 124.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.952, "episode/intrinsic_return": 0.0}
{"step": 556992, "time": 25851.078872680664, "episode/length": 283.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 557000, "time": 25852.65721487999, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 557472, "time": 25871.88023376465, "episode/length": 169.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 557808, "time": 25884.575505018234, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 558120, "time": 25896.509541988373, "episode/length": 434.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 558280, "time": 25903.545288562775, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 558576, "time": 25915.102517843246, "episode/length": 397.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 558624, "time": 25918.27996778488, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 558816, "time": 25926.1383395195, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 558824, "time": 25927.772803783417, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 559096, "time": 25938.400729894638, "episode/length": 160.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 559264, "time": 25945.799859523773, "episode/length": 54.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 559688, "time": 25961.29789185524, "episode/length": 494.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 559744, "time": 25965.207417726517, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 25996.483735084534, "eval_episode/length": 151.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9802631578947368}
{"step": 560040, "time": 25998.46740961075, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 560040, "time": 26001.01577925682, "eval_episode/length": 180.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 560040, "time": 26004.21633386612, "eval_episode/length": 216.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.967741935483871}
{"step": 560040, "time": 26005.90729546547, "eval_episode/length": 221.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 560040, "time": 26007.53728199005, "eval_episode/length": 224.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 560040, "time": 26011.298493623734, "eval_episode/length": 278.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.982078853046595}
{"step": 560040, "time": 26015.287192106247, "eval_episode/length": 181.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 560104, "time": 26017.403292417526, "episode/length": 190.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 560104, "time": 26017.411277532578, "episode/length": 227.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 560224, "time": 26024.939020872116, "episode/length": 140.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 560376, "time": 26031.38930940628, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 560704, "time": 26043.935996055603, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 560752, "time": 26047.13837170601, "episode/length": 46.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 560952, "time": 26055.01671910286, "episode/length": 290.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 561272, "time": 26067.206030368805, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 561664, "time": 26082.12650203705, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 561720, "time": 26085.41095972061, "episode/length": 253.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9881889763779528, "episode/intrinsic_return": 0.0}
{"step": 561840, "time": 26091.348415374756, "episode/length": 216.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9907834101382489, "episode/intrinsic_return": 0.0}
{"step": 562432, "time": 26112.534121990204, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 562432, "time": 26112.543410778046, "episode/length": 335.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 562480, "time": 26117.558129310608, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 562808, "time": 26129.6806576252, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 563048, "time": 26139.28233909607, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 563232, "time": 26147.125266313553, "episode/length": 244.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 563664, "time": 26162.98815870285, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 563728, "time": 26166.832768201828, "episode/length": 155.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 563760, "time": 26169.437848567963, "episode/length": 165.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 563936, "time": 26176.941331148148, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 564008, "time": 26180.686970949173, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 564184, "time": 26187.959490776062, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 564400, "time": 26197.204900979996, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 564424, "time": 26199.345396518707, "episode/length": 29.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 564640, "time": 26208.503905534744, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 565104, "time": 26225.63742995262, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 565232, "time": 26231.439287424088, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 565656, "time": 26248.384488344193, "episode/length": 156.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 565688, "time": 26251.06396985054, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 565776, "time": 26255.939296722412, "episode/length": 229.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 566136, "time": 26269.232848882675, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 566144, "time": 26271.3069562912, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 566584, "time": 26287.327481031418, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 566592, "time": 26289.472371339798, "episode/length": 270.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 566616, "time": 26291.833244800568, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 567000, "time": 26306.106509923935, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 567448, "time": 26322.46286535263, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 567464, "time": 26324.54252767563, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 567696, "time": 26333.96823143959, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 567848, "time": 26340.436396598816, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 567880, "time": 26343.093169927597, "episode/length": 53.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 567936, "time": 26346.743196725845, "episode/length": 168.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 568072, "time": 26352.50572490692, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 568480, "time": 26367.837492227554, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 568848, "time": 26381.934373140335, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 568969, "time": 26388.27887392044, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.182638113839285, "train/action_min": 0.0, "train/action_std": 3.1093388744762964, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04835589448256152, "train/actor_opt_grad_steps": 34765.0, "train/actor_opt_loss": 0.1925151656780924, "train/adv_mag": 0.6436467462352344, "train/adv_max": 0.6094123991472381, "train/adv_mean": 0.004548381095647918, "train/adv_min": -0.4702783535633768, "train/adv_std": 0.06911324161503996, "train/cont_avg": 0.9946568080357143, "train/cont_loss_mean": 0.00024242067671715567, "train/cont_loss_std": 0.007099893858121017, "train/cont_neg_acc": 0.9868282330887658, "train/cont_neg_loss": 0.030192402846458726, "train/cont_pos_acc": 0.9999649005276816, "train/cont_pos_loss": 0.00011064325373908446, "train/cont_pred": 0.9946578949689865, "train/cont_rate": 0.9946568080357143, "train/dyn_loss_mean": 13.440749672480992, "train/dyn_loss_std": 9.09106580870492, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8317461507661003, "train/extr_critic_critic_opt_grad_steps": 34765.0, "train/extr_critic_critic_opt_loss": 15867.87795061384, "train/extr_critic_mag": 5.856110760143825, "train/extr_critic_max": 5.856110760143825, "train/extr_critic_mean": 1.5165356022971017, "train/extr_critic_min": -0.2063829413482121, "train/extr_critic_std": 1.3061721959284374, "train/extr_return_normed_mag": 1.7457909635135105, "train/extr_return_normed_max": 1.7457909635135105, "train/extr_return_normed_mean": 0.3495925175292151, "train/extr_return_normed_min": -0.14305650650390556, "train/extr_return_normed_std": 0.32698795295187405, "train/extr_return_rate": 0.7356278244938169, "train/extr_return_raw_mag": 7.286883561951774, "train/extr_return_raw_max": 7.286883561951774, "train/extr_return_raw_mean": 1.5352264991828373, "train/extr_return_raw_min": -0.49390569222824915, "train/extr_return_raw_std": 1.346979541012219, "train/extr_reward_mag": 1.0237210171563285, "train/extr_reward_max": 1.0237210171563285, "train/extr_reward_mean": 0.02988695242841329, "train/extr_reward_min": -0.40363849401474, "train/extr_reward_std": 0.16089535600372723, "train/image_loss_mean": 6.757150561468942, "train/image_loss_std": 11.246662756374905, "train/model_loss_mean": 14.875022424970354, "train/model_loss_std": 14.97684598650251, "train/model_opt_grad_norm": 56.30942452294486, "train/model_opt_grad_steps": 34733.92857142857, "train/model_opt_loss": 20048.11498325893, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1348.2142857142858, "train/policy_entropy_mag": 2.534995983328138, "train/policy_entropy_max": 2.534995983328138, "train/policy_entropy_mean": 0.5275354127798761, "train/policy_entropy_min": 0.07937503925391606, "train/policy_entropy_std": 0.6135537107075963, "train/policy_logprob_mag": 7.438383626937866, "train/policy_logprob_max": -0.009455659253788846, "train/policy_logprob_mean": -0.5279576633657728, "train/policy_logprob_min": -7.438383626937866, "train/policy_logprob_std": 1.089164970602308, "train/policy_randomness_mag": 0.8947423372949873, "train/policy_randomness_max": 0.8947423372949873, "train/policy_randomness_mean": 0.18619684970804623, "train/policy_randomness_min": 0.02801590548562152, "train/policy_randomness_std": 0.21655753531626293, "train/post_ent_mag": 59.02766933441162, "train/post_ent_max": 59.02766933441162, "train/post_ent_mean": 41.665710176740376, "train/post_ent_min": 20.130630125318255, "train/post_ent_std": 7.493254293714251, "train/prior_ent_mag": 68.02687699454171, "train/prior_ent_max": 68.02687699454171, "train/prior_ent_mean": 55.17683296203613, "train/prior_ent_min": 39.86015708105905, "train/prior_ent_std": 4.405710806165422, "train/rep_loss_mean": 13.440749672480992, "train/rep_loss_std": 9.09106580870492, "train/reward_avg": 0.02484444732378636, "train/reward_loss_mean": 0.05317965165844985, "train/reward_loss_std": 0.2430880469935281, "train/reward_max_data": 1.0121428600379399, "train/reward_max_pred": 1.0094091125896998, "train/reward_neg_acc": 0.9928317116839546, "train/reward_neg_loss": 0.029270197730511427, "train/reward_pos_acc": 0.9696555840117591, "train/reward_pos_loss": 0.8378150727067675, "train/reward_pred": 0.024435344358373967, "train/reward_rate": 0.029750279017857144, "train_stats/sum_log_reward": 6.581481518568816, "train_stats/max_log_achievement_collect_coal": 0.14814814814814814, "train_stats/max_log_achievement_collect_drink": 5.0092592592592595, "train_stats/max_log_achievement_collect_sapling": 2.064814814814815, "train_stats/max_log_achievement_collect_stone": 1.8240740740740742, "train_stats/max_log_achievement_collect_wood": 11.037037037037036, "train_stats/max_log_achievement_defeat_skeleton": 0.009259259259259259, "train_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "train_stats/max_log_achievement_eat_cow": 0.06481481481481481, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.009259259259259259, "train_stats/max_log_achievement_make_wood_pickaxe": 2.861111111111111, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.018518518518518517, "train_stats/max_log_achievement_place_plant": 2.0277777777777777, "train_stats/max_log_achievement_place_stone": 0.046296296296296294, "train_stats/max_log_achievement_place_table": 2.935185185185185, "train_stats/max_log_achievement_wake_up": 1.2314814814814814, "train_stats/mean_log_entropy": 0.49759286655871954, "eval_stats/sum_log_reward": 6.849999904632568, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 3.0625, "eval_stats/max_log_achievement_collect_wood": 9.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.734755283512641e-07, "report/cont_loss_std": 9.22724575502798e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.398354162229225e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.015106125938473e-07, "report/cont_pred": 0.9941405653953552, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.056463241577148, "report/dyn_loss_std": 8.401965141296387, "report/image_loss_mean": 4.33406925201416, "report/image_loss_std": 7.401882648468018, "report/model_loss_mean": 12.221345901489258, "report/model_loss_std": 10.962020874023438, "report/post_ent_mag": 60.947608947753906, "report/post_ent_max": 60.947608947753906, "report/post_ent_mean": 41.4078369140625, "report/post_ent_min": 21.209476470947266, "report/post_ent_std": 7.572721004486084, "report/prior_ent_mag": 68.39695739746094, "report/prior_ent_max": 68.39695739746094, "report/prior_ent_mean": 54.738006591796875, "report/prior_ent_min": 41.514251708984375, "report/prior_ent_std": 4.226029396057129, "report/rep_loss_mean": 13.056463241577148, "report/rep_loss_std": 8.401965141296387, "report/reward_avg": 0.03173828125, "report/reward_loss_mean": 0.053397469222545624, "report/reward_loss_std": 0.2686925232410431, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006294250488281, "report/reward_neg_acc": 0.9959472417831421, "report/reward_neg_loss": 0.023092977702617645, "report/reward_pos_acc": 0.9459459185600281, "report/reward_pos_loss": 0.8617900609970093, "report/reward_pred": 0.03011336177587509, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.8381593690719455e-05, "eval/cont_loss_std": 0.0005236288998275995, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004662850871682167, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.6798860258404602e-07, "eval/cont_pred": 0.9961117506027222, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.69266128540039, "eval/dyn_loss_std": 10.500597953796387, "eval/image_loss_mean": 12.776433944702148, "eval/image_loss_std": 15.427718162536621, "eval/model_loss_mean": 22.880443572998047, "eval/model_loss_std": 19.31492042541504, "eval/post_ent_mag": 58.40740203857422, "eval/post_ent_max": 58.40740203857422, "eval/post_ent_mean": 41.21269226074219, "eval/post_ent_min": 20.907527923583984, "eval/post_ent_std": 8.090344429016113, "eval/prior_ent_mag": 68.39695739746094, "eval/prior_ent_max": 68.39695739746094, "eval/prior_ent_mean": 55.768882751464844, "eval/prior_ent_min": 41.01150894165039, "eval/prior_ent_std": 4.1010422706604, "eval/rep_loss_mean": 16.69266128540039, "eval/rep_loss_std": 10.500597953796387, "eval/reward_avg": 0.02597656287252903, "eval/reward_loss_mean": 0.08839413523674011, "eval/reward_loss_std": 0.5717868804931641, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0042016506195068, "eval/reward_neg_acc": 0.9919517040252686, "eval/reward_neg_loss": 0.026976127177476883, "eval/reward_pos_acc": 0.7666667103767395, "eval/reward_pos_loss": 2.123377561569214, "eval/reward_pred": 0.019919078797101974, "eval/reward_rate": 0.029296875, "replay/size": 568465.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.3806917125063393e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.938991290134762e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1994259590606208e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4631552696228, "timer/env.step_count": 2796.0, "timer/env.step_total": 247.71961569786072, "timer/env.step_frac": 0.24760493616689042, "timer/env.step_avg": 0.08859785969165261, "timer/env.step_min": 0.022674560546875, "timer/env.step_max": 3.454151153564453, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 11.049837827682495, "timer/replay._sample_frac": 0.011044722406298496, "timer/replay._sample_avg": 0.0004940020488055479, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.02861499786376953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3430.0, "timer/agent.policy_total": 55.63267660140991, "timer/agent.policy_frac": 0.055606921962475485, "timer/agent.policy_avg": 0.01621943924239356, "timer/agent.policy_min": 0.009398221969604492, "timer/agent.policy_max": 0.09424233436584473, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.15191006660461426, "timer/dataset_train_frac": 0.0001518397412283262, "timer/dataset_train_avg": 0.0001086624224639587, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010569095611572266, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 626.1034109592438, "timer/agent.train_frac": 0.625813562110151, "timer/agent.train_avg": 0.4478565171382287, "timer/agent.train_min": 0.43372631072998047, "timer/agent.train_max": 1.6847918033599854, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48058485984802246, "timer/agent.report_frac": 0.00048036237748156333, "timer/agent.report_avg": 0.24029242992401123, "timer/agent.report_min": 0.2346820831298828, "timer/agent.report_max": 0.24590277671813965, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1456683112857674e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.357350117371166}
{"step": 569328, "time": 26400.208133220673, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 569360, "time": 26402.877880573273, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 569408, "time": 26406.193631887436, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 569472, "time": 26409.797218561172, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 569800, "time": 26422.04547905922, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 569888, "time": 26426.998198986053, "episode/length": 360.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9916897506925207, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26432.881246328354, "episode/length": 76.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26455.358721017838, "eval_episode/length": 159.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.96875}
{"step": 570024, "time": 26457.074645996094, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 570024, "time": 26458.92605280876, "eval_episode/length": 167.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 570024, "time": 26461.896832227707, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 570024, "time": 26464.261893987656, "eval_episode/length": 212.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 570024, "time": 26466.149391889572, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 570024, "time": 26468.152458906174, "eval_episode/length": 223.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 570024, "time": 26475.01281642914, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 570304, "time": 26485.94667649269, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 570520, "time": 26494.33669424057, "episode/length": 144.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 570824, "time": 26506.127028942108, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 570984, "time": 26512.905249118805, "episode/length": 387.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 571216, "time": 26522.38385796547, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 571224, "time": 26524.04708456993, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 571472, "time": 26534.28630065918, "episode/length": 180.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 571688, "time": 26542.71130347252, "episode/length": 58.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 571816, "time": 26548.42685365677, "episode/length": 123.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 571880, "time": 26552.154258966446, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 571928, "time": 26555.399227142334, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 572192, "time": 26566.070046663284, "episode/length": 46.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 572312, "time": 26571.370404481888, "episode/length": 135.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 572592, "time": 26582.41301703453, "episode/length": 258.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 573088, "time": 26601.226885080338, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 573256, "time": 26608.180180311203, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 573792, "time": 26629.45399570465, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 573840, "time": 26632.61855173111, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 573896, "time": 26636.017394304276, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 574096, "time": 26644.363775730133, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 574160, "time": 26648.172315835953, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 574400, "time": 26657.676087856293, "episode/length": 142.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 574736, "time": 26670.330560445786, "episode/length": 267.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 575264, "time": 26689.516139268875, "episode/length": 170.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 575288, "time": 26691.698255062103, "episode/length": 274.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 575392, "time": 26696.997142791748, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 575504, "time": 26702.238528728485, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 576056, "time": 26721.994429826736, "episode/length": 206.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 576208, "time": 26728.804502487183, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 576336, "time": 26734.602004528046, "episode/length": 133.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 576376, "time": 26737.42787718773, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 576472, "time": 26742.21022248268, "episode/length": 288.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.972318339100346, "episode/intrinsic_return": 0.0}
{"step": 576664, "time": 26750.10266637802, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 576824, "time": 26756.981805086136, "episode/length": 55.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 576928, "time": 26762.300874471664, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9609756097560975, "episode/intrinsic_return": 0.0}
{"step": 577432, "time": 26781.003206968307, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 577968, "time": 26800.67182278633, "episode/length": 307.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 577984, "time": 26802.95082950592, "episode/length": 131.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 578000, "time": 26805.04142189026, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 578056, "time": 26808.28731560707, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 578120, "time": 26811.974443674088, "episode/length": 257.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 578224, "time": 26817.211508750916, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 579216, "time": 26851.668474197388, "episode/length": 123.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 579232, "time": 26853.736166238785, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 579336, "time": 26858.74793934822, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 579408, "time": 26862.98405480385, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 579568, "time": 26869.887362003326, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 579600, "time": 26872.53221464157, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 579664, "time": 26876.318578004837, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 26908.917645931244, "eval_episode/length": 153.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 580008, "time": 26911.361687898636, "eval_episode/length": 175.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 580008, "time": 26914.161249160767, "eval_episode/length": 189.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9631578947368421}
{"step": 580008, "time": 26916.47982597351, "eval_episode/length": 195.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 580008, "time": 26918.768270730972, "eval_episode/length": 200.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 580008, "time": 26918.811933994293, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 580008, "time": 26923.52577853203, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 580008, "time": 26926.833739995956, "eval_episode/length": 240.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.970954356846473}
{"step": 580504, "time": 26943.361181735992, "episode/length": 160.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 580728, "time": 26952.469623088837, "episode/length": 144.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 580920, "time": 26960.395907640457, "episode/length": 435.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 580952, "time": 26963.061323165894, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 581024, "time": 26967.19814682007, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 581264, "time": 26976.96974825859, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 581672, "time": 26993.260717391968, "episode/length": 282.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 581960, "time": 27004.258237600327, "episode/length": 294.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 582112, "time": 27011.115692138672, "episode/length": 200.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 582184, "time": 27014.742038965225, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 582432, "time": 27024.729935646057, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 582704, "time": 27036.18166732788, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 582832, "time": 27042.013737678528, "episode/length": 238.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 582864, "time": 27044.57073879242, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 583136, "time": 27055.072489500046, "episode/length": 182.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 583656, "time": 27073.681074619293, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 583696, "time": 27076.780738830566, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 583920, "time": 27085.77077102661, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 583960, "time": 27088.416340589523, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 584016, "time": 27092.107237815857, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 584184, "time": 27099.166460990906, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 584776, "time": 27120.38806772232, "episode/length": 238.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 584864, "time": 27125.130498170853, "episode/length": 105.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 585000, "time": 27131.213184833527, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 585224, "time": 27140.05598282814, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 585432, "time": 27148.63941025734, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 585544, "time": 27153.878888845444, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 585552, "time": 27156.161053180695, "episode/length": 301.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 585552, "time": 27156.169827461243, "episode/length": 170.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 586224, "time": 27181.710200548172, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 586472, "time": 27191.40688586235, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 586824, "time": 27204.606189012527, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 586984, "time": 27211.516799926758, "episode/length": 178.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 586992, "time": 27213.52701306343, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 587080, "time": 27217.982734680176, "episode/length": 276.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 587168, "time": 27222.931284427643, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 587416, "time": 27232.500526428223, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 587856, "time": 27248.893595457077, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 588576, "time": 27274.6290307045, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 588640, "time": 27278.448178768158, "episode/length": 206.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 588640, "time": 27278.455923318863, "episode/length": 205.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 588656, "time": 27282.36820626259, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 588792, "time": 27288.235493183136, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 588848, "time": 27291.944731473923, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 588880, "time": 27294.67957186699, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 589864, "time": 27329.99224615097, "episode/length": 122.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 589968, "time": 27335.513827323914, "episode/length": 263.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27361.15655398369, "eval_episode/length": 52.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 590096, "time": 27368.63380742073, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 590096, "time": 27370.855187177658, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 590096, "time": 27372.66592526436, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 590096, "time": 27377.76653122902, "eval_episode/length": 286.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9825783972125436}
{"step": 590096, "time": 27379.338231563568, "eval_episode/length": 234.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9872340425531915}
{"step": 590096, "time": 27381.061105251312, "eval_episode/length": 291.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9863013698630136}
{"step": 590096, "time": 27383.181465387344, "eval_episode/length": 303.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9868421052631579}
{"step": 590184, "time": 27385.884429454803, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 590185, "time": 27388.61334824562, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.15422987400141, "train/action_min": 0.0, "train/action_std": 2.997539993515588, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048206922871277744, "train/actor_opt_grad_steps": 36130.0, "train/actor_opt_loss": -3.3969222783370125, "train/adv_mag": 0.6440777198264473, "train/adv_max": 0.6102800685212129, "train/adv_mean": 0.0038709052201273807, "train/adv_min": -0.48620117651788813, "train/adv_std": 0.0681042310718755, "train/cont_avg": 0.9949703359962406, "train/cont_loss_mean": 0.00026349368046674454, "train/cont_loss_std": 0.00806693399772399, "train/cont_neg_acc": 0.9906385297125037, "train/cont_neg_loss": 0.037064958950113025, "train/cont_pos_acc": 0.9999631033804184, "train/cont_pos_loss": 0.00010289175512186907, "train/cont_pred": 0.9949651158841929, "train/cont_rate": 0.9949703359962406, "train/dyn_loss_mean": 13.316684192284606, "train/dyn_loss_std": 9.11593318881845, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8285654769804245, "train/extr_critic_critic_opt_grad_steps": 36130.0, "train/extr_critic_critic_opt_loss": 15710.32849212876, "train/extr_critic_mag": 6.182389212730236, "train/extr_critic_max": 6.182389212730236, "train/extr_critic_mean": 1.619607453059433, "train/extr_critic_min": -0.20318196859574855, "train/extr_critic_std": 1.3437644341834505, "train/extr_return_normed_mag": 1.7461670395126916, "train/extr_return_normed_max": 1.7461670395126916, "train/extr_return_normed_mean": 0.35433673881050337, "train/extr_return_normed_min": -0.13992491168411156, "train/extr_return_normed_std": 0.3234235526699769, "train/extr_return_rate": 0.7656309138563343, "train/extr_return_raw_mag": 7.575933929672815, "train/extr_return_raw_max": 7.575933929672815, "train/extr_return_raw_mean": 1.6361369755035056, "train/extr_return_raw_min": -0.47421443271905855, "train/extr_return_raw_std": 1.3806081051216985, "train/extr_reward_mag": 1.029602102767256, "train/extr_reward_max": 1.029602102767256, "train/extr_reward_mean": 0.03065322747776159, "train/extr_reward_min": -0.37169404137403445, "train/extr_reward_std": 0.16337364856013678, "train/image_loss_mean": 6.643089247825451, "train/image_loss_std": 11.173720894003273, "train/model_loss_mean": 14.686139594343372, "train/model_loss_std": 14.961952367223295, "train/model_opt_grad_norm": 62.17627210328073, "train/model_opt_grad_steps": 36097.65413533834, "train/model_opt_loss": 19659.64175575658, "train/model_opt_model_opt_grad_overflow": 0.007518796992481203, "train/model_opt_model_opt_grad_scale": 1334.5864661654136, "train/policy_entropy_mag": 2.602390590466951, "train/policy_entropy_max": 2.602390590466951, "train/policy_entropy_mean": 0.5126511799661737, "train/policy_entropy_min": 0.07937503863770262, "train/policy_entropy_std": 0.6130340717788926, "train/policy_logprob_mag": 7.4383836258622935, "train/policy_logprob_max": -0.009455658453411626, "train/policy_logprob_mean": -0.5117286076223043, "train/policy_logprob_min": -7.4383836258622935, "train/policy_logprob_std": 1.0804384050512672, "train/policy_randomness_mag": 0.9185296772117901, "train/policy_randomness_max": 0.9185296772117901, "train/policy_randomness_mean": 0.18094337031357272, "train/policy_randomness_min": 0.028015905304958944, "train/policy_randomness_std": 0.21637412524761113, "train/post_ent_mag": 58.97758790783416, "train/post_ent_max": 58.97758790783416, "train/post_ent_mean": 41.86701093401228, "train/post_ent_min": 19.99225782810297, "train/post_ent_std": 7.507602996395943, "train/prior_ent_mag": 68.13032887394267, "train/prior_ent_max": 68.13032887394267, "train/prior_ent_mean": 55.228501197987036, "train/prior_ent_min": 40.31095622356673, "train/prior_ent_std": 4.343401767257461, "train/rep_loss_mean": 13.316684192284606, "train/rep_loss_std": 9.11593318881845, "train/reward_avg": 0.025104264336589136, "train/reward_loss_mean": 0.05277649800580247, "train/reward_loss_std": 0.2456786524980588, "train/reward_max_data": 1.021052636598286, "train/reward_max_pred": 1.014322394715216, "train/reward_neg_acc": 0.9932926929086671, "train/reward_neg_loss": 0.027929110788649188, "train/reward_pos_acc": 0.9639067170315219, "train/reward_pos_loss": 0.8620958373062593, "train/reward_pred": 0.02434897579644856, "train/reward_rate": 0.029766799812030075, "train_stats/sum_log_reward": 7.225000074276557, "train_stats/max_log_achievement_collect_coal": 0.17307692307692307, "train_stats/max_log_achievement_collect_drink": 5.211538461538462, "train_stats/max_log_achievement_collect_sapling": 2.048076923076923, "train_stats/max_log_achievement_collect_stone": 2.875, "train_stats/max_log_achievement_collect_wood": 11.057692307692308, "train_stats/max_log_achievement_defeat_skeleton": 0.009615384615384616, "train_stats/max_log_achievement_defeat_zombie": 0.7692307692307693, "train_stats/max_log_achievement_eat_cow": 0.1346153846153846, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.5, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.9807692307692308, "train_stats/max_log_achievement_place_stone": 0.057692307692307696, "train_stats/max_log_achievement_place_table": 3.1826923076923075, "train_stats/max_log_achievement_wake_up": 1.1634615384615385, "train_stats/mean_log_entropy": 0.46297009103000164, "eval_stats/sum_log_reward": 6.641666571299235, "eval_stats/max_log_achievement_collect_coal": 0.16666666666666666, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "eval_stats/max_log_achievement_collect_stone": 1.8333333333333333, "eval_stats/max_log_achievement_collect_wood": 10.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.5833333333333335, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.16666666666666666, "eval_stats/max_log_achievement_place_table": 2.9583333333333335, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.5915738294534094e-07, "report/cont_loss_std": 7.001122867222875e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.411937647499144e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.354209354711202e-07, "report/cont_pred": 0.9960935115814209, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.239920616149902, "report/dyn_loss_std": 8.7284574508667, "report/image_loss_mean": 6.422366142272949, "report/image_loss_std": 9.20785140991211, "report/model_loss_mean": 14.418708801269531, "report/model_loss_std": 12.945405006408691, "report/post_ent_mag": 58.60556411743164, "report/post_ent_max": 58.60556411743164, "report/post_ent_mean": 41.55064392089844, "report/post_ent_min": 18.604877471923828, "report/post_ent_std": 7.7848052978515625, "report/prior_ent_mag": 67.68223571777344, "report/prior_ent_max": 67.68223571777344, "report/prior_ent_mean": 55.10137939453125, "report/prior_ent_min": 41.15447235107422, "report/prior_ent_std": 4.042757034301758, "report/rep_loss_mean": 13.239920616149902, "report/rep_loss_std": 8.7284574508667, "report/reward_avg": 0.02451171912252903, "report/reward_loss_mean": 0.05238994210958481, "report/reward_loss_std": 0.25756049156188965, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022878646850586, "report/reward_neg_acc": 0.9959757924079895, "report/reward_neg_loss": 0.029275042936205864, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8182636499404907, "report/reward_pred": 0.023426201194524765, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 6.018530984874815e-05, "eval/cont_loss_std": 0.0018567144870758057, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008686978369951248, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.071828005995485e-07, "eval/cont_pred": 0.9932210445404053, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 15.638568878173828, "eval/dyn_loss_std": 10.657974243164062, "eval/image_loss_mean": 10.525043487548828, "eval/image_loss_std": 14.942047119140625, "eval/model_loss_mean": 19.990646362304688, "eval/model_loss_std": 19.383094787597656, "eval/post_ent_mag": 56.96086883544922, "eval/post_ent_max": 56.96086883544922, "eval/post_ent_mean": 41.578369140625, "eval/post_ent_min": 19.926496505737305, "eval/post_ent_std": 7.775789737701416, "eval/prior_ent_mag": 67.68223571777344, "eval/prior_ent_max": 67.68223571777344, "eval/prior_ent_mean": 55.324134826660156, "eval/prior_ent_min": 37.556541442871094, "eval/prior_ent_std": 4.0758843421936035, "eval/rep_loss_mean": 15.638568878173828, "eval/rep_loss_std": 10.657974243164062, "eval/reward_avg": 0.02910156175494194, "eval/reward_loss_mean": 0.08240105211734772, "eval/reward_loss_std": 0.5253989100456238, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002377986907959, "eval/reward_neg_acc": 0.9989888072013855, "eval/reward_neg_loss": 0.023365678265690804, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 1.7505719661712646, "eval/reward_pred": 0.021092992275953293, "eval/reward_rate": 0.0341796875, "replay/size": 589681.0, "replay/inserts": 21216.0, "replay/samples": 21216.0, "replay/insert_wait_avg": 1.3766043326433966e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.128815448122326e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2398242406104797e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3218269348145, "timer/env.step_count": 2652.0, "timer/env.step_total": 239.17427229881287, "timer/env.step_frac": 0.23909732433979825, "timer/env.step_avg": 0.09018637718658103, "timer/env.step_min": 0.022874832153320312, "timer/env.step_max": 3.4110043048858643, "timer/replay._sample_count": 21216.0, "timer/replay._sample_total": 10.609225988388062, "timer/replay._sample_frac": 0.010605812752178811, "timer/replay._sample_avg": 0.000500057786028849, "timer/replay._sample_min": 0.00041675567626953125, "timer/replay._sample_max": 0.0352323055267334, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3528.0, "timer/agent.policy_total": 59.215519428253174, "timer/agent.policy_frac": 0.05919646841027285, "timer/agent.policy_avg": 0.016784444282384688, "timer/agent.policy_min": 0.009293794631958008, "timer/agent.policy_max": 0.11296582221984863, "timer/dataset_train_count": 1326.0, "timer/dataset_train_total": 0.1430983543395996, "timer/dataset_train_frac": 0.0001430523162511424, "timer/dataset_train_avg": 0.00010791731096500725, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0002741813659667969, "timer/agent.train_count": 1326.0, "timer/agent.train_total": 591.8425140380859, "timer/agent.train_frac": 0.5916521044548327, "timer/agent.train_avg": 0.4463367375852835, "timer/agent.train_min": 0.43346643447875977, "timer/agent.train_max": 1.552640438079834, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774482250213623, "timer/agent.report_frac": 0.00047729461875720423, "timer/agent.report_avg": 0.23872411251068115, "timer/agent.report_min": 0.23148679733276367, "timer/agent.report_max": 0.24596142768859863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.6253204345703125e-05, "timer/dataset_eval_frac": 4.6238323607745485e-08, "timer/dataset_eval_avg": 4.6253204345703125e-05, "timer/dataset_eval_min": 4.6253204345703125e-05, "timer/dataset_eval_max": 4.6253204345703125e-05, "fps": 21.208893978049858}
{"step": 590208, "time": 27389.307893037796, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 590256, "time": 27392.672863721848, "episode/length": 209.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 590448, "time": 27400.67706489563, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 590488, "time": 27403.380409240723, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 591176, "time": 27427.798582792282, "episode/length": 114.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9478260869565217, "episode/intrinsic_return": 0.0}
{"step": 591296, "time": 27433.4882979393, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 591320, "time": 27435.69128227234, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 591496, "time": 27443.049047231674, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 591512, "time": 27445.11558651924, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 591848, "time": 27458.067331314087, "episode/length": 398.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 592096, "time": 27468.068191051483, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 592784, "time": 27492.518971443176, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 592800, "time": 27494.566596508026, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 592864, "time": 27498.225001573563, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 592936, "time": 27502.21483850479, "episode/length": 310.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 593360, "time": 27518.147468566895, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 593424, "time": 27521.891202688217, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 593504, "time": 27526.10148882866, "episode/length": 175.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 593768, "time": 27536.084221839905, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 593840, "time": 27540.16681241989, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 593984, "time": 27546.66020679474, "episode/length": 147.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 594336, "time": 27560.026757717133, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 594432, "time": 27564.917667627335, "episode/length": 115.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 594776, "time": 27577.658199310303, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 595072, "time": 27589.22684264183, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 595312, "time": 27598.764016628265, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 595312, "time": 27598.7732629776, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 595856, "time": 27619.971660375595, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 595984, "time": 27625.94469833374, "episode/length": 276.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 596408, "time": 27641.294996738434, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 596472, "time": 27644.989953756332, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 596608, "time": 27651.304160118103, "episode/length": 397.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 596744, "time": 27657.255685567856, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 596976, "time": 27666.900325775146, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 597448, "time": 27683.960069179535, "episode/length": 58.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 597560, "time": 27689.18888568878, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 597840, "time": 27700.43090724945, "episode/length": 425.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 597984, "time": 27706.817341566086, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 598032, "time": 27711.59822368622, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 598096, "time": 27715.343556404114, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 598264, "time": 27722.319448709488, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 598352, "time": 27727.09737586975, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 599224, "time": 27757.14267063141, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 599464, "time": 27766.817169189453, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 599480, "time": 27768.85730934143, "episode/length": 253.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 599832, "time": 27782.031723737717, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 599896, "time": 27785.8229534626, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 600072, "time": 27793.23506140709, "episode/length": 214.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 27810.986147642136, "eval_episode/length": 62.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 600080, "time": 27814.991441488266, "eval_episode/length": 117.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9576271186440678}
{"step": 600080, "time": 27816.771428108215, "eval_episode/length": 57.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 600080, "time": 27821.810193777084, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 600080, "time": 27825.498015880585, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 600080, "time": 27827.45134949684, "eval_episode/length": 214.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 600080, "time": 27829.163526296616, "eval_episode/length": 216.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 600080, "time": 27831.542195796967, "eval_episode/length": 231.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 600408, "time": 27842.171766281128, "episode/length": 288.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 600456, "time": 27845.440294981003, "episode/length": 273.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 600824, "time": 27859.26738357544, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 601376, "time": 27879.595693588257, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 601480, "time": 27884.319564819336, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 601648, "time": 27893.25405573845, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 601824, "time": 27900.61180973053, "episode/length": 324.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 602096, "time": 27911.43246436119, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 602216, "time": 27916.721272468567, "episode/length": 225.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 602640, "time": 27932.470112085342, "episode/length": 272.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 603000, "time": 27945.827275276184, "episode/length": 271.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9889705882352942, "episode/intrinsic_return": 0.0}
{"step": 603104, "time": 27951.054396390915, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 603240, "time": 27956.888969659805, "episode/length": 219.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 603376, "time": 27963.169810533524, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 603384, "time": 27964.713163614273, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 603912, "time": 27983.72475552559, "episode/length": 211.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 604264, "time": 27997.0322535038, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 604992, "time": 28023.512122631073, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 605000, "time": 28025.225941181183, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 605120, "time": 28030.931928634644, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 605224, "time": 28035.707638025284, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 605368, "time": 28042.022665262222, "episode/length": 442.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 605584, "time": 28051.101150751114, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 605592, "time": 28052.74764585495, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 605712, "time": 28058.565024375916, "episode/length": 180.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 606016, "time": 28070.07639145851, "episode/length": 376.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 606512, "time": 28090.166412830353, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 606672, "time": 28097.283876895905, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 606792, "time": 28102.57213306427, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 606912, "time": 28108.498874902725, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 607168, "time": 28118.85304570198, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 607296, "time": 28124.703773975372, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 607320, "time": 28126.87429857254, "episode/length": 50.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 607456, "time": 28133.19835615158, "episode/length": 291.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 607680, "time": 28142.12836790085, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 608224, "time": 28161.75759100914, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 608256, "time": 28164.32920908928, "episode/length": 217.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 608560, "time": 28176.119718790054, "episode/length": 220.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9638009049773756, "episode/intrinsic_return": 0.0}
{"step": 608880, "time": 28188.48255085945, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 609008, "time": 28194.335973262787, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 609184, "time": 28201.6297852993, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 609344, "time": 28208.489107131958, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 609504, "time": 28215.353937387466, "episode/length": 39.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 609984, "time": 28232.868797063828, "episode/length": 219.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28257.213319063187, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 610064, "time": 28258.952681303024, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 610064, "time": 28261.2203373909, "eval_episode/length": 180.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.994475138121547}
{"step": 610064, "time": 28262.865529060364, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 610064, "time": 28262.87412238121, "eval_episode/length": 182.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 610064, "time": 28267.13004899025, "eval_episode/length": 201.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.995049504950495}
{"step": 610064, "time": 28269.378779649734, "eval_episode/length": 218.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 610064, "time": 28271.05020737648, "eval_episode/length": 222.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 610320, "time": 28279.494577407837, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 610480, "time": 28286.330764055252, "episode/length": 141.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 610576, "time": 28291.247785568237, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 610808, "time": 28300.667145729065, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 610920, "time": 28306.06231188774, "episode/length": 238.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 611096, "time": 28313.368671894073, "episode/length": 426.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 611472, "time": 28327.67216181755, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 612104, "time": 28350.07210278511, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 612192, "time": 28354.758915662766, "episode/length": 491.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 612280, "time": 28359.116765737534, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 612360, "time": 28363.514628648758, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 612536, "time": 28371.022584438324, "episode/length": 201.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 612696, "time": 28377.83088493347, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 612953, "time": 28389.096466064453, "train_stats/sum_log_reward": 7.300000143051148, "train_stats/max_log_achievement_collect_coal": 0.26666666666666666, "train_stats/max_log_achievement_collect_drink": 4.819047619047619, "train_stats/max_log_achievement_collect_sapling": 2.104761904761905, "train_stats/max_log_achievement_collect_stone": 2.8190476190476192, "train_stats/max_log_achievement_collect_wood": 11.723809523809523, "train_stats/max_log_achievement_defeat_skeleton": 0.02857142857142857, "train_stats/max_log_achievement_defeat_zombie": 0.8857142857142857, "train_stats/max_log_achievement_eat_cow": 0.0761904761904762, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0380952380952381, "train_stats/max_log_achievement_make_wood_pickaxe": 2.942857142857143, "train_stats/max_log_achievement_make_wood_sword": 0.0380952380952381, "train_stats/max_log_achievement_place_furnace": 0.05714285714285714, "train_stats/max_log_achievement_place_plant": 2.038095238095238, "train_stats/max_log_achievement_place_stone": 0.08571428571428572, "train_stats/max_log_achievement_place_table": 3.5142857142857142, "train_stats/max_log_achievement_wake_up": 1.2095238095238094, "train_stats/mean_log_entropy": 0.4804803422519139, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.221449731101452, "train/action_min": 0.0, "train/action_std": 3.177776559977464, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045435467393885196, "train/actor_opt_grad_steps": 37505.0, "train/actor_opt_loss": -5.2170774960811706, "train/adv_mag": 0.5941604440900642, "train/adv_max": 0.5651558990209875, "train/adv_mean": 0.0031439510869308257, "train/adv_min": -0.45710046694312295, "train/adv_std": 0.06526361298288258, "train/cont_avg": 0.994965889084507, "train/cont_loss_mean": 0.0002614453139032526, "train/cont_loss_std": 0.0075234207198373185, "train/cont_neg_acc": 0.9876089881003742, "train/cont_neg_loss": 0.037452347150984285, "train/cont_pos_acc": 0.9999723186795141, "train/cont_pos_loss": 0.00010854683578817855, "train/cont_pred": 0.9949646319302035, "train/cont_rate": 0.994965889084507, "train/dyn_loss_mean": 13.369114090019549, "train/dyn_loss_std": 9.126870847084152, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8218863959043798, "train/extr_critic_critic_opt_grad_steps": 37505.0, "train/extr_critic_critic_opt_loss": 15568.535032460388, "train/extr_critic_mag": 6.456751161897686, "train/extr_critic_max": 6.456751161897686, "train/extr_critic_mean": 1.69760142749464, "train/extr_critic_min": -0.18023934918390194, "train/extr_critic_std": 1.4051015767413126, "train/extr_return_normed_mag": 1.6927499116306575, "train/extr_return_normed_max": 1.6927499116306575, "train/extr_return_normed_mean": 0.3561995747223706, "train/extr_return_normed_min": -0.13347182669480082, "train/extr_return_normed_std": 0.32336359544539117, "train/extr_return_rate": 0.7665566676099536, "train/extr_return_raw_mag": 7.673311723789698, "train/extr_return_raw_max": 7.673311723789698, "train/extr_return_raw_mean": 1.711584319531078, "train/extr_return_raw_min": -0.47294017053406, "train/extr_return_raw_std": 1.4428384820340385, "train/extr_reward_mag": 1.0320381026872447, "train/extr_reward_max": 1.0320381026872447, "train/extr_reward_mean": 0.03205750404502934, "train/extr_reward_min": -0.3898752726299662, "train/extr_reward_std": 0.16692694276571274, "train/image_loss_mean": 6.828954941789869, "train/image_loss_std": 11.759600565467082, "train/model_loss_mean": 14.904592480458005, "train/model_loss_std": 15.49555239207308, "train/model_opt_grad_norm": 58.359966600444956, "train/model_opt_grad_steps": 37470.90140845071, "train/model_opt_loss": 14636.482972051057, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 981.5140845070423, "train/policy_entropy_mag": 2.5861492610313523, "train/policy_entropy_max": 2.5861492610313523, "train/policy_entropy_mean": 0.5136230951043922, "train/policy_entropy_min": 0.07937503968116263, "train/policy_entropy_std": 0.6212723964536694, "train/policy_logprob_mag": 7.438383656488338, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5136458556836759, "train/policy_logprob_min": -7.438383656488338, "train/policy_logprob_std": 1.0851297504465345, "train/policy_randomness_mag": 0.9127971991686754, "train/policy_randomness_max": 0.9127971991686754, "train/policy_randomness_mean": 0.18128641369477125, "train/policy_randomness_min": 0.028015905558328395, "train/policy_randomness_std": 0.21928189149205113, "train/post_ent_mag": 59.02893149684852, "train/post_ent_max": 59.02893149684852, "train/post_ent_mean": 41.9265534844197, "train/post_ent_min": 20.26747233431104, "train/post_ent_std": 7.557739244380468, "train/prior_ent_mag": 68.14366934333049, "train/prior_ent_max": 68.14366934333049, "train/prior_ent_mean": 55.33410870189398, "train/prior_ent_min": 40.30327138766437, "train/prior_ent_std": 4.381947760850611, "train/rep_loss_mean": 13.369114090019549, "train/rep_loss_std": 9.126870847084152, "train/reward_avg": 0.026019201082715267, "train/reward_loss_mean": 0.053907750843381376, "train/reward_loss_std": 0.24598753011562455, "train/reward_max_data": 1.0190140890403532, "train/reward_max_pred": 1.01308381305614, "train/reward_neg_acc": 0.9930318875212065, "train/reward_neg_loss": 0.029241941816790004, "train/reward_pos_acc": 0.9696666724245313, "train/reward_pos_loss": 0.8364732542508085, "train/reward_pred": 0.02542111648141708, "train/reward_rate": 0.030679192341549297, "eval_stats/sum_log_reward": 6.7874999940395355, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 1.0, "eval_stats/max_log_achievement_collect_wood": 12.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.1875, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.4392629661160754e-07, "report/cont_loss_std": 3.7028573842690093e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.3069191229296848e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.10575074990993e-07, "report/cont_pred": 0.9941405057907104, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.054244995117188, "report/dyn_loss_std": 8.507292747497559, "report/image_loss_mean": 5.886669635772705, "report/image_loss_std": 11.904840469360352, "report/model_loss_mean": 13.778085708618164, "report/model_loss_std": 15.22479248046875, "report/post_ent_mag": 61.00004196166992, "report/post_ent_max": 61.00004196166992, "report/post_ent_mean": 41.837398529052734, "report/post_ent_min": 20.825159072875977, "report/post_ent_std": 8.009967803955078, "report/prior_ent_mag": 67.9852294921875, "report/prior_ent_max": 67.9852294921875, "report/prior_ent_mean": 55.433143615722656, "report/prior_ent_min": 44.79627990722656, "report/prior_ent_std": 4.389047145843506, "report/rep_loss_mean": 13.054244995117188, "report/rep_loss_std": 8.507292747497559, "report/reward_avg": 0.02958984300494194, "report/reward_loss_mean": 0.05886906012892723, "report/reward_loss_std": 0.3505552113056183, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012705326080322, "report/reward_neg_acc": 0.9929220676422119, "report/reward_neg_loss": 0.03076135739684105, "report/reward_pos_acc": 0.9428571462631226, "report/reward_pos_loss": 0.8531123399734497, "report/reward_pred": 0.027911074459552765, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0008958173566497862, "eval/cont_loss_std": 0.028634794056415558, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.5307336879195645e-05, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0008991134236566722, "eval/cont_pred": 0.9955075979232788, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.99443244934082, "eval/dyn_loss_std": 10.451916694641113, "eval/image_loss_mean": 13.322028160095215, "eval/image_loss_std": 18.057891845703125, "eval/model_loss_mean": 24.214412689208984, "eval/model_loss_std": 22.30588150024414, "eval/post_ent_mag": 59.95665740966797, "eval/post_ent_max": 59.95665740966797, "eval/post_ent_mean": 39.934532165527344, "eval/post_ent_min": 21.994958877563477, "eval/post_ent_std": 7.298373699188232, "eval/prior_ent_mag": 67.9852294921875, "eval/prior_ent_max": 67.9852294921875, "eval/prior_ent_mean": 55.17876434326172, "eval/prior_ent_min": 40.92886734008789, "eval/prior_ent_std": 4.293095111846924, "eval/rep_loss_mean": 17.99443244934082, "eval/rep_loss_std": 10.451916694641113, "eval/reward_avg": 0.03583984449505806, "eval/reward_loss_mean": 0.09483128786087036, "eval/reward_loss_std": 0.522429883480072, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9998315572738647, "eval/reward_neg_acc": 0.9908350706100464, "eval/reward_neg_loss": 0.04208206757903099, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.3281584978103638, "eval/reward_pred": 0.02814711630344391, "eval/reward_rate": 0.041015625, "replay/size": 612449.0, "replay/inserts": 22768.0, "replay/samples": 22768.0, "replay/insert_wait_avg": 1.3716607887981145e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.190026757085482e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1831849485963256e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4675211906433, "timer/env.step_count": 2846.0, "timer/env.step_total": 243.49436593055725, "timer/env.step_frac": 0.2433805803518517, "timer/env.step_avg": 0.08555669920258512, "timer/env.step_min": 0.022877931594848633, "timer/env.step_max": 3.1949684619903564, "timer/replay._sample_count": 22768.0, "timer/replay._sample_total": 11.384420394897461, "timer/replay._sample_frac": 0.011379100424318634, "timer/replay._sample_avg": 0.000500018464287485, "timer/replay._sample_min": 0.0003943443298339844, "timer/replay._sample_max": 0.007397651672363281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3301.0, "timer/agent.policy_total": 54.28639578819275, "timer/agent.policy_frac": 0.05426102760795994, "timer/agent.policy_avg": 0.016445439499603982, "timer/agent.policy_min": 0.00924372673034668, "timer/agent.policy_max": 0.11899328231811523, "timer/dataset_train_count": 1423.0, "timer/dataset_train_total": 0.1552891731262207, "timer/dataset_train_frac": 0.0001552166060737415, "timer/dataset_train_avg": 0.00010912802046818039, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.00035071372985839844, "timer/agent.train_count": 1423.0, "timer/agent.train_total": 635.5167429447174, "timer/agent.train_frac": 0.6352197642442178, "timer/agent.train_avg": 0.4466034736083748, "timer/agent.train_min": 0.4307677745819092, "timer/agent.train_max": 1.9924039840698242, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48106837272644043, "timer/agent.report_frac": 0.0004808435681689369, "timer/agent.report_avg": 0.24053418636322021, "timer/agent.report_min": 0.23445653915405273, "timer/agent.report_max": 0.2466118335723877, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.383961749416009e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 22.757024861052486}
{"step": 613008, "time": 28391.004394054413, "episode/length": 335.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 613040, "time": 28393.69636940956, "episode/length": 62.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 613464, "time": 28409.061781406403, "episode/length": 147.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 613688, "time": 28418.33768939972, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 613848, "time": 28425.074127674103, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 614360, "time": 28443.64064359665, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 614736, "time": 28459.516976833344, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 614792, "time": 28462.666166305542, "episode/length": 117.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 614912, "time": 28468.46946454048, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 615184, "time": 28479.097811698914, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 615264, "time": 28483.28978419304, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 615440, "time": 28490.86221551895, "episode/length": 303.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 615488, "time": 28493.958015203476, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 616168, "time": 28517.81951904297, "episode/length": 433.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976958525345622, "episode/intrinsic_return": 0.0}
{"step": 616360, "time": 28525.77855682373, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 616688, "time": 28538.52289891243, "episode/length": 155.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 616696, "time": 28540.046862125397, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 616744, "time": 28543.445713043213, "episode/length": 297.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 616752, "time": 28545.570059776306, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 616784, "time": 28548.27558517456, "episode/length": 52.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 616832, "time": 28551.58049583435, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 617232, "time": 28566.472452163696, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 617480, "time": 28576.014256238937, "episode/length": 163.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 617848, "time": 28589.674823760986, "episode/length": 143.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 618104, "time": 28599.841406583786, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 618416, "time": 28612.322402715683, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 618616, "time": 28620.37240743637, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 619208, "time": 28641.712511062622, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 619440, "time": 28651.17626786232, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 619576, "time": 28657.18089389801, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 619600, "time": 28659.768083572388, "episode/length": 356.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 619800, "time": 28667.765080690384, "episode/length": 44.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 620000, "time": 28676.181339502335, "episode/length": 197.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28679.35271883011, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28699.167961597443, "eval_episode/length": 158.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 620048, "time": 28701.210701704025, "eval_episode/length": 170.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 620048, "time": 28704.112467765808, "eval_episode/length": 202.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 620048, "time": 28707.58930158615, "eval_episode/length": 247.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9717741935483871}
{"step": 620048, "time": 28709.331973791122, "eval_episode/length": 249.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.98}
{"step": 620048, "time": 28713.487268209457, "eval_episode/length": 154.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.967741935483871}
{"step": 620048, "time": 28716.06796145439, "eval_episode/length": 334.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9880597014925373}
{"step": 620048, "time": 28717.756129026413, "eval_episode/length": 339.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9823529411764705}
{"step": 620240, "time": 28725.663674354553, "episode/length": 435.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 620496, "time": 28735.888506650925, "episode/length": 111.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 620960, "time": 28752.739767074585, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 621256, "time": 28763.763063907623, "episode/length": 181.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 621296, "time": 28766.87508416176, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 621296, "time": 28766.882653474808, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 621320, "time": 28770.849291086197, "episode/length": 263.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 621888, "time": 28791.30456852913, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 622232, "time": 28803.953969717026, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 622344, "time": 28809.421333789825, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 622392, "time": 28812.984259605408, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 622832, "time": 28831.776573181152, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 622952, "time": 28837.886575460434, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 623424, "time": 28855.748530626297, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 623464, "time": 28858.383541345596, "episode/length": 275.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 623528, "time": 28862.12775373459, "episode/length": 278.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 623728, "time": 28870.64982175827, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 623760, "time": 28873.194538593292, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 623896, "time": 28879.060492277145, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 624488, "time": 28900.433651208878, "episode/length": 206.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 625208, "time": 28925.977955579758, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 625272, "time": 28929.61847758293, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 625296, "time": 28932.288668632507, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 625392, "time": 28937.07696914673, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 625520, "time": 28942.730462789536, "episode/length": 320.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 625752, "time": 28951.720883846283, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 625824, "time": 28956.09610271454, "episode/length": 286.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9721254355400697, "episode/intrinsic_return": 0.0}
{"step": 626568, "time": 28981.937692642212, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 626888, "time": 28994.219328403473, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 626968, "time": 28998.439826250076, "episode/length": 208.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 627176, "time": 29007.024015665054, "episode/length": 335.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 627456, "time": 29018.04144883156, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 627688, "time": 29027.207686662674, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 627800, "time": 29032.553960084915, "episode/length": 300.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 628016, "time": 29041.43321967125, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 628112, "time": 29046.209732055664, "episode/length": 362.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 628416, "time": 29057.77309012413, "episode/length": 49.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 628736, "time": 29069.911734580994, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 628864, "time": 29075.818840503693, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 629056, "time": 29083.74951672554, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 629080, "time": 29085.920489788055, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 629168, "time": 29090.839464187622, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 629392, "time": 29099.853939056396, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 29138.192045211792, "eval_episode/length": 58.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 630032, "time": 29143.899822473526, "eval_episode/length": 154.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 630032, "time": 29145.649054288864, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 630032, "time": 29148.487416028976, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 630032, "time": 29150.750144958496, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 630032, "time": 29153.092908859253, "eval_episode/length": 221.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 630032, "time": 29154.848686933517, "eval_episode/length": 226.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 630032, "time": 29154.856728553772, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 630176, "time": 29159.602826595306, "episode/length": 296.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 630200, "time": 29161.86336183548, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 630376, "time": 29169.328209638596, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 630480, "time": 29174.451768159866, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 630728, "time": 29183.969787836075, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 630808, "time": 29189.76679611206, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 630992, "time": 29197.998576641083, "episode/length": 199.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 631848, "time": 29227.575922250748, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 631904, "time": 29231.210938692093, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 632048, "time": 29237.56112265587, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 632048, "time": 29237.569759845734, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 632312, "time": 29249.794003009796, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 632400, "time": 29254.532673358917, "episode/length": 457.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9978165938864629, "episode/intrinsic_return": 0.0}
{"step": 632632, "time": 29263.739874601364, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 632672, "time": 29266.85094642639, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 633776, "time": 29304.95923614502, "episode/length": 182.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 633784, "time": 29306.582900762558, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 633792, "time": 29308.649347305298, "episode/length": 217.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 633904, "time": 29314.1958026886, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 633944, "time": 29316.912169218063, "episode/length": 192.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 634000, "time": 29320.63023042679, "episode/length": 261.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 634088, "time": 29324.914561748505, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 634448, "time": 29338.60953116417, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 634576, "time": 29344.443771362305, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 634920, "time": 29357.27331161499, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 635168, "time": 29367.24763894081, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 635264, "time": 29372.016009807587, "episode/length": 164.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 635264, "time": 29372.024329185486, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 635352, "time": 29378.21933865547, "episode/length": 196.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 635609, "time": 29389.2036986351, "train_stats/sum_log_reward": 7.335849195156458, "train_stats/max_log_achievement_collect_coal": 0.2169811320754717, "train_stats/max_log_achievement_collect_drink": 4.5, "train_stats/max_log_achievement_collect_sapling": 2.1037735849056602, "train_stats/max_log_achievement_collect_stone": 3.292452830188679, "train_stats/max_log_achievement_collect_wood": 10.754716981132075, "train_stats/max_log_achievement_defeat_skeleton": 0.018867924528301886, "train_stats/max_log_achievement_defeat_zombie": 0.7264150943396226, "train_stats/max_log_achievement_eat_cow": 0.05660377358490566, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.03773584905660377, "train_stats/max_log_achievement_make_stone_sword": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_pickaxe": 2.339622641509434, "train_stats/max_log_achievement_make_wood_sword": 0.018867924528301886, "train_stats/max_log_achievement_place_furnace": 0.08490566037735849, "train_stats/max_log_achievement_place_plant": 2.0943396226415096, "train_stats/max_log_achievement_place_stone": 0.3584905660377358, "train_stats/max_log_achievement_place_table": 3.150943396226415, "train_stats/max_log_achievement_wake_up": 1.1981132075471699, "train_stats/mean_log_entropy": 0.5176491945419671, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.171936900903147, "train/action_min": 0.0, "train/action_std": 3.1480145860225597, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04536269377943472, "train/actor_opt_grad_steps": 38920.0, "train/actor_opt_loss": -2.8833441572620515, "train/adv_mag": 0.5757752938050751, "train/adv_max": 0.5546742533961087, "train/adv_mean": 0.0032347233914764508, "train/adv_min": -0.43738432640724995, "train/adv_std": 0.0646376612972706, "train/cont_avg": 0.9948747783687943, "train/cont_loss_mean": 0.00015232171333311065, "train/cont_loss_std": 0.004560537001760357, "train/cont_neg_acc": 0.9952718683168398, "train/cont_neg_loss": 0.009277407603981406, "train/cont_pos_acc": 0.9999721198217243, "train/cont_pos_loss": 0.00010616434991932008, "train/cont_pred": 0.9948555209957961, "train/cont_rate": 0.9948747783687943, "train/dyn_loss_mean": 13.214659859948124, "train/dyn_loss_std": 9.167033865096721, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8052401584936372, "train/extr_critic_critic_opt_grad_steps": 38920.0, "train/extr_critic_critic_opt_loss": 15341.96068123892, "train/extr_critic_mag": 6.4505280704363015, "train/extr_critic_max": 6.4505280704363015, "train/extr_critic_mean": 1.672857623573736, "train/extr_critic_min": -0.18459612849756335, "train/extr_critic_std": 1.3629399432358167, "train/extr_return_normed_mag": 1.702410934664679, "train/extr_return_normed_max": 1.702410934664679, "train/extr_return_normed_mean": 0.3524958990144391, "train/extr_return_normed_min": -0.13652630567762022, "train/extr_return_normed_std": 0.3192082380360745, "train/extr_return_rate": 0.7833698497596362, "train/extr_return_raw_mag": 7.590206754968522, "train/extr_return_raw_max": 7.590206754968522, "train/extr_return_raw_mean": 1.6869888394436938, "train/extr_return_raw_min": -0.4513466050650211, "train/extr_return_raw_std": 1.395765687979705, "train/extr_reward_mag": 1.0332655061221292, "train/extr_reward_max": 1.0332655061221292, "train/extr_reward_mean": 0.03172136890100883, "train/extr_reward_min": -0.3551922284119518, "train/extr_reward_std": 0.16647854146171123, "train/image_loss_mean": 6.706958828242958, "train/image_loss_std": 11.366668931135894, "train/model_loss_mean": 14.689024113594218, "train/model_loss_std": 15.129142348647964, "train/model_opt_grad_norm": 58.15802319844564, "train/model_opt_grad_steps": 38884.87234042553, "train/model_opt_loss": 16872.57031596299, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1148.049645390071, "train/policy_entropy_mag": 2.5858786917747336, "train/policy_entropy_max": 2.5858786917747336, "train/policy_entropy_mean": 0.5286950904426845, "train/policy_entropy_min": 0.07937503336591924, "train/policy_entropy_std": 0.6231716158964955, "train/policy_logprob_mag": 7.4383836671815695, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5293134332548642, "train/policy_logprob_min": -7.4383836671815695, "train/policy_logprob_std": 1.1000856740254883, "train/policy_randomness_mag": 0.9127016997506433, "train/policy_randomness_max": 0.9127016997506433, "train/policy_randomness_mean": 0.18660616473103245, "train/policy_randomness_min": 0.02801590345482877, "train/policy_randomness_std": 0.21995223287149523, "train/post_ent_mag": 59.346832221281446, "train/post_ent_max": 59.346832221281446, "train/post_ent_mean": 42.154545669014574, "train/post_ent_min": 20.304224176609768, "train/post_ent_std": 7.6401003573803195, "train/prior_ent_mag": 68.12871118640223, "train/prior_ent_max": 68.12871118640223, "train/prior_ent_mean": 55.43182037569952, "train/prior_ent_min": 40.27511134046189, "train/prior_ent_std": 4.403787041386814, "train/rep_loss_mean": 13.214659859948124, "train/rep_loss_std": 9.167033865096721, "train/reward_avg": 0.026054133211942852, "train/reward_loss_mean": 0.053117076199211126, "train/reward_loss_std": 0.23829621404198045, "train/reward_max_data": 1.0198581607629222, "train/reward_max_pred": 1.0134370986451493, "train/reward_neg_acc": 0.9933333878821515, "train/reward_neg_loss": 0.028528318595114753, "train/reward_pos_acc": 0.9711008274808843, "train/reward_pos_loss": 0.8328734200896947, "train/reward_pred": 0.02536717473350941, "train/reward_rate": 0.030695921985815604, "eval_stats/sum_log_reward": 7.537500083446503, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 3.5625, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 3.375, "eval_stats/max_log_achievement_collect_wood": 11.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.25, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.173650161945261e-06, "report/cont_loss_std": 1.3154831322026439e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000156129477545619, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.659800876856025e-07, "report/cont_pred": 0.9960939288139343, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.98503589630127, "report/dyn_loss_std": 9.05038833618164, "report/image_loss_mean": 5.58873176574707, "report/image_loss_std": 11.486517906188965, "report/model_loss_mean": 13.416034698486328, "report/model_loss_std": 15.318865776062012, "report/post_ent_mag": 63.33597183227539, "report/post_ent_max": 63.33597183227539, "report/post_ent_mean": 41.77001953125, "report/post_ent_min": 19.889904022216797, "report/post_ent_std": 7.6406941413879395, "report/prior_ent_mag": 68.73405456542969, "report/prior_ent_max": 68.73405456542969, "report/prior_ent_mean": 55.22900390625, "report/prior_ent_min": 41.58424758911133, "report/prior_ent_std": 4.283002853393555, "report/rep_loss_mean": 12.98503589630127, "report/rep_loss_std": 9.05038833618164, "report/reward_avg": 0.02470703050494194, "report/reward_loss_mean": 0.03627972677350044, "report/reward_loss_std": 0.1659736931324005, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009799003601074, "report/reward_neg_acc": 0.9989949464797974, "report/reward_neg_loss": 0.015123856253921986, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.762144923210144, "report/reward_pred": 0.023752082139253616, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.1574058994010556e-06, "eval/cont_loss_std": 7.962105155456811e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012904958566650748, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.381528123711178e-07, "eval/cont_pred": 0.9980488419532776, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.02128028869629, "eval/dyn_loss_std": 10.316643714904785, "eval/image_loss_mean": 9.755138397216797, "eval/image_loss_std": 15.916629791259766, "eval/model_loss_mean": 20.062152862548828, "eval/model_loss_std": 20.0383243560791, "eval/post_ent_mag": 58.39313507080078, "eval/post_ent_max": 58.39313507080078, "eval/post_ent_mean": 40.302574157714844, "eval/post_ent_min": 20.538406372070312, "eval/post_ent_std": 7.667536735534668, "eval/prior_ent_mag": 68.73405456542969, "eval/prior_ent_max": 68.73405456542969, "eval/prior_ent_mean": 55.56571960449219, "eval/prior_ent_min": 42.252159118652344, "eval/prior_ent_std": 3.729440450668335, "eval/rep_loss_mean": 17.02128028869629, "eval/rep_loss_std": 10.316643714904785, "eval/reward_avg": 0.03701172024011612, "eval/reward_loss_mean": 0.0942450612783432, "eval/reward_loss_std": 0.5875945091247559, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020790100097656, "eval/reward_neg_acc": 0.9928862452507019, "eval/reward_neg_loss": 0.025101695209741592, "eval/reward_pos_acc": 0.824999988079071, "eval/reward_pos_loss": 1.7951719760894775, "eval/reward_pred": 0.02848329208791256, "eval/reward_rate": 0.0390625, "replay/size": 635105.0, "replay/inserts": 22656.0, "replay/samples": 22656.0, "replay/insert_wait_avg": 1.3964261207203407e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.229669799912447e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.155878080472324e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0937676429749, "timer/env.step_count": 2832.0, "timer/env.step_total": 247.35591292381287, "timer/env.step_frac": 0.2473327211175231, "timer/env.step_avg": 0.08734318959174184, "timer/env.step_min": 0.023139476776123047, "timer/env.step_max": 3.77227783203125, "timer/replay._sample_count": 22656.0, "timer/replay._sample_total": 11.30915093421936, "timer/replay._sample_frac": 0.011308090601217138, "timer/replay._sample_avg": 0.0004991680320541738, "timer/replay._sample_min": 0.00037932395935058594, "timer/replay._sample_max": 0.028539657592773438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3399.0, "timer/agent.policy_total": 55.003307819366455, "timer/agent.policy_frac": 0.05499815077240055, "timer/agent.policy_avg": 0.01618220294773947, "timer/agent.policy_min": 0.009418964385986328, "timer/agent.policy_max": 0.09916925430297852, "timer/dataset_train_count": 1416.0, "timer/dataset_train_total": 0.15431690216064453, "timer/dataset_train_frac": 0.00015430243358514198, "timer/dataset_train_avg": 0.00010898086310779981, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.00047516822814941406, "timer/agent.train_count": 1416.0, "timer/agent.train_total": 630.8654408454895, "timer/agent.train_frac": 0.63080629162635, "timer/agent.train_avg": 0.4455264412750632, "timer/agent.train_min": 0.4332585334777832, "timer/agent.train_max": 1.6098244190216064, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48248791694641113, "timer/agent.report_frac": 0.0004824426794334902, "timer/agent.report_avg": 0.24124395847320557, "timer/agent.report_min": 0.23596835136413574, "timer/agent.report_max": 0.2465195655822754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075311305717605e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.653573175568418}
{"step": 635800, "time": 29395.390787363052, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 635888, "time": 29400.059361696243, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 636048, "time": 29406.91693520546, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 636104, "time": 29410.081233263016, "episode/length": 262.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 637080, "time": 29443.956652879715, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 637112, "time": 29446.738691091537, "episode/length": 242.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 637144, "time": 29449.327829360962, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 637256, "time": 29454.54627752304, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 637320, "time": 29458.25612616539, "episode/length": 151.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 637520, "time": 29466.72047185898, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 637792, "time": 29477.14971590042, "episode/length": 304.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 638048, "time": 29487.181281089783, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 638360, "time": 29498.9905731678, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 638784, "time": 29514.72285580635, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 639000, "time": 29524.703406333923, "episode/length": 231.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 639000, "time": 29524.71083688736, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 639048, "time": 29529.723959684372, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 639328, "time": 29540.924461841583, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 639832, "time": 29558.98481798172, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 29586.080319166183, "eval_episode/length": 152.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 640016, "time": 29588.208854198456, "eval_episode/length": 165.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 640016, "time": 29590.281002759933, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 640016, "time": 29594.82952284813, "eval_episode/length": 201.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 640016, "time": 29597.164355039597, "eval_episode/length": 219.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 640016, "time": 29598.915180444717, "eval_episode/length": 225.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 640016, "time": 29603.448712825775, "eval_episode/length": 295.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9797297297297297}
{"step": 640016, "time": 29605.983834266663, "eval_episode/length": 318.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9937304075235109}
{"step": 640312, "time": 29615.647922754288, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 640496, "time": 29623.554712295532, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 640496, "time": 29623.561672449112, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 640560, "time": 29629.024223327637, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 640776, "time": 29637.623330116272, "episode/length": 406.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9901719901719902, "episode/intrinsic_return": 0.0}
{"step": 641032, "time": 29647.758773565292, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 641040, "time": 29649.791610240936, "episode/length": 373.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 641064, "time": 29651.971663951874, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 641496, "time": 29667.77588415146, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 642176, "time": 29692.20792579651, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 642288, "time": 29697.544098615646, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 642392, "time": 29702.32122015953, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 642504, "time": 29707.85523223877, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 642576, "time": 29712.0397939682, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 642656, "time": 29716.133843898773, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 642952, "time": 29727.214813947678, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 642984, "time": 29730.37801384926, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 643184, "time": 29739.332062721252, "episode/length": 327.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 643352, "time": 29746.411576986313, "episode/length": 49.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 643688, "time": 29759.182839155197, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 644016, "time": 29772.232422351837, "episode/length": 229.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9869565217391304, "episode/intrinsic_return": 0.0}
{"step": 644200, "time": 29779.77303814888, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 644448, "time": 29789.871963262558, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 644664, "time": 29798.345223903656, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693486590038314, "episode/intrinsic_return": 0.0}
{"step": 644960, "time": 29809.9524435997, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 645184, "time": 29819.04046201706, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 645408, "time": 29828.335509300232, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 645512, "time": 29833.10856819153, "episode/length": 290.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 645728, "time": 29842.034016609192, "episode/length": 383.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 645736, "time": 29843.63817715645, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 646072, "time": 29856.50097513199, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 646128, "time": 29860.123955488205, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 646400, "time": 29870.673500299454, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 646712, "time": 29882.384162425995, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 647072, "time": 29896.16736650467, "episode/length": 167.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 647208, "time": 29903.55307507515, "episode/length": 280.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 647240, "time": 29906.299998760223, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 647376, "time": 29912.567955970764, "episode/length": 245.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 647912, "time": 29931.883195400238, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 647960, "time": 29934.9371175766, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 648240, "time": 29945.87438893318, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 648616, "time": 29959.677468299866, "episode/length": 46.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 648648, "time": 29962.28882598877, "episode/length": 175.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 648664, "time": 29964.44446206093, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 648696, "time": 29967.065800189972, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 648768, "time": 29971.257159471512, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 649328, "time": 29991.431082963943, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 30030.752910137177, "eval_episode/length": 53.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9074074074074074}
{"step": 650000, "time": 30037.348967552185, "eval_episode/length": 166.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 650000, "time": 30041.17338037491, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 650000, "time": 30043.064700126648, "eval_episode/length": 57.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 650000, "time": 30047.57593345642, "eval_episode/length": 289.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9862068965517241}
{"step": 650000, "time": 30049.80179476738, "eval_episode/length": 248.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 650000, "time": 30051.814040660858, "eval_episode/length": 312.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9840255591054313}
{"step": 650000, "time": 30054.357267141342, "eval_episode/length": 336.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9940652818991098}
{"step": 650192, "time": 30060.689386367798, "episode/length": 278.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 650200, "time": 30062.296071767807, "episode/length": 178.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 650272, "time": 30066.73484802246, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 650368, "time": 30071.57319188118, "episode/length": 411.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 650456, "time": 30075.892518043518, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 650632, "time": 30083.296728610992, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 650816, "time": 30091.16504740715, "episode/length": 274.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 651552, "time": 30117.04350733757, "episode/length": 362.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 651712, "time": 30123.824430704117, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 651752, "time": 30126.60546183586, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 651864, "time": 30131.846614599228, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 652120, "time": 30141.813441753387, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 652160, "time": 30145.097273111343, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 652472, "time": 30156.790719270706, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 652568, "time": 30161.515959739685, "episode/length": 55.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 652800, "time": 30171.310191631317, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 652960, "time": 30178.22018289566, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 653024, "time": 30181.87764954567, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 653120, "time": 30186.719151496887, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 653344, "time": 30195.649465560913, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 653920, "time": 30216.472423553467, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 654008, "time": 30220.688992500305, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 654216, "time": 30229.13848400116, "episode/length": 136.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 654296, "time": 30233.367096185684, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 654320, "time": 30236.13025689125, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 654520, "time": 30244.14244580269, "episode/length": 194.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 654552, "time": 30246.900315523148, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 655192, "time": 30269.570759534836, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 655720, "time": 30290.463285446167, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 656000, "time": 30301.885729312897, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 656032, "time": 30304.56776547432, "episode/length": 252.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 656664, "time": 30327.332610845566, "episode/length": 342.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 656728, "time": 30331.097904920578, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 656952, "time": 30340.412310123444, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 657016, "time": 30344.055951595306, "episode/length": 336.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 657144, "time": 30349.918796539307, "episode/length": 138.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 657296, "time": 30356.673486471176, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 657768, "time": 30373.764200925827, "episode/length": 220.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 657880, "time": 30379.570556640625, "episode/length": 415.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 657960, "time": 30383.7776055336, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 658057, "time": 30389.506231069565, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.381443754155585, "train/action_min": 0.0, "train/action_std": 3.3490222092215896, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04759654270630356, "train/actor_opt_grad_steps": 40330.0, "train/actor_opt_loss": 5.7129865273773826, "train/adv_mag": 0.6104065566620929, "train/adv_max": 0.5764127168672305, "train/adv_mean": 0.005308056938592411, "train/adv_min": -0.46223264848086854, "train/adv_std": 0.06800549429781894, "train/cont_avg": 0.9945215536347518, "train/cont_loss_mean": 0.0002962392082419315, "train/cont_loss_std": 0.009105406895173473, "train/cont_neg_acc": 0.9863163059484874, "train/cont_neg_loss": 0.04402173494758025, "train/cont_pos_acc": 0.9999860288403558, "train/cont_pos_loss": 5.2919402774734734e-05, "train/cont_pred": 0.9945783847612693, "train/cont_rate": 0.9945215536347518, "train/dyn_loss_mean": 13.208283180886127, "train/dyn_loss_std": 9.080276888313023, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8730589197882523, "train/extr_critic_critic_opt_grad_steps": 40330.0, "train/extr_critic_critic_opt_loss": 15713.323262965425, "train/extr_critic_mag": 6.597037927478763, "train/extr_critic_max": 6.597037927478763, "train/extr_critic_mean": 1.8650922969723425, "train/extr_critic_min": -0.20382111038722045, "train/extr_critic_std": 1.3992278330714991, "train/extr_return_normed_mag": 1.7175486527436168, "train/extr_return_normed_max": 1.7175486527436168, "train/extr_return_normed_mean": 0.38696395547677437, "train/extr_return_normed_min": -0.15820798325411817, "train/extr_return_normed_std": 0.32463545177845243, "train/extr_return_rate": 0.8239819255281002, "train/extr_return_raw_mag": 7.773982683817546, "train/extr_return_raw_max": 7.773982683817546, "train/extr_return_raw_mean": 1.8886130346474073, "train/extr_return_raw_min": -0.5242363163765441, "train/extr_return_raw_std": 1.4361907176092161, "train/extr_reward_mag": 1.0309285475007186, "train/extr_reward_max": 1.0309285475007186, "train/extr_reward_mean": 0.034449573698724416, "train/extr_reward_min": -0.41559859793236914, "train/extr_reward_std": 0.17269584060983456, "train/image_loss_mean": 6.518903184444346, "train/image_loss_std": 11.518240461958216, "train/model_loss_mean": 14.501023008468303, "train/model_loss_std": 15.222334482991103, "train/model_opt_grad_norm": 57.216177825386644, "train/model_opt_grad_steps": 40293.32624113475, "train/model_opt_loss": 12077.084528064051, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 828.9007092198582, "train/policy_entropy_mag": 2.5482012380099466, "train/policy_entropy_max": 2.5482012380099466, "train/policy_entropy_mean": 0.5580827274643783, "train/policy_entropy_min": 0.07937503119943835, "train/policy_entropy_std": 0.6447498612370052, "train/policy_logprob_mag": 7.43838362321786, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5580264784342853, "train/policy_logprob_min": -7.43838362321786, "train/policy_logprob_std": 1.1168041072838695, "train/policy_randomness_mag": 0.899403211918283, "train/policy_randomness_max": 0.899403211918283, "train/policy_randomness_mean": 0.19697871413213988, "train/policy_randomness_min": 0.028015902596162566, "train/policy_randomness_std": 0.22756840848753637, "train/post_ent_mag": 58.96830665642488, "train/post_ent_max": 58.96830665642488, "train/post_ent_mean": 42.0268163207575, "train/post_ent_min": 20.278117213688844, "train/post_ent_std": 7.543579077889733, "train/prior_ent_mag": 68.16711809956436, "train/prior_ent_max": 68.16711809956436, "train/prior_ent_mean": 55.289310563540624, "train/prior_ent_min": 39.96268076254121, "train/prior_ent_std": 4.402380365006467, "train/rep_loss_mean": 13.208283180886127, "train/rep_loss_std": 9.080276888313023, "train/reward_avg": 0.028064051233496225, "train/reward_loss_mean": 0.05685369297862053, "train/reward_loss_std": 0.2580096408830467, "train/reward_max_data": 1.0219858208446637, "train/reward_max_pred": 1.0149506491126743, "train/reward_neg_acc": 0.992799478642484, "train/reward_neg_loss": 0.02963536282908832, "train/reward_pos_acc": 0.9666573223492778, "train/reward_pos_loss": 0.8579689640525385, "train/reward_pred": 0.027331298349279883, "train/reward_rate": 0.0329260859929078, "train_stats/sum_log_reward": 7.835849201904153, "train_stats/max_log_achievement_collect_coal": 0.3113207547169811, "train_stats/max_log_achievement_collect_drink": 3.8679245283018866, "train_stats/max_log_achievement_collect_sapling": 1.8773584905660377, "train_stats/max_log_achievement_collect_stone": 4.9245283018867925, "train_stats/max_log_achievement_collect_wood": 10.867924528301886, "train_stats/max_log_achievement_defeat_skeleton": 0.009433962264150943, "train_stats/max_log_achievement_defeat_zombie": 0.6226415094339622, "train_stats/max_log_achievement_eat_cow": 0.04716981132075472, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0660377358490566, "train_stats/max_log_achievement_make_stone_sword": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_pickaxe": 2.4339622641509435, "train_stats/max_log_achievement_make_wood_sword": 0.16037735849056603, "train_stats/max_log_achievement_place_furnace": 0.07547169811320754, "train_stats/max_log_achievement_place_plant": 1.849056603773585, "train_stats/max_log_achievement_place_stone": 2.7641509433962264, "train_stats/max_log_achievement_place_table": 3.2358490566037736, "train_stats/max_log_achievement_wake_up": 1.0188679245283019, "train_stats/mean_log_entropy": 0.6083159428441299, "eval_stats/sum_log_reward": 7.4750000685453415, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 4.625, "eval_stats/max_log_achievement_collect_wood": 10.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.5, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 3.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.3041407075652387e-06, "report/cont_loss_std": 3.4207965654786676e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.441173273837194e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2608776362176286e-06, "report/cont_pred": 0.9980446696281433, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 15.778693199157715, "report/dyn_loss_std": 9.02584457397461, "report/image_loss_mean": 6.251873970031738, "report/image_loss_std": 12.336799621582031, "report/model_loss_mean": 15.764787673950195, "report/model_loss_std": 15.80403995513916, "report/post_ent_mag": 55.63194274902344, "report/post_ent_max": 55.63194274902344, "report/post_ent_mean": 39.24567794799805, "report/post_ent_min": 19.086034774780273, "report/post_ent_std": 7.076961040496826, "report/prior_ent_mag": 67.99439239501953, "report/prior_ent_max": 67.99439239501953, "report/prior_ent_mean": 55.287662506103516, "report/prior_ent_min": 41.674503326416016, "report/prior_ent_std": 3.908292055130005, "report/rep_loss_mean": 15.778693199157715, "report/rep_loss_std": 9.02584457397461, "report/reward_avg": 0.02910156175494194, "report/reward_loss_mean": 0.04569657891988754, "report/reward_loss_std": 0.2205752730369568, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0081830024719238, "report/reward_neg_acc": 0.9919273257255554, "report/reward_neg_loss": 0.016981156542897224, "report/reward_pos_acc": 0.939393937587738, "report/reward_pos_loss": 0.9080294370651245, "report/reward_pred": 0.026519082486629486, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.852599911624566e-05, "eval/cont_loss_std": 0.0011882937978953123, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0077412002719938755, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.307404530365602e-07, "eval/cont_pred": 0.995153546333313, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.051475524902344, "eval/dyn_loss_std": 10.32249927520752, "eval/image_loss_mean": 15.280817031860352, "eval/image_loss_std": 20.587257385253906, "eval/model_loss_mean": 26.790283203125, "eval/model_loss_std": 24.11585235595703, "eval/post_ent_mag": 57.1911506652832, "eval/post_ent_max": 57.1911506652832, "eval/post_ent_mean": 39.275203704833984, "eval/post_ent_min": 21.504026412963867, "eval/post_ent_std": 7.700749397277832, "eval/prior_ent_mag": 67.99439239501953, "eval/prior_ent_max": 67.99439239501953, "eval/prior_ent_mean": 55.85813903808594, "eval/prior_ent_min": 41.76848602294922, "eval/prior_ent_std": 3.681117057800293, "eval/rep_loss_mean": 19.051475524902344, "eval/rep_loss_std": 10.32249927520752, "eval/reward_avg": 0.02988281287252903, "eval/reward_loss_mean": 0.07854419201612473, "eval/reward_loss_std": 0.3968416154384613, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0058636665344238, "eval/reward_neg_acc": 0.9858585000038147, "eval/reward_neg_loss": 0.043102115392684937, "eval/reward_pos_acc": 0.9117646813392639, "eval/reward_pos_loss": 1.1105340719223022, "eval/reward_pred": 0.0324467271566391, "eval/reward_rate": 0.033203125, "replay/size": 657553.0, "replay/inserts": 22448.0, "replay/samples": 22448.0, "replay/insert_wait_avg": 1.37205388999716e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.267927490636781e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1618362694251828e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2896115779877, "timer/env.step_count": 2806.0, "timer/env.step_total": 245.63995170593262, "timer/env.step_frac": 0.24556883212895517, "timer/env.step_avg": 0.08754096639555689, "timer/env.step_min": 0.022818326950073242, "timer/env.step_max": 3.458136796951294, "timer/replay._sample_count": 22448.0, "timer/replay._sample_total": 11.216594457626343, "timer/replay._sample_frac": 0.011213346942523796, "timer/replay._sample_avg": 0.0004996701023532762, "timer/replay._sample_min": 0.0004031658172607422, "timer/replay._sample_max": 0.011014938354492188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3462.0, "timer/agent.policy_total": 56.28962993621826, "timer/agent.policy_frac": 0.056273332527586324, "timer/agent.policy_avg": 0.016259280744141614, "timer/agent.policy_min": 0.00926065444946289, "timer/agent.policy_max": 0.1033024787902832, "timer/dataset_train_count": 1403.0, "timer/dataset_train_total": 0.15224432945251465, "timer/dataset_train_frac": 0.00015220025049779787, "timer/dataset_train_avg": 0.0001085134208499748, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00019478797912597656, "timer/agent.train_count": 1403.0, "timer/agent.train_total": 625.4377853870392, "timer/agent.train_frac": 0.6252567038064024, "timer/agent.train_avg": 0.4457860195203415, "timer/agent.train_min": 0.43189334869384766, "timer/agent.train_max": 1.5793814659118652, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4796786308288574, "timer/agent.report_frac": 0.0004795397505649885, "timer/agent.report_avg": 0.2398393154144287, "timer/agent.report_min": 0.23430752754211426, "timer/agent.report_max": 0.24537110328674316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9793693789022993e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.44119399464892}
{"step": 658144, "time": 30392.44556927681, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 658728, "time": 30413.612202882767, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 658744, "time": 30415.75385451317, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 658840, "time": 30420.54510807991, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 658896, "time": 30424.309508562088, "episode/length": 218.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 659120, "time": 30433.544095277786, "episode/length": 46.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 659216, "time": 30438.35817861557, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 659224, "time": 30439.948070526123, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 659456, "time": 30449.447016954422, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 659528, "time": 30453.711356639862, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 659976, "time": 30470.34756588936, "episode/length": 55.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 660072, "time": 30475.125881433487, "episode/length": 153.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 30498.24741077423, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 660088, "time": 30500.751650094986, "eval_episode/length": 189.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9842105263157894}
{"step": 660088, "time": 30502.400514364243, "eval_episode/length": 194.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 660088, "time": 30504.306299448013, "eval_episode/length": 200.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 660088, "time": 30507.085500717163, "eval_episode/length": 60.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 660088, "time": 30509.646119832993, "eval_episode/length": 249.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.988}
{"step": 660088, "time": 30511.728914022446, "eval_episode/length": 262.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 660088, "time": 30513.68451833725, "eval_episode/length": 43.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 660304, "time": 30521.268759012222, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 660368, "time": 30524.935142993927, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 660840, "time": 30542.16094827652, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 660880, "time": 30545.412957906723, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 660880, "time": 30545.420497894287, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 660984, "time": 30552.11326622963, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 661408, "time": 30568.472033262253, "episode/length": 178.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 661424, "time": 30570.5737991333, "episode/length": 131.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 661784, "time": 30584.074803829193, "episode/length": 213.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 661808, "time": 30586.708074569702, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 662304, "time": 30605.117464780807, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 662760, "time": 30622.53028512001, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 662928, "time": 30630.057186365128, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 662976, "time": 30633.323669433594, "episode/length": 261.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.0}
{"step": 663048, "time": 30637.345369577408, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 663288, "time": 30646.94655227661, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 663520, "time": 30656.505206346512, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 663736, "time": 30666.687117815018, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 663960, "time": 30675.620933055878, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 664416, "time": 30692.71019411087, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 664896, "time": 30710.39121365547, "episode/length": 59.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 664960, "time": 30714.009296178818, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 665040, "time": 30718.167426109314, "episode/length": 248.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 665072, "time": 30720.771771669388, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 665224, "time": 30727.422165870667, "episode/length": 280.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 665264, "time": 30730.56472468376, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 665352, "time": 30734.834364891052, "episode/length": 257.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 666264, "time": 30766.93176150322, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 666432, "time": 30774.444974422455, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 666472, "time": 30777.11355495453, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 666736, "time": 30787.80425620079, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 666816, "time": 30792.050167560577, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 667256, "time": 30808.249653577805, "episode/length": 248.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 667392, "time": 30814.61385035515, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 667616, "time": 30824.021919727325, "episode/length": 298.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 667976, "time": 30837.401998996735, "episode/length": 327.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 668432, "time": 30854.64168071747, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 668480, "time": 30857.782663583755, "episode/length": 276.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 668568, "time": 30862.022740125656, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 669568, "time": 30897.353439569473, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 669672, "time": 30902.139581918716, "episode/length": 399.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 669880, "time": 30910.7349588871, "episode/length": 310.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 30938.09622859955, "eval_episode/length": 144.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 670072, "time": 30940.55736017227, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 670072, "time": 30942.82959342003, "eval_episode/length": 176.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 670072, "time": 30944.735377788544, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 670072, "time": 30946.53003168106, "eval_episode/length": 186.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 670072, "time": 30948.232828617096, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 670072, "time": 30950.51760816574, "eval_episode/length": 202.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 670072, "time": 30958.4444129467, "eval_episode/length": 141.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 670072, "time": 30958.454583883286, "eval_episode/length": 304.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9901639344262295}
{"step": 670120, "time": 30960.084889411926, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 670376, "time": 30970.469264030457, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 670624, "time": 30980.591646909714, "episode/length": 273.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 670664, "time": 30983.257945537567, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 670672, "time": 30985.332198619843, "episode/length": 336.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 670880, "time": 30993.752660512924, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 670888, "time": 30995.703981399536, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 670992, "time": 31000.944427490234, "episode/length": 138.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 671968, "time": 31037.16814827919, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 672216, "time": 31046.803318738937, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 672504, "time": 31058.23765540123, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 672728, "time": 31067.374328374863, "episode/length": 262.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 672816, "time": 31072.13282251358, "episode/length": 38.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 672832, "time": 31074.30200266838, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 672840, "time": 31075.86347770691, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 672952, "time": 31081.400116682053, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 673088, "time": 31087.811492204666, "episode/length": 370.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9973045822102425, "episode/intrinsic_return": 0.0}
{"step": 673984, "time": 31119.534526586533, "episode/length": 251.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 674040, "time": 31122.768251895905, "episode/length": 152.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 674072, "time": 31125.41562485695, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 674160, "time": 31130.278342723846, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 674312, "time": 31136.71180486679, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 674376, "time": 31140.456820964813, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 674416, "time": 31143.591950654984, "episode/length": 31.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 674464, "time": 31146.88564324379, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 674752, "time": 31158.065455436707, "episode/length": 46.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 675192, "time": 31174.00255703926, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 675384, "time": 31182.02364063263, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 675456, "time": 31186.258329629898, "episode/length": 123.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 676088, "time": 31209.16150355339, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 676192, "time": 31214.413976430893, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 676256, "time": 31218.037997961044, "episode/length": 283.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 676640, "time": 31232.362611055374, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 676864, "time": 31241.490161657333, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 677000, "time": 31247.2791724205, "episode/length": 365.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 677192, "time": 31255.35405755043, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 677456, "time": 31265.983345270157, "episode/length": 379.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 677864, "time": 31280.966605901718, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 677968, "time": 31286.271585941315, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 677984, "time": 31288.320452451706, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 678088, "time": 31293.08156967163, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 678440, "time": 31306.49056339264, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 678784, "time": 31319.710016965866, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 678808, "time": 31321.863394021988, "episode/length": 225.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 679136, "time": 31335.05421113968, "episode/length": 40.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 679216, "time": 31339.52654004097, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 679456, "time": 31349.1064722538, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 679560, "time": 31353.96875309944, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 679664, "time": 31359.400814294815, "episode/length": 308.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31390.254608631134, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 680056, "time": 31396.201890945435, "eval_episode/length": 142.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 680056, "time": 31398.343331575394, "eval_episode/length": 157.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 680056, "time": 31402.478574752808, "eval_episode/length": 215.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 680056, "time": 31404.060955286026, "eval_episode/length": 216.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 680056, "time": 31408.48528790474, "eval_episode/length": 278.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.985663082437276}
{"step": 680056, "time": 31411.76331090927, "eval_episode/length": 313.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9968152866242038}
{"step": 680056, "time": 31413.584297418594, "eval_episode/length": 177.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 680057, "time": 31414.63591980934, "train_stats/sum_log_reward": 7.575728257882942, "train_stats/max_log_achievement_collect_coal": 0.5339805825242718, "train_stats/max_log_achievement_collect_drink": 2.9902912621359223, "train_stats/max_log_achievement_collect_sapling": 1.5631067961165048, "train_stats/max_log_achievement_collect_stone": 4.631067961165049, "train_stats/max_log_achievement_collect_wood": 9.427184466019417, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6310679611650486, "train_stats/max_log_achievement_eat_cow": 0.038834951456310676, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009708737864077669, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.2524271844660193, "train_stats/max_log_achievement_make_wood_sword": 0.2621359223300971, "train_stats/max_log_achievement_place_furnace": 0.1650485436893204, "train_stats/max_log_achievement_place_plant": 1.4951456310679612, "train_stats/max_log_achievement_place_stone": 0.9805825242718447, "train_stats/max_log_achievement_place_table": 2.8737864077669903, "train_stats/max_log_achievement_wake_up": 1.058252427184466, "train_stats/mean_log_entropy": 0.5681794939689266, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.330899203780794, "train/action_min": 0.0, "train/action_std": 3.378651411864009, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04735732635986196, "train/actor_opt_grad_steps": 41720.0, "train/actor_opt_loss": 13.080489615236756, "train/adv_mag": 0.5866124993258149, "train/adv_max": 0.5403086801950079, "train/adv_mean": 0.007751555577596908, "train/adv_min": -0.44414110394724965, "train/adv_std": 0.06748307053081311, "train/cont_avg": 0.9948391879562044, "train/cont_loss_mean": 0.00012409844252046786, "train/cont_loss_std": 0.0036687817358235578, "train/cont_neg_acc": 0.9938477591006425, "train/cont_neg_loss": 0.014977792554952967, "train/cont_pos_acc": 0.9999856561639883, "train/cont_pos_loss": 4.0333419333099326e-05, "train/cont_pred": 0.9948566642990948, "train/cont_rate": 0.9948391879562044, "train/dyn_loss_mean": 13.274821900973356, "train/dyn_loss_std": 9.136211130740868, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9689325720724398, "train/extr_critic_critic_opt_grad_steps": 41720.0, "train/extr_critic_critic_opt_loss": 16062.84399948677, "train/extr_critic_mag": 6.866717279392438, "train/extr_critic_max": 6.866717279392438, "train/extr_critic_mean": 2.2654474216656095, "train/extr_critic_min": -0.17921192976680114, "train/extr_critic_std": 1.4991966542536326, "train/extr_return_normed_mag": 1.6634167824348394, "train/extr_return_normed_max": 1.6634167824348394, "train/extr_return_normed_mean": 0.4286247280827404, "train/extr_return_normed_min": -0.15192941005212546, "train/extr_return_normed_std": 0.32307462448621316, "train/extr_return_rate": 0.8691088331006739, "train/extr_return_raw_mag": 8.20567486407983, "train/extr_return_raw_max": 8.20567486407983, "train/extr_return_raw_mean": 2.3025618721968937, "train/extr_return_raw_min": -0.4788562229079922, "train/extr_return_raw_std": 1.547826829617911, "train/extr_reward_mag": 1.0292932412920206, "train/extr_reward_max": 1.0292932412920206, "train/extr_reward_mean": 0.036280225962400436, "train/extr_reward_min": -0.40134145047542824, "train/extr_reward_std": 0.17673193201096388, "train/image_loss_mean": 6.39234233076555, "train/image_loss_std": 11.346335310135444, "train/model_loss_mean": 14.411433512276977, "train/model_loss_std": 15.099309963031407, "train/model_opt_grad_norm": 56.29641754261769, "train/model_opt_grad_steps": 41682.77372262774, "train/model_opt_loss": 17620.725275861085, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1227.1897810218977, "train/policy_entropy_mag": 2.551704420660534, "train/policy_entropy_max": 2.551704420660534, "train/policy_entropy_mean": 0.5141849200220874, "train/policy_entropy_min": 0.07937502409637409, "train/policy_entropy_std": 0.6058451574649254, "train/policy_logprob_mag": 7.438383621020908, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5137725026503096, "train/policy_logprob_min": -7.438383621020908, "train/policy_logprob_std": 1.087012420605569, "train/policy_randomness_mag": 0.9006396823555883, "train/policy_randomness_max": 0.9006396823555883, "train/policy_randomness_mean": 0.18148471328028798, "train/policy_randomness_min": 0.028015900117746236, "train/policy_randomness_std": 0.21383675519567336, "train/post_ent_mag": 58.879272628004536, "train/post_ent_max": 58.879272628004536, "train/post_ent_mean": 42.05081243584626, "train/post_ent_min": 19.918767128547614, "train/post_ent_std": 7.601723660517783, "train/prior_ent_mag": 68.22888656950344, "train/prior_ent_max": 68.22888656950344, "train/prior_ent_mean": 55.393021493062484, "train/prior_ent_min": 40.63000474358997, "train/prior_ent_std": 4.298748775120199, "train/rep_loss_mean": 13.274821900973356, "train/rep_loss_std": 9.136211130740868, "train/reward_avg": 0.027901887343040783, "train/reward_loss_mean": 0.05407406120513478, "train/reward_loss_std": 0.24274306499609982, "train/reward_max_data": 1.0160583979892035, "train/reward_max_pred": 1.0112815129495885, "train/reward_neg_acc": 0.9927491201971569, "train/reward_neg_loss": 0.02795218598831744, "train/reward_pos_acc": 0.9708098308013303, "train/reward_pos_loss": 0.8371187605126931, "train/reward_pred": 0.027304959503838617, "train/reward_rate": 0.03240476733576642, "eval_stats/sum_log_reward": 7.500000213980675, "eval_stats/max_log_achievement_collect_coal": 0.36, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 1.56, "eval_stats/max_log_achievement_collect_stone": 3.96, "eval_stats/max_log_achievement_collect_wood": 9.92, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.04, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.16, "eval_stats/max_log_achievement_make_wood_sword": 0.12, "eval_stats/max_log_achievement_place_furnace": 0.08, "eval_stats/max_log_achievement_place_plant": 1.52, "eval_stats/max_log_achievement_place_stone": 1.32, "eval_stats/max_log_achievement_place_table": 3.12, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.918973430292681e-05, "report/cont_loss_std": 0.0005519805708900094, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1521138731040992e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9234932551626116e-05, "report/cont_pred": 0.994121789932251, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.639795303344727, "report/dyn_loss_std": 9.172111511230469, "report/image_loss_mean": 6.163092613220215, "report/image_loss_std": 12.50667667388916, "report/model_loss_mean": 13.202178955078125, "report/model_loss_std": 16.136211395263672, "report/post_ent_mag": 59.8166618347168, "report/post_ent_max": 59.8166618347168, "report/post_ent_mean": 43.998779296875, "report/post_ent_min": 19.835596084594727, "report/post_ent_std": 8.045161247253418, "report/prior_ent_mag": 67.99085998535156, "report/prior_ent_max": 67.99085998535156, "report/prior_ent_mean": 55.8057746887207, "report/prior_ent_min": 42.216163635253906, "report/prior_ent_std": 4.286893367767334, "report/rep_loss_mean": 11.639795303344727, "report/rep_loss_std": 9.172111511230469, "report/reward_avg": 0.02597656100988388, "report/reward_loss_mean": 0.055189020931720734, "report/reward_loss_std": 0.24377207458019257, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017902851104736, "report/reward_neg_acc": 0.9909273982048035, "report/reward_neg_loss": 0.030191408470273018, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.8301149606704712, "report/reward_pred": 0.027124494314193726, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0030405649449676275, "eval/cont_loss_std": 0.09644556045532227, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.7779943346977234, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.5305713532143272e-06, "eval/cont_pred": 0.9970477819442749, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.333091735839844, "eval/dyn_loss_std": 10.798283576965332, "eval/image_loss_mean": 12.981610298156738, "eval/image_loss_std": 21.451820373535156, "eval/model_loss_mean": 23.46229362487793, "eval/model_loss_std": 25.215810775756836, "eval/post_ent_mag": 58.525577545166016, "eval/post_ent_max": 58.525577545166016, "eval/post_ent_mean": 40.929779052734375, "eval/post_ent_min": 20.409439086914062, "eval/post_ent_std": 7.545480728149414, "eval/prior_ent_mag": 67.99085998535156, "eval/prior_ent_max": 67.99085998535156, "eval/prior_ent_mean": 55.83064270019531, "eval/prior_ent_min": 41.327152252197266, "eval/prior_ent_std": 4.007246971130371, "eval/rep_loss_mean": 17.333091735839844, "eval/rep_loss_std": 10.798283576965332, "eval/reward_avg": 0.021484375, "eval/reward_loss_mean": 0.07778875529766083, "eval/reward_loss_std": 0.43691882491111755, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012547969818115, "eval/reward_neg_acc": 0.9909729361534119, "eval/reward_neg_loss": 0.03916201367974281, "eval/reward_pos_acc": 0.8148148059844971, "eval/reward_pos_loss": 1.5041170120239258, "eval/reward_pred": 0.017862748354673386, "eval/reward_rate": 0.0263671875, "replay/size": 679553.0, "replay/inserts": 22000.0, "replay/samples": 22000.0, "replay/insert_wait_avg": 1.3742880387739701e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.288462725552645e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.909373066738613e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1025.1077253818512, "timer/env.step_count": 2750.0, "timer/env.step_total": 240.71809434890747, "timer/env.step_frac": 0.23482224198363183, "timer/env.step_avg": 0.08753385249051181, "timer/env.step_min": 0.02309107780456543, "timer/env.step_max": 3.4598593711853027, "timer/replay._sample_count": 22000.0, "timer/replay._sample_total": 11.088565587997437, "timer/replay._sample_frac": 0.0108169759269612, "timer/replay._sample_avg": 0.000504025708545338, "timer/replay._sample_min": 0.0003609657287597656, "timer/replay._sample_max": 0.010778188705444336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3648.0, "timer/agent.policy_total": 61.43953895568848, "timer/agent.policy_frac": 0.05993471460065559, "timer/agent.policy_avg": 0.01684197888039706, "timer/agent.policy_min": 0.009403228759765625, "timer/agent.policy_max": 0.12338972091674805, "timer/dataset_train_count": 1375.0, "timer/dataset_train_total": 0.15412020683288574, "timer/dataset_train_frac": 0.00015034537640956337, "timer/dataset_train_avg": 0.00011208742315118962, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0009860992431640625, "timer/agent.train_count": 1375.0, "timer/agent.train_total": 619.9572215080261, "timer/agent.train_frac": 0.60477275329975, "timer/agent.train_avg": 0.45087797927856443, "timer/agent.train_min": 0.43361926078796387, "timer/agent.train_max": 1.6711957454681396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795646667480469, "timer/agent.report_frac": 0.0004678188007698505, "timer/agent.report_avg": 0.23978233337402344, "timer/agent.report_min": 0.23437118530273438, "timer/agent.report_max": 0.2451934814453125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.0700434366235265e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 21.460876949638564}
{"step": 680640, "time": 31434.378556489944, "episode/length": 346.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9971181556195965, "episode/intrinsic_return": 0.0}
{"step": 680656, "time": 31436.470507860184, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 680656, "time": 31436.478761911392, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 680968, "time": 31450.246153354645, "episode/length": 272.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 681288, "time": 31462.68629527092, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 681360, "time": 31467.018128871918, "episode/length": 211.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 681368, "time": 31468.55928826332, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 681768, "time": 31483.65849661827, "episode/length": 50.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 681904, "time": 31490.059354782104, "episode/length": 335.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 681968, "time": 31494.23034453392, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 682016, "time": 31497.44643688202, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 682560, "time": 31517.329639434814, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 682672, "time": 31522.7659573555, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 682944, "time": 31533.384964227676, "episode/length": 121.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 683040, "time": 31538.263255119324, "episode/length": 218.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 683472, "time": 31554.426017522812, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 683560, "time": 31558.570235967636, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 683848, "time": 31569.78590655327, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 684032, "time": 31577.678176641464, "episode/length": 265.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 684240, "time": 31586.16450214386, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 684288, "time": 31589.403992414474, "episode/length": 201.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 684752, "time": 31606.585344076157, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 684848, "time": 31611.34334421158, "episode/length": 160.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 684896, "time": 31614.58366894722, "episode/length": 231.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 685184, "time": 31625.90301847458, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 685680, "time": 31644.001059770584, "episode/length": 205.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 685920, "time": 31653.729300260544, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 686024, "time": 31658.949746847153, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 686104, "time": 31663.204352378845, "episode/length": 232.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 686592, "time": 31681.453294992447, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 686600, "time": 31683.197644233704, "episode/length": 71.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 686688, "time": 31688.101503372192, "episode/length": 223.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 686784, "time": 31693.080017089844, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 687112, "time": 31705.363174915314, "episode/length": 240.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 687296, "time": 31713.361592292786, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 687520, "time": 31722.505526304245, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 688120, "time": 31743.939376831055, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 688144, "time": 31748.24729323387, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 688544, "time": 31763.19924736023, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 688648, "time": 31767.98318696022, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 688680, "time": 31770.576029777527, "episode/length": 248.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 689008, "time": 31783.648402929306, "episode/length": 300.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 689464, "time": 31800.20126771927, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 689488, "time": 31802.76847743988, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9932659932659933, "episode/intrinsic_return": 0.0}
{"step": 689616, "time": 31808.666698217392, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 31841.855756998062, "eval_episode/length": 102.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9902912621359223}
{"step": 690040, "time": 31845.58989882469, "eval_episode/length": 151.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 690040, "time": 31848.05295276642, "eval_episode/length": 161.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 690040, "time": 31851.047597885132, "eval_episode/length": 183.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 690040, "time": 31854.276228666306, "eval_episode/length": 220.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 690040, "time": 31856.5329515934, "eval_episode/length": 52.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9245283018867925}
{"step": 690040, "time": 31858.928364276886, "eval_episode/length": 256.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9883268482490273}
{"step": 690040, "time": 31861.751653194427, "eval_episode/length": 181.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 690208, "time": 31867.698046922684, "episode/length": 73.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 690328, "time": 31873.565581083298, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 690600, "time": 31884.329339265823, "episode/length": 256.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 690672, "time": 31888.56458067894, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 690816, "time": 31895.447147369385, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 690912, "time": 31900.33032488823, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 691072, "time": 31907.24746274948, "episode/length": 257.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 691192, "time": 31912.500460624695, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 691256, "time": 31916.31378722191, "episode/length": 54.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 692000, "time": 31943.10357117653, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 692120, "time": 31948.339206933975, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 692168, "time": 31952.0520362854, "episode/length": 186.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 692384, "time": 31961.250245332718, "episode/length": 256.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 692408, "time": 31963.590218782425, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 692520, "time": 31969.021422624588, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 693248, "time": 31994.961781978607, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 693744, "time": 32012.978279829025, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 693760, "time": 32015.17006635666, "episode/length": 320.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 693928, "time": 32022.11131620407, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 694672, "time": 32048.747564792633, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 695144, "time": 32065.763011217117, "episode/length": 344.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 695352, "time": 32074.358942985535, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 695432, "time": 32078.67807841301, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 695464, "time": 32081.262712955475, "episode/length": 367.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 695880, "time": 32096.694136857986, "episode/length": 328.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9969604863221885, "episode/intrinsic_return": 0.0}
{"step": 696040, "time": 32103.52442264557, "episode/length": 170.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 696120, "time": 32107.775991678238, "episode/length": 499.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.998, "episode/intrinsic_return": 0.0}
{"step": 696600, "time": 32126.870698213577, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 696824, "time": 32136.206481218338, "episode/length": 384.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974025974025974, "episode/intrinsic_return": 0.0}
{"step": 697168, "time": 32149.417388677597, "episode/length": 160.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 697288, "time": 32154.767213344574, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 697336, "time": 32157.8222489357, "episode/length": 247.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 697616, "time": 32169.10854077339, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 698432, "time": 32198.075500011444, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 698672, "time": 32207.72988677025, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 698744, "time": 32211.55686402321, "episode/length": 181.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 699000, "time": 32221.683820724487, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 699080, "time": 32226.181277513504, "episode/length": 50.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 699256, "time": 32233.777128219604, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 699328, "time": 32238.09406375885, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 699376, "time": 32241.762523412704, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 699464, "time": 32246.244915485382, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 699680, "time": 32255.238653421402, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 700008, "time": 32267.463214159012, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32285.067788362503, "eval_episode/length": 46.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 700024, "time": 32286.84868788719, "eval_episode/length": 49.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.98}
{"step": 700024, "time": 32292.511038064957, "eval_episode/length": 148.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 700024, "time": 32294.368294000626, "eval_episode/length": 153.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 700024, "time": 32298.366058588028, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9631901840490797}
{"step": 700024, "time": 32300.803611278534, "eval_episode/length": 217.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.981651376146789}
{"step": 700024, "time": 32303.159778356552, "eval_episode/length": 173.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 700024, "time": 32305.291872739792, "eval_episode/length": 225.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 700056, "time": 32306.37834596634, "episode/length": 46.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 700792, "time": 32332.765475034714, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 700792, "time": 32332.782980918884, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 700816, "time": 32337.193727493286, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 701192, "time": 32351.245656251907, "episode/length": 49.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 701200, "time": 32353.336716890335, "episode/length": 306.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993485342019544, "episode/intrinsic_return": 0.0}
{"step": 701512, "time": 32365.079049110413, "episode/length": 39.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 701592, "time": 32369.268979549408, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9891696750902527, "episode/intrinsic_return": 0.0}
{"step": 701600, "time": 32371.45786190033, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 701968, "time": 32385.282754659653, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 701992, "time": 32387.588548898697, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 702184, "time": 32395.448697328568, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 702384, "time": 32403.925916671753, "episode/length": 290.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 702633, "time": 32414.771512508392, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.501225464732935, "train/action_min": 0.0, "train/action_std": 3.4864127179409596, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04200240314429533, "train/actor_opt_grad_steps": 43110.0, "train/actor_opt_loss": -4.203624744840125, "train/adv_mag": 0.5405692718130477, "train/adv_max": 0.5021244980764727, "train/adv_mean": 0.002581502212873963, "train/adv_min": -0.4102084738142947, "train/adv_std": 0.060006013628861585, "train/cont_avg": 0.9949994459219859, "train/cont_loss_mean": 0.00022820702952956593, "train/cont_loss_std": 0.006842636078527445, "train/cont_neg_acc": 0.9890661954034304, "train/cont_neg_loss": 0.029861098437438758, "train/cont_pos_acc": 0.9999721430717631, "train/cont_pos_loss": 8.052474560979639e-05, "train/cont_pred": 0.9950252264103991, "train/cont_rate": 0.9949994459219859, "train/dyn_loss_mean": 13.297405628447837, "train/dyn_loss_std": 9.175712605740161, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.936992921305041, "train/extr_critic_critic_opt_grad_steps": 43110.0, "train/extr_critic_critic_opt_loss": 15586.711256094859, "train/extr_critic_mag": 7.5242751743776575, "train/extr_critic_max": 7.5242751743776575, "train/extr_critic_mean": 2.488160896808543, "train/extr_critic_min": -0.17431202678815694, "train/extr_critic_std": 1.6775995357662228, "train/extr_return_normed_mag": 1.6013759949528579, "train/extr_return_normed_max": 1.6013759949528579, "train/extr_return_normed_mean": 0.40557570935141113, "train/extr_return_normed_min": -0.15010091440474732, "train/extr_return_normed_std": 0.3218075692230928, "train/extr_return_rate": 0.9133468650756998, "train/extr_return_raw_mag": 8.852236504250385, "train/extr_return_raw_max": 8.852236504250385, "train/extr_return_raw_mean": 2.5018387381912124, "train/extr_return_raw_min": -0.4479670798313533, "train/extr_return_raw_std": 1.7088563788867166, "train/extr_reward_mag": 1.0316423000173365, "train/extr_reward_max": 1.0316423000173365, "train/extr_reward_mean": 0.03576978947306778, "train/extr_reward_min": -0.38851749897003174, "train/extr_reward_std": 0.17516394202590835, "train/image_loss_mean": 6.685859896612506, "train/image_loss_std": 11.582888704665164, "train/model_loss_mean": 14.720410793385607, "train/model_loss_std": 15.337568404826712, "train/model_opt_grad_norm": 56.33608546155564, "train/model_opt_grad_steps": 43071.02836879432, "train/model_opt_loss": 14212.173966644503, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 961.8794326241135, "train/policy_entropy_mag": 2.568835309211244, "train/policy_entropy_max": 2.568835309211244, "train/policy_entropy_mean": 0.5702946181838394, "train/policy_entropy_min": 0.07937502100112591, "train/policy_entropy_std": 0.6786956947746007, "train/policy_logprob_mag": 7.438383653654275, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5692296833434003, "train/policy_logprob_min": -7.438383653654275, "train/policy_logprob_std": 1.1233990217777008, "train/policy_randomness_mag": 0.906686135640381, "train/policy_randomness_max": 0.906686135640381, "train/policy_randomness_mean": 0.201288973186033, "train/policy_randomness_min": 0.028015899082236256, "train/policy_randomness_std": 0.23954979546949373, "train/post_ent_mag": 59.35956048627272, "train/post_ent_max": 59.35956048627272, "train/post_ent_mean": 42.29872596686614, "train/post_ent_min": 20.234291597461024, "train/post_ent_std": 7.702445246649127, "train/prior_ent_mag": 68.29187119937112, "train/prior_ent_max": 68.29187119937112, "train/prior_ent_mean": 55.6555578894649, "train/prior_ent_min": 41.52290631016941, "train/prior_ent_std": 4.3582056042150406, "train/rep_loss_mean": 13.297405628447837, "train/rep_loss_std": 9.175712605740161, "train/reward_avg": 0.02742686145773805, "train/reward_loss_mean": 0.055879399338935286, "train/reward_loss_std": 0.2565696146471281, "train/reward_max_data": 1.0205673807901694, "train/reward_max_pred": 1.0132923067038786, "train/reward_neg_acc": 0.992879793153587, "train/reward_neg_loss": 0.028995023683664647, "train/reward_pos_acc": 0.9576456741238317, "train/reward_pos_loss": 0.8742132381344518, "train/reward_pred": 0.026521869301003344, "train/reward_rate": 0.03201185726950355, "train_stats/sum_log_reward": 7.737254993588317, "train_stats/max_log_achievement_collect_coal": 0.3627450980392157, "train_stats/max_log_achievement_collect_drink": 3.3137254901960786, "train_stats/max_log_achievement_collect_sapling": 1.607843137254902, "train_stats/max_log_achievement_collect_stone": 8.843137254901961, "train_stats/max_log_achievement_collect_wood": 8.450980392156863, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "train_stats/max_log_achievement_eat_cow": 0.06862745098039216, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.029411764705882353, "train_stats/max_log_achievement_make_stone_sword": 0.0196078431372549, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7549019607843137, "train_stats/max_log_achievement_make_wood_sword": 0.17647058823529413, "train_stats/max_log_achievement_place_furnace": 0.14705882352941177, "train_stats/max_log_achievement_place_plant": 1.5686274509803921, "train_stats/max_log_achievement_place_stone": 6.401960784313726, "train_stats/max_log_achievement_place_table": 2.6666666666666665, "train_stats/max_log_achievement_wake_up": 0.9803921568627451, "train_stats/mean_log_entropy": 0.6384650907095741, "eval_stats/sum_log_reward": 6.28750005364418, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 1.625, "eval_stats/max_log_achievement_collect_sapling": 1.0625, "eval_stats/max_log_achievement_collect_stone": 4.125, "eval_stats/max_log_achievement_collect_wood": 7.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 3.0625, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 0.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0005396039923653007, "report/cont_loss_std": 0.01228675339370966, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.026338867843151093, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00036202784394845366, "report/cont_pred": 0.9930269718170166, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.863104820251465, "report/dyn_loss_std": 9.201869010925293, "report/image_loss_mean": 9.124277114868164, "report/image_loss_std": 15.202766418457031, "report/model_loss_mean": 17.50688362121582, "report/model_loss_std": 18.772367477416992, "report/post_ent_mag": 59.024322509765625, "report/post_ent_max": 59.024322509765625, "report/post_ent_mean": 42.22544860839844, "report/post_ent_min": 19.634078979492188, "report/post_ent_std": 7.71103048324585, "report/prior_ent_mag": 68.52864074707031, "report/prior_ent_max": 68.52864074707031, "report/prior_ent_mean": 55.908180236816406, "report/prior_ent_min": 37.48871612548828, "report/prior_ent_std": 4.239668369293213, "report/rep_loss_mean": 13.863104820251465, "report/rep_loss_std": 9.201869010925293, "report/reward_avg": 0.03544921427965164, "report/reward_loss_mean": 0.06420297175645828, "report/reward_loss_std": 0.2211148589849472, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041263103485107, "report/reward_neg_acc": 0.9888097643852234, "report/reward_neg_loss": 0.03639225289225578, "report/reward_pos_acc": 0.9756097197532654, "report/reward_pos_loss": 0.7309818863868713, "report/reward_pred": 0.03592117130756378, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.2733986295643263e-05, "eval/cont_loss_std": 0.0003355852677486837, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008253667037934065, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1143706615257543e-05, "eval/cont_pred": 0.9980374574661255, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.79133415222168, "eval/dyn_loss_std": 10.047101974487305, "eval/image_loss_mean": 11.708282470703125, "eval/image_loss_std": 14.974973678588867, "eval/model_loss_mean": 22.500093460083008, "eval/model_loss_std": 18.669715881347656, "eval/post_ent_mag": 56.566322326660156, "eval/post_ent_max": 56.566322326660156, "eval/post_ent_mean": 40.535804748535156, "eval/post_ent_min": 16.47787094116211, "eval/post_ent_std": 7.663229942321777, "eval/prior_ent_mag": 68.52864074707031, "eval/prior_ent_max": 68.52864074707031, "eval/prior_ent_mean": 56.29034423828125, "eval/prior_ent_min": 46.14242172241211, "eval/prior_ent_std": 3.7752723693847656, "eval/rep_loss_mean": 17.79133415222168, "eval/rep_loss_std": 10.047101974487305, "eval/reward_avg": 0.03046875074505806, "eval/reward_loss_mean": 0.11699744313955307, "eval/reward_loss_std": 0.717107355594635, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004663467407227, "eval/reward_neg_acc": 0.988877534866333, "eval/reward_neg_loss": 0.037265826016664505, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.3699848651885986, "eval/reward_pred": 0.022811613976955414, "eval/reward_rate": 0.0341796875, "replay/size": 702129.0, "replay/inserts": 22576.0, "replay/samples": 22576.0, "replay/insert_wait_avg": 1.3938024481672669e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.316974798049765e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.197225193688081e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1270287036896, "timer/env.step_count": 2822.0, "timer/env.step_total": 242.97118377685547, "timer/env.step_frac": 0.24294032338250227, "timer/env.step_avg": 0.0860989311753563, "timer/env.step_min": 0.02312159538269043, "timer/env.step_max": 3.4853403568267822, "timer/replay._sample_count": 22576.0, "timer/replay._sample_total": 11.348883867263794, "timer/replay._sample_frac": 0.011347442416363452, "timer/replay._sample_avg": 0.0005026968403288357, "timer/replay._sample_min": 0.0004055500030517578, "timer/replay._sample_max": 0.010664939880371094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3333.0, "timer/agent.policy_total": 54.13277339935303, "timer/agent.policy_frac": 0.054125897856712256, "timer/agent.policy_avg": 0.01624145616542245, "timer/agent.policy_min": 0.009482860565185547, "timer/agent.policy_max": 0.10841178894042969, "timer/dataset_train_count": 1411.0, "timer/dataset_train_total": 0.15269970893859863, "timer/dataset_train_frac": 0.00015268031415621245, "timer/dataset_train_avg": 0.00010822091349298273, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00040411949157714844, "timer/agent.train_count": 1411.0, "timer/agent.train_total": 632.9553511142731, "timer/agent.train_frac": 0.6328749578287824, "timer/agent.train_avg": 0.4485863579831843, "timer/agent.train_min": 0.43614697456359863, "timer/agent.train_max": 1.6439192295074463, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4813506603240967, "timer/agent.report_frac": 0.00048128952273992365, "timer/agent.report_avg": 0.24067533016204834, "timer/agent.report_min": 0.23465538024902344, "timer/agent.report_max": 0.24669528007507324, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075209030593426e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.572808466359717}
{"step": 702896, "time": 32423.63065314293, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 702944, "time": 32426.7573697567, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 702992, "time": 32429.90166401863, "episode/length": 127.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9453125, "episode/intrinsic_return": 0.0}
{"step": 703368, "time": 32443.967556476593, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 703624, "time": 32454.068353891373, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 703728, "time": 32459.395498752594, "episode/length": 103.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 703744, "time": 32461.482345104218, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 703904, "time": 32468.3039624691, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 704112, "time": 32476.811735391617, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 704408, "time": 32487.932898521423, "episode/length": 182.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 704816, "time": 32505.25318789482, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 704904, "time": 32509.412902355194, "episode/length": 61.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 705176, "time": 32520.065798282623, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 705192, "time": 32522.08557009697, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 705376, "time": 32530.113545656204, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 705392, "time": 32532.148502349854, "episode/length": 185.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 705664, "time": 32542.697030067444, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 705704, "time": 32545.396560668945, "episode/length": 291.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 706200, "time": 32563.422950029373, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 706224, "time": 32566.189303398132, "episode/length": 105.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 706256, "time": 32568.742161750793, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 706432, "time": 32576.310791015625, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 706840, "time": 32591.79594373703, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 707368, "time": 32611.25999379158, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 707440, "time": 32615.42829298973, "episode/length": 151.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 707496, "time": 32618.625545978546, "episode/length": 161.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 707880, "time": 32633.091492176056, "episode/length": 129.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 707944, "time": 32636.775602817535, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 708544, "time": 32658.582817792892, "episode/length": 130.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 708568, "time": 32660.87665438652, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 708600, "time": 32663.523485422134, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 708904, "time": 32675.239711999893, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 708952, "time": 32678.487784147263, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 709312, "time": 32692.205330371857, "episode/length": 489.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9979591836734694, "episode/intrinsic_return": 0.0}
{"step": 709464, "time": 32698.648265600204, "episode/length": 111.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 709584, "time": 32704.446084976196, "episode/length": 204.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 709816, "time": 32713.558926820755, "episode/length": 43.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 709848, "time": 32716.105768442154, "episode/length": 162.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32742.76962661743, "eval_episode/length": 151.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 710008, "time": 32746.06749510765, "eval_episode/length": 153.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 710008, "time": 32749.164143562317, "eval_episode/length": 185.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 710008, "time": 32751.94527554512, "eval_episode/length": 209.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 710008, "time": 32754.07681298256, "eval_episode/length": 221.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9864864864864865}
{"step": 710008, "time": 32755.743324279785, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 710008, "time": 32759.210844278336, "eval_episode/length": 44.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 710008, "time": 32762.444284677505, "eval_episode/length": 156.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 710024, "time": 32762.977380752563, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 710208, "time": 32770.964584589005, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 710312, "time": 32775.6453371048, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 710528, "time": 32784.557624578476, "episode/length": 117.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 710904, "time": 32798.37513899803, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 711048, "time": 32804.71803832054, "episode/length": 153.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 711192, "time": 32811.046723365784, "episode/length": 109.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 711360, "time": 32818.39581036568, "episode/length": 143.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 711496, "time": 32824.16615772247, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 711840, "time": 32837.51947569847, "episode/length": 248.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 711968, "time": 32843.47371864319, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 712216, "time": 32853.06545853615, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 712744, "time": 32873.71168971062, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 713224, "time": 32891.324959754944, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 713376, "time": 32898.13252854347, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 713400, "time": 32900.29494428635, "episode/length": 311.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 713568, "time": 32907.63333773613, "episode/length": 199.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 713704, "time": 32913.65819478035, "episode/length": 292.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9897610921501706, "episode/intrinsic_return": 0.0}
{"step": 713976, "time": 32924.38855051994, "episode/length": 266.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 714392, "time": 32939.98112297058, "episode/length": 271.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 714464, "time": 32944.204556941986, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 714528, "time": 32948.12449145317, "episode/length": 119.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 714768, "time": 32957.76494884491, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 714936, "time": 32964.734531879425, "episode/length": 153.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 715016, "time": 32968.98726654053, "episode/length": 223.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 715400, "time": 32983.362134218216, "episode/length": 47.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 715648, "time": 32993.38167834282, "episode/length": 208.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 715840, "time": 33001.60912132263, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 715928, "time": 33005.97435450554, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 715928, "time": 33005.98158621788, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 716104, "time": 33015.21128535271, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 716336, "time": 33024.65742611885, "episode/length": 50.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 716456, "time": 33030.133487701416, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 716464, "time": 33032.140345573425, "episode/length": 66.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 716624, "time": 33039.0934548378, "episode/length": 121.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 716704, "time": 33043.447175979614, "episode/length": 107.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 716832, "time": 33049.405974149704, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 717112, "time": 33060.44596505165, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 717288, "time": 33068.12173438072, "episode/length": 56.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 717912, "time": 33091.08235621452, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 717968, "time": 33095.0222389698, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 718064, "time": 33099.889576911926, "episode/length": 118.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 718168, "time": 33104.764297008514, "episode/length": 228.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 718168, "time": 33104.771752119064, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 718344, "time": 33115.609916210175, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 718440, "time": 33120.29744410515, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 718568, "time": 33126.22351312637, "episode/length": 49.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 718752, "time": 33134.08969044685, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 718824, "time": 33137.92122912407, "episode/length": 47.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 718992, "time": 33145.34997177124, "episode/length": 316.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 719688, "time": 33169.97208929062, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 719712, "time": 33172.499371528625, "episode/length": 224.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33202.374695539474, "eval_episode/length": 58.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 720096, "time": 33207.96532034874, "eval_episode/length": 155.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 720096, "time": 33210.13793897629, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 720096, "time": 33212.09581899643, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 720096, "time": 33215.28663110733, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 720096, "time": 33217.920118808746, "eval_episode/length": 176.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 720096, "time": 33222.420135736465, "eval_episode/length": 303.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9802631578947368}
{"step": 720096, "time": 33224.03663825989, "eval_episode/length": 306.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9837133550488599}
{"step": 720352, "time": 33232.709605932236, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 720400, "time": 33235.88698530197, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 720416, "time": 33237.945252895355, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 720488, "time": 33241.647096157074, "episode/length": 186.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 720528, "time": 33244.844376802444, "episode/length": 272.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 720872, "time": 33257.58854222298, "episode/length": 287.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 721248, "time": 33273.594014406204, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 721288, "time": 33276.359385728836, "episode/length": 196.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 721360, "time": 33280.714851140976, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 721840, "time": 33298.68747854233, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 721864, "time": 33300.87689447403, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 721920, "time": 33304.59048247337, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 722008, "time": 33308.95947599411, "episode/length": 200.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9900497512437811, "episode/intrinsic_return": 0.0}
{"step": 722056, "time": 33312.14744544029, "episode/length": 100.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 723008, "time": 33345.55078649521, "episode/length": 135.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 723096, "time": 33349.71464776993, "episode/length": 216.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 723336, "time": 33359.38221335411, "episode/length": 186.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 723632, "time": 33371.16405773163, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 723704, "time": 33374.96047139168, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 723744, "time": 33378.10315847397, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 724264, "time": 33397.40073657036, "episode/length": 371.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 724344, "time": 33401.889763593674, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 724584, "time": 33411.45629000664, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 724617, "time": 33415.14008760452, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.392960700435915, "train/action_min": 0.0, "train/action_std": 3.41144147126571, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04417934886895228, "train/actor_opt_grad_steps": 44505.0, "train/actor_opt_loss": -6.242807653071224, "train/adv_mag": 0.5395420493854992, "train/adv_max": 0.49971498138662696, "train/adv_mean": 0.0026961711490108373, "train/adv_min": -0.42531203780917154, "train/adv_std": 0.06247132789829503, "train/cont_avg": 0.9948482789855072, "train/cont_loss_mean": 0.00016969086004256707, "train/cont_loss_std": 0.005207654275473626, "train/cont_neg_acc": 0.9987922708193461, "train/cont_neg_loss": 0.007441897258302007, "train/cont_pos_acc": 0.9999501471934111, "train/cont_pos_loss": 0.0001355008812777482, "train/cont_pred": 0.9948105734327565, "train/cont_rate": 0.9948482789855072, "train/dyn_loss_mean": 13.390706145245096, "train/dyn_loss_std": 9.16024871494459, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8769213807755623, "train/extr_critic_critic_opt_grad_steps": 44505.0, "train/extr_critic_critic_opt_loss": 15440.136591372282, "train/extr_critic_mag": 7.614776272704636, "train/extr_critic_max": 7.614776272704636, "train/extr_critic_mean": 2.459585700346076, "train/extr_critic_min": -0.1705235709314761, "train/extr_critic_std": 1.603774190812871, "train/extr_return_normed_mag": 1.6287645084270532, "train/extr_return_normed_max": 1.6287645084270532, "train/extr_return_normed_mean": 0.399072454891343, "train/extr_return_normed_min": -0.1758628150691157, "train/extr_return_normed_std": 0.32118964303230896, "train/extr_return_rate": 0.9402193262957145, "train/extr_return_raw_mag": 8.731430876082268, "train/extr_return_raw_max": 8.731430876082268, "train/extr_return_raw_mean": 2.4732912934344746, "train/extr_return_raw_min": -0.4522575384032899, "train/extr_return_raw_std": 1.634876043036364, "train/extr_reward_mag": 1.0378322255784187, "train/extr_reward_max": 1.0378322255784187, "train/extr_reward_mean": 0.03664125000005183, "train/extr_reward_min": -0.40192014065341675, "train/extr_reward_std": 0.17734073329231012, "train/image_loss_mean": 6.823415180911189, "train/image_loss_std": 11.9541068042534, "train/model_loss_mean": 14.913473281307496, "train/model_loss_std": 15.679607011269832, "train/model_opt_grad_norm": 56.15962285580842, "train/model_opt_grad_steps": 44464.985507246376, "train/model_opt_loss": 16446.63025433084, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1100.5434782608695, "train/policy_entropy_mag": 2.5773677532223687, "train/policy_entropy_max": 2.5773677532223687, "train/policy_entropy_mean": 0.5614660950242609, "train/policy_entropy_min": 0.0793750208357106, "train/policy_entropy_std": 0.6812334816524948, "train/policy_logprob_mag": 7.438383665637693, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5614831937827925, "train/policy_logprob_min": -7.438383665637693, "train/policy_logprob_std": 1.1183165735092715, "train/policy_randomness_mag": 0.9096977088762366, "train/policy_randomness_max": 0.9096977088762366, "train/policy_randomness_mean": 0.19817289288925088, "train/policy_randomness_min": 0.028015899040020893, "train/policy_randomness_std": 0.2404455235902814, "train/post_ent_mag": 59.22750138545382, "train/post_ent_max": 59.22750138545382, "train/post_ent_mean": 42.13344861459041, "train/post_ent_min": 20.169315103171527, "train/post_ent_std": 7.687073728312617, "train/prior_ent_mag": 68.26532850403717, "train/prior_ent_max": 68.26532850403717, "train/prior_ent_mean": 55.596325639365375, "train/prior_ent_min": 40.313230265741765, "train/prior_ent_std": 4.420013120208961, "train/rep_loss_mean": 13.390706145245096, "train/rep_loss_std": 9.16024871494459, "train/reward_avg": 0.02849156463491744, "train/reward_loss_mean": 0.05546476041385229, "train/reward_loss_std": 0.24373440163722937, "train/reward_max_data": 1.017391308494236, "train/reward_max_pred": 1.0127941750097966, "train/reward_neg_acc": 0.9924711835557136, "train/reward_neg_loss": 0.02851290908385662, "train/reward_pos_acc": 0.9669342192186825, "train/reward_pos_loss": 0.8462231673192286, "train/reward_pred": 0.02761825903629263, "train/reward_rate": 0.033033288043478264, "train_stats/sum_log_reward": 7.630973623917166, "train_stats/max_log_achievement_collect_coal": 0.4336283185840708, "train_stats/max_log_achievement_collect_drink": 2.6194690265486726, "train_stats/max_log_achievement_collect_sapling": 1.4336283185840708, "train_stats/max_log_achievement_collect_stone": 7.699115044247788, "train_stats/max_log_achievement_collect_wood": 8.893805309734514, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.5929203539823009, "train_stats/max_log_achievement_eat_cow": 0.061946902654867256, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.008849557522123894, "train_stats/max_log_achievement_make_stone_sword": 0.008849557522123894, "train_stats/max_log_achievement_make_wood_pickaxe": 1.592920353982301, "train_stats/max_log_achievement_make_wood_sword": 0.12389380530973451, "train_stats/max_log_achievement_place_furnace": 0.07079646017699115, "train_stats/max_log_achievement_place_plant": 1.424778761061947, "train_stats/max_log_achievement_place_stone": 6.097345132743363, "train_stats/max_log_achievement_place_table": 2.814159292035398, "train_stats/max_log_achievement_wake_up": 1.0265486725663717, "train_stats/mean_log_entropy": 0.568364177525571, "train_stats/max_log_achievement_collect_iron": 0.011627906976744186, "eval_stats/sum_log_reward": 7.600000239908695, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 4.5, "eval_stats/max_log_achievement_collect_wood": 8.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 3.75, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.006346161011606455, "report/cont_loss_std": 0.19740232825279236, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03097516857087612, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.006225312128663063, "report/cont_pred": 0.9942581057548523, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.872753143310547, "report/dyn_loss_std": 9.437989234924316, "report/image_loss_mean": 8.00201416015625, "report/image_loss_std": 12.671154975891113, "report/model_loss_mean": 17.016613006591797, "report/model_loss_std": 16.70836639404297, "report/post_ent_mag": 59.88541793823242, "report/post_ent_max": 59.88541793823242, "report/post_ent_mean": 41.24005889892578, "report/post_ent_min": 20.618896484375, "report/post_ent_std": 7.713888168334961, "report/prior_ent_mag": 68.26191711425781, "report/prior_ent_max": 68.26191711425781, "report/prior_ent_mean": 56.084510803222656, "report/prior_ent_min": 39.32624053955078, "report/prior_ent_std": 4.7932281494140625, "report/rep_loss_mean": 14.872753143310547, "report/rep_loss_std": 9.437989234924316, "report/reward_avg": 0.03291015699505806, "report/reward_loss_mean": 0.08460107445716858, "report/reward_loss_std": 0.354086309671402, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011827945709229, "report/reward_neg_acc": 0.9908537268638611, "report/reward_neg_loss": 0.04915182664990425, "report/reward_pos_acc": 0.925000011920929, "report/reward_pos_loss": 0.9566526412963867, "report/reward_pred": 0.031224902719259262, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.3244036836113082e-06, "eval/cont_loss_std": 2.0174757082713768e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.0290475731599145e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.287288000639819e-06, "eval/cont_pred": 0.9980456829071045, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.61855697631836, "eval/dyn_loss_std": 10.453336715698242, "eval/image_loss_mean": 11.433043479919434, "eval/image_loss_std": 18.42910385131836, "eval/model_loss_mean": 22.097373962402344, "eval/model_loss_std": 22.046287536621094, "eval/post_ent_mag": 61.529911041259766, "eval/post_ent_max": 61.529911041259766, "eval/post_ent_mean": 40.980369567871094, "eval/post_ent_min": 21.122478485107422, "eval/post_ent_std": 8.1360445022583, "eval/prior_ent_mag": 68.26191711425781, "eval/prior_ent_max": 68.26191711425781, "eval/prior_ent_mean": 56.057769775390625, "eval/prior_ent_min": 43.25054931640625, "eval/prior_ent_std": 3.8151869773864746, "eval/rep_loss_mean": 17.61855697631836, "eval/rep_loss_std": 10.453336715698242, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.09319578111171722, "eval/reward_loss_std": 0.643872082233429, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024116039276123, "eval/reward_neg_acc": 0.9959840178489685, "eval/reward_neg_loss": 0.025086600333452225, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 2.515936851501465, "eval/reward_pred": 0.015262432396411896, "eval/reward_rate": 0.02734375, "replay/size": 724113.0, "replay/inserts": 21984.0, "replay/samples": 21984.0, "replay/insert_wait_avg": 1.3788671299186163e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.289149634182193e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1813872068831064e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3543674945831, "timer/env.step_count": 2748.0, "timer/env.step_total": 256.18652534484863, "timer/env.step_frac": 0.25609577332728134, "timer/env.step_avg": 0.09322653760729571, "timer/env.step_min": 0.022734403610229492, "timer/env.step_max": 3.4260497093200684, "timer/replay._sample_count": 21984.0, "timer/replay._sample_total": 11.0881826877594, "timer/replay._sample_frac": 0.011084254788160797, "timer/replay._sample_avg": 0.000504375122259798, "timer/replay._sample_min": 0.0004138946533203125, "timer/replay._sample_max": 0.010897397994995117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3366.0, "timer/agent.policy_total": 54.57383894920349, "timer/agent.policy_frac": 0.05455450660537953, "timer/agent.policy_avg": 0.016213261719905968, "timer/agent.policy_min": 0.009415626525878906, "timer/agent.policy_max": 0.105377197265625, "timer/dataset_train_count": 1374.0, "timer/dataset_train_total": 0.149092435836792, "timer/dataset_train_frac": 0.00014903962103969055, "timer/dataset_train_avg": 0.00010850977862939737, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0006220340728759766, "timer/agent.train_count": 1374.0, "timer/agent.train_total": 618.3131103515625, "timer/agent.train_frac": 0.6180940779017597, "timer/agent.train_avg": 0.45000954174058405, "timer/agent.train_min": 0.4329688549041748, "timer/agent.train_max": 2.248535394668579, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4816572666168213, "timer/agent.report_frac": 0.0004814866434013239, "timer/agent.report_avg": 0.24082863330841064, "timer/agent.report_min": 0.23352527618408203, "timer/agent.report_max": 0.24813199043273926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8838428669573712e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.975919530784157}
{"step": 724744, "time": 33419.191286325455, "episode/length": 138.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 724792, "time": 33422.34776163101, "episode/length": 347.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 724960, "time": 33429.799041986465, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 725160, "time": 33437.742037534714, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 725648, "time": 33455.92097878456, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 726208, "time": 33476.19120192528, "episode/length": 232.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 726424, "time": 33485.38320493698, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 726480, "time": 33489.055562734604, "episode/length": 236.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 726648, "time": 33496.03076004982, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 726816, "time": 33503.424258708954, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 726944, "time": 33509.30760240555, "episode/length": 334.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 726976, "time": 33512.07001256943, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 727280, "time": 33524.28448152542, "episode/length": 106.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 727320, "time": 33526.95136833191, "episode/length": 269.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 727376, "time": 33530.491378068924, "episode/length": 49.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 727576, "time": 33538.353346824646, "episode/length": 78.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 727968, "time": 33553.32138800621, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 728216, "time": 33563.32307934761, "episode/length": 116.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 728320, "time": 33568.6288151741, "episode/length": 263.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 728344, "time": 33570.79924750328, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 728752, "time": 33586.377816200256, "episode/length": 171.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 729024, "time": 33597.01110267639, "episode/length": 296.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 729192, "time": 33605.75498843193, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 729272, "time": 33609.9811668396, "episode/length": 131.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 729472, "time": 33618.45745396614, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 729720, "time": 33628.219036102295, "episode/length": 171.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 729736, "time": 33630.348158836365, "episode/length": 220.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 33659.11185979843, "eval_episode/length": 62.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 730080, "time": 33665.28215384483, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 730080, "time": 33667.56596827507, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 730080, "time": 33670.965405225754, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 730080, "time": 33672.743539094925, "eval_episode/length": 225.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 730080, "time": 33674.40429830551, "eval_episode/length": 226.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9691629955947136}
{"step": 730080, "time": 33679.9605448246, "eval_episode/length": 320.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9750778816199377}
{"step": 730080, "time": 33681.859907865524, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 730160, "time": 33684.513017416, "episode/length": 229.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 730280, "time": 33689.778289079666, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 730384, "time": 33695.11035037041, "episode/length": 169.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 730552, "time": 33702.18247151375, "episode/length": 169.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 730800, "time": 33712.37340784073, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 730800, "time": 33712.38050222397, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 731072, "time": 33724.97263097763, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 731456, "time": 33739.3478076458, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 731896, "time": 33755.53497886658, "episode/length": 188.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 731992, "time": 33760.35315108299, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 732168, "time": 33767.772299051285, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 732192, "time": 33770.47999501228, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 732400, "time": 33778.8935444355, "episode/length": 50.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 732440, "time": 33781.590691804886, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 732496, "time": 33785.40270400047, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 733008, "time": 33804.360855579376, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 733360, "time": 33818.086550712585, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 733376, "time": 33820.25097703934, "episode/length": 401.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 733456, "time": 33824.53032207489, "episode/length": 131.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 733528, "time": 33828.28155231476, "episode/length": 306.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 733528, "time": 33828.2886903286, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 733568, "time": 33833.16573429108, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 733656, "time": 33837.34038710594, "episode/length": 24.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.84, "episode/intrinsic_return": 0.0}
{"step": 734144, "time": 33855.48025083542, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 734352, "time": 33864.150081157684, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 734528, "time": 33871.56086182594, "episode/length": 124.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.944, "episode/intrinsic_return": 0.0}
{"step": 734568, "time": 33874.350700855255, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 734824, "time": 33884.54789185524, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 735000, "time": 33891.947177410126, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 735248, "time": 33901.99068379402, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 735256, "time": 33903.632301568985, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 735736, "time": 33921.15552663803, "episode/length": 198.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 736088, "time": 33934.55522823334, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 736336, "time": 33944.711179971695, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 736768, "time": 33960.7099776268, "episode/length": 301.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 737000, "time": 33970.58388328552, "episode/length": 271.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 737096, "time": 33975.46904087067, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 737232, "time": 33982.23215389252, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 737336, "time": 33988.49039769173, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 737336, "time": 33988.49806022644, "episode/length": 124.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.952, "episode/intrinsic_return": 0.0}
{"step": 737456, "time": 33996.2583656311, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 737928, "time": 34013.219949007034, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 738184, "time": 34023.13017177582, "episode/length": 365.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.0}
{"step": 738560, "time": 34037.57356786728, "episode/length": 194.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 738712, "time": 34044.577454805374, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 738848, "time": 34050.91287612915, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 738928, "time": 34055.17035365105, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 739032, "time": 34059.95059680939, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 739320, "time": 34071.09139442444, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 739464, "time": 34077.55892372131, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 739520, "time": 34081.29269719124, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 34115.83713197708, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 740064, "time": 34121.05628490448, "eval_episode/length": 124.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.992}
{"step": 740064, "time": 34124.024005413055, "eval_episode/length": 154.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 740064, "time": 34125.99207639694, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 740064, "time": 34128.753531455994, "eval_episode/length": 189.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 740064, "time": 34130.76250076294, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9633507853403142}
{"step": 740064, "time": 34132.84618020058, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 740064, "time": 34135.59149360657, "eval_episode/length": 84.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9882352941176471}
{"step": 740144, "time": 34138.37166905403, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 740384, "time": 34148.701805114746, "episode/length": 227.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 740432, "time": 34152.50284123421, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 740448, "time": 34154.52587270737, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 740752, "time": 34166.24355316162, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 740808, "time": 34169.56411719322, "episode/length": 82.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 741048, "time": 34179.17671775818, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 741296, "time": 34189.22339057922, "episode/length": 295.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 741568, "time": 34199.92406415939, "episode/length": 101.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 741760, "time": 34207.88184642792, "episode/length": 304.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 741816, "time": 34211.29912304878, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 741824, "time": 34213.29506826401, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 742232, "time": 34228.332387685776, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 742320, "time": 34232.99224472046, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 742344, "time": 34235.25702428818, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 742840, "time": 34253.23240804672, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 743016, "time": 34260.528681755066, "episode/length": 180.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 743280, "time": 34271.23664474487, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 743472, "time": 34279.131839990616, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 743480, "time": 34280.82412338257, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 743896, "time": 34296.245433568954, "episode/length": 193.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 744008, "time": 34301.535388469696, "episode/length": 280.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 744584, "time": 34322.45823454857, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 744640, "time": 34326.20117306709, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 744808, "time": 34333.30935049057, "episode/length": 165.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 744904, "time": 34338.108122348785, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 745352, "time": 34354.7469432354, "episode/length": 181.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 745968, "time": 34379.02767443657, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 745968, "time": 34379.03745174408, "episode/length": 335.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 746048, "time": 34386.03609204292, "episode/length": 154.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 746296, "time": 34396.24302530289, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 746793, "time": 34415.39167547226, "train_stats/sum_log_reward": 7.760550617829922, "train_stats/max_log_achievement_collect_coal": 0.5688073394495413, "train_stats/max_log_achievement_collect_drink": 2.6422018348623855, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.0825688073394495, "train_stats/max_log_achievement_collect_stone": 11.669724770642201, "train_stats/max_log_achievement_collect_wood": 8.779816513761467, "train_stats/max_log_achievement_defeat_skeleton": 0.01834862385321101, "train_stats/max_log_achievement_defeat_zombie": 0.5596330275229358, "train_stats/max_log_achievement_eat_cow": 0.11926605504587157, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.03669724770642202, "train_stats/max_log_achievement_make_stone_sword": 0.01834862385321101, "train_stats/max_log_achievement_make_wood_pickaxe": 1.688073394495413, "train_stats/max_log_achievement_make_wood_sword": 0.027522935779816515, "train_stats/max_log_achievement_place_furnace": 0.06422018348623854, "train_stats/max_log_achievement_place_plant": 1.0275229357798166, "train_stats/max_log_achievement_place_stone": 8.513761467889909, "train_stats/max_log_achievement_place_table": 2.7155963302752295, "train_stats/max_log_achievement_wake_up": 1.2201834862385321, "train_stats/mean_log_entropy": 0.5635566771577257, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4682913517606435, "train/action_min": 0.0, "train/action_std": 3.4430193849231885, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04547308131620504, "train/actor_opt_grad_steps": 45885.0, "train/actor_opt_loss": -4.46712300710488, "train/adv_mag": 0.5975457051957863, "train/adv_max": 0.5343994349241257, "train/adv_mean": 0.003466756613214375, "train/adv_min": -0.47326698035433673, "train/adv_std": 0.06404760658093121, "train/cont_avg": 0.9949898097826086, "train/cont_loss_mean": 0.00014614812397995968, "train/cont_loss_std": 0.0042304289854115905, "train/cont_neg_acc": 0.9937198080014491, "train/cont_neg_loss": 0.013785507660153651, "train/cont_pos_acc": 0.9999786313029303, "train/cont_pos_loss": 7.434754492552214e-05, "train/cont_pred": 0.9949922397516776, "train/cont_rate": 0.9949898097826086, "train/dyn_loss_mean": 13.278323111326799, "train/dyn_loss_std": 9.136303500852723, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.850790859564491, "train/extr_critic_critic_opt_grad_steps": 45885.0, "train/extr_critic_critic_opt_loss": 15260.725755774456, "train/extr_critic_mag": 7.574684675189032, "train/extr_critic_max": 7.574684675189032, "train/extr_critic_mean": 2.51770172689272, "train/extr_critic_min": -0.15079193616258926, "train/extr_critic_std": 1.5734341792438342, "train/extr_return_normed_mag": 1.6500609093818113, "train/extr_return_normed_max": 1.6500609093818113, "train/extr_return_normed_mean": 0.4019162244554879, "train/extr_return_normed_min": -0.18502721714152806, "train/extr_return_normed_std": 0.31931018807749817, "train/extr_return_rate": 0.954470532959786, "train/extr_return_raw_mag": 8.816639413004337, "train/extr_return_raw_max": 8.816639413004337, "train/extr_return_raw_mean": 2.5351650628490723, "train/extr_return_raw_min": -0.4197185155058253, "train/extr_return_raw_std": 1.607409510059633, "train/extr_reward_mag": 1.0393027654592542, "train/extr_reward_max": 1.0393027654592542, "train/extr_reward_mean": 0.03786677818583405, "train/extr_reward_min": -0.44140834220941516, "train/extr_reward_std": 0.1805076906862466, "train/image_loss_mean": 6.514048116794531, "train/image_loss_std": 11.474733114242554, "train/model_loss_mean": 14.536545414855516, "train/model_loss_std": 15.206985902095187, "train/model_opt_grad_norm": 54.400179199550465, "train/model_opt_grad_steps": 45843.717391304344, "train/model_opt_loss": 18299.60799507473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.0579710144928, "train/policy_entropy_mag": 2.562690634658371, "train/policy_entropy_max": 2.562690634658371, "train/policy_entropy_mean": 0.5442194457071415, "train/policy_entropy_min": 0.07937502051177232, "train/policy_entropy_std": 0.6668521083783412, "train/policy_logprob_mag": 7.438383734744528, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5445077376089235, "train/policy_logprob_min": -7.438383734744528, "train/policy_logprob_std": 1.1062846607056216, "train/policy_randomness_mag": 0.9045173353043156, "train/policy_randomness_max": 0.9045173353043156, "train/policy_randomness_mean": 0.19208558249300806, "train/policy_randomness_min": 0.028015898918544037, "train/policy_randomness_std": 0.23536953027697577, "train/post_ent_mag": 59.23901975327644, "train/post_ent_max": 59.23901975327644, "train/post_ent_mean": 42.261926208717234, "train/post_ent_min": 20.214112122853596, "train/post_ent_std": 7.712518090787142, "train/prior_ent_mag": 68.32568707673445, "train/prior_ent_max": 68.32568707673445, "train/prior_ent_mean": 55.61287600752236, "train/prior_ent_min": 40.78998540795368, "train/prior_ent_std": 4.390445413796798, "train/rep_loss_mean": 13.278323111326799, "train/rep_loss_std": 9.136303500852723, "train/reward_avg": 0.027728713407734598, "train/reward_loss_mean": 0.05535738498134458, "train/reward_loss_std": 0.24759475822034088, "train/reward_max_data": 1.0202898599099421, "train/reward_max_pred": 1.0137112978575886, "train/reward_neg_acc": 0.9926474379456561, "train/reward_neg_loss": 0.02911907740180259, "train/reward_pos_acc": 0.9660539540691652, "train/reward_pos_loss": 0.8529355534608813, "train/reward_pred": 0.026901546238071245, "train/reward_rate": 0.032169950181159424, "eval_stats/sum_log_reward": 6.975000120699406, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 2.3125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_stone": 8.6875, "eval_stats/max_log_achievement_collect_wood": 7.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.8125, "eval_stats/max_log_achievement_place_stone": 6.6875, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0006329394527710974, "report/cont_loss_std": 0.015906251966953278, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.09231721609830856, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8775401713355677e-06, "report/cont_pred": 0.9936835765838623, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.106401443481445, "report/dyn_loss_std": 9.091063499450684, "report/image_loss_mean": 4.833384037017822, "report/image_loss_std": 8.596214294433594, "report/model_loss_mean": 12.755748748779297, "report/model_loss_std": 12.479031562805176, "report/post_ent_mag": 55.88993453979492, "report/post_ent_max": 55.88993453979492, "report/post_ent_mean": 41.884910583496094, "report/post_ent_min": 19.4183349609375, "report/post_ent_std": 7.309159755706787, "report/prior_ent_mag": 68.47618103027344, "report/prior_ent_max": 68.47618103027344, "report/prior_ent_mean": 55.1670036315918, "report/prior_ent_min": 35.17992401123047, "report/prior_ent_std": 4.326277732849121, "report/rep_loss_mean": 13.106401443481445, "report/rep_loss_std": 9.091063499450684, "report/reward_avg": 0.03720702975988388, "report/reward_loss_mean": 0.05789077281951904, "report/reward_loss_std": 0.20275753736495972, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.008920431137085, "report/reward_neg_acc": 0.9918450117111206, "report/reward_neg_loss": 0.027956552803516388, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7408086657524109, "report/reward_pred": 0.03623711317777634, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.8099421999504557e-06, "eval/cont_loss_std": 6.596145976800472e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.38818120630458e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.4567190141387982e-06, "eval/cont_pred": 0.9960907101631165, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.119579315185547, "eval/dyn_loss_std": 10.36181640625, "eval/image_loss_mean": 10.13510799407959, "eval/image_loss_std": 16.57269287109375, "eval/model_loss_mean": 19.897380828857422, "eval/model_loss_std": 20.649988174438477, "eval/post_ent_mag": 56.11590576171875, "eval/post_ent_max": 56.11590576171875, "eval/post_ent_mean": 41.350502014160156, "eval/post_ent_min": 20.603992462158203, "eval/post_ent_std": 7.654680252075195, "eval/prior_ent_mag": 68.47618103027344, "eval/prior_ent_max": 68.47618103027344, "eval/prior_ent_mean": 55.61457061767578, "eval/prior_ent_min": 40.87223434448242, "eval/prior_ent_std": 3.817277193069458, "eval/rep_loss_mean": 16.119579315185547, "eval/rep_loss_std": 10.36181640625, "eval/reward_avg": 0.03759765625, "eval/reward_loss_mean": 0.09052031487226486, "eval/reward_loss_std": 0.4829651117324829, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0071585178375244, "eval/reward_neg_acc": 0.9898062944412231, "eval/reward_neg_loss": 0.04245300590991974, "eval/reward_pos_acc": 0.8837209343910217, "eval/reward_pos_loss": 1.187125563621521, "eval/reward_pred": 0.03531879931688309, "eval/reward_rate": 0.0419921875, "replay/size": 746289.0, "replay/inserts": 22176.0, "replay/samples": 22176.0, "replay/insert_wait_avg": 1.3794217790876116e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.022298313322522e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.256729101205801e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2418940067291, "timer/env.step_count": 2772.0, "timer/env.step_total": 254.77462148666382, "timer/env.step_frac": 0.254713007936608, "timer/env.step_avg": 0.09191003661135058, "timer/env.step_min": 0.022928476333618164, "timer/env.step_max": 4.202262878417969, "timer/replay._sample_count": 22176.0, "timer/replay._sample_total": 11.211356163024902, "timer/replay._sample_frac": 0.011208644859009952, "timer/replay._sample_avg": 0.0005055625975390018, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.027469635009765625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3311.0, "timer/agent.policy_total": 53.6424503326416, "timer/agent.policy_frac": 0.05362947768340597, "timer/agent.policy_avg": 0.01620128370058641, "timer/agent.policy_min": 0.00930023193359375, "timer/agent.policy_max": 0.10474872589111328, "timer/dataset_train_count": 1386.0, "timer/dataset_train_total": 0.1512584686279297, "timer/dataset_train_frac": 0.00015122188895930417, "timer/dataset_train_avg": 0.00010913309424814552, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0009062290191650391, "timer/agent.train_count": 1386.0, "timer/agent.train_total": 622.6349213123322, "timer/agent.train_frac": 0.6224843460797328, "timer/agent.train_avg": 0.4492315449583926, "timer/agent.train_min": 0.4352412223815918, "timer/agent.train_max": 1.619889497756958, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.505528450012207, "timer/agent.report_frac": 0.0005054061952826045, "timer/agent.report_avg": 0.2527642250061035, "timer/agent.report_min": 0.24704384803771973, "timer/agent.report_max": 0.2584846019744873, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.581710815429688e-05, "timer/dataset_eval_frac": 7.579877288541846e-08, "timer/dataset_eval_avg": 7.581710815429688e-05, "timer/dataset_eval_min": 7.581710815429688e-05, "timer/dataset_eval_max": 7.581710815429688e-05, "fps": 22.170362121879986}
{"step": 746936, "time": 34419.997103214264, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 747144, "time": 34428.648203372955, "episode/length": 391.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 747224, "time": 34433.050101041794, "episode/length": 322.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 747344, "time": 34438.82955408096, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 747360, "time": 34440.9012093544, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 747896, "time": 34460.127397060394, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9626556016597511, "episode/intrinsic_return": 0.0}
{"step": 747960, "time": 34463.8604285717, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 748176, "time": 34472.864886045456, "episode/length": 275.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 748464, "time": 34484.16758298874, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 748704, "time": 34493.76094651222, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 748880, "time": 34501.37908864021, "episode/length": 87.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 748992, "time": 34506.71757602692, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 749264, "time": 34517.407759428024, "episode/length": 290.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 749416, "time": 34523.89266896248, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 749896, "time": 34541.57737851143, "episode/length": 59.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34571.01371335983, "eval_episode/length": 184.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 750048, "time": 34574.938401937485, "eval_episode/length": 235.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 750048, "time": 34578.04792356491, "eval_episode/length": 270.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.981549815498155}
{"step": 750048, "time": 34580.13204598427, "eval_episode/length": 279.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 750048, "time": 34582.103974580765, "eval_episode/length": 287.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9826388888888888}
{"step": 750048, "time": 34584.45472788811, "eval_episode/length": 306.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.996742671009772}
{"step": 750048, "time": 34588.92662739754, "eval_episode/length": 376.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9973474801061007}
{"step": 750048, "time": 34593.81648135185, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 750432, "time": 34606.70628499985, "episode/length": 383.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 750440, "time": 34608.23979830742, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 750616, "time": 34615.836430072784, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 750704, "time": 34620.49243044853, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 750720, "time": 34622.766694545746, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 751120, "time": 34637.605754852295, "episode/length": 402.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776674937965261, "episode/intrinsic_return": 0.0}
{"step": 751232, "time": 34642.88956928253, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 751264, "time": 34645.457768917084, "episode/length": 249.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 751416, "time": 34651.796239852905, "episode/length": 189.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 751672, "time": 34661.91704726219, "episode/length": 68.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 752448, "time": 34689.499398231506, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 752552, "time": 34694.44927716255, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 752752, "time": 34703.00672149658, "episode/length": 266.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 752776, "time": 34705.1432390213, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 753032, "time": 34715.34938621521, "episode/length": 220.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 753160, "time": 34721.1516559124, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 753472, "time": 34733.36447715759, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 753824, "time": 34748.5195274353, "episode/length": 130.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 754104, "time": 34759.167546749115, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 754248, "time": 34765.55067205429, "episode/length": 376.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9920424403183024, "episode/intrinsic_return": 0.0}
{"step": 754800, "time": 34785.76695084572, "episode/length": 293.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 754952, "time": 34792.33655834198, "episode/length": 105.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 755480, "time": 34811.53529930115, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758620689655172, "episode/intrinsic_return": 0.0}
{"step": 755824, "time": 34824.62893795967, "episode/length": 383.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 756000, "time": 34831.97688651085, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 756032, "time": 34834.57822370529, "episode/length": 374.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946666666666667, "episode/intrinsic_return": 0.0}
{"step": 756272, "time": 34844.269654512405, "episode/length": 183.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 756328, "time": 34847.66103386879, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 756792, "time": 34864.442935705185, "episode/length": 414.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9975903614457832, "episode/intrinsic_return": 0.0}
{"step": 757264, "time": 34882.06944847107, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 757264, "time": 34882.07673573494, "episode/length": 222.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 757336, "time": 34887.43603348732, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 757536, "time": 34895.978526592255, "episode/length": 213.0, "episode/score": 7.099999949336052, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 757600, "time": 34899.75078177452, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 757696, "time": 34904.531997680664, "episode/length": 53.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 757920, "time": 34913.58011698723, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 758008, "time": 34918.032056093216, "episode/length": 209.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 758760, "time": 34944.88008022308, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 758896, "time": 34951.090138196945, "episode/length": 110.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 759104, "time": 34960.12543773651, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 759152, "time": 34963.77910780907, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 759352, "time": 34972.3164665699, "episode/length": 260.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 759632, "time": 34983.354937553406, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 759720, "time": 34987.79758262634, "episode/length": 297.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9899328859060402, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 35018.96428799629, "eval_episode/length": 137.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9637681159420289}
{"step": 760032, "time": 35021.82411503792, "eval_episode/length": 168.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9822485207100592}
{"step": 760032, "time": 35024.023641586304, "eval_episode/length": 180.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.994475138121547}
{"step": 760032, "time": 35026.854964733124, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9663461538461539}
{"step": 760032, "time": 35028.60464024544, "eval_episode/length": 213.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 760032, "time": 35030.353590250015, "eval_episode/length": 217.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9678899082568807}
{"step": 760032, "time": 35032.11502408981, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 760032, "time": 35034.31278800964, "eval_episode/length": 234.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9872340425531915}
{"step": 760408, "time": 35046.78015232086, "episode/length": 310.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 760648, "time": 35056.95999240875, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 760728, "time": 35061.15916085243, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 760896, "time": 35068.44450235367, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 760912, "time": 35070.56514072418, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 761024, "time": 35075.88443827629, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 761304, "time": 35086.53796648979, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 762144, "time": 35117.98236370087, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 762208, "time": 35121.64328503609, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 762280, "time": 35125.44579195976, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 762352, "time": 35129.640983104706, "episode/length": 179.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 762504, "time": 35136.17920589447, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 762632, "time": 35142.02433872223, "episode/length": 200.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 762728, "time": 35146.745885849, "episode/length": 177.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 763104, "time": 35161.0404214859, "episode/length": 336.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 763960, "time": 35190.99520468712, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 764040, "time": 35195.22019696236, "episode/length": 175.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 764440, "time": 35210.18104338646, "episode/length": 260.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 764520, "time": 35214.347927093506, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 764640, "time": 35220.10672187805, "episode/length": 294.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 764696, "time": 35223.26412987709, "episode/length": 198.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 765016, "time": 35235.83242917061, "episode/length": 313.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 765312, "time": 35247.5213098526, "episode/length": 322.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 765800, "time": 35265.26285767555, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 765872, "time": 35269.4657497406, "episode/length": 228.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 766096, "time": 35278.54568243027, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 766096, "time": 35278.55388355255, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 766360, "time": 35290.62992930412, "episode/length": 130.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 766384, "time": 35293.72893357277, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 766856, "time": 35310.6341278553, "episode/length": 269.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 767008, "time": 35317.723281145096, "episode/length": 320.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 767160, "time": 35324.153581380844, "episode/length": 37.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 767328, "time": 35331.818526506424, "episode/length": 153.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 767632, "time": 35343.47197365761, "episode/length": 219.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 767904, "time": 35354.171469688416, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 767944, "time": 35357.27824020386, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 768480, "time": 35377.848450899124, "episode/length": 334.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 768576, "time": 35382.66354584694, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 768576, "time": 35382.67130064964, "episode/length": 273.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 768680, "time": 35389.12796807289, "episode/length": 168.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 769304, "time": 35411.635818719864, "episode/length": 208.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 769353, "time": 35415.82361078262, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.368580919630984, "train/action_min": 0.0, "train/action_std": 3.382743035647886, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045350098335151134, "train/actor_opt_grad_steps": 47280.0, "train/actor_opt_loss": -3.3574701430844076, "train/adv_mag": 0.5696903818042566, "train/adv_max": 0.517060916263161, "train/adv_mean": 0.0036712388595952555, "train/adv_min": -0.4628110368412437, "train/adv_std": 0.06397936384834296, "train/cont_avg": 0.9945561835106383, "train/cont_loss_mean": 0.0003269809881170141, "train/cont_loss_std": 0.009447454403668598, "train/cont_neg_acc": 0.9879939226394004, "train/cont_neg_loss": 0.05484540495491654, "train/cont_pos_acc": 0.9999860664631458, "train/cont_pos_loss": 6.215037227581496e-05, "train/cont_pred": 0.9945972037653551, "train/cont_rate": 0.9945561835106383, "train/dyn_loss_mean": 13.354491889899505, "train/dyn_loss_std": 9.184259955764663, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8405753171190302, "train/extr_critic_critic_opt_grad_steps": 47280.0, "train/extr_critic_critic_opt_loss": 15309.719075520834, "train/extr_critic_mag": 7.810595830281575, "train/extr_critic_max": 7.810595830281575, "train/extr_critic_mean": 2.6410557851723744, "train/extr_critic_min": -0.14994964785609685, "train/extr_critic_std": 1.6485681347813166, "train/extr_return_normed_mag": 1.6190464302157679, "train/extr_return_normed_max": 1.6190464302157679, "train/extr_return_normed_mean": 0.41086296113670295, "train/extr_return_normed_min": -0.18902872682463193, "train/extr_return_normed_std": 0.32476619477813123, "train/extr_return_rate": 0.9490239468026669, "train/extr_return_raw_mag": 8.937057180607573, "train/extr_return_raw_max": 8.937057180607573, "train/extr_return_raw_mean": 2.660133794689855, "train/extr_return_raw_min": -0.45742785185575485, "train/extr_return_raw_std": 1.6877128054909671, "train/extr_reward_mag": 1.0410014399399994, "train/extr_reward_max": 1.0410014399399994, "train/extr_reward_mean": 0.040538831144994035, "train/extr_reward_min": -0.4404201938750896, "train/extr_reward_std": 0.18712749834179032, "train/image_loss_mean": 6.660720182648787, "train/image_loss_std": 12.030938307444254, "train/model_loss_mean": 14.73079305337676, "train/model_loss_std": 15.761680481281687, "train/model_opt_grad_norm": 55.60714701388745, "train/model_opt_grad_steps": 47237.43262411348, "train/model_opt_loss": 18413.491307901153, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5675283797243806, "train/policy_entropy_max": 2.5675283797243806, "train/policy_entropy_mean": 0.5327443085240979, "train/policy_entropy_min": 0.07937501714373311, "train/policy_entropy_std": 0.6644558733236705, "train/policy_logprob_mag": 7.438383707763456, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5318905451196305, "train/policy_logprob_min": -7.438383707763456, "train/policy_logprob_std": 1.09501147608385, "train/policy_randomness_mag": 0.9062248443035369, "train/policy_randomness_max": 0.9062248443035369, "train/policy_randomness_mean": 0.18803536194436093, "train/policy_randomness_min": 0.028015897800842075, "train/policy_randomness_std": 0.23452376368197989, "train/post_ent_mag": 59.46180984821726, "train/post_ent_max": 59.46180984821726, "train/post_ent_mean": 42.25828627998947, "train/post_ent_min": 20.020472797096197, "train/post_ent_std": 7.698589838988392, "train/prior_ent_mag": 68.33859869774352, "train/prior_ent_max": 68.33859869774352, "train/prior_ent_mean": 55.65872874158494, "train/prior_ent_min": 40.59859699222213, "train/prior_ent_std": 4.440989854487967, "train/rep_loss_mean": 13.354491889899505, "train/rep_loss_std": 9.184259955764663, "train/reward_avg": 0.02935990102668392, "train/reward_loss_mean": 0.05705075784989282, "train/reward_loss_std": 0.25363553373526176, "train/reward_max_data": 1.0156028405994388, "train/reward_max_pred": 1.0145488918250334, "train/reward_neg_acc": 0.9924339060242294, "train/reward_neg_loss": 0.029178194391230743, "train/reward_pos_acc": 0.9677664886975119, "train/reward_pos_loss": 0.8459254858341623, "train/reward_pred": 0.028481289334859407, "train/reward_rate": 0.034131205673758866, "train_stats/sum_log_reward": 7.770000120848417, "train_stats/max_log_achievement_collect_coal": 0.51, "train_stats/max_log_achievement_collect_drink": 3.11, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.16, "train_stats/max_log_achievement_collect_stone": 13.85, "train_stats/max_log_achievement_collect_wood": 9.2, "train_stats/max_log_achievement_defeat_skeleton": 0.03, "train_stats/max_log_achievement_defeat_zombie": 0.78, "train_stats/max_log_achievement_eat_cow": 0.06, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.02, "train_stats/max_log_achievement_make_wood_pickaxe": 1.87, "train_stats/max_log_achievement_make_wood_sword": 0.02, "train_stats/max_log_achievement_place_furnace": 0.13, "train_stats/max_log_achievement_place_plant": 1.16, "train_stats/max_log_achievement_place_stone": 10.89, "train_stats/max_log_achievement_place_table": 2.59, "train_stats/max_log_achievement_wake_up": 1.45, "train_stats/mean_log_entropy": 0.5930469760298729, "eval_stats/sum_log_reward": 8.16250017285347, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_iron": 0.0625, "eval_stats/max_log_achievement_collect_sapling": 1.0625, "eval_stats/max_log_achievement_collect_stone": 15.3125, "eval_stats/max_log_achievement_collect_wood": 7.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 11.8125, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 6.74929833621718e-06, "report/cont_loss_std": 5.747949398937635e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5731502319104038e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.693522664136253e-06, "report/cont_pred": 0.9970636963844299, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 15.13217830657959, "report/dyn_loss_std": 9.161792755126953, "report/image_loss_mean": 7.344487190246582, "report/image_loss_std": 11.38668441772461, "report/model_loss_mean": 16.492774963378906, "report/model_loss_std": 14.82161808013916, "report/post_ent_mag": 57.81541442871094, "report/post_ent_max": 57.81541442871094, "report/post_ent_mean": 41.63494873046875, "report/post_ent_min": 18.02444076538086, "report/post_ent_std": 7.794867992401123, "report/prior_ent_mag": 68.1031494140625, "report/prior_ent_max": 68.1031494140625, "report/prior_ent_mean": 56.659141540527344, "report/prior_ent_min": 40.294593811035156, "report/prior_ent_std": 4.438720226287842, "report/rep_loss_mean": 15.13217830657959, "report/rep_loss_std": 9.161792755126953, "report/reward_avg": 0.03828125074505806, "report/reward_loss_mean": 0.06897445023059845, "report/reward_loss_std": 0.31504735350608826, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004194736480713, "report/reward_neg_acc": 0.9898167252540588, "report/reward_neg_loss": 0.030354155227541924, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.971953809261322, "report/reward_pred": 0.037544526159763336, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.812934351619333e-05, "eval/cont_loss_std": 0.00022297118266578764, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010287307668477297, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5159896065597422e-05, "eval/cont_pred": 0.9970582127571106, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.59563636779785, "eval/dyn_loss_std": 10.574311256408691, "eval/image_loss_mean": 11.460556983947754, "eval/image_loss_std": 18.66351318359375, "eval/model_loss_mean": 22.11266326904297, "eval/model_loss_std": 22.33961296081543, "eval/post_ent_mag": 59.25524139404297, "eval/post_ent_max": 59.25524139404297, "eval/post_ent_mean": 40.25288391113281, "eval/post_ent_min": 19.21731185913086, "eval/post_ent_std": 7.827911376953125, "eval/prior_ent_mag": 68.1031494140625, "eval/prior_ent_max": 68.1031494140625, "eval/prior_ent_mean": 55.930946350097656, "eval/prior_ent_min": 42.050193786621094, "eval/prior_ent_std": 4.537948131561279, "eval/rep_loss_mean": 17.59563636779785, "eval/rep_loss_std": 10.574311256408691, "eval/reward_avg": 0.02998046949505806, "eval/reward_loss_mean": 0.0947052538394928, "eval/reward_loss_std": 0.48736801743507385, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012028217315674, "eval/reward_neg_acc": 0.9908998012542725, "eval/reward_neg_loss": 0.04555584490299225, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 1.4835270643234253, "eval/reward_pred": 0.028046779334545135, "eval/reward_rate": 0.0341796875, "replay/size": 768849.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.3614799959439758e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.207966479849308e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1675395993339616e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4170207977295, "timer/env.step_count": 2820.0, "timer/env.step_total": 238.019061088562, "timer/env.step_frac": 0.2379198435656026, "timer/env.step_avg": 0.0844039223718305, "timer/env.step_min": 0.022683143615722656, "timer/env.step_max": 3.40368390083313, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.40494990348816, "timer/replay._sample_frac": 0.01140019578474773, "timer/replay._sample_avg": 0.0005055385595517801, "timer/replay._sample_min": 0.00040984153747558594, "timer/replay._sample_max": 0.009106636047363281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3507.0, "timer/agent.policy_total": 58.35779690742493, "timer/agent.policy_frac": 0.05833347063696557, "timer/agent.policy_avg": 0.01664037550824777, "timer/agent.policy_min": 0.009378433227539062, "timer/agent.policy_max": 0.12324738502502441, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.15227794647216797, "timer/dataset_train_frac": 0.00015221446987251575, "timer/dataset_train_avg": 0.00010799854359728225, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0004916191101074219, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 632.148113489151, "timer/agent.train_frac": 0.6318846044673231, "timer/agent.train_avg": 0.4483319953823766, "timer/agent.train_min": 0.4344775676727295, "timer/agent.train_max": 1.6480045318603516, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4802286624908447, "timer/agent.report_frac": 0.00048002848063091914, "timer/agent.report_avg": 0.24011433124542236, "timer/agent.report_min": 0.2351360321044922, "timer/agent.report_max": 0.24509263038635254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9551580185050812e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.550288229215614}
{"step": 769560, "time": 35422.53488135338, "episode/length": 122.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 769760, "time": 35430.94708442688, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 769816, "time": 35434.12177872658, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 769928, "time": 35439.51675415039, "episode/length": 180.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35459.38110232353, "eval_episode/length": 49.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 770016, "time": 35465.86074066162, "eval_episode/length": 161.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 770016, "time": 35467.80646395683, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 770016, "time": 35469.603159189224, "eval_episode/length": 176.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 770016, "time": 35471.24383234978, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 770016, "time": 35473.2904586792, "eval_episode/length": 190.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 770016, "time": 35475.036465168, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 770016, "time": 35480.035247564316, "eval_episode/length": 272.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9963369963369964}
{"step": 770152, "time": 35486.025718688965, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 770184, "time": 35488.66007757187, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 770248, "time": 35492.26531624794, "episode/length": 385.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9974093264248705, "episode/intrinsic_return": 0.0}
{"step": 770904, "time": 35515.82379961014, "episode/length": 89.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 771536, "time": 35539.133846998215, "episode/length": 221.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 771680, "time": 35545.40302014351, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 772120, "time": 35561.306316137314, "episode/length": 319.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 772160, "time": 35564.3211350441, "episode/length": 356.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 772176, "time": 35566.35122728348, "episode/length": 158.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 772240, "time": 35570.032366752625, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 772560, "time": 35582.139172554016, "episode/length": 109.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 772888, "time": 35594.46984243393, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 772920, "time": 35597.06928086281, "episode/length": 92.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 773120, "time": 35605.49093580246, "episode/length": 109.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 773248, "time": 35611.304580926895, "episode/length": 414.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9903614457831326, "episode/intrinsic_return": 0.0}
{"step": 773664, "time": 35626.86925625801, "episode/length": 426.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 773792, "time": 35633.15596294403, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 774064, "time": 35644.308623075485, "episode/length": 49.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 774312, "time": 35654.53332591057, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 774552, "time": 35664.09757256508, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 774728, "time": 35671.53105401993, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 774848, "time": 35677.531566381454, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 774936, "time": 35681.71636223793, "episode/length": 210.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 775016, "time": 35686.409866809845, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 775456, "time": 35702.80931830406, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 775784, "time": 35715.330951690674, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 775888, "time": 35720.547980070114, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 776072, "time": 35727.99580335617, "episode/length": 141.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 776504, "time": 35744.05017161369, "episode/length": 243.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 776696, "time": 35751.984689712524, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 776944, "time": 35762.04155540466, "episode/length": 276.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 776992, "time": 35765.31647825241, "episode/length": 267.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 777280, "time": 35776.476799964905, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 777296, "time": 35778.702380657196, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 777392, "time": 35783.50381875038, "episode/length": 164.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 778128, "time": 35809.52300834656, "episode/length": 333.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9850299401197605, "episode/intrinsic_return": 0.0}
{"step": 778360, "time": 35820.35611248016, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 778464, "time": 35825.98781824112, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 778496, "time": 35828.787157297134, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 778752, "time": 35839.3836107254, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 778776, "time": 35841.46363854408, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 778840, "time": 35845.22003340721, "episode/length": 192.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 779808, "time": 35879.176597356796, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 779984, "time": 35886.87097740173, "episode/length": 142.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35889.113719940186, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35911.545545578, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 780000, "time": 35914.22935962677, "eval_episode/length": 208.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 780000, "time": 35916.22691369057, "eval_episode/length": 214.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 780000, "time": 35919.23433971405, "eval_episode/length": 247.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9637096774193549}
{"step": 780000, "time": 35921.018949747086, "eval_episode/length": 253.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9763779527559056}
{"step": 780000, "time": 35922.852449417114, "eval_episode/length": 259.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 780000, "time": 35926.15352296829, "eval_episode/length": 302.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 780000, "time": 35927.70143389702, "eval_episode/length": 56.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 780112, "time": 35933.02672290802, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 780408, "time": 35944.26084780693, "episode/length": 376.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 780440, "time": 35946.98625469208, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 780848, "time": 35962.17800068855, "episode/length": 297.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 781432, "time": 35982.8758058548, "episode/length": 412.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9878934624697336, "episode/intrinsic_return": 0.0}
{"step": 781592, "time": 35989.86507320404, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 781640, "time": 35992.964545726776, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 781920, "time": 36004.05371379852, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 782208, "time": 36015.3071706295, "episode/length": 261.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 782312, "time": 36020.11506772041, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 782536, "time": 36029.31943678856, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 782848, "time": 36041.46676325798, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 782928, "time": 36045.71636390686, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 783168, "time": 36055.50215768814, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 783248, "time": 36059.68692564964, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 783488, "time": 36069.32753252983, "episode/length": 146.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 783504, "time": 36071.30666637421, "episode/length": 238.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 783824, "time": 36083.370059490204, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 783880, "time": 36087.04414987564, "episode/length": 78.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 784208, "time": 36100.13716387749, "episode/length": 47.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 784256, "time": 36103.293686151505, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 784672, "time": 36119.31076145172, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 784816, "time": 36125.880669116974, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 784832, "time": 36127.984513521194, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 785272, "time": 36143.86889958382, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 785352, "time": 36148.149512290955, "episode/length": 64.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 785552, "time": 36156.557751894, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 785856, "time": 36168.14750266075, "episode/length": 37.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 785888, "time": 36170.87390089035, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 786144, "time": 36180.78838014603, "episode/length": 411.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 786176, "time": 36183.465420246124, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 786608, "time": 36201.111142635345, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 786616, "time": 36202.64567399025, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 786840, "time": 36211.6166331768, "episode/length": 322.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 787288, "time": 36228.06469988823, "episode/length": 55.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 787304, "time": 36230.20990562439, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 787344, "time": 36233.311568021774, "episode/length": 315.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 787384, "time": 36235.92472076416, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 787648, "time": 36246.68250966072, "episode/length": 219.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 787976, "time": 36259.07805228233, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 788272, "time": 36270.69039773941, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 788312, "time": 36273.36402773857, "episode/length": 82.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 788584, "time": 36283.97892165184, "episode/length": 300.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 788704, "time": 36289.94785785675, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 789160, "time": 36306.49450683594, "episode/length": 147.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 789312, "time": 36313.36518073082, "episode/length": 252.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 789696, "time": 36327.64640235901, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 789880, "time": 36335.37540411949, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 790056, "time": 36343.05971741676, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854651162790697, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 36365.40060830116, "eval_episode/length": 159.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 790088, "time": 36367.63750886917, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 790088, "time": 36369.93880414963, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 790088, "time": 36371.68097829819, "eval_episode/length": 193.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 790088, "time": 36373.56893348694, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 790088, "time": 36375.95839071274, "eval_episode/length": 218.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 790088, "time": 36377.92469334602, "eval_episode/length": 227.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 790088, "time": 36381.937638282776, "eval_episode/length": 285.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9965034965034965}
{"step": 790432, "time": 36393.547354221344, "episode/length": 269.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 790432, "time": 36393.55452299118, "episode/length": 139.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 790544, "time": 36400.55949783325, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 790568, "time": 36402.66236162186, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 790889, "time": 36415.83625650406, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.363730649594907, "train/action_min": 0.0, "train/action_std": 3.4070497353871665, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04222860339063185, "train/actor_opt_grad_steps": 48660.0, "train/actor_opt_loss": -10.803440424192834, "train/adv_mag": 0.5400946250668278, "train/adv_max": 0.4851623232717867, "train/adv_mean": 0.0019488957981324078, "train/adv_min": -0.43354913548186974, "train/adv_std": 0.05915019688782869, "train/cont_avg": 0.9948857060185186, "train/cont_loss_mean": 0.000208711583675941, "train/cont_loss_std": 0.006408411548408434, "train/cont_neg_acc": 0.9933156980408563, "train/cont_neg_loss": 0.02580397052446036, "train/cont_pos_acc": 0.9999854538175795, "train/cont_pos_loss": 3.7097933485736376e-05, "train/cont_pred": 0.9949154054677045, "train/cont_rate": 0.9948857060185186, "train/dyn_loss_mean": 13.326194374649614, "train/dyn_loss_std": 9.150285855046025, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8471897902312102, "train/extr_critic_critic_opt_grad_steps": 48660.0, "train/extr_critic_critic_opt_loss": 15368.268648726851, "train/extr_critic_mag": 7.957884837962963, "train/extr_critic_max": 7.957884837962963, "train/extr_critic_mean": 2.6094575449272437, "train/extr_critic_min": -0.13967824423754657, "train/extr_critic_std": 1.7167904836160166, "train/extr_return_normed_mag": 1.576626397062231, "train/extr_return_normed_max": 1.576626397062231, "train/extr_return_normed_mean": 0.3995218396186829, "train/extr_return_normed_min": -0.15784554613961113, "train/extr_return_normed_std": 0.3172665136831778, "train/extr_return_rate": 0.9221870656366702, "train/extr_return_raw_mag": 9.107015214142976, "train/extr_return_raw_max": 9.107015214142976, "train/extr_return_raw_mean": 2.6201613973688196, "train/extr_return_raw_min": -0.44941970893630273, "train/extr_return_raw_std": 1.748087556273849, "train/extr_reward_mag": 1.0416229671902126, "train/extr_reward_max": 1.0416229671902126, "train/extr_reward_mean": 0.03957263918386565, "train/extr_reward_min": -0.4220865903077302, "train/extr_reward_std": 0.18493418605239303, "train/image_loss_mean": 6.706338334966589, "train/image_loss_std": 11.88530581438983, "train/model_loss_mean": 14.758315418384694, "train/model_loss_std": 15.632165449636954, "train/model_opt_grad_norm": 54.71084125660084, "train/model_opt_grad_steps": 48616.2, "train/model_opt_loss": 20526.47926070602, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1388.888888888889, "train/policy_entropy_mag": 2.5583683243504276, "train/policy_entropy_max": 2.5583683243504276, "train/policy_entropy_mean": 0.5192880091843781, "train/policy_entropy_min": 0.07937501459210007, "train/policy_entropy_std": 0.6624689777692159, "train/policy_logprob_mag": 7.438383759392632, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.51974137712408, "train/policy_logprob_min": -7.438383759392632, "train/policy_logprob_std": 1.0893917542916758, "train/policy_randomness_mag": 0.9029917500637196, "train/policy_randomness_max": 0.9029917500637196, "train/policy_randomness_mean": 0.18328588053032205, "train/policy_randomness_min": 0.028015896940120945, "train/policy_randomness_std": 0.2338224759808293, "train/post_ent_mag": 59.388711886935766, "train/post_ent_max": 59.388711886935766, "train/post_ent_mean": 42.27300836068613, "train/post_ent_min": 20.170400506478767, "train/post_ent_std": 7.6260576177526405, "train/prior_ent_mag": 68.31155887179905, "train/prior_ent_max": 68.31155887179905, "train/prior_ent_mean": 55.669818284776476, "train/prior_ent_min": 40.7387893959328, "train/prior_ent_std": 4.4203494760725235, "train/rep_loss_mean": 13.326194374649614, "train/rep_loss_std": 9.150285855046025, "train/reward_avg": 0.028556857589218353, "train/reward_loss_mean": 0.05605172768787101, "train/reward_loss_std": 0.2451975351130521, "train/reward_max_data": 1.016296300181636, "train/reward_max_pred": 1.0148584383505361, "train/reward_neg_acc": 0.9924624959627787, "train/reward_neg_loss": 0.02924627530629988, "train/reward_pos_acc": 0.9719058994893675, "train/reward_pos_loss": 0.8340637811908016, "train/reward_pred": 0.02779422565880749, "train/reward_rate": 0.03325376157407407, "train_stats/sum_log_reward": 7.884313917627521, "train_stats/max_log_achievement_collect_coal": 0.7254901960784313, "train_stats/max_log_achievement_collect_drink": 3.5784313725490198, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.2549019607843137, "train_stats/max_log_achievement_collect_stone": 12.196078431372548, "train_stats/max_log_achievement_collect_wood": 8.735294117647058, "train_stats/max_log_achievement_defeat_skeleton": 0.00980392156862745, "train_stats/max_log_achievement_defeat_zombie": 0.803921568627451, "train_stats/max_log_achievement_eat_cow": 0.0784313725490196, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.00980392156862745, "train_stats/max_log_achievement_make_stone_sword": 0.00980392156862745, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7352941176470589, "train_stats/max_log_achievement_make_wood_sword": 0.00980392156862745, "train_stats/max_log_achievement_place_furnace": 0.08823529411764706, "train_stats/max_log_achievement_place_plant": 1.1666666666666667, "train_stats/max_log_achievement_place_stone": 8.754901960784315, "train_stats/max_log_achievement_place_table": 2.5392156862745097, "train_stats/max_log_achievement_wake_up": 1.4019607843137254, "train_stats/mean_log_entropy": 0.5388673494259516, "eval_stats/sum_log_reward": 8.141666799783707, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.5416666666666665, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 10.125, "eval_stats/max_log_achievement_collect_wood": 9.666666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 1.3333333333333333, "eval_stats/max_log_achievement_place_stone": 7.541666666666667, "eval_stats/max_log_achievement_place_table": 2.7916666666666665, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.4768604160053656e-05, "report/cont_loss_std": 0.00038924140972085297, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.630362541822251e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4712005395267624e-05, "report/cont_pred": 0.9951027631759644, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.254677772521973, "report/dyn_loss_std": 9.515875816345215, "report/image_loss_mean": 6.390749454498291, "report/image_loss_std": 12.371685028076172, "report/model_loss_mean": 14.413406372070312, "report/model_loss_std": 16.247879028320312, "report/post_ent_mag": 60.20381546020508, "report/post_ent_max": 60.20381546020508, "report/post_ent_mean": 42.03760528564453, "report/post_ent_min": 20.877443313598633, "report/post_ent_std": 7.953190803527832, "report/prior_ent_mag": 68.33433532714844, "report/prior_ent_max": 68.33433532714844, "report/prior_ent_mean": 55.61973571777344, "report/prior_ent_min": 40.50363540649414, "report/prior_ent_std": 4.884936332702637, "report/rep_loss_mean": 13.254677772521973, "report/rep_loss_std": 9.515875816345215, "report/reward_avg": 0.04179687425494194, "report/reward_loss_mean": 0.06983581930398941, "report/reward_loss_std": 0.33188530802726746, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041167736053467, "report/reward_neg_acc": 0.9959099888801575, "report/reward_neg_loss": 0.028559772297739983, "report/reward_pos_acc": 0.9347826242446899, "report/reward_pos_loss": 0.9474006295204163, "report/reward_pred": 0.038696177303791046, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.294146103551611e-05, "eval/cont_loss_std": 0.0016380111919716, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002648827794473618, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.211031384533271e-05, "eval/cont_pred": 0.9960442781448364, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.702037811279297, "eval/dyn_loss_std": 11.313882827758789, "eval/image_loss_mean": 12.365468978881836, "eval/image_loss_std": 22.059728622436523, "eval/model_loss_mean": 23.687238693237305, "eval/model_loss_std": 26.100440979003906, "eval/post_ent_mag": 54.96337890625, "eval/post_ent_max": 54.96337890625, "eval/post_ent_mean": 39.47651290893555, "eval/post_ent_min": 19.858489990234375, "eval/post_ent_std": 7.620420455932617, "eval/prior_ent_mag": 68.33433532714844, "eval/prior_ent_max": 68.33433532714844, "eval/prior_ent_mean": 55.46333694458008, "eval/prior_ent_min": 42.086856842041016, "eval/prior_ent_std": 4.308487892150879, "eval/rep_loss_mean": 18.702037811279297, "eval/rep_loss_std": 11.313882827758789, "eval/reward_avg": 0.03916015475988388, "eval/reward_loss_mean": 0.1004943922162056, "eval/reward_loss_std": 0.5533154010772705, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.006462812423706, "eval/reward_neg_acc": 0.9928570985794067, "eval/reward_neg_loss": 0.03932919353246689, "eval/reward_pos_acc": 0.886363685131073, "eval/reward_pos_loss": 1.4628103971481323, "eval/reward_pred": 0.035208795219659805, "eval/reward_rate": 0.04296875, "replay/size": 790385.0, "replay/inserts": 21536.0, "replay/samples": 21536.0, "replay/insert_wait_avg": 1.3928600264516662e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.215250057770274e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1618766519758437e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0003213882446, "timer/env.step_count": 2692.0, "timer/env.step_total": 236.38628768920898, "timer/env.step_frac": 0.23638621171745935, "timer/env.step_avg": 0.0878106566453228, "timer/env.step_min": 0.022837162017822266, "timer/env.step_max": 3.3232479095458984, "timer/replay._sample_count": 21536.0, "timer/replay._sample_total": 11.202561378479004, "timer/replay._sample_frac": 0.011202557778108625, "timer/replay._sample_avg": 0.000520178370100251, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.011166810989379883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3556.0, "timer/agent.policy_total": 59.381959199905396, "timer/agent.policy_frac": 0.0593819401152479, "timer/agent.policy_avg": 0.01669908863889353, "timer/agent.policy_min": 0.009264469146728516, "timer/agent.policy_max": 0.12144088745117188, "timer/dataset_train_count": 1346.0, "timer/dataset_train_total": 0.14833593368530273, "timer/dataset_train_frac": 0.00014833588601189271, "timer/dataset_train_avg": 0.00011020500273796637, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0009212493896484375, "timer/agent.train_count": 1346.0, "timer/agent.train_total": 603.9576394557953, "timer/agent.train_frac": 0.6039574453509721, "timer/agent.train_avg": 0.4487055270845433, "timer/agent.train_min": 0.4353344440460205, "timer/agent.train_max": 1.645484209060669, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48134684562683105, "timer/agent.report_frac": 0.000481346690927663, "timer/agent.report_avg": 0.24067342281341553, "timer/agent.report_min": 0.23752593994140625, "timer/agent.report_max": 0.2438209056854248, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.288818359375e-05, "timer/dataset_eval_frac": 2.2888176237759216e-08, "timer/dataset_eval_avg": 2.288818359375e-05, "timer/dataset_eval_min": 2.288818359375e-05, "timer/dataset_eval_max": 2.288818359375e-05, "fps": 21.535721647610195}
{"step": 791072, "time": 36421.95825171471, "episode/length": 238.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 791584, "time": 36440.472448825836, "episode/length": 235.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 791896, "time": 36452.31057071686, "episode/length": 165.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 791904, "time": 36454.836013793945, "episode/length": 252.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 792056, "time": 36462.022304058075, "episode/length": 249.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 792192, "time": 36468.33783698082, "episode/length": 219.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 792416, "time": 36477.35636854172, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 792464, "time": 36480.619737148285, "episode/length": 253.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 793056, "time": 36501.900933504105, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 793280, "time": 36510.87344408035, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 793424, "time": 36517.504868507385, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 793464, "time": 36520.19784975052, "episode/length": 298.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 793472, "time": 36522.31987142563, "episode/length": 23.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 793576, "time": 36527.20206427574, "episode/length": 189.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 793888, "time": 36539.4267578125, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 794280, "time": 36553.89372777939, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 794352, "time": 36557.99274682999, "episode/length": 269.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 794776, "time": 36575.437898635864, "episode/length": 52.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 794832, "time": 36579.11359333992, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 794920, "time": 36583.59770321846, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 794952, "time": 36586.09220790863, "episode/length": 236.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 795144, "time": 36593.934497117996, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 795280, "time": 36600.23548364639, "episode/length": 40.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 795328, "time": 36603.36923670769, "episode/length": 218.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 795720, "time": 36617.91060590744, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 795784, "time": 36621.7487282753, "episode/length": 236.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 796344, "time": 36642.07449007034, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 796344, "time": 36642.082559108734, "episode/length": 195.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 796400, "time": 36647.700234889984, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 796552, "time": 36654.583156347275, "episode/length": 152.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 796704, "time": 36661.48387479782, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 796904, "time": 36669.49842309952, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 797480, "time": 36690.21195578575, "episode/length": 211.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 797552, "time": 36694.95040845871, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 797744, "time": 36703.10388469696, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 797832, "time": 36707.49357008934, "episode/length": 185.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 798232, "time": 36722.37956285477, "episode/length": 313.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9777070063694268, "episode/intrinsic_return": 0.0}
{"step": 798248, "time": 36724.58735895157, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 798384, "time": 36731.12791919708, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 798440, "time": 36734.32270860672, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 798584, "time": 36740.570607185364, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 799248, "time": 36764.573315382004, "episode/length": 176.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 799328, "time": 36768.814972639084, "episode/length": 230.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 799384, "time": 36772.009726285934, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 799440, "time": 36775.582782030106, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 799968, "time": 36794.721239089966, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 800000, "time": 36797.36235880852, "episode/length": 305.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 36820.963141441345, "eval_episode/length": 152.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 800072, "time": 36822.5469994545, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 800072, "time": 36824.17886400223, "eval_episode/length": 154.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 800072, "time": 36825.77037906647, "eval_episode/length": 156.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 800072, "time": 36828.94565272331, "eval_episode/length": 37.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 800072, "time": 36830.833844423294, "eval_episode/length": 200.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 800072, "time": 36833.460545778275, "eval_episode/length": 223.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 800072, "time": 36836.16835927963, "eval_episode/length": 95.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9375}
{"step": 800592, "time": 36853.74302530289, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 800696, "time": 36858.653057813644, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 800816, "time": 36864.33919048309, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 801016, "time": 36872.28606271744, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 801040, "time": 36874.919605493546, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 801432, "time": 36889.18860054016, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 801624, "time": 36897.539815187454, "episode/length": 286.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 801808, "time": 36905.91071677208, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 802040, "time": 36915.11194562912, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 802352, "time": 36927.235654592514, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 802376, "time": 36929.370567560196, "episode/length": 194.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 802424, "time": 36932.52202415466, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 802512, "time": 36937.35859084129, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 802648, "time": 36943.23498725891, "episode/length": 151.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 802840, "time": 36952.885253190994, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 802912, "time": 36957.11338162422, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 803728, "time": 36985.97613310814, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 803736, "time": 36987.52768778801, "episode/length": 240.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 804104, "time": 37001.31468987465, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 804112, "time": 37003.34369277954, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 804368, "time": 37013.54202246666, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 804496, "time": 37019.43188524246, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 804736, "time": 37028.94513964653, "episode/length": 288.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9930795847750865, "episode/intrinsic_return": 0.0}
{"step": 805360, "time": 37051.233897686005, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 805608, "time": 37061.095757722855, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 805648, "time": 37064.184369802475, "episode/length": 411.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 805744, "time": 37068.98032832146, "episode/length": 125.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 805944, "time": 37076.98165011406, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 805992, "time": 37080.13913273811, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 806024, "time": 37082.80003619194, "episode/length": 34.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 806176, "time": 37089.652105093, "episode/length": 305.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 806560, "time": 37103.83966588974, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 806776, "time": 37112.27609419823, "episode/length": 379.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 806984, "time": 37120.822828769684, "episode/length": 119.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 807040, "time": 37124.38460063934, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 807208, "time": 37131.4118270874, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 807328, "time": 37137.30232453346, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 807336, "time": 37138.91154265404, "episode/length": 43.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 807408, "time": 37142.99514389038, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 808248, "time": 37172.22891163826, "episode/length": 129.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 808352, "time": 37177.681033849716, "episode/length": 223.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 808656, "time": 37189.446021556854, "episode/length": 165.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 808936, "time": 37200.1917848587, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 808952, "time": 37202.324724435806, "episode/length": 238.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 809048, "time": 37207.144461393356, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683098591549296, "episode/intrinsic_return": 0.0}
{"step": 809152, "time": 37212.45673394203, "episode/length": 226.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 809200, "time": 37215.679505348206, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 809520, "time": 37228.04704284668, "episode/length": 158.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 809976, "time": 37245.49509382248, "episode/length": 102.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 37265.61125707626, "eval_episode/length": 60.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 810056, "time": 37272.438660144806, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 810056, "time": 37274.34173440933, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 810056, "time": 37275.93007159233, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 810056, "time": 37275.93710947037, "eval_episode/length": 191.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 810056, "time": 37280.49874687195, "eval_episode/length": 221.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 810056, "time": 37286.75446677208, "eval_episode/length": 285.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9825174825174825}
{"step": 810056, "time": 37291.59025835991, "eval_episode/length": 287.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9895833333333334}
{"step": 810288, "time": 37299.59784865379, "episode/length": 241.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 810328, "time": 37302.146502017975, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 810424, "time": 37306.92376732826, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 810552, "time": 37312.80120635033, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 810832, "time": 37323.91714334488, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 811336, "time": 37343.92398452759, "episode/length": 266.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 811704, "time": 37357.860975027084, "episode/length": 176.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 811784, "time": 37362.13986182213, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 811848, "time": 37365.816496133804, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 811848, "time": 37365.82390379906, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 812192, "time": 37380.75447010994, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 812224, "time": 37383.38278865814, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 812280, "time": 37387.00193977356, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 812864, "time": 37408.17336130142, "episode/length": 190.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 813033, "time": 37416.194132089615, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.440603062726449, "train/action_min": 0.0, "train/action_std": 3.4443208462950112, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04330866998466461, "train/actor_opt_grad_steps": 50025.0, "train/actor_opt_loss": -7.433070151972166, "train/adv_mag": 0.5272803682348003, "train/adv_max": 0.48803228679774463, "train/adv_mean": 0.002568269130384526, "train/adv_min": -0.4287562643488248, "train/adv_std": 0.06003257467586925, "train/cont_avg": 0.9950039628623188, "train/cont_loss_mean": 0.00014794565220838189, "train/cont_loss_std": 0.004378461716573773, "train/cont_neg_acc": 0.9946859906549039, "train/cont_neg_loss": 0.019667879785037836, "train/cont_pos_acc": 0.9999786356221074, "train/cont_pos_loss": 6.921339372129906e-05, "train/cont_pred": 0.9949961956860363, "train/cont_rate": 0.9950039628623188, "train/dyn_loss_mean": 13.179006555806035, "train/dyn_loss_std": 9.16615488909293, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8726336653681769, "train/extr_critic_critic_opt_grad_steps": 50025.0, "train/extr_critic_critic_opt_loss": 15548.994041553442, "train/extr_critic_mag": 8.00365896501403, "train/extr_critic_max": 8.00365896501403, "train/extr_critic_mean": 2.5935661533604497, "train/extr_critic_min": -0.15268286933069644, "train/extr_critic_std": 1.7263249867204307, "train/extr_return_normed_mag": 1.5851895714151687, "train/extr_return_normed_max": 1.5851895714151687, "train/extr_return_normed_mean": 0.40035703961831937, "train/extr_return_normed_min": -0.15040615028229312, "train/extr_return_normed_std": 0.31488017878238705, "train/extr_return_rate": 0.9213886533094489, "train/extr_return_raw_mag": 9.237290251082268, "train/extr_return_raw_max": 9.237290251082268, "train/extr_return_raw_mean": 2.6079198260238203, "train/extr_return_raw_min": -0.4738884906190029, "train/extr_return_raw_std": 1.761841186578723, "train/extr_reward_mag": 1.046185458915821, "train/extr_reward_max": 1.046185458915821, "train/extr_reward_mean": 0.04118309889420651, "train/extr_reward_min": -0.4603548239970553, "train/extr_reward_std": 0.188778900473878, "train/image_loss_mean": 6.494602158449698, "train/image_loss_std": 11.475182630013729, "train/model_loss_mean": 14.458552422730818, "train/model_loss_std": 15.24332837090976, "train/model_opt_grad_norm": 57.92410289377406, "train/model_opt_grad_steps": 49979.74637681159, "train/model_opt_loss": 18419.713343523552, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1277.1739130434783, "train/policy_entropy_mag": 2.566994445911352, "train/policy_entropy_max": 2.566994445911352, "train/policy_entropy_mean": 0.5316820589528568, "train/policy_entropy_min": 0.0793750148428523, "train/policy_entropy_std": 0.6652269086975983, "train/policy_logprob_mag": 7.438383734744528, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5325682685858961, "train/policy_logprob_min": -7.438383734744528, "train/policy_logprob_std": 1.0990408106126648, "train/policy_randomness_mag": 0.9060363877510679, "train/policy_randomness_max": 0.9060363877510679, "train/policy_randomness_mean": 0.18766043842702673, "train/policy_randomness_min": 0.02801589702890403, "train/policy_randomness_std": 0.23479590456986774, "train/post_ent_mag": 59.30177895919137, "train/post_ent_max": 59.30177895919137, "train/post_ent_mean": 42.35851818582286, "train/post_ent_min": 20.193891262662582, "train/post_ent_std": 7.62468155225118, "train/prior_ent_mag": 68.33982550579569, "train/prior_ent_max": 68.33982550579569, "train/prior_ent_mean": 55.58711836994558, "train/prior_ent_min": 40.4166879515717, "train/prior_ent_std": 4.474874892096588, "train/rep_loss_mean": 13.179006555806035, "train/rep_loss_std": 9.16615488909293, "train/reward_avg": 0.029285552169101826, "train/reward_loss_mean": 0.05639848987693372, "train/reward_loss_std": 0.2494218208003735, "train/reward_max_data": 1.0224637734717217, "train/reward_max_pred": 1.0174463572709456, "train/reward_neg_acc": 0.9925387726313826, "train/reward_neg_loss": 0.02907897571803651, "train/reward_pos_acc": 0.9690214957016102, "train/reward_pos_loss": 0.8374820951966272, "train/reward_pred": 0.028511402048710464, "train/reward_rate": 0.03392493206521739, "train_stats/sum_log_reward": 7.809091096439145, "train_stats/max_log_achievement_collect_coal": 0.6636363636363637, "train_stats/max_log_achievement_collect_drink": 3.227272727272727, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.1636363636363636, "train_stats/max_log_achievement_collect_stone": 11.39090909090909, "train_stats/max_log_achievement_collect_wood": 8.554545454545455, "train_stats/max_log_achievement_defeat_skeleton": 0.01818181818181818, "train_stats/max_log_achievement_defeat_zombie": 0.6818181818181818, "train_stats/max_log_achievement_eat_cow": 0.08181818181818182, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.00909090909090909, "train_stats/max_log_achievement_make_stone_sword": 0.01818181818181818, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8181818181818181, "train_stats/max_log_achievement_make_wood_sword": 0.045454545454545456, "train_stats/max_log_achievement_place_furnace": 0.10909090909090909, "train_stats/max_log_achievement_place_plant": 1.1181818181818182, "train_stats/max_log_achievement_place_stone": 8.254545454545454, "train_stats/max_log_achievement_place_table": 2.6454545454545455, "train_stats/max_log_achievement_wake_up": 1.2545454545454546, "train_stats/mean_log_entropy": 0.5439334118908102, "eval_stats/sum_log_reward": 7.100000225007534, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 2.6875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 10.6875, "eval_stats/max_log_achievement_collect_wood": 7.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_stone": 7.0, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.8122568690159824e-07, "report/cont_loss_std": 2.33199170907028e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.3942149002541555e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.622886287577785e-07, "report/cont_pred": 0.9941405057907104, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.589439392089844, "report/dyn_loss_std": 9.108890533447266, "report/image_loss_mean": 7.462336540222168, "report/image_loss_std": 16.009321212768555, "report/model_loss_mean": 15.6531982421875, "report/model_loss_std": 19.311662673950195, "report/post_ent_mag": 57.79521179199219, "report/post_ent_max": 57.79521179199219, "report/post_ent_mean": 41.76072692871094, "report/post_ent_min": 19.308229446411133, "report/post_ent_std": 7.500840187072754, "report/prior_ent_mag": 68.40731048583984, "report/prior_ent_max": 68.40731048583984, "report/prior_ent_mean": 55.29774475097656, "report/prior_ent_min": 38.052574157714844, "report/prior_ent_std": 4.777927875518799, "report/rep_loss_mean": 13.589439392089844, "report/rep_loss_std": 9.108890533447266, "report/reward_avg": 0.01816406100988388, "report/reward_loss_mean": 0.037199005484580994, "report/reward_loss_std": 0.16112904250621796, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9996018409729004, "report/reward_neg_acc": 0.9980019927024841, "report/reward_neg_loss": 0.020510222762823105, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7635239362716675, "report/reward_pred": 0.017246063798666, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.2424396800270188e-07, "eval/cont_loss_std": 6.517836368402641e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.254761734046042e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1210727990373925e-07, "eval/cont_pred": 0.9970702528953552, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.257396697998047, "eval/dyn_loss_std": 10.351598739624023, "eval/image_loss_mean": 10.628293991088867, "eval/image_loss_std": 16.47222900390625, "eval/model_loss_mean": 21.081634521484375, "eval/model_loss_std": 20.500089645385742, "eval/post_ent_mag": 56.14118957519531, "eval/post_ent_max": 56.14118957519531, "eval/post_ent_mean": 39.921058654785156, "eval/post_ent_min": 21.316509246826172, "eval/post_ent_std": 7.474652290344238, "eval/prior_ent_mag": 68.40731048583984, "eval/prior_ent_max": 68.40731048583984, "eval/prior_ent_mean": 55.03581237792969, "eval/prior_ent_min": 39.24535369873047, "eval/prior_ent_std": 4.3362507820129395, "eval/rep_loss_mean": 17.257396697998047, "eval/rep_loss_std": 10.351598739624023, "eval/reward_avg": 0.0361328125, "eval/reward_loss_mean": 0.09890316426753998, "eval/reward_loss_std": 0.5717360973358154, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.044417142868042, "eval/reward_neg_acc": 0.9827585816383362, "eval/reward_neg_loss": 0.03745436668395996, "eval/reward_pos_acc": 0.8157894611358643, "eval/reward_pos_loss": 1.6933376789093018, "eval/reward_pred": 0.034590672701597214, "eval/reward_rate": 0.037109375, "replay/size": 812529.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.3917081617895578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.249594342501866e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1923412481943766e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3430578708649, "timer/env.step_count": 2768.0, "timer/env.step_total": 253.1614215373993, "timer/env.step_frac": 0.2530746023031632, "timer/env.step_avg": 0.0914600511334535, "timer/env.step_min": 0.02297067642211914, "timer/env.step_max": 3.5566658973693848, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.241095066070557, "timer/replay._sample_frac": 0.011237240042427205, "timer/replay._sample_avg": 0.0005076361572466833, "timer/replay._sample_min": 0.0003972053527832031, "timer/replay._sample_max": 0.008741140365600586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3368.0, "timer/agent.policy_total": 56.27017140388489, "timer/agent.policy_frac": 0.05625087409878227, "timer/agent.policy_avg": 0.01670729554747176, "timer/agent.policy_min": 0.00930929183959961, "timer/agent.policy_max": 0.12901091575622559, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.1507103443145752, "timer/dataset_train_frac": 0.00015065865967555953, "timer/dataset_train_avg": 0.00010889475745272774, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0010843276977539062, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 620.4349453449249, "timer/agent.train_frac": 0.6202221732467077, "timer/agent.train_avg": 0.4482911454804371, "timer/agent.train_min": 0.43350791931152344, "timer/agent.train_max": 1.6547348499298096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48084521293640137, "timer/agent.report_frac": 0.0004806803117720782, "timer/agent.report_avg": 0.24042260646820068, "timer/agent.report_min": 0.23310017585754395, "timer/agent.report_max": 0.24774503707885742, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812374426215705e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.136121795385016}
{"step": 813072, "time": 37417.57776141167, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 813496, "time": 37432.9888586998, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 813736, "time": 37442.56309056282, "episode/length": 108.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 813976, "time": 37452.32120680809, "episode/length": 265.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 814192, "time": 37461.32607126236, "episode/length": 56.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 814216, "time": 37463.54181957245, "episode/length": 303.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 814816, "time": 37485.231320858, "episode/length": 323.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 814960, "time": 37491.821206092834, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.0}
{"step": 815072, "time": 37497.07418012619, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 815080, "time": 37498.7147231102, "episode/length": 360.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861495844875346, "episode/intrinsic_return": 0.0}
{"step": 815504, "time": 37514.6594183445, "episode/length": 85.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 815936, "time": 37530.682383298874, "episode/length": 357.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 815968, "time": 37533.32469749451, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 815992, "time": 37535.69990777969, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 816552, "time": 37555.88418340683, "episode/length": 183.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 816936, "time": 37570.50037884712, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 817208, "time": 37581.31903362274, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 817216, "time": 37583.40381383896, "episode/length": 281.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 817464, "time": 37592.9820933342, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 817536, "time": 37597.30898857117, "episode/length": 414.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951807228915662, "episode/intrinsic_return": 0.0}
{"step": 817632, "time": 37602.09791517258, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 817912, "time": 37612.71405029297, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 818016, "time": 37617.97203397751, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 818336, "time": 37630.38629412651, "episode/length": 174.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 818544, "time": 37639.06415295601, "episode/length": 166.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 818648, "time": 37643.91413855553, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 818896, "time": 37653.97622799873, "episode/length": 169.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 818976, "time": 37658.25206756592, "episode/length": 167.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 819056, "time": 37662.487027168274, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 819088, "time": 37665.06079149246, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 819976, "time": 37697.67745542526, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 37717.7867732048, "eval_episode/length": 82.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 820040, "time": 37722.157373189926, "eval_episode/length": 147.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 820040, "time": 37724.486689567566, "eval_episode/length": 164.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 820040, "time": 37726.240309238434, "eval_episode/length": 168.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 820040, "time": 37728.30275440216, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 820040, "time": 37730.25632023811, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 820040, "time": 37734.73015499115, "eval_episode/length": 169.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 820040, "time": 37737.671441078186, "eval_episode/length": 284.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 820088, "time": 37739.25978422165, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 820168, "time": 37743.652183294296, "episode/length": 158.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 820320, "time": 37750.5491104126, "episode/length": 287.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 820424, "time": 37755.351273059845, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 820664, "time": 37764.953001499176, "episode/length": 264.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 821216, "time": 37785.18393278122, "episode/length": 279.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 821664, "time": 37801.58544373512, "episode/length": 186.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 821736, "time": 37805.43468928337, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 821784, "time": 37808.76716518402, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 821880, "time": 37813.570826768875, "episode/length": 352.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9915014164305949, "episode/intrinsic_return": 0.0}
{"step": 821920, "time": 37816.66509985924, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 822208, "time": 37827.834050655365, "episode/length": 222.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 822328, "time": 37833.115371227264, "episode/length": 293.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 822464, "time": 37839.490770578384, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 823104, "time": 37862.28955388069, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 823432, "time": 37874.52829623222, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 823504, "time": 37879.07883691788, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 823632, "time": 37884.989817380905, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 823704, "time": 37888.71333003044, "episode/length": 154.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 823864, "time": 37895.61183977127, "episode/length": 247.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 824504, "time": 37918.63109207153, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 824800, "time": 37930.424700021744, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 824920, "time": 37936.11265420914, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 825072, "time": 37942.937141895294, "episode/length": 195.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 825096, "time": 37945.034489393234, "episode/length": 413.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9975845410628019, "episode/intrinsic_return": 0.0}
{"step": 825816, "time": 37970.827239751816, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 825864, "time": 37974.07027673721, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 825880, "time": 37976.13541555405, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 826312, "time": 37992.28477692604, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 826344, "time": 37994.86524415016, "episode/length": 59.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 826640, "time": 38006.50600242615, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 826696, "time": 38009.89977788925, "episode/length": 353.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 826704, "time": 38011.986693143845, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 826760, "time": 38015.3207116127, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 827408, "time": 38040.41763424873, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 828152, "time": 38066.88627099991, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 828176, "time": 38069.55004835129, "episode/length": 232.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9871244635193133, "episode/intrinsic_return": 0.0}
{"step": 828416, "time": 38079.18867278099, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 828552, "time": 38085.18339920044, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 828648, "time": 38090.01422047615, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9670781893004116, "episode/intrinsic_return": 0.0}
{"step": 828792, "time": 38096.38636922836, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 829032, "time": 38105.96220827103, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 829048, "time": 38108.234387397766, "episode/length": 31.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 829104, "time": 38111.887197732925, "episode/length": 211.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 829472, "time": 38125.646799087524, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 829672, "time": 38133.74338340759, "episode/length": 156.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 38169.94174909592, "eval_episode/length": 204.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 830024, "time": 38171.975246191025, "eval_episode/length": 214.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 830024, "time": 38174.1185092926, "eval_episode/length": 224.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 830024, "time": 38176.429087638855, "eval_episode/length": 239.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 830024, "time": 38179.80848622322, "eval_episode/length": 284.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 830024, "time": 38181.9744887352, "eval_episode/length": 297.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 830024, "time": 38184.47565245628, "eval_episode/length": 321.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9906832298136646}
{"step": 830024, "time": 38189.531876564026, "eval_episode/length": 162.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 830080, "time": 38191.673218011856, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 830160, "time": 38195.96822023392, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 830272, "time": 38201.289762973785, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 830456, "time": 38208.682523489, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 830568, "time": 38213.903537750244, "episode/length": 191.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 830784, "time": 38222.92268371582, "episode/length": 266.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 830984, "time": 38231.002071380615, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 831168, "time": 38238.960698843, "episode/length": 88.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 831216, "time": 38242.09495019913, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 831592, "time": 38255.95668101311, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 831976, "time": 38270.31872844696, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 832176, "time": 38278.789674043655, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 832360, "time": 38286.39477300644, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 832408, "time": 38289.583809137344, "episode/length": 202.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 832472, "time": 38293.35760807991, "episode/length": 156.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 832696, "time": 38302.41239500046, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 833688, "time": 38337.19620466232, "episode/length": 261.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 833728, "time": 38340.3157992363, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 833728, "time": 38340.32284474373, "episode/length": 170.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 833928, "time": 38349.98894047737, "episode/length": 218.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 834128, "time": 38358.5607008934, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 834680, "time": 38378.38217997551, "episode/length": 513.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9863813229571985, "episode/intrinsic_return": 0.0}
{"step": 834800, "time": 38384.28923225403, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 835088, "time": 38395.51464986801, "episode/length": 35.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 835368, "time": 38406.31629347801, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 835593, "time": 38417.979511499405, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6091265306405145, "train/action_min": 0.0, "train/action_std": 3.518070455984021, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04177559478908566, "train/actor_opt_grad_steps": 51420.0, "train/actor_opt_loss": -7.66794413602944, "train/adv_mag": 0.5140426676746801, "train/adv_max": 0.46405124917943424, "train/adv_mean": 0.0027034220709164086, "train/adv_min": -0.4269635640348948, "train/adv_std": 0.05881380997862376, "train/cont_avg": 0.994888630319149, "train/cont_loss_mean": 0.00021305496400215326, "train/cont_loss_std": 0.005834280359379668, "train/cont_neg_acc": 0.9918861883751889, "train/cont_neg_loss": 0.016803242644902044, "train/cont_pos_acc": 0.9999721498354107, "train/cont_pos_loss": 0.000122884402297207, "train/cont_pred": 0.994880847051634, "train/cont_rate": 0.994888630319149, "train/dyn_loss_mean": 13.227200798954524, "train/dyn_loss_std": 9.164744079535735, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8907300867932908, "train/extr_critic_critic_opt_grad_steps": 51420.0, "train/extr_critic_critic_opt_loss": 15414.625346298759, "train/extr_critic_mag": 8.029653177193715, "train/extr_critic_max": 8.029653177193715, "train/extr_critic_mean": 2.5640977139168597, "train/extr_critic_min": -0.1483735869116817, "train/extr_critic_std": 1.790618508420092, "train/extr_return_normed_mag": 1.5704821060735283, "train/extr_return_normed_max": 1.5704821060735283, "train/extr_return_normed_mean": 0.4018429534655091, "train/extr_return_normed_min": -0.13550389780009048, "train/extr_return_normed_std": 0.3231193312305085, "train/extr_return_rate": 0.8901956347709007, "train/extr_return_raw_mag": 9.184283270058057, "train/extr_return_raw_max": 9.184283270058057, "train/extr_return_raw_mean": 2.5793661158135595, "train/extr_return_raw_min": -0.4577647227767511, "train/extr_return_raw_std": 1.8261466119306307, "train/extr_reward_mag": 1.0384165699600327, "train/extr_reward_max": 1.0384165699600327, "train/extr_reward_mean": 0.04014593654754737, "train/extr_reward_min": -0.45843236328016784, "train/extr_reward_std": 0.18592217448332632, "train/image_loss_mean": 6.68769175279225, "train/image_loss_std": 11.68139585535577, "train/model_loss_mean": 14.680088821032369, "train/model_loss_std": 15.448422229036371, "train/model_opt_grad_norm": 50.58448930835048, "train/model_opt_grad_steps": 51373.46808510638, "train/model_opt_loss": 18350.111058011968, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8652482269504, "train/policy_entropy_mag": 2.5403181880923875, "train/policy_entropy_max": 2.5403181880923875, "train/policy_entropy_mean": 0.5569518588958903, "train/policy_entropy_min": 0.0793750154528212, "train/policy_entropy_std": 0.6877858875491095, "train/policy_logprob_mag": 7.438383673945217, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5554734747460548, "train/policy_logprob_min": -7.438383673945217, "train/policy_logprob_std": 1.112158384728939, "train/policy_randomness_mag": 0.8966208421592171, "train/policy_randomness_max": 0.8966208421592171, "train/policy_randomness_mean": 0.1965795653931638, "train/policy_randomness_min": 0.028015897232801356, "train/policy_randomness_std": 0.2427582376180811, "train/post_ent_mag": 59.393809081814815, "train/post_ent_max": 59.393809081814815, "train/post_ent_mean": 42.47492550789042, "train/post_ent_min": 20.083660720933413, "train/post_ent_std": 7.684066522205975, "train/prior_ent_mag": 68.33952948387633, "train/prior_ent_max": 68.33952948387633, "train/prior_ent_mean": 55.76667141745276, "train/prior_ent_min": 40.81561763574046, "train/prior_ent_std": 4.502647716102871, "train/rep_loss_mean": 13.227200798954524, "train/rep_loss_std": 9.164744079535735, "train/reward_avg": 0.028770500741212082, "train/reward_loss_mean": 0.055863569233011695, "train/reward_loss_std": 0.24618986597720613, "train/reward_max_data": 1.0170212806539332, "train/reward_max_pred": 1.0111320483769086, "train/reward_neg_acc": 0.9925053643842116, "train/reward_neg_loss": 0.028796715245760503, "train/reward_pos_acc": 0.969292420867487, "train/reward_pos_loss": 0.8410317965433107, "train/reward_pred": 0.027886964129746384, "train/reward_rate": 0.03330008865248227, "train_stats/sum_log_reward": 7.943137432430305, "train_stats/max_log_achievement_collect_coal": 0.5882352941176471, "train_stats/max_log_achievement_collect_drink": 4.431372549019608, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.1666666666666667, "train_stats/max_log_achievement_collect_stone": 11.27450980392157, "train_stats/max_log_achievement_collect_wood": 8.098039215686274, "train_stats/max_log_achievement_defeat_skeleton": 0.00980392156862745, "train_stats/max_log_achievement_defeat_zombie": 0.6862745098039216, "train_stats/max_log_achievement_eat_cow": 0.0784313725490196, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.00980392156862745, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8137254901960784, "train_stats/max_log_achievement_make_wood_sword": 0.029411764705882353, "train_stats/max_log_achievement_place_furnace": 0.06862745098039216, "train_stats/max_log_achievement_place_plant": 1.1372549019607843, "train_stats/max_log_achievement_place_stone": 8.823529411764707, "train_stats/max_log_achievement_place_table": 2.549019607843137, "train_stats/max_log_achievement_wake_up": 1.8137254901960784, "train_stats/mean_log_entropy": 0.5879647996203572, "eval_stats/sum_log_reward": 8.35000017285347, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 8.3125, "eval_stats/max_log_achievement_collect_wood": 8.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 6.4375, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.941439904840081e-06, "report/cont_loss_std": 3.524655039655045e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00044941282249055803, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8665026857433986e-07, "report/cont_pred": 0.9960954189300537, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.401657104492188, "report/dyn_loss_std": 8.972280502319336, "report/image_loss_mean": 4.9668097496032715, "report/image_loss_std": 8.511387825012207, "report/model_loss_mean": 13.053407669067383, "report/model_loss_std": 12.565784454345703, "report/post_ent_mag": 56.89910125732422, "report/post_ent_max": 56.89910125732422, "report/post_ent_mean": 41.25859832763672, "report/post_ent_min": 19.003395080566406, "report/post_ent_std": 7.650088787078857, "report/prior_ent_mag": 68.0914306640625, "report/prior_ent_max": 68.0914306640625, "report/prior_ent_mean": 54.802268981933594, "report/prior_ent_min": 43.73139953613281, "report/prior_ent_std": 3.99603533744812, "report/rep_loss_mean": 13.401657104492188, "report/rep_loss_std": 8.972280502319336, "report/reward_avg": 0.02041015774011612, "report/reward_loss_mean": 0.04560152068734169, "report/reward_loss_std": 0.25578296184539795, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9998774528503418, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.018016086891293526, "report/reward_pos_acc": 0.8799999952316284, "report/reward_pos_loss": 1.1479153633117676, "report/reward_pred": 0.015663979575037956, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.183246114233043e-06, "eval/cont_loss_std": 0.0001369037781842053, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007524053216911852, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.7229291340045165e-06, "eval/cont_pred": 0.9980437755584717, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.617155075073242, "eval/dyn_loss_std": 10.192947387695312, "eval/image_loss_mean": 8.255833625793457, "eval/image_loss_std": 11.546504020690918, "eval/model_loss_mean": 18.990840911865234, "eval/model_loss_std": 15.754630088806152, "eval/post_ent_mag": 56.376441955566406, "eval/post_ent_max": 56.376441955566406, "eval/post_ent_mean": 39.98434066772461, "eval/post_ent_min": 21.171920776367188, "eval/post_ent_std": 7.6116743087768555, "eval/prior_ent_mag": 68.0914306640625, "eval/prior_ent_max": 68.0914306640625, "eval/prior_ent_mean": 55.363807678222656, "eval/prior_ent_min": 34.61064529418945, "eval/prior_ent_std": 4.025149822235107, "eval/rep_loss_mean": 17.617155075073242, "eval/rep_loss_std": 10.192947387695312, "eval/reward_avg": 0.05869140475988388, "eval/reward_loss_mean": 0.16470885276794434, "eval/reward_loss_std": 0.8285119533538818, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011909008026123, "eval/reward_neg_acc": 0.987525999546051, "eval/reward_neg_loss": 0.03714548423886299, "eval/reward_pos_acc": 0.774193525314331, "eval/reward_pos_loss": 2.143998622894287, "eval/reward_pred": 0.04264316335320473, "eval/reward_rate": 0.060546875, "replay/size": 835089.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.3889467462580254e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.076181032978897e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1775382729463798e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3709068298339844e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.7740740776062, "timer/env.step_count": 2820.0, "timer/env.step_total": 239.18403935432434, "timer/env.step_frac": 0.23876046061039813, "timer/env.step_avg": 0.08481703523202991, "timer/env.step_min": 0.023433685302734375, "timer/env.step_max": 3.1952764987945557, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.46260142326355, "timer/replay._sample_frac": 0.011442301932017814, "timer/replay._sample_avg": 0.000508094034719129, "timer/replay._sample_min": 0.0003638267517089844, "timer/replay._sample_max": 0.03398895263671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3508.0, "timer/agent.policy_total": 56.84159016609192, "timer/agent.policy_frac": 0.056740927557373054, "timer/agent.policy_avg": 0.01620341794928504, "timer/agent.policy_min": 0.009333372116088867, "timer/agent.policy_max": 0.11159920692443848, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.1537320613861084, "timer/dataset_train_frac": 0.0001534598123111329, "timer/dataset_train_avg": 0.00010902983077028964, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0009181499481201172, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 633.6623783111572, "timer/agent.train_frac": 0.632540205130192, "timer/agent.train_avg": 0.4494059420646505, "timer/agent.train_min": 0.43523263931274414, "timer/agent.train_max": 1.6454682350158691, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5197405815124512, "timer/agent.report_frac": 0.0005188201561225346, "timer/agent.report_avg": 0.2598702907562256, "timer/agent.report_min": 0.2502143383026123, "timer/agent.report_max": 0.26952624320983887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.712743152600536e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 22.51973555337756}
{"step": 835880, "time": 38427.4556927681, "episode/length": 273.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 835992, "time": 38432.85835003853, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 836272, "time": 38444.05314016342, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.0}
{"step": 836296, "time": 38446.182735681534, "episode/length": 270.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 837072, "time": 38473.96332907677, "episode/length": 247.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9637096774193549, "episode/intrinsic_return": 0.0}
{"step": 837080, "time": 38475.64401316643, "episode/length": 575.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878472222222222, "episode/intrinsic_return": 0.0}
{"step": 837216, "time": 38481.925132513046, "episode/length": 316.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936908517350158, "episode/intrinsic_return": 0.0}
{"step": 837720, "time": 38500.531071186066, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 838080, "time": 38514.345539569855, "episode/length": 274.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 838400, "time": 38526.76574444771, "episode/length": 262.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 838416, "time": 38528.777292728424, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 838592, "time": 38536.19395518303, "episode/length": 324.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9938461538461538, "episode/intrinsic_return": 0.0}
{"step": 838936, "time": 38549.109184741974, "episode/length": 151.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 839104, "time": 38556.54754471779, "episode/length": 85.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 839232, "time": 38562.30868268013, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 839528, "time": 38573.62608361244, "episode/length": 36.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 839568, "time": 38576.97288608551, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 839704, "time": 38582.7939684391, "episode/length": 328.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848024316109423, "episode/intrinsic_return": 0.0}
{"step": 839904, "time": 38591.361043930054, "episode/length": 227.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 38612.02634382248, "eval_episode/length": 65.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 840008, "time": 38617.87898397446, "eval_episode/length": 161.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 840008, "time": 38619.467672109604, "eval_episode/length": 162.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 840008, "time": 38621.70627975464, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 840008, "time": 38623.79288697243, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 840008, "time": 38625.907059431076, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 840008, "time": 38628.10606884956, "eval_episode/length": 57.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 840008, "time": 38632.95630192757, "eval_episode/length": 197.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 840272, "time": 38642.70731520653, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 840280, "time": 38644.314529418945, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 840704, "time": 38660.21855688095, "episode/length": 199.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 840920, "time": 38668.92487668991, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 840976, "time": 38672.74300956726, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 841200, "time": 38681.80048966408, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 841760, "time": 38702.07811021805, "episode/length": 131.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 841768, "time": 38703.73001074791, "episode/length": 396.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9924433249370277, "episode/intrinsic_return": 0.0}
{"step": 841928, "time": 38710.67244005203, "episode/length": 90.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 842256, "time": 38723.36601638794, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 842264, "time": 38725.05075120926, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 842416, "time": 38731.8384912014, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 842432, "time": 38733.98693442345, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778481012658228, "episode/intrinsic_return": 0.0}
{"step": 842536, "time": 38738.90305566788, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 843208, "time": 38762.94932389259, "episode/length": 180.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 843312, "time": 38768.29431462288, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 843488, "time": 38775.6274831295, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 843744, "time": 38785.6982793808, "episode/length": 433.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 844064, "time": 38801.99166870117, "episode/length": 224.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 844072, "time": 38803.999850034714, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 844168, "time": 38809.458188295364, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 844272, "time": 38814.65422010422, "episode/length": 229.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 844536, "time": 38824.87858200073, "episode/length": 58.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 844728, "time": 38832.83875441551, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 844864, "time": 38839.215074300766, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 844984, "time": 38844.51620006561, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 845096, "time": 38849.678552389145, "episode/length": 235.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 845408, "time": 38861.83429598808, "episode/length": 52.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 845816, "time": 38876.900242328644, "episode/length": 217.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 845968, "time": 38883.90772604942, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 846120, "time": 38890.5321187973, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 846400, "time": 38901.6703813076, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 846424, "time": 38903.927305459976, "episode/length": 126.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 846560, "time": 38910.223774671555, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 846584, "time": 38912.31665921211, "episode/length": 185.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 847064, "time": 38929.72992539406, "episode/length": 155.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 847216, "time": 38936.73433637619, "episode/length": 380.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989501312335958, "episode/intrinsic_return": 0.0}
{"step": 847520, "time": 38948.51784992218, "episode/length": 174.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 847528, "time": 38950.04176354408, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 848088, "time": 38970.34073758125, "episode/length": 210.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 848184, "time": 38975.21530342102, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 848192, "time": 38977.36881899834, "episode/length": 140.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 848200, "time": 38979.19813942909, "episode/length": 204.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 848464, "time": 38989.77831244469, "episode/length": 234.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 849080, "time": 39011.786971092224, "episode/length": 123.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 849784, "time": 39037.123354911804, "episode/length": 281.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 849824, "time": 39040.22472548485, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 849832, "time": 39041.91903305054, "episode/length": 326.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847094801223242, "episode/intrinsic_return": 0.0}
{"step": 849864, "time": 39044.50856947899, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 849872, "time": 39046.54578924179, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 39075.189863443375, "eval_episode/length": 143.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 850096, "time": 39077.22382235527, "eval_episode/length": 152.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 850096, "time": 39080.86418271065, "eval_episode/length": 197.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 850096, "time": 39083.529546260834, "eval_episode/length": 221.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 850096, "time": 39087.24908232689, "eval_episode/length": 268.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 850096, "time": 39089.408708810806, "eval_episode/length": 282.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9681978798586572}
{"step": 850096, "time": 39091.1830804348, "eval_episode/length": 143.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 850096, "time": 39096.24792742729, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 850120, "time": 39096.84709262848, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 850288, "time": 39104.24821615219, "episode/length": 56.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 850296, "time": 39105.88282775879, "episode/length": 53.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 850360, "time": 39109.51493692398, "episode/length": 270.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 850944, "time": 39131.0165374279, "episode/length": 232.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 851336, "time": 39145.63984942436, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 851440, "time": 39150.9120926857, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 851648, "time": 39159.50446629524, "episode/length": 232.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 851800, "time": 39166.04276037216, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 851992, "time": 39176.06322169304, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 852120, "time": 39181.879878520966, "episode/length": 58.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 852128, "time": 39184.040220975876, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 852424, "time": 39195.66777420044, "episode/length": 184.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 852424, "time": 39195.675255060196, "episode/length": 122.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 852608, "time": 39205.590079545975, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.977491961414791, "episode/intrinsic_return": 0.0}
{"step": 853056, "time": 39222.17585992813, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 853240, "time": 39229.66257715225, "episode/length": 139.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 853328, "time": 39234.4812104702, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 853568, "time": 39244.07362151146, "episode/length": 142.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 853584, "time": 39246.216166973114, "episode/length": 198.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 853936, "time": 39259.52172374725, "episode/length": 165.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 853952, "time": 39261.624166727066, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 854296, "time": 39274.443172216415, "episode/length": 270.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 854800, "time": 39293.25365781784, "episode/length": 194.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 854928, "time": 39299.11877989769, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 854992, "time": 39302.93521261215, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 855304, "time": 39314.7366104126, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 855488, "time": 39322.63283610344, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 855696, "time": 39331.13034558296, "episode/length": 265.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 855800, "time": 39336.12435078621, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 856144, "time": 39349.998356580734, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 856344, "time": 39358.01757669449, "episode/length": 298.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 856480, "time": 39364.366246938705, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 856680, "time": 39372.47419500351, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 856696, "time": 39374.659657001495, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 856720, "time": 39377.20741915703, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 857208, "time": 39394.93770599365, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 857464, "time": 39404.995235681534, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 857769, "time": 39417.89237618446, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.364572209419964, "train/action_min": 0.0, "train/action_std": 3.2605727782352365, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04094238359507897, "train/actor_opt_grad_steps": 52820.0, "train/actor_opt_loss": -9.180743530714254, "train/adv_mag": 0.5210547809549373, "train/adv_max": 0.4735121711981382, "train/adv_mean": 0.002130939906217843, "train/adv_min": -0.4237230488722273, "train/adv_std": 0.05743400538139206, "train/cont_avg": 0.9949977517985612, "train/cont_loss_mean": 0.00021952045386127532, "train/cont_loss_std": 0.006689979354662931, "train/cont_neg_acc": 0.9920080553959397, "train/cont_neg_loss": 0.02641692199038329, "train/cont_pos_acc": 0.999978792753151, "train/cont_pos_loss": 7.419719368512995e-05, "train/cont_pred": 0.9950195683849802, "train/cont_rate": 0.9949977517985612, "train/dyn_loss_mean": 13.242198875482133, "train/dyn_loss_std": 9.228198785576032, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8385940074063033, "train/extr_critic_critic_opt_grad_steps": 52820.0, "train/extr_critic_critic_opt_loss": 15551.059212005395, "train/extr_critic_mag": 8.106451576562236, "train/extr_critic_max": 8.106451576562236, "train/extr_critic_mean": 2.5448631125388386, "train/extr_critic_min": -0.15988964914417952, "train/extr_critic_std": 1.8516075268066188, "train/extr_return_normed_mag": 1.5519005660530474, "train/extr_return_normed_max": 1.5519005660530474, "train/extr_return_normed_mean": 0.39766875284610037, "train/extr_return_normed_min": -0.11903606403431446, "train/extr_return_normed_std": 0.32200551944242106, "train/extr_return_rate": 0.8646255298484143, "train/extr_return_raw_mag": 9.30671280236553, "train/extr_return_raw_max": 9.30671280236553, "train/extr_return_raw_mean": 2.557329360529673, "train/extr_return_raw_min": -0.46435361382343787, "train/extr_return_raw_std": 1.883316009164714, "train/extr_reward_mag": 1.0362561006340192, "train/extr_reward_max": 1.0362561006340192, "train/extr_reward_mean": 0.042200529009854194, "train/extr_reward_min": -0.44461834687980817, "train/extr_reward_std": 0.1902689739740152, "train/image_loss_mean": 6.508694693338957, "train/image_loss_std": 11.970176436060624, "train/model_loss_mean": 14.510079905283536, "train/model_loss_std": 15.74130716255243, "train/model_opt_grad_norm": 56.44189116937651, "train/model_opt_grad_steps": 52772.13669064748, "train/model_opt_loss": 18900.89187556205, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1303.9568345323742, "train/policy_entropy_mag": 2.584197370268458, "train/policy_entropy_max": 2.584197370268458, "train/policy_entropy_mean": 0.5229637693586967, "train/policy_entropy_min": 0.07937501563871507, "train/policy_entropy_std": 0.6537624886996455, "train/policy_logprob_mag": 7.438383833109904, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5223769391183373, "train/policy_logprob_min": -7.438383833109904, "train/policy_logprob_std": 1.0964275354104076, "train/policy_randomness_mag": 0.9121082682403729, "train/policy_randomness_max": 0.9121082682403729, "train/policy_randomness_mean": 0.18458326246669823, "train/policy_randomness_min": 0.02801589725418485, "train/policy_randomness_std": 0.23074947083167893, "train/post_ent_mag": 59.169806336327426, "train/post_ent_max": 59.169806336327426, "train/post_ent_mean": 42.392349572490446, "train/post_ent_min": 19.890844825360414, "train/post_ent_std": 7.724605443666307, "train/prior_ent_mag": 68.3275582841832, "train/prior_ent_max": 68.3275582841832, "train/prior_ent_mean": 55.68180899311313, "train/prior_ent_min": 40.52466408983409, "train/prior_ent_std": 4.3978578649836475, "train/rep_loss_mean": 13.242198875482133, "train/rep_loss_std": 9.228198785576032, "train/reward_avg": 0.029394530932412302, "train/reward_loss_mean": 0.055846365208891656, "train/reward_loss_std": 0.24717501534832467, "train/reward_max_data": 1.0122302187432488, "train/reward_max_pred": 1.0089821875524179, "train/reward_neg_acc": 0.9925309042278811, "train/reward_neg_loss": 0.028517676859075646, "train/reward_pos_acc": 0.9721809376915582, "train/reward_pos_loss": 0.8398705793799256, "train/reward_pred": 0.028569727821154987, "train/reward_rate": 0.03388461106115108, "train_stats/sum_log_reward": 7.941121691855315, "train_stats/max_log_achievement_collect_coal": 0.6261682242990654, "train_stats/max_log_achievement_collect_drink": 4.214953271028038, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.1308411214953271, "train_stats/max_log_achievement_collect_stone": 10.336448598130842, "train_stats/max_log_achievement_collect_wood": 8.85981308411215, "train_stats/max_log_achievement_defeat_skeleton": 0.018691588785046728, "train_stats/max_log_achievement_defeat_zombie": 0.7850467289719626, "train_stats/max_log_achievement_eat_cow": 0.07476635514018691, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8130841121495327, "train_stats/max_log_achievement_make_wood_sword": 0.028037383177570093, "train_stats/max_log_achievement_place_furnace": 0.07476635514018691, "train_stats/max_log_achievement_place_plant": 1.0560747663551402, "train_stats/max_log_achievement_place_stone": 8.88785046728972, "train_stats/max_log_achievement_place_table": 2.794392523364486, "train_stats/max_log_achievement_wake_up": 1.4299065420560748, "train_stats/mean_log_entropy": 0.5361680062574761, "eval_stats/sum_log_reward": 7.72500017285347, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 11.0, "eval_stats/max_log_achievement_collect_wood": 7.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 9.1875, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.8721573724178597e-05, "report/cont_loss_std": 0.000556157436221838, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.132758037187159e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.835948569350876e-05, "report/cont_pred": 0.993146538734436, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.469303131103516, "report/dyn_loss_std": 8.899043083190918, "report/image_loss_mean": 6.619714736938477, "report/image_loss_std": 7.813403606414795, "report/model_loss_mean": 14.159838676452637, "report/model_loss_std": 11.438273429870605, "report/post_ent_mag": 61.3270378112793, "report/post_ent_max": 61.3270378112793, "report/post_ent_mean": 43.326107025146484, "report/post_ent_min": 18.55034065246582, "report/post_ent_std": 8.154783248901367, "report/prior_ent_mag": 68.5179443359375, "report/prior_ent_max": 68.5179443359375, "report/prior_ent_mean": 56.155426025390625, "report/prior_ent_min": 41.01007843017578, "report/prior_ent_std": 4.464233875274658, "report/rep_loss_mean": 12.469303131103516, "report/rep_loss_std": 8.899043083190918, "report/reward_avg": 0.03037109412252903, "report/reward_loss_mean": 0.058524250984191895, "report/reward_loss_std": 0.25715065002441406, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017287731170654, "report/reward_neg_acc": 0.9949392676353455, "report/reward_neg_loss": 0.028014132753014565, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 0.8958573937416077, "report/reward_pred": 0.02854990027844906, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.5734071894257795e-06, "eval/cont_loss_std": 3.82190992240794e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.958064775768435e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5648265616619028e-06, "eval/cont_pred": 0.9980453848838806, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.4254150390625, "eval/dyn_loss_std": 10.53309154510498, "eval/image_loss_mean": 9.541160583496094, "eval/image_loss_std": 11.524895668029785, "eval/model_loss_mean": 20.122276306152344, "eval/model_loss_std": 16.0891170501709, "eval/post_ent_mag": 56.92658615112305, "eval/post_ent_max": 56.92658615112305, "eval/post_ent_mean": 40.01069641113281, "eval/post_ent_min": 20.310096740722656, "eval/post_ent_std": 7.670647621154785, "eval/prior_ent_mag": 68.5179443359375, "eval/prior_ent_max": 68.5179443359375, "eval/prior_ent_mean": 55.857887268066406, "eval/prior_ent_min": 44.290374755859375, "eval/prior_ent_std": 3.6864702701568604, "eval/rep_loss_mean": 17.4254150390625, "eval/rep_loss_std": 10.53309154510498, "eval/reward_avg": 0.03457031026482582, "eval/reward_loss_mean": 0.12586282193660736, "eval/reward_loss_std": 0.8194240927696228, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012032985687256, "eval/reward_neg_acc": 0.9969543218612671, "eval/reward_neg_loss": 0.027300409972667694, "eval/reward_pos_acc": 0.7179487347602844, "eval/reward_pos_loss": 2.6151955127716064, "eval/reward_pred": 0.023575734347105026, "eval/reward_rate": 0.0380859375, "replay/size": 857265.0, "replay/inserts": 22176.0, "replay/samples": 22176.0, "replay/insert_wait_avg": 1.3645958762836318e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.189909498756926e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2114573205140805e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.8986899852753, "timer/env.step_count": 2772.0, "timer/env.step_total": 247.6779637336731, "timer/env.step_frac": 0.24770305853418056, "timer/env.step_avg": 0.08934991476683733, "timer/env.step_min": 0.023078441619873047, "timer/env.step_max": 3.54902720451355, "timer/replay._sample_count": 22176.0, "timer/replay._sample_total": 11.304449558258057, "timer/replay._sample_frac": 0.011305594928246709, "timer/replay._sample_avg": 0.0005097605320282313, "timer/replay._sample_min": 0.0004181861877441406, "timer/replay._sample_max": 0.03454756736755371, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3403.0, "timer/agent.policy_total": 56.159615993499756, "timer/agent.policy_frac": 0.056165306101487913, "timer/agent.policy_avg": 0.016502972669262345, "timer/agent.policy_min": 0.009410619735717773, "timer/agent.policy_max": 0.12444829940795898, "timer/dataset_train_count": 1386.0, "timer/dataset_train_total": 0.15304136276245117, "timer/dataset_train_frac": 0.00015305686895609883, "timer/dataset_train_avg": 0.00011041945365256217, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010786056518554688, "timer/agent.train_count": 1386.0, "timer/agent.train_total": 625.1160335540771, "timer/agent.train_frac": 0.6251793704853066, "timer/agent.train_avg": 0.4510216692309359, "timer/agent.train_min": 0.43688178062438965, "timer/agent.train_max": 2.4956822395324707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4788994789123535, "timer/agent.report_frac": 0.0004789480011414015, "timer/agent.report_avg": 0.23944973945617676, "timer/agent.report_min": 0.23371028900146484, "timer/agent.report_max": 0.24518918991088867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9090013760113006e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.17794563262392}
{"step": 857872, "time": 39421.39271426201, "episode/length": 215.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 857920, "time": 39424.536511182785, "episode/length": 152.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 858304, "time": 39438.88545584679, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 858336, "time": 39441.64831995964, "episode/length": 248.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 858488, "time": 39448.0489821434, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 858648, "time": 39455.48151731491, "episode/length": 240.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 858944, "time": 39467.083057165146, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 859176, "time": 39476.12083315849, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 859440, "time": 39486.83706974983, "episode/length": 137.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 859496, "time": 39490.11839342117, "episode/length": 202.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 859616, "time": 39495.81488919258, "episode/length": 211.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 859832, "time": 39504.431859731674, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 859896, "time": 39508.0828499794, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 860000, "time": 39513.352900743484, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39536.77096128464, "eval_episode/length": 140.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 860080, "time": 39538.97762513161, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 860080, "time": 39541.44838643074, "eval_episode/length": 178.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 860080, "time": 39543.87266898155, "eval_episode/length": 59.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9333333333333333}
{"step": 860080, "time": 39546.472984075546, "eval_episode/length": 220.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 860080, "time": 39549.06475138664, "eval_episode/length": 246.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9838056680161943}
{"step": 860080, "time": 39551.840928554535, "eval_episode/length": 70.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 860080, "time": 39556.30379343033, "eval_episode/length": 337.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9970414201183432}
{"step": 860552, "time": 39573.407791137695, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 860880, "time": 39586.42440152168, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 861320, "time": 39602.36291837692, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 861448, "time": 39608.35974049568, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 861480, "time": 39611.02385044098, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 861704, "time": 39620.09000968933, "episode/length": 233.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 861728, "time": 39622.696243047714, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 862224, "time": 39641.11985421181, "episode/length": 208.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 862576, "time": 39654.446986198425, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 862672, "time": 39659.13333559036, "episode/length": 396.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 862936, "time": 39669.31439805031, "episode/length": 181.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 863184, "time": 39679.33912587166, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 863472, "time": 39690.421389341354, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 863632, "time": 39697.32269740105, "episode/length": 240.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 863840, "time": 39705.8755235672, "episode/length": 314.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 863864, "time": 39708.01086139679, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 864032, "time": 39715.35394048691, "episode/length": 225.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 864312, "time": 39726.229408741, "episode/length": 216.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 864336, "time": 39728.88831233978, "episode/length": 58.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 864720, "time": 39743.156802892685, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 864952, "time": 39752.279287576675, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 865104, "time": 39759.21636772156, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 865632, "time": 39778.36414694786, "episode/length": 336.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 865632, "time": 39778.37109661102, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 866160, "time": 39799.393424510956, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 866520, "time": 39812.697909832, "episode/length": 176.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 866584, "time": 39816.5728290081, "episode/length": 52.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 866600, "time": 39818.70458602905, "episode/length": 344.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 866616, "time": 39820.76110649109, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 867008, "time": 39835.51339626312, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 867136, "time": 39841.22379541397, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 867672, "time": 39860.55774021149, "episode/length": 82.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 867704, "time": 39863.169946432114, "episode/length": 258.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 867776, "time": 39867.3920340538, "episode/length": 429.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 867888, "time": 39872.58948326111, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 868240, "time": 39885.96630048752, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 868568, "time": 39899.881083250046, "episode/length": 451.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 868616, "time": 39903.08944773674, "episode/length": 251.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 868912, "time": 39914.87995028496, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 869400, "time": 39932.60593295097, "episode/length": 144.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 869608, "time": 39941.258682489395, "episode/length": 237.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 869816, "time": 39949.81548523903, "episode/length": 267.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 869912, "time": 39954.65007805824, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 870000, "time": 39959.39737844467, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 39978.93678569794, "eval_episode/length": 57.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 870064, "time": 39985.411924123764, "eval_episode/length": 164.0, "eval_episode/score": 9.100000038743019, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 870064, "time": 39987.62244272232, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 870064, "time": 39990.31692314148, "eval_episode/length": 183.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 870064, "time": 39990.324321985245, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 870064, "time": 39995.87280654907, "eval_episode/length": 160.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 870064, "time": 39997.710743665695, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 870064, "time": 39999.81672215462, "eval_episode/length": 235.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9745762711864406}
{"step": 870536, "time": 40015.219431877136, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 870784, "time": 40025.43355631828, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 871088, "time": 40037.04300928116, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 871336, "time": 40046.61232805252, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 871360, "time": 40049.18742895126, "episode/length": 180.0, "episode/score": 8.100000061094761, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 871536, "time": 40056.73854613304, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9875518672199171, "episode/intrinsic_return": 0.0}
{"step": 871648, "time": 40062.07330036163, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 872728, "time": 40099.609055519104, "episode/length": 519.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9980769230769231, "episode/intrinsic_return": 0.0}
{"step": 872928, "time": 40108.204354047775, "episode/length": 298.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 872984, "time": 40112.02029299736, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 873000, "time": 40114.54063129425, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 873048, "time": 40118.36792707443, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 873312, "time": 40128.9634437561, "episode/length": 277.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 873416, "time": 40134.14359641075, "episode/length": 220.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 873512, "time": 40138.770654439926, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 873896, "time": 40153.093103170395, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 874256, "time": 40166.704721689224, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 874472, "time": 40175.40685009956, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 874552, "time": 40179.61344027519, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 874552, "time": 40179.62136745453, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 874776, "time": 40190.64443850517, "episode/length": 223.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 874944, "time": 40198.06267261505, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 875016, "time": 40201.86417508125, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 875312, "time": 40213.51021695137, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 876176, "time": 40243.66414499283, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 876264, "time": 40247.94802212715, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 876448, "time": 40256.1880531311, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 876472, "time": 40258.31975531578, "episode/length": 249.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 876704, "time": 40269.57957625389, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 876704, "time": 40269.586641311646, "episode/length": 173.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 876728, "time": 40273.36851763725, "episode/length": 308.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 876952, "time": 40282.40406990051, "episode/length": 59.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 877120, "time": 40289.72798585892, "episode/length": 292.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 877488, "time": 40303.435292482376, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 877760, "time": 40314.07928228378, "episode/length": 131.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 877960, "time": 40322.0804309845, "episode/length": 211.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 878072, "time": 40327.602657318115, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 878280, "time": 40336.07609629631, "episode/length": 193.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 878368, "time": 40340.765933036804, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 878408, "time": 40343.41624855995, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 878816, "time": 40358.81489491463, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 878904, "time": 40363.115319252014, "episode/length": 61.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 879320, "time": 40378.487327337265, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 879416, "time": 40383.98615717888, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 879448, "time": 40386.75128555298, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 879480, "time": 40389.3668859005, "episode/length": 378.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 879784, "time": 40401.036594867706, "episode/length": 176.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 40433.3624792099, "eval_episode/length": 156.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 880048, "time": 40435.57339763641, "eval_episode/length": 171.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 880048, "time": 40437.18956494331, "eval_episode/length": 173.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 880048, "time": 40438.78892111778, "eval_episode/length": 176.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 880048, "time": 40441.981078863144, "eval_episode/length": 213.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 880048, "time": 40443.86737728119, "eval_episode/length": 46.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 880048, "time": 40448.517843961716, "eval_episode/length": 287.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 880048, "time": 40451.02549004555, "eval_episode/length": 297.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9798657718120806}
{"step": 880049, "time": 40451.621737957, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.433424256688399, "train/action_min": 0.0, "train/action_std": 3.302054665929122, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04026884347093191, "train/actor_opt_grad_steps": 54210.0, "train/actor_opt_loss": -5.773467764579992, "train/adv_mag": 0.486966246538025, "train/adv_max": 0.45564624517084024, "train/adv_mean": 0.002700121923664496, "train/adv_min": -0.38700122488059585, "train/adv_std": 0.05716736531622118, "train/cont_avg": 0.9951382643884892, "train/cont_loss_mean": 7.529385269378555e-05, "train/cont_loss_std": 0.0020227738514226527, "train/cont_neg_acc": 0.9970023983674083, "train/cont_neg_loss": 0.007476831284187114, "train/cont_pos_acc": 0.999992918196342, "train/cont_pos_loss": 4.3216419083770685e-05, "train/cont_pred": 0.9951272834119179, "train/cont_rate": 0.9951382643884892, "train/dyn_loss_mean": 13.084627652339798, "train/dyn_loss_std": 9.195982054840746, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8899405855926679, "train/extr_critic_critic_opt_grad_steps": 54210.0, "train/extr_critic_critic_opt_loss": 15865.6064453125, "train/extr_critic_mag": 8.188466538628228, "train/extr_critic_max": 8.188466538628228, "train/extr_critic_mean": 2.4985842035828734, "train/extr_critic_min": -0.17227616327272044, "train/extr_critic_std": 1.886207877303199, "train/extr_return_normed_mag": 1.5549119487940837, "train/extr_return_normed_max": 1.5549119487940837, "train/extr_return_normed_mean": 0.3889640093707352, "train/extr_return_normed_min": -0.1069391094308963, "train/extr_return_normed_std": 0.32227997642626866, "train/extr_return_rate": 0.8445781323549558, "train/extr_return_raw_mag": 9.457510028811667, "train/extr_return_raw_max": 9.457510028811667, "train/extr_return_raw_mean": 2.5146700795605885, "train/extr_return_raw_min": -0.43852311667564103, "train/extr_return_raw_std": 1.9191272061505764, "train/extr_reward_mag": 1.0387021809173145, "train/extr_reward_max": 1.0387021809173145, "train/extr_reward_mean": 0.04304275179295231, "train/extr_reward_min": -0.4104427785324536, "train/extr_reward_std": 0.19251347456475815, "train/image_loss_mean": 6.313250838423804, "train/image_loss_std": 11.422497258769523, "train/model_loss_mean": 14.220370553380294, "train/model_loss_std": 15.199559458725744, "train/model_opt_grad_norm": 53.00523956902593, "train/model_opt_grad_steps": 54160.676258992804, "train/model_opt_loss": 18036.430474370503, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.9856115107914, "train/policy_entropy_mag": 2.5745666095678756, "train/policy_entropy_max": 2.5745666095678756, "train/policy_entropy_mean": 0.5309507349412218, "train/policy_entropy_min": 0.07937501397707479, "train/policy_entropy_std": 0.6477250073024695, "train/policy_logprob_mag": 7.438383812527005, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5297364251647921, "train/policy_logprob_min": -7.438383812527005, "train/policy_logprob_std": 1.0976631975860047, "train/policy_randomness_mag": 0.9087090316436274, "train/policy_randomness_max": 0.9087090316436274, "train/policy_randomness_mean": 0.1874023107744807, "train/policy_randomness_min": 0.02801589677177316, "train/policy_randomness_std": 0.22861850272408493, "train/post_ent_mag": 59.295284079133175, "train/post_ent_max": 59.295284079133175, "train/post_ent_mean": 42.502087846934366, "train/post_ent_min": 19.966609975416883, "train/post_ent_std": 7.706305092187237, "train/prior_ent_mag": 68.46822626127613, "train/prior_ent_max": 68.46822626127613, "train/prior_ent_mean": 55.650719869051045, "train/prior_ent_min": 40.51468158968919, "train/prior_ent_std": 4.473419395282114, "train/rep_loss_mean": 13.084627652339798, "train/rep_loss_std": 9.195982054840746, "train/reward_avg": 0.028988449717034324, "train/reward_loss_mean": 0.05626787130030797, "train/reward_loss_std": 0.2455197987582186, "train/reward_max_data": 1.015827341903028, "train/reward_max_pred": 1.013439760791312, "train/reward_neg_acc": 0.9917259194868074, "train/reward_neg_loss": 0.029327576263077398, "train/reward_pos_acc": 0.9713813010737192, "train/reward_pos_loss": 0.8398703006531695, "train/reward_pred": 0.02822250972682838, "train/reward_rate": 0.03340686825539568, "train_stats/sum_log_reward": 8.042857281366985, "train_stats/max_log_achievement_collect_coal": 0.5047619047619047, "train_stats/max_log_achievement_collect_drink": 4.714285714285714, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.2666666666666666, "train_stats/max_log_achievement_collect_stone": 9.352380952380953, "train_stats/max_log_achievement_collect_wood": 8.933333333333334, "train_stats/max_log_achievement_defeat_skeleton": 0.02857142857142857, "train_stats/max_log_achievement_defeat_zombie": 0.819047619047619, "train_stats/max_log_achievement_eat_cow": 0.12380952380952381, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01904761904761905, "train_stats/max_log_achievement_make_stone_sword": 0.047619047619047616, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7714285714285714, "train_stats/max_log_achievement_make_wood_sword": 0.047619047619047616, "train_stats/max_log_achievement_place_furnace": 0.17142857142857143, "train_stats/max_log_achievement_place_plant": 1.2285714285714286, "train_stats/max_log_achievement_place_stone": 7.533333333333333, "train_stats/max_log_achievement_place_table": 2.7904761904761903, "train_stats/max_log_achievement_wake_up": 1.3238095238095238, "train_stats/mean_log_entropy": 0.5324449160269329, "eval_stats/sum_log_reward": 7.266666809717814, "eval_stats/max_log_achievement_collect_coal": 0.5833333333333334, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.6666666666666666, "eval_stats/max_log_achievement_collect_stone": 7.458333333333333, "eval_stats/max_log_achievement_collect_wood": 7.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.7083333333333334, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5416666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_stone": 6.541666666666667, "eval_stats/max_log_achievement_place_table": 2.2916666666666665, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.769733873719815e-05, "report/cont_loss_std": 0.0006337613449431956, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007975632324814796, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1635401935782284e-05, "report/cont_pred": 0.9921724796295166, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.451716423034668, "report/dyn_loss_std": 9.48390007019043, "report/image_loss_mean": 7.157054901123047, "report/image_loss_std": 11.801709175109863, "report/model_loss_mean": 15.304254531860352, "report/model_loss_std": 15.517520904541016, "report/post_ent_mag": 59.42919158935547, "report/post_ent_max": 59.42919158935547, "report/post_ent_mean": 42.712066650390625, "report/post_ent_min": 18.967945098876953, "report/post_ent_std": 7.602598667144775, "report/prior_ent_mag": 68.47673034667969, "report/prior_ent_max": 68.47673034667969, "report/prior_ent_mean": 56.13920974731445, "report/prior_ent_min": 38.916908264160156, "report/prior_ent_std": 5.518954753875732, "report/rep_loss_mean": 13.451716423034668, "report/rep_loss_std": 9.48390007019043, "report/reward_avg": 0.03515625, "report/reward_loss_mean": 0.07614198327064514, "report/reward_loss_std": 0.3112647831439972, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018138885498047, "report/reward_neg_acc": 0.9877550601959229, "report/reward_neg_loss": 0.04399529844522476, "report/reward_pos_acc": 0.9772727489471436, "report/reward_pos_loss": 0.7921363711357117, "report/reward_pred": 0.03416738659143448, "report/reward_rate": 0.04296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.9485714599723e-06, "eval/cont_loss_std": 0.00015937139687594026, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016785913612693548, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.484583642915823e-06, "eval/cont_pred": 0.9970613718032837, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.156883239746094, "eval/dyn_loss_std": 10.235843658447266, "eval/image_loss_mean": 9.627023696899414, "eval/image_loss_std": 12.215726852416992, "eval/model_loss_mean": 20.03176498413086, "eval/model_loss_std": 16.01530647277832, "eval/post_ent_mag": 60.888973236083984, "eval/post_ent_max": 60.888973236083984, "eval/post_ent_mean": 41.71862030029297, "eval/post_ent_min": 19.309720993041992, "eval/post_ent_std": 8.074715614318848, "eval/prior_ent_mag": 68.47673034667969, "eval/prior_ent_max": 68.47673034667969, "eval/prior_ent_mean": 56.82805252075195, "eval/prior_ent_min": 44.685951232910156, "eval/prior_ent_std": 4.036850452423096, "eval/rep_loss_mean": 17.156883239746094, "eval/rep_loss_std": 10.235843658447266, "eval/reward_avg": 0.03964843600988388, "eval/reward_loss_mean": 0.11060114204883575, "eval/reward_loss_std": 0.6347649097442627, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001514196395874, "eval/reward_neg_acc": 0.9908069968223572, "eval/reward_neg_loss": 0.032462168484926224, "eval/reward_pos_acc": 0.8222222328186035, "eval/reward_pos_loss": 1.8105579614639282, "eval/reward_pred": 0.03112575225532055, "eval/reward_rate": 0.0439453125, "replay/size": 879545.0, "replay/inserts": 22280.0, "replay/samples": 22272.0, "replay/insert_wait_avg": 1.3752942453380974e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.203393911493236e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1889486137880098e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1033.7099797725677, "timer/env.step_count": 2785.0, "timer/env.step_total": 244.81203079223633, "timer/env.step_frac": 0.2368285453199347, "timer/env.step_avg": 0.08790378125394482, "timer/env.step_min": 0.023506879806518555, "timer/env.step_max": 3.5787973403930664, "timer/replay._sample_count": 22272.0, "timer/replay._sample_total": 11.388098239898682, "timer/replay._sample_frac": 0.011016724673978904, "timer/replay._sample_avg": 0.0005113190660874049, "timer/replay._sample_min": 0.00039315223693847656, "timer/replay._sample_max": 0.011144161224365234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3657.0, "timer/agent.policy_total": 60.6068594455719, "timer/agent.policy_frac": 0.058630428874166765, "timer/agent.policy_avg": 0.01657283550603552, "timer/agent.policy_min": 0.009318828582763672, "timer/agent.policy_max": 0.13643622398376465, "timer/dataset_train_count": 1392.0, "timer/dataset_train_total": 0.15177226066589355, "timer/dataset_train_frac": 0.00014682286486126972, "timer/dataset_train_avg": 0.0001090317964553833, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0010721683502197266, "timer/agent.train_count": 1392.0, "timer/agent.train_total": 624.03857254982, "timer/agent.train_frac": 0.6036882537277217, "timer/agent.train_avg": 0.44830357223406603, "timer/agent.train_min": 0.433074951171875, "timer/agent.train_max": 1.6199760437011719, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790823459625244, "timer/agent.report_frac": 0.0004634591474757068, "timer/agent.report_avg": 0.2395411729812622, "timer/agent.report_min": 0.23204827308654785, "timer/agent.report_max": 0.24703407287597656, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.054473876953125e-05, "timer/dataset_eval_frac": 4.889644074119501e-08, "timer/dataset_eval_avg": 5.054473876953125e-05, "timer/dataset_eval_min": 5.054473876953125e-05, "timer/dataset_eval_max": 5.054473876953125e-05, "fps": 21.553139553272388}
{"step": 880416, "time": 40464.07196712494, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 880464, "time": 40467.28527259827, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 880488, "time": 40469.538392066956, "episode/length": 197.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 880768, "time": 40480.75608706474, "episode/length": 164.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 880880, "time": 40486.02688407898, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 880960, "time": 40490.245628118515, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 881112, "time": 40496.862050533295, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 881560, "time": 40513.56134271622, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 881576, "time": 40515.64460492134, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 881920, "time": 40528.87051296234, "episode/length": 44.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 882240, "time": 40541.39902424812, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 882656, "time": 40557.7984418869, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9671532846715328, "episode/intrinsic_return": 0.0}
{"step": 882976, "time": 40570.23291516304, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742765273311897, "episode/intrinsic_return": 0.0}
{"step": 883008, "time": 40572.925246953964, "episode/length": 279.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 883160, "time": 40579.25164628029, "episode/length": 154.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 883216, "time": 40582.93317079544, "episode/length": 291.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 883304, "time": 40587.28612232208, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 883664, "time": 40601.086401462555, "episode/length": 405.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778325123152709, "episode/intrinsic_return": 0.0}
{"step": 883896, "time": 40610.13660287857, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 884520, "time": 40632.76918768883, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 884544, "time": 40635.40082812309, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 884832, "time": 40648.30419135094, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 884920, "time": 40653.222868680954, "episode/length": 219.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 885184, "time": 40663.95853757858, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 885520, "time": 40676.663877010345, "episode/length": 276.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 885824, "time": 40688.315932273865, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 886016, "time": 40696.38920497894, "episode/length": 61.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 886032, "time": 40698.50270938873, "episode/length": 381.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9921465968586387, "episode/intrinsic_return": 0.0}
{"step": 886448, "time": 40713.78215742111, "episode/length": 190.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 886568, "time": 40719.24424791336, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 886792, "time": 40728.2548828125, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 886832, "time": 40731.39480996132, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 887232, "time": 40746.27671074867, "episode/length": 338.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9852507374631269, "episode/intrinsic_return": 0.0}
{"step": 887240, "time": 40747.89671254158, "episode/length": 176.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 887536, "time": 40759.58431959152, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 887544, "time": 40761.269201517105, "episode/length": 136.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 887992, "time": 40777.83076572418, "episode/length": 177.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 888016, "time": 40780.43635368347, "episode/length": 249.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 888144, "time": 40786.32411456108, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 888512, "time": 40800.036239385605, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 888696, "time": 40807.45586204529, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 888800, "time": 40812.6964302063, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 888856, "time": 40815.9759786129, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 888968, "time": 40822.2262134552, "episode/length": 266.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 889720, "time": 40848.99089336395, "episode/length": 212.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 889736, "time": 40850.988263607025, "episode/length": 217.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 889752, "time": 40853.02125120163, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 889872, "time": 40858.76794505119, "episode/length": 18.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 40880.84674310684, "eval_episode/length": 43.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 890032, "time": 40886.50522303581, "eval_episode/length": 141.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 890032, "time": 40889.90979552269, "eval_episode/length": 180.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 890032, "time": 40891.876415491104, "eval_episode/length": 189.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 890032, "time": 40894.26055264473, "eval_episode/length": 207.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 890032, "time": 40898.7244477272, "eval_episode/length": 272.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 890032, "time": 40900.82806611061, "eval_episode/length": 285.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9825174825174825}
{"step": 890032, "time": 40903.72146701813, "eval_episode/length": 314.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 890112, "time": 40906.392036914825, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 890288, "time": 40913.9727833271, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 890336, "time": 40917.773855924606, "episode/length": 273.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 890344, "time": 40919.84053659439, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 890776, "time": 40936.32018303871, "episode/length": 53.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 891432, "time": 40959.672449827194, "episode/length": 307.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 891464, "time": 40962.28294181824, "episode/length": 146.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 891560, "time": 40967.036433935165, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 891720, "time": 40974.04882287979, "episode/length": 357.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 891952, "time": 40984.26607108116, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 891984, "time": 40987.01803898811, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 892464, "time": 41004.6142950058, "episode/length": 293.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 893168, "time": 41031.503902196884, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 893296, "time": 41037.39186501503, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 893472, "time": 41044.757180929184, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 893608, "time": 41050.69587159157, "episode/length": 142.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 893688, "time": 41054.99036574364, "episode/length": 216.0, "episode/score": 11.10000005364418, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 893720, "time": 41057.598081827164, "episode/length": 249.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 893808, "time": 41062.27587080002, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 893976, "time": 41069.745332717896, "episode/length": 399.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 894248, "time": 41080.43331551552, "episode/length": 33.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 894704, "time": 41097.250774145126, "episode/length": 56.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 894752, "time": 41100.39706945419, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 894880, "time": 41106.331713438034, "episode/length": 213.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 894912, "time": 41108.959634780884, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 895104, "time": 41116.873906612396, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 895224, "time": 41122.26542210579, "episode/length": 240.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 895272, "time": 41125.39810657501, "episode/length": 207.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 895648, "time": 41139.671105623245, "episode/length": 52.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 895752, "time": 41144.51255989075, "episode/length": 257.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 896032, "time": 41155.702373981476, "episode/length": 143.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 896424, "time": 41170.60869526863, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 896784, "time": 41184.21467471123, "episode/length": 253.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 897008, "time": 41193.221418857574, "episode/length": 237.0, "episode/score": 9.099999949336052, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 897256, "time": 41203.21673941612, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 897432, "time": 41210.64228796959, "episode/length": 209.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 897568, "time": 41216.86607789993, "episode/length": 38.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 897664, "time": 41221.56123447418, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 897856, "time": 41229.57060813904, "episode/length": 178.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 898056, "time": 41237.50790119171, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 898664, "time": 41259.448422431946, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 899128, "time": 41276.916501522064, "episode/length": 211.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 899168, "time": 41280.049624204636, "episode/length": 297.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 899240, "time": 41283.90674877167, "episode/length": 172.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 899256, "time": 41286.132133722305, "episode/length": 280.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 899296, "time": 41289.3407394886, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 899520, "time": 41298.82674717903, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 899816, "time": 41309.988936662674, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 41333.770939826965, "eval_episode/length": 57.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 900016, "time": 41340.536366939545, "eval_episode/length": 180.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 900016, "time": 41342.284235715866, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 900016, "time": 41344.00620698929, "eval_episode/length": 188.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 900016, "time": 41346.770500183105, "eval_episode/length": 212.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 900016, "time": 41348.49855804443, "eval_episode/length": 216.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.967741935483871}
{"step": 900016, "time": 41351.230484724045, "eval_episode/length": 244.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9755102040816327}
{"step": 900016, "time": 41354.41414690018, "eval_episode/length": 284.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 900352, "time": 41365.51895427704, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 900640, "time": 41376.599605321884, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 900648, "time": 41378.15758538246, "episode/length": 168.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 900664, "time": 41380.24160027504, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 900880, "time": 41389.22887301445, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 901064, "time": 41396.621569395065, "episode/length": 49.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 901440, "time": 41413.22638297081, "episode/length": 46.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 901688, "time": 41423.36971282959, "episode/length": 233.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 901824, "time": 41429.65860438347, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 901968, "time": 41436.00959324837, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 902224, "time": 41446.12828588486, "episode/length": 337.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 902320, "time": 41450.847554683685, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 902321, "time": 41452.945036411285, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.467963129496403, "train/action_min": 0.0, "train/action_std": 3.2004929978212866, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04151267753981, "train/actor_opt_grad_steps": 55600.0, "train/actor_opt_loss": -6.439729296260601, "train/adv_mag": 0.5031611482016474, "train/adv_max": 0.4581489498666722, "train/adv_mean": 0.0028569910911834385, "train/adv_min": -0.40773863468667587, "train/adv_std": 0.05822885347356042, "train/cont_avg": 0.9948642648381295, "train/cont_loss_mean": 0.0001788478245074998, "train/cont_loss_std": 0.005391634352554156, "train/cont_neg_acc": 0.9890116491763712, "train/cont_neg_loss": 0.038634384396534036, "train/cont_pos_acc": 0.9999858188114578, "train/cont_pos_loss": 5.2067737508759665e-05, "train/cont_pred": 0.9948972673724881, "train/cont_rate": 0.9948642648381295, "train/dyn_loss_mean": 13.222322587486651, "train/dyn_loss_std": 9.196029868914927, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8971260074231264, "train/extr_critic_critic_opt_grad_steps": 55600.0, "train/extr_critic_critic_opt_loss": 15823.305460319245, "train/extr_critic_mag": 8.167178346098757, "train/extr_critic_max": 8.167178346098757, "train/extr_critic_mean": 2.4743246020172998, "train/extr_critic_min": -0.17402885200308382, "train/extr_critic_std": 1.865676990515894, "train/extr_return_normed_mag": 1.5810531429249606, "train/extr_return_normed_max": 1.5810531429249606, "train/extr_return_normed_mean": 0.39275688040170736, "train/extr_return_normed_min": -0.1176524920214852, "train/extr_return_normed_std": 0.32477162735496495, "train/extr_return_rate": 0.8435088327462724, "train/extr_return_raw_mag": 9.437198467391857, "train/extr_return_raw_max": 9.437198467391857, "train/extr_return_raw_mean": 2.4909840179004257, "train/extr_return_raw_min": -0.49216830698277453, "train/extr_return_raw_std": 1.8982151343668108, "train/extr_reward_mag": 1.0405336318256186, "train/extr_reward_max": 1.0405336318256186, "train/extr_reward_mean": 0.04264457886971587, "train/extr_reward_min": -0.4689731580747975, "train/extr_reward_std": 0.19185352111034257, "train/image_loss_mean": 6.328771941095805, "train/image_loss_std": 11.346878096354093, "train/model_loss_mean": 14.320464676232646, "train/model_loss_std": 15.118192412012773, "train/model_opt_grad_norm": 52.26319505156373, "train/model_opt_grad_steps": 55549.438848920865, "train/model_opt_loss": 18638.136233981564, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1303.9568345323742, "train/policy_entropy_mag": 2.5721402545627075, "train/policy_entropy_max": 2.5721402545627075, "train/policy_entropy_mean": 0.5268601063344118, "train/policy_entropy_min": 0.0793750140306761, "train/policy_entropy_std": 0.6350904746021299, "train/policy_logprob_mag": 7.438383802235555, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5273984574156699, "train/policy_logprob_min": -7.438383802235555, "train/policy_logprob_std": 1.097751196768644, "train/policy_randomness_mag": 0.9078526333939257, "train/policy_randomness_max": 0.9078526333939257, "train/policy_randomness_mean": 0.18595849717263696, "train/policy_randomness_min": 0.02801589677177316, "train/policy_randomness_std": 0.22415906887689083, "train/post_ent_mag": 59.019859313964844, "train/post_ent_max": 59.019859313964844, "train/post_ent_mean": 42.375882841700275, "train/post_ent_min": 20.078575230330873, "train/post_ent_std": 7.678363549623558, "train/prior_ent_mag": 68.40921355322968, "train/prior_ent_max": 68.40921355322968, "train/prior_ent_mean": 55.678880595474794, "train/prior_ent_min": 40.49306880484382, "train/prior_ent_std": 4.470260616686704, "train/rep_loss_mean": 13.222322587486651, "train/rep_loss_std": 9.196029868914927, "train/reward_avg": 0.03011536087653191, "train/reward_loss_mean": 0.058120347800657904, "train/reward_loss_std": 0.2513474437187044, "train/reward_max_data": 1.018705040430851, "train/reward_max_pred": 1.0133146450673933, "train/reward_neg_acc": 0.9920016329923123, "train/reward_neg_loss": 0.0300426673840919, "train/reward_pos_acc": 0.9693070650100708, "train/reward_pos_loss": 0.8401588090032125, "train/reward_pred": 0.029185935714208393, "train/reward_rate": 0.034727686600719426, "train_stats/sum_log_reward": 7.92407426348439, "train_stats/max_log_achievement_collect_coal": 0.7222222222222222, "train_stats/max_log_achievement_collect_drink": 4.972222222222222, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 0.8611111111111112, "train_stats/max_log_achievement_collect_stone": 9.268518518518519, "train_stats/max_log_achievement_collect_wood": 8.63888888888889, "train_stats/max_log_achievement_defeat_skeleton": 0.009259259259259259, "train_stats/max_log_achievement_defeat_zombie": 0.6759259259259259, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.018518518518518517, "train_stats/max_log_achievement_make_stone_sword": 0.027777777777777776, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.027777777777777776, "train_stats/max_log_achievement_place_furnace": 0.5555555555555556, "train_stats/max_log_achievement_place_plant": 0.8518518518518519, "train_stats/max_log_achievement_place_stone": 5.407407407407407, "train_stats/max_log_achievement_place_table": 2.7685185185185186, "train_stats/max_log_achievement_wake_up": 1.4074074074074074, "train_stats/mean_log_entropy": 0.5369032654497359, "eval_stats/sum_log_reward": 7.287500240840018, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 8.5, "eval_stats/max_log_achievement_collect_wood": 7.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_stone": 3.6875, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.9883458662661724e-05, "report/cont_loss_std": 0.0005311809945851564, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.266316005261615e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.98752895812504e-05, "report/cont_pred": 0.9970507621765137, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.263223648071289, "report/dyn_loss_std": 9.18441390991211, "report/image_loss_mean": 5.537781715393066, "report/image_loss_std": 9.570611953735352, "report/model_loss_mean": 12.950756072998047, "report/model_loss_std": 13.696770668029785, "report/post_ent_mag": 58.81047439575195, "report/post_ent_max": 58.81047439575195, "report/post_ent_mean": 43.608577728271484, "report/post_ent_min": 21.04914093017578, "report/post_ent_std": 7.714651107788086, "report/prior_ent_mag": 68.80904388427734, "report/prior_ent_max": 68.80904388427734, "report/prior_ent_mean": 55.71476745605469, "report/prior_ent_min": 41.12266540527344, "report/prior_ent_std": 4.121354103088379, "report/rep_loss_mean": 12.263223648071289, "report/rep_loss_std": 9.18441390991211, "report/reward_avg": 0.03876952826976776, "report/reward_loss_mean": 0.05501971021294594, "report/reward_loss_std": 0.22861069440841675, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023517608642578, "report/reward_neg_acc": 0.9969450831413269, "report/reward_neg_loss": 0.024994682520627975, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.7570335268974304, "report/reward_pred": 0.03769152611494064, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.07166657068592e-07, "eval/cont_loss_std": 1.071026417776011e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.1131465220823884e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.180648822213698e-07, "eval/cont_pred": 0.9970697164535522, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.978841781616211, "eval/dyn_loss_std": 9.765035629272461, "eval/image_loss_mean": 9.565065383911133, "eval/image_loss_std": 10.673079490661621, "eval/model_loss_mean": 19.23550033569336, "eval/model_loss_std": 14.529441833496094, "eval/post_ent_mag": 59.37017059326172, "eval/post_ent_max": 59.37017059326172, "eval/post_ent_mean": 42.64329147338867, "eval/post_ent_min": 19.047304153442383, "eval/post_ent_std": 8.374807357788086, "eval/prior_ent_mag": 68.80904388427734, "eval/prior_ent_max": 68.80904388427734, "eval/prior_ent_mean": 56.706321716308594, "eval/prior_ent_min": 41.707767486572266, "eval/prior_ent_std": 4.4069600105285645, "eval/rep_loss_mean": 15.978841781616211, "eval/rep_loss_std": 9.765035629272461, "eval/reward_avg": 0.0380859375, "eval/reward_loss_mean": 0.08313022553920746, "eval/reward_loss_std": 0.49107852578163147, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0018010139465332, "eval/reward_neg_acc": 0.9898167252540588, "eval/reward_neg_loss": 0.04087258502840996, "eval/reward_pos_acc": 0.9285714626312256, "eval/reward_pos_loss": 1.0711541175842285, "eval/reward_pred": 0.03695632889866829, "eval/reward_rate": 0.041015625, "replay/size": 901817.0, "replay/inserts": 22272.0, "replay/samples": 22272.0, "replay/insert_wait_avg": 1.3759381127083438e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.401219672170179e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1826554934183756e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3145704269409, "timer/env.step_count": 2784.0, "timer/env.step_total": 251.75956082344055, "timer/env.step_frac": 0.2514290396434511, "timer/env.step_avg": 0.09043087673255767, "timer/env.step_min": 0.023094654083251953, "timer/env.step_max": 2.474233865737915, "timer/replay._sample_count": 22272.0, "timer/replay._sample_total": 11.456877708435059, "timer/replay._sample_frac": 0.011441836608399767, "timer/replay._sample_avg": 0.0005144072246962581, "timer/replay._sample_min": 0.0004208087921142578, "timer/replay._sample_max": 0.011154890060424805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3384.0, "timer/agent.policy_total": 54.92090106010437, "timer/agent.policy_frac": 0.05484879845170652, "timer/agent.policy_avg": 0.016229580691520203, "timer/agent.policy_min": 0.009451627731323242, "timer/agent.policy_max": 0.10323953628540039, "timer/dataset_train_count": 1392.0, "timer/dataset_train_total": 0.15349054336547852, "timer/dataset_train_frac": 0.00015328903413443104, "timer/dataset_train_avg": 0.00011026619494646445, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010769367218017578, "timer/agent.train_count": 1392.0, "timer/agent.train_total": 625.0913877487183, "timer/agent.train_frac": 0.624270739895647, "timer/agent.train_avg": 0.4490599049918953, "timer/agent.train_min": 0.43482518196105957, "timer/agent.train_max": 1.5737383365631104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790315628051758, "timer/agent.report_frac": 0.00047840266880459564, "timer/agent.report_avg": 0.2395157814025879, "timer/agent.report_min": 0.23033928871154785, "timer/agent.report_max": 0.24869227409362793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010251998901367188, "timer/dataset_eval_frac": 1.0238539619967715e-07, "timer/dataset_eval_avg": 0.00010251998901367188, "timer/dataset_eval_min": 0.00010251998901367188, "timer/dataset_eval_max": 0.00010251998901367188, "fps": 22.242450071785328}
{"step": 902376, "time": 41454.878316402435, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 902856, "time": 41472.61022520065, "episode/length": 59.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 902984, "time": 41478.4132065773, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 903264, "time": 41489.50171113014, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 903376, "time": 41494.748797893524, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9669421487603306, "episode/intrinsic_return": 0.0}
{"step": 903408, "time": 41497.6279296875, "episode/length": 197.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 903648, "time": 41507.12942814827, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 903736, "time": 41511.30399060249, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 904056, "time": 41523.48649477959, "episode/length": 39.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 904088, "time": 41526.35537290573, "episode/length": 400.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 904368, "time": 41537.40378212929, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 904640, "time": 41548.10550189018, "episode/length": 171.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 905080, "time": 41564.77201485634, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 905232, "time": 41571.74843907356, "episode/length": 231.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 905360, "time": 41577.88480901718, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 905488, "time": 41583.67747545242, "episode/length": 139.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 905552, "time": 41587.543372392654, "episode/length": 336.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 905768, "time": 41596.16125655174, "episode/length": 140.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 905976, "time": 41604.614077568054, "episode/length": 290.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 906048, "time": 41608.790251493454, "episode/length": 244.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 906392, "time": 41621.60706615448, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 906872, "time": 41639.45630979538, "episode/length": 172.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 907224, "time": 41652.92083334923, "episode/length": 43.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 907624, "time": 41667.8578619957, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 907800, "time": 41675.46759676933, "episode/length": 175.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 907808, "time": 41677.70050048828, "episode/length": 340.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9912023460410557, "episode/intrinsic_return": 0.0}
{"step": 907832, "time": 41679.79849696159, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 908160, "time": 41692.47569870949, "episode/length": 298.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 908728, "time": 41712.82123827934, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 908728, "time": 41712.84345006943, "episode/length": 137.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 908728, "time": 41712.85599732399, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 908784, "time": 41720.171552181244, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 909200, "time": 41735.83723449707, "episode/length": 173.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 909216, "time": 41737.935534238815, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 909504, "time": 41750.80391430855, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 909840, "time": 41763.43766593933, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41785.940346717834, "eval_episode/length": 55.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 910000, "time": 41791.814432621, "eval_episode/length": 156.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 910000, "time": 41794.16931223869, "eval_episode/length": 172.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 910000, "time": 41795.99563217163, "eval_episode/length": 174.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 910000, "time": 41797.63292002678, "eval_episode/length": 178.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.994413407821229}
{"step": 910000, "time": 41800.80647420883, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 910000, "time": 41805.14563202858, "eval_episode/length": 228.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 910000, "time": 41808.462225198746, "eval_episode/length": 208.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 910008, "time": 41808.5214612484, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 910056, "time": 41812.173839092255, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 910104, "time": 41815.44685006142, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 910320, "time": 41825.16971182823, "episode/length": 59.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 910624, "time": 41836.78674912453, "episode/length": 236.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 910800, "time": 41844.16971707344, "episode/length": 92.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 911056, "time": 41854.197452783585, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 911112, "time": 41857.50804710388, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 911280, "time": 41865.01042795181, "episode/length": 27.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 911464, "time": 41872.58805727959, "episode/length": 142.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 911592, "time": 41878.453661203384, "episode/length": 98.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 911928, "time": 41891.26870179176, "episode/length": 227.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 912152, "time": 41900.32782292366, "episode/length": 267.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 912200, "time": 41903.461819410324, "episode/length": 336.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 912576, "time": 41917.991013765335, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 912752, "time": 41925.52796649933, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 913344, "time": 41946.984538555145, "episode/length": 148.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 913568, "time": 41956.00744366646, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 913688, "time": 41961.31596016884, "episode/length": 321.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 914056, "time": 41975.45021653175, "episode/length": 428.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 914120, "time": 41979.07970166206, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 914248, "time": 41984.89434456825, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 914344, "time": 41989.519961833954, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 914480, "time": 41995.86841106415, "episode/length": 141.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 914528, "time": 41998.99056267738, "episode/length": 50.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 914552, "time": 42001.04845261574, "episode/length": 37.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 914776, "time": 42010.021308898926, "episode/length": 355.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9971910112359551, "episode/intrinsic_return": 0.0}
{"step": 915120, "time": 42023.22944545746, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 915144, "time": 42025.34996700287, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 915520, "time": 42039.87767076492, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 915928, "time": 42054.72270107269, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 916128, "time": 42063.26796245575, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 916272, "time": 42069.67811894417, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 916488, "time": 42078.18564796448, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 916576, "time": 42083.05386757851, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 916696, "time": 42088.32316946983, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 916848, "time": 42095.31313419342, "episode/length": 295.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 916872, "time": 42097.53739404678, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 917288, "time": 42112.92832875252, "episode/length": 144.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 917608, "time": 42126.76086139679, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 917984, "time": 42141.119424819946, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 918088, "time": 42146.0368642807, "episode/length": 151.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 918328, "time": 42155.74047231674, "episode/length": 229.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 918344, "time": 42157.97622537613, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 918608, "time": 42168.56864333153, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 918896, "time": 42179.907457351685, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 919272, "time": 42194.31340050697, "episode/length": 247.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 919280, "time": 42196.446199417114, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 919296, "time": 42198.54364180565, "episode/length": 163.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 919672, "time": 42212.409385442734, "episode/length": 165.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 920000, "time": 42225.19823861122, "episode/length": 137.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 42250.34683704376, "eval_episode/length": 164.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 920088, "time": 42252.22042274475, "eval_episode/length": 168.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 920088, "time": 42253.937205553055, "eval_episode/length": 172.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 920088, "time": 42256.04758429527, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 920088, "time": 42257.887724637985, "eval_episode/length": 190.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 920088, "time": 42259.62937140465, "eval_episode/length": 195.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 920088, "time": 42262.39859366417, "eval_episode/length": 221.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 920088, "time": 42270.740226745605, "eval_episode/length": 187.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 920152, "time": 42272.90503168106, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 920552, "time": 42287.995218753815, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 920832, "time": 42299.282440662384, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 920912, "time": 42304.08353090286, "episode/length": 352.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 921144, "time": 42313.808807611465, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 921504, "time": 42327.5589492321, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 921576, "time": 42331.66399598122, "episode/length": 237.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 921816, "time": 42341.28878712654, "episode/length": 226.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 921824, "time": 42343.384872198105, "episode/length": 315.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 921984, "time": 42350.25860476494, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 922280, "time": 42361.445286512375, "episode/length": 87.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 922296, "time": 42363.56000614166, "episode/length": 58.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 922352, "time": 42367.32645201683, "episode/length": 105.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 922400, "time": 42370.56372284889, "episode/length": 156.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 922440, "time": 42373.3308365345, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 922576, "time": 42379.6623313427, "episode/length": 207.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 923528, "time": 42412.84425640106, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 923696, "time": 42420.22229337692, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 923920, "time": 42429.66385650635, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 924120, "time": 42437.71129798889, "episode/length": 227.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 924144, "time": 42440.232845783234, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 924441, "time": 42453.15616130829, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.454002325483363, "train/action_min": 0.0, "train/action_std": 3.144333455202391, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04136401693597972, "train/actor_opt_grad_steps": 56990.0, "train/actor_opt_loss": -3.778848638583859, "train/adv_mag": 0.4973816112648669, "train/adv_max": 0.44923389729836005, "train/adv_mean": 0.003641081353634945, "train/adv_min": -0.40586168871080275, "train/adv_std": 0.05778371797298356, "train/cont_avg": 0.9947869829136691, "train/cont_loss_mean": 0.0001471313399086989, "train/cont_loss_std": 0.004562319032730817, "train/cont_neg_acc": 0.9968739302038289, "train/cont_neg_loss": 0.008514578331215102, "train/cont_pos_acc": 0.9999787657380962, "train/cont_pos_loss": 9.065302876854878e-05, "train/cont_pred": 0.9947825434396593, "train/cont_rate": 0.9947869829136691, "train/dyn_loss_mean": 13.241182258660844, "train/dyn_loss_std": 9.159900919138956, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8859634922562744, "train/extr_critic_critic_opt_grad_steps": 56990.0, "train/extr_critic_critic_opt_loss": 15812.028495953238, "train/extr_critic_mag": 8.277752471484726, "train/extr_critic_max": 8.277752471484726, "train/extr_critic_mean": 2.555873634146272, "train/extr_critic_min": -0.17256984779303022, "train/extr_critic_std": 1.9037951754151488, "train/extr_return_normed_mag": 1.5576149070863243, "train/extr_return_normed_max": 1.5576149070863243, "train/extr_return_normed_mean": 0.40008694748226686, "train/extr_return_normed_min": -0.10990170207169415, "train/extr_return_normed_std": 0.32456471872844284, "train/extr_return_rate": 0.8526084255829132, "train/extr_return_raw_mag": 9.488942743205339, "train/extr_return_raw_max": 9.488942743205339, "train/extr_return_raw_mean": 2.57761001501152, "train/extr_return_raw_min": -0.46723273246408364, "train/extr_return_raw_std": 1.93792134823559, "train/extr_reward_mag": 1.0411125395795424, "train/extr_reward_max": 1.0411125395795424, "train/extr_reward_mean": 0.04201551741190094, "train/extr_reward_min": -0.46758648217153204, "train/extr_reward_std": 0.19033091702907207, "train/image_loss_mean": 6.335473564888933, "train/image_loss_std": 11.432730506649978, "train/model_loss_mean": 14.338761487453104, "train/model_loss_std": 15.1743081799514, "train/model_opt_grad_norm": 50.92167173701225, "train/model_opt_grad_steps": 56938.18705035971, "train/model_opt_loss": 19581.147924629047, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1357.913669064748, "train/policy_entropy_mag": 2.5621553753777375, "train/policy_entropy_max": 2.5621553753777375, "train/policy_entropy_mean": 0.5063950511620199, "train/policy_entropy_min": 0.0793750140842774, "train/policy_entropy_std": 0.6115860415877198, "train/policy_logprob_mag": 7.43838377479169, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5066484470161603, "train/policy_logprob_min": -7.43838377479169, "train/policy_logprob_std": 1.0811841367817612, "train/policy_randomness_mag": 0.9043284101451902, "train/policy_randomness_max": 0.9043284101451902, "train/policy_randomness_mean": 0.1787352314312681, "train/policy_randomness_min": 0.02801589679857381, "train/policy_randomness_std": 0.21586303487956096, "train/post_ent_mag": 59.32927410208064, "train/post_ent_max": 59.32927410208064, "train/post_ent_mean": 42.516424412350005, "train/post_ent_min": 19.909908912164703, "train/post_ent_std": 7.700227061621577, "train/prior_ent_mag": 68.42018072553675, "train/prior_ent_max": 68.42018072553675, "train/prior_ent_mean": 55.83750827706975, "train/prior_ent_min": 41.12753998461387, "train/prior_ent_std": 4.460556757535866, "train/rep_loss_mean": 13.241182258660844, "train/rep_loss_std": 9.159900919138956, "train/reward_avg": 0.030567108727187563, "train/reward_loss_mean": 0.05843146558073785, "train/reward_loss_std": 0.2505953606727312, "train/reward_max_data": 1.0273381360143208, "train/reward_max_pred": 1.018744695100853, "train/reward_neg_acc": 0.9917794620390419, "train/reward_neg_loss": 0.03012317396941588, "train/reward_pos_acc": 0.9706073000276689, "train/reward_pos_loss": 0.8354315020197587, "train/reward_pred": 0.02974770356157272, "train/reward_rate": 0.03530378821942446, "train_stats/sum_log_reward": 8.155555744965872, "train_stats/max_log_achievement_collect_coal": 0.8240740740740741, "train_stats/max_log_achievement_collect_drink": 3.925925925925926, "train_stats/max_log_achievement_collect_iron": 0.009259259259259259, "train_stats/max_log_achievement_collect_sapling": 1.0462962962962963, "train_stats/max_log_achievement_collect_stone": 9.12962962962963, "train_stats/max_log_achievement_collect_wood": 8.194444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.018518518518518517, "train_stats/max_log_achievement_defeat_zombie": 0.5370370370370371, "train_stats/max_log_achievement_eat_cow": 0.046296296296296294, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009259259259259259, "train_stats/max_log_achievement_make_stone_sword": 0.027777777777777776, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2407407407407407, "train_stats/max_log_achievement_make_wood_sword": 0.009259259259259259, "train_stats/max_log_achievement_place_furnace": 0.7129629629629629, "train_stats/max_log_achievement_place_plant": 1.0277777777777777, "train_stats/max_log_achievement_place_stone": 4.324074074074074, "train_stats/max_log_achievement_place_table": 2.7314814814814814, "train_stats/max_log_achievement_wake_up": 1.1574074074074074, "train_stats/mean_log_entropy": 0.5015076848643797, "eval_stats/sum_log_reward": 7.7250000685453415, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 8.625, "eval_stats/max_log_achievement_collect_wood": 7.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.5625, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 5.5, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.878928052676201e-07, "report/cont_loss_std": 1.4210593690222595e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.539126040181145e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2223646922725493e-08, "report/cont_pred": 0.9951176643371582, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.239339828491211, "report/dyn_loss_std": 8.749117851257324, "report/image_loss_mean": 4.866138458251953, "report/image_loss_std": 9.744974136352539, "report/model_loss_mean": 12.247758865356445, "report/model_loss_std": 13.29500675201416, "report/post_ent_mag": 58.27840042114258, "report/post_ent_max": 58.27840042114258, "report/post_ent_mean": 43.16931915283203, "report/post_ent_min": 17.92144012451172, "report/post_ent_std": 7.690688133239746, "report/prior_ent_mag": 68.58876037597656, "report/prior_ent_max": 68.58876037597656, "report/prior_ent_mean": 55.67867660522461, "report/prior_ent_min": 41.506919860839844, "report/prior_ent_std": 4.535560607910156, "report/rep_loss_mean": 12.239339828491211, "report/rep_loss_std": 8.749117851257324, "report/reward_avg": 0.02392578125, "report/reward_loss_mean": 0.038016557693481445, "report/reward_loss_std": 0.18175509572029114, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002389907836914, "report/reward_neg_acc": 0.994979977607727, "report/reward_neg_loss": 0.0192763339728117, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7046332955360413, "report/reward_pred": 0.024051450192928314, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.32333627789194e-06, "eval/cont_loss_std": 4.045716195832938e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002205727796535939, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.1100011455009735e-08, "eval/cont_pred": 0.9941419363021851, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.538211822509766, "eval/dyn_loss_std": 9.977036476135254, "eval/image_loss_mean": 10.346372604370117, "eval/image_loss_std": 15.530248641967773, "eval/model_loss_mean": 20.356136322021484, "eval/model_loss_std": 18.988182067871094, "eval/post_ent_mag": 59.70841979980469, "eval/post_ent_max": 59.70841979980469, "eval/post_ent_mean": 41.431640625, "eval/post_ent_min": 19.66654396057129, "eval/post_ent_std": 7.7708563804626465, "eval/prior_ent_mag": 68.58876037597656, "eval/prior_ent_max": 68.58876037597656, "eval/prior_ent_mean": 56.458553314208984, "eval/prior_ent_min": 45.470863342285156, "eval/prior_ent_std": 4.339471340179443, "eval/rep_loss_mean": 16.538211822509766, "eval/rep_loss_std": 9.977036476135254, "eval/reward_avg": 0.03330077975988388, "eval/reward_loss_mean": 0.08683348447084427, "eval/reward_loss_std": 0.47631388902664185, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035209655761719, "eval/reward_neg_acc": 0.9908629655838013, "eval/reward_neg_loss": 0.03367798775434494, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.42935049533844, "eval/reward_pred": 0.028055861592292786, "eval/reward_rate": 0.0380859375, "replay/size": 923937.0, "replay/inserts": 22120.0, "replay/samples": 22128.0, "replay/insert_wait_avg": 1.3891978031041179e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.193143720482022e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5152.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.190843419258639e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.197860956192, "timer/env.step_count": 2765.0, "timer/env.step_total": 250.91067600250244, "timer/env.step_frac": 0.25086104039717816, "timer/env.step_avg": 0.09074527161030829, "timer/env.step_min": 0.022977590560913086, "timer/env.step_max": 5.241564035415649, "timer/replay._sample_count": 22128.0, "timer/replay._sample_total": 11.438376665115356, "timer/replay._sample_frac": 0.011436113904683055, "timer/replay._sample_avg": 0.0005169186851552493, "timer/replay._sample_min": 0.0003991127014160156, "timer/replay._sample_max": 0.01105809211730957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3409.0, "timer/agent.policy_total": 55.81032967567444, "timer/agent.policy_frac": 0.05579928917496345, "timer/agent.policy_avg": 0.016371466610640786, "timer/agent.policy_min": 0.009372234344482422, "timer/agent.policy_max": 0.1052560806274414, "timer/dataset_train_count": 1383.0, "timer/dataset_train_total": 0.15169453620910645, "timer/dataset_train_frac": 0.00015166452772063122, "timer/dataset_train_avg": 0.00010968513102610734, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0003476142883300781, "timer/agent.train_count": 1383.0, "timer/agent.train_total": 620.0417039394379, "timer/agent.train_frac": 0.6199190461642021, "timer/agent.train_avg": 0.44833095006466944, "timer/agent.train_min": 0.43485569953918457, "timer/agent.train_max": 1.5574009418487549, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48491716384887695, "timer/agent.report_frac": 0.00048482123665541014, "timer/agent.report_avg": 0.24245858192443848, "timer/agent.report_min": 0.23555374145507812, "timer/agent.report_max": 0.24936342239379883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.673004150390625e-05, "timer/dataset_eval_frac": 4.6720797282281925e-08, "timer/dataset_eval_avg": 4.673004150390625e-05, "timer/dataset_eval_min": 4.673004150390625e-05, "timer/dataset_eval_max": 4.673004150390625e-05, "fps": 22.11533520466147}
{"step": 924704, "time": 42462.035380363464, "episode/length": 282.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 924872, "time": 42468.88111996651, "episode/length": 146.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 925144, "time": 42479.63913321495, "episode/length": 320.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 925864, "time": 42506.82123708725, "episode/length": 217.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 925992, "time": 42512.58989620209, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 926296, "time": 42524.474596977234, "episode/length": 345.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971098265895953, "episode/intrinsic_return": 0.0}
{"step": 926320, "time": 42526.99231362343, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 926456, "time": 42532.9426047802, "episode/length": 579.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879310344827587, "episode/intrinsic_return": 0.0}
{"step": 926664, "time": 42541.40407681465, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 927440, "time": 42568.9993019104, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 927680, "time": 42578.76465678215, "episode/length": 210.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 927840, "time": 42585.61733651161, "episode/length": 391.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 927944, "time": 42590.46437048912, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 928008, "time": 42594.15482091904, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 928232, "time": 42603.12986469269, "episode/length": 295.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 928424, "time": 42611.07714128494, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 928816, "time": 42625.955399513245, "episode/length": 314.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 928928, "time": 42631.28016471863, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 929288, "time": 42644.84397268295, "episode/length": 180.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 929360, "time": 42649.054174661636, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 929424, "time": 42652.763268232346, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 929592, "time": 42659.69075465202, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 929664, "time": 42663.77068591118, "episode/length": 154.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 929904, "time": 42673.9044816494, "episode/length": 208.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 42696.215706825256, "eval_episode/length": 47.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 930072, "time": 42698.36152076721, "eval_episode/length": 59.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 930072, "time": 42704.12504005432, "eval_episode/length": 157.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 930072, "time": 42705.99073433876, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 930072, "time": 42708.49150490761, "eval_episode/length": 139.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 930072, "time": 42710.881076812744, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 930072, "time": 42712.946506500244, "eval_episode/length": 213.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9672897196261683}
{"step": 930072, "time": 42714.59858870506, "eval_episode/length": 48.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9183673469387755}
{"step": 930552, "time": 42730.86240339279, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 930744, "time": 42739.01121401787, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 930768, "time": 42741.503975868225, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 931120, "time": 42754.96999955177, "episode/length": 151.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 931256, "time": 42760.873628139496, "episode/length": 304.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 931296, "time": 42764.01554465294, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 931704, "time": 42778.8909471035, "episode/length": 284.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 931976, "time": 42790.10983967781, "episode/length": 288.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 932192, "time": 42799.15741086006, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 932288, "time": 42803.9013736248, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 932296, "time": 42805.57218384743, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 932712, "time": 42821.32001829147, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 932832, "time": 42827.18908929825, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 933048, "time": 42835.762356996536, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 933096, "time": 42838.97476911545, "episode/length": 173.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 933312, "time": 42847.99546766281, "episode/length": 139.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 933408, "time": 42852.750799417496, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 933520, "time": 42858.108268499374, "episode/length": 152.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 933648, "time": 42864.133016347885, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 934232, "time": 42887.16270780563, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 934792, "time": 42907.419783353806, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 934832, "time": 42910.548313617706, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 934952, "time": 42915.88290762901, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 935128, "time": 42923.88629794121, "episode/length": 214.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 935248, "time": 42929.708005189896, "episode/length": 268.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 935304, "time": 42932.911036252975, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 936456, "time": 42973.052940130234, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 936512, "time": 42976.780823946, "episode/length": 373.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 936912, "time": 42992.00877213478, "episode/length": 207.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 937000, "time": 42996.42185330391, "episode/length": 233.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 937168, "time": 43004.28169679642, "episode/length": 366.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 937216, "time": 43007.37901568413, "episode/length": 297.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 937256, "time": 43010.11673736572, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 937512, "time": 43020.39307284355, "episode/length": 124.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 937928, "time": 43036.92658877373, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 938208, "time": 43048.030108213425, "episode/length": 362.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9972451790633609, "episode/intrinsic_return": 0.0}
{"step": 938464, "time": 43058.18492984772, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 938536, "time": 43061.957297086716, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 938616, "time": 43066.17875266075, "episode/length": 174.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 938632, "time": 43068.148080825806, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 938720, "time": 43072.91211605072, "episode/length": 31.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 938728, "time": 43074.60219526291, "episode/length": 226.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 938976, "time": 43084.62014961243, "episode/length": 182.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 939928, "time": 43118.184977054596, "episode/length": 149.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 939944, "time": 43120.34826207161, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 43145.083278656006, "eval_episode/length": 149.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 940056, "time": 43148.63713288307, "eval_episode/length": 194.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 940056, "time": 43152.71504831314, "eval_episode/length": 252.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 940056, "time": 43155.6878657341, "eval_episode/length": 281.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9858156028368794}
{"step": 940056, "time": 43157.860693216324, "eval_episode/length": 294.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9898305084745763}
{"step": 940056, "time": 43160.219426870346, "eval_episode/length": 315.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 940056, "time": 43162.16931152344, "eval_episode/length": 325.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9815950920245399}
{"step": 940056, "time": 43164.06110882759, "eval_episode/length": 80.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9876543209876543}
{"step": 940088, "time": 43165.15527296066, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 940384, "time": 43176.72086787224, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.0}
{"step": 940560, "time": 43184.17349386215, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 940688, "time": 43189.998183727264, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 940872, "time": 43197.670379161835, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 940880, "time": 43199.74102663994, "episode/length": 292.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 940992, "time": 43205.11004400253, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 941256, "time": 43215.13907814026, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 941872, "time": 43237.484533548355, "episode/length": 185.0, "episode/score": 10.10000005364418, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 942232, "time": 43252.46188521385, "episode/length": 154.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 942344, "time": 43257.730783462524, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 942384, "time": 43260.897146463394, "episode/length": 304.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 942840, "time": 43277.84343504906, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 943160, "time": 43290.62447357178, "episode/length": 324.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 943432, "time": 43301.25491142273, "episode/length": 319.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 943504, "time": 43305.495534181595, "episode/length": 280.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 943656, "time": 43311.990837574005, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 943696, "time": 43315.170714616776, "episode/length": 227.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 943864, "time": 43322.119644641876, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 944040, "time": 43329.73423933983, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 944096, "time": 43333.3410885334, "episode/length": 232.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 944424, "time": 43345.65071797371, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 944688, "time": 43356.89201259613, "episode/length": 128.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 944776, "time": 43361.13550949097, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 944824, "time": 43364.3168156147, "episode/length": 247.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 944912, "time": 43369.695625305176, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 945048, "time": 43376.079676151276, "episode/length": 147.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 945320, "time": 43386.78861069679, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 945512, "time": 43394.775408029556, "episode/length": 57.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 945880, "time": 43408.5213842392, "episode/length": 120.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 946144, "time": 43419.182049036026, "episode/length": 181.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 946280, "time": 43425.0806517601, "episode/length": 272.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 946352, "time": 43429.278297662735, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 946392, "time": 43432.074481248856, "episode/length": 245.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 946953, "time": 43453.26568722725, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.201014927455357, "train/action_min": 0.0, "train/action_std": 3.0670863696507045, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04188960362225771, "train/actor_opt_grad_steps": 58385.0, "train/actor_opt_loss": 3.8889399304986, "train/adv_mag": 0.5197188447628702, "train/adv_max": 0.4689291917851993, "train/adv_mean": 0.005478184913668624, "train/adv_min": -0.4104801636721407, "train/adv_std": 0.05980722656739609, "train/cont_avg": 0.9949148995535714, "train/cont_loss_mean": 0.00018673003206153281, "train/cont_loss_std": 0.005743259750040254, "train/cont_neg_acc": 0.9985611511648987, "train/cont_neg_loss": 0.0075662013167163795, "train/cont_pos_acc": 0.999964942250933, "train/cont_pos_loss": 0.00014426183076015063, "train/cont_pred": 0.9948962360620499, "train/cont_rate": 0.9949148995535714, "train/dyn_loss_mean": 13.104267495019096, "train/dyn_loss_std": 9.249867684500558, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9392961872475488, "train/extr_critic_critic_opt_grad_steps": 58385.0, "train/extr_critic_critic_opt_loss": 16104.573416573661, "train/extr_critic_mag": 8.439588199343, "train/extr_critic_max": 8.439588199343, "train/extr_critic_mean": 2.8222623637744357, "train/extr_critic_min": -0.15513435091291156, "train/extr_critic_std": 1.9311214872768947, "train/extr_return_normed_mag": 1.5353761221681321, "train/extr_return_normed_max": 1.5353761221681321, "train/extr_return_normed_mean": 0.43006222099065783, "train/extr_return_normed_min": -0.10881589214716639, "train/extr_return_normed_std": 0.31999341951949256, "train/extr_return_rate": 0.8697912480149951, "train/extr_return_raw_mag": 9.671247380120414, "train/extr_return_raw_max": 9.671247380120414, "train/extr_return_raw_mean": 2.85611805660384, "train/extr_return_raw_min": -0.4670640521815845, "train/extr_return_raw_std": 1.974234643152782, "train/extr_reward_mag": 1.0464353220803397, "train/extr_reward_max": 1.0464353220803397, "train/extr_reward_mean": 0.04395463699474931, "train/extr_reward_min": -0.4469244914395469, "train/extr_reward_std": 0.19451129085251262, "train/image_loss_mean": 6.289297350815365, "train/image_loss_std": 11.40011523791722, "train/model_loss_mean": 14.20879669189453, "train/model_loss_std": 15.211320543289185, "train/model_opt_grad_norm": 51.82983292170933, "train/model_opt_grad_steps": 58331.67857142857, "train/model_opt_loss": 17760.995912388393, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5616120270320346, "train/policy_entropy_max": 2.5616120270320346, "train/policy_entropy_mean": 0.501441390812397, "train/policy_entropy_min": 0.07937501392194203, "train/policy_entropy_std": 0.6342151382139751, "train/policy_logprob_mag": 7.438383793830871, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5012427255511284, "train/policy_logprob_min": -7.438383793830871, "train/policy_logprob_std": 1.0761674412659237, "train/policy_randomness_mag": 0.9041366347244808, "train/policy_randomness_max": 0.9041366347244808, "train/policy_randomness_mean": 0.17698680694614138, "train/policy_randomness_min": 0.028015896744493927, "train/policy_randomness_std": 0.2238501126212733, "train/post_ent_mag": 59.512803132193426, "train/post_ent_max": 59.512803132193426, "train/post_ent_mean": 42.55094348362514, "train/post_ent_min": 19.863259315490723, "train/post_ent_std": 7.813990385191781, "train/prior_ent_mag": 68.40327115740095, "train/prior_ent_max": 68.40327115740095, "train/prior_ent_mean": 55.72030958448138, "train/prior_ent_min": 40.746222850254604, "train/prior_ent_std": 4.4081300871712825, "train/rep_loss_mean": 13.104267495019096, "train/rep_loss_std": 9.249867684500558, "train/reward_avg": 0.030691963913185256, "train/reward_loss_mean": 0.05675214980063694, "train/reward_loss_std": 0.24728210153324262, "train/reward_max_data": 1.0200000047683715, "train/reward_max_pred": 1.016859143120902, "train/reward_neg_acc": 0.9920515588351658, "train/reward_neg_loss": 0.028524557115244015, "train/reward_pos_acc": 0.9711456724575588, "train/reward_pos_loss": 0.8322491424424308, "train/reward_pred": 0.029841949810673084, "train/reward_rate": 0.035205078125, "train_stats/sum_log_reward": 8.44951472351852, "train_stats/max_log_achievement_collect_coal": 1.058252427184466, "train_stats/max_log_achievement_collect_drink": 4.495145631067961, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.2427184466019416, "train_stats/max_log_achievement_collect_stone": 13.271844660194175, "train_stats/max_log_achievement_collect_wood": 7.689320388349515, "train_stats/max_log_achievement_defeat_skeleton": 0.038834951456310676, "train_stats/max_log_achievement_defeat_zombie": 0.5242718446601942, "train_stats/max_log_achievement_eat_cow": 0.05825242718446602, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.009708737864077669, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2621359223300972, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.7766990291262137, "train_stats/max_log_achievement_place_plant": 1.203883495145631, "train_stats/max_log_achievement_place_stone": 3.262135922330097, "train_stats/max_log_achievement_place_table": 2.436893203883495, "train_stats/max_log_achievement_wake_up": 1.1650485436893203, "train_stats/mean_log_entropy": 0.5228125128931213, "eval_stats/sum_log_reward": 7.9124999940395355, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0625, "eval_stats/max_log_achievement_collect_stone": 12.3125, "eval_stats/max_log_achievement_collect_wood": 5.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 1.6875, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00011143251322209835, "report/cont_loss_std": 0.002034409437328577, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00028607103740796447, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00011005740816472098, "report/cont_pred": 0.9920826554298401, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.392451286315918, "report/dyn_loss_std": 8.858956336975098, "report/image_loss_mean": 6.281023979187012, "report/image_loss_std": 9.5786714553833, "report/model_loss_mean": 14.383121490478516, "report/model_loss_std": 13.434709548950195, "report/post_ent_mag": 57.82801818847656, "report/post_ent_max": 57.82801818847656, "report/post_ent_mean": 43.194889068603516, "report/post_ent_min": 20.264892578125, "report/post_ent_std": 7.659572124481201, "report/prior_ent_mag": 68.78938293457031, "report/prior_ent_max": 68.78938293457031, "report/prior_ent_mean": 56.4037971496582, "report/prior_ent_min": 41.74518966674805, "report/prior_ent_std": 4.336940765380859, "report/rep_loss_mean": 13.392451286315918, "report/rep_loss_std": 8.858956336975098, "report/reward_avg": 0.03720702975988388, "report/reward_loss_mean": 0.06651590764522552, "report/reward_loss_std": 0.2373512089252472, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0225262641906738, "report/reward_neg_acc": 0.9979591369628906, "report/reward_neg_loss": 0.0360877588391304, "report/reward_pos_acc": 0.9772727489471436, "report/reward_pos_loss": 0.7442336082458496, "report/reward_pred": 0.03642098605632782, "report/reward_rate": 0.04296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.621722266369034e-06, "eval/cont_loss_std": 0.0001316037669312209, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.4445659871853422e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.604454145213822e-06, "eval/cont_pred": 0.9980413913726807, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.6912784576416, "eval/dyn_loss_std": 10.231901168823242, "eval/image_loss_mean": 10.291295051574707, "eval/image_loss_std": 16.982519149780273, "eval/model_loss_mean": 21.66006851196289, "eval/model_loss_std": 20.75042152404785, "eval/post_ent_mag": 57.46903991699219, "eval/post_ent_max": 57.46903991699219, "eval/post_ent_mean": 39.2674560546875, "eval/post_ent_min": 20.08388328552246, "eval/post_ent_std": 7.097477912902832, "eval/prior_ent_mag": 68.78938293457031, "eval/prior_ent_max": 68.78938293457031, "eval/prior_ent_mean": 55.52565383911133, "eval/prior_ent_min": 43.20625305175781, "eval/prior_ent_std": 4.01124906539917, "eval/rep_loss_mean": 18.6912784576416, "eval/rep_loss_std": 10.231901168823242, "eval/reward_avg": 0.05029296875, "eval/reward_loss_mean": 0.15400046110153198, "eval/reward_loss_std": 0.7437559366226196, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047967433929443, "eval/reward_neg_acc": 0.9752577543258667, "eval/reward_neg_loss": 0.08213723450899124, "eval/reward_pos_acc": 0.9074074029922485, "eval/reward_pos_loss": 1.444877028465271, "eval/reward_pred": 0.05549817532300949, "eval/reward_rate": 0.052734375, "replay/size": 946449.0, "replay/inserts": 22512.0, "replay/samples": 22512.0, "replay/insert_wait_avg": 1.3711292352249374e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.058889295500733e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1476879779975487e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0985555648804, "timer/env.step_count": 2814.0, "timer/env.step_total": 245.31547355651855, "timer/env.step_frac": 0.2452912987340116, "timer/env.step_avg": 0.08717678520132145, "timer/env.step_min": 0.023469924926757812, "timer/env.step_max": 2.300339460372925, "timer/replay._sample_count": 22512.0, "timer/replay._sample_total": 11.44996166229248, "timer/replay._sample_frac": 0.011448833316057795, "timer/replay._sample_avg": 0.0005086159231650889, "timer/replay._sample_min": 0.00042057037353515625, "timer/replay._sample_max": 0.01060342788696289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3363.0, "timer/agent.policy_total": 54.80302548408508, "timer/agent.policy_frac": 0.0547976248732116, "timer/agent.policy_avg": 0.016295874363391343, "timer/agent.policy_min": 0.009402275085449219, "timer/agent.policy_max": 0.11391901969909668, "timer/dataset_train_count": 1407.0, "timer/dataset_train_total": 0.1554250717163086, "timer/dataset_train_frac": 0.00015540975522009495, "timer/dataset_train_avg": 0.00011046558046645956, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.000579833984375, "timer/agent.train_count": 1407.0, "timer/agent.train_total": 631.6325137615204, "timer/agent.train_frac": 0.6315702689968977, "timer/agent.train_avg": 0.44892147388878495, "timer/agent.train_min": 0.4338359832763672, "timer/agent.train_max": 1.7681372165679932, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4800865650177002, "timer/agent.report_frac": 0.0004800392544778104, "timer/agent.report_avg": 0.2400432825088501, "timer/agent.report_min": 0.23323678970336914, "timer/agent.report_max": 0.24684977531433105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146815108000082e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.509502860613093}
{"step": 947024, "time": 43455.719384908676, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 947088, "time": 43459.370220422745, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9896193771626297, "episode/intrinsic_return": 0.0}
{"step": 947224, "time": 43465.25786757469, "episode/length": 237.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 947264, "time": 43468.31540083885, "episode/length": 108.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 947432, "time": 43475.40017771721, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 947440, "time": 43477.416706323624, "episode/length": 135.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 947736, "time": 43488.829823732376, "episode/length": 37.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 947776, "time": 43491.85613512993, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 948416, "time": 43514.80526137352, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 948848, "time": 43530.82783317566, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 948944, "time": 43535.65640091896, "episode/length": 187.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 949008, "time": 43539.43131637573, "episode/length": 390.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 949032, "time": 43541.53664112091, "episode/length": 156.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 949656, "time": 43563.80824756622, "episode/length": 154.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 949744, "time": 43568.6323928833, "episode/length": 250.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 949768, "time": 43570.777878046036, "episode/length": 317.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 949920, "time": 43577.515983343124, "episode/length": 331.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 43599.424931287766, "eval_episode/length": 46.0, "eval_episode/score": 4.099999964237213, "eval_episode/reward_rate": 0.9148936170212766}
{"step": 950040, "time": 43606.97629094124, "eval_episode/length": 183.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 950040, "time": 43609.337960481644, "eval_episode/length": 203.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 950040, "time": 43612.11188006401, "eval_episode/length": 229.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 950040, "time": 43613.9403591156, "eval_episode/length": 235.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 950040, "time": 43616.083330869675, "eval_episode/length": 245.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 950040, "time": 43618.801983356476, "eval_episode/length": 272.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 950040, "time": 43620.82630586624, "eval_episode/length": 282.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9752650176678446}
{"step": 950144, "time": 43624.49594426155, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 950904, "time": 43652.67233085632, "episode/length": 155.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 950976, "time": 43656.94011974335, "episode/length": 245.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 950992, "time": 43659.049100637436, "episode/length": 155.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 951080, "time": 43663.231125593185, "episode/length": 163.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 951112, "time": 43665.85786128044, "episode/length": 259.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 951472, "time": 43679.55983901024, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.0}
{"step": 951688, "time": 43688.18925857544, "episode/length": 220.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 951816, "time": 43694.0503988266, "episode/length": 208.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 952216, "time": 43708.86908745766, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 952240, "time": 43711.50064134598, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 952384, "time": 43718.22582244873, "episode/length": 86.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 952472, "time": 43722.445959568024, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 952488, "time": 43724.585119485855, "episode/length": 175.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 953048, "time": 43744.652183294296, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 953768, "time": 43770.528757572174, "episode/length": 161.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 953888, "time": 43776.447501182556, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 954392, "time": 43794.83612179756, "episode/length": 250.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 954456, "time": 43798.496629714966, "episode/length": 279.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 954488, "time": 43801.14326429367, "episode/length": 438.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9977220956719818, "episode/intrinsic_return": 0.0}
{"step": 954560, "time": 43805.4089744091, "episode/length": 342.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 954928, "time": 43819.931956768036, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 954960, "time": 43822.55543088913, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 955120, "time": 43829.53471803665, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 955328, "time": 43838.192237854004, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 955512, "time": 43845.549588918686, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 955640, "time": 43851.425023555756, "episode/length": 84.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 955896, "time": 43861.48742103577, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 956024, "time": 43867.39724779129, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 956448, "time": 43883.55588197708, "episode/length": 165.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 956624, "time": 43891.62931013107, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 956752, "time": 43897.51535511017, "episode/length": 294.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 956984, "time": 43906.60733628273, "episode/length": 206.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 957072, "time": 43911.37760639191, "episode/length": 146.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 957240, "time": 43918.44599890709, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 957240, "time": 43918.45456433296, "episode/length": 199.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 957432, "time": 43928.27005696297, "episode/length": 100.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 957664, "time": 43937.8786714077, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 958232, "time": 43958.19169282913, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 958264, "time": 43960.870780706406, "episode/length": 226.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 958288, "time": 43963.541056871414, "episode/length": 130.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 958624, "time": 43977.84548711777, "episode/length": 119.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 959288, "time": 44001.535670518875, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 959312, "time": 44004.18817973137, "episode/length": 279.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 959584, "time": 44014.87231397629, "episode/length": 161.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 959696, "time": 44020.158061265945, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 959704, "time": 44021.8824570179, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 959720, "time": 44023.98544359207, "episode/length": 285.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 960016, "time": 44035.68533658981, "episode/length": 378.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 44053.03873538971, "eval_episode/length": 61.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 960024, "time": 44059.35766196251, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 960024, "time": 44061.210966825485, "eval_episode/length": 176.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 960024, "time": 44064.225234270096, "eval_episode/length": 209.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 960024, "time": 44066.40821504593, "eval_episode/length": 222.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9730941704035875}
{"step": 960024, "time": 44068.841945409775, "eval_episode/length": 242.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 960024, "time": 44071.71632218361, "eval_episode/length": 209.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 960024, "time": 44073.55876469612, "eval_episode/length": 279.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9964285714285714}
{"step": 960152, "time": 44077.90566277504, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 960808, "time": 44101.095863342285, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 960896, "time": 44105.922760248184, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 961056, "time": 44112.809440135956, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 961784, "time": 44138.69542884827, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 961960, "time": 44146.10033750534, "episode/length": 279.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 961976, "time": 44148.23351478577, "episode/length": 284.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 962632, "time": 44171.808525800705, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 962960, "time": 44184.41979575157, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 963144, "time": 44191.86276578903, "episode/length": 280.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 963264, "time": 44197.61927127838, "episode/length": 388.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.987146529562982, "episode/intrinsic_return": 0.0}
{"step": 963488, "time": 44206.582387924194, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761194029850746, "episode/intrinsic_return": 0.0}
{"step": 964176, "time": 44231.09194159508, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 964184, "time": 44232.66592717171, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 964224, "time": 44235.71079349518, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 964624, "time": 44250.58388376236, "episode/length": 169.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 964664, "time": 44253.21330022812, "episode/length": 359.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 964696, "time": 44255.85469841957, "episode/length": 150.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 964704, "time": 44257.88301706314, "episode/length": 340.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765395894428153, "episode/intrinsic_return": 0.0}
{"step": 965096, "time": 44272.38483953476, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 965296, "time": 44280.79052734375, "episode/length": 133.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 965968, "time": 44304.72001051903, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 965992, "time": 44306.90597271919, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 966064, "time": 44311.29282426834, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 966224, "time": 44318.399629831314, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 966344, "time": 44323.66315126419, "episode/length": 155.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 966352, "time": 44325.76416897774, "episode/length": 206.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 966400, "time": 44328.97339749336, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 966976, "time": 44351.7006547451, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 967416, "time": 44367.768600702286, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 967480, "time": 44371.54906916618, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 967680, "time": 44380.08952283859, "episode/length": 181.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 967744, "time": 44383.68126249313, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 967768, "time": 44385.934161901474, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 967848, "time": 44390.19124674797, "episode/length": 234.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 968328, "time": 44407.81514501572, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 968696, "time": 44421.66505551338, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 969024, "time": 44434.45426225662, "episode/length": 86.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 969072, "time": 44437.79156756401, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 969248, "time": 44445.152144908905, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 969416, "time": 44452.099573135376, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 969417, "time": 44454.60725593567, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.388279258782137, "train/action_min": 0.0, "train/action_std": 3.272756304301269, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04139611341640459, "train/actor_opt_grad_steps": 59790.0, "train/actor_opt_loss": 1.6268794202635475, "train/adv_mag": 0.49508255318546973, "train/adv_max": 0.4402427022338759, "train/adv_mean": 0.004710169770600685, "train/adv_min": -0.42446062898804954, "train/adv_std": 0.05897717333748831, "train/cont_avg": 0.9946462211879432, "train/cont_loss_mean": 0.00018009068489408547, "train/cont_loss_std": 0.005400393195893056, "train/cont_neg_acc": 0.9917088840024691, "train/cont_neg_loss": 0.01998759806127132, "train/cont_pos_acc": 0.9999790956788029, "train/cont_pos_loss": 5.164989343177099e-05, "train/cont_pred": 0.9946727541321558, "train/cont_rate": 0.9946462211879432, "train/dyn_loss_mean": 13.39116928425241, "train/dyn_loss_std": 9.222816521394337, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0250332647181573, "train/extr_critic_critic_opt_grad_steps": 59790.0, "train/extr_critic_critic_opt_loss": 16290.799119015957, "train/extr_critic_mag": 9.234657767816639, "train/extr_critic_max": 9.234657767816639, "train/extr_critic_mean": 3.2453697049025947, "train/extr_critic_min": -0.1580093946862728, "train/extr_critic_std": 2.191009666902799, "train/extr_return_normed_mag": 1.4993671753727797, "train/extr_return_normed_max": 1.4993671753727797, "train/extr_return_normed_mean": 0.4439223993120464, "train/extr_return_normed_min": -0.10159784975521108, "train/extr_return_normed_std": 0.32753159613051314, "train/extr_return_rate": 0.8785221344190286, "train/extr_return_raw_mag": 10.47040298137259, "train/extr_return_raw_max": 10.47040298137259, "train/extr_return_raw_mean": 3.2772226654891425, "train/extr_return_raw_min": -0.4408549761518519, "train/extr_return_raw_std": 2.2320529230942965, "train/extr_reward_mag": 1.0388339648010037, "train/extr_reward_max": 1.0388339648010037, "train/extr_reward_mean": 0.0436283058440643, "train/extr_reward_min": -0.46441366909243537, "train/extr_reward_std": 0.19387945944958546, "train/image_loss_mean": 6.509497529225992, "train/image_loss_std": 11.632974844452336, "train/model_loss_mean": 14.603176827126362, "train/model_loss_std": 15.388025899305411, "train/model_opt_grad_norm": 53.79034550984701, "train/model_opt_grad_steps": 59735.397163120564, "train/model_opt_loss": 18253.971042497782, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8652482269504, "train/policy_entropy_mag": 2.533611201225443, "train/policy_entropy_max": 2.533611201225443, "train/policy_entropy_mean": 0.49580865823630743, "train/policy_entropy_min": 0.07937501386759128, "train/policy_entropy_std": 0.6379389866446772, "train/policy_logprob_mag": 7.4383838227454655, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49601030920414213, "train/policy_logprob_min": -7.4383838227454655, "train/policy_logprob_std": 1.0764867473155895, "train/policy_randomness_mag": 0.8942535688691106, "train/policy_randomness_max": 0.8942535688691106, "train/policy_randomness_mean": 0.17499869787101205, "train/policy_randomness_min": 0.028015896717601633, "train/policy_randomness_std": 0.22516446861814945, "train/post_ent_mag": 59.28030122256448, "train/post_ent_max": 59.28030122256448, "train/post_ent_mean": 42.33615298981362, "train/post_ent_min": 19.795318833479644, "train/post_ent_std": 7.72699680734188, "train/prior_ent_mag": 68.50744753357367, "train/prior_ent_max": 68.50744753357367, "train/prior_ent_mean": 55.767908948533076, "train/prior_ent_min": 40.716391705452125, "train/prior_ent_std": 4.472856773552319, "train/rep_loss_mean": 13.39116928425241, "train/rep_loss_std": 9.222816521394337, "train/reward_avg": 0.031207751396858524, "train/reward_loss_mean": 0.058797805735194095, "train/reward_loss_std": 0.2528713439584624, "train/reward_max_data": 1.0212766008174166, "train/reward_max_pred": 1.0165984436129847, "train/reward_neg_acc": 0.9921757211076453, "train/reward_neg_loss": 0.03003747548564529, "train/reward_pos_acc": 0.9699072951966143, "train/reward_pos_loss": 0.8343953059074727, "train/reward_pred": 0.030457628210544162, "train/reward_rate": 0.03584192154255319, "train_stats/sum_log_reward": 8.455140390128733, "train_stats/max_log_achievement_collect_coal": 1.1775700934579438, "train_stats/max_log_achievement_collect_drink": 4.579439252336448, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 0.9906542056074766, "train_stats/max_log_achievement_collect_stone": 14.607476635514018, "train_stats/max_log_achievement_collect_wood": 6.962616822429907, "train_stats/max_log_achievement_defeat_skeleton": 0.06542056074766354, "train_stats/max_log_achievement_defeat_zombie": 0.42990654205607476, "train_stats/max_log_achievement_eat_cow": 0.037383177570093455, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.205607476635514, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.9532710280373833, "train_stats/max_log_achievement_place_plant": 0.9813084112149533, "train_stats/max_log_achievement_place_stone": 3.439252336448598, "train_stats/max_log_achievement_place_table": 1.7757009345794392, "train_stats/max_log_achievement_wake_up": 1.280373831775701, "train_stats/mean_log_entropy": 0.5047836507035193, "eval_stats/sum_log_reward": 8.850000143051147, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 16.25, "eval_stats/max_log_achievement_collect_wood": 6.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.125, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.4375, "eval_stats/max_log_achievement_place_table": 1.8125, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00020308539387769997, "report/cont_loss_std": 0.0029685995541512966, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0030713847372680902, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00018334291235078126, "report/cont_pred": 0.9930070638656616, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.786218643188477, "report/dyn_loss_std": 8.936872482299805, "report/image_loss_mean": 5.134063720703125, "report/image_loss_std": 11.90161418914795, "report/model_loss_mean": 12.261383056640625, "report/model_loss_std": 15.301036834716797, "report/post_ent_mag": 62.18056869506836, "report/post_ent_max": 62.18056869506836, "report/post_ent_mean": 44.20465087890625, "report/post_ent_min": 19.05870819091797, "report/post_ent_std": 8.177214622497559, "report/prior_ent_mag": 68.3603515625, "report/prior_ent_max": 68.3603515625, "report/prior_ent_mean": 55.93659591674805, "report/prior_ent_min": 41.890159606933594, "report/prior_ent_std": 4.472636699676514, "report/rep_loss_mean": 11.786218643188477, "report/rep_loss_std": 8.936872482299805, "report/reward_avg": 0.02548828162252903, "report/reward_loss_mean": 0.055384501814842224, "report/reward_loss_std": 0.20961904525756836, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023396015167236, "report/reward_neg_acc": 0.9878787398338318, "report/reward_neg_loss": 0.032133836299180984, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7323890328407288, "report/reward_pred": 0.02684197947382927, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.8113495470024645e-05, "eval/cont_loss_std": 0.001550107728689909, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010828654281795025, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.264908395474777e-06, "eval/cont_pred": 0.9951636791229248, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.27121353149414, "eval/dyn_loss_std": 10.269844055175781, "eval/image_loss_mean": 12.075399398803711, "eval/image_loss_std": 14.873376846313477, "eval/model_loss_mean": 23.7665958404541, "eval/model_loss_std": 18.590251922607422, "eval/post_ent_mag": 61.87411880493164, "eval/post_ent_max": 61.87411880493164, "eval/post_ent_mean": 39.660484313964844, "eval/post_ent_min": 18.614662170410156, "eval/post_ent_std": 8.254237174987793, "eval/prior_ent_mag": 68.3603515625, "eval/prior_ent_max": 68.3603515625, "eval/prior_ent_mean": 56.77648162841797, "eval/prior_ent_min": 42.192840576171875, "eval/prior_ent_std": 4.179830074310303, "eval/rep_loss_mean": 19.27121353149414, "eval/rep_loss_std": 10.269844055175781, "eval/reward_avg": 0.05312499776482582, "eval/reward_loss_mean": 0.12841059267520905, "eval/reward_loss_std": 0.6273870468139648, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0030012130737305, "eval/reward_neg_acc": 0.9844720959663391, "eval/reward_neg_loss": 0.050089795142412186, "eval/reward_pos_acc": 0.8793103694915771, "eval/reward_pos_loss": 1.4328571557998657, "eval/reward_pred": 0.04727194830775261, "eval/reward_rate": 0.056640625, "replay/size": 968913.0, "replay/inserts": 22464.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.3761816710828036e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.093847539689806e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1910341984425303e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3299658298492, "timer/env.step_count": 2808.0, "timer/env.step_total": 246.2853410243988, "timer/env.step_frac": 0.24595822498959227, "timer/env.step_avg": 0.0877084547807688, "timer/env.step_min": 0.023018360137939453, "timer/env.step_max": 3.350943088531494, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.455223321914673, "timer/replay._sample_frac": 0.011440008501514474, "timer/replay._sample_avg": 0.0005099369356265435, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.03172945976257324, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3371.0, "timer/agent.policy_total": 56.395193099975586, "timer/agent.policy_frac": 0.05632028904002512, "timer/agent.policy_avg": 0.016729514417079674, "timer/agent.policy_min": 0.009443521499633789, "timer/agent.policy_max": 0.12542486190795898, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.15399837493896484, "timer/dataset_train_frac": 0.00015379383439437884, "timer/dataset_train_avg": 0.00010968545223572995, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0006432533264160156, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 629.8996937274933, "timer/agent.train_frac": 0.629063061351076, "timer/agent.train_avg": 0.4486465055039126, "timer/agent.train_min": 0.4316418170928955, "timer/agent.train_max": 1.6467595100402832, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48063206672668457, "timer/agent.report_frac": 0.00047999369151842185, "timer/agent.report_avg": 0.24031603336334229, "timer/agent.report_min": 0.23352956771850586, "timer/agent.report_max": 0.2471024990081787, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.904843322678834e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.433889414566384}
{"step": 969496, "time": 44457.05208683014, "episode/length": 226.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 969672, "time": 44464.367180109024, "episode/length": 281.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 969888, "time": 44473.53860139847, "episode/length": 442.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 44502.583921670914, "eval_episode/length": 161.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 970008, "time": 44505.28085589409, "eval_episode/length": 185.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 970008, "time": 44507.50910973549, "eval_episode/length": 198.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 970008, "time": 44509.51290297508, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 970008, "time": 44511.659215927124, "eval_episode/length": 219.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 970008, "time": 44515.846118450165, "eval_episode/length": 276.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9711191335740073}
{"step": 970008, "time": 44518.08873295784, "eval_episode/length": 94.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 970008, "time": 44521.794211387634, "eval_episode/length": 96.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 970536, "time": 44539.51928663254, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 970640, "time": 44544.759044885635, "episode/length": 242.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 970768, "time": 44550.558691740036, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 970784, "time": 44552.71624708176, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 971376, "time": 44574.140043735504, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 971504, "time": 44580.05774116516, "episode/length": 201.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 971624, "time": 44585.45749592781, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 972224, "time": 44607.158509492874, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 972224, "time": 44607.16806125641, "episode/length": 197.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 972784, "time": 44629.29281926155, "episode/length": 410.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829683698296837, "episode/intrinsic_return": 0.0}
{"step": 973032, "time": 44638.87411046028, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 973048, "time": 44640.97959423065, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 973272, "time": 44650.28021264076, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 973456, "time": 44658.18704414368, "episode/length": 335.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 973480, "time": 44660.333104372025, "episode/length": 246.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 973648, "time": 44667.77741575241, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 974032, "time": 44682.24198651314, "episode/length": 68.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 974168, "time": 44688.17672300339, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 974312, "time": 44694.51272702217, "episode/length": 157.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 974392, "time": 44698.875238895416, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 974808, "time": 44714.31368255615, "episode/length": 252.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 974824, "time": 44716.425704717636, "episode/length": 170.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 975088, "time": 44728.59076118469, "episode/length": 131.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 975168, "time": 44732.854605674744, "episode/length": 236.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 975312, "time": 44739.747230768204, "episode/length": 142.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 975688, "time": 44753.56373333931, "episode/length": 254.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 975792, "time": 44758.873055934906, "episode/length": 120.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 975888, "time": 44763.55456781387, "episode/length": 186.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 975928, "time": 44766.26535701752, "episode/length": 139.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 976592, "time": 44789.93795323372, "episode/length": 284.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9754385964912281, "episode/intrinsic_return": 0.0}
{"step": 976768, "time": 44797.727734565735, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 977032, "time": 44807.73205447197, "episode/length": 154.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 977456, "time": 44823.65728902817, "episode/length": 195.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 977520, "time": 44827.49277448654, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9650655021834061, "episode/intrinsic_return": 0.0}
{"step": 977816, "time": 44838.64093875885, "episode/length": 340.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853372434017595, "episode/intrinsic_return": 0.0}
{"step": 978008, "time": 44846.6331577301, "episode/length": 336.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 978128, "time": 44852.38227081299, "episode/length": 191.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 978288, "time": 44859.54690742493, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 978344, "time": 44862.707129478455, "episode/length": 110.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 978440, "time": 44867.38741326332, "episode/length": 313.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 978624, "time": 44875.30373573303, "episode/length": 34.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 979000, "time": 44889.22312998772, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 979184, "time": 44897.19808769226, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 979440, "time": 44907.84535193443, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 979472, "time": 44910.51062941551, "episode/length": 147.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 979600, "time": 44916.398535728455, "episode/length": 198.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 979632, "time": 44919.09997057915, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 979688, "time": 44922.39390707016, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 980040, "time": 44935.64166140556, "episode/length": 54.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 44954.17912006378, "eval_episode/length": 37.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 980096, "time": 44960.2715075016, "eval_episode/length": 147.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 980096, "time": 44962.584688186646, "eval_episode/length": 166.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 980096, "time": 44966.1625931263, "eval_episode/length": 183.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 980096, "time": 44968.61860013008, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 980096, "time": 44970.797895908356, "eval_episode/length": 202.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 980096, "time": 44974.21137237549, "eval_episode/length": 53.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 980096, "time": 44975.98366069794, "eval_episode/length": 246.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 980544, "time": 44990.73706245422, "episode/length": 377.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 980600, "time": 44993.94400072098, "episode/length": 199.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 980888, "time": 45005.16120505333, "episode/length": 212.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 981056, "time": 45012.57370471954, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 981080, "time": 45014.85909819603, "episode/length": 200.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 981936, "time": 45045.266795158386, "episode/length": 106.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 982224, "time": 45056.49322581291, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 982264, "time": 45059.26341962814, "episode/length": 321.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 982544, "time": 45070.459738731384, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 982576, "time": 45073.141371011734, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 982600, "time": 45075.350872039795, "episode/length": 82.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 982744, "time": 45081.70480108261, "episode/length": 412.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 982784, "time": 45084.75401687622, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 982944, "time": 45091.62071728706, "episode/length": 235.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 983304, "time": 45106.83693742752, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 983632, "time": 45119.610457897186, "episode/length": 128.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 983696, "time": 45123.320872068405, "episode/length": 178.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 984040, "time": 45136.28220486641, "episode/length": 136.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 984112, "time": 45141.24121403694, "episode/length": 100.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 984352, "time": 45150.7290956974, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 984368, "time": 45152.79616689682, "episode/length": 91.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 984464, "time": 45157.580246925354, "episode/length": 209.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 985056, "time": 45179.04255485535, "episode/length": 169.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 985648, "time": 45202.84900474548, "episode/length": 147.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 985760, "time": 45208.53957247734, "episode/length": 214.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 985840, "time": 45212.84387540817, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 985952, "time": 45218.19809818268, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 985984, "time": 45220.85405468941, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 985984, "time": 45220.86553525925, "episode/length": 429.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 986064, "time": 45226.860392808914, "episode/length": 435.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 986880, "time": 45255.54433488846, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 987160, "time": 45266.14986348152, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 987400, "time": 45275.7605111599, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 987448, "time": 45278.88105416298, "episode/length": 182.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 988032, "time": 45300.218349933624, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 988360, "time": 45312.502257823944, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 988640, "time": 45323.608628988266, "episode/length": 359.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9972222222222222, "episode/intrinsic_return": 0.0}
{"step": 988672, "time": 45326.39597272873, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 988688, "time": 45328.45120501518, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 988848, "time": 45335.399832725525, "episode/length": 375.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9973404255319149, "episode/intrinsic_return": 0.0}
{"step": 989248, "time": 45350.18582820892, "episode/length": 224.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 989456, "time": 45358.55591869354, "episode/length": 101.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 989504, "time": 45361.8924510479, "episode/length": 327.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 989616, "time": 45367.271361112595, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 989632, "time": 45369.38137602806, "episode/length": 119.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 989672, "time": 45372.05746459961, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 45406.04794549942, "eval_episode/length": 132.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 990080, "time": 45409.19198656082, "eval_episode/length": 170.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 990080, "time": 45411.166293382645, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 990080, "time": 45414.05227518082, "eval_episode/length": 208.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 990080, "time": 45416.40985870361, "eval_episode/length": 90.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.945054945054945}
{"step": 990080, "time": 45418.573790073395, "eval_episode/length": 237.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 990080, "time": 45420.38634300232, "eval_episode/length": 241.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 990080, "time": 45425.02553772926, "eval_episode/length": 309.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9967741935483871}
{"step": 990352, "time": 45434.0436565876, "episode/length": 91.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 990360, "time": 45435.75559616089, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 990528, "time": 45443.34657430649, "episode/length": 209.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 990608, "time": 45447.99589180946, "episode/length": 169.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 990672, "time": 45451.83317565918, "episode/length": 39.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 990697, "time": 45455.0788435936, "train_stats/sum_log_reward": 8.459223511149583, "train_stats/max_log_achievement_collect_coal": 0.8932038834951457, "train_stats/max_log_achievement_collect_drink": 4.29126213592233, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.0776699029126213, "train_stats/max_log_achievement_collect_stone": 12.96116504854369, "train_stats/max_log_achievement_collect_wood": 7.349514563106796, "train_stats/max_log_achievement_defeat_skeleton": 0.009708737864077669, "train_stats/max_log_achievement_defeat_zombie": 0.4077669902912621, "train_stats/max_log_achievement_eat_cow": 0.05825242718446602, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4660194174757282, "train_stats/max_log_achievement_make_wood_sword": 0.019417475728155338, "train_stats/max_log_achievement_place_furnace": 1.5436893203883495, "train_stats/max_log_achievement_place_plant": 1.0485436893203883, "train_stats/max_log_achievement_place_stone": 3.9611650485436893, "train_stats/max_log_achievement_place_table": 1.883495145631068, "train_stats/max_log_achievement_wake_up": 1.5436893203883495, "train_stats/mean_log_entropy": 0.5434920974437473, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.553814192463581, "train/action_min": 0.0, "train/action_std": 3.3826459009844556, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03824489474072492, "train/actor_opt_grad_steps": 61160.0, "train/actor_opt_loss": -9.500955172163204, "train/adv_mag": 0.4609655504836176, "train/adv_max": 0.41365860458603476, "train/adv_mean": 0.00174176606471068, "train/adv_min": -0.3677818240751897, "train/adv_std": 0.05431044751540162, "train/cont_avg": 0.995131872650376, "train/cont_loss_mean": 0.0002047194367725048, "train/cont_loss_std": 0.0062303154014577205, "train/cont_neg_acc": 0.9921679200982689, "train/cont_neg_loss": 0.01476670712093991, "train/cont_pos_acc": 0.999970429373863, "train/cont_pos_loss": 0.00013395490629440672, "train/cont_pred": 0.9951202138922268, "train/cont_rate": 0.995131872650376, "train/dyn_loss_mean": 13.058824187830874, "train/dyn_loss_std": 9.242170061383929, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9729481191563427, "train/extr_critic_critic_opt_grad_steps": 61160.0, "train/extr_critic_critic_opt_loss": 15743.912314967105, "train/extr_critic_mag": 9.448920687338463, "train/extr_critic_max": 9.448920687338463, "train/extr_critic_mean": 3.201982621859787, "train/extr_critic_min": -0.15604584378407413, "train/extr_critic_std": 2.156270075561409, "train/extr_return_normed_mag": 1.490046757504456, "train/extr_return_normed_max": 1.490046757504456, "train/extr_return_normed_mean": 0.42295946528140765, "train/extr_return_normed_min": -0.10788339975857197, "train/extr_return_normed_std": 0.3150381900762257, "train/extr_return_rate": 0.89957417715761, "train/extr_return_raw_mag": 10.61457317753842, "train/extr_return_raw_max": 10.61457317753842, "train/extr_return_raw_mean": 3.214067025292189, "train/extr_return_raw_min": -0.4682871327364355, "train/extr_return_raw_std": 2.185335856631286, "train/extr_reward_mag": 1.0414439484589082, "train/extr_reward_max": 1.0414439484589082, "train/extr_reward_mean": 0.04390897765699634, "train/extr_reward_min": -0.46568213369613304, "train/extr_reward_std": 0.19438394131068898, "train/image_loss_mean": 6.413151242679223, "train/image_loss_std": 11.854282128183465, "train/model_loss_mean": 14.305183374792113, "train/model_loss_std": 15.628969120800047, "train/model_opt_grad_norm": 49.284072187610136, "train/model_opt_grad_steps": 61103.38345864662, "train/model_opt_loss": 11885.02815510456, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 827.0676691729324, "train/policy_entropy_mag": 2.5941471282700848, "train/policy_entropy_max": 2.5941471282700848, "train/policy_entropy_mean": 0.5352690269176225, "train/policy_entropy_min": 0.07937501398916531, "train/policy_entropy_std": 0.6923112945449084, "train/policy_logprob_mag": 7.438383819465351, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5355792979996904, "train/policy_logprob_min": -7.438383819465351, "train/policy_logprob_std": 1.1099122986757666, "train/policy_randomness_mag": 0.915620095747754, "train/policy_randomness_max": 0.915620095747754, "train/policy_randomness_mean": 0.1889264780775945, "train/policy_randomness_min": 0.02801589676199999, "train/policy_randomness_std": 0.24435550579451082, "train/post_ent_mag": 59.51925099881968, "train/post_ent_max": 59.51925099881968, "train/post_ent_mean": 42.661246020094794, "train/post_ent_min": 20.099060589209536, "train/post_ent_std": 7.797841642135964, "train/prior_ent_mag": 68.4980620764252, "train/prior_ent_max": 68.4980620764252, "train/prior_ent_mean": 55.80001684776823, "train/prior_ent_min": 40.798835238119715, "train/prior_ent_std": 4.4291109411340015, "train/rep_loss_mean": 13.058824187830874, "train/rep_loss_std": 9.242170061383929, "train/reward_avg": 0.030988604159451517, "train/reward_loss_mean": 0.05653295982489012, "train/reward_loss_std": 0.23997853954035536, "train/reward_max_data": 1.0157894774487144, "train/reward_max_pred": 1.0135605514497685, "train/reward_neg_acc": 0.9920966674510697, "train/reward_neg_loss": 0.02859693380506863, "train/reward_pos_acc": 0.9740585079766754, "train/reward_pos_loss": 0.8192115484323717, "train/reward_pred": 0.030341609437158683, "train/reward_rate": 0.03541324013157895, "eval_stats/sum_log_reward": 8.225000262260437, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 3.9166666666666665, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0416666666666667, "eval_stats/max_log_achievement_collect_stone": 10.583333333333334, "eval_stats/max_log_achievement_collect_wood": 7.666666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6666666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.0416666666666667, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 2.1666666666666665, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.711963702495268e-07, "report/cont_loss_std": 4.020215783384629e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.128597983159125e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1265476018706977e-07, "report/cont_pred": 0.9980469942092896, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 13.511714935302734, "report/dyn_loss_std": 9.719876289367676, "report/image_loss_mean": 5.775396347045898, "report/image_loss_std": 10.4982328414917, "report/model_loss_mean": 13.945842742919922, "report/model_loss_std": 14.748963356018066, "report/post_ent_mag": 58.301937103271484, "report/post_ent_max": 58.301937103271484, "report/post_ent_mean": 42.20722198486328, "report/post_ent_min": 19.516948699951172, "report/post_ent_std": 7.952770233154297, "report/prior_ent_mag": 68.1278076171875, "report/prior_ent_max": 68.1278076171875, "report/prior_ent_mean": 55.692466735839844, "report/prior_ent_min": 39.6622314453125, "report/prior_ent_std": 4.179102897644043, "report/rep_loss_mean": 13.511714935302734, "report/rep_loss_std": 9.719876289367676, "report/reward_avg": 0.041015625, "report/reward_loss_mean": 0.06341752409934998, "report/reward_loss_std": 0.3323259949684143, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0132310390472412, "report/reward_neg_acc": 0.9928498864173889, "report/reward_neg_loss": 0.018632229417562485, "report/reward_pos_acc": 0.9111111164093018, "report/reward_pos_loss": 1.0377466678619385, "report/reward_pred": 0.03834721818566322, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.0597515029076021e-05, "eval/cont_loss_std": 0.00031338416738435626, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0021356414072215557, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7041240596427087e-07, "eval/cont_pred": 0.9951274394989014, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.160633087158203, "eval/dyn_loss_std": 10.046086311340332, "eval/image_loss_mean": 9.790061950683594, "eval/image_loss_std": 12.982028007507324, "eval/model_loss_mean": 20.823368072509766, "eval/model_loss_std": 17.01348304748535, "eval/post_ent_mag": 57.955467224121094, "eval/post_ent_max": 57.955467224121094, "eval/post_ent_mean": 40.7479248046875, "eval/post_ent_min": 19.323684692382812, "eval/post_ent_std": 7.7626848220825195, "eval/prior_ent_mag": 68.1278076171875, "eval/prior_ent_max": 68.1278076171875, "eval/prior_ent_mean": 56.76885223388672, "eval/prior_ent_min": 45.825843811035156, "eval/prior_ent_std": 4.140554428100586, "eval/rep_loss_mean": 18.160633087158203, "eval/rep_loss_std": 10.046086311340332, "eval/reward_avg": 0.04853515699505806, "eval/reward_loss_mean": 0.13691633939743042, "eval/reward_loss_std": 0.7499119639396667, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023927688598633, "eval/reward_neg_acc": 0.9917526245117188, "eval/reward_neg_loss": 0.051561325788497925, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.6701453924179077, "eval/reward_pred": 0.04039018228650093, "eval/reward_rate": 0.052734375, "replay/size": 990193.0, "replay/inserts": 21280.0, "replay/samples": 21280.0, "replay/insert_wait_avg": 1.3876678352069138e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.086683280485913e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1880692409978032e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4591088294983, "timer/env.step_count": 2660.0, "timer/env.step_total": 237.81603002548218, "timer/env.step_frac": 0.23770689669037898, "timer/env.step_avg": 0.08940452256597074, "timer/env.step_min": 0.02279353141784668, "timer/env.step_max": 3.456669807434082, "timer/replay._sample_count": 21280.0, "timer/replay._sample_total": 10.733060598373413, "timer/replay._sample_frac": 0.010728135216771342, "timer/replay._sample_avg": 0.0005043731484198033, "timer/replay._sample_min": 0.0004172325134277344, "timer/replay._sample_max": 0.010605096817016602, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3534.0, "timer/agent.policy_total": 57.999828815460205, "timer/agent.policy_frac": 0.05797321280158861, "timer/agent.policy_avg": 0.01641194929696101, "timer/agent.policy_min": 0.009238958358764648, "timer/agent.policy_max": 0.12184023857116699, "timer/dataset_train_count": 1330.0, "timer/dataset_train_total": 0.14455389976501465, "timer/dataset_train_frac": 0.00014448756424851545, "timer/dataset_train_avg": 0.00010868714268046214, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0004031658172607422, "timer/agent.train_count": 1330.0, "timer/agent.train_total": 597.8134405612946, "timer/agent.train_frac": 0.5975391050821808, "timer/agent.train_avg": 0.4494837898957102, "timer/agent.train_min": 0.43407630920410156, "timer/agent.train_max": 2.720804452896118, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5254917144775391, "timer/agent.report_frac": 0.0005252505673043906, "timer/agent.report_avg": 0.26274585723876953, "timer/agent.report_min": 0.25874996185302734, "timer/agent.report_max": 0.2667417526245117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7882172803163284e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 21.269966942377817}
{"step": 990896, "time": 45461.74585723877, "episode/length": 173.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 991416, "time": 45482.194487810135, "episode/length": 244.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 991728, "time": 45495.46895933151, "episode/length": 170.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 991768, "time": 45498.24569749832, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 991928, "time": 45505.44661331177, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 991944, "time": 45507.57821393013, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 992096, "time": 45514.553166389465, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 992248, "time": 45521.107380628586, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 992400, "time": 45527.90723514557, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 992544, "time": 45534.24420285225, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 993088, "time": 45553.97782087326, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 993600, "time": 45572.66442298889, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 993856, "time": 45582.87465620041, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 994056, "time": 45590.891030311584, "episode/length": 285.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 994064, "time": 45593.120757341385, "episode/length": 226.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 994296, "time": 45602.22039651871, "episode/length": 274.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9890909090909091, "episode/intrinsic_return": 0.0}
{"step": 994536, "time": 45611.78375959396, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 995032, "time": 45629.930955410004, "episode/length": 387.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 995200, "time": 45637.56522870064, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 995384, "time": 45645.22917294502, "episode/length": 286.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 995480, "time": 45650.121758937836, "episode/length": 147.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 995504, "time": 45652.80743956566, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 995928, "time": 45668.31407499313, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 996600, "time": 45692.39411878586, "episode/length": 257.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 996688, "time": 45697.194680929184, "episode/length": 206.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 996728, "time": 45699.83155941963, "episode/length": 390.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769820971867008, "episode/intrinsic_return": 0.0}
{"step": 996872, "time": 45706.30990457535, "episode/length": 185.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 997280, "time": 45722.27315711975, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 997512, "time": 45731.55839967728, "episode/length": 79.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 997600, "time": 45736.36395597458, "episode/length": 261.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 997736, "time": 45742.211789131165, "episode/length": 316.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 997968, "time": 45751.74622416496, "episode/length": 159.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 998016, "time": 45754.91062569618, "episode/length": 176.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 998632, "time": 45776.75904750824, "episode/length": 237.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 998640, "time": 45778.86666035652, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 998880, "time": 45788.55749416351, "episode/length": 424.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976470588235294, "episode/intrinsic_return": 0.0}
{"step": 999248, "time": 45802.929174661636, "episode/length": 153.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 999296, "time": 45806.1096329689, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 999632, "time": 45820.71938204765, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 999920, "time": 45832.58420372009, "episode/length": 289.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 999984, "time": 45836.754134655, "episode/length": 167.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45860.84348773956, "eval_episode/length": 158.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 1000064, "time": 45863.112364053726, "eval_episode/length": 174.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 1000064, "time": 45865.56845879555, "eval_episode/length": 191.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.984375}
{"step": 1000064, "time": 45867.21444821358, "eval_episode/length": 193.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1000064, "time": 45867.22096157074, "eval_episode/length": 193.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1000064, "time": 45872.71887230873, "eval_episode/length": 246.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 1000064, "time": 45877.901153326035, "eval_episode/length": 168.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 1000064, "time": 45879.52751302719, "eval_episode/length": 329.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.990909090909091}
{"step": 1000136, "time": 45881.712218761444, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 1000296, "time": 45888.55692410469, "episode/length": 347.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1000800, "time": 45907.24784874916, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 1000984, "time": 45914.761499881744, "episode/length": 262.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 1001008, "time": 45917.31238770485, "episode/length": 171.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 1001472, "time": 45934.24952363968, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1001472, "time": 45934.25778508186, "episode/length": 277.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 1001568, "time": 45941.04994940758, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 1001656, "time": 45945.29766726494, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1002048, "time": 45960.163321495056, "episode/length": 265.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1002520, "time": 45977.30248093605, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1002584, "time": 45980.94583654404, "episode/length": 138.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 1002704, "time": 45986.89989042282, "episode/length": 237.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 1002760, "time": 45990.06077718735, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 1003584, "time": 46019.28414463997, "episode/length": 124.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 1003632, "time": 46022.63778877258, "episode/length": 246.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1003656, "time": 46024.83958721161, "episode/length": 260.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 1003880, "time": 46033.90876722336, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1004040, "time": 46040.814569950104, "episode/length": 159.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 1004280, "time": 46050.296805381775, "episode/length": 350.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 1004400, "time": 46056.09287047386, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1004696, "time": 46067.18638563156, "episode/length": 330.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969788519637462, "episode/intrinsic_return": 0.0}
{"step": 1005112, "time": 46082.487011671066, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1005192, "time": 46086.86682200432, "episode/length": 143.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 1005344, "time": 46093.69151711464, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 1005472, "time": 46099.42046022415, "episode/length": 198.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1005608, "time": 46105.352122306824, "episode/length": 252.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1005936, "time": 46118.21584057808, "episode/length": 206.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 1006024, "time": 46122.42769789696, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1006496, "time": 46139.81970191002, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 1006736, "time": 46149.40469646454, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 1007048, "time": 46161.26715922356, "episode/length": 293.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 1007160, "time": 46166.54839396477, "episode/length": 226.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1007200, "time": 46169.69542098045, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 1007352, "time": 46176.29364705086, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1007424, "time": 46180.4055621624, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1007592, "time": 46187.21782398224, "episode/length": 106.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 1008416, "time": 46218.225908994675, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 1008496, "time": 46222.49417734146, "episode/length": 166.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1008688, "time": 46230.385756492615, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1008696, "time": 46232.16148543358, "episode/length": 274.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 1008944, "time": 46242.269994974136, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 1009272, "time": 46254.40347313881, "episode/length": 405.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778325123152709, "episode/intrinsic_return": 0.0}
{"step": 1009656, "time": 46268.75256896019, "episode/length": 287.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 46301.48189783096, "eval_episode/length": 120.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9586776859504132}
{"step": 1010048, "time": 46303.20937538147, "eval_episode/length": 125.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 1010048, "time": 46306.638174533844, "eval_episode/length": 168.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1010048, "time": 46309.84404730797, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1010048, "time": 46312.244980335236, "eval_episode/length": 228.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 1010048, "time": 46314.078766822815, "eval_episode/length": 233.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9700854700854701}
{"step": 1010048, "time": 46317.34097933769, "eval_episode/length": 61.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9354838709677419}
{"step": 1010048, "time": 46319.34774470329, "eval_episode/length": 282.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9858657243816255}
{"step": 1010112, "time": 46321.49138092995, "episode/length": 104.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1010312, "time": 46329.449670791626, "episode/length": 360.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 1010536, "time": 46338.581112623215, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1010816, "time": 46349.788343667984, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1010816, "time": 46349.796696186066, "episode/length": 265.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1010960, "time": 46358.28211021423, "episode/length": 317.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.0}
{"step": 1010992, "time": 46360.83607792854, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1011224, "time": 46369.95011663437, "episode/length": 50.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 1011296, "time": 46374.29034972191, "episode/length": 349.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1011816, "time": 46392.90446972847, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1011912, "time": 46397.6594452858, "episode/length": 118.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 1012080, "time": 46405.071716070175, "episode/length": 97.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1012184, "time": 46409.86824607849, "episode/length": 258.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 1012480, "time": 46421.519491672516, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1012520, "time": 46424.18563747406, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1013232, "time": 46449.91335272789, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 1013321, "time": 46455.28681349754, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.48551042705563, "train/action_min": 0.0, "train/action_std": 3.2592426783649633, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03888903397089201, "train/actor_opt_grad_steps": 62530.0, "train/actor_opt_loss": -9.674744634552205, "train/adv_mag": 0.5147554656715257, "train/adv_max": 0.4450951248196, "train/adv_mean": 0.0018912083923949608, "train/adv_min": -0.4386957958869055, "train/adv_std": 0.05547086249852012, "train/cont_avg": 0.9950063718971631, "train/cont_loss_mean": 0.0001932349542681495, "train/cont_loss_std": 0.00592272586147901, "train/cont_neg_acc": 0.9921394806381658, "train/cont_neg_loss": 0.02027443263930647, "train/cont_pos_acc": 0.9999721549081464, "train/cont_pos_loss": 6.907943916682295e-05, "train/cont_pred": 0.9950097067981747, "train/cont_rate": 0.9950063718971631, "train/dyn_loss_mean": 13.180300557021553, "train/dyn_loss_std": 9.220135587327023, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8965835089379168, "train/extr_critic_critic_opt_grad_steps": 62530.0, "train/extr_critic_critic_opt_loss": 15635.957758477394, "train/extr_critic_mag": 9.308808110284467, "train/extr_critic_max": 9.308808110284467, "train/extr_critic_mean": 3.0609329642978964, "train/extr_critic_min": -0.15631030214593766, "train/extr_critic_std": 2.1191957157554357, "train/extr_return_normed_mag": 1.5156750484561243, "train/extr_return_normed_max": 1.5156750484561243, "train/extr_return_normed_mean": 0.4195930691475564, "train/extr_return_normed_min": -0.10969337334869601, "train/extr_return_normed_std": 0.32323454478953745, "train/extr_return_rate": 0.8848030727805821, "train/extr_return_raw_mag": 10.371699218208908, "train/extr_return_raw_max": 10.371699218208908, "train/extr_return_raw_mean": 3.073479613513811, "train/extr_return_raw_min": -0.4510558927101446, "train/extr_return_raw_std": 2.1522348637276507, "train/extr_reward_mag": 1.0431052099728415, "train/extr_reward_max": 1.0431052099728415, "train/extr_reward_mean": 0.045321393599535555, "train/extr_reward_min": -0.44807455725703677, "train/extr_reward_std": 0.19773944388044642, "train/image_loss_mean": 6.3331524835410695, "train/image_loss_std": 11.939306330173574, "train/model_loss_mean": 14.298835632648874, "train/model_loss_std": 15.69474214188596, "train/model_opt_grad_norm": 48.43237702389981, "train/model_opt_grad_steps": 62472.70921985816, "train/model_opt_loss": 18089.715106937056, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.7304964539007, "train/policy_entropy_mag": 2.5880015217666084, "train/policy_entropy_max": 2.5880015217666084, "train/policy_entropy_mean": 0.5081048299234809, "train/policy_entropy_min": 0.0793750137619093, "train/policy_entropy_std": 0.6578529557437761, "train/policy_logprob_mag": 7.4383838565637035, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5081798275734516, "train/policy_logprob_min": -7.4383838565637035, "train/policy_logprob_std": 1.0902248232077199, "train/policy_randomness_mag": 0.91345096564462, "train/policy_randomness_max": 0.91345096564462, "train/policy_randomness_mean": 0.17933871010516553, "train/policy_randomness_min": 0.028015896691181135, "train/policy_randomness_std": 0.23219322418490201, "train/post_ent_mag": 59.33939226299313, "train/post_ent_max": 59.33939226299313, "train/post_ent_mean": 42.47450259053115, "train/post_ent_min": 19.865152196681247, "train/post_ent_std": 7.707252167640848, "train/prior_ent_mag": 68.5692736037234, "train/prior_ent_max": 68.5692736037234, "train/prior_ent_mean": 55.724932136265096, "train/prior_ent_min": 40.64392181829358, "train/prior_ent_std": 4.491047424627534, "train/rep_loss_mean": 13.180300557021553, "train/rep_loss_std": 9.220135587327023, "train/reward_avg": 0.0317084993242372, "train/reward_loss_mean": 0.057309698815464126, "train/reward_loss_std": 0.24446011646419552, "train/reward_max_data": 1.0248227009536526, "train/reward_max_pred": 1.0164499223654997, "train/reward_neg_acc": 0.9917955060377188, "train/reward_neg_loss": 0.028829360420399523, "train/reward_pos_acc": 0.9752620568512179, "train/reward_pos_loss": 0.8148405365910091, "train/reward_pred": 0.030969472760532763, "train/reward_rate": 0.036084330673758866, "train_stats/sum_log_reward": 8.664356647151532, "train_stats/max_log_achievement_collect_coal": 1.0495049504950495, "train_stats/max_log_achievement_collect_drink": 4.0594059405940595, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.1287128712871286, "train_stats/max_log_achievement_collect_stone": 14.663366336633663, "train_stats/max_log_achievement_collect_wood": 8.386138613861386, "train_stats/max_log_achievement_defeat_skeleton": 0.019801980198019802, "train_stats/max_log_achievement_defeat_zombie": 0.5841584158415841, "train_stats/max_log_achievement_eat_cow": 0.06930693069306931, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009900990099009901, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7623762376237624, "train_stats/max_log_achievement_make_wood_sword": 0.019801980198019802, "train_stats/max_log_achievement_place_furnace": 2.1683168316831685, "train_stats/max_log_achievement_place_plant": 1.108910891089109, "train_stats/max_log_achievement_place_stone": 3.118811881188119, "train_stats/max_log_achievement_place_table": 2.4554455445544554, "train_stats/max_log_achievement_wake_up": 1.5148514851485149, "train_stats/mean_log_entropy": 0.5159849244179112, "eval_stats/sum_log_reward": 8.850000232458115, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 9.625, "eval_stats/max_log_achievement_collect_wood": 6.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.9375, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.9375, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 4.7431326493097e-06, "report/cont_loss_std": 0.00011391405860194936, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004795961722265929, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0041321729659103e-06, "report/cont_pred": 0.9921903014183044, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.830833435058594, "report/dyn_loss_std": 9.533020973205566, "report/image_loss_mean": 6.620536804199219, "report/image_loss_std": 13.251773834228516, "report/model_loss_mean": 14.393613815307617, "report/model_loss_std": 17.169719696044922, "report/post_ent_mag": 61.361595153808594, "report/post_ent_max": 61.361595153808594, "report/post_ent_mean": 42.7059326171875, "report/post_ent_min": 19.0574951171875, "report/post_ent_std": 8.152356147766113, "report/prior_ent_mag": 68.7931137084961, "report/prior_ent_max": 68.7931137084961, "report/prior_ent_mean": 55.902061462402344, "report/prior_ent_min": 40.65473937988281, "report/prior_ent_std": 4.94205904006958, "report/rep_loss_mean": 12.830833435058594, "report/rep_loss_std": 9.533020973205566, "report/reward_avg": 0.03251953050494194, "report/reward_loss_mean": 0.07457304745912552, "report/reward_loss_std": 0.2863653600215912, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.102670669555664, "report/reward_neg_acc": 0.9918616414070129, "report/reward_neg_loss": 0.045250218361616135, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7776058316230774, "report/reward_pred": 0.03314667567610741, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.859772954863729e-06, "eval/cont_loss_std": 0.00014509071479551494, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002477762463968247, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.672744125855388e-06, "eval/cont_pred": 0.9951138496398926, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.895816802978516, "eval/dyn_loss_std": 10.034385681152344, "eval/image_loss_mean": 12.480071067810059, "eval/image_loss_std": 18.15423011779785, "eval/model_loss_mean": 23.979591369628906, "eval/model_loss_std": 21.99325180053711, "eval/post_ent_mag": 59.97553253173828, "eval/post_ent_max": 59.97553253173828, "eval/post_ent_mean": 40.143592834472656, "eval/post_ent_min": 18.4932804107666, "eval/post_ent_std": 7.715368747711182, "eval/prior_ent_mag": 68.7931137084961, "eval/prior_ent_max": 68.7931137084961, "eval/prior_ent_mean": 56.943138122558594, "eval/prior_ent_min": 45.20176696777344, "eval/prior_ent_std": 4.16882848739624, "eval/rep_loss_mean": 18.895816802978516, "eval/rep_loss_std": 10.034385681152344, "eval/reward_avg": 0.04521484300494194, "eval/reward_loss_mean": 0.16202545166015625, "eval/reward_loss_std": 0.7589108943939209, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017626285552979, "eval/reward_neg_acc": 0.9773663282394409, "eval/reward_neg_loss": 0.06574644148349762, "eval/reward_pos_acc": 0.826923131942749, "eval/reward_pos_loss": 1.9617024660110474, "eval/reward_pred": 0.03969138115644455, "eval/reward_rate": 0.05078125, "replay/size": 1000000.0, "replay/inserts": 22624.0, "replay/samples": 22624.0, "replay/insert_wait_avg": 1.3633192512911483e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.059041864969774e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.145906588381694e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1877729892731, "timer/env.step_count": 2828.0, "timer/env.step_total": 239.4279556274414, "timer/env.step_frac": 0.23938300596483023, "timer/env.step_avg": 0.08466335064619569, "timer/env.step_min": 0.02293086051940918, "timer/env.step_max": 3.636726140975952, "timer/replay._sample_count": 22624.0, "timer/replay._sample_total": 11.581461906433105, "timer/replay._sample_frac": 0.011579287628981359, "timer/replay._sample_avg": 0.0005119104449448862, "timer/replay._sample_min": 0.0003955364227294922, "timer/replay._sample_max": 0.009949207305908203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3441.0, "timer/agent.policy_total": 56.13121485710144, "timer/agent.policy_frac": 0.05612067690983805, "timer/agent.policy_avg": 0.016312471623685394, "timer/agent.policy_min": 0.009268760681152344, "timer/agent.policy_max": 0.22385859489440918, "timer/dataset_train_count": 1414.0, "timer/dataset_train_total": 0.15684723854064941, "timer/dataset_train_frac": 0.00015681779239500021, "timer/dataset_train_avg": 0.00011092449684628671, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0002830028533935547, "timer/agent.train_count": 1414.0, "timer/agent.train_total": 634.8312854766846, "timer/agent.train_frac": 0.6347121036876473, "timer/agent.train_avg": 0.4489613051461701, "timer/agent.train_min": 0.4352304935455322, "timer/agent.train_max": 1.677199125289917, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4817066192626953, "timer/agent.report_frac": 0.00048161618475200214, "timer/agent.report_avg": 0.24085330963134766, "timer/agent.report_min": 0.23485064506530762, "timer/agent.report_max": 0.2468559741973877, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.981590270996094e-05, "timer/dataset_eval_frac": 3.980842776248172e-08, "timer/dataset_eval_avg": 3.981590270996094e-05, "timer/dataset_eval_min": 3.981590270996094e-05, "timer/dataset_eval_max": 3.981590270996094e-05, "fps": 22.61944437824695}
{"step": 1013464, "time": 46459.896543741226, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 1013648, "time": 46467.81455492973, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1013752, "time": 46472.62677669525, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9778481012658228, "episode/intrinsic_return": 0.0}
{"step": 1013832, "time": 46477.0968978405, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1014344, "time": 46495.841870069504, "episode/length": 227.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1014640, "time": 46507.51669573784, "episode/length": 123.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 1014728, "time": 46511.83316373825, "episode/length": 363.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1015072, "time": 46525.132199048996, "episode/length": 200.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 1015208, "time": 46531.41646695137, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 1015464, "time": 46541.52821779251, "episode/length": 139.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1015640, "time": 46548.92112970352, "episode/length": 431.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1015696, "time": 46552.53243494034, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1015712, "time": 46554.616418361664, "episode/length": 133.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1016000, "time": 46567.543628931046, "episode/length": 280.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 1016464, "time": 46584.85749530792, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1016680, "time": 46593.33491873741, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 1016976, "time": 46605.18066763878, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1016992, "time": 46607.3258395195, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1017280, "time": 46618.441531419754, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1017392, "time": 46623.94707584381, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1017424, "time": 46626.75442481041, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 1017808, "time": 46640.98216056824, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.0}
{"step": 1018032, "time": 46650.04734826088, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1018632, "time": 46671.45460796356, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1018664, "time": 46674.1404106617, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1018856, "time": 46682.01065039635, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 1018864, "time": 46684.06345367432, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1019200, "time": 46697.027163505554, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1019456, "time": 46707.26420044899, "episode/length": 205.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 1019568, "time": 46712.518112659454, "episode/length": 323.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 1019600, "time": 46715.20620059967, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
