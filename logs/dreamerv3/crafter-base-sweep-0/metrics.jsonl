{"step": 1136, "time": 196.9844264984131, "episode/length": 141.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 1232, "time": 198.83352875709534, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 1240, "time": 200.2610731124878, "episode/length": 154.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1280, "time": 201.75394415855408, "episode/length": 159.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 1336, "time": 203.36823201179504, "episode/length": 166.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1336, "time": 203.3760302066803, "episode/length": 166.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1344, "time": 206.1471071243286, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1424, "time": 207.87948489189148, "episode/length": 177.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1536, "time": 209.5788869857788, "episode/length": 49.0, "episode/score": -0.8999999985098839, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 224.9980251789093, "eval_episode/length": 64.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 1560, "time": 228.9727566242218, "eval_episode/length": 143.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 1560, "time": 231.2299451828003, "eval_episode/length": 164.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 1560, "time": 233.0378773212433, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 1560, "time": 234.62304139137268, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1560, "time": 236.19688630104065, "eval_episode/length": 190.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 1560, "time": 237.65942311286926, "train_stats/sum_log_reward": 1.0999999509917364, "train_stats/max_log_achievement_collect_sapling": 0.7777777777777778, "train_stats/max_log_achievement_place_plant": 0.4444444444444444, "train_stats/max_log_achievement_wake_up": 1.5555555555555556, "train_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/sum_log_reward": 1.433333287636439, "eval_stats/max_log_achievement_collect_sapling": 0.8333333333333334, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.6666666666666666, "eval_stats/max_log_achievement_wake_up": 1.6666666666666667}
{"step": 1560, "time": 273.2250084877014, "eval_episode/length": 122.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.991869918699187}
{"step": 1560, "time": 275.990483045578, "eval_episode/length": 140.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 1560, "time": 279.15217757225037, "eval_episode/length": 159.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.99375}
{"step": 1560, "time": 281.2315196990967, "eval_episode/length": 42.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 1560, "time": 283.3768093585968, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 1560, "time": 285.7385792732239, "eval_episode/length": 193.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 1560, "time": 287.95240092277527, "eval_episode/length": 206.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 1560, "time": 289.7975072860718, "eval_episode/length": 211.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 1561, "time": 406.6393084526062, "eval_stats/sum_log_reward": 1.849999949336052, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_wood": 1.125, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/max_log_achievement_collect_drink": 3.3333333333333335, "eval_stats/max_log_achievement_place_table": 0.25, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.3602294921875, "train/action_min": 0.0, "train/action_std": 4.852486610412598, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00035643132287077606, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.2871170043945312, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.998046875, "train/cont_loss_mean": 0.6364500522613525, "train/cont_loss_std": 0.2657160460948944, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 1.4890159368515015, "train/cont_pos_acc": 0.5978473424911499, "train/cont_pos_loss": 0.6347815990447998, "train/cont_pred": 0.5482062697410583, "train/cont_rate": 0.998046875, "train/dyn_loss_mean": 10.878183364868164, "train/dyn_loss_std": 0.5566738843917847, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 8.039335250854492, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 32844.1796875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3676.62841796875, "train/image_loss_std": 172.21826171875, "train/model_loss_mean": 3689.3330078125, "train/model_loss_std": 172.0639190673828, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36893332.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7775766849517822, "train/policy_entropy_max": 2.7775766849517822, "train/policy_entropy_mean": 2.5720155239105225, "train/policy_entropy_min": 1.8899211883544922, "train/policy_entropy_std": 0.08297083526849747, "train/policy_logprob_mag": 5.885035991668701, "train/policy_logprob_max": -0.6492133736610413, "train/policy_logprob_mean": -2.582157850265503, "train/policy_logprob_min": -5.885035991668701, "train/policy_logprob_std": 0.6839210391044617, "train/policy_randomness_mag": 0.9803626537322998, "train/policy_randomness_max": 0.9803626537322998, "train/policy_randomness_mean": 0.9078086018562317, "train/policy_randomness_min": 0.6670592427253723, "train/policy_randomness_std": 0.029285063967108727, "train/post_ent_mag": 106.2117691040039, "train/post_ent_max": 106.2117691040039, "train/post_ent_mean": 105.60668182373047, "train/post_ent_min": 104.92659759521484, "train/post_ent_std": 0.2555607259273529, "train/prior_ent_mag": 106.33723449707031, "train/prior_ent_max": 106.33723449707031, "train/prior_ent_mean": 105.49668884277344, "train/prior_ent_min": 104.62425231933594, "train/prior_ent_std": 0.2947623133659363, "train/rep_loss_mean": 10.878183364868164, "train/rep_loss_std": 0.5566738843917847, "train/reward_avg": 0.0087890625, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.548376738166553e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.01171875, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.6572310924530029, "report/cont_loss_std": 0.2796271741390228, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.0936784744262695, "report/cont_pos_acc": 0.611545979976654, "report/cont_pos_loss": 0.6563770174980164, "report/cont_pred": 0.538060188293457, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 10.840265274047852, "report/dyn_loss_std": 0.5301513075828552, "report/image_loss_mean": 3674.8876953125, "report/image_loss_std": 169.2667236328125, "report/model_loss_mean": 3687.59033203125, "report/model_loss_std": 169.11767578125, "report/post_ent_mag": 106.31381225585938, "report/post_ent_max": 106.31381225585938, "report/post_ent_mean": 105.6275634765625, "report/post_ent_min": 104.9720687866211, "report/post_ent_std": 0.2569613754749298, "report/prior_ent_mag": 106.28387451171875, "report/prior_ent_max": 106.28387451171875, "report/prior_ent_mean": 105.55615234375, "report/prior_ent_min": 104.60894012451172, "report/prior_ent_std": 0.28039151430130005, "report/rep_loss_mean": 10.840265274047852, "report/rep_loss_std": 0.5301513075828552, "report/reward_avg": 0.0087890625, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.548376738166553e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.01171875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.6431738138198853, "eval/cont_loss_std": 0.2832270562648773, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 0.9809492230415344, "eval/cont_pos_acc": 0.6291584968566895, "eval/cont_pos_loss": 0.642512857913971, "eval/cont_pred": 0.5460641980171204, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.873766899108887, "eval/dyn_loss_std": 0.5412037968635559, "eval/image_loss_mean": 3654.705078125, "eval/image_loss_std": 174.5795135498047, "eval/model_loss_mean": 3667.41357421875, "eval/model_loss_std": 174.4802703857422, "eval/post_ent_mag": 106.16776275634766, "eval/post_ent_max": 106.16776275634766, "eval/post_ent_mean": 105.60194396972656, "eval/post_ent_min": 104.93168640136719, "eval/post_ent_std": 0.2601749897003174, "eval/prior_ent_mag": 106.37582397460938, "eval/prior_ent_max": 106.37582397460938, "eval/prior_ent_mean": 105.53836059570312, "eval/prior_ent_min": 104.5105209350586, "eval/prior_ent_std": 0.2995826005935669, "eval/rep_loss_mean": 10.873766899108887, "eval/rep_loss_std": 0.5412037968635559, "eval/reward_avg": 0.01767578162252903, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541263103485107, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0205078125, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.823214167339574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.961477552141462e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2752.0, "eval_replay/inserts": 2752.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.6936209312705108e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0664973940168108e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 224.3227767944336, "timer/env.step_count": 196.0, "timer/env.step_total": 28.45294165611267, "timer/env.step_frac": 0.12683928962856308, "timer/env.step_avg": 0.14516806967404425, "timer/env.step_min": 0.020792245864868164, "timer/env.step_max": 11.28719687461853, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.08526897430419922, "timer/replay._sample_frac": 0.0003801173270173032, "timer/replay._sample_avg": 0.0007613301277160645, "timer/replay._sample_min": 0.00037598609924316406, "timer/replay._sample_max": 0.00311279296875, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.861213684082031, "timer/agent.save_frac": 0.03950206845113338, "timer/agent.save_avg": 8.861213684082031, "timer/agent.save_min": 8.861213684082031, "timer/agent.save_max": 8.861213684082031, "timer/agent.policy_count": 213.0, "timer/agent.policy_total": 18.71310520172119, "timer/agent.policy_frac": 0.08342044204842218, "timer/agent.policy_avg": 0.08785495399869105, "timer/agent.policy_min": 0.010198593139648438, "timer/agent.policy_max": 12.368553876876831, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.9577484130859375e-05, "timer/dataset_train_frac": 1.7643096566661912e-07, "timer/dataset_train_avg": 3.9577484130859375e-05, "timer/dataset_train_min": 3.9577484130859375e-05, "timer/dataset_train_max": 3.9577484130859375e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 90.633455991745, "timer/agent.train_frac": 0.4040314465026451, "timer/agent.train_avg": 90.633455991745, "timer/agent.train_min": 90.633455991745, "timer/agent.train_max": 90.633455991745, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.87177276611328, "timer/agent.report_frac": 0.106417070558952, "timer/agent.report_avg": 11.93588638305664, "timer/agent.report_min": 0.24421977996826172, "timer/agent.report_max": 23.62755298614502, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 1.7855663995175908e-07, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05}
{"step": 2160, "time": 426.67366456985474, "episode/length": 101.0, "episode/score": -0.8999999761581421, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 2576, "time": 442.413635969162, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 2600, "time": 445.0754714012146, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 2824, "time": 454.87257862091064, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 2880, "time": 458.7721016407013, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 2896, "time": 460.93407797813416, "episode/length": 206.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 2912, "time": 463.08523511886597, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 3008, "time": 467.94213819503784, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 3680, "time": 492.17476630210876, "episode/length": 189.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 3744, "time": 495.846905708313, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 4056, "time": 507.57700657844543, "episode/length": 181.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 4224, "time": 515.1643867492676, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 4272, "time": 518.6356213092804, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 4400, "time": 524.6042149066925, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 4696, "time": 535.8786218166351, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 4768, "time": 540.0507147312164, "episode/length": 231.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 5016, "time": 549.8155844211578, "episode/length": 166.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 5032, "time": 551.9990599155426, "episode/length": 160.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 5376, "time": 565.3286299705505, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 5552, "time": 572.9462339878082, "episode/length": 159.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 5896, "time": 586.0102207660675, "episode/length": 229.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 5920, "time": 588.6264514923096, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 5952, "time": 591.7760758399963, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 6312, "time": 606.0079464912415, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 6464, "time": 612.9534401893616, "episode/length": 180.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 6656, "time": 621.0546531677246, "episode/length": 235.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 7048, "time": 635.7006847858429, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 7184, "time": 642.1808142662048, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 7240, "time": 645.3752474784851, "episode/length": 232.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 7568, "time": 658.3683624267578, "episode/length": 251.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 7880, "time": 670.2482130527496, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 8008, "time": 676.1998884677887, "episode/length": 260.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 8120, "time": 681.5365242958069, "episode/length": 225.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 8440, "time": 695.0819857120514, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 8504, "time": 698.9198958873749, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 8840, "time": 711.8211560249329, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 8896, "time": 715.4804680347443, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 9256, "time": 728.9680047035217, "episode/length": 210.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 9528, "time": 739.6438789367676, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 9920, "time": 754.6007704734802, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 9976, "time": 757.7550280094147, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 10040, "time": 761.6056492328644, "episode/length": 149.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 780.043524980545, "eval_episode/length": 44.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9111111111111111}
{"step": 10088, "time": 783.2515349388123, "eval_episode/length": 68.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 10088, "time": 786.9562306404114, "eval_episode/length": 117.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9576271186440678}
{"step": 10088, "time": 790.2243318557739, "eval_episode/length": 150.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 10088, "time": 793.5162055492401, "eval_episode/length": 190.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 10088, "time": 795.4191951751709, "eval_episode/length": 151.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 10088, "time": 795.4275770187378, "eval_episode/length": 196.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 10088, "time": 799.6221792697906, "eval_episode/length": 215.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 10184, "time": 802.8062524795532, "episode/length": 271.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 10656, "time": 820.4565033912659, "episode/length": 140.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 10728, "time": 824.2621059417725, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 10832, "time": 829.6315786838531, "episode/length": 338.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 10856, "time": 831.764518737793, "episode/length": 244.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 11264, "time": 847.205724477768, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 11312, "time": 850.516998052597, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 11952, "time": 873.4568998813629, "episode/length": 246.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 12088, "time": 879.525533914566, "episode/length": 178.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 12128, "time": 882.6863486766815, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 12224, "time": 887.4971935749054, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 12328, "time": 892.4242579936981, "episode/length": 267.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 12520, "time": 900.3742589950562, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 12544, "time": 903.0079090595245, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 12608, "time": 906.6569724082947, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 13024, "time": 922.3818335533142, "episode/length": 219.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 13656, "time": 945.0344512462616, "episode/length": 141.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 13800, "time": 951.3241934776306, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 14024, "time": 960.330992937088, "episode/length": 258.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9884169884169884, "episode/intrinsic_return": 0.0}
{"step": 14048, "time": 962.9889359474182, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 14368, "time": 975.5381283760071, "episode/length": 227.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 14392, "time": 978.1568183898926, "episode/length": 222.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9865470852017937, "episode/intrinsic_return": 0.0}
{"step": 14544, "time": 985.6672196388245, "episode/length": 301.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 14800, "time": 995.7458808422089, "episode/length": 221.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 14920, "time": 1001.3200781345367, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 15104, "time": 1009.2906060218811, "episode/length": 131.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 15112, "time": 1010.9774634838104, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 15512, "time": 1025.9391210079193, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 16032, "time": 1045.354944229126, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 16040, "time": 1047.0235080718994, "episode/length": 139.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 16080, "time": 1050.1745615005493, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 16192, "time": 1055.5169503688812, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 16200, "time": 1057.1658585071564, "episode/length": 228.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 16416, "time": 1067.5455696582794, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 16456, "time": 1070.319257259369, "episode/length": 168.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 16760, "time": 1082.1111617088318, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 17168, "time": 1097.6942248344421, "episode/length": 135.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 17312, "time": 1104.1777036190033, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 17408, "time": 1109.00563788414, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 17552, "time": 1115.3461668491364, "episode/length": 188.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 17592, "time": 1118.0199599266052, "episode/length": 146.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 17896, "time": 1129.8324184417725, "episode/length": 211.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 1152.2564465999603, "episode/length": 216.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 18520, "time": 1154.938993692398, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 18528, "time": 1157.4594807624817, "episode/length": 258.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9922779922779923, "episode/intrinsic_return": 0.0}
{"step": 18776, "time": 1167.151306629181, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 19176, "time": 1182.3579268455505, "episode/length": 202.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 19240, "time": 1186.1107470989227, "episode/length": 258.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9884169884169884, "episode/intrinsic_return": 0.0}
{"step": 19608, "time": 1200.0292677879333, "episode/length": 251.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 19904, "time": 1211.8881978988647, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1236.3457527160645, "eval_episode/length": 94.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 20072, "time": 1239.2511241436005, "eval_episode/length": 122.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.959349593495935}
{"step": 20072, "time": 1241.3074970245361, "eval_episode/length": 132.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9624060150375939}
{"step": 20072, "time": 1244.1399686336517, "eval_episode/length": 160.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 20072, "time": 1246.597328901291, "eval_episode/length": 179.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 20072, "time": 1249.1189517974854, "eval_episode/length": 201.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 20072, "time": 1251.485880613327, "eval_episode/length": 217.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9678899082568807}
{"step": 20072, "time": 1253.3405730724335, "eval_episode/length": 225.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 20104, "time": 1254.4225492477417, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 20176, "time": 1258.6696524620056, "episode/length": 209.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 20488, "time": 1270.514330148697, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 20512, "time": 1273.177731513977, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 20608, "time": 1277.9401183128357, "episode/length": 338.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 20800, "time": 1285.8679053783417, "episode/length": 252.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 20920, "time": 1291.329999446869, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 21400, "time": 1309.1375186443329, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 21416, "time": 1311.3182196617126, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 21688, "time": 1322.1476347446442, "episode/length": 134.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 21848, "time": 1329.1964933872223, "episode/length": 242.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 21960, "time": 1334.563146352768, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 22192, "time": 1344.1748082637787, "episode/length": 212.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 22208, "time": 1346.317295074463, "episode/length": 44.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 22368, "time": 1353.1906554698944, "episode/length": 120.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 22464, "time": 1358.0672688484192, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 22488, "time": 1360.2011551856995, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 22864, "time": 1374.5737845897675, "episode/length": 180.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 23065, "time": 1383.5785615444183, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.961307810313666, "train/action_min": 0.0, "train/action_std": 2.0386419754419753, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008595174099857321, "train/actor_opt_grad_steps": 675.0, "train/actor_opt_loss": 172.1895276808472, "train/adv_mag": 1.8970652857600754, "train/adv_max": 1.874208527269648, "train/adv_mean": 0.023299758793197536, "train/adv_min": -0.4579202546041767, "train/adv_std": 0.13434601341650199, "train/cont_avg": 0.9948912663246269, "train/cont_loss_mean": 0.0274201230729805, "train/cont_loss_std": 0.2555805565928345, "train/cont_neg_acc": 0.035966004175481514, "train/cont_neg_loss": 3.455584678187299, "train/cont_pos_acc": 0.9966089236202524, "train/cont_pos_loss": 0.009985486291776369, "train/cont_pred": 0.9913678262660752, "train/cont_rate": 0.9948912663246269, "train/dyn_loss_mean": 4.93235644653662, "train/dyn_loss_std": 7.529162682481666, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.159456322887051, "train/extr_critic_critic_opt_grad_steps": 675.0, "train/extr_critic_critic_opt_loss": 20254.484433302237, "train/extr_critic_mag": 0.25499032860371607, "train/extr_critic_max": 0.2549903268244729, "train/extr_critic_mean": 0.08729782398111825, "train/extr_critic_min": -0.012620644782906148, "train/extr_critic_std": 0.0649553514572417, "train/extr_return_normed_mag": 2.144102411634438, "train/extr_return_normed_max": 2.13484583712736, "train/extr_return_normed_mean": 0.16151665859159595, "train/extr_return_normed_min": -0.38607688935317497, "train/extr_return_normed_std": 0.17240215888284224, "train/extr_return_rate": 0.03034534494519849, "train/extr_return_raw_mag": 2.0996792078687574, "train/extr_return_raw_max": 2.083926758020004, "train/extr_return_raw_mean": 0.11059758031456791, "train/extr_return_raw_min": -0.4369959671677996, "train/extr_return_raw_std": 0.17240215761096142, "train/extr_reward_mag": 0.5690644036478071, "train/extr_reward_max": 0.5690008081606964, "train/extr_reward_mean": 0.006044007082864618, "train/extr_reward_min": -0.0812061936108034, "train/extr_reward_std": 0.034604917724933064, "train/image_loss_mean": 88.57860902530044, "train/image_loss_std": 48.142395233040425, "train/model_loss_mean": 91.87352139202517, "train/model_loss_std": 49.62005725547449, "train/model_opt_grad_norm": 296.19430163390655, "train/model_opt_grad_steps": 665.0, "train/model_opt_loss": 1238.8664824072994, "train/model_opt_model_opt_grad_overflow": 0.007462686567164179, "train/model_opt_model_opt_grad_scale": 12.170592350746269, "train/policy_entropy_mag": 1.0901438623333155, "train/policy_entropy_max": 1.0901438623333155, "train/policy_entropy_mean": 0.8988482521207475, "train/policy_entropy_min": 0.7562539067619772, "train/policy_entropy_std": 0.06507265556485517, "train/policy_logprob_mag": 6.7333176563035195, "train/policy_logprob_max": -0.4048477329605662, "train/policy_logprob_mean": -0.8985260050577014, "train/policy_logprob_min": -6.7333176563035195, "train/policy_logprob_std": 0.7495831993978415, "train/policy_randomness_mag": 0.38477294447261895, "train/policy_randomness_max": 0.38477294447261895, "train/policy_randomness_mean": 0.31725399148886774, "train/policy_randomness_min": 0.2669244409580506, "train/policy_randomness_std": 0.022967791248203268, "train/post_ent_mag": 50.56198384868565, "train/post_ent_max": 50.56198384868565, "train/post_ent_mean": 31.14911611756282, "train/post_ent_min": 16.24392293104485, "train/post_ent_std": 6.449802609744356, "train/prior_ent_mag": 55.73281359316698, "train/prior_ent_max": 55.73281359316698, "train/prior_ent_mean": 36.732157621810686, "train/prior_ent_min": 21.036044156373435, "train/prior_ent_std": 6.208709439123744, "train/rep_loss_mean": 4.93235644653662, "train/rep_loss_std": 7.529162682481666, "train/reward_avg": 0.008273087624363157, "train/reward_loss_mean": 0.3080763502129868, "train/reward_loss_std": 0.6618408737738697, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.6973210083904551, "train/reward_neg_acc": 0.9966458473632585, "train/reward_neg_loss": 0.26960671106492407, "train/reward_pos_acc": 0.4304930802935095, "train/reward_pos_loss": 3.2205327313337753, "train/reward_pred": 0.005943653320566987, "train/reward_rate": 0.012877506996268656, "train_stats/sum_log_reward": 1.0909090516242115, "train_stats/max_log_achievement_collect_drink": 7.181818181818182, "train_stats/max_log_achievement_collect_sapling": 11.690909090909091, "train_stats/max_log_achievement_collect_wood": 0.2818181818181818, "train_stats/max_log_achievement_place_plant": 0.3181818181818182, "train_stats/max_log_achievement_place_table": 0.045454545454545456, "train_stats/max_log_achievement_wake_up": 0.6545454545454545, "train_stats/mean_log_entropy": 0.9262756804850969, "train_stats/max_log_achievement_make_wood_sword": 0.013333333333333334, "train_stats/max_log_achievement_defeat_zombie": 0.2535211267605634, "train_stats/max_log_achievement_eat_cow": 0.2463768115942029, "eval_stats/sum_log_reward": 0.5375000154599547, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 14.4375, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.010369464755058289, "report/cont_loss_std": 0.15666519105434418, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.167309045791626, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.001910879509523511, "report/cont_pred": 0.997403621673584, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.92753791809082, "report/dyn_loss_std": 5.311349391937256, "report/image_loss_mean": 22.658843994140625, "report/image_loss_std": 13.849274635314941, "report/model_loss_mean": 26.293609619140625, "report/model_loss_std": 15.4183988571167, "report/post_ent_mag": 43.653812408447266, "report/post_ent_max": 43.653812408447266, "report/post_ent_mean": 30.672565460205078, "report/post_ent_min": 22.606502532958984, "report/post_ent_std": 2.778503894805908, "report/prior_ent_mag": 51.32285690307617, "report/prior_ent_max": 51.32285690307617, "report/prior_ent_mean": 35.53059768676758, "report/prior_ent_min": 26.443927764892578, "report/prior_ent_std": 3.6047780513763428, "report/rep_loss_mean": 5.92753791809082, "report/rep_loss_std": 5.311349391937256, "report/reward_avg": 0.0020507811568677425, "report/reward_loss_mean": 0.06787367165088654, "report/reward_loss_std": 0.4134180247783661, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9938538074493408, "report/reward_neg_acc": 0.9970559477806091, "report/reward_neg_loss": 0.06233534961938858, "report/reward_pos_acc": 0.800000011920929, "report/reward_pos_loss": 1.1965837478637695, "report/reward_pred": 0.0036875437945127487, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01128519419580698, "eval/cont_loss_std": 0.3091272711753845, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.89067554473877, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016279227565973997, "eval/cont_pred": 0.9984471797943115, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 10.626558303833008, "eval/dyn_loss_std": 8.830399513244629, "eval/image_loss_mean": 95.80845642089844, "eval/image_loss_std": 87.67523956298828, "eval/model_loss_mean": 102.31705474853516, "eval/model_loss_std": 90.18794250488281, "eval/post_ent_mag": 56.234130859375, "eval/post_ent_max": 56.234130859375, "eval/post_ent_mean": 32.628604888916016, "eval/post_ent_min": 13.916060447692871, "eval/post_ent_std": 9.19570541381836, "eval/prior_ent_mag": 61.74057388305664, "eval/prior_ent_max": 61.74057388305664, "eval/prior_ent_mean": 35.695987701416016, "eval/prior_ent_min": 16.620189666748047, "eval/prior_ent_std": 7.335495471954346, "eval/rep_loss_mean": 10.626558303833008, "eval/rep_loss_std": 8.830399513244629, "eval/reward_avg": 0.01308593712747097, "eval/reward_loss_mean": 0.12137412279844284, "eval/reward_loss_std": 0.77791827917099, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.993267297744751, "eval/reward_neg_acc": 0.9940477013587952, "eval/reward_neg_loss": 0.07442968338727951, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 3.078873634338379, "eval/reward_pred": 0.008550900965929031, "eval/reward_rate": 0.015625, "replay/size": 22561.0, "replay/inserts": 21504.0, "replay/samples": 21504.0, "replay/insert_wait_avg": 1.560453148115249e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.979232258739926e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6288.0, "eval_replay/inserts": 3536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.351150991690105e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.9303193092346, "timer/env.step_count": 2688.0, "timer/env.step_total": 252.07801127433777, "timer/env.step_frac": 0.2580306970640203, "timer/env.step_avg": 0.09377902205146495, "timer/env.step_min": 0.023011207580566406, "timer/env.step_max": 2.2029528617858887, "timer/replay._sample_count": 21504.0, "timer/replay._sample_total": 11.648366928100586, "timer/replay._sample_frac": 0.011923436807997609, "timer/replay._sample_avg": 0.0005416837299153919, "timer/replay._sample_min": 0.0003509521484375, "timer/replay._sample_max": 0.010245800018310547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3130.0, "timer/agent.policy_total": 53.76384115219116, "timer/agent.policy_frac": 0.05503344515932965, "timer/agent.policy_avg": 0.017176946055013152, "timer/agent.policy_min": 0.009634017944335938, "timer/agent.policy_max": 0.10212135314941406, "timer/dataset_train_count": 1344.0, "timer/dataset_train_total": 0.1516094207763672, "timer/dataset_train_frac": 0.00015518959518378628, "timer/dataset_train_avg": 0.00011280462855384463, "timer/dataset_train_min": 7.963180541992188e-05, "timer/dataset_train_max": 0.0005638599395751953, "timer/agent.train_count": 1344.0, "timer/agent.train_total": 603.9069583415985, "timer/agent.train_frac": 0.6181678942758246, "timer/agent.train_avg": 0.449335534480356, "timer/agent.train_min": 0.4372985363006592, "timer/agent.train_max": 1.4350790977478027, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4700331687927246, "timer/agent.report_frac": 0.00048113274765090153, "timer/agent.report_avg": 0.2350165843963623, "timer/agent.report_min": 0.2290942668914795, "timer/agent.report_max": 0.24093890190124512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.270252644241725e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.011549698768558}
{"step": 23152, "time": 1386.5184440612793, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 23176, "time": 1388.7763583660126, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 23648, "time": 1406.2987968921661, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 23800, "time": 1412.7971694469452, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 23832, "time": 1415.42822265625, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 23856, "time": 1418.0258572101593, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 23920, "time": 1421.8594906330109, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 24240, "time": 1434.145966053009, "episode/length": 171.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 25000, "time": 1461.9743444919586, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 25096, "time": 1466.7756032943726, "episode/length": 180.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 25224, "time": 1472.6573231220245, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 25288, "time": 1476.5413358211517, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 25312, "time": 1479.3153512477875, "episode/length": 266.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 25312, "time": 1479.324565410614, "episode/length": 181.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 25488, "time": 1488.4819259643555, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 26312, "time": 1517.4096748828888, "episode/length": 298.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 26368, "time": 1521.1813187599182, "episode/length": 134.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 26392, "time": 1523.3109498023987, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 26456, "time": 1526.9226360321045, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 26600, "time": 1533.2206208705902, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 26736, "time": 1539.6932909488678, "episode/length": 52.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 26784, "time": 1543.033153295517, "episode/length": 40.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 26800, "time": 1545.1461942195892, "episode/length": 185.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 26808, "time": 1546.7589037418365, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 26848, "time": 1549.9085068702698, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 27496, "time": 1572.832926750183, "episode/length": 111.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 27888, "time": 1587.7298383712769, "episode/length": 186.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 28048, "time": 1594.6593759059906, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 28048, "time": 1594.6685309410095, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 28120, "time": 1600.5001447200775, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 28400, "time": 1611.674329996109, "episode/length": 193.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 28408, "time": 1613.9800913333893, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 28480, "time": 1618.83789229393, "episode/length": 209.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 28560, "time": 1623.5955884456635, "episode/length": 83.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 28672, "time": 1629.5132899284363, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 29024, "time": 1642.9216830730438, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 29344, "time": 1655.0893051624298, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 29560, "time": 1663.715930223465, "episode/length": 179.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 29712, "time": 1670.5817787647247, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 29760, "time": 1673.7687847614288, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 29944, "time": 1681.1397547721863, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 30024, "time": 1685.3296246528625, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 30032, "time": 1687.5063769817352, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1704.2709658145905, "eval_episode/length": 36.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8918918918918919}
{"step": 30056, "time": 1710.3480939865112, "eval_episode/length": 146.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 30056, "time": 1713.0070161819458, "eval_episode/length": 170.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 30056, "time": 1715.9331002235413, "eval_episode/length": 181.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 30056, "time": 1718.7867813110352, "eval_episode/length": 161.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9567901234567902}
{"step": 30056, "time": 1720.3926310539246, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 30056, "time": 1722.1049149036407, "eval_episode/length": 204.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 30056, "time": 1723.9576518535614, "eval_episode/length": 209.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 30424, "time": 1736.1435005664825, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 30544, "time": 1741.966078042984, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 30664, "time": 1747.298084974289, "episode/length": 78.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 31128, "time": 1764.2765936851501, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 31160, "time": 1766.951658964157, "episode/length": 174.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 31296, "time": 1773.1445701122284, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 31352, "time": 1776.4923477172852, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 31864, "time": 1795.1829917430878, "episode/length": 179.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 32000, "time": 1801.4734070301056, "episode/length": 181.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 32032, "time": 1804.126178741455, "episode/length": 289.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 32040, "time": 1805.800078868866, "episode/length": 171.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 32464, "time": 1821.7727749347687, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 32496, "time": 1824.484623670578, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 32632, "time": 1830.4216957092285, "episode/length": 187.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 32848, "time": 1840.731278181076, "episode/length": 47.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 32872, "time": 1842.9125549793243, "episode/length": 189.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 33112, "time": 1852.5592138767242, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 33312, "time": 1861.659008026123, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 33320, "time": 1863.355484008789, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 33664, "time": 1876.8661572933197, "episode/length": 145.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 33864, "time": 1885.3874106407166, "episode/length": 227.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 34216, "time": 1898.6982116699219, "episode/length": 170.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 34224, "time": 1900.8111164569855, "episode/length": 168.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 34264, "time": 1903.9910554885864, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 34416, "time": 1910.8708956241608, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 34616, "time": 1919.4861972332, "episode/length": 162.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 34888, "time": 1930.2934257984161, "episode/length": 195.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 35064, "time": 1937.7231130599976, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 35368, "time": 1949.342736005783, "episode/length": 59.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 35528, "time": 1956.1942193508148, "episode/length": 232.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 35616, "time": 1960.9560425281525, "episode/length": 173.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 35768, "time": 1967.352588891983, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 35792, "time": 1969.9616973400116, "episode/length": 171.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 35936, "time": 1976.3113453388214, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 36128, "time": 1984.2868521213531, "episode/length": 232.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 36376, "time": 1993.885969877243, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 36800, "time": 2010.199303150177, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 36856, "time": 2013.469276189804, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 36928, "time": 2017.8120605945587, "episode/length": 194.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 36976, "time": 2021.2918021678925, "episode/length": 105.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 37064, "time": 2025.4615750312805, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 37496, "time": 2041.4027304649353, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 37528, "time": 2044.0655119419098, "episode/length": 90.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 37736, "time": 2052.553871154785, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 37760, "time": 2055.184807777405, "episode/length": 248.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 38072, "time": 2066.8807759284973, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 38368, "time": 2078.5609846115112, "episode/length": 173.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 38560, "time": 2086.6085793972015, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 38696, "time": 2092.4372475147247, "episode/length": 229.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 38760, "time": 2096.2302465438843, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 38912, "time": 2103.1440908908844, "episode/length": 172.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 39024, "time": 2108.4706625938416, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 39088, "time": 2112.193529367447, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 39464, "time": 2126.1795122623444, "episode/length": 173.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 39696, "time": 2135.7215921878815, "episode/length": 141.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 39704, "time": 2137.3527941703796, "episode/length": 76.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 39984, "time": 2148.721774816513, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 40000, "time": 2150.8109335899353, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2168.660491704941, "eval_episode/length": 40.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 40040, "time": 2170.750830888748, "eval_episode/length": 49.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.98}
{"step": 40040, "time": 2176.2656037807465, "eval_episode/length": 144.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 40040, "time": 2178.380635499954, "eval_episode/length": 155.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 40040, "time": 2180.365156173706, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 40040, "time": 2182.053118467331, "eval_episode/length": 167.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 40040, "time": 2184.6467406749725, "eval_episode/length": 190.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 40040, "time": 2186.3358256816864, "eval_episode/length": 191.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 40128, "time": 2189.4930970668793, "episode/length": 219.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 40208, "time": 2193.7469413280487, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 40384, "time": 2201.187326192856, "episode/length": 169.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 40472, "time": 2205.4499440193176, "episode/length": 60.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 40800, "time": 2218.272994995117, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 40896, "time": 2223.554716348648, "episode/length": 111.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 41104, "time": 2233.5399339199066, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 41488, "time": 2247.9514632225037, "episode/length": 169.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 41592, "time": 2252.800637483597, "episode/length": 172.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 41672, "time": 2257.012106180191, "episode/length": 246.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 41760, "time": 2261.838001728058, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 41880, "time": 2267.26784324646, "episode/length": 48.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 42048, "time": 2274.617961168289, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 42424, "time": 2288.5841286182404, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 42456, "time": 2291.2374589443207, "episode/length": 194.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 42992, "time": 2310.84383559227, "episode/length": 153.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 43008, "time": 2313.0988788604736, "episode/length": 176.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 43096, "time": 2317.4143714904785, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 43136, "time": 2320.560977935791, "episode/length": 343.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.997093023255814, "episode/intrinsic_return": 0.0}
{"step": 43328, "time": 2328.5813167095184, "episode/length": 108.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 43360, "time": 2331.3018548488617, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 43472, "time": 2336.536474466324, "episode/length": 59.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 43616, "time": 2342.8061883449554, "episode/length": 64.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 43624, "time": 2344.4401326179504, "episode/length": 243.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 43792, "time": 2351.9800906181335, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 44336, "time": 2371.504733324051, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 44568, "time": 2381.2756464481354, "episode/length": 178.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 44569, "time": 2383.900137424469, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.712328099492771, "train/action_min": 0.0, "train/action_std": 2.7035263999184567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03594068162588041, "train/actor_opt_grad_steps": 2015.0, "train/actor_opt_loss": 33.06210716791562, "train/adv_mag": 1.9095722152226007, "train/adv_max": 1.9066358564504937, "train/adv_mean": 0.02060128557070075, "train/adv_min": -0.6407907416126621, "train/adv_std": 0.14490151433135146, "train/cont_avg": 0.9947819496268657, "train/cont_loss_mean": 0.005584379901847569, "train/cont_loss_std": 0.0755170264691881, "train/cont_neg_acc": 0.7274313018615566, "train/cont_neg_loss": 0.7526600300543306, "train/cont_pos_acc": 0.9996846914291382, "train/cont_pos_loss": 0.0017043682506353624, "train/cont_pred": 0.9947644592221103, "train/cont_rate": 0.9947819496268657, "train/dyn_loss_mean": 6.3591746928086925, "train/dyn_loss_std": 5.844527760548378, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5546837475762438, "train/extr_critic_critic_opt_grad_steps": 2015.0, "train/extr_critic_critic_opt_loss": 17319.102947178173, "train/extr_critic_mag": 1.4797116695944943, "train/extr_critic_max": 1.4797116695944943, "train/extr_critic_mean": 0.35168326403181166, "train/extr_critic_min": -0.3739182806726712, "train/extr_critic_std": 0.587936060864534, "train/extr_return_normed_mag": 2.681602502047126, "train/extr_return_normed_max": 2.681602502047126, "train/extr_return_normed_mean": 0.39484487796452505, "train/extr_return_normed_min": -0.2892129197508208, "train/extr_return_normed_std": 0.372308269699118, "train/extr_return_rate": 0.35477157073345644, "train/extr_return_raw_mag": 4.599051005804717, "train/extr_return_raw_max": 4.599051005804717, "train/extr_return_raw_mean": 0.3881336158113693, "train/extr_return_raw_min": -0.8614939345575091, "train/extr_return_raw_std": 0.6922276756211893, "train/extr_reward_mag": 0.9963697061609866, "train/extr_reward_max": 0.9963697061609866, "train/extr_reward_mean": 0.012964452563006598, "train/extr_reward_min": -0.37160350849379353, "train/extr_reward_std": 0.09041676275543313, "train/image_loss_mean": 17.489233365699427, "train/image_loss_std": 14.271608523468473, "train/model_loss_mean": 21.392462524015514, "train/model_loss_std": 16.186610150693067, "train/model_opt_grad_norm": 142.25713806721703, "train/model_opt_grad_steps": 2005.0, "train/model_opt_loss": 596.2473046601708, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 29.296875, "train/policy_entropy_mag": 2.176274522026973, "train/policy_entropy_max": 2.176274522026973, "train/policy_entropy_mean": 0.30250891798467777, "train/policy_entropy_min": 0.07947491031529298, "train/policy_entropy_std": 0.32239602728566125, "train/policy_logprob_mag": 7.437797510801857, "train/policy_logprob_max": -0.009469877796442205, "train/policy_logprob_mean": -0.30262361700410273, "train/policy_logprob_min": -7.437797510801857, "train/policy_logprob_std": 0.9411450277513532, "train/policy_randomness_mag": 0.7681294061354736, "train/policy_randomness_max": 0.7681294061354736, "train/policy_randomness_mean": 0.10677237291611842, "train/policy_randomness_min": 0.028051155577622243, "train/policy_randomness_std": 0.11379164991094105, "train/post_ent_mag": 42.02813757711382, "train/post_ent_max": 42.02813757711382, "train/post_ent_mean": 30.286201889835187, "train/post_ent_min": 14.63144974210369, "train/post_ent_std": 4.027262596941706, "train/prior_ent_mag": 52.239955275806025, "train/prior_ent_max": 52.239955275806025, "train/prior_ent_mean": 36.82010804361372, "train/prior_ent_min": 18.565706580432494, "train/prior_ent_std": 4.893702003493238, "train/rep_loss_mean": 6.3591746928086925, "train/rep_loss_std": 5.844527760548378, "train/reward_avg": 0.00864039172997017, "train/reward_loss_mean": 0.08213992876959826, "train/reward_loss_std": 0.3981121353693862, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.9948124823285572, "train/reward_neg_acc": 0.995430390781431, "train/reward_neg_loss": 0.0626254451822545, "train/reward_pos_acc": 0.8304054214438396, "train/reward_pos_loss": 1.547914626883037, "train/reward_pred": 0.007795098473130267, "train/reward_rate": 0.01330019822761194, "train_stats/sum_log_reward": 2.3968749279156327, "train_stats/max_log_achievement_collect_drink": 0.34375, "train_stats/max_log_achievement_collect_sapling": 3.15625, "train_stats/max_log_achievement_collect_wood": 0.046875, "train_stats/max_log_achievement_defeat_zombie": 0.234375, "train_stats/max_log_achievement_eat_cow": 0.1484375, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.609375, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.1015625, "train_stats/mean_log_entropy": 0.23493943607900292, "eval_stats/sum_log_reward": 2.0999999344348907, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.066364923957735e-05, "report/cont_loss_std": 0.0002094369410770014, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00027772560133598745, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.96476417942904e-05, "report/cont_pred": 0.995049238204956, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.344029426574707, "report/dyn_loss_std": 5.8390302658081055, "report/image_loss_mean": 8.940288543701172, "report/image_loss_std": 6.780248641967773, "report/model_loss_mean": 12.199663162231445, "report/model_loss_std": 8.961320877075195, "report/post_ent_mag": 38.909950256347656, "report/post_ent_max": 38.909950256347656, "report/post_ent_mean": 31.09164810180664, "report/post_ent_min": 16.36134910583496, "report/post_ent_std": 4.03331184387207, "report/prior_ent_mag": 51.98436737060547, "report/prior_ent_max": 51.98436737060547, "report/prior_ent_mean": 36.82098388671875, "report/prior_ent_min": 18.179149627685547, "report/prior_ent_std": 4.782836437225342, "report/rep_loss_mean": 5.344029426574707, "report/rep_loss_std": 5.8390302658081055, "report/reward_avg": 0.01015624962747097, "report/reward_loss_mean": 0.052887286990880966, "report/reward_loss_std": 0.3023468852043152, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9996856451034546, "report/reward_neg_acc": 0.9940535426139832, "report/reward_neg_loss": 0.03152933344244957, "report/reward_pos_acc": 0.8000000715255737, "report/reward_pos_loss": 1.4895657300949097, "report/reward_pred": 0.0074745062738657, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 7.156685023801401e-05, "eval/cont_loss_std": 0.00012716908531729132, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.888480078894645e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.154991908464581e-05, "eval/cont_pred": 0.9989520311355591, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 11.682381629943848, "eval/dyn_loss_std": 8.648974418640137, "eval/image_loss_mean": 63.87334442138672, "eval/image_loss_std": 68.64620971679688, "eval/model_loss_mean": 70.96989440917969, "eval/model_loss_std": 71.02085876464844, "eval/post_ent_mag": 49.362640380859375, "eval/post_ent_max": 49.362640380859375, "eval/post_ent_mean": 30.486637115478516, "eval/post_ent_min": 14.322996139526367, "eval/post_ent_std": 6.718355178833008, "eval/prior_ent_mag": 58.03474807739258, "eval/prior_ent_max": 58.03474807739258, "eval/prior_ent_mean": 37.738868713378906, "eval/prior_ent_min": 17.521482467651367, "eval/prior_ent_std": 7.748246669769287, "eval/rep_loss_mean": 11.682381629943848, "eval/rep_loss_std": 8.648974418640137, "eval/reward_avg": 0.01523437537252903, "eval/reward_loss_mean": 0.08704957365989685, "eval/reward_loss_std": 0.6865938305854797, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017220973968506, "eval/reward_neg_acc": 0.9980139136314392, "eval/reward_neg_loss": 0.03139324113726616, "eval/reward_pos_acc": 0.5882353186607361, "eval/reward_pos_loss": 3.383868932723999, "eval/reward_pred": 0.00836915336549282, "eval/reward_rate": 0.0166015625, "replay/size": 44065.0, "replay/inserts": 21504.0, "replay/samples": 21504.0, "replay/insert_wait_avg": 1.4950166500750043e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0231687199501765e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9504.0, "eval_replay/inserts": 3216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2648194583494271e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.311315536499, "timer/env.step_count": 2688.0, "timer/env.step_total": 282.7046754360199, "timer/env.step_frac": 0.2826166924687804, "timer/env.step_avg": 0.10517287032590025, "timer/env.step_min": 0.023138046264648438, "timer/env.step_max": 3.650897979736328, "timer/replay._sample_count": 21504.0, "timer/replay._sample_total": 11.201475620269775, "timer/replay._sample_frac": 0.011197989512157088, "timer/replay._sample_avg": 0.0005209019540676049, "timer/replay._sample_min": 0.00036072731018066406, "timer/replay._sample_max": 0.011326313018798828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3090.0, "timer/agent.policy_total": 52.35268521308899, "timer/agent.policy_frac": 0.05233639208110984, "timer/agent.policy_avg": 0.016942616573815208, "timer/agent.policy_min": 0.009374618530273438, "timer/agent.policy_max": 0.12489581108093262, "timer/dataset_train_count": 1344.0, "timer/dataset_train_total": 0.14512300491333008, "timer/dataset_train_frac": 0.00014507783992775885, "timer/dataset_train_avg": 0.00010797842627479917, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.00043964385986328125, "timer/agent.train_count": 1344.0, "timer/agent.train_total": 600.1788468360901, "timer/agent.train_frac": 0.5999920599860403, "timer/agent.train_avg": 0.44656164199113846, "timer/agent.train_min": 0.43363118171691895, "timer/agent.train_max": 1.4283742904663086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712059497833252, "timer/agent.report_frac": 0.00047105930170409234, "timer/agent.report_avg": 0.2356029748916626, "timer/agent.report_min": 0.22905325889587402, "timer/agent.report_max": 0.24215269088745117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193814675831653e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 21.497058070821364}
{"step": 44680, "time": 2387.425862312317, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 44792, "time": 2392.7265889644623, "episode/length": 164.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 45168, "time": 2407.165722846985, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 45224, "time": 2411.0505032539368, "episode/length": 199.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 45264, "time": 2414.8001556396484, "episode/length": 237.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 45784, "time": 2433.4216804504395, "episode/length": 248.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 45824, "time": 2436.564176082611, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 45864, "time": 2439.4672062397003, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 46104, "time": 2449.132758617401, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 2455.539246559143, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 46464, "time": 2464.6121983528137, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 46792, "time": 2477.027863740921, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 46832, "time": 2480.1786694526672, "episode/length": 195.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 47152, "time": 2492.432715654373, "episode/length": 165.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 47272, "time": 2498.0512392520905, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 47272, "time": 2498.067640542984, "episode/length": 54.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 47512, "time": 2509.514122247696, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 47736, "time": 2518.6153869628906, "episode/length": 233.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 47768, "time": 2521.310245037079, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 47928, "time": 2528.358772754669, "episode/length": 210.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 48088, "time": 2535.197834968567, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 48104, "time": 2537.3657722473145, "episode/length": 103.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 48392, "time": 2548.5904517173767, "episode/length": 154.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 48568, "time": 2556.0360996723175, "episode/length": 161.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 48960, "time": 2570.9166643619537, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 49112, "time": 2577.465901851654, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 49200, "time": 2583.5528542995453, "episode/length": 210.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 49312, "time": 2589.0575098991394, "episode/length": 43.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 49472, "time": 2596.069699525833, "episode/length": 172.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 49496, "time": 2598.187129020691, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 49776, "time": 2609.3785679340363, "episode/length": 82.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.927710843373494, "episode/intrinsic_return": 0.0}
{"step": 49976, "time": 2617.5316257476807, "episode/length": 197.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2639.8489923477173, "eval_episode/length": 136.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9562043795620438}
{"step": 50024, "time": 2641.9386065006256, "eval_episode/length": 147.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 50024, "time": 2644.327053785324, "eval_episode/length": 164.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 50024, "time": 2646.1801381111145, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 50024, "time": 2648.7520847320557, "eval_episode/length": 191.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 50024, "time": 2651.8458123207092, "eval_episode/length": 222.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 50024, "time": 2655.7912526130676, "eval_episode/length": 276.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 50024, "time": 2657.69828081131, "eval_episode/length": 281.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9964539007092199}
{"step": 50096, "time": 2660.3580853939056, "episode/length": 190.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.0}
{"step": 50640, "time": 2680.4569234848022, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 50680, "time": 2683.1412670612335, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 50840, "time": 2690.160122871399, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 51072, "time": 2699.682246208191, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 51096, "time": 2701.846551656723, "episode/length": 395.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 51288, "time": 2709.953699827194, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 51528, "time": 2719.6137356758118, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 51712, "time": 2727.6481816768646, "episode/length": 279.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 51944, "time": 2736.7118055820465, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 52168, "time": 2746.0249593257904, "episode/length": 133.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 52272, "time": 2751.3430399894714, "episode/length": 178.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 52320, "time": 2754.5185825824738, "episode/length": 75.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 52376, "time": 2757.7026646137238, "episode/length": 284.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 52520, "time": 2764.1847491264343, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 52576, "time": 2767.852507352829, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 52816, "time": 2777.6689641475677, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 53296, "time": 2795.3867535591125, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 53472, "time": 2803.0193314552307, "episode/length": 162.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 53832, "time": 2816.562052965164, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 53928, "time": 2821.389825820923, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9587628865979382, "episode/intrinsic_return": 0.0}
{"step": 53944, "time": 2823.4816040992737, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 53976, "time": 2826.156086206436, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 54240, "time": 2836.8989396095276, "episode/length": 95.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 54248, "time": 2838.5831830501556, "episode/length": 178.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 54392, "time": 2844.9705939292908, "episode/length": 258.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 54648, "time": 2855.0315895080566, "episode/length": 50.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 54904, "time": 2865.1056530475616, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 55160, "time": 2875.2172157764435, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 55224, "time": 2878.9297132492065, "episode/length": 173.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 55384, "time": 2885.874324321747, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 55416, "time": 2888.652500152588, "episode/length": 183.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 56160, "time": 2915.411986351013, "episode/length": 238.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 56456, "time": 2926.825350999832, "episode/length": 225.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 56480, "time": 2929.3578674793243, "episode/length": 196.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 56552, "time": 2933.1988525390625, "episode/length": 269.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 56560, "time": 2935.3464522361755, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 56584, "time": 2937.599194765091, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 56704, "time": 2943.3878152370453, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 57376, "time": 2968.863844394684, "episode/length": 248.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 57656, "time": 2979.7451617717743, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 57760, "time": 2984.9666657447815, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 57968, "time": 2993.551502466202, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 57976, "time": 2995.1245362758636, "episode/length": 176.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 58016, "time": 2998.369908094406, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 58040, "time": 3000.5979385375977, "episode/length": 194.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 58160, "time": 3006.3789341449738, "episode/length": 181.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 58832, "time": 3030.685515642166, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 59344, "time": 3049.667781352997, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 59416, "time": 3053.440395116806, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 59456, "time": 3056.673450946808, "episode/length": 211.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 59736, "time": 3067.455156326294, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 59768, "time": 3070.3228754997253, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 59960, "time": 3078.320358276367, "episode/length": 247.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3097.4884617328644, "eval_episode/length": 62.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 60008, "time": 3102.915219068527, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 60008, "time": 3104.6152608394623, "eval_episode/length": 154.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 60008, "time": 3106.8041863441467, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 60008, "time": 3109.0735692977905, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 60008, "time": 3112.5506851673126, "eval_episode/length": 221.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 60008, "time": 3114.62184548378, "eval_episode/length": 50.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9215686274509803}
{"step": 60008, "time": 3116.693250656128, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 60248, "time": 3124.7124230861664, "episode/length": 112.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 60576, "time": 3137.6393315792084, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 61016, "time": 3154.176316022873, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 61064, "time": 3157.393741130829, "episode/length": 425.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 61088, "time": 3160.2766768932343, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 61104, "time": 3162.2907526493073, "episode/length": 283.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 61200, "time": 3167.015068769455, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 61304, "time": 3171.908212184906, "episode/length": 191.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 61480, "time": 3179.442577123642, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 61792, "time": 3191.7967658042908, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 62176, "time": 3206.375641345978, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 3216.057231426239, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 62480, "time": 3219.9534409046173, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 62736, "time": 3230.1533029079437, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 62744, "time": 3231.9213197231293, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 62792, "time": 3235.173349380493, "episode/length": 215.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 63232, "time": 3252.5769534111023, "episode/length": 131.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 63272, "time": 3255.325419187546, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 63544, "time": 3266.0434188842773, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 63648, "time": 3271.431230068207, "episode/length": 305.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 63736, "time": 3275.7582235336304, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 63928, "time": 3284.0287761688232, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 64280, "time": 3297.641660451889, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 64424, "time": 3303.955710411072, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 64680, "time": 3314.258227825165, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 64680, "time": 3314.267210483551, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 65096, "time": 3331.4876153469086, "episode/length": 193.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 65152, "time": 3335.2317826747894, "episode/length": 187.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 65152, "time": 3335.24050116539, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 65168, "time": 3339.277302503586, "episode/length": 154.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 65400, "time": 3348.474470615387, "episode/length": 30.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 65616, "time": 3358.872453689575, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 65808, "time": 3367.0478723049164, "episode/length": 140.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 65840, "time": 3369.955790758133, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 66201, "time": 3384.299945831299, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.215884937959559, "train/action_min": 0.0, "train/action_std": 2.5089183072833454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05109680563156657, "train/actor_opt_grad_steps": 3365.0, "train/actor_opt_loss": 39.03352872096002, "train/adv_mag": 1.7959564959301668, "train/adv_max": 1.7887024051126312, "train/adv_mean": 0.015863881280839612, "train/adv_min": -0.6625187291818506, "train/adv_std": 0.1355404314749381, "train/cont_avg": 0.9940616383272058, "train/cont_loss_mean": 0.0009006963596003543, "train/cont_loss_std": 0.022711715659093388, "train/cont_neg_acc": 0.966275150723317, "train/cont_neg_loss": 0.11804510827776352, "train/cont_pos_acc": 0.9999132756801212, "train/cont_pos_loss": 0.0003203572137095989, "train/cont_pred": 0.9940648482126349, "train/cont_rate": 0.9940616383272058, "train/dyn_loss_mean": 7.358409345149994, "train/dyn_loss_std": 6.546646377619575, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3949895001509611, "train/extr_critic_critic_opt_grad_steps": 3365.0, "train/extr_critic_critic_opt_loss": 15527.371151194853, "train/extr_critic_mag": 1.7760987614884096, "train/extr_critic_max": 1.7760987614884096, "train/extr_critic_mean": 0.5346603989601135, "train/extr_critic_min": -0.17989332272725947, "train/extr_critic_std": 0.5124208552434164, "train/extr_return_normed_mag": 2.6924069146899616, "train/extr_return_normed_max": 2.6924069146899616, "train/extr_return_normed_mean": 0.42159859682707224, "train/extr_return_normed_min": -0.34464294564745884, "train/extr_return_normed_std": 0.3691907152533531, "train/extr_return_rate": 0.4203627862255363, "train/extr_return_raw_mag": 4.0487815790316635, "train/extr_return_raw_max": 4.0487815790316635, "train/extr_return_raw_mean": 0.5588252140099511, "train/extr_return_raw_min": -0.6335265511537299, "train/extr_return_raw_std": 0.572253755567705, "train/extr_reward_mag": 1.0004955845720627, "train/extr_reward_max": 1.0004955845720627, "train/extr_reward_mean": 0.011577058092156863, "train/extr_reward_min": -0.4326626667205025, "train/extr_reward_std": 0.08769323674085386, "train/image_loss_mean": 18.68431458753698, "train/image_loss_std": 22.352908495594473, "train/model_loss_mean": 23.15809861351462, "train/model_loss_std": 24.533313624999103, "train/model_opt_grad_norm": 137.91827361723955, "train/model_opt_grad_steps": 3355.0, "train/model_opt_loss": 1638.7064722846535, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 70.36994485294117, "train/policy_entropy_mag": 2.186832285102676, "train/policy_entropy_max": 2.186832285102676, "train/policy_entropy_mean": 0.5072964885655571, "train/policy_entropy_min": 0.07945183691952158, "train/policy_entropy_std": 0.4055210190879948, "train/policy_logprob_mag": 7.438189846627853, "train/policy_logprob_max": -0.009466701221433194, "train/policy_logprob_mean": -0.5076322233413949, "train/policy_logprob_min": -7.438189846627853, "train/policy_logprob_std": 1.0540946384563166, "train/policy_randomness_mag": 0.7718558333375874, "train/policy_randomness_max": 0.7718558333375874, "train/policy_randomness_mean": 0.17905339765745928, "train/policy_randomness_min": 0.028043011696461367, "train/policy_randomness_std": 0.14313112259568536, "train/post_ent_mag": 43.71840886508717, "train/post_ent_max": 43.71840886508717, "train/post_ent_mean": 31.86509109945858, "train/post_ent_min": 15.624040224972893, "train/post_ent_std": 4.683662384748459, "train/prior_ent_mag": 55.70003666597254, "train/prior_ent_max": 55.70003666597254, "train/prior_ent_mean": 39.22195353227503, "train/prior_ent_min": 18.230674505233765, "train/prior_ent_std": 5.869998018531239, "train/rep_loss_mean": 7.358409345149994, "train/rep_loss_std": 6.546646377619575, "train/reward_avg": 0.011153636180097237, "train/reward_loss_mean": 0.05783769558183849, "train/reward_loss_std": 0.3076539594022667, "train/reward_max_data": 1.0058823543436386, "train/reward_max_pred": 0.9991512342410929, "train/reward_neg_acc": 0.9936875192558065, "train/reward_neg_loss": 0.03818401717580855, "train/reward_pos_acc": 0.8883228832307983, "train/reward_pos_loss": 1.2394588436273968, "train/reward_pred": 0.010443949621677509, "train/reward_rate": 0.016414866727941176, "train_stats/sum_log_reward": 2.891666599114736, "train_stats/max_log_achievement_collect_drink": 11.375, "train_stats/max_log_achievement_collect_sapling": 3.125, "train_stats/max_log_achievement_collect_wood": 1.3, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.10833333333333334, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.925, "train_stats/max_log_achievement_place_table": 0.041666666666666664, "train_stats/max_log_achievement_wake_up": 1.275, "train_stats/mean_log_entropy": 0.5061275875195861, "eval_stats/sum_log_reward": 2.9749999484047294, "eval_stats/max_log_achievement_collect_drink": 13.25, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_wood": 1.3125, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.04, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.2738763517700136e-06, "report/cont_loss_std": 2.845587550837081e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.0224014557898045e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.058223334548529e-06, "report/cont_pred": 0.9951114058494568, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 9.838499069213867, "report/dyn_loss_std": 7.73636531829834, "report/image_loss_mean": 26.580429077148438, "report/image_loss_std": 29.371267318725586, "report/model_loss_mean": 32.533477783203125, "report/model_loss_std": 32.37968063354492, "report/post_ent_mag": 47.118736267089844, "report/post_ent_max": 47.118736267089844, "report/post_ent_mean": 32.879852294921875, "report/post_ent_min": 15.60260009765625, "report/post_ent_std": 5.2437591552734375, "report/prior_ent_mag": 61.69171142578125, "report/prior_ent_max": 61.69171142578125, "report/prior_ent_mean": 43.304115295410156, "report/prior_ent_min": 15.600593566894531, "report/prior_ent_std": 7.788742542266846, "report/rep_loss_mean": 9.838499069213867, "report/rep_loss_std": 7.73636531829834, "report/reward_avg": 0.0078125, "report/reward_loss_mean": 0.04994089901447296, "report/reward_loss_std": 0.2654866874217987, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9999518394470215, "report/reward_neg_acc": 0.9950543642044067, "report/reward_neg_loss": 0.04161860793828964, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6971588134765625, "report/reward_pred": 0.00891614705324173, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.002299682004377246, "eval/cont_loss_std": 0.07324236631393433, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.5862483382225037, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.687523743195925e-06, "eval/cont_pred": 0.996967077255249, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 11.542909622192383, "eval/dyn_loss_std": 8.003746032714844, "eval/image_loss_mean": 35.530513763427734, "eval/image_loss_std": 39.47374725341797, "eval/model_loss_mean": 42.553977966308594, "eval/model_loss_std": 42.269901275634766, "eval/post_ent_mag": 46.76951217651367, "eval/post_ent_max": 46.76951217651367, "eval/post_ent_mean": 30.872772216796875, "eval/post_ent_min": 15.838398933410645, "eval/post_ent_std": 6.009587287902832, "eval/prior_ent_mag": 58.000553131103516, "eval/prior_ent_max": 58.000553131103516, "eval/prior_ent_mean": 40.37861251831055, "eval/prior_ent_min": 16.288982391357422, "eval/prior_ent_std": 8.581262588500977, "eval/rep_loss_mean": 11.542909622192383, "eval/rep_loss_std": 8.003746032714844, "eval/reward_avg": 0.00957031175494194, "eval/reward_loss_mean": 0.09541527181863785, "eval/reward_loss_std": 0.6844788193702698, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0007669925689697, "eval/reward_neg_acc": 0.997026801109314, "eval/reward_neg_loss": 0.04720494896173477, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.3383634090423584, "eval/reward_pred": 0.00418337807059288, "eval/reward_rate": 0.0146484375, "replay/size": 65697.0, "replay/inserts": 21632.0, "replay/samples": 21632.0, "replay/insert_wait_avg": 1.501743874606296e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0021030902862549e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13704.0, "eval_replay/inserts": 4200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2979620978945777e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3888547420502, "timer/env.step_count": 2704.0, "timer/env.step_total": 268.5014810562134, "timer/env.step_frac": 0.2683971135658507, "timer/env.step_avg": 0.09929788500599607, "timer/env.step_min": 0.02366495132446289, "timer/env.step_max": 3.528465509414673, "timer/replay._sample_count": 21632.0, "timer/replay._sample_total": 11.747101545333862, "timer/replay._sample_frac": 0.01174253540475803, "timer/replay._sample_avg": 0.0005430427859344426, "timer/replay._sample_min": 0.00039649009704589844, "timer/replay._sample_max": 0.016760826110839844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3229.0, "timer/agent.policy_total": 54.97211766242981, "timer/agent.policy_frac": 0.05495074980278978, "timer/agent.policy_avg": 0.017024502218157267, "timer/agent.policy_min": 0.009621620178222656, "timer/agent.policy_max": 0.09360384941101074, "timer/dataset_train_count": 1352.0, "timer/dataset_train_total": 0.14862298965454102, "timer/dataset_train_frac": 0.0001485652193644874, "timer/dataset_train_avg": 0.00010992824678590312, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0002658367156982422, "timer/agent.train_count": 1352.0, "timer/agent.train_total": 608.0983159542084, "timer/agent.train_frac": 0.6078619459540123, "timer/agent.train_avg": 0.449776860912876, "timer/agent.train_min": 0.43517327308654785, "timer/agent.train_max": 1.4317893981933594, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46425628662109375, "timer/agent.report_frac": 0.00046407582853449724, "timer/agent.report_avg": 0.23212814331054688, "timer/agent.report_min": 0.22243046760559082, "timer/agent.report_max": 0.24182581901550293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.859910859319263e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 21.623329348605093}
{"step": 66216, "time": 3384.385526895523, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 66512, "time": 3396.554230928421, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 66568, "time": 3400.08433675766, "episode/length": 235.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 66712, "time": 3406.431534051895, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 66736, "time": 3408.9858808517456, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 66752, "time": 3411.1642847061157, "episode/length": 66.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 67088, "time": 3424.0219762325287, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 67152, "time": 3427.8288629055023, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 67176, "time": 3430.1430294513702, "episode/length": 170.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 67992, "time": 3459.2258813381195, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 68088, "time": 3464.079605102539, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 68208, "time": 3469.915661096573, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 68240, "time": 3472.511741399765, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 68344, "time": 3477.3387575149536, "episode/length": 198.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 68376, "time": 3480.0759239196777, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 68840, "time": 3497.2972400188446, "episode/length": 207.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 68952, "time": 3502.6782965660095, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 69440, "time": 3521.083258867264, "episode/length": 60.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 69544, "time": 3525.84614109993, "episode/length": 193.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 69544, "time": 3525.8544232845306, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 69768, "time": 3536.874457836151, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 69872, "time": 3542.1470160484314, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 70024, "time": 3548.7074360847473, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3553.0114374160767, "episode/length": 235.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3572.567758321762, "eval_episode/length": 142.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 70096, "time": 3575.105473279953, "eval_episode/length": 163.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 70096, "time": 3576.83327794075, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 70096, "time": 3578.8444442749023, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 70096, "time": 3578.85245513916, "eval_episode/length": 174.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 70096, "time": 3582.895644426346, "eval_episode/length": 185.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 70096, "time": 3584.805477142334, "eval_episode/length": 191.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 70096, "time": 3584.8136603832245, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 70176, "time": 3589.021055698395, "episode/length": 241.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 70872, "time": 3613.838329076767, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 71088, "time": 3622.743531227112, "episode/length": 26.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 71208, "time": 3628.0765392780304, "episode/length": 179.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 71440, "time": 3637.6427397727966, "episode/length": 43.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 71472, "time": 3640.4917924404144, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 71488, "time": 3642.6381800174713, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 71528, "time": 3645.453702688217, "episode/length": 247.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 71560, "time": 3648.5245819091797, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 71584, "time": 3651.965152025223, "episode/length": 194.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 71736, "time": 3658.5145452022552, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 72600, "time": 3689.1066224575043, "episode/length": 381.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764397905759162, "episode/intrinsic_return": 0.0}
{"step": 72744, "time": 3695.589186668396, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 72832, "time": 3700.5624961853027, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 72856, "time": 3702.762847185135, "episode/length": 176.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 72944, "time": 3707.4841854572296, "episode/length": 42.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 72960, "time": 3709.5062334537506, "episode/length": 183.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 72976, "time": 3711.5830228328705, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 72992, "time": 3713.700268507004, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 73208, "time": 3722.441980600357, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 73328, "time": 3728.3902111053467, "episode/length": 58.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 73352, "time": 3730.4497900009155, "episode/length": 50.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 73768, "time": 3747.4144077301025, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 73944, "time": 3754.9064223766327, "episode/length": 149.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 74040, "time": 3759.755234479904, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 74232, "time": 3767.765467405319, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 74296, "time": 3771.49689912796, "episode/length": 162.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 74392, "time": 3776.3487660884857, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 74472, "time": 3780.6460824012756, "episode/length": 204.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 74592, "time": 3786.5676810741425, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 74776, "time": 3794.145122528076, "episode/length": 59.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 74944, "time": 3801.56787276268, "episode/length": 216.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 75200, "time": 3811.71887755394, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 75208, "time": 3813.3666343688965, "episode/length": 91.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 75496, "time": 3824.59428191185, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 75696, "time": 3833.242254257202, "episode/length": 218.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 75824, "time": 3839.102250099182, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 76264, "time": 3855.1688330173492, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 76280, "time": 3857.348205804825, "episode/length": 210.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 76400, "time": 3863.0064034461975, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 76720, "time": 3875.17014503479, "episode/length": 189.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 76736, "time": 3877.466831922531, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 76888, "time": 3883.937718153, "episode/length": 209.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 76968, "time": 3888.1983823776245, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 77496, "time": 3907.4583735466003, "episode/length": 208.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 77752, "time": 3917.732358932495, "episode/length": 183.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 77808, "time": 3921.3424344062805, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 77840, "time": 3924.097202539444, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 78248, "time": 3939.2531571388245, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 78328, "time": 3943.3689255714417, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 78488, "time": 3950.3492481708527, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 78848, "time": 3964.1886701583862, "episode/length": 168.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 78936, "time": 3968.475694656372, "episode/length": 255.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 79128, "time": 3976.5237646102905, "episode/length": 171.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 79152, "time": 3979.1207087039948, "episode/length": 163.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 79408, "time": 3989.1836638450623, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 79624, "time": 3997.802558898926, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 80016, "time": 4012.794801235199, "episode/length": 210.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4032.016439437866, "eval_episode/length": 53.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9074074074074074}
{"step": 80080, "time": 4039.2888622283936, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 80080, "time": 4041.854206085205, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 80080, "time": 4043.5929551124573, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 80080, "time": 4046.0624101161957, "eval_episode/length": 198.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 80080, "time": 4047.8029084205627, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 80080, "time": 4049.8158614635468, "eval_episode/length": 211.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 80080, "time": 4052.263674736023, "eval_episode/length": 230.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 80160, "time": 4054.9387135505676, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 80352, "time": 4062.8999960422516, "episode/length": 117.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 80432, "time": 4067.2586829662323, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 80496, "time": 4071.0231647491455, "episode/length": 170.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 80840, "time": 4083.9398283958435, "episode/length": 50.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 80912, "time": 4088.680805683136, "episode/length": 219.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 81024, "time": 4094.5857932567596, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 81064, "time": 4097.205271482468, "episode/length": 351.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 81600, "time": 4117.315769433975, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 81688, "time": 4121.743854045868, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 81872, "time": 4129.791961431503, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 82008, "time": 4137.061326980591, "episode/length": 188.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 82360, "time": 4151.077821969986, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 82496, "time": 4157.361010313034, "episode/length": 206.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 82656, "time": 4164.261065483093, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 83016, "time": 4177.703089237213, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 83056, "time": 4181.504556894302, "episode/length": 49.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 83160, "time": 4186.655485868454, "episode/length": 143.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 83168, "time": 4188.650161743164, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 83248, "time": 4192.857072353363, "episode/length": 272.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 83528, "time": 4203.623653650284, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 83744, "time": 4212.850918769836, "episode/length": 172.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 84416, "time": 4236.776519536972, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 84464, "time": 4240.202857971191, "episode/length": 175.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 84480, "time": 4242.317898511887, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 84632, "time": 4248.73530960083, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 84824, "time": 4256.75244641304, "episode/length": 206.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 84936, "time": 4262.098572731018, "episode/length": 488.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 85136, "time": 4270.667598962784, "episode/length": 200.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 85184, "time": 4273.796630620956, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 85224, "time": 4276.5275955200195, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 85808, "time": 4297.839380264282, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 86104, "time": 4309.152627229691, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 86168, "time": 4313.105651855469, "episode/length": 191.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 86208, "time": 4316.167182922363, "episode/length": 217.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 86464, "time": 4326.278069019318, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 86600, "time": 4332.3068861961365, "episode/length": 48.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 86616, "time": 4334.434116601944, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 86656, "time": 4337.511142253876, "episode/length": 189.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 86696, "time": 4340.229436635971, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 86792, "time": 4345.504846572876, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 87360, "time": 4366.5562608242035, "episode/length": 156.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 87368, "time": 4368.167898893356, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 87785, "time": 4384.646105289459, "train_stats/sum_log_reward": 3.251999920964241, "train_stats/max_log_achievement_collect_drink": 6.928, "train_stats/max_log_achievement_collect_sapling": 3.28, "train_stats/max_log_achievement_collect_wood": 2.016, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.152, "train_stats/max_log_achievement_eat_cow": 0.08, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.864, "train_stats/max_log_achievement_place_table": 0.024, "train_stats/max_log_achievement_wake_up": 1.2, "train_stats/mean_log_entropy": 0.5822732462882996, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.006360315393518, "train/action_min": 0.0, "train/action_std": 2.509837907331961, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050870705354544854, "train/actor_opt_grad_steps": 4720.0, "train/actor_opt_loss": 9.151554559557527, "train/adv_mag": 1.2093536465256303, "train/adv_max": 1.2029054827160306, "train/adv_mean": 0.006760937020158895, "train/adv_min": -0.5704832726054722, "train/adv_std": 0.10178730460228744, "train/cont_avg": 0.9943287037037037, "train/cont_loss_mean": 0.000643964138096096, "train/cont_loss_std": 0.017928783384848903, "train/cont_neg_acc": 0.9781834244728088, "train/cont_neg_loss": 0.0794218228020327, "train/cont_pos_acc": 0.9999272306760152, "train/cont_pos_loss": 0.00023048766968700976, "train/cont_pred": 0.9943207414061935, "train/cont_rate": 0.9943287037037037, "train/dyn_loss_mean": 9.550162788673683, "train/dyn_loss_std": 7.578057624675609, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0762725039764687, "train/extr_critic_critic_opt_grad_steps": 4720.0, "train/extr_critic_critic_opt_loss": 14165.50912181713, "train/extr_critic_mag": 2.130963350225378, "train/extr_critic_max": 2.130963350225378, "train/extr_critic_mean": 0.6905954115920596, "train/extr_critic_min": -0.15683299435509576, "train/extr_critic_std": 0.648499525697143, "train/extr_return_normed_mag": 2.1686926470862495, "train/extr_return_normed_max": 2.1686926470862495, "train/extr_return_normed_mean": 0.3975033860515665, "train/extr_return_normed_min": -0.2852250988284747, "train/extr_return_normed_std": 0.36507873777989985, "train/extr_return_rate": 0.4414395482451827, "train/extr_return_raw_mag": 4.055650493833753, "train/extr_return_raw_max": 4.055650493833753, "train/extr_return_raw_mean": 0.7034110243673678, "train/extr_return_raw_min": -0.5871468070480559, "train/extr_return_raw_std": 0.6911967926555209, "train/extr_reward_mag": 1.002046239817584, "train/extr_reward_max": 1.002046239817584, "train/extr_reward_mean": 0.012584808137681749, "train/extr_reward_min": -0.37741312274226435, "train/extr_reward_std": 0.09464595792470155, "train/image_loss_mean": 19.445529775266294, "train/image_loss_std": 21.731183468853985, "train/model_loss_mean": 25.23034220095034, "train/model_loss_std": 24.870615613019027, "train/model_opt_grad_norm": 104.64178955643266, "train/model_opt_grad_steps": 4710.0, "train/model_opt_loss": 5028.591351996528, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 200.2314814814815, "train/policy_entropy_mag": 2.168962084805524, "train/policy_entropy_max": 2.168962084805524, "train/policy_entropy_mean": 0.5625184365996608, "train/policy_entropy_min": 0.0793843467478399, "train/policy_entropy_std": 0.42050704956054685, "train/policy_logprob_mag": 7.4382793567798755, "train/policy_logprob_max": -0.009457573253247474, "train/policy_logprob_mean": -0.5641096479362911, "train/policy_logprob_min": -7.4382793567798755, "train/policy_logprob_std": 1.0671752717759875, "train/policy_randomness_mag": 0.7655484323148374, "train/policy_randomness_max": 0.7655484323148374, "train/policy_randomness_mean": 0.19854432333398747, "train/policy_randomness_min": 0.0280191908142081, "train/policy_randomness_std": 0.14842053453127543, "train/post_ent_mag": 46.25437048452872, "train/post_ent_max": 46.25437048452872, "train/post_ent_mean": 33.484290497391314, "train/post_ent_min": 17.480649432429562, "train/post_ent_std": 4.877451815428557, "train/prior_ent_mag": 59.1782745078758, "train/prior_ent_max": 59.1782745078758, "train/prior_ent_mean": 43.19917718392831, "train/prior_ent_min": 20.233696619669598, "train/prior_ent_std": 7.025893610495108, "train/rep_loss_mean": 9.550162788673683, "train/rep_loss_std": 7.578057624675609, "train/reward_avg": 0.013028790425785162, "train/reward_loss_mean": 0.05407070539615772, "train/reward_loss_std": 0.28348939551247493, "train/reward_max_data": 1.0051851864214296, "train/reward_max_pred": 1.0007651231907033, "train/reward_neg_acc": 0.9933375967873468, "train/reward_neg_loss": 0.03411166105695345, "train/reward_pos_acc": 0.9163786733591998, "train/reward_pos_loss": 1.131054377997363, "train/reward_pred": 0.01209082180392687, "train/reward_rate": 0.0181640625, "eval_stats/sum_log_reward": 3.53749995585531, "eval_stats/max_log_achievement_collect_drink": 6.8125, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_wood": 2.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.0625, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0003296812647022307, "report/cont_loss_std": 0.010446831583976746, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0672059878706932, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.534625880594831e-06, "report/cont_pred": 0.9953948855400085, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.566461563110352, "report/dyn_loss_std": 8.449748039245605, "report/image_loss_mean": 27.07750701904297, "report/image_loss_std": 27.6270751953125, "report/model_loss_mean": 34.677852630615234, "report/model_loss_std": 30.939983367919922, "report/post_ent_mag": 49.85129928588867, "report/post_ent_max": 49.85129928588867, "report/post_ent_mean": 35.12270736694336, "report/post_ent_min": 17.714609146118164, "report/post_ent_std": 5.294063091278076, "report/prior_ent_mag": 61.954071044921875, "report/prior_ent_max": 61.954071044921875, "report/prior_ent_mean": 47.43828582763672, "report/prior_ent_min": 21.853639602661133, "report/prior_ent_std": 7.035885334014893, "report/rep_loss_mean": 12.566461563110352, "report/rep_loss_std": 8.449748039245605, "report/reward_avg": 0.0166015625, "report/reward_loss_mean": 0.06014164537191391, "report/reward_loss_std": 0.2815321087837219, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0010180473327637, "report/reward_neg_acc": 0.9900199770927429, "report/reward_neg_loss": 0.037203993648290634, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 1.1048475503921509, "report/reward_pred": 0.01680661365389824, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.297942501172656e-06, "eval/cont_loss_std": 5.686378790414892e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006861395086161792, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.8861398959634244e-07, "eval/cont_pred": 0.9970721006393433, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 12.522079467773438, "eval/dyn_loss_std": 8.452862739562988, "eval/image_loss_mean": 27.7200984954834, "eval/image_loss_std": 36.94960021972656, "eval/model_loss_mean": 35.287994384765625, "eval/model_loss_std": 39.677391052246094, "eval/post_ent_mag": 44.14744567871094, "eval/post_ent_max": 44.14744567871094, "eval/post_ent_mean": 32.60392761230469, "eval/post_ent_min": 17.932626724243164, "eval/post_ent_std": 4.933253765106201, "eval/prior_ent_mag": 58.98488235473633, "eval/prior_ent_max": 58.98488235473633, "eval/prior_ent_mean": 42.00455856323242, "eval/prior_ent_min": 20.007272720336914, "eval/prior_ent_std": 8.109343528747559, "eval/rep_loss_mean": 12.522079467773438, "eval/rep_loss_std": 8.452862739562988, "eval/reward_avg": 0.007812499534338713, "eval/reward_loss_mean": 0.05464736372232437, "eval/reward_loss_std": 0.5543845295906067, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022289752960205, "eval/reward_neg_acc": 0.9980257153511047, "eval/reward_neg_loss": 0.01773250289261341, "eval/reward_pos_acc": 0.7272727489471436, "eval/reward_pos_loss": 3.4541707038879395, "eval/reward_pred": 0.0038685202598571777, "eval/reward_rate": 0.0107421875, "replay/size": 87281.0, "replay/inserts": 21584.0, "replay/samples": 21584.0, "replay/insert_wait_avg": 1.4796665282139873e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.410265554225914e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17088.0, "eval_replay/inserts": 3384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2847407771622318e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3293087482452, "timer/env.step_count": 2698.0, "timer/env.step_total": 277.3716359138489, "timer/env.step_frac": 0.2772803250770847, "timer/env.step_avg": 0.10280638840394696, "timer/env.step_min": 0.023541688919067383, "timer/env.step_max": 3.517305374145508, "timer/replay._sample_count": 21584.0, "timer/replay._sample_total": 11.469408988952637, "timer/replay._sample_frac": 0.011465633255617391, "timer/replay._sample_avg": 0.000531384775247991, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.027744770050048828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3121.0, "timer/agent.policy_total": 53.470832109451294, "timer/agent.policy_frac": 0.05345322949335717, "timer/agent.policy_avg": 0.017132595997901727, "timer/agent.policy_min": 0.009598016738891602, "timer/agent.policy_max": 0.13073992729187012, "timer/dataset_train_count": 1349.0, "timer/dataset_train_total": 0.1409001350402832, "timer/dataset_train_frac": 0.0001408537506679651, "timer/dataset_train_avg": 0.00010444783916996531, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0004227161407470703, "timer/agent.train_count": 1349.0, "timer/agent.train_total": 604.2410867214203, "timer/agent.train_frac": 0.6040421703504149, "timer/agent.train_avg": 0.44791778111298763, "timer/agent.train_min": 0.4360232353210449, "timer/agent.train_max": 1.4525179862976074, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725301265716553, "timer/agent.report_frac": 0.00047237456949347247, "timer/agent.report_avg": 0.23626506328582764, "timer/agent.report_min": 0.22910094261169434, "timer/agent.report_max": 0.24342918395996094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979251145304163e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 21.576628154455538}
{"step": 87856, "time": 4387.21391248703, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 88040, "time": 4395.637762308121, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 88248, "time": 4404.187231063843, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 88336, "time": 4408.987660884857, "episode/length": 120.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9421487603305785, "episode/intrinsic_return": 0.0}
{"step": 88384, "time": 4412.077975273132, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 88384, "time": 4412.087934732437, "episode/length": 239.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 88912, "time": 4433.206759691238, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 89424, "time": 4451.988502025604, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 89544, "time": 4457.39363193512, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 89552, "time": 4459.515920639038, "episode/length": 356.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 89752, "time": 4467.546063661575, "episode/length": 40.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 89888, "time": 4473.865355491638, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 89904, "time": 4475.92480301857, "episode/length": 189.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 89968, "time": 4479.725390911102, "episode/length": 197.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 90056, "time": 4484.051696062088, "episode/length": 251.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4501.337565422058, "eval_episode/length": 41.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 90064, "time": 4505.95570731163, "eval_episode/length": 112.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 90064, "time": 4508.808357715607, "eval_episode/length": 139.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 90064, "time": 4511.820329904556, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9881656804733728}
{"step": 90064, "time": 4511.829269647598, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 90064, "time": 4511.836484909058, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 90064, "time": 4517.72820186615, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 90064, "time": 4523.3279275894165, "eval_episode/length": 236.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 90192, "time": 4528.947676181793, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 90352, "time": 4535.881506443024, "episode/length": 36.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 90744, "time": 4550.403542518616, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 90768, "time": 4553.076066732407, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 91168, "time": 4568.06303024292, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 91528, "time": 4581.505623340607, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 91640, "time": 4586.881232500076, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 91656, "time": 4589.006932258606, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 91728, "time": 4593.268522024155, "episode/length": 69.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 91744, "time": 4595.3825352191925, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 91784, "time": 4598.183487653732, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 92544, "time": 4625.108462572098, "episode/length": 221.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 92552, "time": 4626.746790409088, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 92848, "time": 4638.561611175537, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 92928, "time": 4642.788928031921, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 92968, "time": 4645.463875055313, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 93008, "time": 4648.538036584854, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 93216, "time": 4657.014477014542, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 93416, "time": 4665.149537086487, "episode/length": 203.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 93800, "time": 4679.463150024414, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 93872, "time": 4683.546627044678, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 94128, "time": 4693.693769931793, "episode/length": 40.0, "episode/score": 1.1000000312924385, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 94200, "time": 4697.445612668991, "episode/length": 40.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 94232, "time": 4700.161383867264, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 94304, "time": 4704.173122882843, "episode/length": 135.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 94352, "time": 4707.443189382553, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 94424, "time": 4711.212073326111, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 94480, "time": 4714.888451337814, "episode/length": 132.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 94776, "time": 4726.184447050095, "episode/length": 225.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 95024, "time": 4736.265670061111, "episode/length": 111.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 95352, "time": 4748.612861156464, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 95840, "time": 4766.636798143387, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 95904, "time": 4770.418599128723, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 95920, "time": 4772.550569534302, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 96240, "time": 4784.820209503174, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 96248, "time": 4786.84871506691, "episode/length": 227.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 96328, "time": 4791.585912704468, "episode/length": 230.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 96376, "time": 4794.705882549286, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 96480, "time": 4800.141503572464, "episode/length": 12.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 96632, "time": 4806.497718095779, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 97384, "time": 4833.094415187836, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 97448, "time": 4836.911432266235, "episode/length": 192.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 97528, "time": 4841.171770334244, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 97536, "time": 4843.3231019973755, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 97584, "time": 4846.4955842494965, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 97624, "time": 4849.131875514984, "episode/length": 171.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 97840, "time": 4858.162471532822, "episode/length": 37.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 98024, "time": 4865.661488294601, "episode/length": 222.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 98296, "time": 4876.2857620716095, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 98448, "time": 4884.458650827408, "episode/length": 102.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 98736, "time": 4895.565458774567, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 98800, "time": 4899.3656351566315, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 99096, "time": 4910.438593626022, "episode/length": 205.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 99104, "time": 4912.398337841034, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 99496, "time": 4926.845557928085, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 99632, "time": 4933.845256567001, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 99840, "time": 4942.384404420853, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 99952, "time": 4947.649423599243, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4969.009066581726, "eval_episode/length": 85.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9418604651162791}
{"step": 100048, "time": 4972.301348686218, "eval_episode/length": 37.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 100048, "time": 4974.561967134476, "eval_episode/length": 136.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 100048, "time": 4978.024600028992, "eval_episode/length": 178.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 100048, "time": 4979.874785423279, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 100048, "time": 4981.814312458038, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 100048, "time": 4983.850100517273, "eval_episode/length": 202.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 100048, "time": 4987.498558282852, "eval_episode/length": 249.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.976}
{"step": 100176, "time": 4991.7931542396545, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 100208, "time": 4994.326845169067, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 100248, "time": 4996.990634441376, "episode/length": 142.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 100464, "time": 5005.893006563187, "episode/length": 63.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 100488, "time": 5007.97611951828, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 100920, "time": 5023.883452415466, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 101176, "time": 5033.91016459465, "episode/length": 120.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9669421487603306, "episode/intrinsic_return": 0.0}
{"step": 101360, "time": 5041.820331096649, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 101560, "time": 5049.923735141754, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 101576, "time": 5051.978491306305, "episode/length": 309.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 101608, "time": 5054.565859794617, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 101704, "time": 5059.250529766083, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 102448, "time": 5085.784282445908, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 102520, "time": 5089.433988571167, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 102608, "time": 5094.167077302933, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 102696, "time": 5098.401713848114, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 102736, "time": 5101.618600845337, "episode/length": 194.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 103184, "time": 5118.131824731827, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 103528, "time": 5131.03430891037, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 103792, "time": 5142.066300153732, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 103912, "time": 5147.332591056824, "episode/length": 287.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 104072, "time": 5154.187798976898, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 104344, "time": 5164.979806423187, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 104456, "time": 5170.811876773834, "episode/length": 67.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 104552, "time": 5175.419002532959, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 104752, "time": 5184.11398935318, "episode/length": 195.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 104824, "time": 5188.352212905884, "episode/length": 33.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 105384, "time": 5208.427523851395, "episode/length": 346.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 105472, "time": 5213.220760583878, "episode/length": 377.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9973544973544973, "episode/intrinsic_return": 0.0}
{"step": 105520, "time": 5216.3679459095, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 105816, "time": 5227.56632399559, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 105872, "time": 5231.460158586502, "episode/length": 292.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 106128, "time": 5241.469735622406, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 106368, "time": 5251.512687921524, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 106376, "time": 5253.214330434799, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 106712, "time": 5267.417062997818, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 106792, "time": 5271.637058019638, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 107000, "time": 5280.132689714432, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 107032, "time": 5282.793943166733, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 107048, "time": 5284.856513977051, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 107048, "time": 5284.863777399063, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 107624, "time": 5307.392998456955, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 107672, "time": 5310.50039935112, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 107840, "time": 5317.741137266159, "episode/length": 26.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 108136, "time": 5329.0275230407715, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 108168, "time": 5331.642734289169, "episode/length": 254.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 108272, "time": 5336.901663064957, "episode/length": 74.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 108512, "time": 5346.459990262985, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 108576, "time": 5350.243200063705, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 108664, "time": 5354.614130973816, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 109096, "time": 5370.573640823364, "episode/length": 156.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 109280, "time": 5378.572735071182, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 109401, "time": 5384.927532196045, "train_stats/sum_log_reward": 3.6919999381303787, "train_stats/max_log_achievement_collect_drink": 5.0, "train_stats/max_log_achievement_collect_sapling": 3.224, "train_stats/max_log_achievement_collect_wood": 1.952, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.288, "train_stats/max_log_achievement_eat_cow": 0.072, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008, "train_stats/max_log_achievement_place_plant": 2.744, "train_stats/max_log_achievement_place_table": 0.4, "train_stats/max_log_achievement_wake_up": 1.352, "train_stats/mean_log_entropy": 0.6478032848834991, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.130875651041666, "train/action_min": 0.0, "train/action_std": 2.7279645019107397, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05336940473428479, "train/actor_opt_grad_steps": 6070.0, "train/actor_opt_loss": 24.55812705081922, "train/adv_mag": 1.0641716882034584, "train/adv_max": 1.0641222423977321, "train/adv_mean": 0.009333659248012636, "train/adv_min": -0.5309950691682321, "train/adv_std": 0.09966422932015526, "train/cont_avg": 0.9940682870370371, "train/cont_loss_mean": 0.0005332550454324047, "train/cont_loss_std": 0.014330266242309672, "train/cont_neg_acc": 0.977889479972698, "train/cont_neg_loss": 0.06099884729238864, "train/cont_pos_acc": 0.9999490521572254, "train/cont_pos_loss": 0.00016533155270950474, "train/cont_pred": 0.9941281142058196, "train/cont_rate": 0.9940682870370371, "train/dyn_loss_mean": 11.263812192281087, "train/dyn_loss_std": 8.010626524466055, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.129402216275533, "train/extr_critic_critic_opt_grad_steps": 6070.0, "train/extr_critic_critic_opt_loss": 15113.469270833333, "train/extr_critic_mag": 2.7815836959415012, "train/extr_critic_max": 2.7815836959415012, "train/extr_critic_mean": 0.7589602053165436, "train/extr_critic_min": -0.11394783920711941, "train/extr_critic_std": 0.7554810599044517, "train/extr_return_normed_mag": 2.044757056236267, "train/extr_return_normed_max": 2.044757056236267, "train/extr_return_normed_mean": 0.3499713287309364, "train/extr_return_normed_min": -0.22409142620033687, "train/extr_return_normed_std": 0.35720328799000495, "train/extr_return_rate": 0.44422021839353776, "train/extr_return_raw_mag": 4.610242502777664, "train/extr_return_raw_max": 4.610242502777664, "train/extr_return_raw_mean": 0.7801836616463131, "train/extr_return_raw_min": -0.5144165886773003, "train/extr_return_raw_std": 0.8065396101386458, "train/extr_reward_mag": 1.0047006315655178, "train/extr_reward_max": 1.0047006315655178, "train/extr_reward_mean": 0.01797500780818087, "train/extr_reward_min": -0.389685148662991, "train/extr_reward_std": 0.11557435023563879, "train/image_loss_mean": 16.627258887114348, "train/image_loss_std": 17.897430688363535, "train/model_loss_mean": 23.440178758126716, "train/model_loss_std": 21.355784486841273, "train/model_opt_grad_norm": 97.20102231061017, "train/model_opt_grad_steps": 6060.0, "train/model_opt_loss": 11212.40232204861, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 481.48148148148147, "train/policy_entropy_mag": 2.3102301465140447, "train/policy_entropy_max": 2.3102301465140447, "train/policy_entropy_mean": 0.6529632956893355, "train/policy_entropy_min": 0.07938493534370705, "train/policy_entropy_std": 0.46691954135894775, "train/policy_logprob_mag": 7.438275457311559, "train/policy_logprob_max": -0.009457622261510954, "train/policy_logprob_mean": -0.6529499857513993, "train/policy_logprob_min": -7.438275457311559, "train/policy_logprob_std": 1.1357336088463112, "train/policy_randomness_mag": 0.8154098594630206, "train/policy_randomness_max": 0.8154098594630206, "train/policy_randomness_mean": 0.23046738704045613, "train/policy_randomness_min": 0.028019398478446183, "train/policy_randomness_std": 0.16480210820833843, "train/post_ent_mag": 47.75254688969365, "train/post_ent_max": 47.75254688969365, "train/post_ent_mean": 34.50926866884585, "train/post_ent_min": 18.52716993402552, "train/post_ent_std": 5.010427732820864, "train/prior_ent_mag": 59.86156992029261, "train/prior_ent_max": 59.86156992029261, "train/prior_ent_mean": 45.89174869678639, "train/prior_ent_min": 22.292293986567746, "train/prior_ent_std": 7.060508071051704, "train/rep_loss_mean": 11.263812192281087, "train/rep_loss_std": 8.010626524466055, "train/reward_avg": 0.014591290382668376, "train/reward_loss_mean": 0.054099353996139986, "train/reward_loss_std": 0.28136156653916394, "train/reward_max_data": 1.008148150090818, "train/reward_max_pred": 1.0021399109451858, "train/reward_neg_acc": 0.9933387681289956, "train/reward_neg_loss": 0.033498269229851385, "train/reward_pos_acc": 0.9273054273040207, "train/reward_pos_loss": 1.0670826660262214, "train/reward_pred": 0.013600328368031316, "train/reward_rate": 0.01990740740740741, "eval_stats/sum_log_reward": 3.162499949336052, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_wood": 2.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.2541068978607655e-05, "report/cont_loss_std": 0.0007361163734458387, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.008428833447396755, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3914487908550655e-06, "report/cont_pred": 0.9951566457748413, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.486221313476562, "report/dyn_loss_std": 8.056270599365234, "report/image_loss_mean": 12.454915046691895, "report/image_loss_std": 12.60509204864502, "report/model_loss_mean": 19.393991470336914, "report/model_loss_std": 16.103200912475586, "report/post_ent_mag": 47.303096771240234, "report/post_ent_max": 47.303096771240234, "report/post_ent_mean": 35.02855682373047, "report/post_ent_min": 16.864604949951172, "report/post_ent_std": 5.045588493347168, "report/prior_ent_mag": 60.37345886230469, "report/prior_ent_max": 60.37345886230469, "report/prior_ent_mean": 47.13486862182617, "report/prior_ent_min": 21.304367065429688, "report/prior_ent_std": 6.110886096954346, "report/rep_loss_mean": 11.486221313476562, "report/rep_loss_std": 8.056270599365234, "report/reward_avg": 0.01972656324505806, "report/reward_loss_mean": 0.04730028286576271, "report/reward_loss_std": 0.21916897594928741, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002310037612915, "report/reward_neg_acc": 0.9899899959564209, "report/reward_neg_loss": 0.025377271696925163, "report/reward_pos_acc": 0.9199999570846558, "report/reward_pos_loss": 0.9233437776565552, "report/reward_pred": 0.02104794979095459, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0001924276730278507, "eval/cont_loss_std": 0.005722893867641687, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.09756888449192047, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8670780264073983e-06, "eval/cont_pred": 0.9982200860977173, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.21744155883789, "eval/dyn_loss_std": 8.938908576965332, "eval/image_loss_mean": 30.719722747802734, "eval/image_loss_std": 32.51677703857422, "eval/model_loss_mean": 39.931339263916016, "eval/model_loss_std": 35.52029800415039, "eval/post_ent_mag": 44.070289611816406, "eval/post_ent_max": 44.070289611816406, "eval/post_ent_mean": 32.92079544067383, "eval/post_ent_min": 18.784467697143555, "eval/post_ent_std": 5.194761276245117, "eval/prior_ent_mag": 60.37345886230469, "eval/prior_ent_max": 60.37345886230469, "eval/prior_ent_mean": 45.58665466308594, "eval/prior_ent_min": 24.438566207885742, "eval/prior_ent_std": 8.17413330078125, "eval/rep_loss_mean": 15.21744155883789, "eval/rep_loss_std": 8.938908576965332, "eval/reward_avg": 0.011914062313735485, "eval/reward_loss_mean": 0.080959752202034, "eval/reward_loss_std": 0.7162080407142639, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0055878162384033, "eval/reward_neg_acc": 0.9980178475379944, "eval/reward_neg_loss": 0.013432125560939312, "eval/reward_pos_acc": 0.40000003576278687, "eval/reward_pos_loss": 4.623318672180176, "eval/reward_pred": 0.003370659425854683, "eval/reward_rate": 0.0146484375, "replay/size": 108897.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.4948258128190905e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.079391144894389e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21320.0, "eval_replay/inserts": 4232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2447117407065033e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2736365795135, "timer/env.step_count": 2702.0, "timer/env.step_total": 273.5302538871765, "timer/env.step_frac": 0.27345542647962523, "timer/env.step_avg": 0.10123251439199724, "timer/env.step_min": 0.023101091384887695, "timer/env.step_max": 3.575342893600464, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.576860427856445, "timer/replay._sample_frac": 0.011573693441970645, "timer/replay._sample_avg": 0.0005355690427394728, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.011771917343139648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3231.0, "timer/agent.policy_total": 53.66477394104004, "timer/agent.policy_frac": 0.05365009331301528, "timer/agent.policy_avg": 0.016609338886115765, "timer/agent.policy_min": 0.009639263153076172, "timer/agent.policy_max": 0.11010098457336426, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.14308977127075195, "timer/dataset_train_frac": 0.0001430506273863767, "timer/dataset_train_avg": 0.0001059139683721332, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.001069784164428711, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 603.982679605484, "timer/agent.train_frac": 0.6038174530629773, "timer/agent.train_avg": 0.4470634193971014, "timer/agent.train_min": 0.43555331230163574, "timer/agent.train_max": 1.4855413436889648, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4705989360809326, "timer/agent.report_frac": 0.00047047019822512724, "timer/agent.report_avg": 0.2352994680404663, "timer/agent.report_min": 0.2247912883758545, "timer/agent.report_max": 0.24580764770507812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.88407561854159e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.609838345057486}
{"step": 109720, "time": 5395.4637331962585, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 109776, "time": 5399.114950895309, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 109920, "time": 5405.454828262329, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 110000, "time": 5409.764533758163, "episode/length": 177.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 110008, "time": 5411.366771936417, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5430.764460802078, "eval_episode/length": 82.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 110032, "time": 5436.394145965576, "eval_episode/length": 157.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9556962025316456}
{"step": 110032, "time": 5438.363372325897, "eval_episode/length": 161.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 110032, "time": 5440.942251205444, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 110032, "time": 5444.001787185669, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 110032, "time": 5446.687138557434, "eval_episode/length": 239.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9708333333333333}
{"step": 110032, "time": 5448.47482085228, "eval_episode/length": 242.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9835390946502057}
{"step": 110032, "time": 5450.745090723038, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 110152, "time": 5454.487695932388, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 110184, "time": 5456.997129440308, "episode/length": 393.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771573604060914, "episode/intrinsic_return": 0.0}
{"step": 110704, "time": 5475.970316171646, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 111392, "time": 5500.312665939331, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 111448, "time": 5503.548857688904, "episode/length": 293.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 111632, "time": 5511.488835096359, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 111696, "time": 5515.218626022339, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 111816, "time": 5520.5710327625275, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 111992, "time": 5528.046060800552, "episode/length": 229.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 112064, "time": 5532.2207407951355, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 112416, "time": 5545.36768746376, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 112424, "time": 5546.915859937668, "episode/length": 121.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 112760, "time": 5559.6716401577, "episode/length": 343.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9912790697674418, "episode/intrinsic_return": 0.0}
{"step": 112816, "time": 5563.342161893845, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 112944, "time": 5569.160272598267, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 113360, "time": 5584.501538276672, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 113496, "time": 5590.494219303131, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 113576, "time": 5594.756641149521, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 114064, "time": 5612.796142101288, "episode/length": 258.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 114096, "time": 5615.4066824913025, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 114312, "time": 5623.993035793304, "episode/length": 186.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 114376, "time": 5627.721067428589, "episode/length": 201.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 114616, "time": 5637.288372993469, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 114664, "time": 5640.505263328552, "episode/length": 214.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 114976, "time": 5653.951364994049, "episode/length": 201.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 115432, "time": 5670.483265161514, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 115560, "time": 5676.3694269657135, "episode/length": 182.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 115792, "time": 5686.040679216385, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 115936, "time": 5692.309354305267, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 116072, "time": 5698.192097663879, "episode/length": 311.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 116240, "time": 5705.608840227127, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 116272, "time": 5708.33150434494, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 116336, "time": 5712.069659471512, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 116536, "time": 5720.0071268081665, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 116672, "time": 5726.330275058746, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 117032, "time": 5739.687732934952, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 117200, "time": 5747.088837862015, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 117504, "time": 5758.658689498901, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 117592, "time": 5762.929226636887, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 117624, "time": 5765.482102870941, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 117864, "time": 5775.10436797142, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 117888, "time": 5777.55962729454, "episode/length": 47.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 118008, "time": 5782.881818532944, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 118080, "time": 5787.004529953003, "episode/length": 192.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 118640, "time": 5806.980266571045, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 118800, "time": 5813.857537031174, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 119048, "time": 5823.453341722488, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 119120, "time": 5827.621719121933, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 119160, "time": 5831.077882051468, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 119176, "time": 5833.65625834465, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 119352, "time": 5841.710321187973, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 119408, "time": 5845.322646856308, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 119728, "time": 5857.506528377533, "episode/length": 70.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9436619718309859, "episode/intrinsic_return": 0.0}
{"step": 119976, "time": 5867.234487056732, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5891.213783979416, "eval_episode/length": 150.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 120016, "time": 5893.006341457367, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 120016, "time": 5895.515408992767, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 120016, "time": 5897.074980020523, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96045197740113}
{"step": 120016, "time": 5898.997811794281, "eval_episode/length": 26.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 120016, "time": 5900.650995016098, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 120016, "time": 5902.756538391113, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 120016, "time": 5905.343638181686, "eval_episode/length": 220.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 120032, "time": 5905.874147176743, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 120344, "time": 5917.4733209609985, "episode/length": 145.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 120496, "time": 5924.375129938126, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 120712, "time": 5932.836771965027, "episode/length": 169.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 120856, "time": 5939.179126024246, "episode/length": 102.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 121064, "time": 5947.554144382477, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 121176, "time": 5952.883917808533, "episode/length": 265.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 121456, "time": 5963.873467922211, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 121560, "time": 5968.9996945858, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 121816, "time": 5979.881208658218, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 122040, "time": 5989.501871109009, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 122208, "time": 5996.830061674118, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 122240, "time": 5999.576271533966, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662447257383966, "episode/intrinsic_return": 0.0}
{"step": 122648, "time": 6014.5055112838745, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 122752, "time": 6019.736230611801, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 122888, "time": 6025.884412527084, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 123040, "time": 6033.96338057518, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 123408, "time": 6047.812767267227, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 123512, "time": 6052.699076414108, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 123592, "time": 6056.97297501564, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 123760, "time": 6064.4330904483795, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 124040, "time": 6075.00513625145, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 124224, "time": 6082.916362047195, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 124288, "time": 6086.601953029633, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 124632, "time": 6099.453933238983, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 124640, "time": 6102.015196084976, "episode/length": 218.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 124936, "time": 6113.693634986877, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 125128, "time": 6121.662304639816, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 125216, "time": 6126.383317947388, "episode/length": 115.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 125360, "time": 6132.771837949753, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 125560, "time": 6140.707225561142, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 125600, "time": 6143.7493669986725, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 125696, "time": 6148.549907684326, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 125888, "time": 6156.404865026474, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 125944, "time": 6159.91211438179, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 125960, "time": 6161.960737228394, "episode/length": 49.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 126512, "time": 6181.935951471329, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 126768, "time": 6192.186410665512, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 126832, "time": 6195.812384843826, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 127104, "time": 6206.265129566193, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 127120, "time": 6208.406097173691, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 127240, "time": 6213.609751224518, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 127360, "time": 6219.365303516388, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 127432, "time": 6223.1849002838135, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 127552, "time": 6228.938653230667, "episode/length": 38.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 127936, "time": 6243.071377754211, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 128368, "time": 6259.166885852814, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 128440, "time": 6262.929723978043, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 128536, "time": 6267.617710828781, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 128760, "time": 6276.566553354263, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 128888, "time": 6282.5644516944885, "episode/length": 55.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 128944, "time": 6286.240786790848, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 129048, "time": 6290.992275953293, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 129520, "time": 6308.542885303497, "episode/length": 269.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 129800, "time": 6319.222339630127, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6344.248893737793, "eval_episode/length": 77.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 130000, "time": 6348.545425415039, "eval_episode/length": 142.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 130000, "time": 6350.178992509842, "eval_episode/length": 145.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 130000, "time": 6352.878670215607, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 130000, "time": 6354.466467142105, "eval_episode/length": 173.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 130000, "time": 6354.476162672043, "eval_episode/length": 173.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 130000, "time": 6357.819623231888, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 130000, "time": 6360.314692020416, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 130096, "time": 6363.500480890274, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 130152, "time": 6366.640463352203, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 130248, "time": 6371.445114612579, "episode/length": 234.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 130400, "time": 6378.259094953537, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 130496, "time": 6382.974306106567, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 130497, "time": 6385.071638584137, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.646042219555105, "train/action_min": 0.0, "train/action_std": 3.811989158164454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05497423431459274, "train/actor_opt_grad_steps": 7400.0, "train/actor_opt_loss": 14.076829872058548, "train/adv_mag": 0.9834771247310493, "train/adv_max": 0.9762142628203822, "train/adv_mean": 0.0074953220329000364, "train/adv_min": -0.5446717311407774, "train/adv_std": 0.09624692234601684, "train/cont_avg": 0.9944239026717557, "train/cont_loss_mean": 0.0005670159062452262, "train/cont_loss_std": 0.016172706609629082, "train/cont_neg_acc": 0.985538593685354, "train/cont_neg_loss": 0.048399057852529535, "train/cont_pos_acc": 0.9999174225421352, "train/cont_pos_loss": 0.0003123485793034526, "train/cont_pred": 0.9943649204632709, "train/cont_rate": 0.9944239026717557, "train/dyn_loss_mean": 12.537114288970715, "train/dyn_loss_std": 8.310450783212676, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.169302185528151, "train/extr_critic_critic_opt_grad_steps": 7400.0, "train/extr_critic_critic_opt_loss": 15358.259743260973, "train/extr_critic_mag": 3.374697870880593, "train/extr_critic_max": 3.374697870880593, "train/extr_critic_mean": 0.9258317105642712, "train/extr_critic_min": -0.11596103296935104, "train/extr_critic_std": 0.8081316201741459, "train/extr_return_normed_mag": 1.9586798662447746, "train/extr_return_normed_max": 1.9586798662447746, "train/extr_return_normed_mean": 0.3653003199182394, "train/extr_return_normed_min": -0.20596731789694486, "train/extr_return_normed_std": 0.3454625032102789, "train/extr_return_rate": 0.5621645678090685, "train/extr_return_raw_mag": 4.8960817406195725, "train/extr_return_raw_max": 4.8960817406195725, "train/extr_return_raw_mean": 0.9443740030281417, "train/extr_return_raw_min": -0.47366997133229527, "train/extr_return_raw_std": 0.8570729161946828, "train/extr_reward_mag": 1.0067773848089554, "train/extr_reward_max": 1.0067773848089554, "train/extr_reward_mean": 0.01808251259948006, "train/extr_reward_min": -0.38592853345943773, "train/extr_reward_std": 0.11715718159693798, "train/image_loss_mean": 14.494356766911864, "train/image_loss_std": 16.1057855955517, "train/model_loss_mean": 22.071337496051353, "train/model_loss_std": 19.691308909700115, "train/model_opt_grad_norm": 94.13107558030349, "train/model_opt_grad_steps": 7389.213740458015, "train/model_opt_loss": 14198.006470658396, "train/model_opt_model_opt_grad_overflow": 0.007633587786259542, "train/model_opt_model_opt_grad_scale": 639.3129770992366, "train/policy_entropy_mag": 2.367670133823657, "train/policy_entropy_max": 2.367670133823657, "train/policy_entropy_mean": 0.7507469058036804, "train/policy_entropy_min": 0.0793790656874198, "train/policy_entropy_std": 0.5436701501598795, "train/policy_logprob_mag": 7.438331378325251, "train/policy_logprob_max": -0.00945671044915687, "train/policy_logprob_mean": -0.7496663978081624, "train/policy_logprob_min": -7.438331378325251, "train/policy_logprob_std": 1.1802730178105012, "train/policy_randomness_mag": 0.835683657012823, "train/policy_randomness_max": 0.835683657012823, "train/policy_randomness_mean": 0.26498071235099824, "train/policy_randomness_min": 0.028017326762885538, "train/policy_randomness_std": 0.1918917058305886, "train/post_ent_mag": 49.180373737830244, "train/post_ent_max": 49.180373737830244, "train/post_ent_mean": 35.46175503912773, "train/post_ent_min": 19.16402990763424, "train/post_ent_std": 5.327724358507695, "train/prior_ent_mag": 60.95869652551549, "train/prior_ent_max": 60.95869652551549, "train/prior_ent_mean": 48.19485048483346, "train/prior_ent_min": 24.224258786849393, "train/prior_ent_std": 6.847148527625863, "train/rep_loss_mean": 12.537114288970715, "train/rep_loss_std": 8.310450783212676, "train/reward_avg": 0.016206464620008496, "train/reward_loss_mean": 0.054145164816206647, "train/reward_loss_std": 0.28116111730346244, "train/reward_max_data": 1.0145038202518726, "train/reward_max_pred": 1.0035860156284944, "train/reward_neg_acc": 0.993942151087841, "train/reward_neg_loss": 0.03241045979199974, "train/reward_pos_acc": 0.926888505921109, "train/reward_pos_loss": 1.0593974431052462, "train/reward_pred": 0.01496675125685812, "train/reward_rate": 0.02123837070610687, "train_stats/sum_log_reward": 4.175630192796723, "train_stats/max_log_achievement_collect_drink": 5.966386554621849, "train_stats/max_log_achievement_collect_sapling": 2.857142857142857, "train_stats/max_log_achievement_collect_wood": 2.2436974789915967, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2184873949579832, "train_stats/max_log_achievement_eat_cow": 0.13445378151260504, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.03361344537815126, "train_stats/max_log_achievement_place_plant": 2.3361344537815127, "train_stats/max_log_achievement_place_table": 0.7142857142857143, "train_stats/max_log_achievement_wake_up": 1.3277310924369747, "train_stats/mean_log_entropy": 0.723068859647302, "eval_stats/sum_log_reward": 4.433333267768224, "eval_stats/max_log_achievement_collect_drink": 6.166666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_wood": 2.3333333333333335, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_table": 0.7916666666666666, "eval_stats/max_log_achievement_wake_up": 1.5416666666666667, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.09523809523809523, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03508771929824561, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0036651017144322395, "report/cont_loss_std": 0.11678381264209747, "report/cont_neg_acc": 0.8888888955116272, "report/cont_neg_loss": 0.4155077040195465, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3295474673213903e-05, "report/cont_pred": 0.9921518564224243, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 13.910771369934082, "report/dyn_loss_std": 8.476441383361816, "report/image_loss_mean": 14.922861099243164, "report/image_loss_std": 13.184652328491211, "report/model_loss_mean": 23.332265853881836, "report/model_loss_std": 17.07769203186035, "report/post_ent_mag": 51.374305725097656, "report/post_ent_max": 51.374305725097656, "report/post_ent_mean": 35.818504333496094, "report/post_ent_min": 19.724491119384766, "report/post_ent_std": 5.361984729766846, "report/prior_ent_mag": 62.01428985595703, "report/prior_ent_max": 62.01428985595703, "report/prior_ent_mean": 49.67796325683594, "report/prior_ent_min": 28.465961456298828, "report/prior_ent_std": 6.2048540115356445, "report/rep_loss_mean": 13.910771369934082, "report/rep_loss_std": 8.476441383361816, "report/reward_avg": 0.01718749850988388, "report/reward_loss_mean": 0.059277039021253586, "report/reward_loss_std": 0.25800907611846924, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0085062980651855, "report/reward_neg_acc": 0.9929929971694946, "report/reward_neg_loss": 0.035478394478559494, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 1.0102709531784058, "report/reward_pred": 0.014638856053352356, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.9113863497041166e-05, "eval/cont_loss_std": 0.001543867983855307, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00019037898164242506, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.8837413487490267e-05, "eval/cont_pred": 0.9979997277259827, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.44448471069336, "eval/dyn_loss_std": 9.300077438354492, "eval/image_loss_mean": 34.44786071777344, "eval/image_loss_std": 44.01546096801758, "eval/model_loss_mean": 44.39801788330078, "eval/model_loss_std": 47.01909637451172, "eval/post_ent_mag": 49.50389099121094, "eval/post_ent_max": 49.50389099121094, "eval/post_ent_mean": 35.150489807128906, "eval/post_ent_min": 19.806991577148438, "eval/post_ent_std": 5.361812591552734, "eval/prior_ent_mag": 62.01428985595703, "eval/prior_ent_max": 62.01428985595703, "eval/prior_ent_mean": 47.28092575073242, "eval/prior_ent_min": 22.101850509643555, "eval/prior_ent_std": 8.476954460144043, "eval/rep_loss_mean": 16.44448471069336, "eval/rep_loss_std": 9.300077438354492, "eval/reward_avg": 0.01728515699505806, "eval/reward_loss_mean": 0.08341854810714722, "eval/reward_loss_std": 0.6788429021835327, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023000240325928, "eval/reward_neg_acc": 0.9960159659385681, "eval/reward_neg_loss": 0.010753635317087173, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 3.7311973571777344, "eval/reward_pred": 0.0075049204751849174, "eval/reward_rate": 0.01953125, "replay/size": 129993.0, "replay/inserts": 21096.0, "replay/samples": 21088.0, "replay/insert_wait_avg": 1.476136038689438e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.529055159804672e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26768.0, "eval_replay/inserts": 5448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.31432180362651e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1299002170563, "timer/env.step_count": 2637.0, "timer/env.step_total": 261.3639175891876, "timer/env.step_frac": 0.2613299707692614, "timer/env.step_avg": 0.09911411360985499, "timer/env.step_min": 0.022747516632080078, "timer/env.step_max": 2.8558759689331055, "timer/replay._sample_count": 21088.0, "timer/replay._sample_total": 11.384709119796753, "timer/replay._sample_frac": 0.011383230435692355, "timer/replay._sample_avg": 0.0005398667071223801, "timer/replay._sample_min": 0.0003962516784667969, "timer/replay._sample_max": 0.011404275894165039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3318.0, "timer/agent.policy_total": 56.42258334159851, "timer/agent.policy_frac": 0.05641525498773032, "timer/agent.policy_avg": 0.017004997993248495, "timer/agent.policy_min": 0.009441852569580078, "timer/agent.policy_max": 0.1583869457244873, "timer/dataset_train_count": 1318.0, "timer/dataset_train_total": 0.1443319320678711, "timer/dataset_train_frac": 0.0001443131857537176, "timer/dataset_train_avg": 0.00010950829443692799, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0003528594970703125, "timer/agent.train_count": 1318.0, "timer/agent.train_total": 585.6976771354675, "timer/agent.train_frac": 0.5856216047618961, "timer/agent.train_avg": 0.44438367005725915, "timer/agent.train_min": 0.4348585605621338, "timer/agent.train_max": 1.3450911045074463, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4747300148010254, "timer/agent.report_frac": 0.00047466835527864497, "timer/agent.report_avg": 0.2373650074005127, "timer/agent.report_min": 0.2306804656982422, "timer/agent.report_max": 0.2440495491027832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0036839174868375e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.092988341742206}
{"step": 130536, "time": 6386.44864821434, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 131184, "time": 6411.042152166367, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 131488, "time": 6422.808755159378, "episode/length": 166.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 131600, "time": 6428.204271316528, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 131800, "time": 6436.27201795578, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 131856, "time": 6439.851628303528, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 131928, "time": 6443.625403642654, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 132072, "time": 6450.649926900864, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 132216, "time": 6457.1238803863525, "episode/length": 90.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 132456, "time": 6466.816214323044, "episode/length": 244.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 132672, "time": 6475.733602046967, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 132904, "time": 6484.655077934265, "episode/length": 28.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 132912, "time": 6486.742628097534, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 133072, "time": 6493.652199983597, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 133456, "time": 6507.867883682251, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 133512, "time": 6511.020642518997, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 133544, "time": 6513.6326315402985, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 133696, "time": 6520.6865355968475, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 133808, "time": 6526.0513479709625, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 134384, "time": 6546.719202280045, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 134600, "time": 6555.48597240448, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 134952, "time": 6568.81982755661, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 134968, "time": 6571.029881000519, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 135032, "time": 6574.746531009674, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 135168, "time": 6581.226761341095, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 135232, "time": 6585.416423559189, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 135464, "time": 6595.111010789871, "episode/length": 107.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 135488, "time": 6597.815592288971, "episode/length": 39.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 135504, "time": 6599.903141260147, "episode/length": 68.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 135856, "time": 6613.231423854828, "episode/length": 292.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 135864, "time": 6615.270281553268, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 136584, "time": 6640.800152301788, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 136592, "time": 6642.8452231884, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 137160, "time": 6663.11754322052, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 137232, "time": 6667.376611471176, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 137248, "time": 6669.661005020142, "episode/length": 251.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 137400, "time": 6676.059061765671, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 137456, "time": 6679.802408456802, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 137744, "time": 6691.065427780151, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 137752, "time": 6692.721965074539, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 137864, "time": 6698.112645149231, "episode/length": 299.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 138136, "time": 6708.719938993454, "episode/length": 192.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 138328, "time": 6716.642946243286, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 138456, "time": 6722.566464185715, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 138680, "time": 6731.62917137146, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 138784, "time": 6736.799880981445, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 138896, "time": 6741.982880115509, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 139448, "time": 6763.403849840164, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 139512, "time": 6767.220687627792, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 139560, "time": 6770.373549222946, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 139632, "time": 6774.608682155609, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 139728, "time": 6779.322865724564, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6792.87279343605, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6812.325775146484, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 140088, "time": 6814.144202947617, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 140088, "time": 6816.062138557434, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 140088, "time": 6818.157324790955, "eval_episode/length": 172.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9595375722543352}
{"step": 140088, "time": 6820.331736564636, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 140088, "time": 6822.026880741119, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 140088, "time": 6824.280075073242, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 140088, "time": 6824.288259983063, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 140168, "time": 6828.49130821228, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 140224, "time": 6832.091206789017, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 140392, "time": 6839.057796955109, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 140464, "time": 6843.243123054504, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 140760, "time": 6854.429248332977, "episode/length": 128.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 140872, "time": 6859.719948291779, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 140880, "time": 6861.730075120926, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 140928, "time": 6865.002689123154, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 141424, "time": 6883.208203792572, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 141520, "time": 6887.923581123352, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 141752, "time": 6896.977639436722, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 141904, "time": 6903.656456232071, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 142056, "time": 6910.03275179863, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 142168, "time": 6915.390399932861, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 142448, "time": 6926.386169672012, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 142792, "time": 6939.247148513794, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 142816, "time": 6941.819115638733, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 142944, "time": 6947.710859537125, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 143400, "time": 6964.189617156982, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 143552, "time": 6971.2129373550415, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 144008, "time": 6987.608604669571, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 144040, "time": 6990.14718413353, "episode/length": 285.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 144096, "time": 6993.735538244247, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 144432, "time": 7006.8185703754425, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 144432, "time": 7006.848764181137, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 144640, "time": 7017.713633298874, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 144760, "time": 7023.059699058533, "episode/length": 93.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 144776, "time": 7025.128748893738, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 7041.742515325546, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 145512, "time": 7052.943493843079, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 145744, "time": 7062.688506603241, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 145752, "time": 7064.2206428050995, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 146048, "time": 7075.851825475693, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 146384, "time": 7088.723319768906, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 146416, "time": 7091.306289196014, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 146512, "time": 7096.034583091736, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 146528, "time": 7098.00229883194, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 146544, "time": 7100.082752943039, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 146832, "time": 7111.215835094452, "episode/length": 51.0, "episode/score": -0.8999999985098839, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 147048, "time": 7119.778732776642, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 147120, "time": 7123.962852239609, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 147432, "time": 7135.610243320465, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 147768, "time": 7149.771969795227, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 148056, "time": 7160.811496734619, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 148120, "time": 7164.521701335907, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 148152, "time": 7167.383786201477, "episode/length": 164.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 148352, "time": 7175.719393968582, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 148432, "time": 7180.014502763748, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 148504, "time": 7183.794279336929, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 148952, "time": 7200.367730140686, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 149352, "time": 7215.2398109436035, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 149416, "time": 7218.854193210602, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 149472, "time": 7222.348344326019, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 149672, "time": 7230.223185062408, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 149728, "time": 7233.89022564888, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 149776, "time": 7237.015071630478, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 149992, "time": 7245.646737337112, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7269.824858903885, "eval_episode/length": 154.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 150072, "time": 7271.510401010513, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 150072, "time": 7273.427424192429, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 150072, "time": 7276.452317714691, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 150072, "time": 7278.191376686096, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 150072, "time": 7279.982484340668, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 150072, "time": 7282.218685388565, "eval_episode/length": 213.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 150072, "time": 7284.329121828079, "eval_episode/length": 225.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 150752, "time": 7307.110002040863, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 150856, "time": 7311.895919799805, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 151128, "time": 7322.540336847305, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 151152, "time": 7325.048008918762, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 151232, "time": 7329.370083808899, "episode/length": 59.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 151256, "time": 7331.463573217392, "episode/length": 49.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 151440, "time": 7339.383365869522, "episode/length": 207.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 151552, "time": 7344.552430391312, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 151728, "time": 7351.909818410873, "episode/length": 35.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 151808, "time": 7356.052571773529, "episode/length": 266.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 152384, "time": 7376.832764387131, "episode/length": 298.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 152569, "time": 7385.355246067047, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.205705283344656, "train/action_min": 0.0, "train/action_std": 3.477235096088354, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0506054133284783, "train/actor_opt_grad_steps": 8745.0, "train/actor_opt_loss": 1.9328497962459275, "train/adv_mag": 0.8841539539288783, "train/adv_max": 0.8772461219974186, "train/adv_mean": 0.004862215633350559, "train/adv_min": -0.5286111220501472, "train/adv_std": 0.08796790225998215, "train/cont_avg": 0.9945722939311594, "train/cont_loss_mean": 0.00036814255713373814, "train/cont_loss_std": 0.010347508555996419, "train/cont_neg_acc": 0.9833072658872952, "train/cont_neg_loss": 0.041092351296256775, "train/cont_pos_acc": 0.9999714757221333, "train/cont_pos_loss": 0.0001484869074450571, "train/cont_pred": 0.9945636849472488, "train/cont_rate": 0.9945722939311594, "train/dyn_loss_mean": 13.240337192148402, "train/dyn_loss_std": 8.512370413628178, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0885688424974247, "train/extr_critic_critic_opt_grad_steps": 8745.0, "train/extr_critic_critic_opt_loss": 15360.313653475996, "train/extr_critic_mag": 3.6541909756867783, "train/extr_critic_max": 3.6541909756867783, "train/extr_critic_mean": 0.9107782352661741, "train/extr_critic_min": -0.15659891781599625, "train/extr_critic_std": 0.8780460266963296, "train/extr_return_normed_mag": 1.919914172179457, "train/extr_return_normed_max": 1.919914172179457, "train/extr_return_normed_mean": 0.3471553568606791, "train/extr_return_normed_min": -0.18866320278333581, "train/extr_return_normed_std": 0.34607012969428214, "train/extr_return_rate": 0.5045308981468712, "train/extr_return_raw_mag": 5.097923016202623, "train/extr_return_raw_max": 5.097923016202623, "train/extr_return_raw_mean": 0.9237182619779006, "train/extr_return_raw_min": -0.4982198857958766, "train/extr_return_raw_std": 0.9184513644895692, "train/extr_reward_mag": 1.007893158905748, "train/extr_reward_max": 1.007893158905748, "train/extr_reward_mean": 0.01863714564335195, "train/extr_reward_min": -0.37224400129871094, "train/extr_reward_std": 0.11946143506877664, "train/image_loss_mean": 12.584796090056932, "train/image_loss_std": 15.002807271653328, "train/model_loss_mean": 20.58278577224068, "train/model_loss_std": 18.628810447195303, "train/model_opt_grad_norm": 81.76622519285783, "train/model_opt_grad_steps": 8732.797101449276, "train/model_opt_loss": 13446.292324784874, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 647.6449275362319, "train/policy_entropy_mag": 2.46551958028821, "train/policy_entropy_max": 2.46551958028821, "train/policy_entropy_mean": 0.6898746602777122, "train/policy_entropy_min": 0.07937712929602983, "train/policy_entropy_std": 0.5619305527728536, "train/policy_logprob_mag": 7.438357460326043, "train/policy_logprob_max": -0.009456336100086353, "train/policy_logprob_mean": -0.6892757536708445, "train/policy_logprob_min": -7.438357460326043, "train/policy_logprob_std": 1.1759131006572558, "train/policy_randomness_mag": 0.8702202149923297, "train/policy_randomness_max": 0.8702202149923297, "train/policy_randomness_mean": 0.24349548062984494, "train/policy_randomness_min": 0.028016643220747726, "train/policy_randomness_std": 0.1983368273662484, "train/post_ent_mag": 51.00511202604874, "train/post_ent_max": 51.00511202604874, "train/post_ent_mean": 36.313590257064156, "train/post_ent_min": 19.56904855672864, "train/post_ent_std": 5.698235726010973, "train/prior_ent_mag": 62.23238121253857, "train/prior_ent_max": 62.23238121253857, "train/prior_ent_mean": 49.72378341011379, "train/prior_ent_min": 25.44546109351559, "train/prior_ent_std": 6.66707840518675, "train/rep_loss_mean": 13.240337192148402, "train/rep_loss_std": 8.512370413628178, "train/reward_avg": 0.017476930239143363, "train/reward_loss_mean": 0.053419370636128, "train/reward_loss_std": 0.27864146702315495, "train/reward_max_data": 1.0094202921010447, "train/reward_max_pred": 1.003667800322823, "train/reward_neg_acc": 0.9934977647187053, "train/reward_neg_loss": 0.031070005492833647, "train/reward_pos_acc": 0.9358382976573446, "train/reward_pos_loss": 1.0275128850902335, "train/reward_pred": 0.016231142463621454, "train/reward_rate": 0.022319406702898552, "train_stats/sum_log_reward": 4.471900773442481, "train_stats/max_log_achievement_collect_drink": 5.520661157024794, "train_stats/max_log_achievement_collect_sapling": 2.6115702479338845, "train_stats/max_log_achievement_collect_wood": 3.074380165289256, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2975206611570248, "train_stats/max_log_achievement_eat_cow": 0.03305785123966942, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.049586776859504134, "train_stats/max_log_achievement_make_wood_sword": 0.0743801652892562, "train_stats/max_log_achievement_place_plant": 2.2231404958677685, "train_stats/max_log_achievement_place_table": 1.1735537190082646, "train_stats/max_log_achievement_wake_up": 1.462809917355372, "train_stats/mean_log_entropy": 0.6740977860186711, "eval_stats/sum_log_reward": 4.912499845027924, "eval_stats/max_log_achievement_collect_drink": 4.6875, "eval_stats/max_log_achievement_collect_sapling": 3.5625, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 3.375, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_stone": 0.02127659574468085, "eval_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 8.296393934870139e-05, "report/cont_loss_std": 0.0025583745446056128, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.01185540296137333, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.934384727064753e-06, "report/cont_pred": 0.9932399988174438, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.879789352416992, "report/dyn_loss_std": 8.439139366149902, "report/image_loss_mean": 10.632083892822266, "report/image_loss_std": 12.692059516906738, "report/model_loss_mean": 18.416664123535156, "report/model_loss_std": 16.36847686767578, "report/post_ent_mag": 51.633995056152344, "report/post_ent_max": 51.633995056152344, "report/post_ent_mean": 36.16651916503906, "report/post_ent_min": 19.80996322631836, "report/post_ent_std": 5.9207763671875, "report/prior_ent_mag": 63.19850540161133, "report/prior_ent_max": 63.19850540161133, "report/prior_ent_mean": 49.28484344482422, "report/prior_ent_min": 26.849185943603516, "report/prior_ent_std": 6.37560510635376, "report/rep_loss_mean": 12.879789352416992, "report/rep_loss_std": 8.439139366149902, "report/reward_avg": 0.02421874925494194, "report/reward_loss_mean": 0.05662404000759125, "report/reward_loss_std": 0.2372795194387436, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0648207664489746, "report/reward_neg_acc": 0.9899294972419739, "report/reward_neg_loss": 0.03211271017789841, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.8417771458625793, "report/reward_pred": 0.024350134655833244, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0011907946318387985, "eval/cont_loss_std": 0.024568721652030945, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003979253116995096, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.001171601703390479, "eval/cont_pred": 0.9922762513160706, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.26317596435547, "eval/dyn_loss_std": 8.205575942993164, "eval/image_loss_mean": 20.24717140197754, "eval/image_loss_std": 27.643484115600586, "eval/model_loss_mean": 30.135658264160156, "eval/model_loss_std": 30.359146118164062, "eval/post_ent_mag": 48.31404113769531, "eval/post_ent_max": 48.31404113769531, "eval/post_ent_mean": 36.6172981262207, "eval/post_ent_min": 21.0452938079834, "eval/post_ent_std": 4.663250923156738, "eval/prior_ent_mag": 63.19850540161133, "eval/prior_ent_max": 63.19850540161133, "eval/prior_ent_mean": 49.053157806396484, "eval/prior_ent_min": 27.655574798583984, "eval/prior_ent_std": 5.352644920349121, "eval/rep_loss_mean": 16.26317596435547, "eval/rep_loss_std": 8.205575942993164, "eval/reward_avg": 0.006054687313735485, "eval/reward_loss_mean": 0.12939110398292542, "eval/reward_loss_std": 0.9126326441764832, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026695728302002, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0967814102768898, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.6654210090637207, "eval/reward_pred": 0.003580670338124037, "eval/reward_rate": 0.0126953125, "replay/size": 152065.0, "replay/inserts": 22072.0, "replay/samples": 22080.0, "replay/insert_wait_avg": 1.49115309761935e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.457054345504098e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30176.0, "eval_replay/inserts": 3408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2759031824102984e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.269288778305, "timer/env.step_count": 2759.0, "timer/env.step_total": 263.4170751571655, "timer/env.step_frac": 0.2633461589917393, "timer/env.step_avg": 0.09547556185471748, "timer/env.step_min": 0.022841930389404297, "timer/env.step_max": 3.9236607551574707, "timer/replay._sample_count": 22080.0, "timer/replay._sample_total": 12.0891752243042, "timer/replay._sample_frac": 0.012085920621505342, "timer/replay._sample_avg": 0.0005475169938543568, "timer/replay._sample_min": 0.00040149688720703125, "timer/replay._sample_max": 0.02763986587524414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3185.0, "timer/agent.policy_total": 53.11057662963867, "timer/agent.policy_frac": 0.053096278397696414, "timer/agent.policy_avg": 0.016675220291880274, "timer/agent.policy_min": 0.009540796279907227, "timer/agent.policy_max": 0.0988922119140625, "timer/dataset_train_count": 1380.0, "timer/dataset_train_total": 0.14537429809570312, "timer/dataset_train_frac": 0.00014533516096776135, "timer/dataset_train_avg": 0.00010534369427224864, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00040793418884277344, "timer/agent.train_count": 1380.0, "timer/agent.train_total": 619.5199551582336, "timer/agent.train_frac": 0.6193531702996643, "timer/agent.train_avg": 0.44892750373785045, "timer/agent.train_min": 0.436370849609375, "timer/agent.train_max": 1.5079772472381592, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722318649291992, "timer/agent.report_frac": 0.0004721047324225731, "timer/agent.report_avg": 0.2361159324645996, "timer/agent.report_min": 0.23003101348876953, "timer/agent.report_max": 0.2422008514404297, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7887463973779287e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.065745035643495}
{"step": 152744, "time": 7391.199140548706, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 152840, "time": 7396.007400512695, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 153080, "time": 7405.5725610256195, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 153184, "time": 7410.849016666412, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 153448, "time": 7421.16956281662, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 153488, "time": 7424.343702793121, "episode/length": 92.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 153496, "time": 7426.066815376282, "episode/length": 210.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 153960, "time": 7443.11660027504, "episode/length": 58.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 153968, "time": 7445.220805883408, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 154120, "time": 7451.640784978867, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 154384, "time": 7462.149563789368, "episode/length": 353.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9858757062146892, "episode/intrinsic_return": 0.0}
{"step": 154536, "time": 7468.476996421814, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 154840, "time": 7480.285642623901, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9590909090909091, "episode/intrinsic_return": 0.0}
{"step": 154864, "time": 7482.893155574799, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 155232, "time": 7496.510456562042, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 155600, "time": 7510.287349224091, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 155896, "time": 7522.852792739868, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 156168, "time": 7533.656795978546, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 156288, "time": 7539.567567110062, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 156384, "time": 7544.430100917816, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 156400, "time": 7546.4971668720245, "episode/length": 251.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 156520, "time": 7551.810835123062, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 156672, "time": 7558.6251611709595, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9606986899563319, "episode/intrinsic_return": 0.0}
{"step": 157240, "time": 7578.822758197784, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 157320, "time": 7583.143201828003, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 157368, "time": 7586.2761471271515, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 157648, "time": 7597.357267379761, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 157744, "time": 7602.30969119072, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 157896, "time": 7608.656905174255, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 157920, "time": 7611.178511381149, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 157952, "time": 7613.860124349594, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 158512, "time": 7634.004151344299, "episode/length": 148.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 158552, "time": 7636.701308250427, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 159000, "time": 7653.156386137009, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 159088, "time": 7657.689519405365, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 159440, "time": 7671.176870584488, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 159456, "time": 7673.246367692947, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 159664, "time": 7681.687947750092, "episode/length": 251.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 159752, "time": 7685.928718090057, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 159800, "time": 7689.14045214653, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7713.567973852158, "eval_episode/length": 34.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 160056, "time": 7715.480366945267, "eval_episode/length": 41.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 160056, "time": 7723.667407035828, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 160056, "time": 7725.451495885849, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 160056, "time": 7727.269083738327, "eval_episode/length": 206.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 160056, "time": 7729.464074611664, "eval_episode/length": 221.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 160056, "time": 7729.472571611404, "eval_episode/length": 221.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 160056, "time": 7733.721229314804, "eval_episode/length": 242.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 160064, "time": 7734.212980508804, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 160320, "time": 7744.242065668106, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 160720, "time": 7759.052228450775, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 160784, "time": 7762.580436706543, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 160864, "time": 7766.711011886597, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 160912, "time": 7769.827173471451, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 161360, "time": 7786.296391010284, "episode/length": 237.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 161632, "time": 7796.884894132614, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 161640, "time": 7798.552903413773, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 162032, "time": 7813.349065065384, "episode/length": 278.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 162152, "time": 7818.782301187515, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 162216, "time": 7822.607340812683, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 162224, "time": 7824.645520687103, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 162560, "time": 7837.361368656158, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 162568, "time": 7839.139117240906, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 163200, "time": 7861.801538944244, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 163392, "time": 7869.766391515732, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 163488, "time": 7874.515979766846, "episode/length": 231.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 163496, "time": 7876.163898944855, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 163824, "time": 7888.755926370621, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 163904, "time": 7894.327680587769, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 163944, "time": 7897.036505699158, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 164264, "time": 7909.29040312767, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 165000, "time": 7935.202234983444, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 165248, "time": 7945.137501478195, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 165256, "time": 7946.715359449387, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 165360, "time": 7952.53075504303, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 165416, "time": 7955.733879804611, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 165496, "time": 7960.118257522583, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 165504, "time": 7962.051264047623, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 165656, "time": 7968.435438156128, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 165872, "time": 7977.407566785812, "episode/length": 56.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 166280, "time": 7992.499470949173, "episode/length": 50.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 166320, "time": 7996.058782815933, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 166632, "time": 8008.146015882492, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 166648, "time": 8010.224629640579, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 166696, "time": 8013.440343141556, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 166704, "time": 8015.4536209106445, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 166712, "time": 8017.127687215805, "episode/length": 150.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 167008, "time": 8028.722532749176, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 167200, "time": 8036.555155992508, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 167712, "time": 8054.923309326172, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 168064, "time": 8067.983978033066, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 168136, "time": 8071.666653394699, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 168184, "time": 8074.925561666489, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 168520, "time": 8087.6809096336365, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 168608, "time": 8092.534588336945, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 168904, "time": 8103.699839830399, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 168976, "time": 8107.9083387851715, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 169056, "time": 8112.334768295288, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 169392, "time": 8125.166632413864, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 169392, "time": 8125.173924207687, "episode/length": 41.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 169424, "time": 8129.476098537445, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 169536, "time": 8134.656712770462, "episode/length": 168.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8169.828758478165, "eval_episode/length": 62.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9365079365079365}
{"step": 170040, "time": 8175.92652797699, "eval_episode/length": 171.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 170040, "time": 8177.67502951622, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9885057471264368}
{"step": 170040, "time": 8177.683279275894, "eval_episode/length": 173.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 170040, "time": 8181.158695936203, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 170040, "time": 8183.956011295319, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 170040, "time": 8185.776371955872, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 170040, "time": 8190.272156000137, "eval_episode/length": 218.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 170064, "time": 8191.300923585892, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 170432, "time": 8205.251471757889, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.0}
{"step": 170496, "time": 8208.935489416122, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 170568, "time": 8212.725267410278, "episode/length": 62.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 170592, "time": 8215.366178035736, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 170632, "time": 8218.103165626526, "episode/length": 206.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 170752, "time": 8223.982289791107, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 170984, "time": 8233.087879896164, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 171664, "time": 8257.328003644943, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 171760, "time": 8262.279689311981, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 171912, "time": 8268.681779146194, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 171952, "time": 8271.807869911194, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 171984, "time": 8274.346183538437, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 171992, "time": 8275.907134771347, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 172280, "time": 8288.322249412537, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 172456, "time": 8295.658067464828, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 172912, "time": 8312.541172504425, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 173176, "time": 8322.608611822128, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 173208, "time": 8325.211699962616, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 173328, "time": 8330.93374323845, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 173480, "time": 8337.291805744171, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 173632, "time": 8344.189600229263, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 173664, "time": 8346.789337396622, "episode/length": 56.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 173752, "time": 8351.2372879982, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 173808, "time": 8355.360149383545, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 173928, "time": 8361.294561386108, "episode/length": 246.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 174376, "time": 8377.584535121918, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 174537, "time": 8385.514389753342, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.719588569972826, "train/action_min": 0.0, "train/action_std": 2.7108833133310513, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05128640225292116, "train/actor_opt_grad_steps": 10125.0, "train/actor_opt_loss": 1.0030459922508916, "train/adv_mag": 0.8728322602700496, "train/adv_max": 0.870908708676048, "train/adv_mean": 0.005668631876661506, "train/adv_min": -0.5072105807670648, "train/adv_std": 0.08873512379933095, "train/cont_avg": 0.9942680027173914, "train/cont_loss_mean": 0.0005405592174558504, "train/cont_loss_std": 0.015826609029478026, "train/cont_neg_acc": 0.9833448373753092, "train/cont_neg_loss": 0.07375963310760594, "train/cont_pos_acc": 0.9999429881572723, "train/cont_pos_loss": 0.00013089226629081307, "train/cont_pred": 0.9942912338436514, "train/cont_rate": 0.9942680027173914, "train/dyn_loss_mean": 14.057064312091772, "train/dyn_loss_std": 8.737787789192753, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.046855900598609, "train/extr_critic_critic_opt_grad_steps": 10125.0, "train/extr_critic_critic_opt_loss": 15294.482520946558, "train/extr_critic_mag": 3.796690014825351, "train/extr_critic_max": 3.796690014825351, "train/extr_critic_mean": 0.9400051365727964, "train/extr_critic_min": -0.1495949816012728, "train/extr_critic_std": 0.8657328378463137, "train/extr_return_normed_mag": 1.9353425831034563, "train/extr_return_normed_max": 1.9353425831034563, "train/extr_return_normed_mean": 0.3394028708554696, "train/extr_return_normed_min": -0.21276546345240827, "train/extr_return_normed_std": 0.3414564528974934, "train/extr_return_rate": 0.552576831717422, "train/extr_return_raw_mag": 5.197901034700697, "train/extr_return_raw_max": 5.197901034700697, "train/extr_return_raw_mean": 0.9551326438136722, "train/extr_return_raw_min": -0.5136265443718951, "train/extr_return_raw_std": 0.9079744332078574, "train/extr_reward_mag": 1.0091477494308914, "train/extr_reward_max": 1.0091477494308914, "train/extr_reward_mean": 0.01969268523912499, "train/extr_reward_min": -0.3879455388456151, "train/extr_reward_std": 0.12376669837512831, "train/image_loss_mean": 11.853564393693123, "train/image_loss_std": 14.402340128801871, "train/model_loss_mean": 20.341906202012215, "train/model_loss_std": 18.072452144346375, "train/model_opt_grad_norm": 77.04738072381504, "train/model_opt_grad_steps": 10111.557971014492, "train/model_opt_loss": 13549.121401579483, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 670.2898550724638, "train/policy_entropy_mag": 2.4784881999527197, "train/policy_entropy_max": 2.4784881999527197, "train/policy_entropy_mean": 0.5661080937454666, "train/policy_entropy_min": 0.07937602623217348, "train/policy_entropy_std": 0.5169364084368167, "train/policy_logprob_mag": 7.438374806141508, "train/policy_logprob_max": -0.009456073325397312, "train/policy_logprob_mean": -0.5658009408608727, "train/policy_logprob_min": -7.438374806141508, "train/policy_logprob_std": 1.10755925938703, "train/policy_randomness_mag": 0.8747975705326467, "train/policy_randomness_max": 0.8747975705326467, "train/policy_randomness_mean": 0.1998113131393557, "train/policy_randomness_min": 0.028016253860424393, "train/policy_randomness_std": 0.1824558682847714, "train/post_ent_mag": 52.392970707105555, "train/post_ent_max": 52.392970707105555, "train/post_ent_mean": 36.91148329472196, "train/post_ent_min": 19.89624297100565, "train/post_ent_std": 5.971230344495911, "train/prior_ent_mag": 63.01801112078238, "train/prior_ent_max": 63.01801112078238, "train/prior_ent_mean": 51.080051753831945, "train/prior_ent_min": 27.614215726437777, "train/prior_ent_std": 6.326581630153933, "train/rep_loss_mean": 14.057064312091772, "train/rep_loss_std": 8.737787789192753, "train/reward_avg": 0.017802451237820198, "train/reward_loss_mean": 0.053562798591303654, "train/reward_loss_std": 0.27211741649586224, "train/reward_max_data": 1.0115942056628242, "train/reward_max_pred": 1.006111150202544, "train/reward_neg_acc": 0.9928947099740955, "train/reward_neg_loss": 0.0315310009215297, "train/reward_pos_acc": 0.9414634834165159, "train/reward_pos_loss": 0.9946300901364589, "train/reward_pred": 0.016858946039354887, "train/reward_rate": 0.022857223731884056, "train_stats/sum_log_reward": 4.802479281898372, "train_stats/max_log_achievement_collect_drink": 4.115702479338843, "train_stats/max_log_achievement_collect_sapling": 2.7355371900826446, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.8925619834710745, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.47107438016528924, "train_stats/max_log_achievement_eat_cow": 0.049586776859504134, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01652892561983471, "train_stats/max_log_achievement_make_wood_sword": 0.049586776859504134, "train_stats/max_log_achievement_place_plant": 2.520661157024793, "train_stats/max_log_achievement_place_table": 1.4545454545454546, "train_stats/max_log_achievement_wake_up": 1.396694214876033, "train_stats/mean_log_entropy": 0.5521856780387153, "eval_stats/sum_log_reward": 4.912499897181988, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.17935373459477e-05, "report/cont_loss_std": 0.00011265674402238801, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001395461440552026, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.1370975193567574e-05, "report/cont_pred": 0.9960630536079407, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.78561019897461, "report/dyn_loss_std": 7.976874828338623, "report/image_loss_mean": 10.59404182434082, "report/image_loss_std": 14.530426025390625, "report/model_loss_mean": 18.316242218017578, "report/model_loss_std": 17.79075050354004, "report/post_ent_mag": 50.64826965332031, "report/post_ent_max": 50.64826965332031, "report/post_ent_mean": 36.24263000488281, "report/post_ent_min": 20.047256469726562, "report/post_ent_std": 5.9336771965026855, "report/prior_ent_mag": 63.10447692871094, "report/prior_ent_max": 63.10447692871094, "report/prior_ent_mean": 49.83197021484375, "report/prior_ent_min": 28.046829223632812, "report/prior_ent_std": 6.662600994110107, "report/rep_loss_mean": 12.78561019897461, "report/rep_loss_std": 7.976874828338623, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.05080131068825722, "report/reward_loss_std": 0.271920382976532, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0097384452819824, "report/reward_neg_acc": 0.9929789304733276, "report/reward_neg_loss": 0.023734865710139275, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 1.0502548217773438, "report/reward_pred": 0.018164679408073425, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.004122020211070776, "eval/cont_loss_std": 0.13078463077545166, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 0.5981862545013428, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.308197119622491e-05, "eval/cont_pred": 0.9940930604934692, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 12.710392951965332, "eval/dyn_loss_std": 8.334962844848633, "eval/image_loss_mean": 17.436920166015625, "eval/image_loss_std": 34.03964614868164, "eval/model_loss_mean": 25.134796142578125, "eval/model_loss_std": 36.53496170043945, "eval/post_ent_mag": 48.871856689453125, "eval/post_ent_max": 48.871856689453125, "eval/post_ent_mean": 37.382408142089844, "eval/post_ent_min": 20.37916374206543, "eval/post_ent_std": 5.028581142425537, "eval/prior_ent_mag": 63.10447692871094, "eval/prior_ent_max": 63.10447692871094, "eval/prior_ent_mean": 49.121097564697266, "eval/prior_ent_min": 27.104351043701172, "eval/prior_ent_std": 5.904078960418701, "eval/rep_loss_mean": 12.710392951965332, "eval/rep_loss_std": 8.334962844848633, "eval/reward_avg": 0.01621093787252903, "eval/reward_loss_mean": 0.06751968711614609, "eval/reward_loss_std": 0.44377976655960083, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022611618041992, "eval/reward_neg_acc": 0.9970089793205261, "eval/reward_neg_loss": 0.03663146123290062, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.5428004264831543, "eval/reward_pred": 0.012493275105953217, "eval/reward_rate": 0.0205078125, "replay/size": 174033.0, "replay/inserts": 21968.0, "replay/samples": 21968.0, "replay/insert_wait_avg": 1.4560702762200897e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.474012856924525e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34376.0, "eval_replay/inserts": 4200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3078394390287854e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3113021850585938e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1470122337341, "timer/env.step_count": 2746.0, "timer/env.step_total": 264.7506082057953, "timer/env.step_frac": 0.2647116923486076, "timer/env.step_avg": 0.09641318579963412, "timer/env.step_min": 0.022453784942626953, "timer/env.step_max": 3.277467727661133, "timer/replay._sample_count": 21968.0, "timer/replay._sample_total": 11.529768466949463, "timer/replay._sample_frac": 0.01152807369908431, "timer/replay._sample_avg": 0.000524843794016272, "timer/replay._sample_min": 0.00038361549377441406, "timer/replay._sample_max": 0.010516166687011719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3271.0, "timer/agent.policy_total": 54.840054988861084, "timer/agent.policy_frac": 0.05483199401494085, "timer/agent.policy_avg": 0.016765531944011338, "timer/agent.policy_min": 0.009350061416625977, "timer/agent.policy_max": 0.16563820838928223, "timer/dataset_train_count": 1373.0, "timer/dataset_train_total": 0.1473710536956787, "timer/dataset_train_frac": 0.00014734939153249015, "timer/dataset_train_avg": 0.00010733507188323286, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0010845661163330078, "timer/agent.train_count": 1373.0, "timer/agent.train_total": 612.4735329151154, "timer/agent.train_frac": 0.6123835050481363, "timer/agent.train_avg": 0.4460841463329318, "timer/agent.train_min": 0.43378281593322754, "timer/agent.train_max": 1.4570088386535645, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46967029571533203, "timer/agent.report_frac": 0.000469601258585343, "timer/agent.report_avg": 0.23483514785766602, "timer/agent.report_min": 0.22379183769226074, "timer/agent.report_max": 0.2458784580230713, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955955819191576e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 21.96448155451455}
{"step": 174544, "time": 8385.54071354866, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 175064, "time": 8404.786242723465, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 175064, "time": 8404.795758962631, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 175112, "time": 8409.793821811676, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 175264, "time": 8416.750346422195, "episode/length": 181.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 175520, "time": 8426.70049571991, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 175544, "time": 8428.920467376709, "episode/length": 53.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 175752, "time": 8437.335574626923, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 175784, "time": 8440.186584949493, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 175888, "time": 8445.362327337265, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 176552, "time": 8469.420303344727, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 176768, "time": 8478.988125801086, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 176976, "time": 8487.440856695175, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 177072, "time": 8492.082905292511, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 177120, "time": 8495.185264587402, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 177488, "time": 8509.146403551102, "episode/length": 216.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 177512, "time": 8511.346274614334, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 177576, "time": 8515.166340112686, "episode/length": 56.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 177736, "time": 8522.088719367981, "episode/length": 308.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 177752, "time": 8524.123229265213, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 178072, "time": 8536.343163490295, "episode/length": 61.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 178200, "time": 8542.19264626503, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 178608, "time": 8557.578337907791, "episode/length": 229.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 178632, "time": 8559.875056505203, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 178920, "time": 8570.96669960022, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 179360, "time": 8587.595126628876, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 179576, "time": 8596.219296455383, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 179840, "time": 8606.828351974487, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 179840, "time": 8606.83722448349, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 179960, "time": 8614.003155469894, "episode/length": 235.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8633.132125139236, "eval_episode/length": 41.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 180024, "time": 8639.617958068848, "eval_episode/length": 113.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 180024, "time": 8641.269800186157, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 180024, "time": 8643.661941051483, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 180024, "time": 8646.6511759758, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 180024, "time": 8646.66026377678, "eval_episode/length": 212.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 180024, "time": 8650.207912683487, "eval_episode/length": 214.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 180024, "time": 8652.04611325264, "eval_episode/length": 221.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 180160, "time": 8656.725838661194, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 180432, "time": 8668.667732954025, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 180488, "time": 8671.845179319382, "episode/length": 371.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 180600, "time": 8677.08116197586, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 181024, "time": 8692.929263830185, "episode/length": 73.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 181168, "time": 8699.325347661972, "episode/length": 198.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 181352, "time": 8706.76342177391, "episode/length": 40.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 181400, "time": 8710.052315235138, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 181472, "time": 8714.21733880043, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 181704, "time": 8723.323005199432, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 181832, "time": 8729.128497123718, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 181896, "time": 8732.742979049683, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 181976, "time": 8736.901054143906, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 182096, "time": 8742.794936656952, "episode/length": 48.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 182528, "time": 8758.579878091812, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 182600, "time": 8762.155165195465, "episode/length": 62.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 182744, "time": 8768.57695388794, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 182912, "time": 8776.158239603043, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 183128, "time": 8784.523971796036, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 183160, "time": 8787.18851351738, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 183248, "time": 8791.795940876007, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 183600, "time": 8804.924150705338, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 183848, "time": 8814.424183607101, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 184016, "time": 8821.783689498901, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 184248, "time": 8830.76290845871, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 184624, "time": 8844.87261915207, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 184768, "time": 8851.232008934021, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 184984, "time": 8859.798511266708, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 185000, "time": 8861.896202325821, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 185336, "time": 8874.561234474182, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 185464, "time": 8880.318180084229, "episode/length": 201.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 185504, "time": 8883.411670207977, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 185952, "time": 8899.85102391243, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 186200, "time": 8909.405184745789, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 186240, "time": 8912.526798725128, "episode/length": 35.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 186320, "time": 8916.741598844528, "episode/length": 193.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 186344, "time": 8918.97436285019, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 186360, "time": 8921.162336826324, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 186904, "time": 8940.657532691956, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 186952, "time": 8943.826349496841, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 187520, "time": 8964.438965082169, "episode/length": 256.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 187640, "time": 8969.780217170715, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 187672, "time": 8972.333798885345, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 187696, "time": 8974.944007635117, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 187712, "time": 8977.061856746674, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 187952, "time": 8986.766612052917, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 188416, "time": 9003.779831171036, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 188616, "time": 9013.310509443283, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 188944, "time": 9025.90488743782, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 189152, "time": 9034.34888958931, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 189208, "time": 9037.603384256363, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 189224, "time": 9039.929985523224, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 189320, "time": 9044.658617258072, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 189616, "time": 9056.235895395279, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 189816, "time": 9064.123876333237, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 189824, "time": 9066.176835298538, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9088.171582460403, "eval_episode/length": 34.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8571428571428571}
{"step": 190008, "time": 9090.722625732422, "eval_episode/length": 58.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 190008, "time": 9095.82244181633, "eval_episode/length": 143.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 190008, "time": 9098.684961795807, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 190008, "time": 9100.260458946228, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 190008, "time": 9102.180938005447, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 190008, "time": 9105.226399183273, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 190008, "time": 9107.081958770752, "eval_episode/length": 159.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.99375}
{"step": 190184, "time": 9112.887437105179, "episode/length": 45.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 190376, "time": 9121.551387310028, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 190568, "time": 9129.637428760529, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 190592, "time": 9132.301815032959, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 190608, "time": 9134.450268268585, "episode/length": 52.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 191032, "time": 9149.757323741913, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 191224, "time": 9157.64065694809, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 191416, "time": 9165.719547271729, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 191776, "time": 9179.322799682617, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 192080, "time": 9190.952138662338, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 192192, "time": 9196.254683971405, "episode/length": 226.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 192288, "time": 9200.88620376587, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 192360, "time": 9204.60459947586, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 192536, "time": 9212.091587305069, "episode/length": 240.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 192656, "time": 9217.712211847305, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 193072, "time": 9233.162727594376, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 193368, "time": 9244.263075590134, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 193592, "time": 9253.336768388748, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 193648, "time": 9257.102875471115, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 193840, "time": 9265.027922868729, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 194328, "time": 9282.606765031815, "episode/length": 254.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 194616, "time": 9293.644026994705, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 194872, "time": 9303.64291882515, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 194872, "time": 9303.653829336166, "episode/length": 291.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 194920, "time": 9308.65405702591, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 194976, "time": 9312.204927444458, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 195104, "time": 9318.007311344147, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 195736, "time": 9340.231973171234, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 196304, "time": 9360.743037462234, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 196400, "time": 9365.38633966446, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 196528, "time": 9371.250319242477, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 196528, "time": 9371.259927511215, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 196704, "time": 9381.757496118546, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 196745, "time": 9385.594532966614, "train_stats/sum_log_reward": 5.032773059957168, "train_stats/max_log_achievement_collect_drink": 3.436974789915966, "train_stats/max_log_achievement_collect_sapling": 2.8487394957983194, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.781512605042017, "train_stats/max_log_achievement_defeat_skeleton": 0.008403361344537815, "train_stats/max_log_achievement_defeat_zombie": 0.5210084033613446, "train_stats/max_log_achievement_eat_cow": 0.06722689075630252, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.12605042016806722, "train_stats/max_log_achievement_make_wood_sword": 0.07563025210084033, "train_stats/max_log_achievement_place_plant": 2.588235294117647, "train_stats/max_log_achievement_place_table": 1.8235294117647058, "train_stats/max_log_achievement_wake_up": 1.3361344537815125, "train_stats/mean_log_entropy": 0.5256606528238088, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9370055713241907, "train/action_min": 0.0, "train/action_std": 2.771307895509459, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04966218603386296, "train/actor_opt_grad_steps": 11510.0, "train/actor_opt_loss": -3.783695620384148, "train/adv_mag": 0.7888863039531296, "train/adv_max": 0.7777696474850606, "train/adv_mean": 0.004185123376347495, "train/adv_min": -0.5148751977965128, "train/adv_std": 0.08309747999627813, "train/cont_avg": 0.9942600607014388, "train/cont_loss_mean": 0.0005954708605103121, "train/cont_loss_std": 0.016963773052067553, "train/cont_neg_acc": 0.9859027077825807, "train/cont_neg_loss": 0.03985572684925939, "train/cont_pos_acc": 0.99990097695975, "train/cont_pos_loss": 0.00037567273961930663, "train/cont_pred": 0.9942112968122359, "train/cont_rate": 0.9942600607014388, "train/dyn_loss_mean": 14.492878618857844, "train/dyn_loss_std": 8.872890129363794, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0172323970485935, "train/extr_critic_critic_opt_grad_steps": 11510.0, "train/extr_critic_critic_opt_loss": 15546.265681205035, "train/extr_critic_mag": 4.012108329388735, "train/extr_critic_max": 4.012108329388735, "train/extr_critic_mean": 0.9663855257651789, "train/extr_critic_min": -0.18530359542627128, "train/extr_critic_std": 0.9582309877272133, "train/extr_return_normed_mag": 1.8225122124171085, "train/extr_return_normed_max": 1.8225122124171085, "train/extr_return_normed_mean": 0.324431620591836, "train/extr_return_normed_min": -0.1997123063146639, "train/extr_return_normed_std": 0.34026230442867006, "train/extr_return_rate": 0.5118649093796024, "train/extr_return_raw_mag": 5.371420908317291, "train/extr_return_raw_max": 5.371420908317291, "train/extr_return_raw_mean": 0.9786804292699416, "train/extr_return_raw_min": -0.5576492750601802, "train/extr_return_raw_std": 0.9976795993262916, "train/extr_reward_mag": 1.0096619652329588, "train/extr_reward_max": 1.0096619652329588, "train/extr_reward_mean": 0.02057653642092034, "train/extr_reward_min": -0.409653788847889, "train/extr_reward_std": 0.12711629598475188, "train/image_loss_mean": 11.140877895218006, "train/image_loss_std": 14.225862125698612, "train/model_loss_mean": 19.890206728050178, "train/model_loss_std": 17.94162779060199, "train/model_opt_grad_norm": 71.16350578747208, "train/model_opt_grad_steps": 11495.84892086331, "train/model_opt_loss": 19394.21639641412, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 980.2158273381295, "train/policy_entropy_mag": 2.48153578291694, "train/policy_entropy_max": 2.48153578291694, "train/policy_entropy_mean": 0.5823130723383787, "train/policy_entropy_min": 0.07937575458622664, "train/policy_entropy_std": 0.5554255442224818, "train/policy_logprob_mag": 7.438378303171062, "train/policy_logprob_max": -0.009455931305938916, "train/policy_logprob_mean": -0.5827651461251349, "train/policy_logprob_min": -7.438378303171062, "train/policy_logprob_std": 1.119037367028298, "train/policy_randomness_mag": 0.8758732294864792, "train/policy_randomness_max": 0.8758732294864792, "train/policy_randomness_mean": 0.20553096185485237, "train/policy_randomness_min": 0.028016158078107044, "train/policy_randomness_std": 0.196040845067381, "train/post_ent_mag": 53.499513365381915, "train/post_ent_max": 53.499513365381915, "train/post_ent_mean": 37.401987857955824, "train/post_ent_min": 20.163942131207143, "train/post_ent_std": 6.172290568729099, "train/prior_ent_mag": 63.669372421374426, "train/prior_ent_max": 63.669372421374426, "train/prior_ent_mean": 52.00767094454319, "train/prior_ent_min": 29.329346540162888, "train/prior_ent_std": 6.0745546286054655, "train/rep_loss_mean": 14.492878618857844, "train/rep_loss_std": 8.872890129363794, "train/reward_avg": 0.018560307837433093, "train/reward_loss_mean": 0.053006413305620496, "train/reward_loss_std": 0.2602455282597233, "train/reward_max_data": 1.015107917271072, "train/reward_max_pred": 1.0058506521389639, "train/reward_neg_acc": 0.9928731901182545, "train/reward_neg_loss": 0.031248144470423244, "train/reward_pos_acc": 0.9523972414380355, "train/reward_pos_loss": 0.9471740396760351, "train/reward_pred": 0.017947656986899943, "train/reward_rate": 0.023844986510791366, "eval_stats/sum_log_reward": 4.662499964237213, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 8.617195703664038e-07, "report/cont_loss_std": 1.5370704204542562e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002786949626170099, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.536341435823488e-08, "report/cont_pred": 0.9970711469650269, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.619345664978027, "report/dyn_loss_std": 8.61206340789795, "report/image_loss_mean": 10.135870933532715, "report/image_loss_std": 9.34766674041748, "report/model_loss_mean": 18.355026245117188, "report/model_loss_std": 13.199615478515625, "report/post_ent_mag": 54.080867767333984, "report/post_ent_max": 54.080867767333984, "report/post_ent_mean": 37.25385665893555, "report/post_ent_min": 20.882701873779297, "report/post_ent_std": 6.656083583831787, "report/prior_ent_mag": 64.20254516601562, "report/prior_ent_max": 64.20254516601562, "report/prior_ent_mean": 51.42950439453125, "report/prior_ent_min": 29.397817611694336, "report/prior_ent_std": 6.647907257080078, "report/rep_loss_mean": 13.619345664978027, "report/rep_loss_std": 8.61206340789795, "report/reward_avg": 0.02607421949505806, "report/reward_loss_mean": 0.047546401619911194, "report/reward_loss_std": 0.26292574405670166, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000483512878418, "report/reward_neg_acc": 0.9989939332008362, "report/reward_neg_loss": 0.019381394609808922, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 0.9807470440864563, "report/reward_pred": 0.023333104327321053, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 3.8069134461693466e-05, "eval/cont_loss_std": 0.0007679353002458811, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003785574110224843, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.2275096196390223e-05, "eval/cont_pred": 0.9931776523590088, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.474544525146484, "eval/dyn_loss_std": 9.450761795043945, "eval/image_loss_mean": 17.50827980041504, "eval/image_loss_std": 24.709671020507812, "eval/model_loss_mean": 27.503623962402344, "eval/model_loss_std": 28.129676818847656, "eval/post_ent_mag": 50.552146911621094, "eval/post_ent_max": 50.552146911621094, "eval/post_ent_mean": 37.627532958984375, "eval/post_ent_min": 19.290252685546875, "eval/post_ent_std": 5.32555627822876, "eval/prior_ent_mag": 64.20254516601562, "eval/prior_ent_max": 64.20254516601562, "eval/prior_ent_mean": 51.30376052856445, "eval/prior_ent_min": 26.72832489013672, "eval/prior_ent_std": 5.6389546394348145, "eval/rep_loss_mean": 16.474544525146484, "eval/rep_loss_std": 9.450761795043945, "eval/reward_avg": 0.014941406436264515, "eval/reward_loss_mean": 0.11057895421981812, "eval/reward_loss_std": 0.766443133354187, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001100778579712, "eval/reward_neg_acc": 0.9870259761810303, "eval/reward_neg_loss": 0.04539741203188896, "eval/reward_pos_acc": 0.7272727489471436, "eval/reward_pos_loss": 3.0793018341064453, "eval/reward_pred": 0.011304675601422787, "eval/reward_rate": 0.021484375, "replay/size": 196241.0, "replay/inserts": 22208.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.4583921054598234e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.407377895772972e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 37904.0, "eval_replay/inserts": 3528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2528463826428194e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.475214958190918e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0532250404358, "timer/env.step_count": 2776.0, "timer/env.step_total": 265.0843460559845, "timer/env.step_frac": 0.26507023768186555, "timer/env.step_avg": 0.09549147912679556, "timer/env.step_min": 0.02301645278930664, "timer/env.step_max": 3.4339258670806885, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.500415563583374, "timer/replay._sample_frac": 0.011499803486077823, "timer/replay._sample_avg": 0.000517850124440894, "timer/replay._sample_min": 0.00040984153747558594, "timer/replay._sample_max": 0.03484678268432617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3217.0, "timer/agent.policy_total": 51.89989686012268, "timer/agent.policy_frac": 0.05189713463303334, "timer/agent.policy_avg": 0.01613301114706953, "timer/agent.policy_min": 0.00936126708984375, "timer/agent.policy_max": 0.09521794319152832, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.14779162406921387, "timer/dataset_train_frac": 0.00014778375827270406, "timer/dataset_train_avg": 0.00010647811532364112, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.00034928321838378906, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 617.395890712738, "timer/agent.train_frac": 0.6173630315404207, "timer/agent.train_avg": 0.44480971953367293, "timer/agent.train_min": 0.4346482753753662, "timer/agent.train_max": 1.547607421875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48254942893981934, "timer/agent.report_frac": 0.00048252374659389565, "timer/agent.report_avg": 0.24127471446990967, "timer/agent.report_min": 0.2223963737487793, "timer/agent.report_max": 0.26015305519104004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.029273986816406e-05, "timer/dataset_eval_frac": 4.0290595399594734e-08, "timer/dataset_eval_avg": 4.029273986816406e-05, "timer/dataset_eval_min": 4.029273986816406e-05, "timer/dataset_eval_max": 4.029273986816406e-05, "fps": 22.20637956534346}
{"step": 197072, "time": 9397.035207748413, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 197096, "time": 9399.23675942421, "episode/length": 48.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 197128, "time": 9401.984092712402, "episode/length": 410.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 197264, "time": 9408.253514528275, "episode/length": 298.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 197952, "time": 9432.91400194168, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 197984, "time": 9435.99771976471, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 198112, "time": 9441.75453209877, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 198320, "time": 9450.250314474106, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 198352, "time": 9452.933979511261, "episode/length": 45.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 198416, "time": 9456.703867197037, "episode/length": 160.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 198784, "time": 9470.81912946701, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 198848, "time": 9474.549039363861, "episode/length": 317.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 199008, "time": 9481.302659511566, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 199120, "time": 9486.462598085403, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 199536, "time": 9501.819899320602, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 199560, "time": 9503.994548559189, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 199680, "time": 9509.719970703125, "episode/length": 169.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 199928, "time": 9519.496814012527, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 200088, "time": 9526.397348880768, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9547.705140590668, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 200096, "time": 9550.397677898407, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 200096, "time": 9552.488496303558, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 200096, "time": 9554.357983589172, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 200096, "time": 9557.005490541458, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 200096, "time": 9558.616905927658, "eval_episode/length": 215.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 200096, "time": 9561.758174657822, "eval_episode/length": 252.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9723320158102767}
{"step": 200096, "time": 9563.424814462662, "eval_episode/length": 254.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.984313725490196}
{"step": 200528, "time": 9577.6104388237, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 200544, "time": 9579.762712717056, "episode/length": 56.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 200648, "time": 9584.57689833641, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 200680, "time": 9587.141659975052, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 200736, "time": 9590.74442744255, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 200944, "time": 9599.256924629211, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 201336, "time": 9613.60039138794, "episode/length": 221.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 201936, "time": 9635.111026763916, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 202056, "time": 9640.842700719833, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 202176, "time": 9647.095141887665, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 202400, "time": 9655.95602440834, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 202440, "time": 9658.573777914047, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 202704, "time": 9669.142003297806, "episode/length": 219.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 203168, "time": 9686.083992958069, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 203504, "time": 9698.836458683014, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 203504, "time": 9698.849471092224, "episode/length": 446.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 203752, "time": 9710.04223036766, "episode/length": 226.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 203848, "time": 9714.752868175507, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 204296, "time": 9731.22973704338, "episode/length": 236.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 204336, "time": 9734.292881250381, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 204416, "time": 9738.44216799736, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 204592, "time": 9745.910464286804, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 204656, "time": 9749.74837756157, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 205096, "time": 9767.231286525726, "episode/length": 62.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 205304, "time": 9775.61706495285, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 205304, "time": 9775.625784873962, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 205536, "time": 9786.727770805359, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 205656, "time": 9792.143258094788, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 205880, "time": 9801.155696630478, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 206000, "time": 9807.001661539078, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 206272, "time": 9817.685797452927, "episode/length": 345.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 206504, "time": 9826.822209119797, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 206592, "time": 9831.5327334404, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 206952, "time": 9844.733805894852, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 207088, "time": 9851.210286855698, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.0}
{"step": 207216, "time": 9857.077659130096, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 207312, "time": 9861.840124845505, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 207760, "time": 9878.314132452011, "episode/length": 100.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 207816, "time": 9881.528060913086, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9628099173553719, "episode/intrinsic_return": 0.0}
{"step": 208104, "time": 9892.543885707855, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 208200, "time": 9897.292184114456, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 208352, "time": 9904.172506809235, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 208640, "time": 9915.182653903961, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 208704, "time": 9918.894828557968, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 208912, "time": 9927.399669885635, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 209400, "time": 9944.973273515701, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 209496, "time": 9949.648426055908, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 209584, "time": 9954.286108016968, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 209592, "time": 9955.844018220901, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 209928, "time": 9968.610584259033, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 9990.114233970642, "eval_episode/length": 46.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 210080, "time": 9997.935580015182, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 210080, "time": 9999.69812631607, "eval_episode/length": 160.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 210080, "time": 10003.42927646637, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 210080, "time": 10005.090265274048, "eval_episode/length": 201.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 210080, "time": 10006.950835943222, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 210080, "time": 10008.99780702591, "eval_episode/length": 219.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 210080, "time": 10011.394792795181, "eval_episode/length": 240.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.970954356846473}
{"step": 210104, "time": 10011.972168445587, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 210120, "time": 10014.206418037415, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 210264, "time": 10020.472753763199, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 210680, "time": 10035.760807275772, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 210800, "time": 10041.513715267181, "episode/length": 108.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.944954128440367, "episode/intrinsic_return": 0.0}
{"step": 210952, "time": 10047.796422719955, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 211072, "time": 10053.581547021866, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 211432, "time": 10066.868926525116, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 211480, "time": 10069.928961515427, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 211712, "time": 10079.483081102371, "episode/length": 198.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 212120, "time": 10094.290475606918, "episode/length": 50.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 212272, "time": 10101.104709625244, "episode/length": 270.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 212416, "time": 10107.393505334854, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 212712, "time": 10118.593584060669, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 212840, "time": 10124.405219316483, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 212944, "time": 10129.5847427845, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 212968, "time": 10131.64234495163, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 213096, "time": 10138.874272108078, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930313588850174, "episode/intrinsic_return": 0.0}
{"step": 213664, "time": 10159.413516521454, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 213896, "time": 10168.410054683685, "episode/length": 99.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 214144, "time": 10178.39001083374, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 214248, "time": 10183.260781526566, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 214408, "time": 10190.19847202301, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9678714859437751, "episode/intrinsic_return": 0.0}
{"step": 214408, "time": 10190.208683490753, "episode/length": 266.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 214472, "time": 10195.618506669998, "episode/length": 190.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 214824, "time": 10208.915793180466, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 215000, "time": 10216.408336639404, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 215208, "time": 10224.806635379791, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 215592, "time": 10239.140376091003, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 215800, "time": 10247.558252811432, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 215824, "time": 10250.174942970276, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 215944, "time": 10255.526649713516, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 216200, "time": 10265.605958938599, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 216576, "time": 10279.91643166542, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 216640, "time": 10283.694794416428, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 216832, "time": 10291.595574378967, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 217024, "time": 10300.186086177826, "episode/length": 134.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 217104, "time": 10304.4477789402, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 217144, "time": 10307.019994735718, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 217464, "time": 10319.133181810379, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 217960, "time": 10337.085651397705, "episode/length": 266.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 218072, "time": 10342.390496253967, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 218264, "time": 10350.296257019043, "episode/length": 202.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 218408, "time": 10356.617197751999, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 218448, "time": 10359.885153770447, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 218480, "time": 10362.59243774414, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 218912, "time": 10378.489414215088, "episode/length": 53.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 218952, "time": 10381.219115495682, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 218976, "time": 10383.792933702469, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 218977, "time": 10385.930887699127, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9608401975769927, "train/action_min": 0.0, "train/action_std": 2.7969782490661177, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049062234740974243, "train/actor_opt_grad_steps": 12895.0, "train/actor_opt_loss": 1.7876947604227758, "train/adv_mag": 0.7581813927145972, "train/adv_max": 0.7458943893080172, "train/adv_mean": 0.005375042539051957, "train/adv_min": -0.5019376744394717, "train/adv_std": 0.08076710515804049, "train/cont_avg": 0.9944378396739131, "train/cont_loss_mean": 0.00030614419150272926, "train/cont_loss_std": 0.008211693632096865, "train/cont_neg_acc": 0.9877956604612046, "train/cont_neg_loss": 0.030514572899092207, "train/cont_pos_acc": 0.9999715094117151, "train/cont_pos_loss": 0.00010123981588275603, "train/cont_pred": 0.9944585354431815, "train/cont_rate": 0.9944378396739131, "train/dyn_loss_mean": 14.318028201227603, "train/dyn_loss_std": 8.895624133123867, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9571759830350461, "train/extr_critic_critic_opt_grad_steps": 12895.0, "train/extr_critic_critic_opt_loss": 15655.44921167346, "train/extr_critic_mag": 4.337437954501829, "train/extr_critic_max": 4.337437954501829, "train/extr_critic_mean": 1.011855406605679, "train/extr_critic_min": -0.18753425280253092, "train/extr_critic_std": 1.0125411135562952, "train/extr_return_normed_mag": 1.8385505494864092, "train/extr_return_normed_max": 1.8385505494864092, "train/extr_return_normed_mean": 0.32449979896562686, "train/extr_return_normed_min": -0.18315219835958618, "train/extr_return_normed_std": 0.33904478526201803, "train/extr_return_rate": 0.5208956324967785, "train/extr_return_raw_mag": 5.723542147788448, "train/extr_return_raw_max": 5.723542147788448, "train/extr_return_raw_mean": 1.0285265804200932, "train/extr_return_raw_min": -0.5470722568207893, "train/extr_return_raw_std": 1.0529123320095781, "train/extr_reward_mag": 1.011481699736222, "train/extr_reward_max": 1.011481699736222, "train/extr_reward_mean": 0.02276815847237257, "train/extr_reward_min": -0.3898748211238695, "train/extr_reward_std": 0.13511194115963535, "train/image_loss_mean": 10.199012576669887, "train/image_loss_std": 13.503213993017225, "train/model_loss_mean": 18.844427081121914, "train/model_loss_std": 17.199475454247516, "train/model_opt_grad_norm": 67.5338896046514, "train/model_opt_grad_steps": 12879.891304347826, "train/model_opt_loss": 15535.382437443388, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 824.2753623188406, "train/policy_entropy_mag": 2.458966421044391, "train/policy_entropy_max": 2.458966421044391, "train/policy_entropy_mean": 0.6049242276644361, "train/policy_entropy_min": 0.07937545010793036, "train/policy_entropy_std": 0.5683481388765833, "train/policy_logprob_mag": 7.438379778378252, "train/policy_logprob_max": -0.00945589495687813, "train/policy_logprob_mean": -0.605415665153144, "train/policy_logprob_min": -7.438379778378252, "train/policy_logprob_std": 1.1267382355703823, "train/policy_randomness_mag": 0.8679072377474412, "train/policy_randomness_max": 0.8679072377474412, "train/policy_randomness_mean": 0.21351170593845673, "train/policy_randomness_min": 0.028016050602646843, "train/policy_randomness_std": 0.20060195179953091, "train/post_ent_mag": 54.584787866343625, "train/post_ent_max": 54.584787866343625, "train/post_ent_mean": 37.8970927639284, "train/post_ent_min": 20.159438271453414, "train/post_ent_std": 6.5110496541728144, "train/prior_ent_mag": 64.2246770720551, "train/prior_ent_max": 64.2246770720551, "train/prior_ent_mean": 52.3443954301917, "train/prior_ent_min": 30.220366450323574, "train/prior_ent_std": 5.963081608647886, "train/rep_loss_mean": 14.318028201227603, "train/rep_loss_std": 8.895624133123867, "train/reward_avg": 0.019401041662617437, "train/reward_loss_mean": 0.05429142419302809, "train/reward_loss_std": 0.26600197087163513, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0069123670674753, "train/reward_neg_acc": 0.9922361296156178, "train/reward_neg_loss": 0.032133441917814205, "train/reward_pos_acc": 0.949957646753477, "train/reward_pos_loss": 0.9497650321842968, "train/reward_pred": 0.01878169838649531, "train/reward_rate": 0.024336220561594204, "train_stats/sum_log_reward": 5.125423673856056, "train_stats/max_log_achievement_collect_drink": 3.711864406779661, "train_stats/max_log_achievement_collect_sapling": 3.093220338983051, "train_stats/max_log_achievement_collect_stone": 0.11016949152542373, "train_stats/max_log_achievement_collect_wood": 5.067796610169491, "train_stats/max_log_achievement_defeat_skeleton": 0.01694915254237288, "train_stats/max_log_achievement_defeat_zombie": 0.3135593220338983, "train_stats/max_log_achievement_eat_cow": 0.11016949152542373, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2627118644067797, "train_stats/max_log_achievement_make_wood_sword": 0.13559322033898305, "train_stats/max_log_achievement_place_plant": 2.593220338983051, "train_stats/max_log_achievement_place_table": 1.9915254237288136, "train_stats/max_log_achievement_wake_up": 1.2542372881355932, "train_stats/mean_log_entropy": 0.5987252625873534, "eval_stats/sum_log_reward": 5.224999934434891, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 3.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 3.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.028985507246376812, "eval_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_place_stone": 0.19230769230769232, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.125867341528647e-06, "report/cont_loss_std": 8.405914559261873e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008857482462190092, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.814668050632463e-06, "report/cont_pred": 0.9951187372207642, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 16.57192039489746, "report/dyn_loss_std": 8.573308944702148, "report/image_loss_mean": 12.684294700622559, "report/image_loss_std": 18.09844398498535, "report/model_loss_mean": 22.678081512451172, "report/model_loss_std": 21.52347183227539, "report/post_ent_mag": 52.51700210571289, "report/post_ent_max": 52.51700210571289, "report/post_ent_mean": 35.66499710083008, "report/post_ent_min": 18.944711685180664, "report/post_ent_std": 5.508230209350586, "report/prior_ent_mag": 64.64723205566406, "report/prior_ent_max": 64.64723205566406, "report/prior_ent_mean": 52.63568115234375, "report/prior_ent_min": 30.350475311279297, "report/prior_ent_std": 6.814614295959473, "report/rep_loss_mean": 16.57192039489746, "report/rep_loss_std": 8.573308944702148, "report/reward_avg": 0.02910156175494194, "report/reward_loss_mean": 0.05062586069107056, "report/reward_loss_std": 0.1985636055469513, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005087852478027, "report/reward_neg_acc": 0.9898989200592041, "report/reward_neg_loss": 0.022170286625623703, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.879185140132904, "report/reward_pred": 0.027797862887382507, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 5.48035586689366e-07, "eval/cont_loss_std": 1.375805186398793e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00043572508729994297, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2264260362826462e-07, "eval/cont_pred": 0.9990237951278687, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 15.813112258911133, "eval/dyn_loss_std": 10.300613403320312, "eval/image_loss_mean": 13.346135139465332, "eval/image_loss_std": 18.913990020751953, "eval/model_loss_mean": 22.894672393798828, "eval/model_loss_std": 23.340486526489258, "eval/post_ent_mag": 53.006221771240234, "eval/post_ent_max": 53.006221771240234, "eval/post_ent_mean": 37.58162307739258, "eval/post_ent_min": 21.150592803955078, "eval/post_ent_std": 5.62367057800293, "eval/prior_ent_mag": 64.64723205566406, "eval/prior_ent_max": 64.64723205566406, "eval/prior_ent_mean": 50.94052505493164, "eval/prior_ent_min": 28.904598236083984, "eval/prior_ent_std": 6.230815887451172, "eval/rep_loss_mean": 15.813112258911133, "eval/rep_loss_std": 10.300613403320312, "eval/reward_avg": 0.02861328050494194, "eval/reward_loss_mean": 0.06066875532269478, "eval/reward_loss_std": 0.46440786123275757, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000525951385498, "eval/reward_neg_acc": 0.9949596524238586, "eval/reward_neg_loss": 0.014108749106526375, "eval/reward_pos_acc": 0.90625, "eval/reward_pos_loss": 1.5040290355682373, "eval/reward_pred": 0.022932864725589752, "eval/reward_rate": 0.03125, "replay/size": 218473.0, "replay/inserts": 22232.0, "replay/samples": 22224.0, "replay/insert_wait_avg": 1.4455574113887692e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.333662543904446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 41872.0, "eval_replay/inserts": 3968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2490537858778431e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3272233009338, "timer/env.step_count": 2779.0, "timer/env.step_total": 261.08647894859314, "timer/env.step_frac": 0.26100107331583544, "timer/env.step_avg": 0.0939497945119083, "timer/env.step_min": 0.022647619247436523, "timer/env.step_max": 3.337476968765259, "timer/replay._sample_count": 22224.0, "timer/replay._sample_total": 11.39393401145935, "timer/replay._sample_frac": 0.011390206870368909, "timer/replay._sample_avg": 0.00051268601563442, "timer/replay._sample_min": 0.0003898143768310547, "timer/replay._sample_max": 0.026566505432128906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3275.0, "timer/agent.policy_total": 54.64149785041809, "timer/agent.policy_frac": 0.05462362372795286, "timer/agent.policy_avg": 0.01668442682455514, "timer/agent.policy_min": 0.009189367294311523, "timer/agent.policy_max": 0.12187910079956055, "timer/dataset_train_count": 1389.0, "timer/dataset_train_total": 0.14932513236999512, "timer/dataset_train_frac": 0.00014927628569104016, "timer/dataset_train_avg": 0.00010750549486680714, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0004260540008544922, "timer/agent.train_count": 1389.0, "timer/agent.train_total": 617.7915060520172, "timer/agent.train_frac": 0.6175894164045596, "timer/agent.train_avg": 0.4447743024132593, "timer/agent.train_min": 0.4348490238189697, "timer/agent.train_max": 1.5929951667785645, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47138166427612305, "timer/agent.report_frac": 0.00047122746766866183, "timer/agent.report_avg": 0.23569083213806152, "timer/agent.report_min": 0.22783470153808594, "timer/agent.report_max": 0.2435469627380371, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7885848855371017e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.224450592940617}
{"step": 219224, "time": 10394.219752311707, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 219792, "time": 10414.788356781006, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 219800, "time": 10416.456885576248, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 220048, "time": 10426.60753417015, "episode/length": 30.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10448.08744931221, "eval_episode/length": 157.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9810126582278481}
{"step": 220064, "time": 10450.34440112114, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 220064, "time": 10452.272694826126, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 220064, "time": 10455.76612329483, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 220064, "time": 10455.775916576385, "eval_episode/length": 222.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9730941704035875}
{"step": 220064, "time": 10459.652338981628, "eval_episode/length": 234.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 220064, "time": 10461.870864391327, "eval_episode/length": 248.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 220064, "time": 10465.65497636795, "eval_episode/length": 298.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9933110367892977}
{"step": 220096, "time": 10466.71090054512, "episode/length": 228.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 220192, "time": 10471.558496952057, "episode/length": 154.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 220288, "time": 10476.272146940231, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 220400, "time": 10481.618546247482, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 220752, "time": 10494.940369844437, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 220776, "time": 10497.139112234116, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 221016, "time": 10506.601212024689, "episode/length": 76.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 221432, "time": 10523.331540107727, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 221480, "time": 10526.409605026245, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 221616, "time": 10532.760934114456, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 221896, "time": 10543.512187957764, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 221960, "time": 10547.085155963898, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 222056, "time": 10551.89614892006, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 222136, "time": 10556.095388412476, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 222328, "time": 10564.017619371414, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 222336, "time": 10566.052455186844, "episode/length": 54.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 222520, "time": 10573.613300561905, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 222744, "time": 10582.690682411194, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 222944, "time": 10591.135786771774, "episode/length": 165.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 223264, "time": 10603.364211559296, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 223440, "time": 10610.92811536789, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 223672, "time": 10619.922532558441, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 223688, "time": 10621.936851024628, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 223792, "time": 10627.064061880112, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 223936, "time": 10633.64136171341, "episode/length": 83.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 223976, "time": 10636.41618013382, "episode/length": 153.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 224288, "time": 10648.525397539139, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 224648, "time": 10661.823721647263, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 224912, "time": 10672.418598651886, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 225312, "time": 10687.183750629425, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 225320, "time": 10688.876277208328, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 225376, "time": 10692.567545413971, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 225480, "time": 10697.34833073616, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 225616, "time": 10703.65020275116, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 226096, "time": 10721.073464155197, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 226296, "time": 10729.049963235855, "episode/length": 325.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 226536, "time": 10738.714751005173, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 226544, "time": 10740.804561138153, "episode/length": 132.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 226640, "time": 10745.584380149841, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 226704, "time": 10749.38069319725, "episode/length": 223.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 226848, "time": 10755.730745315552, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 226896, "time": 10758.73255610466, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 226968, "time": 10762.416121959686, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 227800, "time": 10791.504346609116, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 227944, "time": 10797.909737586975, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 227960, "time": 10800.025759220123, "episode/length": 232.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 228168, "time": 10809.702735424042, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 228408, "time": 10819.279381275177, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 228568, "time": 10826.161260128021, "episode/length": 49.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 228624, "time": 10829.785155534744, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 228696, "time": 10833.400265455246, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 229080, "time": 10847.852596998215, "episode/length": 296.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9932659932659933, "episode/intrinsic_return": 0.0}
{"step": 229216, "time": 10854.207966566086, "episode/length": 64.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 229384, "time": 10861.504108667374, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 229416, "time": 10865.335391521454, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 229472, "time": 10869.084844350815, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 229640, "time": 10875.93335723877, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 229712, "time": 10880.029606819153, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 229752, "time": 10882.675331830978, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 229864, "time": 10887.802604675293, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10914.402565717697, "eval_episode/length": 139.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 230048, "time": 10916.969185113907, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 230048, "time": 10919.353722333908, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 230048, "time": 10921.858974695206, "eval_episode/length": 197.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 230048, "time": 10924.077491521835, "eval_episode/length": 210.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 230048, "time": 10926.209250688553, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 230048, "time": 10927.935510873795, "eval_episode/length": 225.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.995575221238938}
{"step": 230048, "time": 10930.46973490715, "eval_episode/length": 244.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9877551020408163}
{"step": 230352, "time": 10940.425702095032, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 230512, "time": 10947.21044421196, "episode/length": 108.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 230904, "time": 10961.538864850998, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9553072625698324, "episode/intrinsic_return": 0.0}
{"step": 231048, "time": 10967.89461350441, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 231112, "time": 10971.64100766182, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 231112, "time": 10971.649530649185, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 231528, "time": 10988.740061283112, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 231672, "time": 10995.192534446716, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 231680, "time": 10997.247281074524, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 231920, "time": 11006.746617078781, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 232288, "time": 11020.53972363472, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 232432, "time": 11026.837468147278, "episode/length": 190.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 232552, "time": 11032.063507318497, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 232712, "time": 11038.910585641861, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 232944, "time": 11048.381478309631, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 233408, "time": 11065.1556494236, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 233536, "time": 11071.027510404587, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 233840, "time": 11082.832667350769, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 234024, "time": 11090.268011808395, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 234056, "time": 11092.780114412308, "episode/length": 297.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 234296, "time": 11102.231466054916, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 234512, "time": 11111.364086866379, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 234520, "time": 11113.127674341202, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 234880, "time": 11126.804574012756, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 235112, "time": 11135.78403019905, "episode/length": 28.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 235136, "time": 11138.515700817108, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 235208, "time": 11142.335343122482, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 235488, "time": 11153.56354546547, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 235536, "time": 11157.07124876976, "episode/length": 49.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 235544, "time": 11158.61643576622, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 235792, "time": 11168.592654943466, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 236160, "time": 11182.294957876205, "episode/length": 232.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 236496, "time": 11195.159839868546, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 236696, "time": 11203.150656938553, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 236784, "time": 11207.875261068344, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 237208, "time": 11223.174680709839, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 237288, "time": 11227.49364900589, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 237304, "time": 11229.71676158905, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 237344, "time": 11232.891291618347, "episode/length": 193.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 237400, "time": 11236.056502342224, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 237912, "time": 11255.838681459427, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 238048, "time": 11262.23156785965, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 238648, "time": 11283.277555942535, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 238656, "time": 11285.292698860168, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 238720, "time": 11289.063559055328, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 238736, "time": 11291.128526449203, "episode/length": 85.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 238808, "time": 11294.82787156105, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 239104, "time": 11306.389193534851, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 239160, "time": 11309.653535842896, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 239184, "time": 11312.102635145187, "episode/length": 335.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 239544, "time": 11325.232627630234, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 239800, "time": 11335.231885910034, "episode/length": 143.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11361.149243593216, "eval_episode/length": 78.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9367088607594937}
{"step": 240032, "time": 11363.984782218933, "eval_episode/length": 111.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 240032, "time": 11367.26278424263, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 240032, "time": 11369.04372882843, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 240032, "time": 11371.632868528366, "eval_episode/length": 179.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 240032, "time": 11377.611712932587, "eval_episode/length": 209.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 240032, "time": 11380.54612326622, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 240032, "time": 11380.563970327377, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 240153, "time": 11386.323257446289, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.8874355689027253, "train/action_min": 0.0, "train/action_std": 2.7013666378824333, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04872142974483339, "train/actor_opt_grad_steps": 14250.0, "train/actor_opt_loss": -1.6927455902883881, "train/adv_mag": 0.717591494994056, "train/adv_max": 0.6980472103993696, "train/adv_mean": 0.00447921846757811, "train/adv_min": -0.5174097622695722, "train/adv_std": 0.07728227944974612, "train/cont_avg": 0.9941626527255639, "train/cont_loss_mean": 0.00024522727145012127, "train/cont_loss_std": 0.006900076661130376, "train/cont_neg_acc": 0.9917710952292708, "train/cont_neg_loss": 0.02462206027933674, "train/cont_pos_acc": 0.9999852117739225, "train/cont_pos_loss": 0.00011431918898308164, "train/cont_pred": 0.9941698281388534, "train/cont_rate": 0.9941626527255639, "train/dyn_loss_mean": 14.605856178398419, "train/dyn_loss_std": 8.93627935782411, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8829077657004049, "train/extr_critic_critic_opt_grad_steps": 14250.0, "train/extr_critic_critic_opt_loss": 15737.56877055921, "train/extr_critic_mag": 4.638770587462232, "train/extr_critic_max": 4.638770587462232, "train/extr_critic_mean": 1.0549983319483305, "train/extr_critic_min": -0.20184381832753806, "train/extr_critic_std": 1.079118081053397, "train/extr_return_normed_mag": 1.80291724025755, "train/extr_return_normed_max": 1.80291724025755, "train/extr_return_normed_mean": 0.3185361418733023, "train/extr_return_normed_min": -0.17970540889895947, "train/extr_return_normed_std": 0.3399287439826736, "train/extr_return_rate": 0.5318692521493238, "train/extr_return_raw_mag": 5.962380688889582, "train/extr_return_raw_max": 5.962380688889582, "train/extr_return_raw_mean": 1.0697649484290217, "train/extr_return_raw_min": -0.5727782229283699, "train/extr_return_raw_std": 1.1205033305892371, "train/extr_reward_mag": 1.0119841493161998, "train/extr_reward_max": 1.0119841493161998, "train/extr_reward_mean": 0.023749471439006634, "train/extr_reward_min": -0.3997298120556021, "train/extr_reward_std": 0.13986088122640336, "train/image_loss_mean": 9.618699941420017, "train/image_loss_std": 12.599607041007594, "train/model_loss_mean": 18.43684574356653, "train/model_loss_std": 16.272803822854407, "train/model_opt_grad_norm": 69.98267630374792, "train/model_opt_grad_steps": 14233.842105263158, "train/model_opt_loss": 13939.190716047933, "train/model_opt_model_opt_grad_overflow": 0.007518796992481203, "train/model_opt_model_opt_grad_scale": 751.8796992481203, "train/policy_entropy_mag": 2.3413323244654145, "train/policy_entropy_max": 2.3413323244654145, "train/policy_entropy_mean": 0.5627810755618533, "train/policy_entropy_min": 0.07937532870617128, "train/policy_entropy_std": 0.49848126961772604, "train/policy_logprob_mag": 7.438382213277028, "train/policy_logprob_max": -0.009455872776645018, "train/policy_logprob_mean": -0.5630483176923335, "train/policy_logprob_min": -7.438382213277028, "train/policy_logprob_std": 1.0851962136146718, "train/policy_randomness_mag": 0.8263875653869227, "train/policy_randomness_max": 0.8263875653869227, "train/policy_randomness_mean": 0.19863702278388173, "train/policy_randomness_min": 0.028016007736437303, "train/policy_randomness_std": 0.17594201381045177, "train/post_ent_mag": 55.1437652415799, "train/post_ent_max": 55.1437652415799, "train/post_ent_mean": 38.14753135164877, "train/post_ent_min": 20.36601706196491, "train/post_ent_std": 6.647182719151776, "train/prior_ent_mag": 64.58370223081201, "train/prior_ent_max": 64.58370223081201, "train/prior_ent_mean": 52.89439661700026, "train/prior_ent_min": 31.514042459932487, "train/prior_ent_std": 5.688685280936105, "train/rep_loss_mean": 14.605856178398419, "train/rep_loss_std": 8.93627935782411, "train/reward_avg": 0.021123120239130537, "train/reward_loss_mean": 0.05438691341227159, "train/reward_loss_std": 0.2616056165748969, "train/reward_max_data": 1.0172932372057348, "train/reward_max_pred": 1.0068021815522272, "train/reward_neg_acc": 0.9929237114755731, "train/reward_neg_loss": 0.030652927850982302, "train/reward_pos_acc": 0.9584197675375113, "train/reward_pos_loss": 0.9292728484125066, "train/reward_pred": 0.020226334074610157, "train/reward_rate": 0.02638187265037594, "train_stats/sum_log_reward": 5.091379273233229, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.5172413793103448, "train_stats/max_log_achievement_collect_sapling": 2.543103448275862, "train_stats/max_log_achievement_collect_stone": 0.10344827586206896, "train_stats/max_log_achievement_collect_wood": 6.456896551724138, "train_stats/max_log_achievement_defeat_skeleton": 0.017241379310344827, "train_stats/max_log_achievement_defeat_zombie": 0.4051724137931034, "train_stats/max_log_achievement_eat_cow": 0.10344827586206896, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5689655172413793, "train_stats/max_log_achievement_make_wood_sword": 0.0603448275862069, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.04310344827586207, "train_stats/max_log_achievement_place_table": 2.1724137931034484, "train_stats/max_log_achievement_wake_up": 1.2241379310344827, "train_stats/mean_log_entropy": 0.5391575036377743, "eval_stats/sum_log_reward": 5.766666650772095, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 2.4583333333333335, "eval_stats/max_log_achievement_collect_stone": 0.3333333333333333, "eval_stats/max_log_achievement_collect_wood": 8.541666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5416666666666666, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5833333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 0.16666666666666666, "eval_stats/max_log_achievement_place_table": 2.6666666666666665, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.0661906091845594e-05, "report/cont_loss_std": 0.0002063522842945531, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013777642743662, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1320985322527122e-05, "report/cont_pred": 0.993162214756012, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 15.16482925415039, "report/dyn_loss_std": 8.989609718322754, "report/image_loss_mean": 7.845068454742432, "report/image_loss_std": 8.784801483154297, "report/model_loss_mean": 17.00197982788086, "report/model_loss_std": 12.63235092163086, "report/post_ent_mag": 55.3762321472168, "report/post_ent_max": 55.3762321472168, "report/post_ent_mean": 37.75700759887695, "report/post_ent_min": 19.822296142578125, "report/post_ent_std": 6.9790520668029785, "report/prior_ent_mag": 64.74830627441406, "report/prior_ent_max": 64.74830627441406, "report/prior_ent_mean": 53.34852600097656, "report/prior_ent_min": 31.14849090576172, "report/prior_ent_std": 5.630757808685303, "report/rep_loss_mean": 15.16482925415039, "report/rep_loss_std": 8.989609718322754, "report/reward_avg": 0.02304687350988388, "report/reward_loss_mean": 0.057994015514850616, "report/reward_loss_std": 0.1932695358991623, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0027496814727783, "report/reward_neg_acc": 0.98591548204422, "report/reward_neg_loss": 0.03704626485705376, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7520629167556763, "report/reward_pred": 0.025310371071100235, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.1300595360808074e-05, "eval/cont_loss_std": 6.384748849086463e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008388764690607786, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.055198122747242e-06, "eval/cont_pred": 0.996088981628418, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.41866683959961, "eval/dyn_loss_std": 10.54015827178955, "eval/image_loss_mean": 14.306855201721191, "eval/image_loss_std": 21.5792293548584, "eval/model_loss_mean": 24.82866668701172, "eval/model_loss_std": 25.913896560668945, "eval/post_ent_mag": 56.183250427246094, "eval/post_ent_max": 56.183250427246094, "eval/post_ent_mean": 39.418792724609375, "eval/post_ent_min": 20.586013793945312, "eval/post_ent_std": 7.241034030914307, "eval/prior_ent_mag": 64.74830627441406, "eval/prior_ent_max": 64.74830627441406, "eval/prior_ent_mean": 54.71601867675781, "eval/prior_ent_min": 30.619281768798828, "eval/prior_ent_std": 6.198608875274658, "eval/rep_loss_mean": 17.41866683959961, "eval/rep_loss_std": 10.54015827178955, "eval/reward_avg": 0.01865234412252903, "eval/reward_loss_mean": 0.0706009566783905, "eval/reward_loss_std": 0.490231454372406, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0057806968688965, "eval/reward_neg_acc": 0.9920079708099365, "eval/reward_neg_loss": 0.04174194484949112, "eval/reward_pos_acc": 0.9130434989929199, "eval/reward_pos_loss": 1.3265951871871948, "eval/reward_pred": 0.016341369599103928, "eval/reward_rate": 0.0224609375, "replay/size": 239649.0, "replay/inserts": 21176.0, "replay/samples": 21184.0, "replay/insert_wait_avg": 1.4629821575584166e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.622640209255622e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 48680.0, "eval_replay/inserts": 6808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2552345961717546e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3823664188385, "timer/env.step_count": 2647.0, "timer/env.step_total": 254.23853993415833, "timer/env.step_frac": 0.25414136481061694, "timer/env.step_avg": 0.09604780503746065, "timer/env.step_min": 0.023009300231933594, "timer/env.step_max": 3.239870309829712, "timer/replay._sample_count": 21184.0, "timer/replay._sample_total": 10.359984159469604, "timer/replay._sample_frac": 0.010356024363520322, "timer/replay._sample_avg": 0.0004890475906094036, "timer/replay._sample_min": 0.0003745555877685547, "timer/replay._sample_max": 0.009611129760742188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3498.0, "timer/agent.policy_total": 57.03725337982178, "timer/agent.policy_frac": 0.057015452585398245, "timer/agent.policy_avg": 0.016305675637456198, "timer/agent.policy_min": 0.0093231201171875, "timer/agent.policy_max": 0.1132194995880127, "timer/dataset_train_count": 1324.0, "timer/dataset_train_total": 0.1383681297302246, "timer/dataset_train_frac": 0.00013831524262623084, "timer/dataset_train_avg": 0.00010450765085364396, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0005204677581787109, "timer/agent.train_count": 1324.0, "timer/agent.train_total": 589.2572884559631, "timer/agent.train_frac": 0.5890320623756915, "timer/agent.train_avg": 0.4450583749667395, "timer/agent.train_min": 0.43410587310791016, "timer/agent.train_max": 1.442277193069458, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4634418487548828, "timer/agent.report_frac": 0.0004632647118860247, "timer/agent.report_avg": 0.2317209243774414, "timer/agent.report_min": 0.2218031883239746, "timer/agent.report_max": 0.2416386604309082, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.479580780040889e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 21.167664077569764}
{"step": 240160, "time": 11386.348285198212, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 240192, "time": 11389.49836730957, "episode/length": 135.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 240632, "time": 11405.308588027954, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 240936, "time": 11417.166728496552, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 240960, "time": 11419.707316875458, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 241160, "time": 11427.6588909626, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 241424, "time": 11438.278543710709, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 241648, "time": 11447.179032564163, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 242024, "time": 11460.941756010056, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 242056, "time": 11463.567167282104, "episode/length": 361.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751381215469613, "episode/intrinsic_return": 0.0}
{"step": 242176, "time": 11469.497198343277, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 242352, "time": 11476.912838459015, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 242440, "time": 11481.11041522026, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 242720, "time": 11492.091005325317, "episode/length": 315.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 242848, "time": 11497.958443880081, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 243160, "time": 11509.758826732635, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 243336, "time": 11517.208364725113, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 243440, "time": 11522.37499833107, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 243640, "time": 11530.329684257507, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 243728, "time": 11534.952860355377, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 243856, "time": 11540.580365896225, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 244168, "time": 11552.153331756592, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 244368, "time": 11560.639179706573, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 244960, "time": 11581.558230876923, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 245008, "time": 11584.644732236862, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 245256, "time": 11594.198523521423, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 245584, "time": 11606.675868034363, "episode/length": 403.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 245704, "time": 11612.07716536522, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 245784, "time": 11617.58036327362, "episode/length": 327.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 245968, "time": 11625.414190530777, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 246336, "time": 11639.035704612732, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 246592, "time": 11649.122828722, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 246688, "time": 11653.920296430588, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 247064, "time": 11667.61631822586, "episode/length": 400.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 247240, "time": 11675.07534623146, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 247256, "time": 11677.058619260788, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 247288, "time": 11679.759510993958, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 247496, "time": 11688.185851097107, "episode/length": 238.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 247520, "time": 11690.811070919037, "episode/length": 34.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 247632, "time": 11696.066465854645, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 247968, "time": 11708.78898525238, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 247968, "time": 11708.818223953247, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 248632, "time": 11733.670189142227, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 248776, "time": 11739.956300973892, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 248784, "time": 11742.014570713043, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 248808, "time": 11744.075642585754, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 248864, "time": 11747.769838809967, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 249056, "time": 11755.690318107605, "episode/length": 135.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 249056, "time": 11755.697027683258, "episode/length": 52.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 249136, "time": 11761.777383565903, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 249224, "time": 11765.943270206451, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 249256, "time": 11768.664301395416, "episode/length": 58.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 249744, "time": 11786.62831735611, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11812.465848684311, "eval_episode/length": 43.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 250016, "time": 11819.332672834396, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 250016, "time": 11821.677919149399, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 250016, "time": 11823.56868481636, "eval_episode/length": 192.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 250016, "time": 11825.906687021255, "eval_episode/length": 210.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 250016, "time": 11827.740159034729, "eval_episode/length": 214.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 250016, "time": 11829.564418315887, "eval_episode/length": 216.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 250016, "time": 11831.812369585037, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 250400, "time": 11844.518113851547, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 250536, "time": 11850.385719299316, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 250616, "time": 11854.599680423737, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 250640, "time": 11857.118891716003, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 250664, "time": 11859.391609668732, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 250792, "time": 11865.190523862839, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 251376, "time": 11886.13498711586, "episode/length": 203.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 251912, "time": 11905.14753484726, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 252040, "time": 11910.954837560654, "episode/length": 174.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 252120, "time": 11915.76170706749, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 252248, "time": 11922.250627040863, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 252264, "time": 11924.95146393776, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 252320, "time": 11929.183739185333, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 252360, "time": 11931.9182908535, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 252424, "time": 11935.634134054184, "episode/length": 395.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 252720, "time": 11947.076133728027, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 253496, "time": 11973.79036951065, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 253560, "time": 11977.545378446579, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 253816, "time": 11987.782997131348, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 253872, "time": 11991.561478614807, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 253912, "time": 11994.329717159271, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 254000, "time": 12000.369955301285, "episode/length": 260.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 254368, "time": 12014.118180274963, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 254624, "time": 12024.066215991974, "episode/length": 287.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 254792, "time": 12030.969208240509, "episode/length": 98.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 254920, "time": 12037.617246389389, "episode/length": 177.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 255200, "time": 12048.750582456589, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 255320, "time": 12054.04857301712, "episode/length": 219.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 255344, "time": 12056.609592199326, "episode/length": 190.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 255856, "time": 12075.165075540543, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 256144, "time": 12086.117357492447, "episode/length": 102.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 256216, "time": 12089.934353590012, "episode/length": 108.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 256256, "time": 12093.176343917847, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 256336, "time": 12097.379602909088, "episode/length": 302.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 256376, "time": 12100.198167085648, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 256544, "time": 12107.404856920242, "episode/length": 49.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 256736, "time": 12115.28671002388, "episode/length": 191.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 256768, "time": 12118.026089668274, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 257144, "time": 12131.79437661171, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 257384, "time": 12141.72034072876, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 257712, "time": 12154.4679915905, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 258000, "time": 12165.480924844742, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 258096, "time": 12170.261022567749, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 258176, "time": 12174.420955657959, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 258336, "time": 12181.296325922012, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 258464, "time": 12187.005436897278, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 258696, "time": 12196.021804332733, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 259232, "time": 12215.593785047531, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 259400, "time": 12222.539896011353, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 259600, "time": 12230.892011404037, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12264.400721549988, "eval_episode/length": 131.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 260000, "time": 12266.670008420944, "eval_episode/length": 146.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 260000, "time": 12268.74859571457, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 260000, "time": 12271.337244987488, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 260000, "time": 12273.447172641754, "eval_episode/length": 188.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 260000, "time": 12275.308599233627, "eval_episode/length": 48.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 260000, "time": 12277.317519187927, "eval_episode/length": 206.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 260000, "time": 12281.029643535614, "eval_episode/length": 58.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 260040, "time": 12282.13144659996, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 260056, "time": 12284.250796079636, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 260064, "time": 12286.31019616127, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 260104, "time": 12288.922211647034, "episode/length": 87.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 260696, "time": 12309.946158409119, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 260888, "time": 12317.65769982338, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 261216, "time": 12330.317207098007, "episode/length": 401.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 261448, "time": 12339.392699956894, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 261488, "time": 12342.474751710892, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 261504, "time": 12344.55844783783, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 261560, "time": 12347.77421450615, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 261848, "time": 12358.698701143265, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 262480, "time": 12382.685953378677, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 262521, "time": 12386.348424911499, "train_stats/sum_log_reward": 5.5568965097953535, "train_stats/max_log_achievement_collect_coal": 0.034482758620689655, "train_stats/max_log_achievement_collect_drink": 5.241379310344827, "train_stats/max_log_achievement_collect_sapling": 2.4741379310344827, "train_stats/max_log_achievement_collect_stone": 0.3275862068965517, "train_stats/max_log_achievement_collect_wood": 6.939655172413793, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.29310344827586204, "train_stats/max_log_achievement_eat_cow": 0.1206896551724138, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0, "train_stats/max_log_achievement_make_wood_sword": 0.04310344827586207, "train_stats/max_log_achievement_place_plant": 1.6896551724137931, "train_stats/max_log_achievement_place_stone": 0.04310344827586207, "train_stats/max_log_achievement_place_table": 2.0517241379310347, "train_stats/max_log_achievement_wake_up": 1.1724137931034482, "train_stats/mean_log_entropy": 0.513432022826425, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.130767386300223, "train/action_min": 0.0, "train/action_std": 2.92590857063021, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048149468270795685, "train/actor_opt_grad_steps": 15615.0, "train/actor_opt_loss": -9.117248422413, "train/adv_mag": 0.6998105119381632, "train/adv_max": 0.6862199078713145, "train/adv_mean": 0.002914287150549301, "train/adv_min": -0.5001505438770567, "train/adv_std": 0.07542148892368589, "train/cont_avg": 0.9943638392857143, "train/cont_loss_mean": 0.00042333451420647957, "train/cont_loss_std": 0.011543081904821, "train/cont_neg_acc": 0.9911734708717891, "train/cont_neg_loss": 0.023106908094086165, "train/cont_pos_acc": 0.9999157684189933, "train/cont_pos_loss": 0.0003128304161980923, "train/cont_pred": 0.9943045139312744, "train/cont_rate": 0.9943638392857143, "train/dyn_loss_mean": 14.670598479679652, "train/dyn_loss_std": 8.9035767691476, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.918018889427185, "train/extr_critic_critic_opt_grad_steps": 15615.0, "train/extr_critic_critic_opt_loss": 15517.376715959821, "train/extr_critic_mag": 4.76121529511043, "train/extr_critic_max": 4.76121529511043, "train/extr_critic_mean": 1.0710043004580907, "train/extr_critic_min": -0.18160035950796946, "train/extr_critic_std": 1.078715599008969, "train/extr_return_normed_mag": 1.8360181289059776, "train/extr_return_normed_max": 1.8360181289059776, "train/extr_return_normed_mean": 0.3236641492162432, "train/extr_return_normed_min": -0.15399480031004975, "train/extr_return_normed_std": 0.33651033650551526, "train/extr_return_rate": 0.5586635332022395, "train/extr_return_raw_mag": 6.0911239215305875, "train/extr_return_raw_max": 6.0911239215305875, "train/extr_return_raw_mean": 1.080675534265382, "train/extr_return_raw_min": -0.501679853349924, "train/extr_return_raw_std": 1.1147923167262759, "train/extr_reward_mag": 1.0117494923727852, "train/extr_reward_max": 1.0117494923727852, "train/extr_reward_mean": 0.024485606394175973, "train/extr_reward_min": -0.3791719044957842, "train/extr_reward_std": 0.14192769804171154, "train/image_loss_mean": 9.239984720093863, "train/image_loss_std": 12.567793233054024, "train/model_loss_mean": 18.100885016577585, "train/model_loss_std": 16.254588965007237, "train/model_opt_grad_norm": 68.37744595663888, "train/model_opt_grad_steps": 15598.0, "train/model_opt_loss": 16062.053337751116, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 892.8571428571429, "train/policy_entropy_mag": 2.3288507223129273, "train/policy_entropy_max": 2.3288507223129273, "train/policy_entropy_mean": 0.5324570668595178, "train/policy_entropy_min": 0.07937529432986463, "train/policy_entropy_std": 0.47615528724023276, "train/policy_logprob_mag": 7.43838267326355, "train/policy_logprob_max": -0.009455840050109795, "train/policy_logprob_mean": -0.5325812333396502, "train/policy_logprob_min": -7.43838267326355, "train/policy_logprob_std": 1.0635536794151579, "train/policy_randomness_mag": 0.8219821048634393, "train/policy_randomness_max": 0.8219821048634393, "train/policy_randomness_mean": 0.18793397652251378, "train/policy_randomness_min": 0.028015995823911257, "train/policy_randomness_std": 0.16806192046829632, "train/post_ent_mag": 55.34994643075125, "train/post_ent_max": 55.34994643075125, "train/post_ent_mean": 38.54354948316302, "train/post_ent_min": 20.408244296482632, "train/post_ent_std": 6.793959011350359, "train/prior_ent_mag": 65.06041107177734, "train/prior_ent_max": 65.06041107177734, "train/prior_ent_mean": 53.334060723440984, "train/prior_ent_min": 32.487740230560306, "train/prior_ent_std": 5.567398905754089, "train/rep_loss_mean": 14.670598479679652, "train/rep_loss_std": 8.9035767691476, "train/reward_avg": 0.022275390469336083, "train/reward_loss_mean": 0.058117919548281605, "train/reward_loss_std": 0.28107725168977465, "train/reward_max_data": 1.0100000023841857, "train/reward_max_pred": 1.0047433512551445, "train/reward_neg_acc": 0.9924525661127908, "train/reward_neg_loss": 0.03245420100699578, "train/reward_pos_acc": 0.9439111764941897, "train/reward_pos_loss": 0.9739080939974104, "train/reward_pred": 0.02103859135614974, "train/reward_rate": 0.027267020089285714, "eval_stats/sum_log_reward": 5.037499874830246, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.375, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.042749868764076e-06, "report/cont_loss_std": 0.00011458450899226591, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.174707570811734e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.730167453701142e-06, "report/cont_pred": 0.9951097965240479, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.265935897827148, "report/dyn_loss_std": 8.676976203918457, "report/image_loss_mean": 8.380764961242676, "report/image_loss_std": 10.35120964050293, "report/model_loss_mean": 16.401830673217773, "report/model_loss_std": 13.834938049316406, "report/post_ent_mag": 57.91545104980469, "report/post_ent_max": 57.91545104980469, "report/post_ent_mean": 41.30109405517578, "report/post_ent_min": 21.456449508666992, "report/post_ent_std": 7.854308605194092, "report/prior_ent_mag": 65.45535278320312, "report/prior_ent_max": 65.45535278320312, "report/prior_ent_mean": 54.85734939575195, "report/prior_ent_min": 36.3585205078125, "report/prior_ent_std": 5.546627521514893, "report/rep_loss_mean": 13.265935897827148, "report/rep_loss_std": 8.676976203918457, "report/reward_avg": 0.02812499925494194, "report/reward_loss_mean": 0.06149660050868988, "report/reward_loss_std": 0.27061834931373596, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004349946975708, "report/reward_neg_acc": 0.9919191002845764, "report/reward_neg_loss": 0.029430510476231575, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.9951857328414917, "report/reward_pred": 0.02416878379881382, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 8.833727406454273e-06, "eval/cont_loss_std": 0.00011653754336293787, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00041463220259174705, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.441988261940423e-06, "eval/cont_pred": 0.9941366314888, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.100566864013672, "eval/dyn_loss_std": 9.895877838134766, "eval/image_loss_mean": 12.743138313293457, "eval/image_loss_std": 16.569656372070312, "eval/model_loss_mean": 22.485469818115234, "eval/model_loss_std": 20.659372329711914, "eval/post_ent_mag": 53.141517639160156, "eval/post_ent_max": 53.141517639160156, "eval/post_ent_mean": 39.41127014160156, "eval/post_ent_min": 19.543216705322266, "eval/post_ent_std": 6.1328277587890625, "eval/prior_ent_mag": 65.45535278320312, "eval/prior_ent_max": 65.45535278320312, "eval/prior_ent_mean": 53.31010055541992, "eval/prior_ent_min": 35.175559997558594, "eval/prior_ent_std": 5.245066165924072, "eval/rep_loss_mean": 16.100566864013672, "eval/rep_loss_std": 9.895877838134766, "eval/reward_avg": 0.02138671837747097, "eval/reward_loss_mean": 0.0819837898015976, "eval/reward_loss_std": 0.46616989374160767, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030899047851562, "eval/reward_neg_acc": 0.994979977607727, "eval/reward_neg_loss": 0.043643321841955185, "eval/reward_pos_acc": 0.8214285969734192, "eval/reward_pos_loss": 1.445809245109558, "eval/reward_pred": 0.01790233701467514, "eval/reward_rate": 0.02734375, "replay/size": 262017.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.4733922839676363e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.737857590758578e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52584.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2731332270825496e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0152428150177, "timer/env.step_count": 2796.0, "timer/env.step_total": 257.61516523361206, "timer/env.step_frac": 0.2576112385131569, "timer/env.step_avg": 0.09213704049843063, "timer/env.step_min": 0.022557973861694336, "timer/env.step_max": 3.460728168487549, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 11.00770902633667, "timer/replay._sample_frac": 0.011007541240421742, "timer/replay._sample_avg": 0.0004921186081159098, "timer/replay._sample_min": 0.0004074573516845703, "timer/replay._sample_max": 0.01083827018737793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3284.0, "timer/agent.policy_total": 53.325825452804565, "timer/agent.policy_frac": 0.05332501262950124, "timer/agent.policy_avg": 0.016238071087942924, "timer/agent.policy_min": 0.009412288665771484, "timer/agent.policy_max": 0.1055443286895752, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.14701294898986816, "timer/dataset_train_frac": 0.00014701070813283846, "timer/dataset_train_avg": 0.00010515947710290998, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0005536079406738281, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 621.7295541763306, "timer/agent.train_frac": 0.6217200774121978, "timer/agent.train_avg": 0.44472786421768995, "timer/agent.train_min": 0.4326450824737549, "timer/agent.train_max": 1.4799225330352783, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46468353271484375, "timer/agent.report_frac": 0.0004646764497376773, "timer/agent.report_avg": 0.23234176635742188, "timer/agent.report_min": 0.22097182273864746, "timer/agent.report_max": 0.2437117099761963, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.717930372847908e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.36738463753507}
{"step": 262640, "time": 12390.333025217056, "episode/length": 218.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.0}
{"step": 262720, "time": 12394.635307788849, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 262728, "time": 12396.143929958344, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 262816, "time": 12400.894990205765, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 263064, "time": 12410.303005456924, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 263384, "time": 12422.455570220947, "episode/length": 191.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 263800, "time": 12437.781320810318, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 264072, "time": 12448.14915728569, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 264072, "time": 12448.15734910965, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 264192, "time": 12455.58290553093, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 264256, "time": 12459.456394433975, "episode/length": 56.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 264360, "time": 12464.200228214264, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 264376, "time": 12466.152798652649, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 12476.59192442894, "episode/length": 48.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 264656, "time": 12478.66915845871, "episode/length": 386.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948320413436692, "episode/intrinsic_return": 0.0}
{"step": 265072, "time": 12493.86619400978, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 265320, "time": 12503.10629248619, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 265656, "time": 12515.71859908104, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 265840, "time": 12523.777841091156, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 265952, "time": 12529.115410804749, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 266072, "time": 12535.144056797028, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 266120, "time": 12538.785597324371, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 266208, "time": 12543.82401752472, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 267048, "time": 12572.80883693695, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 267112, "time": 12576.90873336792, "episode/length": 254.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 267488, "time": 12591.920626878738, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 267768, "time": 12602.484660863876, "episode/length": 305.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 267864, "time": 12607.318813800812, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 267920, "time": 12611.168089389801, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 268352, "time": 12626.880363464355, "episode/length": 267.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 268744, "time": 12641.137518405914, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 268824, "time": 12645.46406841278, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 269128, "time": 12656.901455402374, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 269320, "time": 12664.800443410873, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 269448, "time": 12670.616173505783, "episode/length": 421.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 269552, "time": 12675.870556354523, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9865470852017937, "episode/intrinsic_return": 0.0}
{"step": 269736, "time": 12683.239963531494, "episode/length": 233.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 270024, "time": 12694.235910892487, "episode/length": 208.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12713.296288013458, "eval_episode/length": 52.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 270088, "time": 12719.734586715698, "eval_episode/length": 164.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 270088, "time": 12722.447925329208, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 270088, "time": 12724.195152759552, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 270088, "time": 12726.329514980316, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 270088, "time": 12728.243575334549, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 270088, "time": 12733.01361489296, "eval_episode/length": 238.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 270088, "time": 12736.783258914948, "eval_episode/length": 345.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 270504, "time": 12751.850568771362, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 270752, "time": 12761.80965590477, "episode/length": 250.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9681274900398407, "episode/intrinsic_return": 0.0}
{"step": 270976, "time": 12770.771083593369, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 271208, "time": 12779.899808168411, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 271432, "time": 12788.898804426193, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 271776, "time": 12801.989772558212, "episode/length": 368.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 271784, "time": 12803.582237005234, "episode/length": 219.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 271792, "time": 12805.618478775024, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 271832, "time": 12808.20441198349, "episode/length": 49.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 272064, "time": 12817.462809801102, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 272184, "time": 12823.029847621918, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 272640, "time": 12839.834211826324, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 273032, "time": 12854.355325460434, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 273080, "time": 12857.519057750702, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 273112, "time": 12860.188512563705, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 273360, "time": 12870.125073671341, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 273552, "time": 12878.31593132019, "episode/length": 64.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 273560, "time": 12879.96488904953, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 273640, "time": 12884.119612693787, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 273856, "time": 12892.941329479218, "episode/length": 61.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 273992, "time": 12898.77994298935, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 274008, "time": 12900.918459653854, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 275088, "time": 12938.335471868515, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 275144, "time": 12941.453736543655, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 275176, "time": 12944.02115225792, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 275456, "time": 12955.109302520752, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 275456, "time": 12955.118516683578, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 275968, "time": 12975.291261672974, "episode/length": 301.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 276016, "time": 12978.502044439316, "episode/length": 362.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 276128, "time": 12983.731186389923, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 276400, "time": 12994.22180223465, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 276432, "time": 12997.241281986237, "episode/length": 51.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 276600, "time": 13004.89453792572, "episode/length": 188.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 276736, "time": 13011.696288585663, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 276744, "time": 13013.36911034584, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 276800, "time": 13017.041589260101, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 277656, "time": 13046.604650497437, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 277856, "time": 13054.913580417633, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 277920, "time": 13058.67377948761, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 278040, "time": 13063.99492263794, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9884169884169884, "episode/intrinsic_return": 0.0}
{"step": 278128, "time": 13068.666635036469, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 278248, "time": 13073.941359043121, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 278344, "time": 13078.666570186615, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 278496, "time": 13085.480313062668, "episode/length": 79.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 278904, "time": 13101.752794027328, "episode/length": 50.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 278992, "time": 13106.514580011368, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 279744, "time": 13132.88840675354, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 279752, "time": 13134.474333524704, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 279768, "time": 13136.524819135666, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13167.165754795074, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.95}
{"step": 280072, "time": 13169.963840007782, "eval_episode/length": 166.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 280072, "time": 13171.949694633484, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 280072, "time": 13173.70172715187, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 280072, "time": 13175.282465219498, "eval_episode/length": 180.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 280072, "time": 13178.187820672989, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9635416666666666}
{"step": 280072, "time": 13181.57724070549, "eval_episode/length": 210.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 280072, "time": 13184.906301259995, "eval_episode/length": 252.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9841897233201581}
{"step": 280192, "time": 13189.11392569542, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 280208, "time": 13191.233012914658, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 280320, "time": 13196.573128938675, "episode/length": 523.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 280360, "time": 13199.233573675156, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 280568, "time": 13207.693818807602, "episode/length": 207.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 281272, "time": 13232.43363237381, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 281352, "time": 13236.509598016739, "episode/length": 97.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 281480, "time": 13242.4308385849, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 281632, "time": 13249.23875260353, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 281760, "time": 13255.06568479538, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 281920, "time": 13261.919309854507, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 282056, "time": 13267.719020366669, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 282344, "time": 13278.77030801773, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 282920, "time": 13299.396227359772, "episode/length": 393.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9898477157360406, "episode/intrinsic_return": 0.0}
{"step": 282936, "time": 13301.296464920044, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 283088, "time": 13308.239625930786, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 283096, "time": 13310.290038347244, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 283544, "time": 13327.26025390625, "episode/length": 283.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 283640, "time": 13332.04543352127, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 284000, "time": 13345.671809911728, "episode/length": 259.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 284008, "time": 13347.347026348114, "episode/length": 207.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 284216, "time": 13355.868415117264, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 284624, "time": 13371.349208116531, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 284824, "time": 13379.35331749916, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 284928, "time": 13384.489754199982, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 284929, "time": 13386.567093372345, "train_stats/sum_log_reward": 5.591071390679905, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.9375, "train_stats/max_log_achievement_collect_sapling": 2.419642857142857, "train_stats/max_log_achievement_collect_stone": 0.29464285714285715, "train_stats/max_log_achievement_collect_wood": 7.419642857142857, "train_stats/max_log_achievement_defeat_skeleton": 0.017857142857142856, "train_stats/max_log_achievement_defeat_zombie": 0.5, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4642857142857143, "train_stats/max_log_achievement_make_wood_sword": 0.5535714285714286, "train_stats/max_log_achievement_place_plant": 1.8839285714285714, "train_stats/max_log_achievement_place_stone": 0.008928571428571428, "train_stats/max_log_achievement_place_table": 2.2589285714285716, "train_stats/max_log_achievement_wake_up": 1.0446428571428572, "train_stats/mean_log_entropy": 0.5295150238754494, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.150129045758929, "train/action_min": 0.0, "train/action_std": 3.214001704965319, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04859233394797359, "train/actor_opt_grad_steps": 17015.0, "train/actor_opt_loss": 0.28819760360888075, "train/adv_mag": 0.7232511660882405, "train/adv_max": 0.7067512673991067, "train/adv_mean": 0.004658206544159579, "train/adv_min": -0.5047302295054709, "train/adv_std": 0.07678438776305743, "train/cont_avg": 0.994482421875, "train/cont_loss_mean": 0.0002373027968478222, "train/cont_loss_std": 0.006659640758684304, "train/cont_neg_acc": 0.9878486403397151, "train/cont_neg_loss": 0.026765765489842254, "train/cont_pos_acc": 0.9999649001019342, "train/cont_pos_loss": 0.00011003380633317152, "train/cont_pred": 0.9944675420011793, "train/cont_rate": 0.994482421875, "train/dyn_loss_mean": 14.72925524711609, "train/dyn_loss_std": 8.89185413973672, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8870070150920323, "train/extr_critic_critic_opt_grad_steps": 17015.0, "train/extr_critic_critic_opt_loss": 15864.2673828125, "train/extr_critic_mag": 4.772040527207511, "train/extr_critic_max": 4.772040527207511, "train/extr_critic_mean": 1.078100607224873, "train/extr_critic_min": -0.20667033450944083, "train/extr_critic_std": 1.0731348054749625, "train/extr_return_normed_mag": 1.8184610332761493, "train/extr_return_normed_max": 1.8184610332761493, "train/extr_return_normed_mean": 0.319156867478575, "train/extr_return_normed_min": -0.1812733614018985, "train/extr_return_normed_std": 0.3338203009750162, "train/extr_return_rate": 0.5588867483394486, "train/extr_return_raw_mag": 6.079381367138454, "train/extr_return_raw_max": 6.079381367138454, "train/extr_return_raw_mean": 1.0935459332806723, "train/extr_return_raw_min": -0.5698761809085097, "train/extr_return_raw_std": 1.1101140980209623, "train/extr_reward_mag": 1.0142022967338562, "train/extr_reward_max": 1.0142022967338562, "train/extr_reward_mean": 0.025283805527059094, "train/extr_reward_min": -0.39297489523887635, "train/extr_reward_std": 0.14451974678252424, "train/image_loss_mean": 9.140741733142308, "train/image_loss_std": 12.63644495010376, "train/model_loss_mean": 18.03336147580828, "train/model_loss_std": 16.299869326182773, "train/model_opt_grad_norm": 69.87572292629763, "train/model_opt_grad_steps": 16997.042857142857, "train/model_opt_loss": 13479.038127790178, "train/model_opt_model_opt_grad_overflow": 0.007142857142857143, "train/model_opt_model_opt_grad_scale": 741.0714285714286, "train/policy_entropy_mag": 2.3275457297052657, "train/policy_entropy_max": 2.3275457297052657, "train/policy_entropy_mean": 0.5418414807745389, "train/policy_entropy_min": 0.07937526511294501, "train/policy_entropy_std": 0.4983363070658275, "train/policy_logprob_mag": 7.438382891246251, "train/policy_logprob_max": -0.009455800342506596, "train/policy_logprob_mean": -0.5409898530159678, "train/policy_logprob_min": -7.438382891246251, "train/policy_logprob_std": 1.0635496752602713, "train/policy_randomness_mag": 0.8215215006044932, "train/policy_randomness_max": 0.8215215006044932, "train/policy_randomness_mean": 0.19124626442790033, "train/policy_randomness_min": 0.02801598540640303, "train/policy_randomness_std": 0.17589084676333835, "train/post_ent_mag": 56.19176109858922, "train/post_ent_max": 56.19176109858922, "train/post_ent_mean": 38.866012246268134, "train/post_ent_min": 20.330103628976005, "train/post_ent_std": 6.953962894848415, "train/prior_ent_mag": 65.56681692940849, "train/prior_ent_max": 65.56681692940849, "train/prior_ent_mean": 53.71622385297503, "train/prior_ent_min": 32.78968381881714, "train/prior_ent_std": 5.515162198884147, "train/rep_loss_mean": 14.72925524711609, "train/rep_loss_std": 8.89185413973672, "train/reward_avg": 0.021926618088036774, "train/reward_loss_mean": 0.05482926024124026, "train/reward_loss_std": 0.2607216292193958, "train/reward_max_data": 1.0185714329992022, "train/reward_max_pred": 1.0103307400430952, "train/reward_neg_acc": 0.992864408663341, "train/reward_neg_loss": 0.030719845781901053, "train/reward_pos_acc": 0.9524253687688282, "train/reward_pos_loss": 0.9371137201786042, "train/reward_pred": 0.02110359173800264, "train/reward_rate": 0.02689732142857143, "eval_stats/sum_log_reward": 6.162500023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.3125, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.4375, "eval_stats/max_log_achievement_collect_wood": 6.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.5625, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.8723445211653598e-05, "report/cont_loss_std": 0.0005927732563577592, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.699965863139369e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8888985980302095e-05, "report/cont_pred": 0.9921591281890869, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 14.994698524475098, "report/dyn_loss_std": 8.590179443359375, "report/image_loss_mean": 9.831709861755371, "report/image_loss_std": 13.413586616516113, "report/model_loss_mean": 18.885265350341797, "report/model_loss_std": 16.87655258178711, "report/post_ent_mag": 57.56874084472656, "report/post_ent_max": 57.56874084472656, "report/post_ent_mean": 39.75295639038086, "report/post_ent_min": 21.292104721069336, "report/post_ent_std": 7.252348899841309, "report/prior_ent_mag": 65.77478790283203, "report/prior_ent_max": 65.77478790283203, "report/prior_ent_mean": 54.58393859863281, "report/prior_ent_min": 36.089073181152344, "report/prior_ent_std": 5.229587554931641, "report/rep_loss_mean": 14.994698524475098, "report/rep_loss_std": 8.590179443359375, "report/reward_avg": 0.03447265550494194, "report/reward_loss_mean": 0.056708935648202896, "report/reward_loss_std": 0.18533119559288025, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002354621887207, "report/reward_neg_acc": 0.9928717613220215, "report/reward_neg_loss": 0.027832331135869026, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7318713665008545, "report/reward_pred": 0.03397039324045181, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.0547264537308365e-05, "eval/cont_loss_std": 0.00015531742246821523, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.33494596008677e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0558119356574025e-05, "eval/cont_pred": 0.9951068162918091, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.588035583496094, "eval/dyn_loss_std": 9.568778991699219, "eval/image_loss_mean": 18.03776741027832, "eval/image_loss_std": 19.913475036621094, "eval/model_loss_mean": 29.88175392150879, "eval/model_loss_std": 23.696430206298828, "eval/post_ent_mag": 55.167579650878906, "eval/post_ent_max": 55.167579650878906, "eval/post_ent_mean": 38.522621154785156, "eval/post_ent_min": 21.95648956298828, "eval/post_ent_std": 6.441576957702637, "eval/prior_ent_mag": 65.77478790283203, "eval/prior_ent_max": 65.77478790283203, "eval/prior_ent_mean": 55.12493133544922, "eval/prior_ent_min": 34.17704772949219, "eval/prior_ent_std": 4.687038898468018, "eval/rep_loss_mean": 19.588035583496094, "eval/rep_loss_std": 9.568778991699219, "eval/reward_avg": 0.0283203125, "eval/reward_loss_mean": 0.09115761518478394, "eval/reward_loss_std": 0.5159676671028137, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001565933227539, "eval/reward_neg_acc": 0.9929364323616028, "eval/reward_neg_loss": 0.04741567745804787, "eval/reward_pos_acc": 0.8787878751754761, "eval/reward_pos_loss": 1.4047411680221558, "eval/reward_pred": 0.024841278791427612, "eval/reward_rate": 0.0322265625, "replay/size": 284425.0, "replay/inserts": 22408.0, "replay/samples": 22400.0, "replay/insert_wait_avg": 1.445449875406349e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.997321128845215e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57376.0, "eval_replay/inserts": 4792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2661260436094662e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2045023441315, "timer/env.step_count": 2801.0, "timer/env.step_total": 254.74740195274353, "timer/env.step_frac": 0.2546953161635488, "timer/env.step_avg": 0.09094873329266102, "timer/env.step_min": 0.02289104461669922, "timer/env.step_max": 3.3055660724639893, "timer/replay._sample_count": 22400.0, "timer/replay._sample_total": 11.17189645767212, "timer/replay._sample_frac": 0.011169612245784817, "timer/replay._sample_avg": 0.0004987453775746482, "timer/replay._sample_min": 0.00037026405334472656, "timer/replay._sample_max": 0.010294198989868164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3400.0, "timer/agent.policy_total": 55.83083486557007, "timer/agent.policy_frac": 0.05581941966340084, "timer/agent.policy_avg": 0.016420833783991198, "timer/agent.policy_min": 0.009298086166381836, "timer/agent.policy_max": 0.14824676513671875, "timer/dataset_train_count": 1400.0, "timer/dataset_train_total": 0.15111660957336426, "timer/dataset_train_frac": 0.00015108571219105642, "timer/dataset_train_avg": 0.0001079404354095459, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0004494190216064453, "timer/agent.train_count": 1400.0, "timer/agent.train_total": 619.2029573917389, "timer/agent.train_frac": 0.6190763548259807, "timer/agent.train_avg": 0.4422878267083849, "timer/agent.train_min": 0.4307229518890381, "timer/agent.train_max": 1.5382812023162842, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4727354049682617, "timer/agent.report_frac": 0.0004726387492361156, "timer/agent.report_avg": 0.23636770248413086, "timer/agent.report_min": 0.2281630039215088, "timer/agent.report_max": 0.24457240104675293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979622898902078e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.403130182775048}
{"step": 284984, "time": 13388.5513818264, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 285336, "time": 13401.759346485138, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 285416, "time": 13406.056121587753, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 285728, "time": 13418.111340761185, "episode/length": 272.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 285944, "time": 13426.647827148438, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 286064, "time": 13432.341677427292, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 286288, "time": 13441.242928266525, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 286400, "time": 13446.547755002975, "episode/length": 272.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 286424, "time": 13448.809845924377, "episode/length": 59.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 286448, "time": 13451.378412008286, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 286768, "time": 13464.866074800491, "episode/length": 39.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 286776, "time": 13467.101930856705, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 286888, "time": 13472.805290222168, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 287656, "time": 13500.110454082489, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 287824, "time": 13507.374766588211, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 288104, "time": 13518.01545882225, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 288192, "time": 13522.69835782051, "episode/length": 307.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 288240, "time": 13525.86392569542, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 288264, "time": 13528.530976772308, "episode/length": 186.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 288336, "time": 13533.227186441422, "episode/length": 84.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 288552, "time": 13542.27679181099, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 288728, "time": 13549.781601667404, "episode/length": 48.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 289168, "time": 13566.011055469513, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 289360, "time": 13574.032159090042, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 289464, "time": 13578.915469884872, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 289656, "time": 13586.674602508545, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 289664, "time": 13588.760870456696, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 290008, "time": 13601.552919149399, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 290008, "time": 13601.562534093857, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13621.49337053299, "eval_episode/length": 47.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 290056, "time": 13623.341920137405, "eval_episode/length": 55.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 290056, "time": 13629.498431444168, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 290056, "time": 13631.477448940277, "eval_episode/length": 170.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 290056, "time": 13634.375402450562, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 290056, "time": 13636.934251070023, "eval_episode/length": 220.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 290056, "time": 13638.711338281631, "eval_episode/length": 51.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 290056, "time": 13640.733199357986, "eval_episode/length": 182.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 290344, "time": 13650.170599222183, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 290592, "time": 13660.117178440094, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 290856, "time": 13670.180088043213, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 290960, "time": 13675.450190067291, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 291312, "time": 13688.680742502213, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 291320, "time": 13690.347072124481, "episode/length": 163.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 291616, "time": 13701.98463511467, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 291888, "time": 13712.52724313736, "episode/length": 234.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 292160, "time": 13723.319478750229, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 292200, "time": 13725.94937467575, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 292632, "time": 13741.872376918793, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 292648, "time": 13744.082788705826, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 292664, "time": 13746.215858221054, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 293000, "time": 13759.072016239166, "episode/length": 104.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 293016, "time": 13761.173145771027, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 293104, "time": 13765.915164709091, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 293120, "time": 13767.979752779007, "episode/length": 58.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 293136, "time": 13769.9858314991, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 293936, "time": 13798.132716417313, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 293984, "time": 13801.349459171295, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 294208, "time": 13810.497795581818, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 294336, "time": 13816.275065660477, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 294416, "time": 13820.515967845917, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 294520, "time": 13825.370978832245, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 294584, "time": 13829.08456659317, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 294664, "time": 13833.28919005394, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 294992, "time": 13847.431202411652, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 295672, "time": 13871.248801708221, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 295800, "time": 13876.992168664932, "episode/length": 232.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 296112, "time": 13889.009621858597, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 296152, "time": 13891.69201207161, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 296272, "time": 13897.402528047562, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 296392, "time": 13902.93159031868, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 296616, "time": 13911.981555461884, "episode/length": 253.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 296640, "time": 13914.602732419968, "episode/length": 104.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 296704, "time": 13918.292088031769, "episode/length": 295.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 297072, "time": 13931.989224910736, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 297664, "time": 13953.019016981125, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 297720, "time": 13956.189490795135, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 297800, "time": 13960.546625852585, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 298032, "time": 13969.969819784164, "episode/length": 28.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 298096, "time": 13973.680225372314, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 298144, "time": 13976.854018688202, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 298440, "time": 13988.098282814026, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 298448, "time": 13990.130755186081, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 298856, "time": 14004.937061309814, "episode/length": 268.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 299360, "time": 14023.368936777115, "episode/length": 211.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 299400, "time": 14026.047819137573, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 299496, "time": 14030.727714300156, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 299536, "time": 14033.770780086517, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 299672, "time": 14039.56203198433, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14069.585575342178, "eval_episode/length": 87.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9431818181818182}
{"step": 300040, "time": 14073.480529785156, "eval_episode/length": 144.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.993103448275862}
{"step": 300040, "time": 14076.004677057266, "eval_episode/length": 167.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 300040, "time": 14077.707839727402, "eval_episode/length": 170.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9590643274853801}
{"step": 300040, "time": 14079.831670761108, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9555555555555556}
{"step": 300040, "time": 14083.050351142883, "eval_episode/length": 219.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9681818181818181}
{"step": 300040, "time": 14084.759423732758, "eval_episode/length": 221.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 300040, "time": 14086.826175451279, "eval_episode/length": 54.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 300152, "time": 14090.509425163269, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 300320, "time": 14097.793979167938, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 300352, "time": 14100.393287420273, "episode/length": 281.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 300560, "time": 14108.818222284317, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 300776, "time": 14117.318761587143, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 300840, "time": 14120.94580578804, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 301184, "time": 14133.903386354446, "episode/length": 210.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 301456, "time": 14144.598873376846, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 301552, "time": 14149.289748430252, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 301632, "time": 14153.397614717484, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 302144, "time": 14171.839477062225, "episode/length": 63.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 302328, "time": 14179.18574166298, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 302664, "time": 14191.863718509674, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 302760, "time": 14196.644384860992, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 302888, "time": 14202.637258529663, "episode/length": 290.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 303072, "time": 14210.599403142929, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 303072, "time": 14210.608640432358, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 303216, "time": 14220.193090438843, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 303808, "time": 14241.196592569351, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 303992, "time": 14248.603219509125, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 304480, "time": 14266.543372631073, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 304528, "time": 14269.672640800476, "episode/length": 274.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 304672, "time": 14276.029809951782, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 304680, "time": 14277.619646787643, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 304720, "time": 14280.70004248619, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 304888, "time": 14287.471296072006, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 305120, "time": 14296.919404029846, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 305280, "time": 14303.730721473694, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 305768, "time": 14321.108170509338, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 305840, "time": 14325.230515241623, "episode/length": 169.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 306216, "time": 14338.974625587463, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 306432, "time": 14347.822509527206, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 306680, "time": 14357.527093172073, "episode/length": 194.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 306720, "time": 14360.526695728302, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 306800, "time": 14364.738013744354, "episode/length": 189.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 307040, "time": 14374.825995206833, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 307168, "time": 14380.715286970139, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 307289, "time": 14387.052188634872, "train_stats/sum_log_reward": 5.9205128015616, "train_stats/max_log_achievement_collect_coal": 0.05128205128205128, "train_stats/max_log_achievement_collect_drink": 3.888888888888889, "train_stats/max_log_achievement_collect_sapling": 2.324786324786325, "train_stats/max_log_achievement_collect_stone": 0.39316239316239315, "train_stats/max_log_achievement_collect_wood": 7.854700854700854, "train_stats/max_log_achievement_defeat_skeleton": 0.008547008547008548, "train_stats/max_log_achievement_defeat_zombie": 0.6239316239316239, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2222222222222222, "train_stats/max_log_achievement_make_wood_sword": 1.1196581196581197, "train_stats/max_log_achievement_place_plant": 1.794871794871795, "train_stats/max_log_achievement_place_stone": 0.017094017094017096, "train_stats/max_log_achievement_place_table": 2.341880341880342, "train_stats/max_log_achievement_wake_up": 1.1538461538461537, "train_stats/mean_log_entropy": 0.5365184494572827, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.173391218665692, "train/action_min": 0.0, "train/action_std": 3.3799210641023922, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04831140193579008, "train/actor_opt_grad_steps": 18410.0, "train/actor_opt_loss": -5.0784907910249215, "train/adv_mag": 0.7043502980427776, "train/adv_max": 0.6886477030867295, "train/adv_mean": 0.004209083816951154, "train/adv_min": -0.4785245496163265, "train/adv_std": 0.0746842145973401, "train/cont_avg": 0.9946886241007195, "train/cont_loss_mean": 0.00029403243053834, "train/cont_loss_std": 0.008261613765990732, "train/cont_neg_acc": 0.9901992704370897, "train/cont_neg_loss": 0.02160825822057867, "train/cont_pos_acc": 0.9999575863639227, "train/cont_pos_loss": 0.00016991319045368475, "train/cont_pred": 0.9946880769386566, "train/cont_rate": 0.9946886241007195, "train/dyn_loss_mean": 14.792787716543074, "train/dyn_loss_std": 8.875808403646346, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8824882918982198, "train/extr_critic_critic_opt_grad_steps": 18410.0, "train/extr_critic_critic_opt_loss": 15714.228628035073, "train/extr_critic_mag": 4.906099261139794, "train/extr_critic_max": 4.906099261139794, "train/extr_critic_mean": 1.137799541298434, "train/extr_critic_min": -0.20192840030725054, "train/extr_critic_std": 1.09049321035687, "train/extr_return_normed_mag": 1.8144000451341808, "train/extr_return_normed_max": 1.8144000451341808, "train/extr_return_normed_mean": 0.31861677519280274, "train/extr_return_normed_min": -0.17036233070514184, "train/extr_return_normed_std": 0.3290835964165146, "train/extr_return_rate": 0.6237911556264479, "train/extr_return_raw_mag": 6.291072759696905, "train/extr_return_raw_max": 6.291072759696905, "train/extr_return_raw_mean": 1.152309888558422, "train/extr_return_raw_min": -0.5284460099052182, "train/extr_return_raw_std": 1.1311458194856163, "train/extr_reward_mag": 1.0125917582203159, "train/extr_reward_max": 1.0125917582203159, "train/extr_reward_mean": 0.025712748185443363, "train/extr_reward_min": -0.3799239131186506, "train/extr_reward_std": 0.1466437702020295, "train/image_loss_mean": 8.939638769026283, "train/image_loss_std": 12.80798858875851, "train/model_loss_mean": 17.871334871799824, "train/model_loss_std": 16.416578073295756, "train/model_opt_grad_norm": 64.95655873525057, "train/model_opt_grad_steps": 18391.0, "train/model_opt_loss": 15224.83173617356, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 858.8129496402878, "train/policy_entropy_mag": 2.3320970964088716, "train/policy_entropy_max": 2.3320970964088716, "train/policy_entropy_mean": 0.527589072426446, "train/policy_entropy_min": 0.07937524542748499, "train/policy_entropy_std": 0.49156508321384734, "train/policy_logprob_mag": 7.438383020085396, "train/policy_logprob_max": -0.009455788605879966, "train/policy_logprob_mean": -0.5285841846208779, "train/policy_logprob_min": -7.438383020085396, "train/policy_logprob_std": 1.0598199894959979, "train/policy_randomness_mag": 0.8231279348297943, "train/policy_randomness_max": 0.8231279348297943, "train/policy_randomness_mean": 0.1862157893052204, "train/policy_randomness_min": 0.028015978419952254, "train/policy_randomness_std": 0.173500903540378, "train/post_ent_mag": 56.50190894037699, "train/post_ent_max": 56.50190894037699, "train/post_ent_mean": 39.22083606308313, "train/post_ent_min": 20.60612583846497, "train/post_ent_std": 7.032912158279967, "train/prior_ent_mag": 65.78063190926751, "train/prior_ent_max": 65.78063190926751, "train/prior_ent_mean": 54.09785283040657, "train/prior_ent_min": 34.257693668063595, "train/prior_ent_std": 5.186227050616587, "train/rep_loss_mean": 14.792787716543074, "train/rep_loss_std": 8.875808403646346, "train/reward_avg": 0.022597937134476446, "train/reward_loss_mean": 0.05572967014188389, "train/reward_loss_std": 0.26448493156072905, "train/reward_max_data": 1.0136690680071605, "train/reward_max_pred": 1.0090244322371997, "train/reward_neg_acc": 0.9926222442723006, "train/reward_neg_loss": 0.03133493301411756, "train/reward_pos_acc": 0.9527607555869672, "train/reward_pos_loss": 0.9197830223351073, "train/reward_pred": 0.021729470934156035, "train/reward_rate": 0.027435083183453238, "eval_stats/sum_log_reward": 5.162500008940697, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 0.875, "eval_stats/max_log_achievement_collect_wood": 6.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.563695645425469e-05, "report/cont_loss_std": 0.0006920437444932759, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.178819315508008e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.56558412022423e-05, "report/cont_pred": 0.9950821399688721, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.13471794128418, "report/dyn_loss_std": 8.664583206176758, "report/image_loss_mean": 7.579527854919434, "report/image_loss_std": 9.872987747192383, "report/model_loss_mean": 15.519211769104004, "report/model_loss_std": 13.361623764038086, "report/post_ent_mag": 58.26100540161133, "report/post_ent_max": 58.26100540161133, "report/post_ent_mean": 40.73161315917969, "report/post_ent_min": 17.393400192260742, "report/post_ent_std": 7.261566162109375, "report/prior_ent_mag": 65.62368774414062, "report/prior_ent_max": 65.62368774414062, "report/prior_ent_mean": 53.98336410522461, "report/prior_ent_min": 35.69403076171875, "report/prior_ent_std": 6.104860782623291, "report/rep_loss_mean": 13.13471794128418, "report/rep_loss_std": 8.664583206176758, "report/reward_avg": 0.01718749850988388, "report/reward_loss_mean": 0.058818235993385315, "report/reward_loss_std": 0.3826925456523895, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0026533603668213, "report/reward_neg_acc": 0.9960079789161682, "report/reward_neg_loss": 0.02823822572827339, "report/reward_pos_acc": 0.8636363744735718, "report/reward_pos_loss": 1.4515987634658813, "report/reward_pred": 0.015462972223758698, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0012962148757651448, "eval/cont_loss_std": 0.04115302115678787, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.3261013918963727e-05, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0013012459967285395, "eval/cont_pred": 0.9953692555427551, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.500240325927734, "eval/dyn_loss_std": 9.777338027954102, "eval/image_loss_mean": 16.093318939208984, "eval/image_loss_std": 20.288333892822266, "eval/model_loss_mean": 26.69777488708496, "eval/model_loss_std": 24.128232955932617, "eval/post_ent_mag": 56.4844856262207, "eval/post_ent_max": 56.4844856262207, "eval/post_ent_mean": 40.30850601196289, "eval/post_ent_min": 21.94390106201172, "eval/post_ent_std": 6.790210723876953, "eval/prior_ent_mag": 65.62368774414062, "eval/prior_ent_max": 65.62368774414062, "eval/prior_ent_mean": 55.222801208496094, "eval/prior_ent_min": 37.910606384277344, "eval/prior_ent_std": 4.422557830810547, "eval/rep_loss_mean": 17.500240325927734, "eval/rep_loss_std": 9.777338027954102, "eval/reward_avg": 0.02324218675494194, "eval/reward_loss_mean": 0.10301654040813446, "eval/reward_loss_std": 0.6774221658706665, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003537893295288, "eval/reward_neg_acc": 0.9929719567298889, "eval/reward_neg_loss": 0.05068602412939072, "eval/reward_pos_acc": 0.785714328289032, "eval/reward_pos_loss": 1.9644876718521118, "eval/reward_pred": 0.021011140197515488, "eval/reward_rate": 0.02734375, "replay/size": 306785.0, "replay/inserts": 22360.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.461401395166496e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.09450483936097e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61104.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2531684703581322e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4628591537476, "timer/env.step_count": 2795.0, "timer/env.step_total": 262.53482723236084, "timer/env.step_frac": 0.26241336680347016, "timer/env.step_avg": 0.09393017074503071, "timer/env.step_min": 0.02289581298828125, "timer/env.step_max": 3.3795900344848633, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 11.251983404159546, "timer/replay._sample_frac": 0.011246777730136989, "timer/replay._sample_avg": 0.0005030393152789497, "timer/replay._sample_min": 0.0003886222839355469, "timer/replay._sample_max": 0.01648426055908203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3261.0, "timer/agent.policy_total": 53.05068039894104, "timer/agent.policy_frac": 0.05302613676615096, "timer/agent.policy_avg": 0.016268224593358183, "timer/agent.policy_min": 0.009458303451538086, "timer/agent.policy_max": 0.12000155448913574, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.14902806282043457, "timer/dataset_train_frac": 0.0001489591157301847, "timer/dataset_train_avg": 0.00010660090330503188, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0003306865692138672, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 619.493371963501, "timer/agent.train_frac": 0.6192067664435902, "timer/agent.train_avg": 0.44312830612553716, "timer/agent.train_min": 0.4322080612182617, "timer/agent.train_max": 1.5093228816986084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4710972309112549, "timer/agent.report_frac": 0.00047087928012613843, "timer/agent.report_avg": 0.23554861545562744, "timer/agent.report_min": 0.2288675308227539, "timer/agent.report_max": 0.24222970008850098, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9073609664025147e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.349301194095002}
{"step": 307664, "time": 14399.447383403778, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 307704, "time": 14402.10932302475, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 307976, "time": 14412.56400179863, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 308048, "time": 14416.772998332977, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 308128, "time": 14421.011407375336, "episode/length": 404.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9975308641975309, "episode/intrinsic_return": 0.0}
{"step": 308560, "time": 14436.826253175735, "episode/length": 173.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 308720, "time": 14443.74437904358, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 308832, "time": 14448.896302223206, "episode/length": 253.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 308968, "time": 14454.729037284851, "episode/length": 162.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 309280, "time": 14466.780344486237, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.950920245398773, "episode/intrinsic_return": 0.0}
{"step": 309320, "time": 14469.601232290268, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 309432, "time": 14474.96597623825, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 309728, "time": 14486.381745100021, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14512.02690076828, "eval_episode/length": 39.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.975}
{"step": 310024, "time": 14518.472854852676, "eval_episode/length": 156.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 310024, "time": 14520.344096183777, "eval_episode/length": 163.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 310024, "time": 14522.692034006119, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 310024, "time": 14525.286299705505, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 310024, "time": 14527.659793615341, "eval_episode/length": 224.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 310024, "time": 14529.331423282623, "eval_episode/length": 185.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 310024, "time": 14530.997027873993, "eval_episode/length": 226.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 310232, "time": 14537.84816145897, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 310384, "time": 14544.615869522095, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 310384, "time": 14544.626634120941, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 310384, "time": 14544.635013580322, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 310568, "time": 14555.644955396652, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 310632, "time": 14559.384942293167, "episode/length": 168.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 310856, "time": 14568.398339748383, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 311272, "time": 14583.613164663315, "episode/length": 229.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 311656, "time": 14599.282374858856, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 311672, "time": 14601.33779668808, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 311784, "time": 14606.695543527603, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 311952, "time": 14613.984084367752, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 312248, "time": 14625.179023981094, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 312312, "time": 14628.953758955002, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 312640, "time": 14641.484172582626, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 313072, "time": 14657.443994045258, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 313288, "time": 14666.449594020844, "episode/length": 381.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 313328, "time": 14669.580407857895, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 313416, "time": 14673.816159009933, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 313488, "time": 14678.019849061966, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 313848, "time": 14691.392649412155, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 313992, "time": 14697.598910331726, "episode/length": 291.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 314240, "time": 14707.57744026184, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 314432, "time": 14715.54141831398, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 314824, "time": 14729.717472553253, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 314888, "time": 14733.504521131516, "episode/length": 56.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 314928, "time": 14736.418741464615, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 315120, "time": 14744.468233346939, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 315152, "time": 14747.113538265228, "episode/length": 227.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 315168, "time": 14749.20093870163, "episode/length": 42.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 315392, "time": 14758.167893648148, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 315608, "time": 14766.647572755814, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 315824, "time": 14775.562853574753, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 316272, "time": 14791.782651901245, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 316384, "time": 14797.067945718765, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 316432, "time": 14800.303805351257, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 316448, "time": 14802.355532169342, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 316680, "time": 14811.452368497849, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 316808, "time": 14817.303908109665, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 317136, "time": 14829.945672988892, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 317312, "time": 14837.292949676514, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 317784, "time": 14854.739248991013, "episode/length": 174.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 317912, "time": 14860.69610118866, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 318096, "time": 14868.650244951248, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 318152, "time": 14871.873072862625, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 318160, "time": 14873.897857904434, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 318608, "time": 14890.11491060257, "episode/length": 269.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 318672, "time": 14893.831233024597, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 318992, "time": 14905.9311170578, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 319344, "time": 14919.168247461319, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 319352, "time": 14920.690326690674, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 319536, "time": 14929.876264572144, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 319960, "time": 14945.196689844131, "episode/length": 330.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 14967.07589507103, "eval_episode/length": 143.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 320008, "time": 14969.522818088531, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 320008, "time": 14971.529444694519, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 320008, "time": 14973.494715690613, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 320008, "time": 14975.510207414627, "eval_episode/length": 190.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 320008, "time": 14977.39424943924, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 320008, "time": 14980.658201217651, "eval_episode/length": 231.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 320008, "time": 14987.366452932358, "eval_episode/length": 320.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9875389408099688}
{"step": 320040, "time": 14988.41710615158, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 320104, "time": 14992.077565431595, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 320672, "time": 15012.508846282959, "episode/length": 313.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 321000, "time": 15024.580972671509, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 321000, "time": 15024.589797735214, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 321064, "time": 15030.0086581707, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 321264, "time": 15038.530588388443, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 321344, "time": 15042.712994337082, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 321376, "time": 15045.330195903778, "episode/length": 252.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 322112, "time": 15071.218556642532, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 322344, "time": 15080.084236383438, "episode/length": 287.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 322424, "time": 15084.282380580902, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 322432, "time": 15086.403367042542, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 322760, "time": 15098.705069065094, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 322784, "time": 15101.293892860413, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 322904, "time": 15106.51842045784, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 323768, "time": 15136.445642709732, "episode/length": 302.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 323776, "time": 15138.473967790604, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 323792, "time": 15140.59967970848, "episode/length": 209.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 324176, "time": 15154.90171790123, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 324272, "time": 15160.205536842346, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 324448, "time": 15167.575061559677, "episode/length": 207.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 324488, "time": 15170.22812962532, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 325064, "time": 15190.706829309464, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 325272, "time": 15199.093132972717, "episode/length": 184.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 325712, "time": 15215.370775222778, "episode/length": 191.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 325800, "time": 15219.914609909058, "episode/length": 420.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 325976, "time": 15227.185643911362, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 326024, "time": 15230.405279874802, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 326128, "time": 15235.640331983566, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 326304, "time": 15243.33564376831, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 326328, "time": 15245.54882311821, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 326936, "time": 15267.133168935776, "episode/length": 207.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 326936, "time": 15267.140831708908, "episode/length": 78.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 327048, "time": 15274.145556926727, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 327184, "time": 15280.474002361298, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 327288, "time": 15285.204335689545, "episode/length": 157.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 327632, "time": 15298.327161312103, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 328000, "time": 15314.52984547615, "episode/length": 45.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 328064, "time": 15318.09861445427, "episode/length": 241.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 328120, "time": 15321.335548639297, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 328440, "time": 15333.345350980759, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 328512, "time": 15337.44510602951, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 328544, "time": 15340.138389348984, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 328608, "time": 15343.841056108475, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 329128, "time": 15362.034424066544, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 329552, "time": 15377.829486131668, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 329752, "time": 15385.74363565445, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 329753, "time": 15388.40911602974, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.24298701725953, "train/action_min": 0.0, "train/action_std": 3.4531748819013015, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04732894593625204, "train/actor_opt_grad_steps": 19810.0, "train/actor_opt_loss": -2.6955527735623064, "train/adv_mag": 0.6699872234611647, "train/adv_max": 0.6501947546258886, "train/adv_mean": 0.0037202441042170657, "train/adv_min": -0.486629566825028, "train/adv_std": 0.0714119609366072, "train/cont_avg": 0.994708554964539, "train/cont_loss_mean": 0.00020994553425884342, "train/cont_loss_std": 0.006019141761973663, "train/cont_neg_acc": 0.9953140840462759, "train/cont_neg_loss": 0.015194715745887707, "train/cont_pos_acc": 0.9999581287938653, "train/cont_pos_loss": 0.00012663050257991063, "train/cont_pred": 0.9946655669110886, "train/cont_rate": 0.994708554964539, "train/dyn_loss_mean": 14.649962317013571, "train/dyn_loss_std": 8.912715719101277, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8660716811815897, "train/extr_critic_critic_opt_grad_steps": 19810.0, "train/extr_critic_critic_opt_loss": 15717.28182485594, "train/extr_critic_mag": 5.11254085378444, "train/extr_critic_max": 5.11254085378444, "train/extr_critic_mean": 1.190122271260471, "train/extr_critic_min": -0.20210044350184447, "train/extr_critic_std": 1.1348420876137755, "train/extr_return_normed_mag": 1.7642905357036185, "train/extr_return_normed_max": 1.7642905357036185, "train/extr_return_normed_mean": 0.3189494460821152, "train/extr_return_normed_min": -0.1685205912547754, "train/extr_return_normed_std": 0.3243423040876997, "train/extr_return_rate": 0.6261963814708358, "train/extr_return_raw_mag": 6.421062466100598, "train/extr_return_raw_max": 6.421062466100598, "train/extr_return_raw_mean": 1.2035679068971188, "train/extr_return_raw_min": -0.5559583967881845, "train/extr_return_raw_std": 1.170958045526599, "train/extr_reward_mag": 1.013622578154219, "train/extr_reward_max": 1.013622578154219, "train/extr_reward_mean": 0.027184850886358438, "train/extr_reward_min": -0.3691469244923152, "train/extr_reward_std": 0.150719479624684, "train/image_loss_mean": 8.502208797644217, "train/image_loss_std": 12.303843268265961, "train/model_loss_mean": 17.347169889625928, "train/model_loss_std": 15.957591956388866, "train/model_opt_grad_norm": 63.858684796813534, "train/model_opt_grad_steps": 19790.347517730497, "train/model_opt_loss": 21840.08720495346, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8652482269504, "train/policy_entropy_mag": 2.3505023979971593, "train/policy_entropy_max": 2.3505023979971593, "train/policy_entropy_mean": 0.5143281570140351, "train/policy_entropy_min": 0.07937522174407405, "train/policy_entropy_std": 0.47969588172351213, "train/policy_logprob_mag": 7.4383830212532205, "train/policy_logprob_max": -0.00945577332551809, "train/policy_logprob_mean": -0.5136072443309405, "train/policy_logprob_min": -7.4383830212532205, "train/policy_logprob_std": 1.0474551556803655, "train/policy_randomness_mag": 0.8296241971617895, "train/policy_randomness_max": 0.8296241971617895, "train/policy_randomness_mean": 0.18153527093694566, "train/policy_randomness_min": 0.02801596998164417, "train/policy_randomness_std": 0.16931159519557412, "train/post_ent_mag": 56.96418007383955, "train/post_ent_max": 56.96418007383955, "train/post_ent_mean": 39.39099012875388, "train/post_ent_min": 20.533791102416128, "train/post_ent_std": 7.0988228980531085, "train/prior_ent_mag": 65.94586836361717, "train/prior_ent_max": 65.94586836361717, "train/prior_ent_mean": 54.1278962480261, "train/prior_ent_min": 34.32817678248629, "train/prior_ent_std": 5.285083956752263, "train/rep_loss_mean": 14.649962317013571, "train/rep_loss_std": 8.912715719101277, "train/reward_avg": 0.02457682269209243, "train/reward_loss_mean": 0.05477401137299149, "train/reward_loss_std": 0.2523315502396712, "train/reward_max_data": 1.0141844005449443, "train/reward_max_pred": 1.00663956006368, "train/reward_neg_acc": 0.9930506458519198, "train/reward_neg_loss": 0.029446341348349624, "train/reward_pos_acc": 0.961027592631942, "train/reward_pos_loss": 0.8961947310900857, "train/reward_pred": 0.023600181485427186, "train/reward_rate": 0.02926917109929078, "train_stats/sum_log_reward": 6.108771901381643, "train_stats/max_log_achievement_collect_coal": 0.008771929824561403, "train_stats/max_log_achievement_collect_drink": 5.140350877192983, "train_stats/max_log_achievement_collect_sapling": 2.2982456140350878, "train_stats/max_log_achievement_collect_stone": 0.22807017543859648, "train_stats/max_log_achievement_collect_wood": 7.842105263157895, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.6842105263157895, "train_stats/max_log_achievement_eat_cow": 0.15789473684210525, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06140350877192982, "train_stats/max_log_achievement_make_wood_sword": 1.3596491228070176, "train_stats/max_log_achievement_place_plant": 1.9035087719298245, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.4035087719298245, "train_stats/max_log_achievement_wake_up": 1.2280701754385965, "train_stats/mean_log_entropy": 0.4933696425797647, "eval_stats/sum_log_reward": 5.912500038743019, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.1875, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.3125, "eval_stats/max_log_achievement_collect_wood": 6.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.011764705882352941, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.0333918150281534e-05, "report/cont_loss_std": 0.0008686259971000254, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.311617754457984e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.0418402932118624e-05, "report/cont_pred": 0.9950774908065796, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.617449760437012, "report/dyn_loss_std": 8.611452102661133, "report/image_loss_mean": 9.708588600158691, "report/image_loss_std": 11.179535865783691, "report/model_loss_mean": 17.927043914794922, "report/model_loss_std": 14.693622589111328, "report/post_ent_mag": 55.94819259643555, "report/post_ent_max": 55.94819259643555, "report/post_ent_mean": 40.63261795043945, "report/post_ent_min": 17.778812408447266, "report/post_ent_std": 7.619388103485107, "report/prior_ent_mag": 65.9425048828125, "report/prior_ent_max": 65.9425048828125, "report/prior_ent_mean": 54.47068786621094, "report/prior_ent_min": 32.9803466796875, "report/prior_ent_std": 5.3694000244140625, "report/rep_loss_mean": 13.617449760437012, "report/rep_loss_std": 8.611452102661133, "report/reward_avg": 0.01572265475988388, "report/reward_loss_mean": 0.04794410616159439, "report/reward_loss_std": 0.230783611536026, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015509128570557, "report/reward_neg_acc": 0.9900398850440979, "report/reward_neg_loss": 0.03267459198832512, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8144737482070923, "report/reward_pred": 0.01732994243502617, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.5995881767594256e-05, "eval/cont_loss_std": 0.0003596075694076717, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.766923641203903e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.5832454664632678e-05, "eval/cont_pred": 0.996078372001648, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.3609619140625, "eval/dyn_loss_std": 9.563420295715332, "eval/image_loss_mean": 12.49609375, "eval/image_loss_std": 16.504716873168945, "eval/model_loss_mean": 22.41599464416504, "eval/model_loss_std": 20.75151252746582, "eval/post_ent_mag": 57.21574401855469, "eval/post_ent_max": 57.21574401855469, "eval/post_ent_mean": 40.09757995605469, "eval/post_ent_min": 23.42642593383789, "eval/post_ent_std": 6.16605806350708, "eval/prior_ent_mag": 65.9425048828125, "eval/prior_ent_max": 65.9425048828125, "eval/prior_ent_mean": 54.21251678466797, "eval/prior_ent_min": 36.420509338378906, "eval/prior_ent_std": 4.392284393310547, "eval/rep_loss_mean": 16.3609619140625, "eval/rep_loss_std": 9.563420295715332, "eval/reward_avg": 0.02646484225988388, "eval/reward_loss_mean": 0.10330811142921448, "eval/reward_loss_std": 0.6189987659454346, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000593900680542, "eval/reward_neg_acc": 0.9899294972419739, "eval/reward_neg_loss": 0.05339515954256058, "eval/reward_pos_acc": 0.8064515590667725, "eval/reward_pos_loss": 1.7021325826644897, "eval/reward_pred": 0.0230374988168478, "eval/reward_rate": 0.0302734375, "replay/size": 329249.0, "replay/inserts": 22464.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.4262342894518817e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.138211395665791e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65488.0, "eval_replay/inserts": 4384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2199917848962937e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3498599529266, "timer/env.step_count": 2808.0, "timer/env.step_total": 255.18368220329285, "timer/env.step_frac": 0.25483968431901416, "timer/env.step_avg": 0.09087737970202736, "timer/env.step_min": 0.022673606872558594, "timer/env.step_max": 5.1820228099823, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.352065563201904, "timer/replay._sample_frac": 0.01133676252147832, "timer/replay._sample_avg": 0.0005053447989317087, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.009833097457885742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3356.0, "timer/agent.policy_total": 55.82197976112366, "timer/agent.policy_frac": 0.055746729483487266, "timer/agent.policy_avg": 0.016633486222027313, "timer/agent.policy_min": 0.00934743881225586, "timer/agent.policy_max": 0.1115262508392334, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.1513981819152832, "timer/dataset_train_frac": 0.00015119409106663321, "timer/dataset_train_avg": 0.00010783346290262336, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0004923343658447266, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 622.7883524894714, "timer/agent.train_frac": 0.621948808699837, "timer/agent.train_avg": 0.4435814476420737, "timer/agent.train_min": 0.4314541816711426, "timer/agent.train_max": 1.526036262512207, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46528124809265137, "timer/agent.report_frac": 0.0004646540302252843, "timer/agent.report_avg": 0.23264062404632568, "timer/agent.report_min": 0.22148680686950684, "timer/agent.report_max": 0.24379444122314453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.833356456895065e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 22.433418476249983}
{"step": 329896, "time": 15392.994319677353, "episode/length": 168.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 330072, "time": 15400.44454050064, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15422.507311820984, "eval_episode/length": 164.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 330096, "time": 15425.11532664299, "eval_episode/length": 187.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 330096, "time": 15427.44399690628, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 330096, "time": 15429.492550611496, "eval_episode/length": 217.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 330096, "time": 15431.533538103104, "eval_episode/length": 229.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 330096, "time": 15433.629394054413, "eval_episode/length": 242.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9794238683127572}
{"step": 330096, "time": 15435.496065378189, "eval_episode/length": 246.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 330096, "time": 15437.594648838043, "eval_episode/length": 258.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.9922779922779923}
{"step": 330192, "time": 15440.761200666428, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 330352, "time": 15447.61479473114, "episode/length": 278.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 330744, "time": 15462.146867513657, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 330848, "time": 15467.402790784836, "episode/length": 291.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 330944, "time": 15472.320140838623, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 331040, "time": 15477.117055177689, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 331616, "time": 15497.702165842056, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 331776, "time": 15504.649447917938, "episode/length": 197.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 331872, "time": 15509.355967283249, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 332432, "time": 15529.450378417969, "episode/length": 173.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 332464, "time": 15532.04343533516, "episode/length": 189.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 332480, "time": 15534.622957229614, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 333104, "time": 15556.893417596817, "episode/length": 77.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 333136, "time": 15559.506408452988, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 333184, "time": 15562.62630534172, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 333248, "time": 15566.288326978683, "episode/length": 299.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 333320, "time": 15569.86071395874, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 333528, "time": 15578.356265306473, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 334152, "time": 15600.52081155777, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 334376, "time": 15609.720673799515, "episode/length": 238.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 334464, "time": 15614.44838142395, "episode/length": 165.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 335376, "time": 15646.341415643692, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 335408, "time": 15649.09286570549, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 335648, "time": 15658.637355566025, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 335824, "time": 15665.98751950264, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 335840, "time": 15668.100344896317, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 335912, "time": 15673.319814920425, "episode/length": 350.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 336672, "time": 15700.22959280014, "episode/length": 157.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 336720, "time": 15703.325632095337, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 336888, "time": 15710.096762657166, "episode/length": 188.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 337272, "time": 15724.447117090225, "episode/length": 202.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 337368, "time": 15729.34799361229, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 337496, "time": 15735.196344852448, "episode/length": 530.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.992467043314501, "episode/intrinsic_return": 0.0}
{"step": 337792, "time": 15746.834300279617, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 338000, "time": 15755.138066530228, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 338160, "time": 15761.988468647003, "episode/length": 280.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 338352, "time": 15769.926937818527, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 338960, "time": 15791.73773598671, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 339280, "time": 15803.97040772438, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 339424, "time": 15810.311940670013, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 339696, "time": 15821.040587186813, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 339768, "time": 15824.781490802765, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 339808, "time": 15827.982829093933, "episode/length": 316.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9810725552050473, "episode/intrinsic_return": 0.0}
{"step": 340000, "time": 15835.9200091362, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 15859.520383834839, "eval_episode/length": 145.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 340080, "time": 15861.173103570938, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 340080, "time": 15864.223404407501, "eval_episode/length": 178.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.994413407821229}
{"step": 340080, "time": 15867.036556005478, "eval_episode/length": 207.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 340080, "time": 15870.653396368027, "eval_episode/length": 254.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 340080, "time": 15872.492475748062, "eval_episode/length": 260.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 340080, "time": 15876.003491163254, "eval_episode/length": 304.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9868852459016394}
{"step": 340080, "time": 15878.483849287033, "eval_episode/length": 180.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 340120, "time": 15879.618275880814, "episode/length": 144.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 340184, "time": 15883.331248998642, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 340592, "time": 15898.539672374725, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 340888, "time": 15909.663388729095, "episode/length": 182.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 341152, "time": 15920.231349945068, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 341168, "time": 15922.368723154068, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 341184, "time": 15924.361806869507, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 341248, "time": 15928.06074166298, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 341568, "time": 15940.287304878235, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 341600, "time": 15943.413014411926, "episode/length": 43.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 342008, "time": 15958.69342970848, "episode/length": 54.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 342080, "time": 15962.941065788269, "episode/length": 185.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 342176, "time": 15967.735184669495, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 342384, "time": 15976.34530544281, "episode/length": 282.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 342480, "time": 15981.03133893013, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 342832, "time": 15994.199199676514, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 342888, "time": 15997.473073720932, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 343368, "time": 16015.069989681244, "episode/length": 148.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 343624, "time": 16025.024166584015, "episode/length": 308.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 343744, "time": 16030.90253853798, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 343768, "time": 16032.949233531952, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 343848, "time": 16037.1156167984, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 343992, "time": 16043.497450828552, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 344144, "time": 16052.116302251816, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 344568, "time": 16067.60413980484, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 344664, "time": 16072.493924856186, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 344744, "time": 16076.776583433151, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 344936, "time": 16084.683252573013, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 345208, "time": 16095.258481740952, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 345288, "time": 16099.62062382698, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 345400, "time": 16104.88914322853, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 346176, "time": 16132.379364967346, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 346464, "time": 16143.36276102066, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 346744, "time": 16154.161733150482, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 346768, "time": 16156.708485841751, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 346776, "time": 16158.299403905869, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 346952, "time": 16165.671525716782, "episode/length": 251.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 347112, "time": 16172.527356386185, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 347536, "time": 16188.47750377655, "episode/length": 423.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929245283018868, "episode/intrinsic_return": 0.0}
{"step": 347608, "time": 16192.129019260406, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 347792, "time": 16199.806144952774, "episode/length": 31.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 347888, "time": 16204.438469648361, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 347944, "time": 16207.561006784439, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 348152, "time": 16216.091725349426, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 348304, "time": 16222.883757591248, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 348312, "time": 16224.946467161179, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 348776, "time": 16242.60894370079, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 349160, "time": 16257.217710733414, "episode/length": 301.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 349216, "time": 16260.8121175766, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 349240, "time": 16262.976087331772, "episode/length": 168.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 349528, "time": 16273.932685613632, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 349592, "time": 16277.670750379562, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 349640, "time": 16280.792417526245, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 349856, "time": 16289.704944372177, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 349952, "time": 16294.525932073593, "episode/length": 52.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16320.073683738708, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 350064, "time": 16321.989627599716, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 350064, "time": 16323.754889965057, "eval_episode/length": 174.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 350064, "time": 16325.983492851257, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 350064, "time": 16328.367507219315, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 350064, "time": 16330.000720739365, "eval_episode/length": 202.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 350064, "time": 16332.070414543152, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 350064, "time": 16335.015484333038, "eval_episode/length": 244.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 350232, "time": 16340.342180728912, "episode/length": 181.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 350848, "time": 16362.584435224533, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 350888, "time": 16365.223709821701, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 350912, "time": 16367.836814165115, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 350920, "time": 16369.475806474686, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 351080, "time": 16376.302706241608, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 351288, "time": 16384.901027441025, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 351321, "time": 16388.621297836304, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.276599573206019, "train/action_min": 0.0, "train/action_std": 3.4864547393940115, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048729247627434906, "train/actor_opt_grad_steps": 21190.0, "train/actor_opt_loss": 0.48286736424046534, "train/adv_mag": 0.682539619339837, "train/adv_max": 0.6621476259496477, "train/adv_mean": 0.005106853546695439, "train/adv_min": -0.4861837689523344, "train/adv_std": 0.0737860260186372, "train/cont_avg": 0.9946976273148148, "train/cont_loss_mean": 0.00018614488200901851, "train/cont_loss_std": 0.005258241181871671, "train/cont_neg_acc": 0.9953759829203288, "train/cont_neg_loss": 0.01349937525383885, "train/cont_pos_acc": 0.9999709124918337, "train/cont_pos_loss": 0.00010856337509955615, "train/cont_pred": 0.9946695230625294, "train/cont_rate": 0.9946976273148148, "train/dyn_loss_mean": 14.466821048877858, "train/dyn_loss_std": 8.885541484974048, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9082922604348924, "train/extr_critic_critic_opt_grad_steps": 21190.0, "train/extr_critic_critic_opt_loss": 15764.464236111111, "train/extr_critic_mag": 5.2207168367173935, "train/extr_critic_max": 5.2207168367173935, "train/extr_critic_mean": 1.2411171811598318, "train/extr_critic_min": -0.19145736164516872, "train/extr_critic_std": 1.1356705171090584, "train/extr_return_normed_mag": 1.7675421635309856, "train/extr_return_normed_max": 1.7675421635309856, "train/extr_return_normed_mean": 0.32309876183668773, "train/extr_return_normed_min": -0.17468775422484786, "train/extr_return_normed_std": 0.3262566149234772, "train/extr_return_rate": 0.6717930482493506, "train/extr_return_raw_mag": 6.452581787109375, "train/extr_return_raw_max": 6.452581787109375, "train/extr_return_raw_mean": 1.2594555894533792, "train/extr_return_raw_min": -0.5303619986331022, "train/extr_return_raw_std": 1.1730445429130836, "train/extr_reward_mag": 1.0166888431266503, "train/extr_reward_max": 1.0166888431266503, "train/extr_reward_mean": 0.028109465511860672, "train/extr_reward_min": -0.410931921005249, "train/extr_reward_std": 0.153402185384874, "train/image_loss_mean": 8.219517488832826, "train/image_loss_std": 12.128644763098823, "train/model_loss_mean": 16.95482753471092, "train/model_loss_std": 15.77641389634874, "train/model_opt_grad_norm": 64.46080104686595, "train/model_opt_grad_steps": 21168.51851851852, "train/model_opt_loss": 15473.54964554398, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 916.6666666666666, "train/policy_entropy_mag": 2.3393182401303894, "train/policy_entropy_max": 2.3393182401303894, "train/policy_entropy_mean": 0.5012344013761592, "train/policy_entropy_min": 0.07937518391344282, "train/policy_entropy_std": 0.48492317574995536, "train/policy_logprob_mag": 7.438383187188043, "train/policy_logprob_max": -0.00945576883300587, "train/policy_logprob_mean": -0.5007410256950944, "train/policy_logprob_min": -7.438383187188043, "train/policy_logprob_std": 1.0450302728900203, "train/policy_randomness_mag": 0.8256766787281743, "train/policy_randomness_max": 0.8256766787281743, "train/policy_randomness_mean": 0.17691374708105018, "train/policy_randomness_min": 0.028015956668942063, "train/policy_randomness_std": 0.1711566005591993, "train/post_ent_mag": 56.67804559778284, "train/post_ent_max": 56.67804559778284, "train/post_ent_mean": 39.65997840033637, "train/post_ent_min": 20.55769196263066, "train/post_ent_std": 7.082201353708903, "train/prior_ent_mag": 66.06727543583622, "train/prior_ent_max": 66.06727543583622, "train/prior_ent_mean": 54.18483471340603, "train/prior_ent_min": 34.873556786996346, "train/prior_ent_std": 5.117757398110849, "train/rep_loss_mean": 14.466821048877858, "train/rep_loss_std": 8.885541484974048, "train/reward_avg": 0.024276620335876943, "train/reward_loss_mean": 0.055031390405363506, "train/reward_loss_std": 0.2558328305129652, "train/reward_max_data": 1.0185185229336773, "train/reward_max_pred": 1.0123725749828196, "train/reward_neg_acc": 0.9925323901353059, "train/reward_neg_loss": 0.029828822060867594, "train/reward_pos_acc": 0.9576008430233708, "train/reward_pos_loss": 0.9030656964690597, "train/reward_pred": 0.023455955681425555, "train/reward_rate": 0.02911603009259259, "train_stats/sum_log_reward": 6.118518492689839, "train_stats/max_log_achievement_collect_coal": 0.009259259259259259, "train_stats/max_log_achievement_collect_drink": 4.351851851851852, "train_stats/max_log_achievement_collect_sapling": 2.537037037037037, "train_stats/max_log_achievement_collect_stone": 0.26851851851851855, "train_stats/max_log_achievement_collect_wood": 8.87962962962963, "train_stats/max_log_achievement_defeat_skeleton": 0.037037037037037035, "train_stats/max_log_achievement_defeat_zombie": 0.9444444444444444, "train_stats/max_log_achievement_eat_cow": 0.12962962962962962, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07407407407407407, "train_stats/max_log_achievement_make_wood_sword": 1.9444444444444444, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.712962962962963, "train_stats/max_log_achievement_place_stone": 0.018518518518518517, "train_stats/max_log_achievement_place_table": 2.388888888888889, "train_stats/max_log_achievement_wake_up": 1.2962962962962963, "train_stats/mean_log_entropy": 0.488223520969903, "eval_stats/sum_log_reward": 6.016666670640309, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.041666666666666664, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 1.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.4583333333333333, "eval_stats/max_log_achievement_place_stone": 0.041666666666666664, "eval_stats/max_log_achievement_place_table": 2.5416666666666665, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00023436493938788772, "report/cont_loss_std": 0.005867050960659981, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004691325593739748, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002325163659406826, "report/cont_pred": 0.9919768571853638, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 15.553954124450684, "report/dyn_loss_std": 8.84194564819336, "report/image_loss_mean": 8.555206298828125, "report/image_loss_std": 10.525795936584473, "report/model_loss_mean": 17.963764190673828, "report/model_loss_std": 14.280908584594727, "report/post_ent_mag": 58.12429428100586, "report/post_ent_max": 58.12429428100586, "report/post_ent_mean": 38.897186279296875, "report/post_ent_min": 19.88202476501465, "report/post_ent_std": 6.770985126495361, "report/prior_ent_mag": 66.02983093261719, "report/prior_ent_max": 66.02983093261719, "report/prior_ent_mean": 54.87880325317383, "report/prior_ent_min": 37.0088005065918, "report/prior_ent_std": 5.168534278869629, "report/rep_loss_mean": 15.553954124450684, "report/rep_loss_std": 8.84194564819336, "report/reward_avg": 0.03632812201976776, "report/reward_loss_mean": 0.0759507268667221, "report/reward_loss_std": 0.33706536889076233, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0093419551849365, "report/reward_neg_acc": 0.9908162951469421, "report/reward_neg_loss": 0.037298865616321564, "report/reward_pos_acc": 0.9545454978942871, "report/reward_pos_loss": 0.9368330836296082, "report/reward_pred": 0.034977227449417114, "report/reward_rate": 0.04296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.599755993694998e-05, "eval/cont_loss_std": 0.0013591930037364364, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.1470056961115915e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.60651281173341e-05, "eval/cont_pred": 0.9980019330978394, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.564302444458008, "eval/dyn_loss_std": 9.622260093688965, "eval/image_loss_mean": 10.513290405273438, "eval/image_loss_std": 12.231478691101074, "eval/model_loss_mean": 20.544754028320312, "eval/model_loss_std": 16.319805145263672, "eval/post_ent_mag": 57.52557373046875, "eval/post_ent_max": 57.52557373046875, "eval/post_ent_mean": 40.200843811035156, "eval/post_ent_min": 21.645679473876953, "eval/post_ent_std": 7.144203186035156, "eval/prior_ent_mag": 66.02983093261719, "eval/prior_ent_max": 66.02983093261719, "eval/prior_ent_mean": 54.65312194824219, "eval/prior_ent_min": 35.707584381103516, "eval/prior_ent_std": 5.581253528594971, "eval/rep_loss_mean": 16.564302444458008, "eval/rep_loss_std": 9.622260093688965, "eval/reward_avg": 0.02373046986758709, "eval/reward_loss_mean": 0.09283696115016937, "eval/reward_loss_std": 0.7132052183151245, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0019526481628418, "eval/reward_neg_acc": 0.9909819960594177, "eval/reward_neg_loss": 0.017486700788140297, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.985128164291382, "eval/reward_pred": 0.014546043239533901, "eval/reward_rate": 0.025390625, "replay/size": 350817.0, "replay/inserts": 21568.0, "replay/samples": 21568.0, "replay/insert_wait_avg": 1.4158756159887115e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.357221756207836e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72136.0, "eval_replay/inserts": 6648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2419786120436538e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1955637931824, "timer/env.step_count": 2696.0, "timer/env.step_total": 244.34247183799744, "timer/env.step_frac": 0.2442946966404681, "timer/env.step_avg": 0.0906314806520762, "timer/env.step_min": 0.023108243942260742, "timer/env.step_max": 2.0728821754455566, "timer/replay._sample_count": 21568.0, "timer/replay._sample_total": 10.957158327102661, "timer/replay._sample_frac": 0.010955015922634457, "timer/replay._sample_avg": 0.0005080284832670002, "timer/replay._sample_min": 0.00038313865661621094, "timer/replay._sample_max": 0.025532007217407227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3527.0, "timer/agent.policy_total": 57.04446005821228, "timer/agent.policy_frac": 0.05703330640847331, "timer/agent.policy_avg": 0.016173649009983634, "timer/agent.policy_min": 0.009376049041748047, "timer/agent.policy_max": 0.10114789009094238, "timer/dataset_train_count": 1348.0, "timer/dataset_train_total": 0.1434779167175293, "timer/dataset_train_frac": 0.0001434498631181664, "timer/dataset_train_avg": 0.00010643762367769236, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00026535987854003906, "timer/agent.train_count": 1348.0, "timer/agent.train_total": 599.4910435676575, "timer/agent.train_frac": 0.5993738277483688, "timer/agent.train_avg": 0.4447262934478171, "timer/agent.train_min": 0.43300771713256836, "timer/agent.train_max": 1.5665664672851562, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47000813484191895, "timer/agent.report_frac": 0.0004699162362402818, "timer/agent.report_avg": 0.23500406742095947, "timer/agent.report_min": 0.2280876636505127, "timer/agent.report_max": 0.24192047119140625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1226727045115074e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.563494944311184}
{"step": 352040, "time": 16412.252199411392, "episode/length": 272.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 352048, "time": 16414.329003810883, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 352288, "time": 16425.389298439026, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 352544, "time": 16435.46364235878, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 352608, "time": 16439.20387148857, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 352928, "time": 16451.42897129059, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 352944, "time": 16453.638857126236, "episode/length": 232.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 353048, "time": 16458.370139837265, "episode/length": 274.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 353384, "time": 16470.955030202866, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 354000, "time": 16493.299612998962, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 354192, "time": 16501.25452017784, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 354240, "time": 16504.35963368416, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 354240, "time": 16504.369797706604, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 354384, "time": 16512.491505622864, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 354712, "time": 16524.64927482605, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 355368, "time": 16547.902274608612, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 355560, "time": 16555.686807870865, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 355576, "time": 16557.838760137558, "episode/length": 330.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9939577039274925, "episode/intrinsic_return": 0.0}
{"step": 355656, "time": 16562.01827597618, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 355728, "time": 16566.106170654297, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 355776, "time": 16569.342707395554, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 355904, "time": 16575.276264190674, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 355944, "time": 16577.878520011902, "episode/length": 153.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 356784, "time": 16607.329318523407, "episode/length": 131.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 356800, "time": 16609.418739557266, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 357008, "time": 16617.955459356308, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 357248, "time": 16627.654638051987, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 357328, "time": 16632.055666446686, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 357368, "time": 16635.185435771942, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 357600, "time": 16645.27663040161, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 357688, "time": 16649.42177462578, "episode/length": 289.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 358088, "time": 16664.261283397675, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 358224, "time": 16670.519968748093, "episode/length": 66.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 358272, "time": 16673.666612148285, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 358792, "time": 16692.380754470825, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 358960, "time": 16699.85266804695, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 359096, "time": 16705.7305393219, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 359232, "time": 16712.080615997314, "episode/length": 277.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 359816, "time": 16732.85449576378, "episode/length": 198.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 359856, "time": 16735.876842737198, "episode/length": 94.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 360024, "time": 16742.7774143219, "episode/length": 218.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16767.815604925156, "eval_episode/length": 178.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 360048, "time": 16769.568843603134, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 360048, "time": 16771.98464202881, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9653465346534653}
{"step": 360048, "time": 16774.300188302994, "eval_episode/length": 218.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9680365296803652}
{"step": 360048, "time": 16776.14737868309, "eval_episode/length": 226.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 360048, "time": 16778.136155366898, "eval_episode/length": 52.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 360048, "time": 16780.40845823288, "eval_episode/length": 246.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9757085020242915}
{"step": 360048, "time": 16782.116265535355, "eval_episode/length": 247.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9717741935483871}
{"step": 360408, "time": 16793.792094230652, "episode/length": 289.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 360456, "time": 16797.35368990898, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 360544, "time": 16803.575972557068, "episode/length": 411.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 360632, "time": 16807.835335731506, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 361216, "time": 16829.028968572617, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 361488, "time": 16839.659384965897, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 361696, "time": 16848.185235738754, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 361992, "time": 16859.19433426857, "episode/length": 399.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 362032, "time": 16862.294893026352, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 362048, "time": 16864.344275712967, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 362128, "time": 16868.65247154236, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 362464, "time": 16881.28585624695, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 362792, "time": 16893.973603725433, "episode/length": 99.0, "episode/score": 5.100000038743019, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 362912, "time": 16899.875494480133, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 363040, "time": 16905.639325380325, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 363128, "time": 16909.91734814644, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 363448, "time": 16922.058228492737, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 363472, "time": 16924.587015867233, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 363512, "time": 16927.22480583191, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 364208, "time": 16952.27632665634, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 364352, "time": 16958.620671987534, "episode/length": 104.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 364368, "time": 16960.663420200348, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 364632, "time": 16970.65973830223, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 364672, "time": 16973.815060853958, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 364688, "time": 16975.898816108704, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 364736, "time": 16979.12096977234, "episode/length": 200.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 364912, "time": 16986.53165245056, "episode/length": 182.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 365600, "time": 17010.931030988693, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 365752, "time": 17017.290662527084, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 366008, "time": 17027.52778339386, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 366224, "time": 17036.612241506577, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 366464, "time": 17046.219608783722, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 366632, "time": 17053.168429613113, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 366640, "time": 17055.20290851593, "episode/length": 51.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 366784, "time": 17061.541348218918, "episode/length": 301.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 366888, "time": 17066.77576160431, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 366936, "time": 17070.04837346077, "episode/length": 280.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 367272, "time": 17082.804470062256, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 367376, "time": 17088.018703460693, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 368000, "time": 17110.227979183197, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 368104, "time": 17114.9544005394, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 368384, "time": 17126.014741182327, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 368432, "time": 17129.103689193726, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 368440, "time": 17130.65613102913, "episode/length": 41.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 368504, "time": 17134.257801532745, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 368904, "time": 17150.483160495758, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 368960, "time": 17154.206742048264, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 369296, "time": 17167.256828069687, "episode/length": 331.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.0}
{"step": 369864, "time": 17187.679431915283, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 369976, "time": 17193.011872291565, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17220.78400182724, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 370032, "time": 17223.04710650444, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 370032, "time": 17225.765003442764, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 370032, "time": 17228.81238770485, "eval_episode/length": 47.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8958333333333334}
{"step": 370032, "time": 17231.001544713974, "eval_episode/length": 221.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 370032, "time": 17233.40003347397, "eval_episode/length": 240.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.991701244813278}
{"step": 370032, "time": 17235.543038129807, "eval_episode/length": 254.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 370032, "time": 17237.858966588974, "eval_episode/length": 51.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 370144, "time": 17241.56569814682, "episode/length": 147.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 370160, "time": 17243.619535446167, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 370336, "time": 17251.028588056564, "episode/length": 178.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 370680, "time": 17263.884032726288, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 370864, "time": 17271.665850162506, "episode/length": 302.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 371040, "time": 17279.013491630554, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 371128, "time": 17283.194866657257, "episode/length": 55.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 371440, "time": 17295.367710590363, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 371448, "time": 17296.877408266068, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 371608, "time": 17303.613705158234, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 371776, "time": 17310.907200813293, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 371784, "time": 17312.551369428635, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 372328, "time": 17332.108116149902, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 372712, "time": 17346.38729119301, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 372840, "time": 17352.345508098602, "episode/length": 213.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 372856, "time": 17354.50383925438, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 372880, "time": 17356.998903751373, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 373008, "time": 17362.83066058159, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 373080, "time": 17367.21892118454, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 373168, "time": 17371.88050174713, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 373609, "time": 17388.660264968872, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.055423434689748, "train/action_min": 0.0, "train/action_std": 3.1635361969899787, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04761828310626874, "train/actor_opt_grad_steps": 22560.0, "train/actor_opt_loss": -5.730920735719821, "train/adv_mag": 0.6536935074723882, "train/adv_max": 0.6358699519857228, "train/adv_mean": 0.0037649685942309093, "train/adv_min": -0.48173996591739515, "train/adv_std": 0.07183009804152757, "train/cont_avg": 0.9948923673561151, "train/cont_loss_mean": 0.00030534947866888465, "train/cont_loss_std": 0.008690604692422128, "train/cont_neg_acc": 0.9924258127592612, "train/cont_neg_loss": 0.03387122535570888, "train/cont_pos_acc": 0.9999575863639227, "train/cont_pos_loss": 0.00012401424277771683, "train/cont_pred": 0.9948829626865524, "train/cont_rate": 0.9948923673561151, "train/dyn_loss_mean": 14.24710150931379, "train/dyn_loss_std": 8.837463231395475, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8683651865815087, "train/extr_critic_critic_opt_grad_steps": 22560.0, "train/extr_critic_critic_opt_loss": 15729.195516243255, "train/extr_critic_mag": 5.417819537704797, "train/extr_critic_max": 5.417819537704797, "train/extr_critic_mean": 1.3249963376161864, "train/extr_critic_min": -0.18852164934007384, "train/extr_critic_std": 1.197699649299649, "train/extr_return_normed_mag": 1.742444303395937, "train/extr_return_normed_max": 1.742444303395937, "train/extr_return_normed_mean": 0.3263655406751221, "train/extr_return_normed_min": -0.1685117623038429, "train/extr_return_normed_std": 0.3276195569004086, "train/extr_return_rate": 0.6921449123526648, "train/extr_return_raw_mag": 6.676745967041675, "train/extr_return_raw_max": 6.676745967041675, "train/extr_return_raw_mean": 1.3391604187677233, "train/extr_return_raw_min": -0.5262639897761585, "train/extr_return_raw_std": 1.235113161930935, "train/extr_reward_mag": 1.0157961793940702, "train/extr_reward_max": 1.0157961793940702, "train/extr_reward_mean": 0.028967309113350704, "train/extr_reward_min": -0.39498989959414915, "train/extr_reward_std": 0.15557365848434915, "train/image_loss_mean": 8.030707355883482, "train/image_loss_std": 12.10200201007102, "train/model_loss_mean": 16.63390762685872, "train/model_loss_std": 15.7172889435034, "train/model_opt_grad_norm": 64.97001084037448, "train/model_opt_grad_steps": 22537.913669064747, "train/model_opt_loss": 19140.789181935703, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 1142.086330935252, "train/policy_entropy_mag": 2.313243407997296, "train/policy_entropy_max": 2.313243407997296, "train/policy_entropy_mean": 0.48629532100485384, "train/policy_entropy_min": 0.07937516341749713, "train/policy_entropy_std": 0.474867564954346, "train/policy_logprob_mag": 7.438383315106948, "train/policy_logprob_max": -0.0094557698856262, "train/policy_logprob_mean": -0.486158753256146, "train/policy_logprob_min": -7.438383315106948, "train/policy_logprob_std": 1.0331359458484237, "train/policy_randomness_mag": 0.8164734081398669, "train/policy_randomness_max": 0.8164734081398669, "train/policy_randomness_mean": 0.17164090983301616, "train/policy_randomness_min": 0.02801594940824903, "train/policy_randomness_std": 0.16760740959815842, "train/post_ent_mag": 56.99950537921713, "train/post_ent_max": 56.99950537921713, "train/post_ent_mean": 39.983791653200875, "train/post_ent_min": 20.493849157429427, "train/post_ent_std": 7.164721087586108, "train/prior_ent_mag": 66.34114003352981, "train/prior_ent_max": 66.34114003352981, "train/prior_ent_mean": 54.313453152882964, "train/prior_ent_min": 35.45870745267799, "train/prior_ent_std": 5.078810283606001, "train/rep_loss_mean": 14.24710150931379, "train/rep_loss_std": 8.837463231395475, "train/reward_avg": 0.024342400832570714, "train/reward_loss_mean": 0.054634203611732386, "train/reward_loss_std": 0.2509813780407254, "train/reward_max_data": 1.0165467665349837, "train/reward_max_pred": 1.0100213452208815, "train/reward_neg_acc": 0.9927542192472828, "train/reward_neg_loss": 0.030100874177334334, "train/reward_pos_acc": 0.9625162932512571, "train/reward_pos_loss": 0.8764285805414049, "train/reward_pred": 0.023552834779935347, "train/reward_rate": 0.029008824190647483, "train_stats/sum_log_reward": 6.289189186182108, "train_stats/max_log_achievement_collect_coal": 0.05405405405405406, "train_stats/max_log_achievement_collect_drink": 4.8108108108108105, "train_stats/max_log_achievement_collect_sapling": 2.027027027027027, "train_stats/max_log_achievement_collect_stone": 1.3603603603603605, "train_stats/max_log_achievement_collect_wood": 9.63063063063063, "train_stats/max_log_achievement_defeat_skeleton": 0.009009009009009009, "train_stats/max_log_achievement_defeat_zombie": 0.7477477477477478, "train_stats/max_log_achievement_eat_cow": 0.11711711711711711, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3063063063063063, "train_stats/max_log_achievement_make_wood_sword": 0.8198198198198198, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.3963963963963963, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.774774774774775, "train_stats/max_log_achievement_wake_up": 1.2162162162162162, "train_stats/mean_log_entropy": 0.45128500636096475, "eval_stats/sum_log_reward": 5.725000087171793, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 1.375, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.3125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.5, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 7.712788828939665e-06, "report/cont_loss_std": 0.00012059266009600833, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.713558155344799e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.480435215256875e-06, "report/cont_pred": 0.994133472442627, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.869319915771484, "report/dyn_loss_std": 8.510445594787598, "report/image_loss_mean": 5.761468887329102, "report/image_loss_std": 9.71849536895752, "report/model_loss_mean": 14.125748634338379, "report/model_loss_std": 13.0529203414917, "report/post_ent_mag": 53.839210510253906, "report/post_ent_max": 53.839210510253906, "report/post_ent_mean": 39.383209228515625, "report/post_ent_min": 21.66069221496582, "report/post_ent_std": 6.548135280609131, "report/prior_ent_mag": 67.04888916015625, "report/prior_ent_max": 67.04888916015625, "report/prior_ent_mean": 53.8367919921875, "report/prior_ent_min": 38.393150329589844, "report/prior_ent_std": 4.599186897277832, "report/rep_loss_mean": 13.869319915771484, "report/rep_loss_std": 8.510445594787598, "report/reward_avg": 0.02978515625, "report/reward_loss_mean": 0.04268048703670502, "report/reward_loss_std": 0.17844772338867188, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029447078704834, "report/reward_neg_acc": 0.9979797005653381, "report/reward_neg_loss": 0.017947709187865257, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.7628408074378967, "report/reward_pred": 0.028986606746912003, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0014671670505777001, "eval/cont_loss_std": 0.04606805741786957, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.2949855327606201, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.6939604140352458e-05, "eval/cont_pred": 0.9958440065383911, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.633914947509766, "eval/dyn_loss_std": 10.624449729919434, "eval/image_loss_mean": 10.396230697631836, "eval/image_loss_std": 17.53514862060547, "eval/model_loss_mean": 20.456607818603516, "eval/model_loss_std": 21.539518356323242, "eval/post_ent_mag": 58.58181381225586, "eval/post_ent_max": 58.58181381225586, "eval/post_ent_mean": 40.19799041748047, "eval/post_ent_min": 22.04562759399414, "eval/post_ent_std": 7.4181952476501465, "eval/prior_ent_mag": 67.04888916015625, "eval/prior_ent_max": 67.04888916015625, "eval/prior_ent_mean": 54.98292922973633, "eval/prior_ent_min": 33.510250091552734, "eval/prior_ent_std": 5.162179470062256, "eval/rep_loss_mean": 16.633914947509766, "eval/rep_loss_std": 10.624449729919434, "eval/reward_avg": 0.02734375186264515, "eval/reward_loss_mean": 0.07856306433677673, "eval/reward_loss_std": 0.46869152784347534, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0023446083068848, "eval/reward_neg_acc": 0.9919273257255554, "eval/reward_neg_loss": 0.04197680577635765, "eval/reward_pos_acc": 0.939393937587738, "eval/reward_pos_loss": 1.1772592067718506, "eval/reward_pred": 0.027875080704689026, "eval/reward_rate": 0.0322265625, "replay/size": 373105.0, "replay/inserts": 22288.0, "replay/samples": 22288.0, "replay/insert_wait_avg": 1.4694919709413066e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.547654279940264e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76312.0, "eval_replay/inserts": 4176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.266484516333803e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0280737876892, "timer/env.step_count": 2786.0, "timer/env.step_total": 252.54975962638855, "timer/env.step_frac": 0.2525426697970942, "timer/env.step_avg": 0.09064959067709567, "timer/env.step_min": 0.02305889129638672, "timer/env.step_max": 3.3227295875549316, "timer/replay._sample_count": 22288.0, "timer/replay._sample_total": 11.38923978805542, "timer/replay._sample_frac": 0.011388920057931705, "timer/replay._sample_avg": 0.0005110032209285454, "timer/replay._sample_min": 0.0003857612609863281, "timer/replay._sample_max": 0.010938644409179688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3308.0, "timer/agent.policy_total": 55.25222158432007, "timer/agent.policy_frac": 0.05525067048872708, "timer/agent.policy_avg": 0.016702606283047178, "timer/agent.policy_min": 0.00932931900024414, "timer/agent.policy_max": 0.1280064582824707, "timer/dataset_train_count": 1393.0, "timer/dataset_train_total": 0.15015912055969238, "timer/dataset_train_frac": 0.0001501549051427649, "timer/dataset_train_avg": 0.00010779549214622569, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0010771751403808594, "timer/agent.train_count": 1393.0, "timer/agent.train_total": 619.1167469024658, "timer/agent.train_frac": 0.6190993664382939, "timer/agent.train_avg": 0.44444849023866895, "timer/agent.train_min": 0.432955265045166, "timer/agent.train_max": 1.5170559883117676, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47148704528808594, "timer/agent.report_frac": 0.00047147380923246454, "timer/agent.report_avg": 0.23574352264404297, "timer/agent.report_min": 0.2287614345550537, "timer/agent.report_max": 0.24272561073303223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956307386113473e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.287058835879535}
{"step": 374032, "time": 17402.871558189392, "episode/length": 148.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 374112, "time": 17407.042116642, "episode/length": 137.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 374112, "time": 17407.052961826324, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 374168, "time": 17412.045097351074, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 374528, "time": 17425.89528107643, "episode/length": 226.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 374576, "time": 17429.138978004456, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 374672, "time": 17433.848697900772, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 375168, "time": 17451.876116752625, "episode/length": 260.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 375680, "time": 17470.416387557983, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 375704, "time": 17472.606018781662, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 375720, "time": 17474.75727725029, "episode/length": 210.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 375936, "time": 17483.607709884644, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 375936, "time": 17483.616609096527, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 376008, "time": 17489.15089416504, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 376432, "time": 17505.073284864426, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 376504, "time": 17508.62493443489, "episode/length": 298.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 376968, "time": 17526.854068756104, "episode/length": 128.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 377288, "time": 17539.133927106857, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 377536, "time": 17549.027230978012, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 377536, "time": 17549.037094593048, "episode/length": 199.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 377624, "time": 17555.890141010284, "episode/length": 201.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 377728, "time": 17561.227832078934, "episode/length": 54.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 377888, "time": 17567.986023426056, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 378024, "time": 17573.77724313736, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 378224, "time": 17582.197043180466, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 378312, "time": 17586.443294525146, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 378944, "time": 17609.30237197876, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 378992, "time": 17612.37897849083, "episode/length": 181.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 379056, "time": 17615.960555553436, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 379088, "time": 17618.556257009506, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 379456, "time": 17632.294673919678, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 379464, "time": 17633.942301511765, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 379608, "time": 17640.363708257675, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 379608, "time": 17640.372891664505, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17672.83041715622, "eval_episode/length": 54.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 380016, "time": 17679.17503428459, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 380016, "time": 17681.108606815338, "eval_episode/length": 172.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 380016, "time": 17682.935033798218, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 380016, "time": 17684.67899441719, "eval_episode/length": 183.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 380016, "time": 17686.65553665161, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 380016, "time": 17688.563731193542, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 380016, "time": 17692.940149068832, "eval_episode/length": 212.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 380264, "time": 17700.875990867615, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 380400, "time": 17707.121351480484, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 380608, "time": 17715.67572236061, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 380664, "time": 17718.894169330597, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 381040, "time": 17733.096240997314, "episode/length": 197.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 381072, "time": 17735.814589738846, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 381128, "time": 17739.066892147064, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 381176, "time": 17742.18182325363, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 381432, "time": 17752.172827482224, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 381896, "time": 17769.112292289734, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 382184, "time": 17780.127579450607, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 382248, "time": 17783.817395687103, "episode/length": 139.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 382448, "time": 17792.264791488647, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 382488, "time": 17794.88826775551, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 382624, "time": 17801.273763656616, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 382928, "time": 17812.89773607254, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 383360, "time": 17828.799908161163, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 383384, "time": 17830.97769188881, "episode/length": 94.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 383800, "time": 17846.86612892151, "episode/length": 54.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 383800, "time": 17846.876226186752, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 383848, "time": 17851.894409894943, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 383984, "time": 17858.218277215958, "episode/length": 186.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 384464, "time": 17875.703737020493, "episode/length": 378.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9920844327176781, "episode/intrinsic_return": 0.0}
{"step": 384576, "time": 17880.910388469696, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 384920, "time": 17894.01352953911, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 385032, "time": 17899.58348441124, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 385152, "time": 17907.29785823822, "episode/length": 362.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 385208, "time": 17910.486703634262, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 385856, "time": 17934.181592941284, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 386072, "time": 17942.671994686127, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 386344, "time": 17953.42847752571, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 386712, "time": 17967.217825889587, "episode/length": 357.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 386720, "time": 17969.229832410812, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 386720, "time": 17969.238753557205, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 387160, "time": 17986.80577468872, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 387312, "time": 17993.535188913345, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 387776, "time": 18010.520908355713, "episode/length": 132.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 387928, "time": 18016.886983394623, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 387944, "time": 18019.05340576172, "episode/length": 341.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 388304, "time": 18032.764913082123, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 388400, "time": 18037.609719753265, "episode/length": 420.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9857482185273159, "episode/intrinsic_return": 0.0}
{"step": 388624, "time": 18046.768537282944, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 388808, "time": 18054.18818449974, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 388840, "time": 18056.730576515198, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 388904, "time": 18060.436467647552, "episode/length": 140.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 389032, "time": 18066.173689842224, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 389232, "time": 18074.627349853516, "episode/length": 48.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 389704, "time": 18091.47205901146, "episode/length": 174.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 389792, "time": 18096.24626684189, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18120.402779102325, "eval_episode/length": 55.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 390000, "time": 18123.060180425644, "eval_episode/length": 80.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9382716049382716}
{"step": 390000, "time": 18129.652165174484, "eval_episode/length": 197.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 390000, "time": 18131.255123853683, "eval_episode/length": 198.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 390000, "time": 18134.424098730087, "eval_episode/length": 236.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 390000, "time": 18136.19391131401, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 390000, "time": 18139.172696113586, "eval_episode/length": 276.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9819494584837545}
{"step": 390000, "time": 18140.901295900345, "eval_episode/length": 228.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 390008, "time": 18140.95186305046, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 390088, "time": 18145.28223466873, "episode/length": 267.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 390312, "time": 18154.94270181656, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 390696, "time": 18169.788898468018, "episode/length": 182.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 390776, "time": 18174.003131628036, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 391136, "time": 18187.69571495056, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 391160, "time": 18189.915309906006, "episode/length": 57.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 391248, "time": 18194.622039318085, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 391584, "time": 18207.332762479782, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 391688, "time": 18212.148693799973, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 391752, "time": 18215.752247810364, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 392320, "time": 18236.552867650986, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 392360, "time": 18239.22506737709, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 392424, "time": 18242.84808087349, "episode/length": 339.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 392680, "time": 18252.880323410034, "episode/length": 178.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 393136, "time": 18269.75763940811, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 393408, "time": 18281.826966285706, "episode/length": 214.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 393432, "time": 18284.08153986931, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9721254355400697, "episode/intrinsic_return": 0.0}
{"step": 393544, "time": 18289.339179754257, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 393624, "time": 18293.530245304108, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 393824, "time": 18301.999212503433, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 394048, "time": 18310.96364879608, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 394424, "time": 18324.83068394661, "episode/length": 99.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 394648, "time": 18333.886885404587, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 394720, "time": 18338.28548336029, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 394904, "time": 18345.787925243378, "episode/length": 59.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 394944, "time": 18348.874251127243, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 395016, "time": 18352.700848340988, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 395112, "time": 18357.36724972725, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 395488, "time": 18371.71688938141, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 395712, "time": 18380.59727549553, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 395897, "time": 18388.97231030464, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.991048908919739, "train/action_min": 0.0, "train/action_std": 2.985405599470619, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04766840522559427, "train/actor_opt_grad_steps": 23950.0, "train/actor_opt_loss": 1.0868203470604025, "train/adv_mag": 0.6653545790439029, "train/adv_max": 0.6466638681699903, "train/adv_mean": 0.005087494074405513, "train/adv_min": -0.48311226380814754, "train/adv_std": 0.07170340544778667, "train/cont_avg": 0.9944989321043165, "train/cont_loss_mean": 0.00031692761773202823, "train/cont_loss_std": 0.008925754165577948, "train/cont_neg_acc": 0.9898024458679364, "train/cont_neg_loss": 0.026486630966338198, "train/cont_pos_acc": 0.9999505873206708, "train/cont_pos_loss": 0.0001404704417655339, "train/cont_pred": 0.9944749911912054, "train/cont_rate": 0.9944989321043165, "train/dyn_loss_mean": 14.249959245860147, "train/dyn_loss_std": 8.919897628345078, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8596221127098412, "train/extr_critic_critic_opt_grad_steps": 23950.0, "train/extr_critic_critic_opt_loss": 15828.719382306655, "train/extr_critic_mag": 5.594598478550534, "train/extr_critic_max": 5.594598478550534, "train/extr_critic_mean": 1.3864505453933058, "train/extr_critic_min": -0.17399946819964074, "train/extr_critic_std": 1.2335201364626986, "train/extr_return_normed_mag": 1.7359726206004191, "train/extr_return_normed_max": 1.7359726206004191, "train/extr_return_normed_mean": 0.3273075822231581, "train/extr_return_normed_min": -0.1652741753797737, "train/extr_return_normed_std": 0.32707944587409066, "train/extr_return_rate": 0.7145290417636899, "train/extr_return_raw_mag": 6.883256706402456, "train/extr_return_raw_max": 6.883256706402456, "train/extr_return_raw_mean": 1.4062254321660927, "train/extr_return_raw_min": -0.5090631094339083, "train/extr_return_raw_std": 1.271871757164276, "train/extr_reward_mag": 1.0149779748573577, "train/extr_reward_max": 1.0149779748573577, "train/extr_reward_mean": 0.030287148303640404, "train/extr_reward_min": -0.3854854029717205, "train/extr_reward_std": 0.15983436706898024, "train/image_loss_mean": 8.126506404053393, "train/image_loss_std": 12.217490360891219, "train/model_loss_mean": 16.73267589541648, "train/model_loss_std": 15.875993207204257, "train/model_opt_grad_norm": 65.09033477563652, "train/model_opt_grad_steps": 23926.266187050358, "train/model_opt_loss": 13356.072451804182, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 800.3597122302158, "train/policy_entropy_mag": 2.3126243876038695, "train/policy_entropy_max": 2.3126243876038695, "train/policy_entropy_mean": 0.47567062755282835, "train/policy_entropy_min": 0.07937517472737127, "train/policy_entropy_std": 0.4700037584030371, "train/policy_logprob_mag": 7.4383833631337115, "train/policy_logprob_max": -0.009455758823658065, "train/policy_logprob_mean": -0.47552505049774113, "train/policy_logprob_min": -7.4383833631337115, "train/policy_logprob_std": 1.0262919222708229, "train/policy_randomness_mag": 0.8162549219543128, "train/policy_randomness_max": 0.8162549219543128, "train/policy_randomness_mean": 0.16789085927198258, "train/policy_randomness_min": 0.028015953280942904, "train/policy_randomness_std": 0.16589070063271968, "train/post_ent_mag": 57.32669816600333, "train/post_ent_max": 57.32669816600333, "train/post_ent_mean": 40.23050911992574, "train/post_ent_min": 20.25044620294365, "train/post_ent_std": 7.213922435431171, "train/prior_ent_mag": 66.37948740128991, "train/prior_ent_max": 66.37948740128991, "train/prior_ent_mean": 54.51421059807428, "train/prior_ent_min": 36.35560105687423, "train/prior_ent_std": 4.999780613741429, "train/rep_loss_mean": 14.249959245860147, "train/rep_loss_std": 8.919897628345078, "train/reward_avg": 0.024333267586587146, "train/reward_loss_mean": 0.055877141265882, "train/reward_loss_std": 0.25858807917550314, "train/reward_max_data": 1.0165467665349837, "train/reward_max_pred": 1.00987453940961, "train/reward_neg_acc": 0.9928935912015627, "train/reward_neg_loss": 0.03108538031953273, "train/reward_pos_acc": 0.9611578549412515, "train/reward_pos_loss": 0.8737766665520428, "train/reward_pred": 0.023547745758680988, "train/reward_rate": 0.029303900629496404, "train_stats/sum_log_reward": 6.678947417359603, "train_stats/max_log_achievement_collect_coal": 0.16666666666666666, "train_stats/max_log_achievement_collect_drink": 4.157894736842105, "train_stats/max_log_achievement_collect_sapling": 2.1140350877192984, "train_stats/max_log_achievement_collect_stone": 2.3596491228070176, "train_stats/max_log_achievement_collect_wood": 10.666666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.7017543859649122, "train_stats/max_log_achievement_eat_cow": 0.12280701754385964, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.517543859649123, "train_stats/max_log_achievement_make_wood_sword": 0.02631578947368421, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.780701754385965, "train_stats/max_log_achievement_place_stone": 0.03508771929824561, "train_stats/max_log_achievement_place_table": 2.7280701754385963, "train_stats/max_log_achievement_wake_up": 1.1140350877192982, "train_stats/mean_log_entropy": 0.43632897917638747, "eval_stats/sum_log_reward": 6.100000023841858, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 1.4375, "eval_stats/max_log_achievement_collect_wood": 7.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.442303624178749e-06, "report/cont_loss_std": 0.00021424728038255125, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0018547145882621408, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.2020191206829622e-06, "report/cont_pred": 0.9960998296737671, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.416561126708984, "report/dyn_loss_std": 7.934936046600342, "report/image_loss_mean": 6.526494026184082, "report/image_loss_std": 9.011849403381348, "report/model_loss_mean": 15.217916488647461, "report/model_loss_std": 12.12864875793457, "report/post_ent_mag": 57.260459899902344, "report/post_ent_max": 57.260459899902344, "report/post_ent_mean": 39.79880905151367, "report/post_ent_min": 21.507610321044922, "report/post_ent_std": 7.103142261505127, "report/prior_ent_mag": 66.40697479248047, "report/prior_ent_max": 66.40697479248047, "report/prior_ent_mean": 55.10877227783203, "report/prior_ent_min": 39.29485321044922, "report/prior_ent_std": 4.51172399520874, "report/rep_loss_mean": 14.416561126708984, "report/rep_loss_std": 7.934936046600342, "report/reward_avg": 0.03173828125, "report/reward_loss_mean": 0.04147655889391899, "report/reward_loss_std": 0.18564753234386444, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041446685791016, "report/reward_neg_acc": 0.9919028878211975, "report/reward_neg_loss": 0.01358080841600895, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.8070599436759949, "report/reward_pred": 0.03134540840983391, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0025509146507829428, "eval/cont_loss_std": 0.07934100925922394, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.870295524597168, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2242476259416435e-06, "eval/cont_pred": 0.99803626537323, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.909236907958984, "eval/dyn_loss_std": 9.177265167236328, "eval/image_loss_mean": 18.362197875976562, "eval/image_loss_std": 31.991594314575195, "eval/model_loss_mean": 29.208053588867188, "eval/model_loss_std": 34.65771484375, "eval/post_ent_mag": 57.772430419921875, "eval/post_ent_max": 57.772430419921875, "eval/post_ent_mean": 40.25579071044922, "eval/post_ent_min": 22.005718231201172, "eval/post_ent_std": 7.05123233795166, "eval/prior_ent_mag": 66.40697479248047, "eval/prior_ent_max": 66.40697479248047, "eval/prior_ent_mean": 56.350379943847656, "eval/prior_ent_min": 40.708885192871094, "eval/prior_ent_std": 4.646608829498291, "eval/rep_loss_mean": 17.909236907958984, "eval/rep_loss_std": 9.177265167236328, "eval/reward_avg": 0.01923828013241291, "eval/reward_loss_mean": 0.0977630466222763, "eval/reward_loss_std": 0.7340782880783081, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022635459899902, "eval/reward_neg_acc": 0.9900199770927429, "eval/reward_neg_loss": 0.040028564631938934, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 2.7273061275482178, "eval/reward_pred": 0.017725156620144844, "eval/reward_rate": 0.021484375, "replay/size": 395393.0, "replay/inserts": 22288.0, "replay/samples": 22288.0, "replay/insert_wait_avg": 1.4334745913722578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.373076425896047e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 80736.0, "eval_replay/inserts": 4424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.221302404972787e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.29993724823, "timer/env.step_count": 2786.0, "timer/env.step_total": 258.59948539733887, "timer/env.step_frac": 0.2585219450365375, "timer/env.step_avg": 0.09282106439244037, "timer/env.step_min": 0.022855043411254883, "timer/env.step_max": 4.121082067489624, "timer/replay._sample_count": 22288.0, "timer/replay._sample_total": 11.341694593429565, "timer/replay._sample_frac": 0.011338293816782537, "timer/replay._sample_avg": 0.0005088700014998907, "timer/replay._sample_min": 0.00037026405334472656, "timer/replay._sample_max": 0.010805606842041016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3339.0, "timer/agent.policy_total": 54.25631785392761, "timer/agent.policy_frac": 0.054240049242813865, "timer/agent.policy_avg": 0.01624927159446769, "timer/agent.policy_min": 0.009392023086547852, "timer/agent.policy_max": 0.10202527046203613, "timer/dataset_train_count": 1393.0, "timer/dataset_train_total": 0.151808500289917, "timer/dataset_train_frac": 0.00015176298091903697, "timer/dataset_train_avg": 0.00010897954076806676, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.00027751922607421875, "timer/agent.train_count": 1393.0, "timer/agent.train_total": 619.6231000423431, "timer/agent.train_frac": 0.6194373077208144, "timer/agent.train_avg": 0.44481198854439563, "timer/agent.train_min": 0.4325075149536133, "timer/agent.train_max": 1.5448524951934814, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47101521492004395, "timer/agent.report_frac": 0.00047087398227353775, "timer/agent.report_avg": 0.23550760746002197, "timer/agent.report_min": 0.22732758522033691, "timer/agent.report_max": 0.24368762969970703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788660952196033e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.28103290088765}
{"step": 396072, "time": 18394.57420706749, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 396328, "time": 18404.73383283615, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 396408, "time": 18408.96913766861, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 396536, "time": 18414.75760602951, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 396800, "time": 18425.392332315445, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 397072, "time": 18436.043355703354, "episode/length": 270.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 397336, "time": 18446.05109143257, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 397368, "time": 18448.75338244438, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 397592, "time": 18457.63951396942, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 397936, "time": 18470.877180099487, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 398432, "time": 18489.07885169983, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 398568, "time": 18494.91364455223, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 398632, "time": 18498.63742041588, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 398744, "time": 18503.9134888649, "episode/length": 333.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9850299401197605, "episode/intrinsic_return": 0.0}
{"step": 399528, "time": 18531.434809207916, "episode/length": 399.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18571.403829813004, "eval_episode/length": 118.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9495798319327731}
{"step": 400088, "time": 18573.394297599792, "eval_episode/length": 127.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9921875}
{"step": 400088, "time": 18575.194814920425, "eval_episode/length": 133.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 400088, "time": 18577.685735225677, "eval_episode/length": 156.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 400088, "time": 18579.649168014526, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 400088, "time": 18582.908274173737, "eval_episode/length": 202.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 400088, "time": 18585.372286319733, "eval_episode/length": 224.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 400088, "time": 18587.12813949585, "eval_episode/length": 227.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 400192, "time": 18590.82179570198, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 400272, "time": 18595.063140392303, "episode/length": 291.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 400472, "time": 18603.056698799133, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 400480, "time": 18605.04292345047, "episode/length": 255.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 400832, "time": 18618.46053957939, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 401192, "time": 18631.667581796646, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 401424, "time": 18642.74871134758, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 401672, "time": 18652.48375606537, "episode/length": 537.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9869888475836431, "episode/intrinsic_return": 0.0}
{"step": 401816, "time": 18658.864993333817, "episode/length": 527.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 402104, "time": 18669.91020965576, "episode/length": 228.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 402192, "time": 18674.592316627502, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 402352, "time": 18681.485268831253, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 402384, "time": 18684.13432621956, "episode/length": 88.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9325842696629213, "episode/intrinsic_return": 0.0}
{"step": 402496, "time": 18689.397059440613, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 402632, "time": 18695.27733850479, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 402696, "time": 18699.11920762062, "episode/length": 276.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 403688, "time": 18733.42752146721, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 403736, "time": 18736.654369354248, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 403744, "time": 18738.733288049698, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 403808, "time": 18742.422674655914, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 403816, "time": 18743.952477931976, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 404008, "time": 18751.774392604828, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 404088, "time": 18755.832591056824, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 404168, "time": 18759.992712020874, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 404200, "time": 18762.604306697845, "episode/length": 48.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 404992, "time": 18790.420216798782, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 405232, "time": 18799.960433721542, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 405272, "time": 18802.650666475296, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 405400, "time": 18808.451134443283, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 405640, "time": 18818.11940217018, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 405768, "time": 18824.02189517021, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 406048, "time": 18835.1897482872, "episode/length": 131.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 406544, "time": 18853.172699928284, "episode/length": 61.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 406616, "time": 18856.91338133812, "episode/length": 301.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 406712, "time": 18861.58226799965, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 406848, "time": 18867.892933368683, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 406936, "time": 18872.093443393707, "episode/length": 191.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 407152, "time": 18881.03122162819, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 407672, "time": 18899.609930753708, "episode/length": 437.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 407680, "time": 18901.768298864365, "episode/length": 238.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 407984, "time": 18913.564967155457, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 408128, "time": 18919.90323662758, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 408160, "time": 18922.51163172722, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 408200, "time": 18925.12679719925, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 408248, "time": 18928.345134735107, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 408368, "time": 18934.099542856216, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 408592, "time": 18943.130667209625, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 409064, "time": 18960.129996061325, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 409120, "time": 18963.83664250374, "episode/length": 123.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 409448, "time": 18976.19249534607, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 409512, "time": 18979.847507476807, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 409688, "time": 18988.711411476135, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 409744, "time": 18992.33354973793, "episode/length": 197.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 409808, "time": 18996.1265604496, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19026.958831071854, "eval_episode/length": 147.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 410072, "time": 19029.005811691284, "eval_episode/length": 153.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 410072, "time": 19030.879917383194, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 410072, "time": 19032.570528030396, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 410072, "time": 19034.362623929977, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9640718562874252}
{"step": 410072, "time": 19038.301701307297, "eval_episode/length": 59.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9333333333333333}
{"step": 410072, "time": 19039.994235515594, "eval_episode/length": 225.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 410072, "time": 19042.2709004879, "eval_episode/length": 242.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9711934156378601}
{"step": 410216, "time": 19047.022987365723, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 410520, "time": 19058.78045606613, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 410768, "time": 19068.869458913803, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 410832, "time": 19072.68995976448, "episode/length": 38.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 410888, "time": 19076.363793849945, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 411120, "time": 19086.410878181458, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 411224, "time": 19091.300523519516, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 411312, "time": 19096.176419973373, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 412192, "time": 19126.94624733925, "episode/length": 305.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 412344, "time": 19133.413009166718, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 412504, "time": 19140.281943321228, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 412576, "time": 19144.411146879196, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 412600, "time": 19146.63358926773, "episode/length": 220.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 412648, "time": 19149.823236227036, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 412648, "time": 19149.832903146744, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 412712, "time": 19155.244346141815, "episode/length": 311.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 413448, "time": 19180.882636785507, "episode/length": 156.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 413656, "time": 19189.313474416733, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 413800, "time": 19195.68708062172, "episode/length": 161.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 413920, "time": 19201.439988851547, "episode/length": 167.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 413936, "time": 19203.62369775772, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 414136, "time": 19211.607173919678, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 414328, "time": 19219.624532699585, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 415160, "time": 19249.287979364395, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 415176, "time": 19251.304265022278, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 415224, "time": 19254.435549259186, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 415248, "time": 19257.077008247375, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 415272, "time": 19259.33940720558, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 415528, "time": 19269.418597459793, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 415664, "time": 19275.75984978676, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 415872, "time": 19284.182687282562, "episode/length": 302.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 416416, "time": 19303.749519109726, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 416728, "time": 19315.39550590515, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 416792, "time": 19319.19681239128, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 416792, "time": 19319.204134464264, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 416832, "time": 19323.8649353981, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 416960, "time": 19329.741887807846, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 417368, "time": 19344.55477619171, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 417552, "time": 19352.34674525261, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 418064, "time": 19372.39924645424, "episode/length": 166.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 418344, "time": 19382.970376729965, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 418432, "time": 19387.72430896759, "episode/length": 204.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 418433, "time": 19389.936531066895, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9357066053025265, "train/action_min": 0.0, "train/action_std": 3.0813261904615037, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047160727995718625, "train/actor_opt_grad_steps": 25350.0, "train/actor_opt_loss": -1.1677487914232498, "train/adv_mag": 0.6100288614736381, "train/adv_max": 0.5964621654216279, "train/adv_mean": 0.004955582587978393, "train/adv_min": -0.4561041538596999, "train/adv_std": 0.06979455436903534, "train/cont_avg": 0.9945215536347518, "train/cont_loss_mean": 0.00022677962393582345, "train/cont_loss_std": 0.006383223019000083, "train/cont_neg_acc": 0.9930433250488119, "train/cont_neg_loss": 0.02669798736848429, "train/cont_pos_acc": 0.9999860567404023, "train/cont_pos_loss": 7.250233126000947e-05, "train/cont_pred": 0.9945293910114478, "train/cont_rate": 0.9945215536347518, "train/dyn_loss_mean": 14.205088202834975, "train/dyn_loss_std": 8.854392281660797, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8556458028495735, "train/extr_critic_critic_opt_grad_steps": 25350.0, "train/extr_critic_critic_opt_loss": 15902.022911125887, "train/extr_critic_mag": 5.757865567579337, "train/extr_critic_max": 5.757865567579337, "train/extr_critic_mean": 1.5868676106135051, "train/extr_critic_min": -0.1664169485687364, "train/extr_critic_std": 1.298553833724759, "train/extr_return_normed_mag": 1.7010905311462727, "train/extr_return_normed_max": 1.7010905311462727, "train/extr_return_normed_mean": 0.34794177421441314, "train/extr_return_normed_min": -0.15972438343661896, "train/extr_return_normed_std": 0.32685203670609925, "train/extr_return_rate": 0.7895589043908086, "train/extr_return_raw_mag": 7.145507355953785, "train/extr_return_raw_max": 7.145507355953785, "train/extr_return_raw_mean": 1.607048268013812, "train/extr_return_raw_min": -0.4714330094503173, "train/extr_return_raw_std": 1.338263674407986, "train/extr_reward_mag": 1.0161071314033887, "train/extr_reward_max": 1.0161071314033887, "train/extr_reward_mean": 0.03223467896963265, "train/extr_reward_min": -0.3789206286694141, "train/extr_reward_std": 0.16465772709525223, "train/image_loss_mean": 7.59337246671636, "train/image_loss_std": 11.552374991964786, "train/model_loss_mean": 16.175130228624276, "train/model_loss_std": 15.19833746700422, "train/model_opt_grad_norm": 62.6028123544463, "train/model_opt_grad_steps": 25325.524822695035, "train/model_opt_loss": 15360.462121841756, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 953.0141843971631, "train/policy_entropy_mag": 2.3320083533618465, "train/policy_entropy_max": 2.3320083533618465, "train/policy_entropy_mean": 0.47495864574790847, "train/policy_entropy_min": 0.07937515595703261, "train/policy_entropy_std": 0.4697439471880595, "train/policy_logprob_mag": 7.438383400017488, "train/policy_logprob_max": -0.009455743965739054, "train/policy_logprob_mean": -0.4747184855295411, "train/policy_logprob_min": -7.438383400017488, "train/policy_logprob_std": 1.0231612007668678, "train/policy_randomness_mag": 0.8230966113983317, "train/policy_randomness_max": 0.8230966113983317, "train/policy_randomness_mean": 0.16763955893668722, "train/policy_randomness_min": 0.028015946850497672, "train/policy_randomness_std": 0.16579899794243752, "train/post_ent_mag": 57.449741525852936, "train/post_ent_max": 57.449741525852936, "train/post_ent_mean": 40.40587077580445, "train/post_ent_min": 20.38298920705809, "train/post_ent_std": 7.183193470569367, "train/prior_ent_mag": 66.54659601306238, "train/prior_ent_max": 66.54659601306238, "train/prior_ent_mean": 54.636279653995594, "train/prior_ent_min": 36.59139826619033, "train/prior_ent_std": 4.886686763019426, "train/rep_loss_mean": 14.205088202834975, "train/rep_loss_std": 8.854392281660797, "train/reward_avg": 0.026225897589209655, "train/reward_loss_mean": 0.05847814071474346, "train/reward_loss_std": 0.2641259531180064, "train/reward_max_data": 1.0234042608991583, "train/reward_max_pred": 1.010759894729506, "train/reward_neg_acc": 0.9922801032133982, "train/reward_neg_loss": 0.032075576576675084, "train/reward_pos_acc": 0.9602483980199124, "train/reward_pos_loss": 0.882773940444838, "train/reward_pred": 0.02526895009668161, "train/reward_rate": 0.031104554521276594, "train_stats/sum_log_reward": 6.712612685453784, "train_stats/max_log_achievement_collect_coal": 0.21621621621621623, "train_stats/max_log_achievement_collect_drink": 4.54954954954955, "train_stats/max_log_achievement_collect_sapling": 1.5675675675675675, "train_stats/max_log_achievement_collect_stone": 3.2612612612612613, "train_stats/max_log_achievement_collect_wood": 11.072072072072071, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6846846846846847, "train_stats/max_log_achievement_eat_cow": 0.09009009009009009, "train_stats/max_log_achievement_eat_plant": 0.009009009009009009, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.099099099099099, "train_stats/max_log_achievement_make_wood_sword": 0.05405405405405406, "train_stats/max_log_achievement_place_furnace": 0.02702702702702703, "train_stats/max_log_achievement_place_plant": 1.3513513513513513, "train_stats/max_log_achievement_place_stone": 0.036036036036036036, "train_stats/max_log_achievement_place_table": 2.6576576576576576, "train_stats/max_log_achievement_wake_up": 1.2792792792792793, "train_stats/mean_log_entropy": 0.4393411549898955, "eval_stats/sum_log_reward": 6.10000005364418, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 1.5, "eval_stats/max_log_achievement_collect_wood": 7.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.586731286806753e-06, "report/cont_loss_std": 8.80567040439928e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.6352925235405564e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.518695739832765e-06, "report/cont_pred": 0.9980454444885254, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 14.996811866760254, "report/dyn_loss_std": 9.02656364440918, "report/image_loss_mean": 8.495159149169922, "report/image_loss_std": 13.947538375854492, "report/model_loss_mean": 17.557714462280273, "report/model_loss_std": 17.76958656311035, "report/post_ent_mag": 55.88554382324219, "report/post_ent_max": 55.88554382324219, "report/post_ent_mean": 39.6799201965332, "report/post_ent_min": 20.614290237426758, "report/post_ent_std": 7.3089799880981445, "report/prior_ent_mag": 66.76920318603516, "report/prior_ent_max": 66.76920318603516, "report/prior_ent_mean": 54.68525695800781, "report/prior_ent_min": 38.118507385253906, "report/prior_ent_std": 4.585476875305176, "report/rep_loss_mean": 14.996811866760254, "report/rep_loss_std": 9.02656364440918, "report/reward_avg": 0.0302734375, "report/reward_loss_mean": 0.06446570158004761, "report/reward_loss_std": 0.3157636225223541, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000459909439087, "report/reward_neg_acc": 0.9949494004249573, "report/reward_neg_loss": 0.02922884188592434, "report/reward_pos_acc": 0.9117646813392639, "report/reward_pos_loss": 1.0904799699783325, "report/reward_pred": 0.02523302473127842, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.0007803994230926037, "eval/cont_loss_std": 0.02484080195426941, "eval/cont_neg_acc": 0.8888888955116272, "eval/cont_neg_loss": 0.08848100155591965, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.758678419922944e-06, "eval/cont_pred": 0.9917449951171875, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 16.393211364746094, "eval/dyn_loss_std": 9.697754859924316, "eval/image_loss_mean": 13.563451766967773, "eval/image_loss_std": 22.37772560119629, "eval/model_loss_mean": 23.491931915283203, "eval/model_loss_std": 25.02027702331543, "eval/post_ent_mag": 61.62995910644531, "eval/post_ent_max": 61.62995910644531, "eval/post_ent_mean": 40.53242874145508, "eval/post_ent_min": 21.048397064208984, "eval/post_ent_std": 7.269490718841553, "eval/prior_ent_mag": 66.76920318603516, "eval/prior_ent_max": 66.76920318603516, "eval/prior_ent_mean": 54.416542053222656, "eval/prior_ent_min": 38.62689971923828, "eval/prior_ent_std": 5.098311901092529, "eval/rep_loss_mean": 16.393211364746094, "eval/rep_loss_std": 9.697754859924316, "eval/reward_avg": 0.01992187462747097, "eval/reward_loss_mean": 0.09177423268556595, "eval/reward_loss_std": 0.5600237250328064, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9992340803146362, "eval/reward_neg_acc": 0.9929789304733276, "eval/reward_neg_loss": 0.051375702023506165, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.5835272073745728, "eval/reward_pred": 0.017531078308820724, "eval/reward_rate": 0.0263671875, "replay/size": 417929.0, "replay/inserts": 22536.0, "replay/samples": 22528.0, "replay/insert_wait_avg": 1.4375468116302544e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.66130755841732e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84504.0, "eval_replay/inserts": 3768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2763113479452275e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.95086145401, "timer/env.step_count": 2817.0, "timer/env.step_total": 251.1428349018097, "timer/env.step_frac": 0.25090425971260205, "timer/env.step_avg": 0.08915258604963071, "timer/env.step_min": 0.02247166633605957, "timer/env.step_max": 3.353222608566284, "timer/replay._sample_count": 22528.0, "timer/replay._sample_total": 11.540842056274414, "timer/replay._sample_frac": 0.011529878739012078, "timer/replay._sample_avg": 0.0005122887986627492, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.026070833206176758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3288.0, "timer/agent.policy_total": 55.08710432052612, "timer/agent.policy_frac": 0.05503477387541783, "timer/agent.policy_avg": 0.01675398549894347, "timer/agent.policy_min": 0.00937652587890625, "timer/agent.policy_max": 0.12089061737060547, "timer/dataset_train_count": 1408.0, "timer/dataset_train_total": 0.15358805656433105, "timer/dataset_train_frac": 0.00015344215433435427, "timer/dataset_train_avg": 0.00010908242653716694, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 1408.0, "timer/agent.train_total": 628.5321598052979, "timer/agent.train_frac": 0.6279350805415902, "timer/agent.train_avg": 0.44640068167989905, "timer/agent.train_min": 0.43251538276672363, "timer/agent.train_max": 1.6414813995361328, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46111059188842773, "timer/agent.report_frac": 0.00046067255611190064, "timer/agent.report_avg": 0.23055529594421387, "timer/agent.report_min": 0.22075438499450684, "timer/agent.report_max": 0.2403562068939209, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.358508489066812e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 22.514289199030017}
{"step": 418664, "time": 19397.605818510056, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 418696, "time": 19400.15571808815, "episode/length": 433.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976958525345622, "episode/intrinsic_return": 0.0}
{"step": 418992, "time": 19411.730916023254, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 419072, "time": 19415.906206846237, "episode/length": 279.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 419216, "time": 19422.305324316025, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 419280, "time": 19425.943849802017, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 419680, "time": 19440.74488067627, "episode/length": 166.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 419904, "time": 19449.783012866974, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 420040, "time": 19455.63971233368, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19472.78240609169, "eval_episode/length": 51.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 420056, "time": 19479.456216573715, "eval_episode/length": 168.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 420056, "time": 19481.070697546005, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 420056, "time": 19482.874522209167, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 420056, "time": 19485.577357053757, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 420056, "time": 19487.429987430573, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 420056, "time": 19489.441132307053, "eval_episode/length": 223.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 420056, "time": 19491.269012212753, "eval_episode/length": 230.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 420152, "time": 19494.46212053299, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 420216, "time": 19498.12152981758, "episode/length": 142.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 420392, "time": 19505.51235461235, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 420792, "time": 19520.40269446373, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 420984, "time": 19528.298515319824, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 421136, "time": 19535.182173490524, "episode/length": 136.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 421136, "time": 19535.1910302639, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 421400, "time": 19547.06549167633, "episode/length": 51.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 421520, "time": 19552.846791267395, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 421592, "time": 19556.649655342102, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 421600, "time": 19558.69833779335, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 421904, "time": 19570.26126742363, "episode/length": 62.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 422672, "time": 19597.24614596367, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 422720, "time": 19600.546450138092, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 422800, "time": 19604.74622106552, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 422984, "time": 19612.227783441544, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 423088, "time": 19617.490931749344, "episode/length": 51.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 423296, "time": 19625.878918647766, "episode/length": 38.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 423376, "time": 19630.18144416809, "episode/length": 372.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758713136729222, "episode/intrinsic_return": 0.0}
{"step": 423528, "time": 19636.584758281708, "episode/length": 250.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 423600, "time": 19640.72018814087, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 424008, "time": 19655.4200963974, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 424056, "time": 19658.62236237526, "episode/length": 56.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 424264, "time": 19667.11192035675, "episode/length": 333.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 424512, "time": 19677.033821105957, "episode/length": 177.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 424760, "time": 19686.66014289856, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 424872, "time": 19691.9817237854, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 424952, "time": 19696.141709804535, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 425192, "time": 19705.565279483795, "episode/length": 308.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 425472, "time": 19716.605074882507, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 425520, "time": 19719.776733875275, "episode/length": 80.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9506172839506173, "episode/intrinsic_return": 0.0}
{"step": 425608, "time": 19724.110420942307, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 425936, "time": 19737.35989880562, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 426120, "time": 19746.25119161606, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 426264, "time": 19752.59682059288, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 426400, "time": 19758.81184411049, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 426568, "time": 19765.672238111496, "episode/length": 201.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 427216, "time": 19788.992718458176, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 427672, "time": 19805.663148641586, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 427752, "time": 19810.09658885002, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 427808, "time": 19813.748358011246, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 428064, "time": 19823.652415513992, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 428352, "time": 19834.94518327713, "episode/length": 301.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 428888, "time": 19854.372800588608, "episode/length": 327.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 428992, "time": 19859.531515836716, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 429024, "time": 19862.226903676987, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 429384, "time": 19875.452223300934, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 429392, "time": 19877.531036376953, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 429472, "time": 19881.703135728836, "episode/length": 383.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 429472, "time": 19881.711767673492, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 429768, "time": 19894.541657924652, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 19924.435571193695, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 430040, "time": 19926.209666728973, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 430040, "time": 19928.17926955223, "eval_episode/length": 168.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 430040, "time": 19930.14962530136, "eval_episode/length": 176.0, "eval_episode/score": 8.099999949336052, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 430040, "time": 19931.945979356766, "eval_episode/length": 181.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 430040, "time": 19933.6295876503, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 430040, "time": 19935.570211172104, "eval_episode/length": 190.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9842931937172775}
{"step": 430040, "time": 19943.34873151779, "eval_episode/length": 336.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9940652818991098}
{"step": 430336, "time": 19953.369517326355, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 430352, "time": 19955.55166745186, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 430488, "time": 19961.521463394165, "episode/length": 182.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 430752, "time": 19972.081498622894, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 430848, "time": 19976.972574472427, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 431160, "time": 19988.662800312042, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 431656, "time": 20006.629151821136, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 431904, "time": 20016.650902032852, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 431912, "time": 20018.402957439423, "episode/length": 267.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 431944, "time": 20021.19769525528, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 432040, "time": 20025.97091937065, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 432136, "time": 20030.736581802368, "episode/length": 160.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 432384, "time": 20040.68230032921, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 432688, "time": 20052.513344049454, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 432784, "time": 20057.23921585083, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 433576, "time": 20085.141798973083, "episode/length": 191.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 433584, "time": 20087.18164920807, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 433712, "time": 20092.98576235771, "episode/length": 225.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 433776, "time": 20096.619426488876, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 434120, "time": 20109.367216825485, "episode/length": 307.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 434128, "time": 20111.462396144867, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 434392, "time": 20123.114881277084, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 434832, "time": 20139.43071746826, "episode/length": 255.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 434872, "time": 20142.168115377426, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 435240, "time": 20155.881587982178, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 435712, "time": 20173.477496147156, "episode/length": 197.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 435752, "time": 20176.17259979248, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 435912, "time": 20182.931730747223, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 436176, "time": 20193.439831018448, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 436344, "time": 20200.35373735428, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 437120, "time": 20227.71831893921, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 437136, "time": 20229.9313519001, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 437368, "time": 20238.98482775688, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 437384, "time": 20241.496933460236, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 437432, "time": 20245.177222967148, "episode/length": 319.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 437496, "time": 20248.859780311584, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 437984, "time": 20266.765023708344, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 438592, "time": 20288.658842086792, "episode/length": 625.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9856230031948882, "episode/intrinsic_return": 0.0}
{"step": 438592, "time": 20288.667724132538, "episode/length": 144.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 438816, "time": 20299.50638151169, "episode/length": 103.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 438848, "time": 20302.15546798706, "episode/length": 215.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 438920, "time": 20305.804299354553, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 439048, "time": 20311.58356142044, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 439264, "time": 20320.67454648018, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 439376, "time": 20325.86621236801, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 439400, "time": 20327.925154447556, "episode/length": 43.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 439440, "time": 20331.04883170128, "episode/length": 105.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 439920, "time": 20348.792117118835, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20375.745287656784, "eval_episode/length": 181.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9835164835164835}
{"step": 440024, "time": 20377.3460958004, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 440024, "time": 20379.576528072357, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 440024, "time": 20381.20823931694, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 440024, "time": 20382.90194249153, "eval_episode/length": 199.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 440024, "time": 20385.25105381012, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 440024, "time": 20387.076489686966, "eval_episode/length": 224.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 440024, "time": 20390.643334388733, "eval_episode/length": 271.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9742647058823529}
{"step": 440025, "time": 20391.654389858246, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.048651801215278, "train/action_min": 0.0, "train/action_std": 3.175495896516023, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04608842173108348, "train/actor_opt_grad_steps": 26730.0, "train/actor_opt_loss": -2.5943766357722104, "train/adv_mag": 0.6011035219386772, "train/adv_max": 0.5678899968111957, "train/adv_mean": 0.004367477493360639, "train/adv_min": -0.465052960757856, "train/adv_std": 0.06813679367855743, "train/cont_avg": 0.9947554976851852, "train/cont_loss_mean": 0.00019001908388984417, "train/cont_loss_std": 0.005153217195852785, "train/cont_neg_acc": 0.9956613770237676, "train/cont_neg_loss": 0.014954272207230841, "train/cont_pos_acc": 0.9999635912753918, "train/cont_pos_loss": 9.385782650944656e-05, "train/cont_pred": 0.9947514591393647, "train/cont_rate": 0.9947554976851852, "train/dyn_loss_mean": 14.060920284412525, "train/dyn_loss_std": 8.861191756637009, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8519725834881818, "train/extr_critic_critic_opt_grad_steps": 26730.0, "train/extr_critic_critic_opt_loss": 15718.2630859375, "train/extr_critic_mag": 6.0720180723402235, "train/extr_critic_max": 6.0720180723402235, "train/extr_critic_mean": 1.7430665687278466, "train/extr_critic_min": -0.15993127116450556, "train/extr_critic_std": 1.347454238820959, "train/extr_return_normed_mag": 1.6829749663670859, "train/extr_return_normed_max": 1.6829749663670859, "train/extr_return_normed_mean": 0.35588922688254604, "train/extr_return_normed_min": -0.16672171889631837, "train/extr_return_normed_std": 0.32548536161581676, "train/extr_return_rate": 0.8457788820619936, "train/extr_return_raw_mag": 7.40399532671328, "train/extr_return_raw_max": 7.40399532671328, "train/extr_return_raw_mean": 1.7616329669952393, "train/extr_return_raw_min": -0.4606614996989568, "train/extr_return_raw_std": 1.384255470169915, "train/extr_reward_mag": 1.0217401928371854, "train/extr_reward_max": 1.0217401928371854, "train/extr_reward_mean": 0.03231855196257432, "train/extr_reward_min": -0.3915170713707253, "train/extr_reward_std": 0.16550787775604814, "train/image_loss_mean": 7.520805267051414, "train/image_loss_std": 11.994594648149278, "train/model_loss_mean": 16.013453186882867, "train/model_loss_std": 15.615514366715043, "train/model_opt_grad_norm": 62.94664233478147, "train/model_opt_grad_steps": 26704.985185185185, "train/model_opt_loss": 17720.718015769675, "train/model_opt_model_opt_grad_overflow": 0.007407407407407408, "train/model_opt_model_opt_grad_scale": 1097.2222222222222, "train/policy_entropy_mag": 2.3474314636654325, "train/policy_entropy_max": 2.3474314636654325, "train/policy_entropy_mean": 0.46629696333849874, "train/policy_entropy_min": 0.0793751522898674, "train/policy_entropy_std": 0.4637273408748485, "train/policy_logprob_mag": 7.438383505079481, "train/policy_logprob_max": -0.009455746053545563, "train/policy_logprob_mean": -0.4660838038833053, "train/policy_logprob_min": -7.438383505079481, "train/policy_logprob_std": 1.0142139302359687, "train/policy_randomness_mag": 0.828540293375651, "train/policy_randomness_max": 0.828540293375651, "train/policy_randomness_mean": 0.16458236497861367, "train/policy_randomness_min": 0.028015945658639626, "train/policy_randomness_std": 0.16367540083549642, "train/post_ent_mag": 57.35716761836299, "train/post_ent_max": 57.35716761836299, "train/post_ent_mean": 40.34470223320855, "train/post_ent_min": 20.376070608916105, "train/post_ent_std": 7.075394139466463, "train/prior_ent_mag": 66.63117184109159, "train/prior_ent_max": 66.63117184109159, "train/prior_ent_mean": 54.470198172110095, "train/prior_ent_min": 37.12038042986835, "train/prior_ent_std": 4.928215129287155, "train/rep_loss_mean": 14.060920284412525, "train/rep_loss_std": 8.861191756637009, "train/reward_avg": 0.025955584362425187, "train/reward_loss_mean": 0.055905906014420366, "train/reward_loss_std": 0.2550888067042386, "train/reward_max_data": 1.0207407456857187, "train/reward_max_pred": 1.0119095890610306, "train/reward_neg_acc": 0.9925798526516667, "train/reward_neg_loss": 0.0298453977883414, "train/reward_pos_acc": 0.9602832317352294, "train/reward_pos_loss": 0.8841433984261972, "train/reward_pred": 0.025039797283157153, "train/reward_rate": 0.03062789351851852, "train_stats/sum_log_reward": 7.220370482515405, "train_stats/max_log_achievement_collect_coal": 0.18518518518518517, "train_stats/max_log_achievement_collect_drink": 4.805555555555555, "train_stats/max_log_achievement_collect_sapling": 1.9722222222222223, "train_stats/max_log_achievement_collect_stone": 2.6018518518518516, "train_stats/max_log_achievement_collect_wood": 10.62037037037037, "train_stats/max_log_achievement_defeat_skeleton": 0.009259259259259259, "train_stats/max_log_achievement_defeat_zombie": 0.9074074074074074, "train_stats/max_log_achievement_eat_cow": 0.1388888888888889, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2592592592592593, "train_stats/max_log_achievement_make_wood_sword": 0.7685185185185185, "train_stats/max_log_achievement_place_furnace": 0.009259259259259259, "train_stats/max_log_achievement_place_plant": 1.75, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.462962962962963, "train_stats/max_log_achievement_wake_up": 1.3333333333333333, "train_stats/mean_log_entropy": 0.4371852891312705, "eval_stats/sum_log_reward": 7.183333496252696, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.9166666666666665, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_stone": 0.8333333333333334, "eval_stats/max_log_achievement_collect_wood": 11.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0416666666666667, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0416666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0003489897644612938, "report/cont_loss_std": 0.009898695163428783, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004457125905901194, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00031664222478866577, "report/cont_pred": 0.9919519424438477, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.200510025024414, "report/dyn_loss_std": 8.401137351989746, "report/image_loss_mean": 6.536751747131348, "report/image_loss_std": 9.231441497802734, "report/model_loss_mean": 13.336602210998535, "report/model_loss_std": 12.833690643310547, "report/post_ent_mag": 57.96070098876953, "report/post_ent_max": 57.96070098876953, "report/post_ent_mean": 44.26263427734375, "report/post_ent_min": 22.19431495666504, "report/post_ent_std": 7.685940742492676, "report/prior_ent_mag": 66.48388671875, "report/prior_ent_max": 66.48388671875, "report/prior_ent_mean": 55.72242736816406, "report/prior_ent_min": 29.939720153808594, "report/prior_ent_std": 5.229361057281494, "report/rep_loss_mean": 11.200510025024414, "report/rep_loss_std": 8.401137351989746, "report/reward_avg": 0.02255859412252903, "report/reward_loss_mean": 0.07919492572546005, "report/reward_loss_std": 0.3792424201965332, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0011405944824219, "report/reward_neg_acc": 0.9889447093009949, "report/reward_neg_loss": 0.05103969946503639, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 1.045210361480713, "report/reward_pred": 0.020084653049707413, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.68917605758179e-05, "eval/cont_loss_std": 0.001408768119290471, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.011267592199146748, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.8890190151287243e-06, "eval/cont_pred": 0.9961339831352234, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.877132415771484, "eval/dyn_loss_std": 10.32552433013916, "eval/image_loss_mean": 16.653060913085938, "eval/image_loss_std": 24.989593505859375, "eval/model_loss_mean": 28.060579299926758, "eval/model_loss_std": 28.906938552856445, "eval/post_ent_mag": 56.60163116455078, "eval/post_ent_max": 56.60163116455078, "eval/post_ent_mean": 39.439735412597656, "eval/post_ent_min": 22.004070281982422, "eval/post_ent_std": 7.114598274230957, "eval/prior_ent_mag": 66.48388671875, "eval/prior_ent_max": 66.48388671875, "eval/prior_ent_mean": 55.610267639160156, "eval/prior_ent_min": 39.055206298828125, "eval/prior_ent_std": 4.541379928588867, "eval/rep_loss_mean": 18.877132415771484, "eval/rep_loss_std": 10.32552433013916, "eval/reward_avg": 0.02001953125, "eval/reward_loss_mean": 0.08119133114814758, "eval/reward_loss_std": 0.5387172102928162, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0094282627105713, "eval/reward_neg_acc": 0.9929929971694946, "eval/reward_neg_loss": 0.037216756492853165, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 1.8384151458740234, "eval/reward_pred": 0.0171507578343153, "eval/reward_rate": 0.0244140625, "replay/size": 439521.0, "replay/inserts": 21592.0, "replay/samples": 21600.0, "replay/insert_wait_avg": 1.4070472526479623e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0422644791779694e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91224.0, "eval_replay/inserts": 6720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.235732010432652e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.7051746845245, "timer/env.step_count": 2699.0, "timer/env.step_total": 244.0896246433258, "timer/env.step_frac": 0.24367411770653877, "timer/env.step_avg": 0.09043705989007995, "timer/env.step_min": 0.022823333740234375, "timer/env.step_max": 3.4400556087493896, "timer/replay._sample_count": 21600.0, "timer/replay._sample_total": 10.80785846710205, "timer/replay._sample_frac": 0.010789460552108918, "timer/replay._sample_avg": 0.0005003638179213912, "timer/replay._sample_min": 0.00035762786865234375, "timer/replay._sample_max": 0.030182600021362305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3539.0, "timer/agent.policy_total": 58.54583191871643, "timer/agent.policy_frac": 0.05844617098754108, "timer/agent.policy_avg": 0.01654304377471501, "timer/agent.policy_min": 0.00920867919921875, "timer/agent.policy_max": 0.11589455604553223, "timer/dataset_train_count": 1350.0, "timer/dataset_train_total": 0.14661884307861328, "timer/dataset_train_frac": 0.00014636925792540625, "timer/dataset_train_avg": 0.00010860655042860243, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.00035119056701660156, "timer/agent.train_count": 1350.0, "timer/agent.train_total": 600.3066806793213, "timer/agent.train_frac": 0.5992847954173551, "timer/agent.train_avg": 0.44467161531801574, "timer/agent.train_min": 0.43441319465637207, "timer/agent.train_max": 1.5473341941833496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4680018424987793, "timer/agent.report_frac": 0.0004672051760600828, "timer/agent.report_avg": 0.23400092124938965, "timer/agent.report_min": 0.22313809394836426, "timer/agent.report_max": 0.24486374855041504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.2438507080078125e-05, "timer/dataset_eval_frac": 4.236626519718603e-08, "timer/dataset_eval_avg": 4.2438507080078125e-05, "timer/dataset_eval_min": 4.2438507080078125e-05, "timer/dataset_eval_max": 4.2438507080078125e-05, "fps": 21.55497719968592}
{"step": 440184, "time": 20396.787227153778, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 440520, "time": 20409.65063047409, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 440624, "time": 20414.89714860916, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 440864, "time": 20424.403752803802, "episode/length": 185.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 440880, "time": 20426.44725418091, "episode/length": 244.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 441000, "time": 20431.6522064209, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 441496, "time": 20449.712401151657, "episode/length": 261.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 442120, "time": 20472.549952030182, "episode/length": 274.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 442224, "time": 20477.791702508926, "episode/length": 254.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 442304, "time": 20482.434200048447, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 442328, "time": 20484.43231654167, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 442336, "time": 20486.457873106003, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 442928, "time": 20509.448211431503, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 443024, "time": 20514.151486635208, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 443256, "time": 20523.142882347107, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 443512, "time": 20533.32887983322, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 443528, "time": 20535.51584482193, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 443752, "time": 20544.432024002075, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 443872, "time": 20550.220291376114, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 443888, "time": 20552.34706711769, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 444184, "time": 20564.13105750084, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 444528, "time": 20577.294558286667, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 444640, "time": 20582.616430044174, "episode/length": 201.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 444648, "time": 20584.250637292862, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 445168, "time": 20603.15216445923, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 445544, "time": 20616.942989349365, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 445640, "time": 20621.7947473526, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 445712, "time": 20625.89021372795, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 445904, "time": 20633.85722875595, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 446128, "time": 20642.792266607285, "episode/length": 296.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 446464, "time": 20655.623833179474, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 447152, "time": 20680.14413690567, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 447168, "time": 20682.124816179276, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 447192, "time": 20684.147085428238, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 447232, "time": 20687.276233434677, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 447688, "time": 20703.69317674637, "episode/length": 222.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 448072, "time": 20718.06353521347, "episode/length": 428.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 448152, "time": 20722.379118204117, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 448328, "time": 20729.83306002617, "episode/length": 141.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 448600, "time": 20740.471114635468, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 448760, "time": 20747.33549261093, "episode/length": 328.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9969604863221885, "episode/intrinsic_return": 0.0}
{"step": 449088, "time": 20759.954966783524, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 449136, "time": 20763.146020889282, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 449368, "time": 20772.189138889313, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 449592, "time": 20781.229029893875, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 449640, "time": 20784.46666240692, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 449992, "time": 20797.760496854782, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 20800.03573989868, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 20814.61075401306, "eval_episode/length": 39.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 450008, "time": 20820.765641450882, "eval_episode/length": 148.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 450008, "time": 20823.497804164886, "eval_episode/length": 177.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 450008, "time": 20825.772563934326, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 450008, "time": 20827.98508501053, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 450008, "time": 20830.85263800621, "eval_episode/length": 237.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9621848739495799}
{"step": 450008, "time": 20832.56830406189, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 450008, "time": 20834.460146665573, "eval_episode/length": 245.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9796747967479674}
{"step": 450088, "time": 20838.638430833817, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 450392, "time": 20850.189959049225, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 450456, "time": 20853.866971492767, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 451040, "time": 20876.458211421967, "episode/length": 208.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 451096, "time": 20879.672084331512, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 451496, "time": 20894.4961745739, "episode/length": 129.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 451672, "time": 20901.942962169647, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 451688, "time": 20904.056352376938, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 451752, "time": 20907.693630456924, "episode/length": 219.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 452080, "time": 20920.279173374176, "episode/length": 310.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 452216, "time": 20926.064386844635, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 452504, "time": 20937.030504465103, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 452520, "time": 20939.09334754944, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 453040, "time": 20958.08432006836, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 453320, "time": 20968.589301347733, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 453376, "time": 20972.10878443718, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 453520, "time": 20978.478867530823, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 453728, "time": 20987.037638902664, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 454008, "time": 20997.66981625557, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 454032, "time": 21000.35714864731, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 454088, "time": 21003.657079219818, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 454648, "time": 21023.834980010986, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 454680, "time": 21026.56523346901, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 454768, "time": 21031.287145614624, "episode/length": 94.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 455248, "time": 21048.624203920364, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 455472, "time": 21057.558332920074, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 455488, "time": 21059.70511174202, "episode/length": 305.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 455544, "time": 21062.93762230873, "episode/length": 226.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 455600, "time": 21066.55346441269, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 455960, "time": 21080.009420394897, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 456536, "time": 21100.67138004303, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 456536, "time": 21100.681153535843, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 456736, "time": 21110.579619646072, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 456928, "time": 21118.438160657883, "episode/length": 181.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 457008, "time": 21122.813133478165, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 457048, "time": 21126.06693649292, "episode/length": 194.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 457248, "time": 21135.017016887665, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 457272, "time": 21137.134759664536, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 457856, "time": 21158.0230717659, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 458248, "time": 21172.479078054428, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 458360, "time": 21177.992216348648, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 458384, "time": 21180.58592915535, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 458504, "time": 21185.783547878265, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 458768, "time": 21197.84099817276, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 459264, "time": 21215.838667869568, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 459304, "time": 21218.857254743576, "episode/length": 253.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 459488, "time": 21226.82541489601, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 459696, "time": 21235.222537994385, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 459744, "time": 21238.34036231041, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 460000, "time": 21248.36421918869, "episode/length": 218.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21274.547586917877, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 460096, "time": 21276.271597146988, "eval_episode/length": 203.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 460096, "time": 21278.16770005226, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 460096, "time": 21280.283623695374, "eval_episode/length": 221.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 460096, "time": 21282.480140924454, "eval_episode/length": 237.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9747899159663865}
{"step": 460096, "time": 21285.277992010117, "eval_episode/length": 265.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 460096, "time": 21288.08160018921, "eval_episode/length": 56.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 460096, "time": 21290.85402417183, "eval_episode/length": 325.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9846625766871165}
{"step": 460360, "time": 21299.341526269913, "episode/length": 249.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.988, "episode/intrinsic_return": 0.0}
{"step": 460688, "time": 21312.02756667137, "episode/length": 149.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 460808, "time": 21317.36426091194, "episode/length": 254.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 460928, "time": 21323.083931446075, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 460992, "time": 21326.669696092606, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 461176, "time": 21334.11062026024, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 461464, "time": 21345.299587726593, "episode/length": 220.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 461784, "time": 21357.376334667206, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 461824, "time": 21360.498334407806, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 462256, "time": 21376.592683315277, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 462304, "time": 21380.19242501259, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 462304, "time": 21380.20124220848, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 462528, "time": 21390.88957452774, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 462529, "time": 21393.07005095482, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9493702557070036, "train/action_min": 0.0, "train/action_std": 3.1268001397450766, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04411322264172507, "train/actor_opt_grad_steps": 28110.0, "train/actor_opt_loss": 3.550182093965246, "train/adv_mag": 0.5881730985979662, "train/adv_max": 0.5577851481048773, "train/adv_mean": 0.005713159713092432, "train/adv_min": -0.4416955713684677, "train/adv_std": 0.06519378935720058, "train/cont_avg": 0.9947847406914894, "train/cont_loss_mean": 0.00017150091458771266, "train/cont_loss_std": 0.005148758190061733, "train/cont_neg_acc": 0.9945429478976744, "train/cont_neg_loss": 0.013572355876125108, "train/cont_pos_acc": 0.9999791096288262, "train/cont_pos_loss": 9.570760334394459e-05, "train/cont_pred": 0.9947791310912328, "train/cont_rate": 0.9947847406914894, "train/dyn_loss_mean": 13.963008278650594, "train/dyn_loss_std": 8.840198827973495, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9007098577546735, "train/extr_critic_critic_opt_grad_steps": 28110.0, "train/extr_critic_critic_opt_loss": 15814.959995567377, "train/extr_critic_mag": 6.575197507303657, "train/extr_critic_max": 6.575197507303657, "train/extr_critic_mean": 1.9563138983773847, "train/extr_critic_min": -0.14391508254599064, "train/extr_critic_std": 1.4679305502708921, "train/extr_return_normed_mag": 1.6333191420169586, "train/extr_return_normed_max": 1.6333191420169586, "train/extr_return_normed_mean": 0.3643655108010515, "train/extr_return_normed_min": -0.15669254336426866, "train/extr_return_normed_std": 0.3250956059770381, "train/extr_return_rate": 0.8611236231546875, "train/extr_return_raw_mag": 7.866970129892335, "train/extr_return_raw_max": 7.866970129892335, "train/extr_return_raw_mean": 1.9827069906478232, "train/extr_return_raw_min": -0.4371936375156362, "train/extr_return_raw_std": 1.5097417298783646, "train/extr_reward_mag": 1.018383448851024, "train/extr_reward_max": 1.018383448851024, "train/extr_reward_mean": 0.03360381727734356, "train/extr_reward_min": -0.3596669393228301, "train/extr_reward_std": 0.1688110849536057, "train/image_loss_mean": 7.501533653719205, "train/image_loss_std": 11.904075027357601, "train/model_loss_mean": 15.93473412128205, "train/model_loss_std": 15.520030326031623, "train/model_opt_grad_norm": 66.51117780698952, "train/model_opt_grad_steps": 28083.397163120568, "train/model_opt_loss": 13938.306938441932, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 873.2269503546099, "train/policy_entropy_mag": 2.2945958350567106, "train/policy_entropy_max": 2.2945958350567106, "train/policy_entropy_mean": 0.46242995972329, "train/policy_entropy_min": 0.07937515278657277, "train/policy_entropy_std": 0.45383531742907585, "train/policy_logprob_mag": 7.438383514999498, "train/policy_logprob_max": -0.00945572970527495, "train/policy_logprob_mean": -0.4621928761191402, "train/policy_logprob_min": -7.438383514999498, "train/policy_logprob_std": 1.0082920138717544, "train/policy_randomness_mag": 0.8098916356445204, "train/policy_randomness_max": 0.8098916356445204, "train/policy_randomness_mean": 0.16321748368283537, "train/policy_randomness_min": 0.028015945740836733, "train/policy_randomness_std": 0.16018394946206546, "train/post_ent_mag": 57.53506280344429, "train/post_ent_max": 57.53506280344429, "train/post_ent_mean": 40.714982242448954, "train/post_ent_min": 20.39325634300286, "train/post_ent_std": 7.127906741825401, "train/prior_ent_mag": 66.74649323808386, "train/prior_ent_max": 66.74649323808386, "train/prior_ent_mean": 54.73414584761816, "train/prior_ent_min": 37.78546860877504, "train/prior_ent_std": 4.855426815384669, "train/rep_loss_mean": 13.963008278650594, "train/rep_loss_std": 8.840198827973495, "train/reward_avg": 0.024778368493132558, "train/reward_loss_mean": 0.05522413633710949, "train/reward_loss_std": 0.2525970313354587, "train/reward_max_data": 1.0099290803814611, "train/reward_max_pred": 1.0093732353643323, "train/reward_neg_acc": 0.9930643874702724, "train/reward_neg_loss": 0.030836200288741303, "train/reward_pos_acc": 0.9654028521361926, "train/reward_pos_loss": 0.8611862519954113, "train/reward_pred": 0.02411448335975197, "train/reward_rate": 0.029497728280141845, "train_stats/sum_log_reward": 7.541441543682201, "train_stats/max_log_achievement_collect_coal": 0.13513513513513514, "train_stats/max_log_achievement_collect_drink": 3.3423423423423424, "train_stats/max_log_achievement_collect_sapling": 2.126126126126126, "train_stats/max_log_achievement_collect_stone": 1.9009009009009008, "train_stats/max_log_achievement_collect_wood": 11.64864864864865, "train_stats/max_log_achievement_defeat_skeleton": 0.018018018018018018, "train_stats/max_log_achievement_defeat_zombie": 1.1531531531531531, "train_stats/max_log_achievement_eat_cow": 0.09009009009009009, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.135135135135135, "train_stats/max_log_achievement_make_wood_sword": 1.5675675675675675, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.936936936936937, "train_stats/max_log_achievement_place_stone": 0.018018018018018018, "train_stats/max_log_achievement_place_table": 2.90990990990991, "train_stats/max_log_achievement_wake_up": 1.3063063063063063, "train_stats/mean_log_entropy": 0.4367757512105478, "eval_stats/sum_log_reward": 7.600000023841858, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 3.0625, "eval_stats/max_log_achievement_collect_wood": 10.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.5999308491009288e-05, "report/cont_loss_std": 0.0005818682257086039, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008811781299300492, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1803140043630265e-05, "report/cont_pred": 0.9950999617576599, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.316936492919922, "report/dyn_loss_std": 9.319457054138184, "report/image_loss_mean": 8.633628845214844, "report/image_loss_std": 11.697721481323242, "report/model_loss_mean": 17.895145416259766, "report/model_loss_std": 15.685315132141113, "report/post_ent_mag": 54.925262451171875, "report/post_ent_max": 54.925262451171875, "report/post_ent_mean": 38.79265594482422, "report/post_ent_min": 21.195785522460938, "report/post_ent_std": 6.446858882904053, "report/prior_ent_mag": 66.64192962646484, "report/prior_ent_max": 66.64192962646484, "report/prior_ent_mean": 54.084022521972656, "report/prior_ent_min": 35.91730880737305, "report/prior_ent_std": 5.218743801116943, "report/rep_loss_mean": 15.316936492919922, "report/rep_loss_std": 9.319457054138184, "report/reward_avg": 0.03437499701976776, "report/reward_loss_mean": 0.07132931053638458, "report/reward_loss_std": 0.2662857472896576, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.004084587097168, "report/reward_neg_acc": 0.9939025044441223, "report/reward_neg_loss": 0.03689712658524513, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.9183613061904907, "report/reward_pred": 0.03213735669851303, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 6.0969163314439356e-05, "eval/cont_loss_std": 0.0006494640838354826, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008336904575116932, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.565052924794145e-05, "eval/cont_pred": 0.9931146502494812, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.012296676635742, "eval/dyn_loss_std": 10.122233390808105, "eval/image_loss_mean": 15.038901329040527, "eval/image_loss_std": 20.248817443847656, "eval/model_loss_mean": 26.533517837524414, "eval/model_loss_std": 24.487865447998047, "eval/post_ent_mag": 55.23637008666992, "eval/post_ent_max": 55.23637008666992, "eval/post_ent_mean": 39.72163009643555, "eval/post_ent_min": 20.76549530029297, "eval/post_ent_std": 7.3096923828125, "eval/prior_ent_mag": 66.64192962646484, "eval/prior_ent_max": 66.64192962646484, "eval/prior_ent_mean": 55.91923522949219, "eval/prior_ent_min": 36.80125045776367, "eval/prior_ent_std": 4.703131198883057, "eval/rep_loss_mean": 19.012296676635742, "eval/rep_loss_std": 10.122233390808105, "eval/reward_avg": 0.01650390587747097, "eval/reward_loss_mean": 0.08717666566371918, "eval/reward_loss_std": 0.4744974970817566, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029363632202148, "eval/reward_neg_acc": 0.9930139780044556, "eval/reward_neg_loss": 0.05180418863892555, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.6982321739196777, "eval/reward_pred": 0.015007806941866875, "eval/reward_rate": 0.021484375, "replay/size": 462025.0, "replay/inserts": 22504.0, "replay/samples": 22496.0, "replay/insert_wait_avg": 1.4270682628155603e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.843616604974565e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95800.0, "eval_replay/inserts": 4576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2345038927518403e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.4033966064453, "timer/env.step_count": 2813.0, "timer/env.step_total": 253.12706685066223, "timer/env.step_frac": 0.2527723270247125, "timer/env.step_avg": 0.08998473759355216, "timer/env.step_min": 0.02321600914001465, "timer/env.step_max": 3.34804368019104, "timer/replay._sample_count": 22496.0, "timer/replay._sample_total": 11.048500061035156, "timer/replay._sample_frac": 0.011033016363312028, "timer/replay._sample_avg": 0.0004911317594699128, "timer/replay._sample_min": 0.0004038810729980469, "timer/replay._sample_max": 0.029878616333007812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3385.0, "timer/agent.policy_total": 55.30137872695923, "timer/agent.policy_frac": 0.0552238777243661, "timer/agent.policy_avg": 0.01633718721623611, "timer/agent.policy_min": 0.009333133697509766, "timer/agent.policy_max": 0.11174654960632324, "timer/dataset_train_count": 1406.0, "timer/dataset_train_total": 0.14927983283996582, "timer/dataset_train_frac": 0.00014907062762703336, "timer/dataset_train_avg": 0.00010617342307252192, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0005590915679931641, "timer/agent.train_count": 1406.0, "timer/agent.train_total": 624.9386975765228, "timer/agent.train_frac": 0.6240628898347204, "timer/agent.train_avg": 0.44447987025357244, "timer/agent.train_min": 0.4294600486755371, "timer/agent.train_max": 1.5984957218170166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46958231925964355, "timer/agent.report_frac": 0.00046892423258295665, "timer/agent.report_avg": 0.23479115962982178, "timer/agent.report_min": 0.22850322723388672, "timer/agent.report_max": 0.24107909202575684, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.904630316709614e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.472181616797656}
{"step": 462728, "time": 21399.733703374863, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 463224, "time": 21417.60073685646, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 463336, "time": 21422.839034557343, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 463688, "time": 21436.216511964798, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 463712, "time": 21438.791437149048, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 463768, "time": 21441.994109392166, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 463792, "time": 21444.69253730774, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 463808, "time": 21446.83725476265, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 464424, "time": 21468.557406425476, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 464592, "time": 21475.93075466156, "episode/length": 232.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9871244635193133, "episode/intrinsic_return": 0.0}
{"step": 464632, "time": 21478.45731806755, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 465168, "time": 21498.18585252762, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 465304, "time": 21504.125102043152, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 465592, "time": 21515.23624777794, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 465640, "time": 21518.43846845627, "episode/length": 230.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 465864, "time": 21527.394817113876, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 466064, "time": 21535.856298208237, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 466096, "time": 21538.478948116302, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 466336, "time": 21547.9687564373, "episode/length": 58.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 466840, "time": 21566.11187696457, "episode/length": 378.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9762532981530343, "episode/intrinsic_return": 0.0}
{"step": 466896, "time": 21569.814601421356, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 466904, "time": 21571.356198310852, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 467328, "time": 21588.698405742645, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 467480, "time": 21595.069962501526, "episode/length": 288.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 467544, "time": 21598.799213171005, "episode/length": 184.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 467560, "time": 21600.90429377556, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 468032, "time": 21618.419212579727, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 468168, "time": 21624.326907634735, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 468272, "time": 21629.649977207184, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 468464, "time": 21637.728264331818, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 468576, "time": 21643.144968032837, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 468896, "time": 21655.38989329338, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 468912, "time": 21657.519614219666, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 469088, "time": 21665.02232313156, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 469152, "time": 21668.823340654373, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 469216, "time": 21672.51923751831, "episode/length": 147.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21719.362840652466, "eval_episode/length": 75.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 470080, "time": 21724.40201663971, "eval_episode/length": 157.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 470080, "time": 21726.25987124443, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 470080, "time": 21728.730431079865, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 470080, "time": 21730.852913856506, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 470080, "time": 21732.81346464157, "eval_episode/length": 205.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 470080, "time": 21735.337490558624, "eval_episode/length": 47.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 470080, "time": 21738.022265672684, "eval_episode/length": 250.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9681274900398407}
{"step": 470176, "time": 21742.517860889435, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 470184, "time": 21744.156477451324, "episode/length": 158.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 470184, "time": 21744.16558432579, "episode/length": 200.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 470384, "time": 21754.17002749443, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 470760, "time": 21768.089420318604, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 470896, "time": 21774.286150693893, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 471152, "time": 21784.401282310486, "episode/length": 281.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 471264, "time": 21789.80418562889, "episode/length": 255.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 471520, "time": 21799.821678876877, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 471608, "time": 21804.070590019226, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 471680, "time": 21808.344955921173, "episode/length": 187.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 472280, "time": 21829.762006759644, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 472448, "time": 21837.074021100998, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 472656, "time": 21845.56525039673, "episode/length": 283.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 472720, "time": 21849.358900785446, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 472928, "time": 21857.903742313385, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 473016, "time": 21862.20686864853, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 473080, "time": 21865.891174793243, "episode/length": 174.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 473424, "time": 21879.27612733841, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 473464, "time": 21881.888476848602, "episode/length": 55.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 473832, "time": 21895.58092236519, "episode/length": 50.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 474176, "time": 21908.90366625786, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 474192, "time": 21911.02829194069, "episode/length": 322.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 474264, "time": 21914.73248386383, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 474504, "time": 21924.288373231888, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 474824, "time": 21936.450776576996, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 474888, "time": 21940.298402309418, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673469387755103, "episode/intrinsic_return": 0.0}
{"step": 475144, "time": 21950.93186378479, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 475696, "time": 21973.09136748314, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 475728, "time": 21975.771961927414, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 475968, "time": 21985.30979681015, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 476032, "time": 21989.019335746765, "episode/length": 110.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 476048, "time": 21991.192271471024, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 476072, "time": 21993.381510734558, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 476096, "time": 21995.876037836075, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 476376, "time": 22006.49274802208, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 476824, "time": 22022.9428794384, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 477312, "time": 22040.98686814308, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 477320, "time": 22042.603574752808, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 477328, "time": 22044.57373905182, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 477368, "time": 22047.192095041275, "episode/length": 158.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 477848, "time": 22064.8050904274, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 478088, "time": 22074.428347349167, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 478152, "time": 22077.963535547256, "episode/length": 264.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 478472, "time": 22090.134683847427, "episode/length": 142.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 478696, "time": 22099.08247613907, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 479064, "time": 22112.743936777115, "episode/length": 279.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 479208, "time": 22119.150767803192, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 479288, "time": 22123.32834792137, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 479360, "time": 22127.493571281433, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 479408, "time": 22130.532581806183, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 479432, "time": 22132.69375562668, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 479960, "time": 22151.728969335556, "episode/length": 111.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22176.113062620163, "eval_episode/length": 149.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 480064, "time": 22178.234748601913, "eval_episode/length": 158.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 480064, "time": 22180.88793182373, "eval_episode/length": 180.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 480064, "time": 22182.685472011566, "eval_episode/length": 188.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 480064, "time": 22184.357228040695, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 480064, "time": 22186.80909347534, "eval_episode/length": 64.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 480064, "time": 22189.03285098076, "eval_episode/length": 39.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 480064, "time": 22190.696716308594, "eval_episode/length": 230.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 480376, "time": 22200.777799844742, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 480608, "time": 22210.252942800522, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 480936, "time": 22222.52419614792, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 480960, "time": 22225.148195266724, "episode/length": 193.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 480984, "time": 22227.296857595444, "episode/length": 46.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 481328, "time": 22240.584697008133, "episode/length": 328.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817629179331308, "episode/intrinsic_return": 0.0}
{"step": 481440, "time": 22245.84979057312, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 481744, "time": 22257.966676473618, "episode/length": 288.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 481880, "time": 22263.817348480225, "episode/length": 187.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 482408, "time": 22282.886926412582, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 482464, "time": 22286.631454229355, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 482544, "time": 22290.860439300537, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 482728, "time": 22298.345214128494, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 482760, "time": 22301.035865306854, "episode/length": 443.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 482784, "time": 22303.65593314171, "episode/length": 39.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 482880, "time": 22308.334623098373, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 483200, "time": 22320.517156600952, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 483432, "time": 22331.008885860443, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 484272, "time": 22360.959679603577, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 484480, "time": 22369.40960431099, "episode/length": 218.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 484544, "time": 22373.08487057686, "episode/length": 266.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 484592, "time": 22376.31928086281, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 484736, "time": 22382.704715251923, "episode/length": 246.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 484985, "time": 22393.365342140198, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.001342337472098, "train/action_min": 0.0, "train/action_std": 3.158346014363425, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04322393611073494, "train/actor_opt_grad_steps": 29515.0, "train/actor_opt_loss": -2.0302667341062, "train/adv_mag": 0.5598742887377739, "train/adv_max": 0.5150272541812488, "train/adv_mean": 0.0040860487377878075, "train/adv_min": -0.455887143101011, "train/adv_std": 0.062239805928298406, "train/cont_avg": 0.9945591517857143, "train/cont_loss_mean": 0.00029249959466304585, "train/cont_loss_std": 0.008789845510688923, "train/cont_neg_acc": 0.9887414979083198, "train/cont_neg_loss": 0.026244613072120566, "train/cont_pos_acc": 0.9999508768320083, "train/cont_pos_loss": 0.00015938774429591669, "train/cont_pred": 0.9945618497473853, "train/cont_rate": 0.9945591517857143, "train/dyn_loss_mean": 13.83043360710144, "train/dyn_loss_std": 8.80960009098053, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8923239218337196, "train/extr_critic_critic_opt_grad_steps": 29515.0, "train/extr_critic_critic_opt_loss": 15603.627483258928, "train/extr_critic_mag": 6.8375969920839585, "train/extr_critic_max": 6.8375969920839585, "train/extr_critic_mean": 2.2588246575423647, "train/extr_critic_min": -0.1561045127255576, "train/extr_critic_std": 1.6089419884341103, "train/extr_return_normed_mag": 1.5666156138692584, "train/extr_return_normed_max": 1.5666156138692584, "train/extr_return_normed_mean": 0.4009316798831735, "train/extr_return_normed_min": -0.150289238350732, "train/extr_return_normed_std": 0.3276538591299738, "train/extr_return_rate": 0.8614946510110583, "train/extr_return_raw_mag": 8.130689399583, "train/extr_return_raw_max": 8.130689399583, "train/extr_return_raw_mean": 2.279198636327471, "train/extr_return_raw_min": -0.48770326493041855, "train/extr_return_raw_std": 1.6453739489827837, "train/extr_reward_mag": 1.0197052478790283, "train/extr_reward_max": 1.0197052478790283, "train/extr_reward_mean": 0.036157926065581186, "train/extr_reward_min": -0.3891072630882263, "train/extr_reward_std": 0.17514091453381947, "train/image_loss_mean": 7.078986511911665, "train/image_loss_std": 11.368550828524999, "train/model_loss_mean": 15.434050267083304, "train/model_loss_std": 14.991712958472116, "train/model_opt_grad_norm": 57.07284814289638, "train/model_opt_grad_steps": 29487.85, "train/model_opt_loss": 18771.2943359375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1218.75, "train/policy_entropy_mag": 2.306065707547324, "train/policy_entropy_max": 2.306065707547324, "train/policy_entropy_mean": 0.4587274200149945, "train/policy_entropy_min": 0.07937513483422143, "train/policy_entropy_std": 0.47206650865929467, "train/policy_logprob_mag": 7.438383552006313, "train/policy_logprob_max": -0.009455709944346122, "train/policy_logprob_mean": -0.45932768029826027, "train/policy_logprob_min": -7.438383552006313, "train/policy_logprob_std": 1.0098864836352213, "train/policy_randomness_mag": 0.8139399941478457, "train/policy_randomness_max": 0.8139399941478457, "train/policy_randomness_mean": 0.16191064747316497, "train/policy_randomness_min": 0.028015939385763237, "train/policy_randomness_std": 0.16661876269749232, "train/post_ent_mag": 57.62448675973075, "train/post_ent_max": 57.62448675973075, "train/post_ent_mean": 40.8695458820888, "train/post_ent_min": 20.564441299438478, "train/post_ent_std": 7.131833818980626, "train/prior_ent_mag": 66.77568081447056, "train/prior_ent_max": 66.77568081447056, "train/prior_ent_mean": 54.797724451337544, "train/prior_ent_min": 38.33862564904349, "train/prior_ent_std": 4.71041921547481, "train/rep_loss_mean": 13.83043360710144, "train/rep_loss_std": 8.80960009098053, "train/reward_avg": 0.026618303558123963, "train/reward_loss_mean": 0.05651115554251841, "train/reward_loss_std": 0.25712655197296824, "train/reward_max_data": 1.0128571459225246, "train/reward_max_pred": 1.0084900311061313, "train/reward_neg_acc": 0.9926448583602905, "train/reward_neg_loss": 0.030454143150044338, "train/reward_pos_acc": 0.9630822432892663, "train/reward_pos_loss": 0.8694674794163023, "train/reward_pred": 0.025826650711574726, "train/reward_rate": 0.03135463169642857, "train_stats/sum_log_reward": 7.617857336997986, "train_stats/max_log_achievement_collect_coal": 0.1875, "train_stats/max_log_achievement_collect_drink": 3.4732142857142856, "train_stats/max_log_achievement_collect_sapling": 2.3125, "train_stats/max_log_achievement_collect_stone": 1.8660714285714286, "train_stats/max_log_achievement_collect_wood": 12.339285714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.008928571428571428, "train_stats/max_log_achievement_defeat_zombie": 0.9821428571428571, "train_stats/max_log_achievement_eat_cow": 0.1875, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0892857142857142, "train_stats/max_log_achievement_make_wood_sword": 1.8571428571428572, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.1517857142857144, "train_stats/max_log_achievement_place_stone": 0.017857142857142856, "train_stats/max_log_achievement_place_table": 3.0714285714285716, "train_stats/max_log_achievement_wake_up": 1.1785714285714286, "train_stats/mean_log_entropy": 0.44331917645675795, "eval_stats/sum_log_reward": 6.600000083446503, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 2.5, "eval_stats/max_log_achievement_collect_wood": 8.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0625, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.730875379114877e-06, "report/cont_loss_std": 0.00020854741160292178, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011756245512515306, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.853309527177771e-06, "report/cont_pred": 0.9941457509994507, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.346600532531738, "report/dyn_loss_std": 8.41994571685791, "report/image_loss_mean": 7.496589183807373, "report/image_loss_std": 10.800168991088867, "report/model_loss_mean": 15.554579734802246, "report/model_loss_std": 14.46641731262207, "report/post_ent_mag": 58.33067321777344, "report/post_ent_max": 58.33067321777344, "report/post_ent_mean": 41.89199447631836, "report/post_ent_min": 19.22765350341797, "report/post_ent_std": 7.110421657562256, "report/prior_ent_mag": 67.54878997802734, "report/prior_ent_max": 67.54878997802734, "report/prior_ent_mean": 55.76982498168945, "report/prior_ent_min": 32.797752380371094, "report/prior_ent_std": 4.972681045532227, "report/rep_loss_mean": 13.346600532531738, "report/rep_loss_std": 8.41994571685791, "report/reward_avg": 0.01123046875, "report/reward_loss_mean": 0.050021544098854065, "report/reward_loss_std": 0.2040119469165802, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9992251396179199, "report/reward_neg_acc": 0.988071620464325, "report/reward_neg_loss": 0.033471059054136276, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.9750100374221802, "report/reward_pred": 0.01063617318868637, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.199129297281615e-06, "eval/cont_loss_std": 0.0001814606657717377, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002750959014520049, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4008880100391252e-07, "eval/cont_pred": 0.9970782399177551, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.526788711547852, "eval/dyn_loss_std": 10.22066879272461, "eval/image_loss_mean": 13.125933647155762, "eval/image_loss_std": 18.85407257080078, "eval/model_loss_mean": 22.497055053710938, "eval/model_loss_std": 22.63149642944336, "eval/post_ent_mag": 58.200347900390625, "eval/post_ent_max": 58.200347900390625, "eval/post_ent_mean": 41.38600158691406, "eval/post_ent_min": 19.814449310302734, "eval/post_ent_std": 6.672253131866455, "eval/prior_ent_mag": 67.54878997802734, "eval/prior_ent_max": 67.54878997802734, "eval/prior_ent_mean": 55.02595901489258, "eval/prior_ent_min": 38.742618560791016, "eval/prior_ent_std": 6.0741658210754395, "eval/rep_loss_mean": 15.526788711547852, "eval/rep_loss_std": 10.22066879272461, "eval/reward_avg": 0.01787109300494194, "eval/reward_loss_mean": 0.0550382137298584, "eval/reward_loss_std": 0.3200278580188751, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0007517337799072, "eval/reward_neg_acc": 0.9850597977638245, "eval/reward_neg_loss": 0.031820155680179596, "eval/reward_pos_acc": 0.9000000357627869, "eval/reward_pos_loss": 1.2205848693847656, "eval/reward_pred": 0.015576805919408798, "eval/reward_rate": 0.01953125, "replay/size": 484481.0, "replay/inserts": 22456.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.4551538651550967e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.842735378830522e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 99656.0, "eval_replay/inserts": 3856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2501517766738828e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2814388275146, "timer/env.step_count": 2807.0, "timer/env.step_total": 254.566339969635, "timer/env.step_frac": 0.2544947152753592, "timer/env.step_avg": 0.09068982542559138, "timer/env.step_min": 0.023354053497314453, "timer/env.step_max": 3.4791107177734375, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.108972549438477, "timer/replay._sample_frac": 0.011105846932899125, "timer/replay._sample_avg": 0.0004945233506694479, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.02780890464782715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3289.0, "timer/agent.policy_total": 53.86139392852783, "timer/agent.policy_frac": 0.053846239506015185, "timer/agent.policy_avg": 0.016376221930230413, "timer/agent.policy_min": 0.009336471557617188, "timer/agent.policy_max": 0.13080525398254395, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.14863324165344238, "timer/dataset_train_frac": 0.00014859142225778343, "timer/dataset_train_avg": 0.00010586413223179657, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0004420280456542969, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 625.6556684970856, "timer/agent.train_frac": 0.6254796342421901, "timer/agent.train_avg": 0.4456236955107447, "timer/agent.train_min": 0.43268251419067383, "timer/agent.train_max": 1.6189849376678467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756348133087158, "timer/agent.report_frac": 0.0004755009888679268, "timer/agent.report_avg": 0.2378174066543579, "timer/agent.report_min": 0.23114466667175293, "timer/agent.report_max": 0.2444901466369629, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836382823052491e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 22.44938886119577}
{"step": 485088, "time": 22396.909515619278, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 485192, "time": 22401.659465312958, "episode/length": 248.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 485216, "time": 22404.230682849884, "episode/length": 333.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 485944, "time": 22429.80761408806, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 486032, "time": 22434.6405107975, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 486384, "time": 22447.984362125397, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 486584, "time": 22456.093101739883, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 486696, "time": 22461.407412290573, "episode/length": 268.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 486904, "time": 22469.88050508499, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 486904, "time": 22469.89092516899, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 487040, "time": 22477.975393533707, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 487584, "time": 22498.109250307083, "episode/length": 193.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 487640, "time": 22501.333998918533, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 487920, "time": 22512.326675653458, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 488240, "time": 22524.408615350723, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 488256, "time": 22526.47694993019, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 488808, "time": 22546.24827194214, "episode/length": 263.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 488904, "time": 22551.044672489166, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 489256, "time": 22564.177942752838, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 489696, "time": 22580.685348033905, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 489712, "time": 22582.83956336975, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 489776, "time": 22586.712155103683, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 489856, "time": 22590.82042312622, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 490000, "time": 22597.047338962555, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22615.758414030075, "eval_episode/length": 62.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9206349206349206}
{"step": 490048, "time": 22620.164771556854, "eval_episode/length": 67.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 490048, "time": 22623.059243917465, "eval_episode/length": 161.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 490048, "time": 22625.725714445114, "eval_episode/length": 186.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 490048, "time": 22628.199301958084, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 490048, "time": 22629.889659643173, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 490048, "time": 22631.99769091606, "eval_episode/length": 221.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 490048, "time": 22632.006316423416, "eval_episode/length": 221.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 490112, "time": 22634.12039732933, "episode/length": 49.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 490136, "time": 22636.23012804985, "episode/length": 54.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 490368, "time": 22645.691568374634, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 490856, "time": 22663.33082962036, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 490856, "time": 22663.34134745598, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 491064, "time": 22673.694514751434, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 491104, "time": 22676.75566458702, "episode/length": 137.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 491776, "time": 22702.384438037872, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 491952, "time": 22709.743118286133, "episode/length": 261.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 492168, "time": 22718.335654258728, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 492272, "time": 22723.584360837936, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 492344, "time": 22727.315259218216, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 492680, "time": 22739.998975992203, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 492712, "time": 22742.621906995773, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 493408, "time": 22767.674671649933, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 493496, "time": 22771.822731494904, "episode/length": 152.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 493840, "time": 22785.062225580215, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 493912, "time": 22788.7294318676, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 493944, "time": 22791.371159553528, "episode/length": 270.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 494160, "time": 22800.436613321304, "episode/length": 381.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 494224, "time": 22804.07051205635, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 494680, "time": 22820.572097063065, "episode/length": 245.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 495056, "time": 22834.900882959366, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 495312, "time": 22845.11324262619, "episode/length": 237.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 495424, "time": 22850.387175559998, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 495440, "time": 22852.498240947723, "episode/length": 47.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 495512, "time": 22856.158313035965, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 495728, "time": 22865.017615556717, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 496224, "time": 22883.105293273926, "episode/length": 249.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 496408, "time": 22890.55371618271, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 496504, "time": 22895.16296339035, "episode/length": 134.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 497104, "time": 22916.88453745842, "episode/length": 407.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 497192, "time": 22921.031864643097, "episode/length": 85.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 497232, "time": 22924.2199447155, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 497408, "time": 22931.75978565216, "episode/length": 245.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 497600, "time": 22939.809098005295, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 497736, "time": 22945.55831003189, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 497768, "time": 22948.0549993515, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 497832, "time": 22951.895639657974, "episode/length": 314.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 497856, "time": 22954.544526815414, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 498024, "time": 22961.577301502228, "episode/length": 35.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 498448, "time": 22977.248784303665, "episode/length": 84.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 498728, "time": 22988.058771133423, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 498992, "time": 22998.637771129608, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 499016, "time": 23000.71821451187, "episode/length": 147.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 499024, "time": 23002.76291179657, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 499496, "time": 23019.937175750732, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 499640, "time": 23026.358301639557, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 499848, "time": 23036.411263227463, "episode/length": 43.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 499872, "time": 23039.0770072937, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23064.60657310486, "eval_episode/length": 130.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9923664122137404}
{"step": 500032, "time": 23067.344486236572, "eval_episode/length": 156.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9872611464968153}
{"step": 500032, "time": 23069.859548807144, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 500032, "time": 23072.223572731018, "eval_episode/length": 197.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 500032, "time": 23075.351850271225, "eval_episode/length": 233.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9658119658119658}
{"step": 500032, "time": 23078.866406440735, "eval_episode/length": 278.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.985663082437276}
{"step": 500032, "time": 23080.502112865448, "eval_episode/length": 281.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9822695035460993}
{"step": 500032, "time": 23083.225139141083, "eval_episode/length": 307.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9902597402597403}
{"step": 500184, "time": 23088.049603939056, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 500264, "time": 23092.24297952652, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 500352, "time": 23096.989216804504, "episode/length": 237.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 500728, "time": 23110.962747573853, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 501016, "time": 23122.105361700058, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 501424, "time": 23137.52869272232, "episode/length": 300.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 501440, "time": 23139.88488292694, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 501536, "time": 23144.634953975677, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 501592, "time": 23147.888473033905, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 501928, "time": 23161.930485725403, "episode/length": 196.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 501960, "time": 23164.650339126587, "episode/length": 45.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 502064, "time": 23169.946467638016, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 502160, "time": 23174.587215662003, "episode/length": 142.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 502312, "time": 23180.89844250679, "episode/length": 333.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9850299401197605, "episode/intrinsic_return": 0.0}
{"step": 502888, "time": 23201.60445189476, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 502952, "time": 23205.233212709427, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 503248, "time": 23216.79644703865, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 503312, "time": 23220.562925577164, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 503456, "time": 23226.943408489227, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 503840, "time": 23241.43453335762, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 504024, "time": 23248.81516599655, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 504192, "time": 23256.29297709465, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 504368, "time": 23263.863678216934, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 504728, "time": 23277.279854536057, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 504904, "time": 23284.77793431282, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 505552, "time": 23308.424637556076, "episode/length": 287.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 505608, "time": 23311.772482395172, "episode/length": 339.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 505752, "time": 23318.336859226227, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 505824, "time": 23322.66210746765, "episode/length": 114.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9478260869565217, "episode/intrinsic_return": 0.0}
{"step": 505952, "time": 23328.553141355515, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 505992, "time": 23331.277810811996, "episode/length": 245.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 506384, "time": 23346.13836288452, "episode/length": 48.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 506920, "time": 23365.38996362686, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 507048, "time": 23371.31810927391, "episode/length": 356.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9859943977591037, "episode/intrinsic_return": 0.0}
{"step": 507208, "time": 23378.25555253029, "episode/length": 172.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 507528, "time": 23390.54726791382, "episode/length": 239.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 507544, "time": 23392.6678211689, "episode/length": 198.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 507545, "time": 23395.27767944336, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.07780467364805, "train/action_min": 0.0, "train/action_std": 3.0997852636567242, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04101171577019049, "train/actor_opt_grad_steps": 30920.0, "train/actor_opt_loss": -5.657027071810836, "train/adv_mag": 0.5294029989563827, "train/adv_max": 0.4937598436859483, "train/adv_mean": 0.00278745534155247, "train/adv_min": -0.4231414560307848, "train/adv_std": 0.0596414049096564, "train/cont_avg": 0.9948609264184397, "train/cont_loss_mean": 0.00016709587306646436, "train/cont_loss_std": 0.004716196703806102, "train/cont_neg_acc": 0.9904166672910962, "train/cont_neg_loss": 0.0196127651072272, "train/cont_pos_acc": 0.9999721540626905, "train/cont_pos_loss": 6.64567748900918e-05, "train/cont_pred": 0.9948674584111423, "train/cont_rate": 0.9948609264184397, "train/dyn_loss_mean": 13.72495088509634, "train/dyn_loss_std": 8.82179142228255, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9087176830210584, "train/extr_critic_critic_opt_grad_steps": 30920.0, "train/extr_critic_critic_opt_loss": 15847.155508920656, "train/extr_critic_mag": 7.240481582939202, "train/extr_critic_max": 7.240481582939202, "train/extr_critic_mean": 2.2489394778055503, "train/extr_critic_min": -0.1548977270193979, "train/extr_critic_std": 1.706464299073456, "train/extr_return_normed_mag": 1.5596544945493658, "train/extr_return_normed_max": 1.5596544945493658, "train/extr_return_normed_mean": 0.3790914355017615, "train/extr_return_normed_min": -0.13195658612547193, "train/extr_return_normed_std": 0.32543351316282937, "train/extr_return_rate": 0.8475828796413774, "train/extr_return_raw_mag": 8.567232429558503, "train/extr_return_raw_max": 8.567232429558503, "train/extr_return_raw_mean": 2.263835628827413, "train/extr_return_raw_min": -0.4648271063540844, "train/extr_return_raw_std": 1.7377190716723179, "train/extr_reward_mag": 1.0219812765189096, "train/extr_reward_max": 1.0219812765189096, "train/extr_reward_mean": 0.037811901578877836, "train/extr_reward_min": -0.37614611108252344, "train/extr_reward_std": 0.17888137465673135, "train/image_loss_mean": 6.793741331032828, "train/image_loss_std": 11.236298797823858, "train/model_loss_mean": 15.084437830228332, "train/model_loss_std": 14.853903154954843, "train/model_opt_grad_norm": 58.34255279378688, "train/model_opt_grad_steps": 30891.482269503547, "train/model_opt_loss": 14044.853657607491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 926.418439716312, "train/policy_entropy_mag": 2.3254133234632777, "train/policy_entropy_max": 2.3254133234632777, "train/policy_entropy_mean": 0.4430371985790577, "train/policy_entropy_min": 0.07937512441095732, "train/policy_entropy_std": 0.45586264048907776, "train/policy_logprob_mag": 7.438383542054089, "train/policy_logprob_max": -0.009455693634689276, "train/policy_logprob_mean": -0.44196839725717585, "train/policy_logprob_min": -7.438383542054089, "train/policy_logprob_std": 0.9988351430453307, "train/policy_randomness_mag": 0.8207688530286154, "train/policy_randomness_max": 0.8207688530286154, "train/policy_randomness_mean": 0.15637268908057653, "train/policy_randomness_min": 0.02801593563499603, "train/policy_randomness_std": 0.1608995070271458, "train/post_ent_mag": 57.64516316407116, "train/post_ent_max": 57.64516316407116, "train/post_ent_mean": 41.033539305342, "train/post_ent_min": 20.450098754666374, "train/post_ent_std": 7.143814462296506, "train/prior_ent_mag": 66.83724688807278, "train/prior_ent_max": 66.83724688807278, "train/prior_ent_mean": 54.844724344023575, "train/prior_ent_min": 38.68743575887477, "train/prior_ent_std": 4.564668638486388, "train/rep_loss_mean": 13.72495088509634, "train/rep_loss_std": 8.82179142228255, "train/reward_avg": 0.027275182749309863, "train/reward_loss_mean": 0.05555903409601103, "train/reward_loss_std": 0.24961031170178813, "train/reward_max_data": 1.0219858208446637, "train/reward_max_pred": 1.0157199159581611, "train/reward_neg_acc": 0.9926717902751679, "train/reward_neg_loss": 0.029311308769363883, "train/reward_pos_acc": 0.9676773780626609, "train/reward_pos_loss": 0.8518783462808487, "train/reward_pred": 0.02665481216386489, "train/reward_rate": 0.031928745567375884, "train_stats/sum_log_reward": 7.937838025995203, "train_stats/max_log_achievement_collect_coal": 0.18018018018018017, "train_stats/max_log_achievement_collect_drink": 3.7117117117117115, "train_stats/max_log_achievement_collect_sapling": 2.4504504504504503, "train_stats/max_log_achievement_collect_stone": 2.4774774774774775, "train_stats/max_log_achievement_collect_wood": 11.396396396396396, "train_stats/max_log_achievement_defeat_skeleton": 0.018018018018018018, "train_stats/max_log_achievement_defeat_zombie": 1.135135135135135, "train_stats/max_log_achievement_eat_cow": 0.26126126126126126, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009009009009009009, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4954954954954955, "train_stats/max_log_achievement_make_wood_sword": 1.4144144144144144, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.3603603603603602, "train_stats/max_log_achievement_place_stone": 0.02702702702702703, "train_stats/max_log_achievement_place_table": 2.981981981981982, "train_stats/max_log_achievement_wake_up": 1.2252252252252251, "train_stats/mean_log_entropy": 0.42068670354447923, "eval_stats/sum_log_reward": 8.225000232458115, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 2.6875, "eval_stats/max_log_achievement_collect_wood": 10.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.5625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.0775651137228124e-06, "report/cont_loss_std": 2.144074096577242e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020630229846574366, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0754811228252947e-06, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.575923919677734, "report/dyn_loss_std": 8.621954917907715, "report/image_loss_mean": 6.090879440307617, "report/image_loss_std": 10.077692031860352, "report/model_loss_mean": 14.885644912719727, "report/model_loss_std": 13.579137802124023, "report/post_ent_mag": 55.08066177368164, "report/post_ent_max": 55.08066177368164, "report/post_ent_mean": 39.743709564208984, "report/post_ent_min": 20.155776977539062, "report/post_ent_std": 6.822027683258057, "report/prior_ent_mag": 66.64547729492188, "report/prior_ent_max": 66.64547729492188, "report/prior_ent_mean": 54.93449020385742, "report/prior_ent_min": 38.34954071044922, "report/prior_ent_std": 4.1244893074035645, "report/rep_loss_mean": 14.575923919677734, "report/rep_loss_std": 8.621954917907715, "report/reward_avg": 0.02939453162252903, "report/reward_loss_mean": 0.0492081344127655, "report/reward_loss_std": 0.20345041155815125, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024070739746094, "report/reward_neg_acc": 0.9919109344482422, "report/reward_neg_loss": 0.024017158895730972, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7610331177711487, "report/reward_pred": 0.028616078197956085, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.005240776110440493, "eval/cont_loss_std": 0.1605343520641327, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.894288957118988, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.0686936598795e-07, "eval/cont_pred": 0.9953128099441528, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.657163619995117, "eval/dyn_loss_std": 9.322310447692871, "eval/image_loss_mean": 10.4707612991333, "eval/image_loss_std": 12.457636833190918, "eval/model_loss_mean": 21.19000244140625, "eval/model_loss_std": 16.19956398010254, "eval/post_ent_mag": 57.457252502441406, "eval/post_ent_max": 57.457252502441406, "eval/post_ent_mean": 40.621917724609375, "eval/post_ent_min": 21.93254852294922, "eval/post_ent_std": 6.803038120269775, "eval/prior_ent_mag": 66.64547729492188, "eval/prior_ent_max": 66.64547729492188, "eval/prior_ent_mean": 56.33008575439453, "eval/prior_ent_min": 42.049652099609375, "eval/prior_ent_std": 4.0730133056640625, "eval/rep_loss_mean": 17.657163619995117, "eval/rep_loss_std": 9.322310447692871, "eval/reward_avg": 0.0341796875, "eval/reward_loss_mean": 0.1197015643119812, "eval/reward_loss_std": 0.5894362926483154, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0070476531982422, "eval/reward_neg_acc": 0.9877800941467285, "eval/reward_neg_loss": 0.060296230018138885, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.5086548328399658, "eval/reward_pred": 0.027237288653850555, "eval/reward_rate": 0.041015625, "replay/size": 507041.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.461677094723316e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.149207291028179e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4240.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2360091479319446e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.898962020874, "timer/env.step_count": 2820.0, "timer/env.step_total": 251.80302023887634, "timer/env.step_frac": 0.25132576216166413, "timer/env.step_avg": 0.08929185114853772, "timer/env.step_min": 0.022942543029785156, "timer/env.step_max": 3.5076630115509033, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.260900735855103, "timer/replay._sample_frac": 0.011239557243518222, "timer/replay._sample_avg": 0.0004991534014120169, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.033666372299194336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3350.0, "timer/agent.policy_total": 54.595067501068115, "timer/agent.policy_frac": 0.054491590041122986, "timer/agent.policy_avg": 0.016297035074945707, "timer/agent.policy_min": 0.009355545043945312, "timer/agent.policy_max": 0.10109591484069824, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.15162944793701172, "timer/dataset_train_frac": 0.0001513420551221737, "timer/dataset_train_avg": 0.00010753861555816434, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0007476806640625, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 630.0036201477051, "timer/agent.train_frac": 0.6288095347229028, "timer/agent.train_avg": 0.4468110781189398, "timer/agent.train_min": 0.43356943130493164, "timer/agent.train_max": 1.809213399887085, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47603654861450195, "timer/agent.report_frac": 0.0004751342866493398, "timer/agent.report_avg": 0.23801827430725098, "timer/agent.report_min": 0.23043346405029297, "timer/agent.report_max": 0.24560308456420898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.093566962150159e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 22.516948133346297}
{"step": 507880, "time": 23406.179223299026, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 508176, "time": 23419.237608909607, "episode/length": 302.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9933993399339934, "episode/intrinsic_return": 0.0}
{"step": 508560, "time": 23434.31317639351, "episode/length": 204.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 508616, "time": 23437.656980991364, "episode/length": 485.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9897119341563786, "episode/intrinsic_return": 0.0}
{"step": 508840, "time": 23446.765689611435, "episode/length": 223.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 509152, "time": 23459.175493955612, "episode/length": 202.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 509184, "time": 23461.92394542694, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9919028340080972, "episode/intrinsic_return": 0.0}
{"step": 509424, "time": 23471.715257883072, "episode/length": 192.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 23512.949525356293, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 510016, "time": 23515.085596084595, "eval_episode/length": 171.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 510016, "time": 23517.03915333748, "eval_episode/length": 180.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 510016, "time": 23520.91392350197, "eval_episode/length": 230.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 510016, "time": 23526.550385713577, "eval_episode/length": 284.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.968421052631579}
{"step": 510016, "time": 23528.63259077072, "eval_episode/length": 293.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9863945578231292}
{"step": 510016, "time": 23530.917463064194, "eval_episode/length": 310.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9967845659163987}
{"step": 510016, "time": 23533.128836631775, "eval_episode/length": 153.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.974025974025974}
{"step": 510264, "time": 23541.234879732132, "episode/length": 134.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 510376, "time": 23546.52156805992, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 510392, "time": 23548.53050327301, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 510512, "time": 23554.207662582397, "episode/length": 291.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 510728, "time": 23562.739800930023, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 510872, "time": 23569.10771203041, "episode/length": 281.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 511112, "time": 23578.64535164833, "episode/length": 445.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910313901345291, "episode/intrinsic_return": 0.0}
{"step": 511384, "time": 23589.377564430237, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 511528, "time": 23595.741312265396, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 512080, "time": 23615.960984945297, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 512480, "time": 23631.188548088074, "episode/length": 276.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9711191335740073, "episode/intrinsic_return": 0.0}
{"step": 512592, "time": 23636.452491760254, "episode/length": 259.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 512760, "time": 23643.34595656395, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 513008, "time": 23653.573279619217, "episode/length": 236.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 513336, "time": 23666.15601658821, "episode/length": 225.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 513360, "time": 23669.24431705475, "episode/length": 328.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 513368, "time": 23671.247798919678, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 513728, "time": 23685.754982471466, "episode/length": 48.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 513832, "time": 23690.51434612274, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 513920, "time": 23695.21531200409, "episode/length": 144.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 514208, "time": 23706.324273347855, "episode/length": 215.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 514248, "time": 23709.087763786316, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 514360, "time": 23714.410501480103, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 514560, "time": 23722.784019708633, "episode/length": 38.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 515040, "time": 23740.398544311523, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 515360, "time": 23752.75677895546, "episode/length": 249.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 515496, "time": 23758.644560575485, "episode/length": 116.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 515544, "time": 23761.751774787903, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 515912, "time": 23775.746685028076, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 516096, "time": 23783.798446178436, "episode/length": 271.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 516248, "time": 23791.87503004074, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 516624, "time": 23806.276899576187, "episode/length": 361.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9972375690607734, "episode/intrinsic_return": 0.0}
{"step": 516752, "time": 23812.254244804382, "episode/length": 317.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 516768, "time": 23814.403557300568, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 516808, "time": 23817.155233860016, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 516872, "time": 23820.896290063858, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 516976, "time": 23826.116974830627, "episode/length": 43.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 517472, "time": 23844.145775794983, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 517560, "time": 23848.40982556343, "episode/length": 205.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 517976, "time": 23863.808324098587, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 518160, "time": 23871.722137451172, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 518184, "time": 23873.8225171566, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 518400, "time": 23882.8868432045, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 518472, "time": 23886.610771417618, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 518744, "time": 23897.36491370201, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 519248, "time": 23915.806108236313, "episode/length": 62.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 519624, "time": 23929.773725271225, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 519704, "time": 23933.95378136635, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 519728, "time": 23936.627690792084, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 519800, "time": 23940.521450281143, "episode/length": 174.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 519944, "time": 23946.969792842865, "episode/length": 297.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 519976, "time": 23949.780957460403, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 23967.370136260986, "eval_episode/length": 47.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 520000, "time": 23969.120157957077, "eval_episode/length": 52.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 520000, "time": 23976.228433847427, "eval_episode/length": 184.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 520000, "time": 23977.783022403717, "eval_episode/length": 185.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 520000, "time": 23979.855746507645, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 520000, "time": 23981.530028104782, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 520000, "time": 23983.962420225143, "eval_episode/length": 166.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 520000, "time": 23985.72914290428, "eval_episode/length": 220.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 520016, "time": 23986.26317667961, "episode/length": 317.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 520344, "time": 23998.49752688408, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 521032, "time": 24022.872611522675, "episode/length": 162.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 521232, "time": 24031.30220222473, "episode/length": 156.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 521328, "time": 24036.08676457405, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 521400, "time": 24040.00439596176, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 521480, "time": 24044.15597319603, "episode/length": 231.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9870689655172413, "episode/intrinsic_return": 0.0}
{"step": 521560, "time": 24048.380628347397, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 521776, "time": 24057.391460180283, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9553072625698324, "episode/intrinsic_return": 0.0}
{"step": 521832, "time": 24060.67603635788, "episode/length": 74.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 522488, "time": 24084.127591133118, "episode/length": 88.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 522648, "time": 24091.070656061172, "episode/length": 201.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 522696, "time": 24094.23987364769, "episode/length": 161.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 522928, "time": 24103.676288366318, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 522952, "time": 24105.832493305206, "episode/length": 202.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 523048, "time": 24110.67718076706, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 523248, "time": 24119.08207845688, "episode/length": 430.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 523568, "time": 24131.358906030655, "episode/length": 134.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 523584, "time": 24133.34974718094, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 523952, "time": 24147.075765371323, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 524288, "time": 24160.129184007645, "episode/length": 198.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 524304, "time": 24163.71722817421, "episode/length": 156.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 524632, "time": 24175.895698785782, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 524672, "time": 24179.025820493698, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 525176, "time": 24197.026423692703, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 525528, "time": 24210.205482006073, "episode/length": 359.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 525904, "time": 24224.591054677963, "episode/length": 243.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 526160, "time": 24234.596164226532, "episode/length": 231.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 526880, "time": 24260.172612190247, "episode/length": 280.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 526960, "time": 24264.366923332214, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 526960, "time": 24264.375571489334, "episode/length": 178.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 526976, "time": 24268.256281852722, "episode/length": 335.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 526992, "time": 24270.362189292908, "episode/length": 289.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 527368, "time": 24284.1711165905, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 527920, "time": 24304.194865226746, "episode/length": 251.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 528320, "time": 24318.89775300026, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 528352, "time": 24321.495846748352, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 528400, "time": 24324.602415800095, "episode/length": 643.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829192546583851, "episode/intrinsic_return": 0.0}
{"step": 528568, "time": 24331.58103632927, "episode/length": 198.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 528952, "time": 24345.84531712532, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 529408, "time": 24362.478449344635, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.0}
{"step": 529416, "time": 24364.110501766205, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 529728, "time": 24376.46849322319, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 529800, "time": 24380.25963807106, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 530000, "time": 24388.626084327698, "episode/length": 178.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 530048, "time": 24391.73834848404, "episode/length": 215.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24414.506229877472, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 530088, "time": 24418.887220859528, "eval_episode/length": 233.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 530088, "time": 24420.931492090225, "eval_episode/length": 244.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9755102040816327}
{"step": 530088, "time": 24423.546646595, "eval_episode/length": 267.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.996268656716418}
{"step": 530088, "time": 24425.94413280487, "eval_episode/length": 286.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9825783972125436}
{"step": 530088, "time": 24425.95507001877, "eval_episode/length": 286.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 530088, "time": 24429.92206978798, "eval_episode/length": 297.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9966442953020134}
{"step": 530088, "time": 24431.71404004097, "eval_episode/length": 302.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 530089, "time": 24432.7443151474, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.246363430158467, "train/action_min": 0.0, "train/action_std": 3.237412341097568, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04330145623138611, "train/actor_opt_grad_steps": 32330.0, "train/actor_opt_loss": -2.6371957771612187, "train/adv_mag": 0.5442097749270446, "train/adv_max": 0.5104428318375391, "train/adv_mean": 0.0042563093146595135, "train/adv_min": -0.42586651719208307, "train/adv_std": 0.06233777758394573, "train/cont_avg": 0.9949024822695035, "train/cont_loss_mean": 0.00023024481593705276, "train/cont_loss_std": 0.006977734982813024, "train/cont_neg_acc": 0.9960431658106742, "train/cont_neg_loss": 0.019225360290861873, "train/cont_pos_acc": 0.9999582704077375, "train/cont_pos_loss": 0.00013173320990313026, "train/cont_pred": 0.9948936975594108, "train/cont_rate": 0.9949024822695035, "train/dyn_loss_mean": 13.843754531643915, "train/dyn_loss_std": 8.899289330692156, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8888077824673755, "train/extr_critic_critic_opt_grad_steps": 32330.0, "train/extr_critic_critic_opt_loss": 16095.18067791445, "train/extr_critic_mag": 7.3491663357890245, "train/extr_critic_max": 7.3491663357890245, "train/extr_critic_mean": 2.272503228052288, "train/extr_critic_min": -0.15800841987555755, "train/extr_critic_std": 1.6899364408871806, "train/extr_return_normed_mag": 1.5725382836997932, "train/extr_return_normed_max": 1.5725382836997932, "train/extr_return_normed_mean": 0.3875722717097465, "train/extr_return_normed_min": -0.1372236354236907, "train/extr_return_normed_std": 0.3261193180760593, "train/extr_return_rate": 0.8546972405825947, "train/extr_return_raw_mag": 8.561170111311244, "train/extr_return_raw_max": 8.561170111311244, "train/extr_return_raw_mean": 2.295036704827708, "train/extr_return_raw_min": -0.4804969124548824, "train/extr_return_raw_std": 1.7251783440299069, "train/extr_reward_mag": 1.024930071323476, "train/extr_reward_max": 1.024930071323476, "train/extr_reward_mean": 0.03925633003789905, "train/extr_reward_min": -0.39446671465609934, "train/extr_reward_std": 0.1831881269706902, "train/image_loss_mean": 7.147485134449411, "train/image_loss_std": 11.578102504107969, "train/model_loss_mean": 15.512296629290208, "train/model_loss_std": 15.231167089854571, "train/model_opt_grad_norm": 58.21636448853405, "train/model_opt_grad_steps": 32300.86524822695, "train/model_opt_loss": 17265.812863613697, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1117.0212765957447, "train/policy_entropy_mag": 2.344168490551888, "train/policy_entropy_max": 2.344168490551888, "train/policy_entropy_mean": 0.44916247856532426, "train/policy_entropy_min": 0.07937512906096506, "train/policy_entropy_std": 0.47266098666698375, "train/policy_logprob_mag": 7.438383545435912, "train/policy_logprob_max": -0.009455702023197574, "train/policy_logprob_mean": -0.45007744706268854, "train/policy_logprob_min": -7.438383545435912, "train/policy_logprob_std": 1.0086778833511028, "train/policy_randomness_mag": 0.8273886074411109, "train/policy_randomness_max": 0.8273886074411109, "train/policy_randomness_mean": 0.15853464466037478, "train/policy_randomness_min": 0.02801593731269769, "train/policy_randomness_std": 0.16682858712284276, "train/post_ent_mag": 57.87057067654657, "train/post_ent_max": 57.87057067654657, "train/post_ent_mean": 41.05967333638076, "train/post_ent_min": 20.289525958663184, "train/post_ent_std": 7.226704769946159, "train/prior_ent_mag": 66.87901711971202, "train/prior_ent_max": 66.87901711971202, "train/prior_ent_mean": 54.94038190909311, "train/prior_ent_min": 38.675269728856726, "train/prior_ent_std": 4.700856606165568, "train/rep_loss_mean": 13.843754531643915, "train/rep_loss_std": 8.899289330692156, "train/reward_avg": 0.029123032683546237, "train/reward_loss_mean": 0.058328554113494586, "train/reward_loss_std": 0.2619271663063807, "train/reward_max_data": 1.0191489407356749, "train/reward_max_pred": 1.0116761550835685, "train/reward_neg_acc": 0.9929545369554074, "train/reward_neg_loss": 0.03052497564663067, "train/reward_pos_acc": 0.9648946029074649, "train/reward_pos_loss": 0.8591077885729201, "train/reward_pred": 0.02814374851551673, "train/reward_rate": 0.03370179521276596, "train_stats/sum_log_reward": 7.732075640334274, "train_stats/max_log_achievement_collect_coal": 0.2641509433962264, "train_stats/max_log_achievement_collect_drink": 4.849056603773585, "train_stats/max_log_achievement_collect_sapling": 1.9622641509433962, "train_stats/max_log_achievement_collect_stone": 3.056603773584906, "train_stats/max_log_achievement_collect_wood": 12.39622641509434, "train_stats/max_log_achievement_defeat_skeleton": 0.018867924528301886, "train_stats/max_log_achievement_defeat_zombie": 1.0471698113207548, "train_stats/max_log_achievement_eat_cow": 0.16981132075471697, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4528301886792452, "train_stats/max_log_achievement_make_wood_sword": 1.820754716981132, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.8962264150943395, "train_stats/max_log_achievement_place_stone": 0.018867924528301886, "train_stats/max_log_achievement_place_table": 3.556603773584906, "train_stats/max_log_achievement_wake_up": 1.1886792452830188, "train_stats/mean_log_entropy": 0.4360674937378685, "eval_stats/sum_log_reward": 7.808333456516266, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 4.833333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.1666666666666665, "eval_stats/max_log_achievement_collect_stone": 2.3333333333333335, "eval_stats/max_log_achievement_collect_wood": 11.208333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.75, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.041666666666666664, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.1666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0002064888394670561, "report/cont_loss_std": 0.005390840582549572, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.036465782672166824, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8572774681379087e-05, "report/cont_pred": 0.9952538013458252, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.914212226867676, "report/dyn_loss_std": 8.65502643585205, "report/image_loss_mean": 6.859140872955322, "report/image_loss_std": 9.938694953918457, "report/model_loss_mean": 15.864995956420898, "report/model_loss_std": 13.521357536315918, "report/post_ent_mag": 57.69165802001953, "report/post_ent_max": 57.69165802001953, "report/post_ent_mean": 40.06200408935547, "report/post_ent_min": 20.30402183532715, "report/post_ent_std": 7.097512722015381, "report/prior_ent_mag": 66.73588562011719, "report/prior_ent_max": 66.73588562011719, "report/prior_ent_mean": 55.05653762817383, "report/prior_ent_min": 41.01847839355469, "report/prior_ent_std": 4.473633289337158, "report/rep_loss_mean": 14.914212226867676, "report/rep_loss_std": 8.65502643585205, "report/reward_avg": 0.03886718675494194, "report/reward_loss_mean": 0.05712147057056427, "report/reward_loss_std": 0.19829240441322327, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0120317935943604, "report/reward_neg_acc": 0.9918450117111206, "report/reward_neg_loss": 0.02525683306157589, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7840797901153564, "report/reward_pred": 0.035410378128290176, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.996996949557797e-07, "eval/cont_loss_std": 6.434159331547562e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00013795919949188828, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3069874544034974e-07, "eval/cont_pred": 0.9980469942092896, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.905414581298828, "eval/dyn_loss_std": 9.834720611572266, "eval/image_loss_mean": 11.223922729492188, "eval/image_loss_std": 13.677694320678711, "eval/model_loss_mean": 20.906587600708008, "eval/model_loss_std": 17.45302963256836, "eval/post_ent_mag": 59.642738342285156, "eval/post_ent_max": 59.642738342285156, "eval/post_ent_mean": 41.29490280151367, "eval/post_ent_min": 21.642913818359375, "eval/post_ent_std": 7.574913024902344, "eval/prior_ent_mag": 66.73588562011719, "eval/prior_ent_max": 66.73588562011719, "eval/prior_ent_mean": 55.5042610168457, "eval/prior_ent_min": 41.272857666015625, "eval/prior_ent_std": 4.5113019943237305, "eval/rep_loss_mean": 15.905414581298828, "eval/rep_loss_std": 9.834720611572266, "eval/reward_avg": 0.041015625, "eval/reward_loss_mean": 0.1394173949956894, "eval/reward_loss_std": 0.8307307362556458, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004488229751587, "eval/reward_neg_acc": 0.9897855520248413, "eval/reward_neg_loss": 0.031588684767484665, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 2.485291004180908, "eval/reward_pred": 0.030157044529914856, "eval/reward_rate": 0.0439453125, "replay/size": 529585.0, "replay/inserts": 22544.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.4715557660169852e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.151787686804832e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2992410098805147e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1037.4446241855621, "timer/env.step_count": 2818.0, "timer/env.step_total": 247.1879324913025, "timer/env.step_frac": 0.2382661461910369, "timer/env.step_avg": 0.08771750620699166, "timer/env.step_min": 0.022972583770751953, "timer/env.step_max": 3.3740522861480713, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.251395463943481, "timer/replay._sample_frac": 0.010845297379391505, "timer/replay._sample_avg": 0.0004990860301607293, "timer/replay._sample_min": 0.0004210472106933594, "timer/replay._sample_max": 0.0336911678314209, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3668.0, "timer/agent.policy_total": 61.56800556182861, "timer/agent.policy_frac": 0.05934582350374807, "timer/agent.policy_avg": 0.0167851705457548, "timer/agent.policy_min": 0.00938272476196289, "timer/agent.policy_max": 0.13463425636291504, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.15137267112731934, "timer/dataset_train_frac": 0.0001459091575573523, "timer/dataset_train_avg": 0.0001074326977482749, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0005979537963867188, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 628.0135712623596, "timer/agent.train_frac": 0.6053465954921466, "timer/agent.train_avg": 0.44571580643176695, "timer/agent.train_min": 0.4321601390838623, "timer/agent.train_max": 1.531158208847046, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4740869998931885, "timer/agent.report_frac": 0.0004569757159476023, "timer/agent.report_avg": 0.23704349994659424, "timer/agent.report_min": 0.23018836975097656, "timer/agent.report_max": 0.24389863014221191, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.171423625800259e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.730029439961932}
{"step": 530256, "time": 24438.3027009964, "episode/length": 65.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 530296, "time": 24441.031039714813, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 530736, "time": 24457.274628162384, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 530784, "time": 24460.611454725266, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 530992, "time": 24469.096799850464, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 531296, "time": 24480.81479716301, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 531616, "time": 24493.158547639847, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 531624, "time": 24494.814815044403, "episode/length": 227.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 532056, "time": 24510.692152500153, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 532200, "time": 24517.01925110817, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 532392, "time": 24525.168627738953, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 532480, "time": 24530.087139606476, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 532528, "time": 24535.0189807415, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 532840, "time": 24546.786916732788, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 532856, "time": 24548.952557325363, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 532984, "time": 24555.045186042786, "episode/length": 169.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 533608, "time": 24577.407374858856, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 533968, "time": 24591.3000164032, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 534032, "time": 24594.96703338623, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 534064, "time": 24597.5576004982, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 534208, "time": 24603.915333986282, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 534272, "time": 24607.666528224945, "episode/length": 371.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 534384, "time": 24612.989666223526, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 534736, "time": 24626.164117336273, "episode/length": 234.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 535392, "time": 24649.58930325508, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 535560, "time": 24656.594336509705, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 535592, "time": 24659.192269086838, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 535624, "time": 24661.808834552765, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 535688, "time": 24665.590070724487, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 535816, "time": 24671.492510080338, "episode/length": 52.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 536176, "time": 24685.169187545776, "episode/length": 60.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 536184, "time": 24686.80562567711, "episode/length": 180.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 536472, "time": 24698.05248594284, "episode/length": 274.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 536584, "time": 24703.3896048069, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 537000, "time": 24718.86369919777, "episode/length": 179.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 537168, "time": 24726.19954061508, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 537408, "time": 24735.90969967842, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 537656, "time": 24745.539182186127, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 538016, "time": 24759.369292259216, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 538048, "time": 24762.15495324135, "episode/length": 233.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 538136, "time": 24766.323337078094, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 538136, "time": 24766.330760240555, "episode/length": 90.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 538152, "time": 24770.382992506027, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 538216, "time": 24774.09188270569, "episode/length": 323.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 538584, "time": 24787.741609096527, "episode/length": 55.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 538592, "time": 24789.904289245605, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 538968, "time": 24803.654155254364, "episode/length": 118.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9495798319327731, "episode/intrinsic_return": 0.0}
{"step": 539072, "time": 24808.89697241783, "episode/length": 60.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 539224, "time": 24815.316304206848, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 539776, "time": 24835.61559319496, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 539816, "time": 24838.29044866562, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 539896, "time": 24842.45202565193, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 24870.431483745575, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 540072, "time": 24872.138595581055, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 540072, "time": 24874.673914909363, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 540072, "time": 24876.324465990067, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 540072, "time": 24879.366727352142, "eval_episode/length": 239.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 540072, "time": 24880.983536720276, "eval_episode/length": 240.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975103734439834}
{"step": 540072, "time": 24883.714663267136, "eval_episode/length": 267.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9813432835820896}
{"step": 540072, "time": 24885.390577316284, "eval_episode/length": 272.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9963369963369964}
{"step": 540208, "time": 24890.13604259491, "episode/length": 141.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 540264, "time": 24893.35924267769, "episode/length": 208.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 540464, "time": 24901.86889243126, "episode/length": 288.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 540736, "time": 24914.06778860092, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 540808, "time": 24917.81782269478, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 541064, "time": 24927.827239513397, "episode/length": 74.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 541096, "time": 24930.38621044159, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 541456, "time": 24944.112298488617, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 541464, "time": 24945.67990541458, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 541464, "time": 24945.688942670822, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 542120, "time": 24970.8029794693, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 542384, "time": 24981.55661892891, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 542464, "time": 24985.850214004517, "episode/length": 274.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 542544, "time": 24990.20241379738, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 542752, "time": 24998.70735669136, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 542784, "time": 25001.3314037323, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 542968, "time": 25008.771911382675, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 543216, "time": 25018.882202386856, "episode/length": 93.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 543384, "time": 25025.860981225967, "episode/length": 330.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 543456, "time": 25030.17892408371, "episode/length": 133.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 543712, "time": 25040.23563027382, "episode/length": 61.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 543856, "time": 25046.691863059998, "episode/length": 49.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 544176, "time": 25059.09018421173, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 544376, "time": 25066.935758829117, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 544464, "time": 25071.601950883865, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 544712, "time": 25081.109404802322, "episode/length": 323.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 544904, "time": 25089.140973567963, "episode/length": 241.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 545056, "time": 25095.96706700325, "episode/length": 208.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 545376, "time": 25108.13729405403, "episode/length": 39.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 545416, "time": 25110.810669898987, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 545768, "time": 25124.55273628235, "episode/length": 162.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 545840, "time": 25128.807680368423, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.0}
{"step": 545896, "time": 25132.062927484512, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 546216, "time": 25144.37046933174, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 546280, "time": 25148.183120965958, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 546672, "time": 25162.980085134506, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 546896, "time": 25171.878903627396, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 547112, "time": 25180.407673835754, "episode/length": 167.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 547112, "time": 25180.417018413544, "episode/length": 211.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 547368, "time": 25192.215740203857, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 547704, "time": 25205.65488600731, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 547840, "time": 25212.027945518494, "episode/length": 249.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 548096, "time": 25222.026498794556, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 548376, "time": 25232.975873470306, "episode/length": 269.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 548512, "time": 25239.389248371124, "episode/length": 51.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 548904, "time": 25255.539314985275, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 548984, "time": 25259.84277200699, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 548992, "time": 25261.888933181763, "episode/length": 234.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 549304, "time": 25273.7141456604, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 549336, "time": 25276.36986732483, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 549824, "time": 25294.18456864357, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 549824, "time": 25294.193695783615, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 549856, "time": 25298.55091738701, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 25325.985659122467, "eval_episode/length": 140.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 550056, "time": 25329.11448907852, "eval_episode/length": 164.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 550056, "time": 25332.681750535965, "eval_episode/length": 174.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 550056, "time": 25334.465418815613, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9606741573033708}
{"step": 550056, "time": 25336.332396507263, "eval_episode/length": 181.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 550056, "time": 25338.40281510353, "eval_episode/length": 52.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 550056, "time": 25340.3341588974, "eval_episode/length": 201.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 550056, "time": 25344.260352134705, "eval_episode/length": 257.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9961240310077519}
{"step": 550056, "time": 25344.26930785179, "eval_episode/length": 257.0, "eval_episode/score": 10.100000068545341, "eval_episode/reward_rate": 0.9961240310077519}
{"step": 550280, "time": 25351.727258205414, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 550632, "time": 25365.071600198746, "episode/length": 205.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 550832, "time": 25373.511780023575, "episode/length": 190.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 550968, "time": 25379.515333414078, "episode/length": 142.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 551112, "time": 25385.860319375992, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 551488, "time": 25400.322517633438, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 551568, "time": 25404.567621469498, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 551752, "time": 25411.971707582474, "episode/length": 344.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9884057971014493, "episode/intrinsic_return": 0.0}
{"step": 551896, "time": 25418.422520399094, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 552016, "time": 25424.24859046936, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 552096, "time": 25428.41923236847, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 552153, "time": 25432.774659633636, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.29775293322577, "train/action_min": 0.0, "train/action_std": 3.167257096456445, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042562347796300186, "train/actor_opt_grad_steps": 33725.0, "train/actor_opt_loss": -2.296384665845097, "train/adv_mag": 0.5466134610815324, "train/adv_max": 0.49323850567790045, "train/adv_mean": 0.003997671868263211, "train/adv_min": -0.44644198998592904, "train/adv_std": 0.06055167922075244, "train/cont_avg": 0.9945086050724637, "train/cont_loss_mean": 0.0001800546507511015, "train/cont_loss_std": 0.005236261009646687, "train/cont_neg_acc": 0.9939527269722759, "train/cont_neg_loss": 0.01946761238012028, "train/cont_pos_acc": 0.9999715120032213, "train/cont_pos_loss": 7.165293511760588e-05, "train/cont_pred": 0.994512750186782, "train/cont_rate": 0.9945086050724637, "train/dyn_loss_mean": 13.5379697550898, "train/dyn_loss_std": 8.851893266042074, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9374403141546941, "train/extr_critic_critic_opt_grad_steps": 33725.0, "train/extr_critic_critic_opt_loss": 16205.800533571106, "train/extr_critic_mag": 7.789202220198037, "train/extr_critic_max": 7.789202220198037, "train/extr_critic_mean": 2.488249395204627, "train/extr_critic_min": -0.1558924196422964, "train/extr_critic_std": 1.824279803296794, "train/extr_return_normed_mag": 1.5483646427375684, "train/extr_return_normed_max": 1.5483646427375684, "train/extr_return_normed_mean": 0.40360839859299036, "train/extr_return_normed_min": -0.12286481760658216, "train/extr_return_normed_std": 0.32853182221668353, "train/extr_return_rate": 0.8425154254056405, "train/extr_return_raw_mag": 8.990534616553266, "train/extr_return_raw_max": 8.990534616553266, "train/extr_return_raw_mean": 2.5106875429982725, "train/extr_return_raw_min": -0.47033988187710446, "train/extr_return_raw_std": 1.8606053625327954, "train/extr_reward_mag": 1.0286622928536457, "train/extr_reward_max": 1.0286622928536457, "train/extr_reward_mean": 0.03949915596108506, "train/extr_reward_min": -0.3904740119325942, "train/extr_reward_std": 0.18445998570625333, "train/image_loss_mean": 6.890971411829409, "train/image_loss_std": 11.228879444841025, "train/model_loss_mean": 15.071961478910584, "train/model_loss_std": 14.858718111895133, "train/model_opt_grad_norm": 59.30626494642617, "train/model_opt_grad_steps": 33694.0, "train/model_opt_loss": 12418.652941717617, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 828.804347826087, "train/policy_entropy_mag": 2.3572566820227583, "train/policy_entropy_max": 2.3572566820227583, "train/policy_entropy_mean": 0.4418745304363361, "train/policy_entropy_min": 0.07937510646339777, "train/policy_entropy_std": 0.4776564275009045, "train/policy_logprob_mag": 7.438383610352226, "train/policy_logprob_max": -0.009455676420011383, "train/policy_logprob_mean": -0.44243744015693665, "train/policy_logprob_min": -7.438383610352226, "train/policy_logprob_std": 1.0064427269541698, "train/policy_randomness_mag": 0.8320081622704215, "train/policy_randomness_max": 0.8320081622704215, "train/policy_randomness_mean": 0.15596231812800188, "train/policy_randomness_min": 0.028015929328250713, "train/policy_randomness_std": 0.16859175729146902, "train/post_ent_mag": 58.20492545418117, "train/post_ent_max": 58.20492545418117, "train/post_ent_mean": 41.48927495099496, "train/post_ent_min": 20.27392453732698, "train/post_ent_std": 7.300941868104797, "train/prior_ent_mag": 66.98340617746547, "train/prior_ent_max": 66.98340617746547, "train/prior_ent_mean": 55.08183509716089, "train/prior_ent_min": 39.12154550137727, "train/prior_ent_std": 4.6404505156088565, "train/rep_loss_mean": 13.5379697550898, "train/rep_loss_std": 8.851893266042074, "train/reward_avg": 0.028653617293668398, "train/reward_loss_mean": 0.05802820614822533, "train/reward_loss_std": 0.2609295575083166, "train/reward_max_data": 1.017391308494236, "train/reward_max_pred": 1.0136115775592085, "train/reward_neg_acc": 0.9931209899377131, "train/reward_neg_loss": 0.030466895921668714, "train/reward_pos_acc": 0.9670090994973114, "train/reward_pos_loss": 0.8535226726013682, "train/reward_pred": 0.02782657002841217, "train/reward_rate": 0.03350033967391304, "train_stats/sum_log_reward": 7.350000124553154, "train_stats/max_log_achievement_collect_coal": 0.1896551724137931, "train_stats/max_log_achievement_collect_drink": 3.336206896551724, "train_stats/max_log_achievement_collect_sapling": 1.7241379310344827, "train_stats/max_log_achievement_collect_stone": 1.7844827586206897, "train_stats/max_log_achievement_collect_wood": 10.905172413793103, "train_stats/max_log_achievement_defeat_skeleton": 0.017241379310344827, "train_stats/max_log_achievement_defeat_zombie": 0.8362068965517241, "train_stats/max_log_achievement_eat_cow": 0.1206896551724138, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2155172413793103, "train_stats/max_log_achievement_make_wood_sword": 1.6896551724137931, "train_stats/max_log_achievement_place_furnace": 0.017241379310344827, "train_stats/max_log_achievement_place_plant": 1.5775862068965518, "train_stats/max_log_achievement_place_stone": 0.008620689655172414, "train_stats/max_log_achievement_place_table": 3.4051724137931036, "train_stats/max_log_achievement_wake_up": 1.0517241379310345, "train_stats/mean_log_entropy": 0.423449424834087, "eval_stats/sum_log_reward": 7.688235507291906, "eval_stats/max_log_achievement_collect_coal": 0.11764705882352941, "eval_stats/max_log_achievement_collect_drink": 5.235294117647059, "eval_stats/max_log_achievement_collect_sapling": 2.2941176470588234, "eval_stats/max_log_achievement_collect_stone": 0.6470588235294118, "eval_stats/max_log_achievement_collect_wood": 10.882352941176471, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.2941176470588236, "eval_stats/max_log_achievement_eat_cow": 0.17647058823529413, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0588235294117647, "eval_stats/max_log_achievement_make_wood_sword": 1.4705882352941178, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0588235294117645, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.4705882352941178, "eval_stats/max_log_achievement_wake_up": 1.2352941176470589, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.784975317306817e-06, "report/cont_loss_std": 4.814239582628943e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00016713781224098057, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.3079344322904944e-06, "report/cont_pred": 0.9970664978027344, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.124311447143555, "report/dyn_loss_std": 9.002595901489258, "report/image_loss_mean": 7.901477336883545, "report/image_loss_std": 12.889605522155762, "report/model_loss_mean": 15.834314346313477, "report/model_loss_std": 16.68917465209961, "report/post_ent_mag": 60.47030258178711, "report/post_ent_max": 60.47030258178711, "report/post_ent_mean": 41.79581832885742, "report/post_ent_min": 20.81007957458496, "report/post_ent_std": 7.325660705566406, "report/prior_ent_mag": 66.63290405273438, "report/prior_ent_max": 66.63290405273438, "report/prior_ent_mean": 54.940826416015625, "report/prior_ent_min": 39.241539001464844, "report/prior_ent_std": 5.868433952331543, "report/rep_loss_mean": 13.124311447143555, "report/rep_loss_std": 9.002595901489258, "report/reward_avg": 0.02705078013241291, "report/reward_loss_mean": 0.05824626237154007, "report/reward_loss_std": 0.2628497779369354, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022516250610352, "report/reward_neg_acc": 0.9879031777381897, "report/reward_neg_loss": 0.02892857789993286, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.9670945405960083, "report/reward_pred": 0.025663403794169426, "report/reward_rate": 0.03125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.620416878722608e-05, "eval/cont_loss_std": 0.00029316064319573343, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0021027391776442528, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.906320216628956e-06, "eval/cont_pred": 0.9941489696502686, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.87257194519043, "eval/dyn_loss_std": 10.025259971618652, "eval/image_loss_mean": 10.226583480834961, "eval/image_loss_std": 12.169671058654785, "eval/model_loss_mean": 20.50605010986328, "eval/model_loss_std": 16.235862731933594, "eval/post_ent_mag": 55.668418884277344, "eval/post_ent_max": 55.668418884277344, "eval/post_ent_mean": 40.832122802734375, "eval/post_ent_min": 18.356884002685547, "eval/post_ent_std": 7.084692001342773, "eval/prior_ent_mag": 66.82039642333984, "eval/prior_ent_max": 66.82039642333984, "eval/prior_ent_mean": 55.46002960205078, "eval/prior_ent_min": 40.11036682128906, "eval/prior_ent_std": 4.526679039001465, "eval/rep_loss_mean": 16.87257194519043, "eval/rep_loss_std": 10.025259971618652, "eval/reward_avg": 0.03759765625, "eval/reward_loss_mean": 0.1559089571237564, "eval/reward_loss_std": 0.7754458785057068, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022916793823242, "eval/reward_neg_acc": 0.9805924892425537, "eval/reward_neg_loss": 0.07391802221536636, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 1.9396673440933228, "eval/reward_pred": 0.03337346762418747, "eval/reward_rate": 0.0439453125, "replay/size": 551649.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.482476437757463e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.337376649177446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.26337151967424e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.023529291153, "timer/env.step_count": 2758.0, "timer/env.step_total": 260.43829584121704, "timer/env.step_frac": 0.2604321680569092, "timer/env.step_avg": 0.09443012902147101, "timer/env.step_min": 0.02310466766357422, "timer/env.step_max": 3.5523509979248047, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.154989004135132, "timer/replay._sample_frac": 0.011154726541326609, "timer/replay._sample_avg": 0.000505574193443398, "timer/replay._sample_min": 0.0003864765167236328, "timer/replay._sample_max": 0.025352954864501953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3289.0, "timer/agent.policy_total": 54.26674246788025, "timer/agent.policy_frac": 0.054265465639939656, "timer/agent.policy_avg": 0.01649946563328679, "timer/agent.policy_min": 0.009512186050415039, "timer/agent.policy_max": 0.11472463607788086, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.14962172508239746, "timer/dataset_train_frac": 0.00014961820467209794, "timer/dataset_train_avg": 0.00010850016322146299, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.00026154518127441406, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 615.8068652153015, "timer/agent.train_frac": 0.6157923760571955, "timer/agent.train_avg": 0.4465604533831048, "timer/agent.train_min": 0.433474063873291, "timer/agent.train_max": 1.5597479343414307, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749329090118408, "timer/agent.report_frac": 0.0004749217344400763, "timer/agent.report_avg": 0.2374664545059204, "timer/agent.report_min": 0.22985529899597168, "timer/agent.report_max": 0.24507761001586914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 4.005337886144961e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 22.063183705589623}
{"step": 553096, "time": 25464.233558893204, "episode/length": 247.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 553120, "time": 25466.778980493546, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 553624, "time": 25485.056315898895, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 553712, "time": 25489.815172195435, "episode/length": 226.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 553832, "time": 25495.131392002106, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 554264, "time": 25511.054851055145, "episode/length": 270.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 554616, "time": 25524.45249772072, "episode/length": 390.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9923273657289002, "episode/intrinsic_return": 0.0}
{"step": 554640, "time": 25527.059863090515, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 555216, "time": 25547.924645662308, "episode/length": 261.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 555256, "time": 25550.60953450203, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 555760, "time": 25569.359086036682, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 555800, "time": 25572.09024977684, "episode/length": 260.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 556152, "time": 25585.336164474487, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 556392, "time": 25594.924295425415, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 556432, "time": 25598.092975139618, "episode/length": 551.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 556672, "time": 25607.652935504913, "episode/length": 176.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 556800, "time": 25613.554649591446, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 556920, "time": 25618.938422203064, "episode/length": 60.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 556920, "time": 25618.948241710663, "episode/length": 287.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 557424, "time": 25640.95884513855, "episode/length": 202.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 557552, "time": 25646.753025770187, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 557640, "time": 25651.239593744278, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9659574468085106, "episode/intrinsic_return": 0.0}
{"step": 558184, "time": 25670.858793258667, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 558408, "time": 25679.89909386635, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 558488, "time": 25684.16672849655, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 558696, "time": 25692.826805591583, "episode/length": 221.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 558840, "time": 25699.300407409668, "episode/length": 305.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 559000, "time": 25706.06795668602, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 559368, "time": 25720.04549431801, "episode/length": 242.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 559832, "time": 25737.723756074905, "episode/length": 167.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 559872, "time": 25740.868149995804, "episode/length": 289.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 25763.32213783264, "eval_episode/length": 59.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 560040, "time": 25767.70223379135, "eval_episode/length": 127.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 560040, "time": 25769.760383605957, "eval_episode/length": 140.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 560040, "time": 25772.852989435196, "eval_episode/length": 173.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 560040, "time": 25774.99833393097, "eval_episode/length": 189.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.968421052631579}
{"step": 560040, "time": 25777.140758514404, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 560040, "time": 25781.01211452484, "eval_episode/length": 252.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9802371541501976}
{"step": 560040, "time": 25783.3201110363, "eval_episode/length": 77.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9871794871794872}
{"step": 560088, "time": 25784.914935588837, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 560680, "time": 25806.338915109634, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 561280, "time": 25828.278158664703, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 561344, "time": 25831.98778772354, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 561384, "time": 25834.74510216713, "episode/length": 399.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 561520, "time": 25841.121123313904, "episode/length": 352.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 561672, "time": 25847.55250644684, "episode/length": 229.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9869565217391304, "episode/intrinsic_return": 0.0}
{"step": 561768, "time": 25852.3797082901, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 561904, "time": 25858.68771791458, "episode/length": 152.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 561968, "time": 25862.37618303299, "episode/length": 324.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9876923076923076, "episode/intrinsic_return": 0.0}
{"step": 562256, "time": 25873.46816968918, "episode/length": 60.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 562856, "time": 25894.801228046417, "episode/length": 188.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 563136, "time": 25906.121019363403, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 563200, "time": 25909.873023986816, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 563240, "time": 25912.451144218445, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 563296, "time": 25915.984249830246, "episode/length": 54.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 563344, "time": 25919.245687246323, "episode/length": 257.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 563472, "time": 25925.004086494446, "episode/length": 243.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 563496, "time": 25927.116973400116, "episode/length": 198.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 564072, "time": 25947.778038978577, "episode/length": 226.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 564536, "time": 25964.798409223557, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 564696, "time": 25971.672959566116, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 564816, "time": 25977.49688220024, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 565096, "time": 25988.245185375214, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 565240, "time": 25994.603556632996, "episode/length": 236.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 565680, "time": 26012.418651103973, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 565872, "time": 26020.46698117256, "episode/length": 341.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 566056, "time": 26027.930508613586, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 566296, "time": 26037.556520223618, "episode/length": 349.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9914285714285714, "episode/intrinsic_return": 0.0}
{"step": 566400, "time": 26042.76633310318, "episode/length": 42.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 566408, "time": 26044.35409450531, "episode/length": 366.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9863760217983651, "episode/intrinsic_return": 0.0}
{"step": 566680, "time": 26055.01060295105, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 567024, "time": 26068.169916391373, "episode/length": 240.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.966804979253112, "episode/intrinsic_return": 0.0}
{"step": 567200, "time": 26075.573006629944, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 567368, "time": 26082.582680940628, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 567600, "time": 26092.021112918854, "episode/length": 382.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9973890339425587, "episode/intrinsic_return": 0.0}
{"step": 567968, "time": 26105.995065927505, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 568536, "time": 26126.716877937317, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 568536, "time": 26126.74489927292, "episode/length": 265.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 569088, "time": 26148.8129966259, "episode/length": 235.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 569248, "time": 26155.759971380234, "episode/length": 159.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 569552, "time": 26167.519872188568, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 569832, "time": 26178.269525527954, "episode/length": 278.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26206.285920619965, "eval_episode/length": 147.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 570024, "time": 26208.090345144272, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 570024, "time": 26210.231415510178, "eval_episode/length": 166.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 570024, "time": 26212.93821334839, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 570024, "time": 26215.918687582016, "eval_episode/length": 228.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9737991266375546}
{"step": 570024, "time": 26217.902185440063, "eval_episode/length": 239.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 570024, "time": 26222.85787320137, "eval_episode/length": 171.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 570024, "time": 26224.854795217514, "eval_episode/length": 328.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9969604863221885}
{"step": 570192, "time": 26230.751700162888, "episode/length": 438.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954441913439636, "episode/intrinsic_return": 0.0}
{"step": 570352, "time": 26237.591818094254, "episode/length": 226.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 570424, "time": 26241.233993530273, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 570528, "time": 26246.627025604248, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 571080, "time": 26266.406250476837, "episode/length": 584.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 571792, "time": 26291.951358795166, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 571904, "time": 26297.23456430435, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 572008, "time": 26302.06062436104, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 572096, "time": 26306.67045354843, "episode/length": 237.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 572448, "time": 26319.951375484467, "episode/length": 54.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 572880, "time": 26335.917414665222, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 573040, "time": 26342.814438343048, "episode/length": 326.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9938837920489296, "episode/intrinsic_return": 0.0}
{"step": 573384, "time": 26355.773164749146, "episode/length": 287.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 573552, "time": 26364.96961736679, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 573576, "time": 26367.086694717407, "episode/length": 540.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833641404805915, "episode/intrinsic_return": 0.0}
{"step": 573632, "time": 26370.71476006508, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 573736, "time": 26375.554285526276, "episode/length": 228.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 574088, "time": 26388.731098413467, "episode/length": 150.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 574352, "time": 26399.131400585175, "episode/length": 319.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 574704, "time": 26412.398183107376, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 574888, "time": 26419.940413713455, "episode/length": 230.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 575168, "time": 26431.126482963562, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 575169, "time": 26433.230478286743, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.133313496907552, "train/action_min": 0.0, "train/action_std": 3.002603530883789, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041302302645312414, "train/actor_opt_grad_steps": 35135.0, "train/actor_opt_loss": -7.009539898045154, "train/adv_mag": 0.5161649973856078, "train/adv_max": 0.49023379964960945, "train/adv_mean": 0.0025272757982798388, "train/adv_min": -0.3980729929688904, "train/adv_std": 0.05927184744117161, "train/cont_avg": 0.994873046875, "train/cont_loss_mean": 0.00023024126473804153, "train/cont_loss_std": 0.0066743258194874346, "train/cont_neg_acc": 0.9977272728106359, "train/cont_neg_loss": 0.015877957822817257, "train/cont_pos_acc": 0.9999659152494537, "train/cont_pos_loss": 0.00013711568891020912, "train/cont_pred": 0.9948589669333564, "train/cont_rate": 0.994873046875, "train/dyn_loss_mean": 13.351788845327166, "train/dyn_loss_std": 8.866110106309256, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.859810603575574, "train/extr_critic_critic_opt_grad_steps": 35135.0, "train/extr_critic_critic_opt_loss": 15823.732991536459, "train/extr_critic_mag": 7.726253297593859, "train/extr_critic_max": 7.726253297593859, "train/extr_critic_mean": 2.4957104532255068, "train/extr_critic_min": -0.1511779030164083, "train/extr_critic_std": 1.7630983028146956, "train/extr_return_normed_mag": 1.5267722598380513, "train/extr_return_normed_max": 1.5267722598380513, "train/extr_return_normed_mean": 0.4056007810350921, "train/extr_return_normed_min": -0.12156318588596252, "train/extr_return_normed_std": 0.31782839064382845, "train/extr_return_rate": 0.8613751870062616, "train/extr_return_raw_mag": 8.837132116158804, "train/extr_return_raw_max": 8.837132116158804, "train/extr_return_raw_mean": 2.509983853333526, "train/extr_return_raw_min": -0.4655656109874447, "train/extr_return_raw_std": 1.7939234243498907, "train/extr_reward_mag": 1.0277783804469638, "train/extr_reward_max": 1.0277783804469638, "train/extr_reward_mean": 0.03931426177991347, "train/extr_reward_min": -0.4035076242354181, "train/extr_reward_std": 0.18423167750653294, "train/image_loss_mean": 6.670577410194609, "train/image_loss_std": 11.40589607755343, "train/model_loss_mean": 14.737136887179481, "train/model_loss_std": 15.058678242895338, "train/model_opt_grad_norm": 59.26122616054295, "train/model_opt_grad_steps": 35103.02777777778, "train/model_opt_loss": 15330.706973605686, "train/model_opt_model_opt_grad_overflow": 0.006944444444444444, "train/model_opt_model_opt_grad_scale": 1032.986111111111, "train/policy_entropy_mag": 2.3603518588675394, "train/policy_entropy_max": 2.3603518588675394, "train/policy_entropy_mean": 0.4371142273561822, "train/policy_entropy_min": 0.07937511527496907, "train/policy_entropy_std": 0.46486092876229024, "train/policy_logprob_mag": 7.438383522960875, "train/policy_logprob_max": -0.009455688776344888, "train/policy_logprob_mean": -0.43723651953041553, "train/policy_logprob_min": -7.438383522960875, "train/policy_logprob_std": 1.0026078443560336, "train/policy_randomness_mag": 0.8331006256242593, "train/policy_randomness_max": 0.8331006256242593, "train/policy_randomness_mean": 0.15428214002814558, "train/policy_randomness_min": 0.028015932456279796, "train/policy_randomness_std": 0.16407550861024195, "train/post_ent_mag": 58.309625678592255, "train/post_ent_max": 58.309625678592255, "train/post_ent_mean": 41.547238455878365, "train/post_ent_min": 20.107321149773068, "train/post_ent_std": 7.300766560766432, "train/prior_ent_mag": 67.11069032880995, "train/prior_ent_max": 67.11069032880995, "train/prior_ent_mean": 55.013875272538925, "train/prior_ent_min": 39.402215361595154, "train/prior_ent_std": 4.596475283304851, "train/rep_loss_mean": 13.351788845327166, "train/rep_loss_std": 8.866110106309256, "train/reward_avg": 0.027669948771492474, "train/reward_loss_mean": 0.055256038490268916, "train/reward_loss_std": 0.24701199784047073, "train/reward_max_data": 1.0159722260302968, "train/reward_max_pred": 1.0116406480471294, "train/reward_neg_acc": 0.9931601277656026, "train/reward_neg_loss": 0.028982045562265232, "train/reward_pos_acc": 0.9672167727516757, "train/reward_pos_loss": 0.8409148206313452, "train/reward_pred": 0.02683152477645005, "train/reward_rate": 0.03237575954861111, "train_stats/sum_log_reward": 8.120833507428566, "train_stats/max_log_achievement_collect_coal": 0.28125, "train_stats/max_log_achievement_collect_drink": 4.3125, "train_stats/max_log_achievement_collect_sapling": 2.2395833333333335, "train_stats/max_log_achievement_collect_stone": 4.375, "train_stats/max_log_achievement_collect_wood": 13.0, "train_stats/max_log_achievement_defeat_skeleton": 0.03125, "train_stats/max_log_achievement_defeat_zombie": 1.1354166666666667, "train_stats/max_log_achievement_eat_cow": 0.11458333333333333, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010416666666666666, "train_stats/max_log_achievement_make_stone_sword": 0.010416666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 1.28125, "train_stats/max_log_achievement_make_wood_sword": 1.9583333333333333, "train_stats/max_log_achievement_place_furnace": 0.010416666666666666, "train_stats/max_log_achievement_place_plant": 2.1145833333333335, "train_stats/max_log_achievement_place_stone": 0.041666666666666664, "train_stats/max_log_achievement_place_table": 3.875, "train_stats/max_log_achievement_wake_up": 1.3854166666666667, "train_stats/mean_log_entropy": 0.45385261345654726, "eval_stats/sum_log_reward": 7.7250001430511475, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.1875, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 2.125, "eval_stats/max_log_achievement_collect_wood": 10.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 1.4375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0015579222235828638, "report/cont_loss_std": 0.04979381710290909, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00022859510499984026, "report/cont_pos_acc": 0.9990195631980896, "report/cont_pos_loss": 0.0015631350688636303, "report/cont_pred": 0.995316207408905, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.35268783569336, "report/dyn_loss_std": 9.31967830657959, "report/image_loss_mean": 7.099960803985596, "report/image_loss_std": 11.853105545043945, "report/model_loss_mean": 15.778736114501953, "report/model_loss_std": 15.732869148254395, "report/post_ent_mag": 58.24093246459961, "report/post_ent_max": 58.24093246459961, "report/post_ent_mean": 41.3763427734375, "report/post_ent_min": 20.555240631103516, "report/post_ent_std": 8.082499504089355, "report/prior_ent_mag": 66.97203063964844, "report/prior_ent_max": 66.97203063964844, "report/prior_ent_mean": 55.60450744628906, "report/prior_ent_min": 43.01872634887695, "report/prior_ent_std": 4.010268211364746, "report/rep_loss_mean": 14.35268783569336, "report/rep_loss_std": 9.31967830657959, "report/reward_avg": 0.03642578050494194, "report/reward_loss_mean": 0.065604567527771, "report/reward_loss_std": 0.24096153676509857, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0028409957885742, "report/reward_neg_acc": 0.9908256530761719, "report/reward_neg_loss": 0.03339472413063049, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.8004381656646729, "report/reward_pred": 0.03412477672100067, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00012816753587685525, "eval/cont_loss_std": 0.0040937503799796104, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03277331590652466, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.4734735032106983e-07, "eval/cont_pred": 0.9962136745452881, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.896010398864746, "eval/dyn_loss_std": 9.258915901184082, "eval/image_loss_mean": 10.4884033203125, "eval/image_loss_std": 11.884157180786133, "eval/model_loss_mean": 20.117019653320312, "eval/model_loss_std": 15.499173164367676, "eval/post_ent_mag": 59.25342559814453, "eval/post_ent_max": 59.25342559814453, "eval/post_ent_mean": 42.48900604248047, "eval/post_ent_min": 21.48151397705078, "eval/post_ent_std": 7.638205051422119, "eval/prior_ent_mag": 66.97203063964844, "eval/prior_ent_max": 66.97203063964844, "eval/prior_ent_mean": 56.47879409790039, "eval/prior_ent_min": 39.61371994018555, "eval/prior_ent_std": 4.471559047698975, "eval/rep_loss_mean": 15.896010398864746, "eval/rep_loss_std": 9.258915901184082, "eval/reward_avg": 0.02695312350988388, "eval/reward_loss_mean": 0.09088251739740372, "eval/reward_loss_std": 0.5352705717086792, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040178298950195, "eval/reward_neg_acc": 0.9909273982048035, "eval/reward_neg_loss": 0.034239258617162704, "eval/reward_pos_acc": 0.84375, "eval/reward_pos_loss": 1.8468234539031982, "eval/reward_pred": 0.01848328486084938, "eval/reward_rate": 0.03125, "replay/size": 574665.0, "replay/inserts": 23016.0, "replay/samples": 23008.0, "replay/insert_wait_avg": 1.4941456999926257e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.412704986391877e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2045230098705197e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5050172805786133e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4421572685242, "timer/env.step_count": 2877.0, "timer/env.step_total": 230.10348629951477, "timer/env.step_frac": 0.23000178933658602, "timer/env.step_avg": 0.07998035672558734, "timer/env.step_min": 0.02266216278076172, "timer/env.step_max": 3.4471635818481445, "timer/replay._sample_count": 23008.0, "timer/replay._sample_total": 11.661740064620972, "timer/replay._sample_frac": 0.01165658602038588, "timer/replay._sample_avg": 0.0005068558790255986, "timer/replay._sample_min": 0.0003674030303955078, "timer/replay._sample_max": 0.011223077774047852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3474.0, "timer/agent.policy_total": 57.041422605514526, "timer/agent.policy_frac": 0.057016212472745985, "timer/agent.policy_avg": 0.01641952291465588, "timer/agent.policy_min": 0.009453535079956055, "timer/agent.policy_max": 0.11760067939758301, "timer/dataset_train_count": 1438.0, "timer/dataset_train_total": 0.15583181381225586, "timer/dataset_train_frac": 0.00015576294209524173, "timer/dataset_train_avg": 0.00010836704715734066, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00041174888610839844, "timer/agent.train_count": 1438.0, "timer/agent.train_total": 644.2249200344086, "timer/agent.train_frac": 0.6439401971957236, "timer/agent.train_avg": 0.44800063980139676, "timer/agent.train_min": 0.43352675437927246, "timer/agent.train_max": 1.8687658309936523, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717833995819092, "timer/agent.report_frac": 0.0004715748893169442, "timer/agent.report_avg": 0.2358916997909546, "timer/agent.report_min": 0.2286069393157959, "timer/agent.report_max": 0.24317646026611328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9550837690917733e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 23.005504052514585}
{"step": 575232, "time": 26435.613721370697, "episode/length": 206.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 575264, "time": 26438.35544347763, "episode/length": 113.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 575568, "time": 26450.079258203506, "episode/length": 241.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 576368, "time": 26478.401361465454, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 576392, "time": 26480.59192585945, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 576584, "time": 26489.185195446014, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 577192, "time": 26511.103883504868, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 577232, "time": 26514.247995853424, "episode/length": 459.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9978260869565218, "episode/intrinsic_return": 0.0}
{"step": 577552, "time": 26526.407844781876, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 577624, "time": 26530.226340532303, "episode/length": 441.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 578056, "time": 26546.19660258293, "episode/length": 183.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 578256, "time": 26554.560668230057, "episode/length": 377.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 578288, "time": 26557.169227600098, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 578520, "time": 26566.40190720558, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 578568, "time": 26569.476425647736, "episode/length": 126.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 578728, "time": 26576.411084651947, "episode/length": 54.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 579144, "time": 26591.945451259613, "episode/length": 238.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 579608, "time": 26608.88778090477, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 26638.160697698593, "eval_episode/length": 34.0, "eval_episode/score": 4.099999964237213, "eval_episode/reward_rate": 0.8857142857142857}
{"step": 580008, "time": 26645.36301612854, "eval_episode/length": 165.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 580008, "time": 26646.990422964096, "eval_episode/length": 167.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 580008, "time": 26649.033908605576, "eval_episode/length": 174.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 580008, "time": 26651.30989050865, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 580008, "time": 26655.6154897213, "eval_episode/length": 254.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.996078431372549}
{"step": 580008, "time": 26657.52650642395, "eval_episode/length": 263.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 580008, "time": 26659.37110567093, "eval_episode/length": 234.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9829787234042553}
{"step": 580096, "time": 26662.545741319656, "episode/length": 254.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 580232, "time": 26668.273414611816, "episode/length": 482.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9834368530020704, "episode/intrinsic_return": 0.0}
{"step": 580632, "time": 26683.19310450554, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 580680, "time": 26686.4094145298, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 580728, "time": 26689.519235134125, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 580744, "time": 26691.619510889053, "episode/length": 271.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 581056, "time": 26703.614996910095, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 581112, "time": 26706.811249256134, "episode/length": 356.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.988795518207283, "episode/intrinsic_return": 0.0}
{"step": 581632, "time": 26726.03710579872, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 582056, "time": 26743.42330813408, "episode/length": 177.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 582480, "time": 26759.211347579956, "episode/length": 224.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 582656, "time": 26766.635237455368, "episode/length": 238.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 583056, "time": 26781.800203561783, "episode/length": 249.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 583488, "time": 26797.712329864502, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 583592, "time": 26802.60254383087, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 584472, "time": 26833.43617796898, "episode/length": 546.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9981718464351006, "episode/intrinsic_return": 0.0}
{"step": 584744, "time": 26844.023001194, "episode/length": 260.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9693486590038314, "episode/intrinsic_return": 0.0}
{"step": 584824, "time": 26848.266219615936, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 584888, "time": 26851.869158506393, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 584960, "time": 26856.062530517578, "episode/length": 528.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.994328922495274, "episode/intrinsic_return": 0.0}
{"step": 585128, "time": 26863.13178086281, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 585232, "time": 26868.518964529037, "episode/length": 343.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 585408, "time": 26875.924088716507, "episode/length": 536.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 586008, "time": 26897.13070678711, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 586160, "time": 26903.997293949127, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 586360, "time": 26911.914879322052, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 586432, "time": 26916.069432497025, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 586480, "time": 26919.3690366745, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 586640, "time": 26926.27947807312, "episode/length": 218.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 586744, "time": 26931.02189517021, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 586808, "time": 26934.755472183228, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 587232, "time": 26950.614807844162, "episode/length": 262.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 588120, "time": 26981.671339273453, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 588240, "time": 26987.381687641144, "episode/length": 259.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 588248, "time": 26989.124833345413, "episode/length": 226.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 588440, "time": 26997.07179737091, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 588504, "time": 27000.793556928635, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 588560, "time": 27004.432733774185, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 588808, "time": 27014.0122961998, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 588992, "time": 27021.9044713974, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 589360, "time": 27035.833082199097, "episode/length": 45.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 589488, "time": 27041.86419224739, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 589768, "time": 27052.585837602615, "episode/length": 50.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 589904, "time": 27060.542150497437, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 590024, "time": 27065.894235372543, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 590040, "time": 27068.075168848038, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27092.964888095856, "eval_episode/length": 150.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 590096, "time": 27096.923678159714, "eval_episode/length": 206.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 590096, "time": 27099.039646863937, "eval_episode/length": 216.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 590096, "time": 27100.94153046608, "eval_episode/length": 223.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.96875}
{"step": 590096, "time": 27104.912085533142, "eval_episode/length": 272.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9853479853479854}
{"step": 590096, "time": 27107.02510714531, "eval_episode/length": 283.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 590096, "time": 27109.286410093307, "eval_episode/length": 299.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9966666666666667}
{"step": 590096, "time": 27112.219452619553, "eval_episode/length": 57.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 590344, "time": 27120.329746723175, "episode/length": 54.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 590584, "time": 27129.96910047531, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 590712, "time": 27135.918362140656, "episode/length": 308.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 590904, "time": 27143.830577373505, "episode/length": 141.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 590936, "time": 27146.53872013092, "episode/length": 180.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 590992, "time": 27150.206550598145, "episode/length": 342.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9970845481049563, "episode/intrinsic_return": 0.0}
{"step": 591264, "time": 27161.047968626022, "episode/length": 152.0, "episode/score": 7.1000000461936, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 592248, "time": 27195.43571805954, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 592280, "time": 27198.03868818283, "episode/length": 160.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 592392, "time": 27203.464851140976, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 592520, "time": 27209.313553094864, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 592872, "time": 27222.722774028778, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 593048, "time": 27230.169165611267, "episode/length": 377.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 593504, "time": 27247.18926668167, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 593528, "time": 27249.43202328682, "episode/length": 397.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 593744, "time": 27258.433111667633, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 593824, "time": 27262.70602965355, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.997229916897507, "episode/intrinsic_return": 0.0}
{"step": 594112, "time": 27273.929642915726, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 594312, "time": 27282.128321886063, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 594680, "time": 27295.98220038414, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 594992, "time": 27308.239743471146, "episode/length": 182.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 595064, "time": 27312.03226327896, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 595216, "time": 27319.02050471306, "episode/length": 27.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 595216, "time": 27319.03013563156, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 595224, "time": 27323.23674583435, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 595536, "time": 27335.850591659546, "episode/length": 39.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 595968, "time": 27351.904281377792, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 596320, "time": 27365.172704696655, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 596328, "time": 27366.70520758629, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 596424, "time": 27371.552382469177, "episode/length": 169.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 596432, "time": 27373.727647781372, "episode/length": 289.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 596752, "time": 27385.97839641571, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 596880, "time": 27391.797864198685, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 596960, "time": 27396.02267551422, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 597312, "time": 27409.494558095932, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 597616, "time": 27421.216725587845, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 597736, "time": 27426.584542036057, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 597816, "time": 27430.847271203995, "episode/length": 62.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 597817, "time": 27433.434817552567, "train_stats/sum_log_reward": 8.02156884033306, "train_stats/max_log_achievement_collect_coal": 0.29411764705882354, "train_stats/max_log_achievement_collect_drink": 4.313725490196078, "train_stats/max_log_achievement_collect_sapling": 2.0784313725490198, "train_stats/max_log_achievement_collect_stone": 3.1666666666666665, "train_stats/max_log_achievement_collect_wood": 12.431372549019608, "train_stats/max_log_achievement_defeat_skeleton": 0.0392156862745098, "train_stats/max_log_achievement_defeat_zombie": 1.2156862745098038, "train_stats/max_log_achievement_eat_cow": 0.17647058823529413, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0196078431372549, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3137254901960784, "train_stats/max_log_achievement_make_wood_sword": 1.9313725490196079, "train_stats/max_log_achievement_place_furnace": 0.00980392156862745, "train_stats/max_log_achievement_place_plant": 1.9803921568627452, "train_stats/max_log_achievement_place_stone": 0.0784313725490196, "train_stats/max_log_achievement_place_table": 3.676470588235294, "train_stats/max_log_achievement_wake_up": 1.6274509803921569, "train_stats/mean_log_entropy": 0.4782387878672749, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.343219297152039, "train/action_min": 0.0, "train/action_std": 3.221051960126728, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04092534952499765, "train/actor_opt_grad_steps": 36560.0, "train/actor_opt_loss": -4.368947077106605, "train/adv_mag": 0.5109625452376426, "train/adv_max": 0.47851526716076737, "train/adv_mean": 0.003169715989715511, "train/adv_min": -0.41116274650215257, "train/adv_std": 0.058958222574376044, "train/cont_avg": 0.9948124445921985, "train/cont_loss_mean": 0.0002145047090253919, "train/cont_loss_std": 0.006426303083463795, "train/cont_neg_acc": 0.9910165494215404, "train/cont_neg_loss": 0.02354595683686805, "train/cont_pos_acc": 0.9999791206197536, "train/cont_pos_loss": 6.974602885660796e-05, "train/cont_pred": 0.9948267873297346, "train/cont_rate": 0.9948124445921985, "train/dyn_loss_mean": 13.407386752730567, "train/dyn_loss_std": 8.799732580252574, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8828056471567627, "train/extr_critic_critic_opt_grad_steps": 36560.0, "train/extr_critic_critic_opt_loss": 15886.051113696809, "train/extr_critic_mag": 7.860906979716416, "train/extr_critic_max": 7.860906979716416, "train/extr_critic_mean": 2.4200244381072675, "train/extr_critic_min": -0.14425344162798942, "train/extr_critic_std": 1.8079415948678417, "train/extr_return_normed_mag": 1.5320212536669793, "train/extr_return_normed_max": 1.5320212536669793, "train/extr_return_normed_mean": 0.38834937878534304, "train/extr_return_normed_min": -0.11901449808414946, "train/extr_return_normed_std": 0.32341225720043726, "train/extr_return_rate": 0.8370300015659197, "train/extr_return_raw_mag": 8.942904262677997, "train/extr_return_raw_max": 8.942904262677997, "train/extr_return_raw_mean": 2.438041184810882, "train/extr_return_raw_min": -0.44786152846001565, "train/extr_return_raw_std": 1.8394597844874605, "train/extr_reward_mag": 1.0308820795505604, "train/extr_reward_max": 1.0308820795505604, "train/extr_reward_mean": 0.04202526864589106, "train/extr_reward_min": -0.4113568177459933, "train/extr_reward_std": 0.1904482996844231, "train/image_loss_mean": 6.697889145384443, "train/image_loss_std": 11.186142170682867, "train/model_loss_mean": 14.798034140404235, "train/model_loss_std": 14.777342424325063, "train/model_opt_grad_norm": 59.92237858062095, "train/model_opt_grad_steps": 36527.0, "train/model_opt_loss": 15271.149420988475, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1032.8014184397164, "train/policy_entropy_mag": 2.3673415742021926, "train/policy_entropy_max": 2.3673415742021926, "train/policy_entropy_mean": 0.4674970938804302, "train/policy_entropy_min": 0.07937511072513904, "train/policy_entropy_std": 0.497968778753957, "train/policy_logprob_mag": 7.438383531908617, "train/policy_logprob_max": -0.009455679374225173, "train/policy_logprob_mean": -0.46728517210229914, "train/policy_logprob_min": -7.438383531908617, "train/policy_logprob_std": 1.0214133106224925, "train/policy_randomness_mag": 0.8355676869974069, "train/policy_randomness_max": 0.8355676869974069, "train/policy_randomness_mean": 0.16500595877779292, "train/policy_randomness_min": 0.02801593082646529, "train/policy_randomness_std": 0.1757611244494188, "train/post_ent_mag": 58.27777310635181, "train/post_ent_max": 58.27777310635181, "train/post_ent_mean": 41.65145966009045, "train/post_ent_min": 20.396544300918038, "train/post_ent_std": 7.2903312520777925, "train/prior_ent_mag": 67.03227948127909, "train/prior_ent_max": 67.03227948127909, "train/prior_ent_mean": 55.12339155048343, "train/prior_ent_min": 40.20658590438518, "train/prior_ent_std": 4.533749347037458, "train/rep_loss_mean": 13.407386752730567, "train/rep_loss_std": 8.799732580252574, "train/reward_avg": 0.028860538174127433, "train/reward_loss_mean": 0.055498453213813456, "train/reward_loss_std": 0.2471738853987227, "train/reward_max_data": 1.0184397207084277, "train/reward_max_pred": 1.0136837147651834, "train/reward_neg_acc": 0.993198535966535, "train/reward_neg_loss": 0.028678270393705116, "train/reward_pos_acc": 0.969190537506807, "train/reward_pos_loss": 0.8328168438681474, "train/reward_pred": 0.028252522546982933, "train/reward_rate": 0.03344553413120567, "eval_stats/sum_log_reward": 7.975000321865082, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 3.5625, "eval_stats/max_log_achievement_collect_wood": 13.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 2.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.647937205641938e-07, "report/cont_loss_std": 6.170442247821484e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011235153942834586, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.5743536130894427e-08, "report/cont_pred": 0.9970706701278687, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 15.75326919555664, "report/dyn_loss_std": 8.598668098449707, "report/image_loss_mean": 6.758586406707764, "report/image_loss_std": 9.587177276611328, "report/model_loss_mean": 16.264202117919922, "report/model_loss_std": 13.163983345031738, "report/post_ent_mag": 55.88670349121094, "report/post_ent_max": 55.88670349121094, "report/post_ent_mean": 38.479835510253906, "report/post_ent_min": 18.638336181640625, "report/post_ent_std": 6.636687755584717, "report/prior_ent_mag": 66.9876708984375, "report/prior_ent_max": 66.9876708984375, "report/prior_ent_mean": 54.379188537597656, "report/prior_ent_min": 42.928749084472656, "report/prior_ent_std": 4.33697509765625, "report/rep_loss_mean": 15.75326919555664, "report/rep_loss_std": 8.598668098449707, "report/reward_avg": 0.04033203050494194, "report/reward_loss_mean": 0.05365276336669922, "report/reward_loss_std": 0.19139181077480316, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0070793628692627, "report/reward_neg_acc": 0.9948927760124207, "report/reward_neg_loss": 0.024228530004620552, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6937934160232544, "report/reward_pred": 0.04027361050248146, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.59646309739037e-07, "eval/cont_loss_std": 1.2548198355943896e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00026703233015723526, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.817328675381759e-08, "eval/cont_pred": 0.9980473518371582, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.187721252441406, "eval/dyn_loss_std": 10.63230037689209, "eval/image_loss_mean": 9.05154800415039, "eval/image_loss_std": 14.279227256774902, "eval/model_loss_mean": 19.431379318237305, "eval/model_loss_std": 18.309396743774414, "eval/post_ent_mag": 55.1473388671875, "eval/post_ent_max": 55.1473388671875, "eval/post_ent_mean": 39.72780990600586, "eval/post_ent_min": 20.108051300048828, "eval/post_ent_std": 6.8796868324279785, "eval/prior_ent_mag": 66.9876708984375, "eval/prior_ent_max": 66.9876708984375, "eval/prior_ent_mean": 54.53224563598633, "eval/prior_ent_min": 40.55686569213867, "eval/prior_ent_std": 4.010876178741455, "eval/rep_loss_mean": 17.187721252441406, "eval/rep_loss_std": 10.63230037689209, "eval/reward_avg": 0.02744140662252903, "eval/reward_loss_mean": 0.06720075756311417, "eval/reward_loss_std": 0.41080614924430847, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0043909549713135, "eval/reward_neg_acc": 0.9879153966903687, "eval/reward_neg_loss": 0.024275265634059906, "eval/reward_pos_acc": 0.8709677457809448, "eval/reward_pos_loss": 1.4422011375427246, "eval/reward_pred": 0.02538914605975151, "eval/reward_rate": 0.0302734375, "replay/size": 597313.0, "replay/inserts": 22648.0, "replay/samples": 22656.0, "replay/insert_wait_avg": 1.4684723274988237e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.450766831468054e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2239283214194604e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1919651031494, "timer/env.step_count": 2831.0, "timer/env.step_total": 241.00599932670593, "timer/env.step_frac": 0.24095974346469687, "timer/env.step_avg": 0.08513104886142915, "timer/env.step_min": 0.023250341415405273, "timer/env.step_max": 4.187595844268799, "timer/replay._sample_count": 22656.0, "timer/replay._sample_total": 11.506067752838135, "timer/replay._sample_frac": 0.011503859413279248, "timer/replay._sample_avg": 0.0005078596289211747, "timer/replay._sample_min": 0.0003924369812011719, "timer/replay._sample_max": 0.010657548904418945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3432.0, "timer/agent.policy_total": 57.35662031173706, "timer/agent.policy_frac": 0.05734561195542287, "timer/agent.policy_avg": 0.01671230195563434, "timer/agent.policy_min": 0.009353876113891602, "timer/agent.policy_max": 0.11788558959960938, "timer/dataset_train_count": 1416.0, "timer/dataset_train_total": 0.15208816528320312, "timer/dataset_train_frac": 0.00015205897526633132, "timer/dataset_train_avg": 0.00010740689638644289, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0006003379821777344, "timer/agent.train_count": 1416.0, "timer/agent.train_total": 632.069263458252, "timer/agent.train_frac": 0.6319479515045563, "timer/agent.train_avg": 0.4463765984874661, "timer/agent.train_min": 0.43300747871398926, "timer/agent.train_max": 1.650709629058838, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4735405445098877, "timer/agent.report_frac": 0.0004734496586973198, "timer/agent.report_avg": 0.23677027225494385, "timer/agent.report_min": 0.22954845428466797, "timer/agent.report_max": 0.24399209022521973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.86047383806337e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.643322068928253}
{"step": 597864, "time": 27434.832106113434, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 597952, "time": 27439.54060268402, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 598208, "time": 27451.43691301346, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 598568, "time": 27465.547693490982, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 599056, "time": 27483.622121572495, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 599088, "time": 27486.26529622078, "episode/length": 141.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 599120, "time": 27489.1993227005, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 599320, "time": 27497.23254609108, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 600072, "time": 27524.018412590027, "episode/length": 275.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 27550.051562309265, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 600080, "time": 27550.059943914413, "eval_episode/length": 155.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 600080, "time": 27554.645191431046, "eval_episode/length": 186.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 600080, "time": 27556.516860961914, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 600080, "time": 27559.130666971207, "eval_episode/length": 216.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 600080, "time": 27561.562948942184, "eval_episode/length": 237.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 600080, "time": 27563.40867638588, "eval_episode/length": 56.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 600080, "time": 27567.860283136368, "eval_episode/length": 308.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9967637540453075}
{"step": 600280, "time": 27574.336703062057, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 600360, "time": 27578.68510699272, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 600992, "time": 27601.69606423378, "episode/length": 513.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 601016, "time": 27603.867331266403, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662447257383966, "episode/intrinsic_return": 0.0}
{"step": 601064, "time": 27607.024000167847, "episode/length": 250.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 601112, "time": 27610.245798110962, "episode/length": 223.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 601608, "time": 27628.27610516548, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 602000, "time": 27643.35647916794, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 602008, "time": 27645.060089111328, "episode/length": 126.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 602120, "time": 27650.32954454422, "episode/length": 255.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 602416, "time": 27661.95534467697, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 602544, "time": 27667.80852150917, "episode/length": 272.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 602736, "time": 27675.872841596603, "episode/length": 202.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 602744, "time": 27677.45944905281, "episode/length": 215.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 603128, "time": 27691.717329978943, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 603744, "time": 27714.05845975876, "episode/length": 216.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 603912, "time": 27721.557322740555, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 603984, "time": 27726.077963113785, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 604168, "time": 27733.69302368164, "episode/length": 218.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 604600, "time": 27749.591970920563, "episode/length": 231.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 604616, "time": 27751.717666864395, "episode/length": 326.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.0}
{"step": 604832, "time": 27760.91230893135, "episode/length": 261.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 605336, "time": 27779.291108608246, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 605368, "time": 27781.98397731781, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 605560, "time": 27789.984124183655, "episode/length": 303.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 605616, "time": 27793.619017601013, "episode/length": 233.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 606032, "time": 27809.409023046494, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 606064, "time": 27812.116374015808, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 606424, "time": 27827.048035621643, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 606528, "time": 27832.406146764755, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 606840, "time": 27844.161706209183, "episode/length": 187.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 606856, "time": 27846.32702755928, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 607152, "time": 27859.685458421707, "episode/length": 222.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 607152, "time": 27859.69515156746, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 607360, "time": 27869.977407455444, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 607832, "time": 27887.17089319229, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 607992, "time": 27894.100701093674, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 608320, "time": 27907.11089873314, "episode/length": 40.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 608376, "time": 27911.041811704636, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 608432, "time": 27914.824415445328, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 608608, "time": 27922.25713801384, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 608704, "time": 27927.125277996063, "episode/length": 230.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 609176, "time": 27944.363064289093, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 609792, "time": 27966.7272336483, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 609816, "time": 27968.994564533234, "episode/length": 172.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 609928, "time": 27974.40218114853, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28000.231488466263, "eval_episode/length": 151.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 610064, "time": 28003.720247030258, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 610064, "time": 28005.441327810287, "eval_episode/length": 194.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 610064, "time": 28007.827387332916, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 610064, "time": 28009.603828907013, "eval_episode/length": 214.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 610064, "time": 28011.804122686386, "eval_episode/length": 229.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 610064, "time": 28014.400469064713, "eval_episode/length": 253.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9803149606299213}
{"step": 610064, "time": 28016.663645744324, "eval_episode/length": 266.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 610144, "time": 28019.345603466034, "episode/length": 288.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 610168, "time": 28021.4712164402, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 610296, "time": 28027.343305826187, "episode/length": 210.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 610600, "time": 28039.633581638336, "episode/length": 284.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 610664, "time": 28043.30407142639, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 611472, "time": 28072.42023229599, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 611480, "time": 28074.090698957443, "episode/length": 147.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 611744, "time": 28084.689733743668, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 611944, "time": 28092.897416830063, "episode/length": 265.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 612024, "time": 28097.12531852722, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 612368, "time": 28110.22346019745, "episode/length": 304.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 612496, "time": 28116.003808498383, "episode/length": 228.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 612912, "time": 28131.69326400757, "episode/length": 51.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 612968, "time": 28135.4171500206, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 613032, "time": 28139.553061962128, "episode/length": 360.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 613632, "time": 28161.486768722534, "episode/length": 210.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 613712, "time": 28165.83193063736, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 614120, "time": 28180.85734820366, "episode/length": 143.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 614176, "time": 28184.480682849884, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 614216, "time": 28187.161868810654, "episode/length": 342.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 614360, "time": 28193.604682683945, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 614584, "time": 28204.22276544571, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 615360, "time": 28231.836863040924, "episode/length": 416.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9976019184652278, "episode/intrinsic_return": 0.0}
{"step": 615552, "time": 28239.899260282516, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 615848, "time": 28251.30707836151, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 615952, "time": 28256.60452389717, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 615968, "time": 28258.77424764633, "episode/length": 172.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 616112, "time": 28265.181914567947, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 616872, "time": 28291.938257455826, "episode/length": 112.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9380530973451328, "episode/intrinsic_return": 0.0}
{"step": 616960, "time": 28296.63211274147, "episode/length": 415.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 616992, "time": 28299.649382829666, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 617120, "time": 28305.479804992676, "episode/length": 425.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 617600, "time": 28323.14326786995, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 617712, "time": 28328.583357810974, "episode/length": 219.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 618296, "time": 28349.355261564255, "episode/length": 162.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 618640, "time": 28362.72492337227, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 618896, "time": 28372.93785238266, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 618912, "time": 28374.928649187088, "episode/length": 349.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 618968, "time": 28378.193174362183, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 619168, "time": 28386.722265720367, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 619264, "time": 28391.582560539246, "episode/length": 298.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 619304, "time": 28394.1505317688, "episode/length": 468.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9914712153518124, "episode/intrinsic_return": 0.0}
{"step": 619320, "time": 28396.312007665634, "episode/length": 50.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 619752, "time": 28412.371062755585, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 619920, "time": 28419.930732250214, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28446.08265018463, "eval_episode/length": 170.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 620048, "time": 28447.934683561325, "eval_episode/length": 177.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 620048, "time": 28447.942764997482, "eval_episode/length": 177.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 620048, "time": 28453.716560602188, "eval_episode/length": 195.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 620048, "time": 28455.579651355743, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 620048, "time": 28457.48130607605, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 620048, "time": 28459.03914165497, "eval_episode/length": 34.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.8857142857142857}
{"step": 620048, "time": 28462.043833732605, "eval_episode/length": 238.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.99581589958159}
{"step": 620049, "time": 28462.62962603569, "train_stats/sum_log_reward": 8.440000188350677, "train_stats/max_log_achievement_collect_coal": 0.27, "train_stats/max_log_achievement_collect_drink": 4.94, "train_stats/max_log_achievement_collect_sapling": 2.24, "train_stats/max_log_achievement_collect_stone": 3.72, "train_stats/max_log_achievement_collect_wood": 12.59, "train_stats/max_log_achievement_defeat_skeleton": 0.08, "train_stats/max_log_achievement_defeat_zombie": 1.15, "train_stats/max_log_achievement_eat_cow": 0.2, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.45, "train_stats/max_log_achievement_make_wood_sword": 1.94, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.2, "train_stats/max_log_achievement_place_stone": 0.05, "train_stats/max_log_achievement_place_table": 3.82, "train_stats/max_log_achievement_wake_up": 1.45, "train_stats/mean_log_entropy": 0.46275721192359925, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.212234606845773, "train/action_min": 0.0, "train/action_std": 3.1595500321696988, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041484049889895555, "train/actor_opt_grad_steps": 37960.0, "train/actor_opt_loss": -3.6398784100151746, "train/adv_mag": 0.5189200483208938, "train/adv_max": 0.4870120029655292, "train/adv_mean": 0.003473135658826342, "train/adv_min": -0.41342872488412924, "train/adv_std": 0.05982521782032878, "train/cont_avg": 0.9947799572841727, "train/cont_loss_mean": 0.00020301975906416377, "train/cont_loss_std": 0.006253915275189631, "train/cont_neg_acc": 0.9963229418658525, "train/cont_neg_loss": 0.01659449170985825, "train/cont_pos_acc": 0.9999717152375969, "train/cont_pos_loss": 0.00010509218668257476, "train/cont_pred": 0.9947826013290625, "train/cont_rate": 0.9947799572841727, "train/dyn_loss_mean": 13.288485726006597, "train/dyn_loss_std": 8.84842056507687, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.850207673988754, "train/extr_critic_critic_opt_grad_steps": 37960.0, "train/extr_critic_critic_opt_loss": 15547.28097600045, "train/extr_critic_mag": 7.918708629745374, "train/extr_critic_max": 7.918708629745374, "train/extr_critic_mean": 2.530628896445679, "train/extr_critic_min": -0.15412167422205425, "train/extr_critic_std": 1.7948656510963714, "train/extr_return_normed_mag": 1.5515771769791198, "train/extr_return_normed_max": 1.5515771769791198, "train/extr_return_normed_mean": 0.3974401007453315, "train/extr_return_normed_min": -0.13383281054042226, "train/extr_return_normed_std": 0.3234246214516729, "train/extr_return_rate": 0.8791240882530487, "train/extr_return_raw_mag": 9.064778646976828, "train/extr_return_raw_max": 9.064778646976828, "train/extr_return_raw_mean": 2.5502185538518343, "train/extr_return_raw_min": -0.4478950792079349, "train/extr_return_raw_std": 1.8257368597195303, "train/extr_reward_mag": 1.0320816022886647, "train/extr_reward_max": 1.0320816022886647, "train/extr_reward_mean": 0.04305138355858034, "train/extr_reward_min": -0.39360406072877296, "train/extr_reward_std": 0.19356607833354594, "train/image_loss_mean": 6.50890644334203, "train/image_loss_std": 11.260149091267758, "train/model_loss_mean": 14.539927715877836, "train/model_loss_std": 14.895113718595436, "train/model_opt_grad_norm": 60.08153389855254, "train/model_opt_grad_steps": 37925.8417266187, "train/model_opt_loss": 18319.18022847347, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9928057553957, "train/policy_entropy_mag": 2.3709679661894874, "train/policy_entropy_max": 2.3709679661894874, "train/policy_entropy_mean": 0.4588366365261215, "train/policy_entropy_min": 0.07937510890497577, "train/policy_entropy_std": 0.49408231686345105, "train/policy_logprob_mag": 7.4383835895456, "train/policy_logprob_max": -0.009455679688039871, "train/policy_logprob_mean": -0.4588588195310222, "train/policy_logprob_min": -7.4383835895456, "train/policy_logprob_std": 1.020665502805504, "train/policy_randomness_mag": 0.8368476414852005, "train/policy_randomness_max": 0.8368476414852005, "train/policy_randomness_mean": 0.1619491969509948, "train/policy_randomness_min": 0.02801593028598552, "train/policy_randomness_std": 0.1743893763787455, "train/post_ent_mag": 58.250668532556766, "train/post_ent_max": 58.250668532556766, "train/post_ent_mean": 41.64048097459533, "train/post_ent_min": 20.23488588127301, "train/post_ent_std": 7.291183571163699, "train/prior_ent_mag": 67.12528393422957, "train/prior_ent_max": 67.12528393422957, "train/prior_ent_mean": 55.026065057987786, "train/prior_ent_min": 40.15606988591256, "train/prior_ent_std": 4.542849840877725, "train/rep_loss_mean": 13.288485726006597, "train/rep_loss_std": 8.84842056507687, "train/reward_avg": 0.02996079664570179, "train/reward_loss_mean": 0.05772680414023159, "train/reward_loss_std": 0.25119003192555134, "train/reward_max_data": 1.015827341903028, "train/reward_max_pred": 1.0134168828991676, "train/reward_neg_acc": 0.993115098356343, "train/reward_neg_loss": 0.030407026711610153, "train/reward_pos_acc": 0.9711762679566582, "train/reward_pos_loss": 0.8200206254883636, "train/reward_pred": 0.029394094758539747, "train/reward_rate": 0.034650404676258996, "eval_stats/sum_log_reward": 7.7250001927216845, "eval_stats/max_log_achievement_collect_coal": 0.3333333333333333, "eval_stats/max_log_achievement_collect_drink": 4.916666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.0833333333333335, "eval_stats/max_log_achievement_collect_stone": 1.9166666666666667, "eval_stats/max_log_achievement_collect_wood": 10.666666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1666666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.346842282146099e-06, "report/cont_loss_std": 2.3539130779681727e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023342008353210986, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0811195611258881e-07, "report/cont_pred": 0.9951181411743164, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.102577209472656, "report/dyn_loss_std": 8.571429252624512, "report/image_loss_mean": 5.7164835929870605, "report/image_loss_std": 10.786690711975098, "report/model_loss_mean": 13.639501571655273, "report/model_loss_std": 14.557234764099121, "report/post_ent_mag": 56.735015869140625, "report/post_ent_max": 56.735015869140625, "report/post_ent_mean": 41.51991271972656, "report/post_ent_min": 20.536792755126953, "report/post_ent_std": 6.535629749298096, "report/prior_ent_mag": 66.8759536743164, "report/prior_ent_max": 66.8759536743164, "report/prior_ent_mean": 54.83613967895508, "report/prior_ent_min": 39.812225341796875, "report/prior_ent_std": 4.930294036865234, "report/rep_loss_mean": 13.102577209472656, "report/rep_loss_std": 8.571429252624512, "report/reward_avg": 0.03759765625, "report/reward_loss_mean": 0.06147082895040512, "report/reward_loss_std": 0.24219553172588348, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020592212677002, "report/reward_neg_acc": 0.9877675175666809, "report/reward_neg_loss": 0.0322805680334568, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7274160385131836, "report/reward_pred": 0.03752235695719719, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0020840794313699007, "eval/cont_loss_std": 0.06412916630506516, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.4105810821056366, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.967828423716128e-05, "eval/cont_pred": 0.9958932995796204, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.552947998046875, "eval/dyn_loss_std": 10.325140953063965, "eval/image_loss_mean": 13.357133865356445, "eval/image_loss_std": 19.671279907226562, "eval/model_loss_mean": 23.391826629638672, "eval/model_loss_std": 23.394916534423828, "eval/post_ent_mag": 58.713768005371094, "eval/post_ent_max": 58.713768005371094, "eval/post_ent_mean": 40.669166564941406, "eval/post_ent_min": 20.154605865478516, "eval/post_ent_std": 7.503320217132568, "eval/prior_ent_mag": 66.8759536743164, "eval/prior_ent_max": 66.8759536743164, "eval/prior_ent_mean": 54.90715789794922, "eval/prior_ent_min": 38.3410758972168, "eval/prior_ent_std": 4.680014610290527, "eval/rep_loss_mean": 16.552947998046875, "eval/rep_loss_std": 10.325140953063965, "eval/reward_avg": 0.02783203125, "eval/reward_loss_mean": 0.10083957761526108, "eval/reward_loss_std": 0.579266369342804, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0007543563842773, "eval/reward_neg_acc": 0.9909090399742126, "eval/reward_neg_loss": 0.04015791788697243, "eval/reward_pos_acc": 0.7941176295280457, "eval/reward_pos_loss": 1.8677465915679932, "eval/reward_pred": 0.021629096940159798, "eval/reward_rate": 0.033203125, "replay/size": 619545.0, "replay/inserts": 22232.0, "replay/samples": 22224.0, "replay/insert_wait_avg": 1.4763678008165665e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.496084128119604e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6520.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2534893363531382e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1029.1790931224823, "timer/env.step_count": 2779.0, "timer/env.step_total": 238.7813365459442, "timer/env.step_frac": 0.23201145276036705, "timer/env.step_avg": 0.08592347482761577, "timer/env.step_min": 0.023286819458007812, "timer/env.step_max": 3.3941307067871094, "timer/replay._sample_count": 22224.0, "timer/replay._sample_total": 11.266978740692139, "timer/replay._sample_frac": 0.010947539467119023, "timer/replay._sample_avg": 0.00050697348545231, "timer/replay._sample_min": 0.0004172325134277344, "timer/replay._sample_max": 0.009609460830688477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3594.0, "timer/agent.policy_total": 60.65994191169739, "timer/agent.policy_frac": 0.058940122586106855, "timer/agent.policy_avg": 0.016878114054451138, "timer/agent.policy_min": 0.009587526321411133, "timer/agent.policy_max": 0.12957978248596191, "timer/dataset_train_count": 1389.0, "timer/dataset_train_total": 0.14948296546936035, "timer/dataset_train_frac": 0.00014524485239574375, "timer/dataset_train_avg": 0.00010761912560789082, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0007197856903076172, "timer/agent.train_count": 1389.0, "timer/agent.train_total": 625.7860839366913, "timer/agent.train_frac": 0.6080439139490144, "timer/agent.train_avg": 0.4505299380393746, "timer/agent.train_min": 0.4360833168029785, "timer/agent.train_max": 2.05129337310791, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47635769844055176, "timer/agent.report_frac": 0.00046285209408530084, "timer/agent.report_avg": 0.23817884922027588, "timer/agent.report_min": 0.23043131828308105, "timer/agent.report_max": 0.2459263801574707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.1968939260312e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.60139528127708}
{"step": 620128, "time": 28465.573236703873, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 620352, "time": 28474.587186574936, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9688715953307393, "episode/intrinsic_return": 0.0}
{"step": 620560, "time": 28483.178583860397, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 620832, "time": 28493.86931347847, "episode/length": 241.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 620864, "time": 28496.530843496323, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 620896, "time": 28499.282266378403, "episode/length": 142.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 621032, "time": 28505.241028785706, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 621992, "time": 28538.882766723633, "episode/length": 232.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 622056, "time": 28542.621118068695, "episode/length": 266.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 622360, "time": 28554.389184236526, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 622376, "time": 28556.52933049202, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 622472, "time": 28561.211703300476, "episode/length": 200.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 622656, "time": 28570.773630142212, "episode/length": 82.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 623296, "time": 28593.7032995224, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 623664, "time": 28607.62980389595, "episode/length": 148.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 623872, "time": 28616.124575853348, "episode/length": 354.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9830985915492958, "episode/intrinsic_return": 0.0}
{"step": 623952, "time": 28620.317580461502, "episode/length": 449.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 623952, "time": 28620.351633548737, "episode/length": 381.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9869109947643979, "episode/intrinsic_return": 0.0}
{"step": 623984, "time": 28624.697035312653, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 624432, "time": 28641.22788953781, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 625096, "time": 28664.783383846283, "episode/length": 341.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 625320, "time": 28673.77053976059, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 625488, "time": 28681.116632699966, "episode/length": 273.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 625552, "time": 28684.929263353348, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 625704, "time": 28691.5220682621, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 625792, "time": 28696.173314094543, "episode/length": 239.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 626624, "time": 28725.586602687836, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.0}
{"step": 626640, "time": 28727.743624210358, "episode/length": 331.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 626648, "time": 28729.42727637291, "episode/length": 165.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 626688, "time": 28732.638355970383, "episode/length": 149.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 626792, "time": 28737.456573963165, "episode/length": 154.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 626904, "time": 28742.626150608063, "episode/length": 308.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 627296, "time": 28757.608156204224, "episode/length": 187.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 627904, "time": 28779.62522673607, "episode/length": 157.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 628072, "time": 28786.641869306564, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 628104, "time": 28789.40984773636, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 628520, "time": 28804.93800830841, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 628520, "time": 28804.94699907303, "episode/length": 201.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 628672, "time": 28813.74463415146, "episode/length": 247.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 628728, "time": 28816.974304676056, "episode/length": 241.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 629544, "time": 28845.94016122818, "episode/length": 108.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 28879.81268310547, "eval_episode/length": 61.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 630032, "time": 28885.243151187897, "eval_episode/length": 152.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 630032, "time": 28888.637994766235, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 630032, "time": 28890.95953464508, "eval_episode/length": 149.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 630032, "time": 28892.588868141174, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9674418604651163}
{"step": 630032, "time": 28894.901461839676, "eval_episode/length": 231.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 630032, "time": 28897.233758211136, "eval_episode/length": 247.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 630032, "time": 28900.440645694733, "eval_episode/length": 282.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9964664310954063}
{"step": 630096, "time": 28902.60400533676, "episode/length": 252.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 630120, "time": 28904.748653411865, "episode/length": 251.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 630256, "time": 28911.089965343475, "episode/length": 369.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9972972972972973, "episode/intrinsic_return": 0.0}
{"step": 630344, "time": 28915.33184981346, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 630504, "time": 28922.307822942734, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 630672, "time": 28929.70895266533, "episode/length": 268.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 630824, "time": 28937.773727416992, "episode/length": 287.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 630856, "time": 28940.35207915306, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 631648, "time": 28968.85322356224, "episode/length": 162.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 631680, "time": 28971.486011981964, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 631752, "time": 28975.187126636505, "episode/length": 155.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 631872, "time": 28981.003561258316, "episode/length": 130.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 632320, "time": 28997.56015110016, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 632360, "time": 29000.29279732704, "episode/length": 187.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 632696, "time": 29013.237604141235, "episode/length": 321.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 633104, "time": 29028.780998945236, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 633336, "time": 29037.950633764267, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 633344, "time": 29039.905905008316, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 633408, "time": 29043.611616134644, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 633792, "time": 29058.13324213028, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 633832, "time": 29060.818503141403, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 634224, "time": 29075.807455301285, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 634880, "time": 29099.639801979065, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 635008, "time": 29105.49903345108, "episode/length": 237.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 635104, "time": 29110.42786860466, "episode/length": 220.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 635272, "time": 29117.38211250305, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 635272, "time": 29117.391718626022, "episode/length": 232.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9871244635193133, "episode/intrinsic_return": 0.0}
{"step": 635760, "time": 29137.106600522995, "episode/length": 382.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9765013054830287, "episode/intrinsic_return": 0.0}
{"step": 636232, "time": 29154.653933286667, "episode/length": 140.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 636464, "time": 29164.613761901855, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 636840, "time": 29178.666110277176, "episode/length": 375.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 636888, "time": 29181.805197238922, "episode/length": 332.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.987987987987988, "episode/intrinsic_return": 0.0}
{"step": 636960, "time": 29185.96085047722, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 636968, "time": 29187.61665892601, "episode/length": 91.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 637024, "time": 29191.25498843193, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 637136, "time": 29196.510901927948, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 637384, "time": 29206.27412056923, "episode/length": 263.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 637904, "time": 29225.419313192368, "episode/length": 117.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 638608, "time": 29251.011275053024, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 638624, "time": 29253.074246168137, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 638720, "time": 29257.973831892014, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 638864, "time": 29264.432122707367, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 639032, "time": 29272.997539281845, "episode/length": 320.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 639336, "time": 29284.696340322495, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 639408, "time": 29288.927849769592, "episode/length": 297.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 639840, "time": 29304.80175304413, "episode/length": 151.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 29332.86050081253, "eval_episode/length": 173.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 640016, "time": 29334.83635878563, "eval_episode/length": 181.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9835164835164835}
{"step": 640016, "time": 29336.812178850174, "eval_episode/length": 189.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 640016, "time": 29338.65951538086, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 640016, "time": 29341.188990831375, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 640016, "time": 29342.965569972992, "eval_episode/length": 223.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 640016, "time": 29345.23257446289, "eval_episode/length": 239.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 640016, "time": 29349.02537727356, "eval_episode/length": 288.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9792387543252595}
{"step": 640256, "time": 29357.02708339691, "episode/length": 191.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 640296, "time": 29359.774034500122, "episode/length": 431.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 640376, "time": 29363.99058008194, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 640592, "time": 29372.95926117897, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 640632, "time": 29375.617337942123, "episode/length": 46.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 640976, "time": 29389.040435791016, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 641152, "time": 29396.6142513752, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 641176, "time": 29398.8541867733, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 641536, "time": 29412.73812532425, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 641944, "time": 29427.848183870316, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 642048, "time": 29433.13829612732, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 642336, "time": 29444.491462945938, "episode/length": 169.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 642512, "time": 29452.07708311081, "episode/length": 487.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9979508196721312, "episode/intrinsic_return": 0.0}
{"step": 642761, "time": 29462.739916801453, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.210834341989437, "train/action_min": 0.0, "train/action_std": 3.2947598443904393, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04233312048017979, "train/actor_opt_grad_steps": 39365.0, "train/actor_opt_loss": -3.39313548451788, "train/adv_mag": 0.5287628136050533, "train/adv_max": 0.47701085873053106, "train/adv_mean": 0.003369022736901378, "train/adv_min": -0.43434178115616384, "train/adv_std": 0.05976901179782941, "train/cont_avg": 0.9949590118838029, "train/cont_loss_mean": 0.00021144387397578038, "train/cont_loss_std": 0.006153940890673676, "train/cont_neg_acc": 0.9926038515483234, "train/cont_neg_loss": 0.015314260722689207, "train/cont_pos_acc": 0.9999723291732896, "train/cont_pos_loss": 0.0001268396714523795, "train/cont_pred": 0.9949516259448629, "train/cont_rate": 0.9949590118838029, "train/dyn_loss_mean": 13.24284417192701, "train/dyn_loss_std": 8.854244682150828, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8497568247183948, "train/extr_critic_critic_opt_grad_steps": 39365.0, "train/extr_critic_critic_opt_loss": 15526.823207801497, "train/extr_critic_mag": 7.986559249985386, "train/extr_critic_max": 7.986559249985386, "train/extr_critic_mean": 2.5772403394672234, "train/extr_critic_min": -0.14474517526760908, "train/extr_critic_std": 1.7737628036821391, "train/extr_return_normed_mag": 1.5631250092681026, "train/extr_return_normed_max": 1.5631250092681026, "train/extr_return_normed_mean": 0.39853619836585624, "train/extr_return_normed_min": -0.13377770466703764, "train/extr_return_normed_std": 0.31822273985181054, "train/extr_return_rate": 0.8899189863406437, "train/extr_return_raw_mag": 9.22241169298199, "train/extr_return_raw_max": 9.22241169298199, "train/extr_return_raw_mean": 2.5963964747710966, "train/extr_return_raw_min": -0.4319916511295547, "train/extr_return_raw_std": 1.8104667075922791, "train/extr_reward_mag": 1.0372608429949048, "train/extr_reward_max": 1.0372608429949048, "train/extr_reward_mean": 0.04220594972057242, "train/extr_reward_min": -0.39869653507017755, "train/extr_reward_std": 0.1914314434561931, "train/image_loss_mean": 6.539258607676332, "train/image_loss_std": 11.123612145303001, "train/model_loss_mean": 14.5416164666834, "train/model_loss_std": 14.773803731085549, "train/model_opt_grad_norm": 56.64095896062717, "train/model_opt_grad_steps": 39329.528169014084, "train/model_opt_loss": 18802.13193909551, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.0140845070423, "train/policy_entropy_mag": 2.3404731028516528, "train/policy_entropy_max": 2.3404731028516528, "train/policy_entropy_mean": 0.5034351055051239, "train/policy_entropy_min": 0.07937513848005885, "train/policy_entropy_std": 0.5312347705935089, "train/policy_logprob_mag": 7.438383515451996, "train/policy_logprob_max": -0.009455700877161933, "train/policy_logprob_mean": -0.5023321819977021, "train/policy_logprob_min": -7.438383515451996, "train/policy_logprob_std": 1.0460085566614714, "train/policy_randomness_mag": 0.826084295628776, "train/policy_randomness_max": 0.826084295628776, "train/policy_randomness_mean": 0.1776905004197443, "train/policy_randomness_min": 0.028015940633772964, "train/policy_randomness_std": 0.1875025621602233, "train/post_ent_mag": 58.10205709430534, "train/post_ent_max": 58.10205709430534, "train/post_ent_mean": 41.82594267079528, "train/post_ent_min": 19.961822241124974, "train/post_ent_std": 7.318319256876556, "train/prior_ent_mag": 67.27391294022681, "train/prior_ent_max": 67.27391294022681, "train/prior_ent_mean": 55.17897544108646, "train/prior_ent_min": 40.07960014611903, "train/prior_ent_std": 4.49560671625003, "train/rep_loss_mean": 13.24284417192701, "train/rep_loss_std": 8.854244682150828, "train/reward_avg": 0.028695119630125627, "train/reward_loss_mean": 0.05643986572157329, "train/reward_loss_std": 0.25156020509525084, "train/reward_max_data": 1.015492961440288, "train/reward_max_pred": 1.0136350208604838, "train/reward_neg_acc": 0.9931513352293364, "train/reward_neg_loss": 0.029574730472875312, "train/reward_pos_acc": 0.9684211746068068, "train/reward_pos_loss": 0.8371742325769344, "train/reward_pred": 0.02782746085005117, "train/reward_rate": 0.03329252860915493, "train_stats/sum_log_reward": 8.540000214576722, "train_stats/max_log_achievement_collect_coal": 0.31, "train_stats/max_log_achievement_collect_drink": 4.32, "train_stats/max_log_achievement_collect_sapling": 2.07, "train_stats/max_log_achievement_collect_stone": 4.02, "train_stats/max_log_achievement_collect_wood": 12.98, "train_stats/max_log_achievement_defeat_skeleton": 0.04, "train_stats/max_log_achievement_defeat_zombie": 0.99, "train_stats/max_log_achievement_eat_cow": 0.16, "train_stats/max_log_achievement_eat_plant": 0.01, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.68, "train_stats/max_log_achievement_make_wood_sword": 1.65, "train_stats/max_log_achievement_place_furnace": 0.05, "train_stats/max_log_achievement_place_plant": 2.01, "train_stats/max_log_achievement_place_stone": 0.15, "train_stats/max_log_achievement_place_table": 3.9, "train_stats/max_log_achievement_wake_up": 1.44, "train_stats/mean_log_entropy": 0.5442432683706283, "eval_stats/sum_log_reward": 8.475000232458115, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 2.625, "eval_stats/max_log_achievement_collect_wood": 13.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 1.4375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.6875, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.3573896467278246e-05, "report/cont_loss_std": 0.00019236090884078294, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001605423865839839, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0396445304650115e-06, "report/cont_pred": 0.9921990633010864, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.627233505249023, "report/dyn_loss_std": 8.766836166381836, "report/image_loss_mean": 6.107542037963867, "report/image_loss_std": 13.20016860961914, "report/model_loss_mean": 13.7478609085083, "report/model_loss_std": 16.464942932128906, "report/post_ent_mag": 58.659027099609375, "report/post_ent_max": 58.659027099609375, "report/post_ent_mean": 42.47250747680664, "report/post_ent_min": 21.130584716796875, "report/post_ent_std": 7.418437480926514, "report/prior_ent_mag": 67.1574478149414, "report/prior_ent_max": 67.1574478149414, "report/prior_ent_mean": 55.4494514465332, "report/prior_ent_min": 39.452266693115234, "report/prior_ent_std": 4.3358893394470215, "report/rep_loss_mean": 12.627233505249023, "report/rep_loss_std": 8.766836166381836, "report/reward_avg": 0.03007812425494194, "report/reward_loss_mean": 0.06396585702896118, "report/reward_loss_std": 0.23433838784694672, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006067752838135, "report/reward_neg_acc": 0.9858300089836121, "report/reward_neg_loss": 0.038561902940273285, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.7611632943153381, "report/reward_pred": 0.03026309795677662, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.001563211902976036, "eval/cont_loss_std": 0.049769479781389236, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.26672348380088806, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.812608326825284e-07, "eval/cont_pred": 0.9949252605438232, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.61313247680664, "eval/dyn_loss_std": 9.627433776855469, "eval/image_loss_mean": 9.608746528625488, "eval/image_loss_std": 12.779837608337402, "eval/model_loss_mean": 19.694072723388672, "eval/model_loss_std": 16.424468994140625, "eval/post_ent_mag": 55.74554443359375, "eval/post_ent_max": 55.74554443359375, "eval/post_ent_mean": 40.79024124145508, "eval/post_ent_min": 19.797134399414062, "eval/post_ent_std": 6.991483211517334, "eval/prior_ent_mag": 67.1574478149414, "eval/prior_ent_max": 67.1574478149414, "eval/prior_ent_mean": 55.210411071777344, "eval/prior_ent_min": 41.831138610839844, "eval/prior_ent_std": 3.594165325164795, "eval/rep_loss_mean": 16.61313247680664, "eval/rep_loss_std": 9.627433776855469, "eval/reward_avg": 0.03847656399011612, "eval/reward_loss_mean": 0.11588480323553085, "eval/reward_loss_std": 0.6410263180732727, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011703968048096, "eval/reward_neg_acc": 0.9897958636283875, "eval/reward_neg_loss": 0.04575398936867714, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.6778894662857056, "eval/reward_pred": 0.03289064019918442, "eval/reward_rate": 0.04296875, "replay/size": 642257.0, "replay/inserts": 22712.0, "replay/samples": 22720.0, "replay/insert_wait_avg": 1.4452604224623908e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.735915022836605e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.224031398346374e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0929915904999, "timer/env.step_count": 2839.0, "timer/env.step_total": 235.9767096042633, "timer/env.step_frac": 0.23595476779512, "timer/env.step_avg": 0.08311965819100504, "timer/env.step_min": 0.023143291473388672, "timer/env.step_max": 3.544431447982788, "timer/replay._sample_count": 22720.0, "timer/replay._sample_total": 11.509856224060059, "timer/replay._sample_frac": 0.011508786003744848, "timer/replay._sample_avg": 0.0005065957845096857, "timer/replay._sample_min": 0.0003921985626220703, "timer/replay._sample_max": 0.009610891342163086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3411.0, "timer/agent.policy_total": 56.116787910461426, "timer/agent.policy_frac": 0.056111570006321096, "timer/agent.policy_avg": 0.016451711495297984, "timer/agent.policy_min": 0.009232759475708008, "timer/agent.policy_max": 0.11490154266357422, "timer/dataset_train_count": 1420.0, "timer/dataset_train_total": 0.15166926383972168, "timer/dataset_train_frac": 0.00015165516118507557, "timer/dataset_train_avg": 0.00010680934073219837, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0009171962738037109, "timer/agent.train_count": 1420.0, "timer/agent.train_total": 639.248354434967, "timer/agent.train_frac": 0.6391889152411089, "timer/agent.train_avg": 0.4501748974894134, "timer/agent.train_min": 0.4363281726837158, "timer/agent.train_max": 1.7205495834350586, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47205114364624023, "timer/agent.report_frac": 0.00047200725094124774, "timer/agent.report_avg": 0.23602557182312012, "timer/agent.report_min": 0.22947192192077637, "timer/agent.report_max": 0.24257922172546387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.838182204867297e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 22.70957736042928}
{"step": 642856, "time": 29465.757608652115, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 642944, "time": 29470.47446322441, "episode/length": 223.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 643512, "time": 29490.7113802433, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 643640, "time": 29496.665983438492, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 643960, "time": 29509.128455400467, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 644040, "time": 29513.243621826172, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 644304, "time": 29523.85155916214, "episode/length": 458.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9978213507625272, "episode/intrinsic_return": 0.0}
{"step": 644328, "time": 29525.96593618393, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 644336, "time": 29527.970999479294, "episode/length": 227.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 644600, "time": 29538.21045732498, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 644768, "time": 29545.556669712067, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 645208, "time": 29561.518716096878, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 645272, "time": 29565.265399694443, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 645904, "time": 29588.287354707718, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 645936, "time": 29590.9977478981, "episode/length": 200.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 646000, "time": 29594.70263981819, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 646216, "time": 29603.37900686264, "episode/length": 234.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 647096, "time": 29634.346167087555, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 647096, "time": 29634.356904029846, "episode/length": 235.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 647136, "time": 29639.15007710457, "episode/length": 295.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 647328, "time": 29648.608765363693, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 647360, "time": 29651.29547572136, "episode/length": 344.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 647416, "time": 29654.542810678482, "episode/length": 188.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 647488, "time": 29658.88201379776, "episode/length": 158.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 647584, "time": 29663.576427698135, "episode/length": 60.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 647856, "time": 29674.237438201904, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 648320, "time": 29691.30545592308, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.0}
{"step": 648552, "time": 29700.480261325836, "episode/length": 132.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 648752, "time": 29709.04514336586, "episode/length": 201.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 648840, "time": 29713.250834465027, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 648896, "time": 29716.98114514351, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 649408, "time": 29735.483848571777, "episode/length": 425.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 649736, "time": 29747.830738544464, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 649752, "time": 29749.879258155823, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 649792, "time": 29752.947739362717, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 29776.090529680252, "eval_episode/length": 36.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.972972972972973}
{"step": 650000, "time": 29778.040407657623, "eval_episode/length": 43.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 650000, "time": 29784.756860494614, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9585798816568047}
{"step": 650000, "time": 29786.482472658157, "eval_episode/length": 176.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 650000, "time": 29789.32113623619, "eval_episode/length": 203.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 650000, "time": 29791.380056142807, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 650000, "time": 29793.880470752716, "eval_episode/length": 224.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 650000, "time": 29796.0396797657, "eval_episode/length": 182.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 650024, "time": 29796.650619506836, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 650480, "time": 29814.282436847687, "episode/length": 197.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 650504, "time": 29816.47235274315, "episode/length": 207.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 650576, "time": 29820.765585660934, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 650824, "time": 29830.30400466919, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 651184, "time": 29844.049762010574, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 651768, "time": 29865.04081439972, "episode/length": 253.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 651880, "time": 29870.361660957336, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 651912, "time": 29872.991567611694, "episode/length": 135.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 652040, "time": 29878.827768325806, "episode/length": 182.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 652192, "time": 29885.71953511238, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 652408, "time": 29894.460938453674, "episode/length": 326.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.0}
{"step": 652736, "time": 29907.152962446213, "episode/length": 281.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 653160, "time": 29922.80478286743, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 653648, "time": 29941.014613866806, "episode/length": 234.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 653800, "time": 29947.46553850174, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 653824, "time": 29950.332513332367, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 653888, "time": 29953.962582349777, "episode/length": 230.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 654632, "time": 29980.23688697815, "episode/length": 304.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 654944, "time": 29992.393372297287, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 655064, "time": 29997.756178617477, "episode/length": 154.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 655216, "time": 30004.593726158142, "episode/length": 309.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 655224, "time": 30006.270894765854, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 655400, "time": 30015.238313913345, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 655888, "time": 30033.193075180054, "episode/length": 60.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 655896, "time": 30034.805776119232, "episode/length": 435.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 656024, "time": 30040.796712636948, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 656168, "time": 30047.134670734406, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 656208, "time": 30050.174658298492, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 656416, "time": 30058.77079963684, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 656688, "time": 30069.46651005745, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 657312, "time": 30091.81807088852, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 657560, "time": 30101.56178164482, "episode/length": 191.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 657864, "time": 30113.21749520302, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 657928, "time": 30116.897268533707, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 657952, "time": 30119.587431907654, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 657984, "time": 30122.354224681854, "episode/length": 261.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 658336, "time": 30135.74258375168, "episode/length": 389.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 659040, "time": 30160.973987579346, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 659456, "time": 30176.421527147293, "episode/length": 187.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 659616, "time": 30183.286715984344, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 659872, "time": 30193.40887117386, "episode/length": 288.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 659976, "time": 30198.170929193497, "episode/length": 410.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9878345498783455, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 30221.180267095566, "eval_episode/length": 108.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 660088, "time": 30225.877853631973, "eval_episode/length": 167.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 660088, "time": 30229.383605480194, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 660088, "time": 30231.502489566803, "eval_episode/length": 192.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 660088, "time": 30233.70471215248, "eval_episode/length": 194.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 660088, "time": 30236.481028795242, "eval_episode/length": 213.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 660088, "time": 30238.967123270035, "eval_episode/length": 234.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 660088, "time": 30241.92688727379, "eval_episode/length": 258.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9768339768339769}
{"step": 660272, "time": 30248.51693034172, "episode/length": 153.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 660440, "time": 30255.451321840286, "episode/length": 313.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 660888, "time": 30271.783453464508, "episode/length": 318.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 661424, "time": 30291.322221279144, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 661552, "time": 30297.24976658821, "episode/length": 460.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9956616052060737, "episode/intrinsic_return": 0.0}
{"step": 661888, "time": 30309.954225063324, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 661944, "time": 30313.067353725433, "episode/length": 245.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 662216, "time": 30323.664818763733, "episode/length": 292.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 662504, "time": 30334.78264093399, "episode/length": 201.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 662728, "time": 30343.89419054985, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 662904, "time": 30351.23183965683, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 663072, "time": 30358.82734799385, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 663312, "time": 30368.487549304962, "episode/length": 170.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 663424, "time": 30373.739104747772, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 663760, "time": 30387.942717313766, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 663976, "time": 30396.40547990799, "episode/length": 318.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 664232, "time": 30406.56770825386, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 664328, "time": 30411.320120811462, "episode/length": 227.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 664984, "time": 30434.914900779724, "episode/length": 259.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 665152, "time": 30442.331645727158, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 665344, "time": 30450.17815065384, "episode/length": 170.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 665424, "time": 30454.533700942993, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 665552, "time": 30460.47161912918, "episode/length": 265.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 665561, "time": 30462.959114551544, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.154857288707387, "train/action_min": 0.0, "train/action_std": 3.3215536537703936, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04191343215378848, "train/actor_opt_grad_steps": 40790.0, "train/actor_opt_loss": -2.5875607081851757, "train/adv_mag": 0.5251339269684745, "train/adv_max": 0.4865780139302874, "train/adv_mean": 0.003437106751442917, "train/adv_min": -0.4320868255791964, "train/adv_std": 0.05952617044111232, "train/cont_avg": 0.9947552447552448, "train/cont_loss_mean": 0.0003133854512529947, "train/cont_loss_std": 0.009670615545601195, "train/cont_neg_acc": 0.992949364051013, "train/cont_neg_loss": 0.03834457496890549, "train/cont_pos_acc": 0.9999862234075586, "train/cont_pos_loss": 8.930689371082907e-05, "train/cont_pred": 0.9947745529088107, "train/cont_rate": 0.9947552447552448, "train/dyn_loss_mean": 13.17447629675165, "train/dyn_loss_std": 8.856046423211797, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8136951752475925, "train/extr_critic_critic_opt_grad_steps": 40790.0, "train/extr_critic_critic_opt_loss": 15348.63595388986, "train/extr_critic_mag": 8.065019160717517, "train/extr_critic_max": 8.065019160717517, "train/extr_critic_mean": 2.6651187126453104, "train/extr_critic_min": -0.13585589899049771, "train/extr_critic_std": 1.8213639667817763, "train/extr_return_normed_mag": 1.543311947709197, "train/extr_return_normed_max": 1.543311947709197, "train/extr_return_normed_mean": 0.39798369566043773, "train/extr_return_normed_min": -0.15145344044882936, "train/extr_return_normed_std": 0.32243074612184003, "train/extr_return_rate": 0.9051241520401481, "train/extr_return_raw_mag": 9.274795082065609, "train/extr_return_raw_max": 9.274795082065609, "train/extr_return_raw_mean": 2.6848947860144237, "train/extr_return_raw_min": -0.47635618164822774, "train/extr_return_raw_std": 1.8551816048322025, "train/extr_reward_mag": 1.0320815956675924, "train/extr_reward_max": 1.0320815956675924, "train/extr_reward_mean": 0.04452083489069572, "train/extr_reward_min": -0.4283861755491137, "train/extr_reward_std": 0.1968964239308884, "train/image_loss_mean": 6.6375953567611585, "train/image_loss_std": 11.534537181987629, "train/model_loss_mean": 14.598588296583483, "train/model_loss_std": 15.144925791066843, "train/model_opt_grad_norm": 58.23367727052916, "train/model_opt_grad_steps": 40752.643356643355, "train/model_opt_loss": 13008.662331321022, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 891.6083916083916, "train/policy_entropy_mag": 2.326068924857186, "train/policy_entropy_max": 2.326068924857186, "train/policy_entropy_mean": 0.5105937702672465, "train/policy_entropy_min": 0.07937513917059331, "train/policy_entropy_std": 0.5272192288111973, "train/policy_logprob_mag": 7.438383605930355, "train/policy_logprob_max": -0.009455697265798813, "train/policy_logprob_mean": -0.5103563835154047, "train/policy_logprob_min": -7.438383605930355, "train/policy_logprob_std": 1.0571174709113327, "train/policy_randomness_mag": 0.8210002542375685, "train/policy_randomness_max": 0.8210002542375685, "train/policy_randomness_mean": 0.18021719470307543, "train/policy_randomness_min": 0.028015940795307392, "train/policy_randomness_std": 0.1860852527034866, "train/post_ent_mag": 58.197354083294634, "train/post_ent_max": 58.197354083294634, "train/post_ent_mean": 41.85346472680152, "train/post_ent_min": 20.197231599500963, "train/post_ent_std": 7.27387417279757, "train/prior_ent_mag": 67.29913810249809, "train/prior_ent_max": 67.29913810249809, "train/prior_ent_mean": 55.11435427365603, "train/prior_ent_min": 40.60413256558505, "train/prior_ent_std": 4.500858685353419, "train/rep_loss_mean": 13.17447629675165, "train/rep_loss_std": 8.856046423211797, "train/reward_avg": 0.029619891717508957, "train/reward_loss_mean": 0.05599390931583784, "train/reward_loss_std": 0.24471737684069814, "train/reward_max_data": 1.0174825216506744, "train/reward_max_pred": 1.0120351414580446, "train/reward_neg_acc": 0.993220763606625, "train/reward_neg_loss": 0.028928413941570513, "train/reward_pos_acc": 0.968778142979095, "train/reward_pos_loss": 0.8269825031707337, "train/reward_pred": 0.02897537218315618, "train/reward_rate": 0.034227491258741256, "train_stats/sum_log_reward": 8.89207940054412, "train_stats/max_log_achievement_collect_coal": 0.3564356435643564, "train_stats/max_log_achievement_collect_drink": 4.287128712871287, "train_stats/max_log_achievement_collect_sapling": 1.900990099009901, "train_stats/max_log_achievement_collect_stone": 4.891089108910891, "train_stats/max_log_achievement_collect_wood": 12.158415841584159, "train_stats/max_log_achievement_defeat_skeleton": 0.04950495049504951, "train_stats/max_log_achievement_defeat_zombie": 1.0, "train_stats/max_log_achievement_eat_cow": 0.19801980198019803, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.019801980198019802, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5445544554455446, "train_stats/max_log_achievement_make_wood_sword": 1.4851485148514851, "train_stats/max_log_achievement_place_furnace": 0.1188118811881188, "train_stats/max_log_achievement_place_plant": 1.7722772277227723, "train_stats/max_log_achievement_place_stone": 0.8712871287128713, "train_stats/max_log_achievement_place_table": 3.623762376237624, "train_stats/max_log_achievement_wake_up": 1.386138613861386, "train_stats/mean_log_entropy": 0.5499652447086749, "eval_stats/sum_log_reward": 8.10000029951334, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 4.4375, "eval_stats/max_log_achievement_collect_wood": 11.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.3125, "eval_stats/max_log_achievement_place_table": 3.1875, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_iron": 0.125, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.710586719942512e-06, "report/cont_loss_std": 6.137413583928719e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.0093549867160618e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.518595116882352e-06, "report/cont_pred": 0.9921822547912598, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.00285530090332, "report/dyn_loss_std": 8.563492774963379, "report/image_loss_mean": 4.812734127044678, "report/image_loss_std": 10.529275894165039, "report/model_loss_mean": 12.066463470458984, "report/model_loss_std": 13.830814361572266, "report/post_ent_mag": 59.32563018798828, "report/post_ent_max": 59.32563018798828, "report/post_ent_mean": 41.9572639465332, "report/post_ent_min": 20.400798797607422, "report/post_ent_std": 7.3158087730407715, "report/prior_ent_mag": 67.38490295410156, "report/prior_ent_max": 67.38490295410156, "report/prior_ent_mean": 54.5914306640625, "report/prior_ent_min": 41.52044677734375, "report/prior_ent_std": 4.202394962310791, "report/rep_loss_mean": 12.00285530090332, "report/rep_loss_std": 8.563492774963379, "report/reward_avg": 0.03515625, "report/reward_loss_mean": 0.05201008915901184, "report/reward_loss_std": 0.18414081633090973, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022964477539062, "report/reward_neg_acc": 0.9969450831413269, "report/reward_neg_loss": 0.025324393063783646, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6759471297264099, "report/reward_pred": 0.03624007850885391, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.0607929652906023e-05, "eval/cont_loss_std": 0.000282013468677178, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.223379851784557e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0585178642941173e-05, "eval/cont_pred": 0.9980363845825195, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.18952178955078, "eval/dyn_loss_std": 10.507513999938965, "eval/image_loss_mean": 11.622700691223145, "eval/image_loss_std": 16.829763412475586, "eval/model_loss_mean": 22.626968383789062, "eval/model_loss_std": 20.59299087524414, "eval/post_ent_mag": 54.337860107421875, "eval/post_ent_max": 54.337860107421875, "eval/post_ent_mean": 39.3408203125, "eval/post_ent_min": 19.56656265258789, "eval/post_ent_std": 7.044205665588379, "eval/prior_ent_mag": 67.38490295410156, "eval/prior_ent_max": 67.38490295410156, "eval/prior_ent_mean": 55.10716247558594, "eval/prior_ent_min": 41.205848693847656, "eval/prior_ent_std": 4.069267749786377, "eval/rep_loss_mean": 18.18952178955078, "eval/rep_loss_std": 10.507513999938965, "eval/reward_avg": 0.04238281399011612, "eval/reward_loss_mean": 0.09054361283779144, "eval/reward_loss_std": 0.5584895610809326, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004152774810791, "eval/reward_neg_acc": 0.9908069968223572, "eval/reward_neg_loss": 0.030317356809973717, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.4007993936538696, "eval/reward_pred": 0.04009808972477913, "eval/reward_rate": 0.0439453125, "replay/size": 665057.0, "replay/inserts": 22800.0, "replay/samples": 22800.0, "replay/insert_wait_avg": 1.4534122065493936e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.62468615749426e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2356312677202892e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2103562355042, "timer/env.step_count": 2850.0, "timer/env.step_total": 237.28438210487366, "timer/env.step_frac": 0.2372344783530755, "timer/env.step_avg": 0.08325767793153462, "timer/env.step_min": 0.023286819458007812, "timer/env.step_max": 3.2690227031707764, "timer/replay._sample_count": 22800.0, "timer/replay._sample_total": 11.536717891693115, "timer/replay._sample_frac": 0.011534291581536816, "timer/replay._sample_avg": 0.0005059963987584699, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.010942459106445312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3336.0, "timer/agent.policy_total": 55.473087787628174, "timer/agent.policy_frac": 0.05546142113186316, "timer/agent.policy_avg": 0.01662862343753842, "timer/agent.policy_min": 0.009479761123657227, "timer/agent.policy_max": 0.12117791175842285, "timer/dataset_train_count": 1425.0, "timer/dataset_train_total": 0.15382933616638184, "timer/dataset_train_frac": 0.00015379698401179323, "timer/dataset_train_avg": 0.00010795041134482935, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0002040863037109375, "timer/agent.train_count": 1425.0, "timer/agent.train_total": 637.6262490749359, "timer/agent.train_frac": 0.6374921486263874, "timer/agent.train_avg": 0.44745701689469186, "timer/agent.train_min": 0.43601489067077637, "timer/agent.train_max": 1.6208131313323975, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4716155529022217, "timer/agent.report_frac": 0.0004715163664943873, "timer/agent.report_avg": 0.23580777645111084, "timer/agent.report_min": 0.22903037071228027, "timer/agent.report_max": 0.2425851821899414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765073867048562e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.794910956607964}
{"step": 666280, "time": 30486.52521467209, "episode/length": 255.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 666400, "time": 30492.470366954803, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 666680, "time": 30503.01515841484, "episode/length": 420.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9928741092636579, "episode/intrinsic_return": 0.0}
{"step": 667120, "time": 30519.384353876114, "episode/length": 221.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 667192, "time": 30523.128882408142, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 667304, "time": 30528.340095043182, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 667440, "time": 30534.52198600769, "episode/length": 306.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.993485342019544, "episode/intrinsic_return": 0.0}
{"step": 668328, "time": 30565.325772047043, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 668440, "time": 30570.58934545517, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 668584, "time": 30577.023552894592, "episode/length": 428.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 668640, "time": 30580.788173913956, "episode/length": 244.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 668952, "time": 30592.53035402298, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 669008, "time": 30596.177088975906, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 669096, "time": 30600.903809309006, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 669424, "time": 30613.58082795143, "episode/length": 247.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 30654.865613222122, "eval_episode/length": 136.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 670072, "time": 30658.530601263046, "eval_episode/length": 187.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 670072, "time": 30660.371940135956, "eval_episode/length": 194.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 670072, "time": 30662.93174791336, "eval_episode/length": 218.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 670072, "time": 30666.827035665512, "eval_episode/length": 271.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9816176470588235}
{"step": 670072, "time": 30668.872879743576, "eval_episode/length": 276.0, "eval_episode/score": 14.099999986588955, "eval_episode/reward_rate": 0.9783393501805054}
{"step": 670072, "time": 30670.81678366661, "eval_episode/length": 283.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9964788732394366}
{"step": 670072, "time": 30674.092200040817, "eval_episode/length": 324.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9876923076923076}
{"step": 670112, "time": 30675.651782512665, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 670176, "time": 30679.367871046066, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 670336, "time": 30686.290098428726, "episode/length": 211.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 670464, "time": 30692.176287412643, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 670568, "time": 30697.05509209633, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 670616, "time": 30700.319094896317, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 671280, "time": 30724.271874904633, "episode/length": 272.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 671688, "time": 30739.239176511765, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 671784, "time": 30745.766021490097, "episode/length": 294.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 672176, "time": 30760.72509407997, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 672536, "time": 30773.919865131378, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 672728, "time": 30781.977521419525, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 672760, "time": 30784.59214401245, "episode/length": 286.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 673448, "time": 30809.280301332474, "episode/length": 408.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951100244498777, "episode/intrinsic_return": 0.0}
{"step": 673480, "time": 30811.895823955536, "episode/length": 223.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 673576, "time": 30816.76013159752, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 673752, "time": 30824.19157576561, "episode/length": 245.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 673992, "time": 30833.680275917053, "episode/length": 63.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 674096, "time": 30839.03026366234, "episode/length": 239.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 674248, "time": 30845.39028453827, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 675088, "time": 30875.15491962433, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 675120, "time": 30877.732830762863, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 675328, "time": 30886.24204325676, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 675368, "time": 30888.80772805214, "episode/length": 223.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 675776, "time": 30904.070398569107, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 675976, "time": 30912.06010246277, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 676096, "time": 30917.89475464821, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 676328, "time": 30927.105412721634, "episode/length": 445.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 676328, "time": 30927.11377477646, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 677112, "time": 30956.425132989883, "episode/length": 126.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9448818897637795, "episode/intrinsic_return": 0.0}
{"step": 677184, "time": 30961.170478105545, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 677784, "time": 30983.063265562057, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 677896, "time": 30988.4228079319, "episode/length": 264.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 678032, "time": 30994.716562747955, "episode/length": 212.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 678088, "time": 30997.964287757874, "episode/length": 344.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942028985507246, "episode/intrinsic_return": 0.0}
{"step": 678272, "time": 31005.83768749237, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 678464, "time": 31013.72608065605, "episode/length": 70.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 678496, "time": 31016.270847320557, "episode/length": 314.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9936507936507937, "episode/intrinsic_return": 0.0}
{"step": 678576, "time": 31020.425451278687, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 678936, "time": 31033.667150735855, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 679992, "time": 31071.81626224518, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31093.016556739807, "eval_episode/length": 110.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.954954954954955}
{"step": 680056, "time": 31095.74138736725, "eval_episode/length": 138.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712230215827338}
{"step": 680056, "time": 31099.281002998352, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9619565217391305}
{"step": 680056, "time": 31101.049595594406, "eval_episode/length": 186.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 680056, "time": 31103.341641902924, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 680056, "time": 31105.782678365707, "eval_episode/length": 224.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 680056, "time": 31107.573030233383, "eval_episode/length": 90.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9560439560439561}
{"step": 680056, "time": 31109.285950899124, "eval_episode/length": 233.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 680200, "time": 31114.032915830612, "episode/length": 263.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 680592, "time": 31128.847770929337, "episode/length": 261.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 680720, "time": 31134.63033270836, "episode/length": 335.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 680752, "time": 31137.29556107521, "episode/length": 226.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 681232, "time": 31154.607950925827, "episode/length": 369.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9918918918918919, "episode/intrinsic_return": 0.0}
{"step": 681232, "time": 31154.61597418785, "episode/length": 63.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 681944, "time": 31181.3703956604, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 682208, "time": 31191.898240089417, "episode/length": 467.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9978632478632479, "episode/intrinsic_return": 0.0}
{"step": 682392, "time": 31199.18286705017, "episode/length": 476.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 682496, "time": 31204.466270685196, "episode/length": 237.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 682504, "time": 31206.65282559395, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 682656, "time": 31214.05242371559, "episode/length": 332.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984984984984985, "episode/intrinsic_return": 0.0}
{"step": 683224, "time": 31234.297357797623, "episode/length": 248.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 683288, "time": 31238.020747184753, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 683408, "time": 31243.722403287888, "episode/length": 331.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 683456, "time": 31246.82213950157, "episode/length": 277.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 683776, "time": 31258.9308450222, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 683784, "time": 31260.51372385025, "episode/length": 40.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 683984, "time": 31268.985810756683, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 684000, "time": 31271.068650007248, "episode/length": 167.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 684608, "time": 31292.71001458168, "episode/length": 263.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 684968, "time": 31306.032601594925, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 685008, "time": 31309.029631853104, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 685192, "time": 31316.427769184113, "episode/length": 245.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 685200, "time": 31318.540328025818, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 685352, "time": 31324.92807340622, "episode/length": 168.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 685648, "time": 31336.647167682648, "episode/length": 207.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 686024, "time": 31350.35573744774, "episode/length": 126.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 686384, "time": 31363.99902653694, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 686480, "time": 31368.82332754135, "episode/length": 337.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.0}
{"step": 686608, "time": 31374.78858780861, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 686704, "time": 31379.447521209717, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 686848, "time": 31385.757436275482, "episode/length": 279.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 687112, "time": 31396.5976395607, "episode/length": 219.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 687272, "time": 31403.467866659164, "episode/length": 202.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 687800, "time": 31422.58361673355, "episode/length": 221.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 688392, "time": 31445.429976463318, "episode/length": 222.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 688504, "time": 31450.847502470016, "episode/length": 224.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 688672, "time": 31458.36214208603, "episode/length": 285.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 688745, "time": 31463.152141809464, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.338036267510776, "train/action_min": 0.0, "train/action_std": 3.1753521837037186, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04153737764934014, "train/actor_opt_grad_steps": 42230.0, "train/actor_opt_loss": 1.1985500812530518, "train/adv_mag": 0.5211022481836122, "train/adv_max": 0.4785820330011434, "train/adv_mean": 0.004589988853673151, "train/adv_min": -0.4230718512987268, "train/adv_std": 0.0589230680260165, "train/cont_avg": 0.9949286099137931, "train/cont_loss_mean": 0.00023221964151189396, "train/cont_loss_std": 0.0071490345098262536, "train/cont_neg_acc": 0.993267652495154, "train/cont_neg_loss": 0.025362213901249122, "train/cont_pos_acc": 0.9999796920809253, "train/cont_pos_loss": 7.067044341895737e-05, "train/cont_pred": 0.9949216065735652, "train/cont_rate": 0.9949286099137931, "train/dyn_loss_mean": 13.077148463808257, "train/dyn_loss_std": 8.823589476223649, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8682276462686473, "train/extr_critic_critic_opt_grad_steps": 42230.0, "train/extr_critic_critic_opt_loss": 15304.03481950431, "train/extr_critic_mag": 8.087926614695581, "train/extr_critic_max": 8.087926614695581, "train/extr_critic_mean": 2.7174502446733673, "train/extr_critic_min": -0.1440569515885978, "train/extr_critic_std": 1.8030932878625805, "train/extr_return_normed_mag": 1.5347906745713333, "train/extr_return_normed_max": 1.5347906745713333, "train/extr_return_normed_mean": 0.3931220008381482, "train/extr_return_normed_min": -0.1607459510194844, "train/extr_return_normed_std": 0.31929856682645863, "train/extr_return_rate": 0.9424811914049346, "train/extr_return_raw_mag": 9.303803496525205, "train/extr_return_raw_max": 9.303803496525205, "train/extr_return_raw_mean": 2.7438334736330754, "train/extr_return_raw_min": -0.43918937352196924, "train/extr_return_raw_std": 1.8349487214252866, "train/extr_reward_mag": 1.035374643062723, "train/extr_reward_max": 1.035374643062723, "train/extr_reward_mean": 0.043564819005028954, "train/extr_reward_min": -0.3787824384097395, "train/extr_reward_std": 0.19398542036270272, "train/image_loss_mean": 6.537927170457511, "train/image_loss_std": 11.464737786917851, "train/model_loss_mean": 14.441222085623906, "train/model_loss_std": 15.038341831338817, "train/model_opt_grad_norm": 58.59033898978398, "train/model_opt_grad_steps": 42191.7724137931, "train/model_opt_loss": 15079.849616109914, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1047.4137931034484, "train/policy_entropy_mag": 2.2947228760554874, "train/policy_entropy_max": 2.2947228760554874, "train/policy_entropy_mean": 0.4976868816490831, "train/policy_entropy_min": 0.0793751192503962, "train/policy_entropy_std": 0.5027307430218007, "train/policy_logprob_mag": 7.438383546368829, "train/policy_logprob_max": -0.009455688561088053, "train/policy_logprob_mean": -0.49814283621722255, "train/policy_logprob_min": -7.438383546368829, "train/policy_logprob_std": 1.0502408323616816, "train/policy_randomness_mag": 0.8099364749316511, "train/policy_randomness_max": 0.8099364749316511, "train/policy_randomness_mean": 0.17566162851350062, "train/policy_randomness_min": 0.0280159338537989, "train/policy_randomness_std": 0.1774418922333882, "train/post_ent_mag": 58.48674447947535, "train/post_ent_max": 58.48674447947535, "train/post_ent_mean": 42.12865711080617, "train/post_ent_min": 20.08041721212453, "train/post_ent_std": 7.37594004992781, "train/prior_ent_mag": 67.26418751683728, "train/prior_ent_max": 67.26418751683728, "train/prior_ent_mean": 55.26509580941036, "train/prior_ent_min": 40.696630122743805, "train/prior_ent_std": 4.437481036679498, "train/rep_loss_mean": 13.077148463808257, "train/rep_loss_std": 8.823589476223649, "train/reward_avg": 0.028683997722792214, "train/reward_loss_mean": 0.056773560288651236, "train/reward_loss_std": 0.25843124132731865, "train/reward_max_data": 1.01724138342101, "train/reward_max_pred": 1.0130473490419059, "train/reward_neg_acc": 0.9928373205250707, "train/reward_neg_loss": 0.02944525369153968, "train/reward_pos_acc": 0.9638938451635426, "train/reward_pos_loss": 0.8594376629796522, "train/reward_pred": 0.027955871454343712, "train/reward_rate": 0.033135775862068964, "train_stats/sum_log_reward": 9.07894764699434, "train_stats/max_log_achievement_collect_coal": 0.3894736842105263, "train_stats/max_log_achievement_collect_drink": 4.073684210526316, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.831578947368421, "train_stats/max_log_achievement_collect_stone": 7.894736842105263, "train_stats/max_log_achievement_collect_wood": 12.410526315789474, "train_stats/max_log_achievement_defeat_skeleton": 0.021052631578947368, "train_stats/max_log_achievement_defeat_zombie": 1.0736842105263158, "train_stats/max_log_achievement_eat_cow": 0.12631578947368421, "train_stats/max_log_achievement_eat_plant": 0.010526315789473684, "train_stats/max_log_achievement_make_stone_pickaxe": 0.042105263157894736, "train_stats/max_log_achievement_make_stone_sword": 0.010526315789473684, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5263157894736843, "train_stats/max_log_achievement_make_wood_sword": 1.4631578947368422, "train_stats/max_log_achievement_place_furnace": 0.05263157894736842, "train_stats/max_log_achievement_place_plant": 1.7894736842105263, "train_stats/max_log_achievement_place_stone": 6.2, "train_stats/max_log_achievement_place_table": 3.8526315789473684, "train_stats/max_log_achievement_wake_up": 1.2842105263157895, "train_stats/mean_log_entropy": 0.565950337836617, "eval_stats/sum_log_reward": 8.225000262260437, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_iron": 0.0625, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 5.1875, "eval_stats/max_log_achievement_collect_wood": 9.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 3.5625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1184312825207599e-05, "report/cont_loss_std": 0.00023273898113984615, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001430801465176046, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.817218728523585e-06, "report/cont_pred": 0.9941462278366089, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.926420211791992, "report/dyn_loss_std": 9.657389640808105, "report/image_loss_mean": 7.06920051574707, "report/image_loss_std": 14.915621757507324, "report/model_loss_mean": 14.901599884033203, "report/model_loss_std": 18.664348602294922, "report/post_ent_mag": 58.259849548339844, "report/post_ent_max": 58.259849548339844, "report/post_ent_mean": 42.295814514160156, "report/post_ent_min": 20.07793617248535, "report/post_ent_std": 7.653870582580566, "report/prior_ent_mag": 67.09310150146484, "report/prior_ent_max": 67.09310150146484, "report/prior_ent_mean": 54.80198669433594, "report/prior_ent_min": 40.08039474487305, "report/prior_ent_std": 4.967315673828125, "report/rep_loss_mean": 12.926420211791992, "report/rep_loss_std": 9.657389640808105, "report/reward_avg": 0.03007812425494194, "report/reward_loss_mean": 0.07653546333312988, "report/reward_loss_std": 0.32599127292633057, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0148975849151611, "report/reward_neg_acc": 0.9878419041633606, "report/reward_neg_loss": 0.0521276630461216, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7276299595832825, "report/reward_pred": 0.03528720512986183, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.6838162234053016e-05, "eval/cont_loss_std": 0.0010720973368734121, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005387759767472744, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.535925366624724e-05, "eval/cont_pred": 0.994156539440155, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.280414581298828, "eval/dyn_loss_std": 10.097917556762695, "eval/image_loss_mean": 10.637248039245605, "eval/image_loss_std": 15.038705825805664, "eval/model_loss_mean": 21.10962677001953, "eval/model_loss_std": 18.5926456451416, "eval/post_ent_mag": 56.427589416503906, "eval/post_ent_max": 56.427589416503906, "eval/post_ent_mean": 41.032196044921875, "eval/post_ent_min": 22.415569305419922, "eval/post_ent_std": 7.116522312164307, "eval/prior_ent_mag": 67.09310150146484, "eval/prior_ent_max": 67.09310150146484, "eval/prior_ent_mean": 55.96727752685547, "eval/prior_ent_min": 44.642948150634766, "eval/prior_ent_std": 4.3469061851501465, "eval/rep_loss_mean": 17.280414581298828, "eval/rep_loss_std": 10.097917556762695, "eval/reward_avg": 0.04287109524011612, "eval/reward_loss_mean": 0.10408198833465576, "eval/reward_loss_std": 0.46123629808425903, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0018060207366943, "eval/reward_neg_acc": 0.9876922965049744, "eval/reward_neg_loss": 0.0530303418636322, "eval/reward_pos_acc": 0.8979591727256775, "eval/reward_pos_loss": 1.1199055910110474, "eval/reward_pred": 0.041745930910110474, "eval/reward_rate": 0.0478515625, "replay/size": 688241.0, "replay/inserts": 23184.0, "replay/samples": 23184.0, "replay/insert_wait_avg": 1.4498243667570947e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.410150138323187e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.216403913412623e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1769931316376, "timer/env.step_count": 2898.0, "timer/env.step_total": 230.5843436717987, "timer/env.step_frac": 0.23054353904884364, "timer/env.step_avg": 0.0795667162428567, "timer/env.step_min": 0.023504257202148438, "timer/env.step_max": 3.3266451358795166, "timer/replay._sample_count": 23184.0, "timer/replay._sample_total": 11.670423746109009, "timer/replay._sample_frac": 0.011668358526792282, "timer/replay._sample_avg": 0.0005033826667576349, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.00967717170715332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3457.0, "timer/agent.policy_total": 56.788639307022095, "timer/agent.policy_frac": 0.0567785898865881, "timer/agent.policy_avg": 0.0164271447228875, "timer/agent.policy_min": 0.009423494338989258, "timer/agent.policy_max": 0.11745691299438477, "timer/dataset_train_count": 1449.0, "timer/dataset_train_total": 0.15784907341003418, "timer/dataset_train_frac": 0.00015782114015220003, "timer/dataset_train_avg": 0.0001089365585990574, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0005424022674560547, "timer/agent.train_count": 1449.0, "timer/agent.train_total": 645.0391681194305, "timer/agent.train_frac": 0.6449250208203241, "timer/agent.train_avg": 0.4451616067076815, "timer/agent.train_min": 0.4322242736816406, "timer/agent.train_max": 1.7336595058441162, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47452783584594727, "timer/agent.report_frac": 0.0004744438625409299, "timer/agent.report_avg": 0.23726391792297363, "timer/agent.report_min": 0.23031210899353027, "timer/agent.report_max": 0.244215726852417, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027380129100137e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 23.179594002348058}
{"step": 688896, "time": 31468.30085349083, "episode/length": 301.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 688952, "time": 31471.525331258774, "episode/length": 229.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 689256, "time": 31483.214599609375, "episode/length": 107.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 689504, "time": 31493.303211450577, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 689560, "time": 31496.53567838669, "episode/length": 131.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 689776, "time": 31505.65615415573, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 689864, "time": 31509.929800271988, "episode/length": 376.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 690016, "time": 31516.804851293564, "episode/length": 56.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 31540.209112405777, "eval_episode/length": 186.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 690040, "time": 31542.000158071518, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 690040, "time": 31544.016584396362, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 690040, "time": 31545.80739760399, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 690040, "time": 31548.879349946976, "eval_episode/length": 242.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 690040, "time": 31550.70254087448, "eval_episode/length": 249.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976}
{"step": 690040, "time": 31554.087325811386, "eval_episode/length": 292.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9863481228668942}
{"step": 690040, "time": 31558.76078057289, "eval_episode/length": 364.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9863013698630136}
{"step": 690304, "time": 31567.70592403412, "episode/length": 203.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 690496, "time": 31575.83709049225, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 690712, "time": 31584.4500977993, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 691120, "time": 31599.940171718597, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 691280, "time": 31606.84862756729, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 691296, "time": 31608.9306807518, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 691464, "time": 31615.82174873352, "episode/length": 93.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 691616, "time": 31622.71163916588, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 691872, "time": 31632.78077840805, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 692528, "time": 31656.247571229935, "episode/length": 277.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 692576, "time": 31659.55924630165, "episode/length": 259.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 692704, "time": 31665.416199207306, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 693064, "time": 31679.21002984047, "episode/length": 220.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 693232, "time": 31686.47928404808, "episode/length": 431.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 693544, "time": 31698.310104608536, "episode/length": 38.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 693848, "time": 31709.963451623917, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 694000, "time": 31716.873359680176, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 694088, "time": 31721.346132993698, "episode/length": 308.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 694648, "time": 31741.78245973587, "episode/length": 242.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 694848, "time": 31750.249623537064, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 695120, "time": 31760.772567272186, "episode/length": 456.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9803063457330415, "episode/intrinsic_return": 0.0}
{"step": 695248, "time": 31766.629005908966, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 695328, "time": 31770.907754182816, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 695344, "time": 31773.03466439247, "episode/length": 345.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 695656, "time": 31784.82913708687, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 696520, "time": 31816.904405117035, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 697032, "time": 31835.322189569473, "episode/length": 272.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 697336, "time": 31847.129733800888, "episode/length": 248.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 697360, "time": 31849.83698105812, "episode/length": 279.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 697440, "time": 31854.046724557877, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 697608, "time": 31860.922021389008, "episode/length": 243.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 697720, "time": 31866.14752459526, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 697752, "time": 31868.719930648804, "episode/length": 302.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 698472, "time": 31894.1733648777, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 698816, "time": 31907.49914073944, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 698896, "time": 31911.66349864006, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 699328, "time": 31927.56836462021, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 699376, "time": 31930.898775815964, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 699496, "time": 31936.18980574608, "episode/length": 269.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 699584, "time": 31941.503080129623, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 699872, "time": 31952.936531066895, "episode/length": 174.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 699888, "time": 31955.12978029251, "episode/length": 133.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 31983.515832424164, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 700024, "time": 31985.570042848587, "eval_episode/length": 192.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 700024, "time": 31988.85543847084, "eval_episode/length": 227.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 700024, "time": 31992.005243062973, "eval_episode/length": 263.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 700024, "time": 31993.724531412125, "eval_episode/length": 266.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 700024, "time": 31995.62926840782, "eval_episode/length": 275.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9818840579710145}
{"step": 700024, "time": 31998.936433315277, "eval_episode/length": 318.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9968652037617555}
{"step": 700024, "time": 32001.336678743362, "eval_episode/length": 146.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 700088, "time": 32003.457275867462, "episode/length": 291.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 700944, "time": 32034.022290945053, "episode/length": 180.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 701120, "time": 32041.4964697361, "episode/length": 277.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 701240, "time": 32046.887674808502, "episode/length": 143.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 701272, "time": 32049.660621643066, "episode/length": 236.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 701472, "time": 32058.165392398834, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 701592, "time": 32063.526208162308, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 701592, "time": 32063.53637123108, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 701864, "time": 32075.991879463196, "episode/length": 248.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 702568, "time": 32101.086844682693, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 702616, "time": 32104.31271314621, "episode/length": 127.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 702816, "time": 32112.89204144478, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 702840, "time": 32115.040251731873, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 702968, "time": 32120.82421064377, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 703184, "time": 32129.832226276398, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 703472, "time": 32141.16226196289, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 703976, "time": 32159.825986146927, "episode/length": 144.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 704048, "time": 32163.970702171326, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 704056, "time": 32165.55288219452, "episode/length": 307.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 704136, "time": 32169.840445280075, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 704424, "time": 32180.875410318375, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 705104, "time": 32207.149513483047, "episode/length": 120.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 705112, "time": 32208.69922566414, "episode/length": 240.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 705568, "time": 32225.700433015823, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 705576, "time": 32227.33703970909, "episode/length": 143.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 705728, "time": 32234.351235866547, "episode/length": 281.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 705744, "time": 32236.411061525345, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 705928, "time": 32243.790437459946, "episode/length": 385.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 705936, "time": 32245.869036197662, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 706640, "time": 32270.78525328636, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 706760, "time": 32276.13366627693, "episode/length": 205.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 707080, "time": 32288.63484311104, "episode/length": 187.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 707144, "time": 32292.274301290512, "episode/length": 196.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 707304, "time": 32299.231182575226, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 707544, "time": 32308.720547914505, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 707600, "time": 32312.252468824387, "episode/length": 231.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 708136, "time": 32331.63115310669, "episode/length": 274.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 708200, "time": 32335.38120698929, "episode/length": 139.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 708488, "time": 32346.57690858841, "episode/length": 147.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 708608, "time": 32352.486094474792, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 708864, "time": 32362.492396354675, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 708960, "time": 32367.274017095566, "episode/length": 289.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 709224, "time": 32377.320076942444, "episode/length": 307.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 709480, "time": 32387.562985897064, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 709624, "time": 32393.84468817711, "episode/length": 177.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 709840, "time": 32402.651344776154, "episode/length": 153.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32429.312966823578, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 710008, "time": 32431.372287988663, "eval_episode/length": 166.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 710008, "time": 32434.315625190735, "eval_episode/length": 197.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 710008, "time": 32436.837166070938, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 710008, "time": 32439.278928041458, "eval_episode/length": 235.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9745762711864406}
{"step": 710008, "time": 32442.20560669899, "eval_episode/length": 266.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 710008, "time": 32444.208876371384, "eval_episode/length": 276.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 710008, "time": 32447.43265724182, "eval_episode/length": 316.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9968454258675079}
{"step": 710136, "time": 32451.68398475647, "episode/length": 249.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 710200, "time": 32455.526599407196, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 710248, "time": 32458.65043282509, "episode/length": 219.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 710313, "time": 32463.288858652115, "train_stats/sum_log_reward": 9.221212387084961, "train_stats/max_log_achievement_collect_coal": 0.3939393939393939, "train_stats/max_log_achievement_collect_drink": 3.5454545454545454, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7171717171717171, "train_stats/max_log_achievement_collect_stone": 8.555555555555555, "train_stats/max_log_achievement_collect_wood": 11.767676767676768, "train_stats/max_log_achievement_defeat_skeleton": 0.04040404040404041, "train_stats/max_log_achievement_defeat_zombie": 1.101010101010101, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010101010101010102, "train_stats/max_log_achievement_make_stone_sword": 0.020202020202020204, "train_stats/max_log_achievement_make_wood_pickaxe": 1.494949494949495, "train_stats/max_log_achievement_make_wood_sword": 1.4747474747474747, "train_stats/max_log_achievement_place_furnace": 0.050505050505050504, "train_stats/max_log_achievement_place_plant": 1.6262626262626263, "train_stats/max_log_achievement_place_stone": 7.090909090909091, "train_stats/max_log_achievement_place_table": 3.1818181818181817, "train_stats/max_log_achievement_wake_up": 1.2323232323232323, "train_stats/mean_log_entropy": 0.568849886758159, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.350156869461287, "train/action_min": 0.0, "train/action_std": 3.3194115482159514, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03987018429020892, "train/actor_opt_grad_steps": 43625.0, "train/actor_opt_loss": -4.777387999554179, "train/adv_mag": 0.5244825308892265, "train/adv_max": 0.4569295887182008, "train/adv_mean": 0.0030694247855454202, "train/adv_min": -0.44525784009428165, "train/adv_std": 0.05640896384729378, "train/cont_avg": 0.9950370219216418, "train/cont_loss_mean": 0.0002904461511056029, "train/cont_loss_std": 0.008760292305545753, "train/cont_neg_acc": 0.9961353949646452, "train/cont_neg_loss": 0.02447106371165088, "train/cont_pos_acc": 0.9999486448159859, "train/cont_pos_loss": 0.00017605094408625334, "train/cont_pred": 0.995008790226125, "train/cont_rate": 0.9950370219216418, "train/dyn_loss_mean": 13.038677315213787, "train/dyn_loss_std": 8.862922091982258, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8475668092272175, "train/extr_critic_critic_opt_grad_steps": 43625.0, "train/extr_critic_critic_opt_loss": 15074.26512943097, "train/extr_critic_mag": 8.389650259444963, "train/extr_critic_max": 8.389650259444963, "train/extr_critic_mean": 2.9122475937231265, "train/extr_critic_min": -0.13175770062119213, "train/extr_critic_std": 1.9004533522164644, "train/extr_return_normed_mag": 1.5216870939553673, "train/extr_return_normed_max": 1.5216870939553673, "train/extr_return_normed_mean": 0.3933565522085375, "train/extr_return_normed_min": -0.1604230170374486, "train/extr_return_normed_std": 0.3194687799064081, "train/extr_return_rate": 0.9558929476275373, "train/extr_return_raw_mag": 9.765187192319045, "train/extr_return_raw_max": 9.765187192319045, "train/extr_return_raw_mean": 2.930806154635415, "train/extr_return_raw_min": -0.4226205294479185, "train/extr_return_raw_std": 1.9351248910178, "train/extr_reward_mag": 1.0295969496912032, "train/extr_reward_max": 1.0295969496912032, "train/extr_reward_mean": 0.04661145870254111, "train/extr_reward_min": -0.3929165201400643, "train/extr_reward_std": 0.20047154511088755, "train/image_loss_mean": 6.3047649682457765, "train/image_loss_std": 11.323219309991865, "train/model_loss_mean": 14.18483892127649, "train/model_loss_std": 14.962446831945163, "train/model_opt_grad_norm": 55.414333813226044, "train/model_opt_grad_steps": 43586.0, "train/model_opt_loss": 13277.509517840484, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 937.5, "train/policy_entropy_mag": 2.316418028589505, "train/policy_entropy_max": 2.316418028589505, "train/policy_entropy_mean": 0.4995283506699462, "train/policy_entropy_min": 0.07937508565721227, "train/policy_entropy_std": 0.5310488225363973, "train/policy_logprob_mag": 7.438383607722041, "train/policy_logprob_max": -0.00945567168684593, "train/policy_logprob_mean": -0.4994091164709917, "train/policy_logprob_min": -7.438383607722041, "train/policy_logprob_std": 1.0457443879611457, "train/policy_randomness_mag": 0.8175939112456877, "train/policy_randomness_max": 0.8175939112456877, "train/policy_randomness_mean": 0.17631158666379415, "train/policy_randomness_min": 0.028015922087786804, "train/policy_randomness_std": 0.1874369318360713, "train/post_ent_mag": 58.38623374255735, "train/post_ent_max": 58.38623374255735, "train/post_ent_mean": 42.03288790005357, "train/post_ent_min": 20.120968576687485, "train/post_ent_std": 7.2966373464954435, "train/prior_ent_mag": 67.42285583268351, "train/prior_ent_max": 67.42285583268351, "train/prior_ent_mean": 55.117374334762346, "train/prior_ent_min": 40.93356676244024, "train/prior_ent_std": 4.485517096163622, "train/rep_loss_mean": 13.038677315213787, "train/rep_loss_std": 8.862922091982258, "train/reward_avg": 0.030207847384040924, "train/reward_loss_mean": 0.056577117585424164, "train/reward_loss_std": 0.24895361432833457, "train/reward_max_data": 1.0231343338738625, "train/reward_max_pred": 1.0109927325106378, "train/reward_neg_acc": 0.9929871665897654, "train/reward_neg_loss": 0.028502081889214357, "train/reward_pos_acc": 0.9697302059451146, "train/reward_pos_loss": 0.8398266047684114, "train/reward_pred": 0.02952020022489909, "train/reward_rate": 0.034777285447761194, "eval_stats/sum_log_reward": 9.225000301996866, "eval_stats/max_log_achievement_collect_coal": 0.4166666666666667, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 10.458333333333334, "eval_stats/max_log_achievement_collect_wood": 10.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 8.791666666666666, "eval_stats/max_log_achievement_place_table": 2.9166666666666665, "eval_stats/max_log_achievement_wake_up": 1.2083333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.682706169958692e-05, "report/cont_loss_std": 0.0004915126482956111, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.462606249144301e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6445321307401173e-05, "report/cont_pred": 0.9951014518737793, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.489156723022461, "report/dyn_loss_std": 8.209696769714355, "report/image_loss_mean": 6.261229991912842, "report/image_loss_std": 12.280213356018066, "report/model_loss_mean": 15.009496688842773, "report/model_loss_std": 15.544899940490723, "report/post_ent_mag": 55.31724166870117, "report/post_ent_max": 55.31724166870117, "report/post_ent_mean": 40.470611572265625, "report/post_ent_min": 18.622356414794922, "report/post_ent_std": 6.538987159729004, "report/prior_ent_mag": 67.34757995605469, "report/prior_ent_max": 67.34757995605469, "report/prior_ent_mean": 55.36353302001953, "report/prior_ent_min": 41.105125427246094, "report/prior_ent_std": 4.449361801147461, "report/rep_loss_mean": 14.489156723022461, "report/rep_loss_std": 8.209696769714355, "report/reward_avg": 0.03798828274011612, "report/reward_loss_mean": 0.05475471168756485, "report/reward_loss_std": 0.2671240270137787, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000544786453247, "report/reward_neg_acc": 0.9959267377853394, "report/reward_neg_loss": 0.02187815122306347, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.8234401345252991, "report/reward_pred": 0.036758653819561005, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0060722073540091515, "eval/cont_loss_std": 0.18261516094207764, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 1.5521451234817505, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.17714714887552e-06, "eval/cont_pred": 0.9973628520965576, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.290767669677734, "eval/dyn_loss_std": 10.395480155944824, "eval/image_loss_mean": 10.544553756713867, "eval/image_loss_std": 15.316606521606445, "eval/model_loss_mean": 21.63884735107422, "eval/model_loss_std": 19.592124938964844, "eval/post_ent_mag": 58.255149841308594, "eval/post_ent_max": 58.255149841308594, "eval/post_ent_mean": 40.23727035522461, "eval/post_ent_min": 22.755107879638672, "eval/post_ent_std": 7.32227897644043, "eval/prior_ent_mag": 67.34757995605469, "eval/prior_ent_max": 67.34757995605469, "eval/prior_ent_mean": 56.12005615234375, "eval/prior_ent_min": 42.87199401855469, "eval/prior_ent_std": 3.8998942375183105, "eval/rep_loss_mean": 18.290767669677734, "eval/rep_loss_std": 10.395480155944824, "eval/reward_avg": 0.03437500074505806, "eval/reward_loss_mean": 0.11376050859689713, "eval/reward_loss_std": 0.6251062750816345, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0085420608520508, "eval/reward_neg_acc": 0.9877924919128418, "eval/reward_neg_loss": 0.06153927743434906, "eval/reward_pos_acc": 0.9024389982223511, "eval/reward_pos_loss": 1.3657963275909424, "eval/reward_pred": 0.03370904177427292, "eval/reward_rate": 0.0400390625, "replay/size": 709809.0, "replay/inserts": 21568.0, "replay/samples": 21568.0, "replay/insert_wait_avg": 1.453935480966766e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.456931306629577e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2146633431869477e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.121330499649, "timer/env.step_count": 2696.0, "timer/env.step_total": 231.48583459854126, "timer/env.step_frac": 0.23145775171387817, "timer/env.step_avg": 0.08586269829322747, "timer/env.step_min": 0.02354574203491211, "timer/env.step_max": 3.449568510055542, "timer/replay._sample_count": 21568.0, "timer/replay._sample_total": 10.760828256607056, "timer/replay._sample_frac": 0.01075952279832995, "timer/replay._sample_avg": 0.0004989256424613805, "timer/replay._sample_min": 0.0004086494445800781, "timer/replay._sample_max": 0.007646083831787109, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3718.0, "timer/agent.policy_total": 62.61694550514221, "timer/agent.policy_frac": 0.06260934908153545, "timer/agent.policy_avg": 0.0168415668383922, "timer/agent.policy_min": 0.009549856185913086, "timer/agent.policy_max": 0.12955760955810547, "timer/dataset_train_count": 1348.0, "timer/dataset_train_total": 0.1468822956085205, "timer/dataset_train_frac": 0.00014686447646820993, "timer/dataset_train_avg": 0.00010896312730602411, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0008943080902099609, "timer/agent.train_count": 1348.0, "timer/agent.train_total": 601.1066048145294, "timer/agent.train_frac": 0.601033681097696, "timer/agent.train_avg": 0.4459247810196806, "timer/agent.train_min": 0.43330836296081543, "timer/agent.train_max": 1.619917869567871, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4742882251739502, "timer/agent.report_frac": 0.0004742306865278049, "timer/agent.report_avg": 0.2371441125869751, "timer/agent.report_min": 0.22959065437316895, "timer/agent.report_max": 0.24469757080078125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.932192758536758e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 21.565077362296403}
{"step": 710712, "time": 32476.499611139297, "episode/length": 153.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 710896, "time": 32484.397603034973, "episode/length": 208.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 711320, "time": 32500.062616586685, "episode/length": 133.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 711496, "time": 32507.495334386826, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 712112, "time": 32529.90642762184, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 712168, "time": 32533.1917283535, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 712448, "time": 32544.67545580864, "episode/length": 447.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 712552, "time": 32549.329531669617, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 712824, "time": 32561.70799779892, "episode/length": 372.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9919571045576407, "episode/intrinsic_return": 0.0}
{"step": 712824, "time": 32561.717671632767, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 713368, "time": 32583.32269859314, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 713656, "time": 32594.589421510696, "episode/length": 291.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 713816, "time": 32601.592606544495, "episode/length": 212.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 713904, "time": 32606.19885444641, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 714144, "time": 32615.676648378372, "episode/length": 246.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 714480, "time": 32628.388192892075, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 714968, "time": 32646.10050392151, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 715104, "time": 32652.52893614769, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 715640, "time": 32671.652679681778, "episode/length": 247.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 715896, "time": 32681.78116583824, "episode/length": 383.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 716040, "time": 32688.17489552498, "episode/length": 194.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 716272, "time": 32697.716831445694, "episode/length": 477.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9937238493723849, "episode/intrinsic_return": 0.0}
{"step": 716616, "time": 32710.616304159164, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 716840, "time": 32719.591472387314, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 717120, "time": 32730.674591064453, "episode/length": 401.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 717288, "time": 32737.545289993286, "episode/length": 392.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 717336, "time": 32740.887720108032, "episode/length": 132.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 718152, "time": 32769.670974969864, "episode/length": 191.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 718296, "time": 32776.03184103966, "episode/length": 331.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 718408, "time": 32781.31061792374, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 718424, "time": 32783.451810121536, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 718488, "time": 32787.03523349762, "episode/length": 323.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 719048, "time": 32807.355063676834, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 719488, "time": 32823.76742935181, "episode/length": 268.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702602230483272, "episode/intrinsic_return": 0.0}
{"step": 719536, "time": 32826.85758686066, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954233409610984, "episode/intrinsic_return": 0.0}
{"step": 719840, "time": 32838.674389600754, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 719984, "time": 32845.21445584297, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 32869.87674021721, "eval_episode/length": 138.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9640287769784173}
{"step": 720096, "time": 32872.960044145584, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 720096, "time": 32875.17809200287, "eval_episode/length": 183.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9836956521739131}
{"step": 720096, "time": 32876.94578409195, "eval_episode/length": 187.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9627659574468085}
{"step": 720096, "time": 32879.46633672714, "eval_episode/length": 25.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8461538461538461}
{"step": 720096, "time": 32881.31692314148, "eval_episode/length": 215.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 720096, "time": 32882.96512556076, "eval_episode/length": 218.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 720096, "time": 32886.163694381714, "eval_episode/length": 39.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 720144, "time": 32887.797033548355, "episode/length": 248.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 720440, "time": 32899.13401412964, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 720936, "time": 32919.020607709885, "episode/length": 61.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 721032, "time": 32923.79703044891, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 721160, "time": 32929.57958841324, "episode/length": 208.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 721232, "time": 32933.81996321678, "episode/length": 366.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 721992, "time": 32960.461275815964, "episode/length": 230.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 722216, "time": 32969.49975800514, "episode/length": 278.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 722736, "time": 32988.72352862358, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 722896, "time": 32997.62827515602, "episode/length": 244.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 722920, "time": 32999.832528591156, "episode/length": 219.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 723120, "time": 33008.33521795273, "episode/length": 409.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 723320, "time": 33016.26278090477, "episode/length": 611.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9918300653594772, "episode/intrinsic_return": 0.0}
{"step": 723608, "time": 33027.31857419014, "episode/length": 60.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 723616, "time": 33029.35066795349, "episode/length": 297.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 723904, "time": 33040.53036618233, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 724224, "time": 33052.754331588745, "episode/length": 250.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 724312, "time": 33057.001544475555, "episode/length": 196.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 724680, "time": 33070.84432697296, "episode/length": 96.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 724808, "time": 33076.70180439949, "episode/length": 148.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 725000, "time": 33084.86181521416, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 725336, "time": 33097.52270627022, "episode/length": 304.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 725416, "time": 33101.94579219818, "episode/length": 311.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 725616, "time": 33110.42144012451, "episode/length": 452.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.977924944812362, "episode/intrinsic_return": 0.0}
{"step": 725664, "time": 33113.640268564224, "episode/length": 168.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 725888, "time": 33122.60374045372, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 726584, "time": 33147.48567008972, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 726592, "time": 33149.647639751434, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 726744, "time": 33156.08315086365, "episode/length": 217.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 726864, "time": 33161.79907679558, "episode/length": 256.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 726992, "time": 33167.55823802948, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 727264, "time": 33178.110607385635, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 727896, "time": 33200.77389860153, "episode/length": 278.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.992831541218638, "episode/intrinsic_return": 0.0}
{"step": 727936, "time": 33203.87663435936, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 728240, "time": 33215.71081709862, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 728272, "time": 33218.45088505745, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 728616, "time": 33231.24235916138, "episode/length": 340.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9853372434017595, "episode/intrinsic_return": 0.0}
{"step": 728928, "time": 33243.47381448746, "episode/length": 257.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 729384, "time": 33261.711201667786, "episode/length": 185.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 729408, "time": 33264.27142715454, "episode/length": 145.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 729624, "time": 33272.6867980957, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 729912, "time": 33283.940811634064, "episode/length": 330.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 33306.841437101364, "eval_episode/length": 52.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 730080, "time": 33315.75996589661, "eval_episode/length": 180.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 730080, "time": 33317.65622019768, "eval_episode/length": 187.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 730080, "time": 33319.343514442444, "eval_episode/length": 189.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 730080, "time": 33322.87771034241, "eval_episode/length": 232.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 730080, "time": 33324.83162045479, "eval_episode/length": 241.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9710743801652892}
{"step": 730080, "time": 33327.875572919846, "eval_episode/length": 276.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 730080, "time": 33331.97274041176, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 730344, "time": 33340.56932449341, "episode/length": 449.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9977777777777778, "episode/intrinsic_return": 0.0}
{"step": 730608, "time": 33351.120034217834, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 730832, "time": 33360.13488507271, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 731296, "time": 33377.20055556297, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 731464, "time": 33384.147335767746, "episode/length": 440.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 731784, "time": 33396.34501481056, "episode/length": 296.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 731872, "time": 33401.19579029083, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 732040, "time": 33408.11645293236, "episode/length": 331.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9909638554216867, "episode/intrinsic_return": 0.0}
{"step": 732080, "time": 33411.18589305878, "episode/length": 270.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 732488, "time": 33426.01597237587, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 732872, "time": 33440.289930820465, "episode/length": 103.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 733248, "time": 33454.55757236481, "episode/length": 46.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 733280, "time": 33457.112181186676, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 733401, "time": 33463.65802311897, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.148038877289871, "train/action_min": 0.0, "train/action_std": 3.119421051288473, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03912441512120181, "train/actor_opt_grad_steps": 45020.0, "train/actor_opt_loss": -5.626424858230969, "train/adv_mag": 0.5211159054575295, "train/adv_max": 0.47448707222938535, "train/adv_mean": 0.002986276220000381, "train/adv_min": -0.4203487352050584, "train/adv_std": 0.05561674807606072, "train/cont_avg": 0.9949757543103448, "train/cont_loss_mean": 0.0002417042281312488, "train/cont_loss_std": 0.007355495774060006, "train/cont_neg_acc": 0.9905747134110023, "train/cont_neg_loss": 0.04493796568923903, "train/cont_pos_acc": 0.9999796682390674, "train/cont_pos_loss": 5.8156868940675744e-05, "train/cont_pred": 0.9949916079126555, "train/cont_rate": 0.9949757543103448, "train/dyn_loss_mean": 13.120145080829488, "train/dyn_loss_std": 8.860212631883293, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7941045987194982, "train/extr_critic_critic_opt_grad_steps": 45020.0, "train/extr_critic_critic_opt_loss": 14916.481526131465, "train/extr_critic_mag": 8.548256091413826, "train/extr_critic_max": 8.548256091413826, "train/extr_critic_mean": 2.9291421232552364, "train/extr_critic_min": -0.14116942882537842, "train/extr_critic_std": 1.8978699865012334, "train/extr_return_normed_mag": 1.5223671452752474, "train/extr_return_normed_max": 1.5223671452752474, "train/extr_return_normed_mean": 0.39340519041850647, "train/extr_return_normed_min": -0.17090991622415083, "train/extr_return_normed_std": 0.3186763979237655, "train/extr_return_rate": 0.9592003937425284, "train/extr_return_raw_mag": 9.770274879192485, "train/extr_return_raw_max": 9.770274879192485, "train/extr_return_raw_mean": 2.9471805539624443, "train/extr_return_raw_min": -0.46349362427818364, "train/extr_return_raw_std": 1.9261542640883347, "train/extr_reward_mag": 1.0384202990038642, "train/extr_reward_max": 1.0384202990038642, "train/extr_reward_mean": 0.04632984297028903, "train/extr_reward_min": -0.4311919064357363, "train/extr_reward_std": 0.1997225863152537, "train/image_loss_mean": 6.563046675714953, "train/image_loss_std": 11.501991485727244, "train/model_loss_mean": 14.49364635862153, "train/model_loss_std": 15.148788202219995, "train/model_opt_grad_norm": 57.40550617349559, "train/model_opt_grad_steps": 44980.1724137931, "train/model_opt_loss": 18373.57826643319, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.2413793103449, "train/policy_entropy_mag": 2.3115551685464792, "train/policy_entropy_max": 2.3115551685464792, "train/policy_entropy_mean": 0.47200609568891855, "train/policy_entropy_min": 0.07937507490659582, "train/policy_entropy_std": 0.5035370989092465, "train/policy_logprob_mag": 7.438383628582132, "train/policy_logprob_max": -0.009455669799755359, "train/policy_logprob_mean": -0.4724536408638132, "train/policy_logprob_min": -7.438383628582132, "train/policy_logprob_std": 1.0275563087956658, "train/policy_randomness_mag": 0.815877536658583, "train/policy_randomness_max": 0.815877536658583, "train/policy_randomness_mean": 0.16659743826964807, "train/policy_randomness_min": 0.02801591824611713, "train/policy_randomness_std": 0.17772649947939248, "train/post_ent_mag": 58.56689303167935, "train/post_ent_max": 58.56689303167935, "train/post_ent_mean": 42.08566944516938, "train/post_ent_min": 20.190633208176184, "train/post_ent_std": 7.330913020824564, "train/prior_ent_mag": 67.5142848573882, "train/prior_ent_max": 67.5142848573882, "train/prior_ent_mean": 55.28661680550411, "train/prior_ent_min": 40.365507954564585, "train/prior_ent_std": 4.505078817236012, "train/rep_loss_mean": 13.120145080829488, "train/rep_loss_std": 8.860212631883293, "train/reward_avg": 0.03128771526289397, "train/reward_loss_mean": 0.0582710696962373, "train/reward_loss_std": 0.25574188016611954, "train/reward_max_data": 1.0193103494315312, "train/reward_max_pred": 1.0116912241639762, "train/reward_neg_acc": 0.993015232990528, "train/reward_neg_loss": 0.029608756958924492, "train/reward_pos_acc": 0.9699101369956444, "train/reward_pos_loss": 0.8365555808461945, "train/reward_pred": 0.030400814867482102, "train/reward_rate": 0.03566810344827586, "train_stats/sum_log_reward": 9.186956755492998, "train_stats/max_log_achievement_collect_coal": 0.5217391304347826, "train_stats/max_log_achievement_collect_drink": 4.413043478260869, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6956521739130435, "train_stats/max_log_achievement_collect_stone": 11.0, "train_stats/max_log_achievement_collect_wood": 10.76086956521739, "train_stats/max_log_achievement_defeat_skeleton": 0.05434782608695652, "train_stats/max_log_achievement_defeat_zombie": 1.0869565217391304, "train_stats/max_log_achievement_eat_cow": 0.15217391304347827, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010869565217391304, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2717391304347827, "train_stats/max_log_achievement_make_wood_sword": 1.2391304347826086, "train_stats/max_log_achievement_place_furnace": 0.043478260869565216, "train_stats/max_log_achievement_place_plant": 1.608695652173913, "train_stats/max_log_achievement_place_stone": 8.706521739130435, "train_stats/max_log_achievement_place_table": 2.902173913043478, "train_stats/max_log_achievement_wake_up": 1.423913043478261, "train_stats/mean_log_entropy": 0.5341411279919355, "eval_stats/sum_log_reward": 7.475000146776438, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 6.25, "eval_stats/max_log_achievement_collect_wood": 7.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 3.8125, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.34257127987803e-07, "report/cont_loss_std": 2.8485262646427145e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.463435521349311e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.169847779347037e-07, "report/cont_pred": 0.9951167702674866, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.064610481262207, "report/dyn_loss_std": 8.536884307861328, "report/image_loss_mean": 6.499272346496582, "report/image_loss_std": 8.304030418395996, "report/model_loss_mean": 15.603791236877441, "report/model_loss_std": 11.805294036865234, "report/post_ent_mag": 58.659175872802734, "report/post_ent_max": 58.659175872802734, "report/post_ent_mean": 40.464942932128906, "report/post_ent_min": 20.387737274169922, "report/post_ent_std": 7.101417541503906, "report/prior_ent_mag": 67.26394653320312, "report/prior_ent_max": 67.26394653320312, "report/prior_ent_mean": 55.52594757080078, "report/prior_ent_min": 43.34202194213867, "report/prior_ent_std": 4.136147499084473, "report/rep_loss_mean": 15.064610481262207, "report/rep_loss_std": 8.536884307861328, "report/reward_avg": 0.04111327975988388, "report/reward_loss_mean": 0.06575357168912888, "report/reward_loss_std": 0.2856611907482147, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1084017753601074, "report/reward_neg_acc": 0.9959058165550232, "report/reward_neg_loss": 0.028416747227311134, "report/reward_pos_acc": 0.9574467539787292, "report/reward_pos_loss": 0.8418828248977661, "report/reward_pred": 0.03965730220079422, "report/reward_rate": 0.0458984375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.313599881948903e-05, "eval/cont_loss_std": 0.0010368619114160538, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006661297287791967, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.131273835308093e-07, "eval/cont_pred": 0.9951486587524414, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.92392921447754, "eval/dyn_loss_std": 10.205519676208496, "eval/image_loss_mean": 9.855243682861328, "eval/image_loss_std": 15.27970027923584, "eval/model_loss_mean": 20.708288192749023, "eval/model_loss_std": 19.0872802734375, "eval/post_ent_mag": 57.11095428466797, "eval/post_ent_max": 57.11095428466797, "eval/post_ent_mean": 39.69082260131836, "eval/post_ent_min": 19.94965171813965, "eval/post_ent_std": 7.166039943695068, "eval/prior_ent_mag": 67.26394653320312, "eval/prior_ent_max": 67.26394653320312, "eval/prior_ent_mean": 54.86852264404297, "eval/prior_ent_min": 42.192283630371094, "eval/prior_ent_std": 4.2884440422058105, "eval/rep_loss_mean": 17.92392921447754, "eval/rep_loss_std": 10.205519676208496, "eval/reward_avg": 0.05869140848517418, "eval/reward_loss_mean": 0.0986548662185669, "eval/reward_loss_std": 0.48592105507850647, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003568172454834, "eval/reward_neg_acc": 0.9958333969116211, "eval/reward_neg_loss": 0.03216230869293213, "eval/reward_pos_acc": 0.921875, "eval/reward_pos_loss": 1.096043348312378, "eval/reward_pred": 0.051968663930892944, "eval/reward_rate": 0.0625, "replay/size": 732897.0, "replay/inserts": 23088.0, "replay/samples": 23088.0, "replay/insert_wait_avg": 1.4653737893636576e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.279303144268583e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3080803123680322e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3588411808014, "timer/env.step_count": 2886.0, "timer/env.step_total": 224.55627846717834, "timer/env.step_frac": 0.22447572733212123, "timer/env.step_avg": 0.07780882829770559, "timer/env.step_min": 0.023520231246948242, "timer/env.step_max": 3.5007224082946777, "timer/replay._sample_count": 23088.0, "timer/replay._sample_total": 11.522215127944946, "timer/replay._sample_frac": 0.011518081965811767, "timer/replay._sample_avg": 0.0004990564417855572, "timer/replay._sample_min": 0.000396728515625, "timer/replay._sample_max": 0.011065959930419922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3478.0, "timer/agent.policy_total": 58.67943716049194, "timer/agent.policy_frac": 0.05865838811523676, "timer/agent.policy_avg": 0.016871603553907977, "timer/agent.policy_min": 0.009427309036254883, "timer/agent.policy_max": 0.12683892250061035, "timer/dataset_train_count": 1443.0, "timer/dataset_train_total": 0.15396499633789062, "timer/dataset_train_frac": 0.00015390976717530056, "timer/dataset_train_avg": 0.00010669784916000736, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0002808570861816406, "timer/agent.train_count": 1443.0, "timer/agent.train_total": 647.6138677597046, "timer/agent.train_frac": 0.6473815605960712, "timer/agent.train_avg": 0.4487968591543344, "timer/agent.train_min": 0.43395423889160156, "timer/agent.train_max": 2.2609822750091553, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47534680366516113, "timer/agent.report_frac": 0.00047517629084386587, "timer/agent.report_avg": 0.23767340183258057, "timer/agent.report_min": 0.23038721084594727, "timer/agent.report_max": 0.24495959281921387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.622662441875462e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 23.07940259370096}
{"step": 733408, "time": 33463.686019182205, "episode/length": 349.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 733520, "time": 33469.40997219086, "episode/length": 277.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 734096, "time": 33490.256183862686, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 734560, "time": 33507.30600595474, "episode/length": 335.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 734568, "time": 33508.86127448082, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 735304, "time": 33535.13613009453, "episode/length": 402.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950372208436724, "episode/intrinsic_return": 0.0}
{"step": 735336, "time": 33537.78245973587, "episode/length": 443.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 735560, "time": 33546.88138651848, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 736064, "time": 33565.57772374153, "episode/length": 245.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 736224, "time": 33572.46510577202, "episode/length": 337.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.0}
{"step": 736496, "time": 33583.11726140976, "episode/length": 241.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 736552, "time": 33586.43844079971, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 737432, "time": 33619.261078596115, "episode/length": 233.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 737448, "time": 33621.26868677139, "episode/length": 524.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9923809523809524, "episode/intrinsic_return": 0.0}
{"step": 737488, "time": 33624.422664403915, "episode/length": 157.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 33634.507865190506, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 737888, "time": 33640.99552369118, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 737992, "time": 33645.91355609894, "episode/length": 240.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 738736, "time": 33672.92405772209, "episode/length": 279.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 738968, "time": 33681.92439365387, "episode/length": 301.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 739168, "time": 33690.43081665039, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 739256, "time": 33694.7025718689, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 739312, "time": 33698.419924259186, "episode/length": 195.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 739352, "time": 33701.18104314804, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 739688, "time": 33713.951083660126, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 740032, "time": 33727.784747600555, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 33750.92706203461, "eval_episode/length": 178.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 740064, "time": 33753.20923280716, "eval_episode/length": 194.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 740064, "time": 33754.97401022911, "eval_episode/length": 198.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 740064, "time": 33757.29775643349, "eval_episode/length": 215.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 740064, "time": 33760.07514190674, "eval_episode/length": 238.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9748953974895398}
{"step": 740064, "time": 33765.274019002914, "eval_episode/length": 323.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9969135802469136}
{"step": 740064, "time": 33766.94577765465, "eval_episode/length": 328.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9848024316109423}
{"step": 740064, "time": 33770.10928821564, "eval_episode/length": 173.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 740272, "time": 33777.02833843231, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 740480, "time": 33785.56479358673, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 740816, "time": 33798.39430141449, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 740920, "time": 33803.16212129593, "episode/length": 218.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 741112, "time": 33811.097536325455, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 741136, "time": 33813.67102980614, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 741424, "time": 33824.93874835968, "episode/length": 216.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 741440, "time": 33826.9211769104, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 741664, "time": 33835.97946667671, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 742400, "time": 33862.032653808594, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 742456, "time": 33865.194516420364, "episode/length": 246.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 742464, "time": 33867.14958810806, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 742544, "time": 33871.39899396896, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 743008, "time": 33888.55063056946, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 743024, "time": 33890.60288023949, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 743344, "time": 33902.740384578705, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 743976, "time": 33925.27020692825, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 744232, "time": 33936.20460319519, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 744312, "time": 33941.17122030258, "episode/length": 231.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 744528, "time": 33950.17552804947, "episode/length": 357.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 744576, "time": 33953.34297347069, "episode/length": 74.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 744936, "time": 33966.833805561066, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 745072, "time": 33973.34420466423, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 745328, "time": 33983.55044865608, "episode/length": 365.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 745344, "time": 33985.58550071716, "episode/length": 50.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 745736, "time": 34001.77842283249, "episode/length": 298.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 745968, "time": 34011.37936449051, "episode/length": 206.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 746008, "time": 34014.07748174667, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 746136, "time": 34019.976518154144, "episode/length": 194.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 746512, "time": 34034.33845829964, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 746976, "time": 34051.50657200813, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 747064, "time": 34055.720556259155, "episode/length": 214.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 748016, "time": 34089.262732982635, "episode/length": 234.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 748288, "time": 34099.93072080612, "episode/length": 469.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.997872340425532, "episode/intrinsic_return": 0.0}
{"step": 748440, "time": 34106.33357644081, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 748480, "time": 34109.45075082779, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9825072886297376, "episode/intrinsic_return": 0.0}
{"step": 749032, "time": 34129.22701382637, "episode/length": 314.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 749272, "time": 34138.7544593811, "episode/length": 407.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9877450980392157, "episode/intrinsic_return": 0.0}
{"step": 749384, "time": 34144.09247493744, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 749400, "time": 34146.168416023254, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34190.202313899994, "eval_episode/length": 132.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 750048, "time": 34194.219838142395, "eval_episode/length": 188.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 750048, "time": 34198.1850566864, "eval_episode/length": 241.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 750048, "time": 34200.00543260574, "eval_episode/length": 246.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9838056680161943}
{"step": 750048, "time": 34204.06921625137, "eval_episode/length": 304.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9868852459016394}
{"step": 750048, "time": 34205.749557971954, "eval_episode/length": 309.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9806451612903225}
{"step": 750048, "time": 34208.85677456856, "eval_episode/length": 212.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 750048, "time": 34211.609597206116, "eval_episode/length": 377.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9894179894179894}
{"step": 750088, "time": 34212.72626519203, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 750480, "time": 34227.682985305786, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 750736, "time": 34238.126250743866, "episode/length": 212.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 750888, "time": 34245.22032618523, "episode/length": 185.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 750960, "time": 34249.90280222893, "episode/length": 314.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 751056, "time": 34254.58982157707, "episode/length": 321.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 751256, "time": 34262.584779024124, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 751536, "time": 34273.87575340271, "episode/length": 59.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 751600, "time": 34277.570425987244, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 751656, "time": 34280.71463918686, "episode/length": 297.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 751728, "time": 34284.942912101746, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 752264, "time": 34304.17967915535, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 752408, "time": 34310.59688067436, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 752464, "time": 34314.71198272705, "episode/length": 215.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 752688, "time": 34324.2499628067, "episode/length": 52.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 752928, "time": 34333.87698864937, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 752984, "time": 34337.06360793114, "episode/length": 180.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 753080, "time": 34341.94431185722, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 753688, "time": 34365.72820544243, "episode/length": 260.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 754008, "time": 34378.00453901291, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 754152, "time": 34384.36667108536, "episode/length": 311.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 754568, "time": 34400.129742622375, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 754704, "time": 34406.561092853546, "episode/length": 251.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 754848, "time": 34412.92136883736, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 754872, "time": 34415.0406191349, "episode/length": 307.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 754912, "time": 34418.319838285446, "episode/length": 247.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9879032258064516, "episode/intrinsic_return": 0.0}
{"step": 755256, "time": 34431.21340203285, "episode/length": 42.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 755544, "time": 34442.46252799034, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 756016, "time": 34460.04224681854, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 756057, "time": 34463.80923485756, "train_stats/sum_log_reward": 9.25789499141668, "train_stats/max_log_achievement_collect_coal": 0.43157894736842106, "train_stats/max_log_achievement_collect_drink": 4.842105263157895, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8105263157894738, "train_stats/max_log_achievement_collect_stone": 11.326315789473684, "train_stats/max_log_achievement_collect_wood": 10.8, "train_stats/max_log_achievement_defeat_skeleton": 0.031578947368421054, "train_stats/max_log_achievement_defeat_zombie": 1.231578947368421, "train_stats/max_log_achievement_eat_cow": 0.2631578947368421, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010526315789473684, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4421052631578948, "train_stats/max_log_achievement_make_wood_sword": 1.2210526315789474, "train_stats/max_log_achievement_place_furnace": 0.042105263157894736, "train_stats/max_log_achievement_place_plant": 1.7578947368421052, "train_stats/max_log_achievement_place_stone": 8.74736842105263, "train_stats/max_log_achievement_place_table": 2.7578947368421054, "train_stats/max_log_achievement_wake_up": 1.305263157894737, "train_stats/mean_log_entropy": 0.5301935330817574, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.241753760804522, "train/action_min": 0.0, "train/action_std": 3.241025836755198, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03966002011711293, "train/actor_opt_grad_steps": 46450.0, "train/actor_opt_loss": -3.2708383749457117, "train/adv_mag": 0.5099384281652194, "train/adv_max": 0.46827579305527056, "train/adv_mean": 0.003903661793316158, "train/adv_min": -0.41258380292577945, "train/adv_std": 0.05643059751877548, "train/cont_avg": 0.9950548537234043, "train/cont_loss_mean": 0.00016722998770593402, "train/cont_loss_std": 0.004980337022081129, "train/cont_neg_acc": 0.9933253402332608, "train/cont_neg_loss": 0.014026407194365582, "train/cont_pos_acc": 0.9999582306713077, "train/cont_pos_loss": 7.639258048239461e-05, "train/cont_pred": 0.9950463657683515, "train/cont_rate": 0.9950548537234043, "train/dyn_loss_mean": 13.061152005026527, "train/dyn_loss_std": 8.844925339340318, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8821901996084984, "train/extr_critic_critic_opt_grad_steps": 46450.0, "train/extr_critic_critic_opt_loss": 15219.795462101063, "train/extr_critic_mag": 8.682542476248233, "train/extr_critic_max": 8.682542476248233, "train/extr_critic_mean": 2.982118645458357, "train/extr_critic_min": -0.13458645428326113, "train/extr_critic_std": 1.9140011393432077, "train/extr_return_normed_mag": 1.5124752064968676, "train/extr_return_normed_max": 1.5124752064968676, "train/extr_return_normed_mean": 0.3992513982539481, "train/extr_return_normed_min": -0.15917091008196485, "train/extr_return_normed_std": 0.3164953108586318, "train/extr_return_rate": 0.9501039381568314, "train/extr_return_raw_mag": 9.85432057346858, "train/extr_return_raw_max": 9.85432057346858, "train/extr_return_raw_mean": 3.0061353149143515, "train/extr_return_raw_min": -0.42962364683337245, "train/extr_return_raw_std": 1.9470884487138573, "train/extr_reward_mag": 1.0449963884150728, "train/extr_reward_max": 1.0449963884150728, "train/extr_reward_mean": 0.04817943107204657, "train/extr_reward_min": -0.41316184253557353, "train/extr_reward_std": 0.2032478761377064, "train/image_loss_mean": 6.603528100548061, "train/image_loss_std": 11.735565773984218, "train/model_loss_mean": 14.499371075461097, "train/model_loss_std": 15.347682432079992, "train/model_opt_grad_norm": 56.78487378654751, "train/model_opt_grad_steps": 46408.77304964539, "train/model_opt_loss": 20532.266698526153, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1418.4397163120568, "train/policy_entropy_mag": 2.3185688248762846, "train/policy_entropy_max": 2.3185688248762846, "train/policy_entropy_mean": 0.47982882333140003, "train/policy_entropy_min": 0.07937506448926655, "train/policy_entropy_std": 0.5273051638129755, "train/policy_logprob_mag": 7.438383731436222, "train/policy_logprob_max": -0.009455662597208581, "train/policy_logprob_mean": -0.47990277790008706, "train/policy_logprob_min": -7.438383731436222, "train/policy_logprob_std": 1.030696340909241, "train/policy_randomness_mag": 0.8183530471849103, "train/policy_randomness_max": 0.8183530471849103, "train/policy_randomness_mean": 0.1693585196919475, "train/policy_randomness_min": 0.028015914458966423, "train/policy_randomness_std": 0.18611558172719697, "train/post_ent_mag": 58.74335433743524, "train/post_ent_max": 58.74335433743524, "train/post_ent_mean": 42.18114790679715, "train/post_ent_min": 20.023803819155862, "train/post_ent_std": 7.378341309567715, "train/prior_ent_mag": 67.50471951099152, "train/prior_ent_max": 67.50471951099152, "train/prior_ent_mean": 55.331647453578654, "train/prior_ent_min": 40.4879024451506, "train/prior_ent_std": 4.514723820043794, "train/rep_loss_mean": 13.061152005026527, "train/rep_loss_std": 8.844925339340318, "train/reward_avg": 0.030657828778873943, "train/reward_loss_mean": 0.05898454914807428, "train/reward_loss_std": 0.25838904051070516, "train/reward_max_data": 1.0234042608991583, "train/reward_max_pred": 1.013635667503303, "train/reward_neg_acc": 0.9924806453657489, "train/reward_neg_loss": 0.030515779826975037, "train/reward_pos_acc": 0.9689134731360362, "train/reward_pos_loss": 0.8424074506083279, "train/reward_pred": 0.029829015994959688, "train/reward_rate": 0.03522550975177305, "eval_stats/sum_log_reward": 9.662500113248825, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 13.125, "eval_stats/max_log_achievement_collect_wood": 11.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 10.3125, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.533112456148956e-05, "report/cont_loss_std": 0.0007310608634725213, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003516933647915721, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.3084774511517026e-05, "report/cont_pred": 0.9931437969207764, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.220985412597656, "report/dyn_loss_std": 9.02572250366211, "report/image_loss_mean": 6.499674320220947, "report/image_loss_std": 11.6757173538208, "report/model_loss_mean": 14.496131896972656, "report/model_loss_std": 15.608264923095703, "report/post_ent_mag": 58.93724060058594, "report/post_ent_max": 58.93724060058594, "report/post_ent_mean": 42.48503494262695, "report/post_ent_min": 18.333206176757812, "report/post_ent_std": 7.59659481048584, "report/prior_ent_mag": 67.86579895019531, "report/prior_ent_max": 67.86579895019531, "report/prior_ent_mean": 55.69200134277344, "report/prior_ent_min": 39.69818115234375, "report/prior_ent_std": 4.726936340332031, "report/rep_loss_mean": 13.220985412597656, "report/rep_loss_std": 9.02572250366211, "report/reward_avg": 0.03085937350988388, "report/reward_loss_mean": 0.06384086608886719, "report/reward_loss_std": 0.2614150643348694, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003582239151001, "report/reward_neg_acc": 0.9949289560317993, "report/reward_neg_loss": 0.039972562342882156, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6831605434417725, "report/reward_pred": 0.03310467302799225, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.090587935934309e-06, "eval/cont_loss_std": 0.0001016187816276215, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008893428603187203, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.190110184434161e-07, "eval/cont_pred": 0.9960966110229492, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.188579559326172, "eval/dyn_loss_std": 10.381675720214844, "eval/image_loss_mean": 9.05370044708252, "eval/image_loss_std": 13.7667875289917, "eval/model_loss_mean": 20.08350372314453, "eval/model_loss_std": 17.90949058532715, "eval/post_ent_mag": 58.978126525878906, "eval/post_ent_max": 58.978126525878906, "eval/post_ent_mean": 39.675811767578125, "eval/post_ent_min": 19.559772491455078, "eval/post_ent_std": 7.040506839752197, "eval/prior_ent_mag": 67.827392578125, "eval/prior_ent_max": 67.827392578125, "eval/prior_ent_mean": 54.8812255859375, "eval/prior_ent_min": 39.115013122558594, "eval/prior_ent_std": 4.343742370605469, "eval/rep_loss_mean": 18.188579559326172, "eval/rep_loss_std": 10.381675720214844, "eval/reward_avg": 0.05615234375, "eval/reward_loss_mean": 0.11665110290050507, "eval/reward_loss_std": 0.5163838267326355, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0654246807098389, "eval/reward_neg_acc": 0.9906445145606995, "eval/reward_neg_loss": 0.04631216824054718, "eval/reward_pos_acc": 0.8709677457809448, "eval/reward_pos_loss": 1.2080390453338623, "eval/reward_pred": 0.04919601231813431, "eval/reward_rate": 0.060546875, "replay/size": 755553.0, "replay/inserts": 22656.0, "replay/samples": 22656.0, "replay/insert_wait_avg": 1.4688588131619038e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.363738156981388e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2191423929360018e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1387615203857, "timer/env.step_count": 2832.0, "timer/env.step_total": 231.41109323501587, "timer/env.step_frac": 0.2313789867350312, "timer/env.step_avg": 0.08171295665078245, "timer/env.step_min": 0.02366042137145996, "timer/env.step_max": 2.2520999908447266, "timer/replay._sample_count": 22656.0, "timer/replay._sample_total": 11.409808874130249, "timer/replay._sample_frac": 0.01140822585136621, "timer/replay._sample_avg": 0.000503610914288941, "timer/replay._sample_min": 0.0004119873046875, "timer/replay._sample_max": 0.010529518127441406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3579.0, "timer/agent.policy_total": 58.70550274848938, "timer/agent.policy_frac": 0.0586973578138765, "timer/agent.policy_avg": 0.016402766903741095, "timer/agent.policy_min": 0.009479522705078125, "timer/agent.policy_max": 0.12323617935180664, "timer/dataset_train_count": 1416.0, "timer/dataset_train_total": 0.15500164031982422, "timer/dataset_train_frac": 0.0001549801350406564, "timer/dataset_train_avg": 0.00010946443525411315, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0008933544158935547, "timer/agent.train_count": 1416.0, "timer/agent.train_total": 634.5712523460388, "timer/agent.train_frac": 0.6344832104910918, "timer/agent.train_avg": 0.4481435397924003, "timer/agent.train_min": 0.43631887435913086, "timer/agent.train_max": 1.6833949089050293, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4707169532775879, "timer/agent.report_frac": 0.000470651644939764, "timer/agent.report_avg": 0.23535847663879395, "timer/agent.report_min": 0.22898221015930176, "timer/agent.report_max": 0.24173474311828613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7175947041848676e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.65254461936304}
{"step": 756176, "time": 34467.87628746033, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 756888, "time": 34493.49679732323, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 756912, "time": 34496.110993385315, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 757032, "time": 34501.37679004669, "episode/length": 377.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 757160, "time": 34507.34152317047, "episode/length": 323.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 757184, "time": 34510.10950946808, "episode/length": 240.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 757248, "time": 34514.381323337555, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 757936, "time": 34539.11473321915, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 758528, "time": 34560.244990587234, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 758560, "time": 34562.81128406525, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 758664, "time": 34567.57348942757, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 758840, "time": 34575.208412885666, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 759296, "time": 34592.10177922249, "episode/length": 169.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 760000, "time": 34617.07252407074, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 34642.59512281418, "eval_episode/length": 177.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 760032, "time": 34644.940495967865, "eval_episode/length": 194.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 760032, "time": 34646.69501590729, "eval_episode/length": 197.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 760032, "time": 34648.68327355385, "eval_episode/length": 203.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 760032, "time": 34650.78640413284, "eval_episode/length": 215.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 760032, "time": 34652.425974845886, "eval_episode/length": 218.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 760032, "time": 34654.222331523895, "eval_episode/length": 224.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 760032, "time": 34656.09746313095, "eval_episode/length": 229.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 760120, "time": 34658.89919924736, "episode/length": 198.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 760608, "time": 34676.906280756, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 760712, "time": 34681.705303668976, "episode/length": 459.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9978260869565218, "episode/intrinsic_return": 0.0}
{"step": 760768, "time": 34685.35645389557, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 760816, "time": 34688.58407306671, "episode/length": 487.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9979508196721312, "episode/intrinsic_return": 0.0}
{"step": 761312, "time": 34706.395287275314, "episode/length": 330.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 761472, "time": 34713.28000354767, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 761936, "time": 34732.05989050865, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 762368, "time": 34748.14130067825, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 762392, "time": 34750.269283533096, "episode/length": 796.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.998745294855709, "episode/intrinsic_return": 0.0}
{"step": 762488, "time": 34755.00520944595, "episode/length": 221.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 762584, "time": 34759.75941491127, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 763304, "time": 34785.237686395645, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 763616, "time": 34797.715586185455, "episode/length": 375.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 763888, "time": 34808.49950027466, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 763912, "time": 34810.68402981758, "episode/length": 189.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 764800, "time": 34842.0996055603, "episode/length": 415.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9831730769230769, "episode/intrinsic_return": 0.0}
{"step": 764808, "time": 34844.150799036026, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 765144, "time": 34857.2144138813, "episode/length": 346.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 765440, "time": 34868.83023095131, "episode/length": 577.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9930795847750865, "episode/intrinsic_return": 0.0}
{"step": 765648, "time": 34877.20123505592, "episode/length": 216.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.0}
{"step": 765816, "time": 34884.66104245186, "episode/length": 240.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 765960, "time": 34891.501809597015, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726962457337884, "episode/intrinsic_return": 0.0}
{"step": 766232, "time": 34902.05657029152, "episode/length": 467.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9978632478632479, "episode/intrinsic_return": 0.0}
{"step": 766360, "time": 34907.76897120476, "episode/length": 194.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 766872, "time": 34926.27157282829, "episode/length": 257.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 766936, "time": 34930.07617998123, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 767160, "time": 34939.00468945503, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 767400, "time": 34948.57362508774, "episode/length": 281.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 767496, "time": 34953.22675490379, "episode/length": 191.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 767600, "time": 34958.52871966362, "episode/length": 170.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 767760, "time": 34965.3185646534, "episode/length": 242.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 768792, "time": 35001.29891562462, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 769000, "time": 35009.891417741776, "episode/length": 329.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996969696969697, "episode/intrinsic_return": 0.0}
{"step": 769472, "time": 35027.39997911453, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 769728, "time": 35037.37751531601, "episode/length": 320.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 769768, "time": 35040.195009469986, "episode/length": 250.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 769960, "time": 35048.645116090775, "episode/length": 307.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35071.40758514404, "eval_episode/length": 141.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9577464788732394}
{"step": 770016, "time": 35074.06332564354, "eval_episode/length": 165.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9819277108433735}
{"step": 770016, "time": 35077.13160085678, "eval_episode/length": 200.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9850746268656716}
{"step": 770016, "time": 35079.013763427734, "eval_episode/length": 205.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 770016, "time": 35080.646234989166, "eval_episode/length": 206.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 770016, "time": 35083.37732219696, "eval_episode/length": 234.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 770016, "time": 35085.460359334946, "eval_episode/length": 248.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 770016, "time": 35091.8999376297, "eval_episode/length": 219.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 770160, "time": 35098.50128388405, "episode/length": 319.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 770488, "time": 35110.79973912239, "episode/length": 443.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 770944, "time": 35127.65200304985, "episode/length": 242.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 771432, "time": 35145.23925471306, "episode/length": 212.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 771664, "time": 35154.79760122299, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 771776, "time": 35160.066712617874, "episode/length": 160.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 771880, "time": 35164.85750746727, "episode/length": 300.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 771912, "time": 35167.42554521561, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 771960, "time": 35170.676743507385, "episode/length": 273.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 772616, "time": 35194.026153087616, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 772784, "time": 35201.520851135254, "episode/length": 102.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 772960, "time": 35208.81138563156, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 773336, "time": 35222.60385251045, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 773464, "time": 35228.96116566658, "episode/length": 253.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 773488, "time": 35231.56130552292, "episode/length": 227.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 773568, "time": 35235.85569906235, "episode/length": 425.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 773624, "time": 35239.036697626114, "episode/length": 213.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 774208, "time": 35260.17973566055, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 774376, "time": 35267.14710736275, "episode/length": 219.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 774432, "time": 35271.2786796093, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 775416, "time": 35305.649228572845, "episode/length": 240.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 775464, "time": 35308.82209253311, "episode/length": 236.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 775576, "time": 35314.19143199921, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 775640, "time": 35318.07502532005, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 775760, "time": 35323.866482019424, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 776232, "time": 35340.843502521515, "episode/length": 361.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972375690607734, "episode/intrinsic_return": 0.0}
{"step": 776856, "time": 35363.165298461914, "episode/length": 423.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 777048, "time": 35371.07158899307, "episode/length": 326.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 777104, "time": 35374.72447824478, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 777160, "time": 35377.85250329971, "episode/length": 441.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 777248, "time": 35382.76600456238, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 777336, "time": 35386.99966311455, "episode/length": 196.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 777528, "time": 35394.92253088951, "episode/length": 243.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 778248, "time": 35420.93609881401, "episode/length": 251.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 778656, "time": 35437.824293613434, "episode/length": 164.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 779176, "time": 35456.56633019447, "episode/length": 251.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 779312, "time": 35462.94791531563, "episode/length": 306.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 779313, "time": 35465.12617492676, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.1692132819188785, "train/action_min": 0.0, "train/action_std": 3.1581495592038924, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03775461366374607, "train/actor_opt_grad_steps": 47885.0, "train/actor_opt_loss": -5.008391955535706, "train/adv_mag": 0.4856338309098596, "train/adv_max": 0.4423449553855478, "train/adv_mean": 0.003256805606791777, "train/adv_min": -0.4010114857595261, "train/adv_std": 0.05429174013639966, "train/cont_avg": 0.9948763912671232, "train/cont_loss_mean": 0.00012944054145555285, "train/cont_loss_std": 0.003686414733460754, "train/cont_neg_acc": 0.9960045663461293, "train/cont_neg_loss": 0.010272701389408523, "train/cont_pos_acc": 0.9999596398987182, "train/cont_pos_loss": 8.636055269910028e-05, "train/cont_pred": 0.9948596786962797, "train/cont_rate": 0.9948763912671232, "train/dyn_loss_mean": 13.064218913039117, "train/dyn_loss_std": 8.865511551295242, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.881614332737988, "train/extr_critic_critic_opt_grad_steps": 47885.0, "train/extr_critic_critic_opt_loss": 15098.718489137415, "train/extr_critic_mag": 9.098163108303122, "train/extr_critic_max": 9.098163108303122, "train/extr_critic_mean": 3.094362066216665, "train/extr_critic_min": -0.13820014914421186, "train/extr_critic_std": 2.0631989069180947, "train/extr_return_normed_mag": 1.4978772442634791, "train/extr_return_normed_max": 1.4978772442634791, "train/extr_return_normed_mean": 0.3988365741216973, "train/extr_return_normed_min": -0.15299607333663393, "train/extr_return_normed_std": 0.3229332593818233, "train/extr_return_rate": 0.9435493856260221, "train/extr_return_raw_mag": 10.250558650656922, "train/extr_return_raw_max": 10.250558650656922, "train/extr_return_raw_mean": 3.1154806352641486, "train/extr_return_raw_min": -0.4658167516327884, "train/extr_return_raw_std": 2.096618792782091, "train/extr_reward_mag": 1.0369819108753988, "train/extr_reward_max": 1.0369819108753988, "train/extr_reward_mean": 0.04901175096324862, "train/extr_reward_min": -0.40770151190561793, "train/extr_reward_std": 0.204968369170411, "train/image_loss_mean": 6.618234970798231, "train/image_loss_std": 11.465067471543403, "train/model_loss_mean": 14.51516312115813, "train/model_loss_std": 15.102923759042401, "train/model_opt_grad_norm": 52.91869756620224, "train/model_opt_grad_steps": 47842.57534246575, "train/model_opt_loss": 20173.483485391695, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1386.986301369863, "train/policy_entropy_mag": 2.321610734887319, "train/policy_entropy_max": 2.321610734887319, "train/policy_entropy_mean": 0.47167429246314585, "train/policy_entropy_min": 0.07937505351353998, "train/policy_entropy_std": 0.5181500144200782, "train/policy_logprob_mag": 7.438383729490515, "train/policy_logprob_max": -0.00945566161471891, "train/policy_logprob_mean": -0.4712239585510672, "train/policy_logprob_min": -7.438383729490515, "train/policy_logprob_std": 1.0239629961856425, "train/policy_randomness_mag": 0.819426711699734, "train/policy_randomness_max": 0.819426711699734, "train/policy_randomness_mean": 0.1664803259789127, "train/policy_randomness_min": 0.028015910609535975, "train/policy_randomness_std": 0.1828842187580997, "train/post_ent_mag": 58.642109465925664, "train/post_ent_max": 58.642109465925664, "train/post_ent_mean": 42.33108269678403, "train/post_ent_min": 19.900383256886105, "train/post_ent_std": 7.378680281443138, "train/prior_ent_mag": 67.49709246909782, "train/prior_ent_max": 67.49709246909782, "train/prior_ent_mean": 55.45119546864131, "train/prior_ent_min": 40.99984419835757, "train/prior_ent_std": 4.519520258250302, "train/rep_loss_mean": 13.064218913039117, "train/rep_loss_std": 8.865511551295242, "train/reward_avg": 0.03057577050201697, "train/reward_loss_mean": 0.05826745927333832, "train/reward_loss_std": 0.2525756182531788, "train/reward_max_data": 1.0198630184343416, "train/reward_max_pred": 1.0117777243052444, "train/reward_neg_acc": 0.99258665965028, "train/reward_neg_loss": 0.03040721769482918, "train/reward_pos_acc": 0.9714832228340514, "train/reward_pos_loss": 0.8287520576013278, "train/reward_pred": 0.02985125367389354, "train/reward_rate": 0.03506260702054795, "train_stats/sum_log_reward": 9.684269875622867, "train_stats/max_log_achievement_collect_coal": 0.42696629213483145, "train_stats/max_log_achievement_collect_drink": 5.49438202247191, "train_stats/max_log_achievement_collect_iron": 0.011235955056179775, "train_stats/max_log_achievement_collect_sapling": 1.5280898876404494, "train_stats/max_log_achievement_collect_stone": 13.52808988764045, "train_stats/max_log_achievement_collect_wood": 11.438202247191011, "train_stats/max_log_achievement_defeat_skeleton": 0.056179775280898875, "train_stats/max_log_achievement_defeat_zombie": 1.1348314606741574, "train_stats/max_log_achievement_eat_cow": 0.29213483146067415, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02247191011235955, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6067415730337078, "train_stats/max_log_achievement_make_wood_sword": 1.2359550561797752, "train_stats/max_log_achievement_place_furnace": 0.0449438202247191, "train_stats/max_log_achievement_place_plant": 1.4269662921348314, "train_stats/max_log_achievement_place_stone": 11.595505617977528, "train_stats/max_log_achievement_place_table": 3.134831460674157, "train_stats/max_log_achievement_wake_up": 1.5056179775280898, "train_stats/mean_log_entropy": 0.550919307751602, "eval_stats/sum_log_reward": 9.037500143051147, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.9375, "eval_stats/max_log_achievement_collect_stone": 11.0, "eval_stats/max_log_achievement_collect_wood": 9.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.9375, "eval_stats/max_log_achievement_place_stone": 8.4375, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 9.830861381487921e-05, "report/cont_loss_std": 0.003055427921935916, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.011112433858215809, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.464176749432227e-07, "report/cont_pred": 0.9913034439086914, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 12.744131088256836, "report/dyn_loss_std": 8.898497581481934, "report/image_loss_mean": 5.482576370239258, "report/image_loss_std": 10.959473609924316, "report/model_loss_mean": 13.198505401611328, "report/model_loss_std": 14.84998893737793, "report/post_ent_mag": 56.921302795410156, "report/post_ent_max": 56.921302795410156, "report/post_ent_mean": 42.58374786376953, "report/post_ent_min": 18.64438247680664, "report/post_ent_std": 7.169413089752197, "report/prior_ent_mag": 67.81526947021484, "report/prior_ent_max": 67.81526947021484, "report/prior_ent_mean": 55.48232650756836, "report/prior_ent_min": 34.176849365234375, "report/prior_ent_std": 4.2719526290893555, "report/rep_loss_mean": 12.744131088256836, "report/rep_loss_std": 8.898497581481934, "report/reward_avg": 0.03134765475988388, "report/reward_loss_mean": 0.06935197114944458, "report/reward_loss_std": 0.3002717196941376, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.010028600692749, "report/reward_neg_acc": 0.9908629655838013, "report/reward_neg_loss": 0.03797277808189392, "report/reward_pos_acc": 0.9487179517745972, "report/reward_pos_loss": 0.8618777394294739, "report/reward_pred": 0.029644038528203964, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.261342135374434e-05, "eval/cont_loss_std": 0.000578245846554637, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006150062661617994, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.62342585605802e-06, "eval/cont_pred": 0.996109127998352, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.969585418701172, "eval/dyn_loss_std": 10.235243797302246, "eval/image_loss_mean": 9.964910507202148, "eval/image_loss_std": 12.696188926696777, "eval/model_loss_mean": 20.271759033203125, "eval/model_loss_std": 16.821640014648438, "eval/post_ent_mag": 58.92433166503906, "eval/post_ent_max": 58.92433166503906, "eval/post_ent_mean": 41.02886199951172, "eval/post_ent_min": 19.464786529541016, "eval/post_ent_std": 7.5683674812316895, "eval/prior_ent_mag": 67.81526947021484, "eval/prior_ent_max": 67.81526947021484, "eval/prior_ent_mean": 55.57158660888672, "eval/prior_ent_min": 45.85968780517578, "eval/prior_ent_std": 4.017597198486328, "eval/rep_loss_mean": 16.969585418701172, "eval/rep_loss_std": 10.235243797302246, "eval/reward_avg": 0.04931640625, "eval/reward_loss_mean": 0.1250647008419037, "eval/reward_loss_std": 0.6213059425354004, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0011622905731201, "eval/reward_neg_acc": 0.9845361113548279, "eval/reward_neg_loss": 0.04297833889722824, "eval/reward_pos_acc": 0.8333333134651184, "eval/reward_pos_loss": 1.599579095840454, "eval/reward_pred": 0.04202237352728844, "eval/reward_rate": 0.052734375, "replay/size": 778809.0, "replay/inserts": 23256.0, "replay/samples": 23248.0, "replay/insert_wait_avg": 1.4550955713020799e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.442495626986478e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.229748532578752e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3012952804565, "timer/env.step_count": 2907.0, "timer/env.step_total": 224.78200149536133, "timer/env.step_frac": 0.22448987388196845, "timer/env.step_avg": 0.07732438991928495, "timer/env.step_min": 0.02310967445373535, "timer/env.step_max": 3.2081289291381836, "timer/replay._sample_count": 23248.0, "timer/replay._sample_total": 11.69999885559082, "timer/replay._sample_frac": 0.011684793488970514, "timer/replay._sample_avg": 0.0005032690491909334, "timer/replay._sample_min": 0.000408172607421875, "timer/replay._sample_max": 0.008582592010498047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3499.0, "timer/agent.policy_total": 59.257607221603394, "timer/agent.policy_frac": 0.05918059579160517, "timer/agent.policy_avg": 0.016935583658646298, "timer/agent.policy_min": 0.00953984260559082, "timer/agent.policy_max": 0.1325075626373291, "timer/dataset_train_count": 1453.0, "timer/dataset_train_total": 0.1564619541168213, "timer/dataset_train_frac": 0.00015625861551791715, "timer/dataset_train_avg": 0.00010768200558625003, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0008971691131591797, "timer/agent.train_count": 1453.0, "timer/agent.train_total": 647.1880474090576, "timer/agent.train_frac": 0.6463469591615633, "timer/agent.train_avg": 0.445415036069551, "timer/agent.train_min": 0.4314546585083008, "timer/agent.train_max": 1.6824414730072021, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47126317024230957, "timer/agent.report_frac": 0.0004706507146885419, "timer/agent.report_avg": 0.23563158512115479, "timer/agent.report_min": 0.22972464561462402, "timer/agent.report_max": 0.24153852462768555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.262089591901039e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 23.225418239474187}
{"step": 779336, "time": 35465.82973051071, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 779512, "time": 35473.54730939865, "episode/length": 307.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 779528, "time": 35475.67822885513, "episode/length": 302.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 779544, "time": 35477.68407225609, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35510.25144529343, "eval_episode/length": 56.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 780000, "time": 35516.433785915375, "eval_episode/length": 162.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9631901840490797}
{"step": 780000, "time": 35518.515023469925, "eval_episode/length": 173.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 780000, "time": 35518.52326273918, "eval_episode/length": 173.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9597701149425287}
{"step": 780000, "time": 35522.893377542496, "eval_episode/length": 199.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.995}
{"step": 780000, "time": 35525.30678129196, "eval_episode/length": 217.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 780000, "time": 35528.57243204117, "eval_episode/length": 250.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9800796812749004}
{"step": 780000, "time": 35530.97633886337, "eval_episode/length": 213.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 780192, "time": 35537.46089243889, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 780256, "time": 35541.77112674713, "episode/length": 250.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 780840, "time": 35563.365251779556, "episode/length": 72.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 780968, "time": 35569.16859149933, "episode/length": 177.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 781112, "time": 35575.53859233856, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 781120, "time": 35577.72648859024, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 781376, "time": 35587.61206483841, "episode/length": 32.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 782008, "time": 35610.00578761101, "episode/length": 333.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 782040, "time": 35612.583015441895, "episode/length": 357.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 782168, "time": 35618.42689156532, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 782464, "time": 35630.19894194603, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 782744, "time": 35640.76230311394, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 782864, "time": 35646.502805233, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 782968, "time": 35651.39703583717, "episode/length": 230.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 783424, "time": 35668.24065327644, "episode/length": 486.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.997946611909651, "episode/intrinsic_return": 0.0}
{"step": 783456, "time": 35670.75115418434, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 783536, "time": 35675.0041282177, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 783848, "time": 35686.901634693146, "episode/length": 38.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 784072, "time": 35695.987345695496, "episode/length": 150.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 784088, "time": 35698.133254528046, "episode/length": 167.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 784336, "time": 35708.14813375473, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 784984, "time": 35730.85256791115, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 785208, "time": 35739.95173740387, "episode/length": 222.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 785328, "time": 35745.71133828163, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 785552, "time": 35754.83602643013, "episode/length": 261.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 786096, "time": 35774.65907263756, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 786368, "time": 35785.351147174835, "episode/length": 524.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9980952380952381, "episode/intrinsic_return": 0.0}
{"step": 786392, "time": 35787.48136091232, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 786464, "time": 35793.50579214096, "episode/length": 265.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 787224, "time": 35820.128286123276, "episode/length": 391.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 787400, "time": 35827.53282403946, "episode/length": 230.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 787696, "time": 35839.047550201416, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 787768, "time": 35842.7368850708, "episode/length": 347.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 788040, "time": 35853.36822557449, "episode/length": 242.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 788088, "time": 35856.53813910484, "episode/length": 359.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 788296, "time": 35865.17898106575, "episode/length": 240.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 788848, "time": 35885.324924468994, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 788872, "time": 35887.452218294144, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 789184, "time": 35899.783358335495, "episode/length": 339.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 789848, "time": 35923.39656615257, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 790032, "time": 35931.29276037216, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 35959.91566848755, "eval_episode/length": 193.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 790088, "time": 35962.358911037445, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 790088, "time": 35965.58306694031, "eval_episode/length": 226.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 790088, "time": 35968.71736454964, "eval_episode/length": 240.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.995850622406639}
{"step": 790088, "time": 35970.588646411896, "eval_episode/length": 248.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 790088, "time": 35972.55042529106, "eval_episode/length": 257.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9961240310077519}
{"step": 790088, "time": 35974.76309943199, "eval_episode/length": 266.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 790088, "time": 35977.01428961754, "eval_episode/length": 280.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9715302491103203}
{"step": 790112, "time": 35978.08573579788, "episode/length": 115.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 790184, "time": 35981.821189165115, "episode/length": 163.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 790272, "time": 35986.46623659134, "episode/length": 278.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 790456, "time": 35993.84291219711, "episode/length": 381.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9921465968586387, "episode/intrinsic_return": 0.0}
{"step": 791080, "time": 36016.00996565819, "episode/length": 278.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 791472, "time": 36030.77560734749, "episode/length": 160.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 791536, "time": 36034.446484327316, "episode/length": 187.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 791576, "time": 36037.13314628601, "episode/length": 162.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 791736, "time": 36044.20381855965, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 791800, "time": 36047.92434358597, "episode/length": 463.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9892241379310345, "episode/intrinsic_return": 0.0}
{"step": 791952, "time": 36054.69446706772, "episode/length": 46.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 791984, "time": 36057.33980631828, "episode/length": 266.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 792544, "time": 36077.557151556015, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 792888, "time": 36090.1679289341, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 793048, "time": 36096.93310189247, "episode/length": 136.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 793384, "time": 36109.74928331375, "episode/length": 197.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 793648, "time": 36120.249803066254, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 793664, "time": 36122.305594444275, "episode/length": 265.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 794160, "time": 36140.34580373764, "episode/length": 158.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 794360, "time": 36148.436035871506, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 794376, "time": 36151.11225557327, "episode/length": 489.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 794728, "time": 36166.533501148224, "episode/length": 134.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 794768, "time": 36169.57032036781, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 795120, "time": 36182.75824189186, "episode/length": 321.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 795480, "time": 36196.08433532715, "episode/length": 436.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9908466819221968, "episode/intrinsic_return": 0.0}
{"step": 795656, "time": 36203.44753694534, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 795928, "time": 36214.08835554123, "episode/length": 195.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 796080, "time": 36221.138239860535, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 796320, "time": 36230.707666158676, "episode/length": 198.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 796632, "time": 36242.41596651077, "episode/length": 370.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 797080, "time": 36259.1331307888, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 797104, "time": 36262.196405887604, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 797432, "time": 36274.99650788307, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 797840, "time": 36290.40277504921, "episode/length": 238.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 797904, "time": 36294.1850168705, "episode/length": 58.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 798168, "time": 36304.25597476959, "episode/length": 230.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 798296, "time": 36310.10050988197, "episode/length": 440.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 798328, "time": 36312.77466630936, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 798352, "time": 36315.39991044998, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 799320, "time": 36348.84429216385, "episode/length": 457.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 799368, "time": 36352.04689788818, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 799656, "time": 36363.19432210922, "episode/length": 218.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 799688, "time": 36365.70832276344, "episode/length": 189.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 799928, "time": 36375.240213871, "episode/length": 411.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 36398.180129766464, "eval_episode/length": 78.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9240506329113924}
{"step": 800072, "time": 36404.23408579826, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 800072, "time": 36406.50026893616, "eval_episode/length": 198.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 800072, "time": 36409.773634433746, "eval_episode/length": 236.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 800072, "time": 36411.709730148315, "eval_episode/length": 242.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 800072, "time": 36414.95588374138, "eval_episode/length": 280.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.99644128113879}
{"step": 800072, "time": 36417.61699843407, "eval_episode/length": 227.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 800072, "time": 36420.43862080574, "eval_episode/length": 134.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 800336, "time": 36429.489433288574, "episode/length": 254.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 800424, "time": 36433.84030723572, "episode/length": 261.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 800528, "time": 36439.065858364105, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 800856, "time": 36451.3153116703, "episode/length": 191.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 801209, "time": 36465.540581941605, "train_stats/sum_log_reward": 9.347312020999128, "train_stats/max_log_achievement_collect_coal": 0.44086021505376344, "train_stats/max_log_achievement_collect_drink": 4.247311827956989, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8279569892473118, "train_stats/max_log_achievement_collect_stone": 12.118279569892474, "train_stats/max_log_achievement_collect_wood": 10.591397849462366, "train_stats/max_log_achievement_defeat_skeleton": 0.08602150537634409, "train_stats/max_log_achievement_defeat_zombie": 1.1290322580645162, "train_stats/max_log_achievement_eat_cow": 0.24731182795698925, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5268817204301075, "train_stats/max_log_achievement_make_wood_sword": 1.4623655913978495, "train_stats/max_log_achievement_place_furnace": 0.03225806451612903, "train_stats/max_log_achievement_place_plant": 1.7634408602150538, "train_stats/max_log_achievement_place_stone": 10.505376344086022, "train_stats/max_log_achievement_place_table": 2.956989247311828, "train_stats/max_log_achievement_wake_up": 1.3978494623655915, "train_stats/mean_log_entropy": 0.510889155890352, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.270233154296875, "train/action_min": 0.0, "train/action_std": 3.1664138436317444, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03764460118049208, "train/actor_opt_grad_steps": 49295.0, "train/actor_opt_loss": -7.426900514264537, "train/adv_mag": 0.5017176092985798, "train/adv_max": 0.44143541266812997, "train/adv_mean": 0.002615421547870971, "train/adv_min": -0.4096812548882821, "train/adv_std": 0.05342561127070118, "train/cont_avg": 0.9950094784007353, "train/cont_loss_mean": 0.00025499358086785784, "train/cont_loss_std": 0.007611074617683922, "train/cont_neg_acc": 0.9944152669871554, "train/cont_neg_loss": 0.029266987097347444, "train/cont_pos_acc": 0.9999638936098885, "train/cont_pos_loss": 0.0001187661678444464, "train/cont_pred": 0.994987263399012, "train/cont_rate": 0.9950094784007353, "train/dyn_loss_mean": 13.039940546540652, "train/dyn_loss_std": 8.908082422088174, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.894420762272442, "train/extr_critic_critic_opt_grad_steps": 49295.0, "train/extr_critic_critic_opt_loss": 15027.840375114889, "train/extr_critic_mag": 9.379702995805179, "train/extr_critic_max": 9.379702995805179, "train/extr_critic_mean": 3.161750595359241, "train/extr_critic_min": -0.12595458328723907, "train/extr_critic_std": 2.1558820254662456, "train/extr_return_normed_mag": 1.4928554769824534, "train/extr_return_normed_max": 1.4928554769824534, "train/extr_return_normed_mean": 0.3998620319454109, "train/extr_return_normed_min": -0.14281018050935337, "train/extr_return_normed_std": 0.32530333331840877, "train/extr_return_rate": 0.9341112813528847, "train/extr_return_raw_mag": 10.53368609793046, "train/extr_return_raw_max": 10.53368609793046, "train/extr_return_raw_mean": 3.1793329663136425, "train/extr_return_raw_min": -0.4711695150198305, "train/extr_return_raw_std": 2.1886212983552147, "train/extr_reward_mag": 1.0396591933334576, "train/extr_reward_max": 1.0396591933334576, "train/extr_reward_mean": 0.04927451111485853, "train/extr_reward_min": -0.42653612704838023, "train/extr_reward_std": 0.20568003209636493, "train/image_loss_mean": 6.5779208260424, "train/image_loss_std": 11.708364409558913, "train/model_loss_mean": 14.46096793343039, "train/model_loss_std": 15.32053810708663, "train/model_opt_grad_norm": 56.22092866897583, "train/model_opt_grad_steps": 49251.16176470588, "train/model_opt_loss": 17864.38816205193, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1231.6176470588234, "train/policy_entropy_mag": 2.3626184936831978, "train/policy_entropy_max": 2.3626184936831978, "train/policy_entropy_mean": 0.4728841439766042, "train/policy_entropy_min": 0.07937504340182333, "train/policy_entropy_std": 0.5260541406186188, "train/policy_logprob_mag": 7.438383772092707, "train/policy_logprob_max": -0.009455661042867339, "train/policy_logprob_mean": -0.47354179883704467, "train/policy_logprob_min": -7.438383772092707, "train/policy_logprob_std": 1.0287447549840982, "train/policy_randomness_mag": 0.8339006466900601, "train/policy_randomness_max": 0.8339006466900601, "train/policy_randomness_mean": 0.16690735025879214, "train/policy_randomness_min": 0.028015906908823288, "train/policy_randomness_std": 0.1856740268276018, "train/post_ent_mag": 58.778706803041345, "train/post_ent_max": 58.778706803041345, "train/post_ent_mean": 42.247430100160486, "train/post_ent_min": 19.945549109402826, "train/post_ent_std": 7.409062729162328, "train/prior_ent_mag": 67.61839328092687, "train/prior_ent_max": 67.61839328092687, "train/prior_ent_mean": 55.364839778226965, "train/prior_ent_min": 40.649116824654975, "train/prior_ent_std": 4.554151066962411, "train/rep_loss_mean": 13.039940546540652, "train/rep_loss_std": 8.908082422088174, "train/reward_avg": 0.03115880611243055, "train/reward_loss_mean": 0.05882787110064836, "train/reward_loss_std": 0.2561264314195689, "train/reward_max_data": 1.0191176516168259, "train/reward_max_pred": 1.015099766499856, "train/reward_neg_acc": 0.9928348577197861, "train/reward_neg_loss": 0.030471194747780615, "train/reward_pos_acc": 0.9714647592867122, "train/reward_pos_loss": 0.8298813516602797, "train/reward_pred": 0.030322825686786983, "train/reward_rate": 0.03565171185661765, "eval_stats/sum_log_reward": 9.14166690905889, "eval_stats/max_log_achievement_collect_coal": 0.4583333333333333, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5833333333333333, "eval_stats/max_log_achievement_collect_stone": 8.916666666666666, "eval_stats/max_log_achievement_collect_wood": 9.041666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 1.2083333333333333, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4583333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.1666666666666667, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5833333333333333, "eval_stats/max_log_achievement_place_stone": 7.5, "eval_stats/max_log_achievement_place_table": 2.5833333333333335, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 4.380072823551018e-06, "report/cont_loss_std": 3.4797041735146195e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1537620594026521e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.323714620113606e-06, "report/cont_pred": 0.9921833276748657, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.975410461425781, "report/dyn_loss_std": 8.63375186920166, "report/image_loss_mean": 5.543881893157959, "report/image_loss_std": 9.406209945678711, "report/model_loss_mean": 12.776219367980957, "report/model_loss_std": 12.925272941589355, "report/post_ent_mag": 59.535457611083984, "report/post_ent_max": 59.535457611083984, "report/post_ent_mean": 42.601409912109375, "report/post_ent_min": 20.511486053466797, "report/post_ent_std": 7.2487897872924805, "report/prior_ent_mag": 67.8429183959961, "report/prior_ent_max": 67.8429183959961, "report/prior_ent_mean": 54.51521301269531, "report/prior_ent_min": 35.556640625, "report/prior_ent_std": 4.989290237426758, "report/rep_loss_mean": 11.975410461425781, "report/rep_loss_std": 8.63375186920166, "report/reward_avg": 0.02929687313735485, "report/reward_loss_mean": 0.047086041420698166, "report/reward_loss_std": 0.18320094048976898, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005669593811035, "report/reward_neg_acc": 0.997973620891571, "report/reward_neg_loss": 0.019392916932702065, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.7858188152313232, "report/reward_pred": 0.027058463543653488, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0020257493015378714, "eval/cont_loss_std": 0.06458766013383865, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.41356754302978516, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.408217814168893e-06, "eval/cont_pred": 0.9959638714790344, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.86774444580078, "eval/dyn_loss_std": 10.71091365814209, "eval/image_loss_mean": 9.387475967407227, "eval/image_loss_std": 12.649377822875977, "eval/model_loss_mean": 19.611791610717773, "eval/model_loss_std": 16.932233810424805, "eval/post_ent_mag": 60.640235900878906, "eval/post_ent_max": 60.640235900878906, "eval/post_ent_mean": 40.96649169921875, "eval/post_ent_min": 19.2541446685791, "eval/post_ent_std": 7.743014335632324, "eval/prior_ent_mag": 67.8429183959961, "eval/prior_ent_max": 67.8429183959961, "eval/prior_ent_mean": 55.24143600463867, "eval/prior_ent_min": 42.98663330078125, "eval/prior_ent_std": 4.324233055114746, "eval/rep_loss_mean": 16.86774444580078, "eval/rep_loss_std": 10.71091365814209, "eval/reward_avg": 0.03369140625, "eval/reward_loss_mean": 0.10164281725883484, "eval/reward_loss_std": 0.6201362609863281, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023365020751953, "eval/reward_neg_acc": 0.9939086437225342, "eval/reward_neg_loss": 0.05004551261663437, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.404805302619934, "eval/reward_pred": 0.03098374232649803, "eval/reward_rate": 0.0380859375, "replay/size": 800705.0, "replay/inserts": 21896.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.4793581016576765e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.474047263056976e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2517311772159207e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3978719711304, "timer/env.step_count": 2737.0, "timer/env.step_total": 223.42521905899048, "timer/env.step_frac": 0.2233363597812992, "timer/env.step_avg": 0.081631428227618, "timer/env.step_min": 0.023267745971679688, "timer/env.step_max": 2.1686885356903076, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 11.014563798904419, "timer/replay._sample_frac": 0.011010183155629781, "timer/replay._sample_avg": 0.0005028562727768636, "timer/replay._sample_min": 0.0004265308380126953, "timer/replay._sample_max": 0.008794307708740234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3623.0, "timer/agent.policy_total": 60.14239740371704, "timer/agent.policy_frac": 0.06011847794639515, "timer/agent.policy_avg": 0.016600164892000287, "timer/agent.policy_min": 0.009441852569580078, "timer/agent.policy_max": 0.12362241744995117, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.14847588539123535, "timer/dataset_train_frac": 0.0001484168344927468, "timer/dataset_train_avg": 0.00010845572344136987, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0008480548858642578, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 609.3794605731964, "timer/agent.train_frac": 0.6091371019937375, "timer/agent.train_avg": 0.44512743650343056, "timer/agent.train_min": 0.43213534355163574, "timer/agent.train_max": 1.6356735229492188, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47301626205444336, "timer/agent.report_frac": 0.0004728281369915726, "timer/agent.report_avg": 0.23650813102722168, "timer/agent.report_min": 0.22856736183166504, "timer/agent.report_max": 0.24444890022277832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217370716242365e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 21.886994212066874}
{"step": 801304, "time": 36468.57383394241, "episode/length": 201.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 801320, "time": 36470.674297094345, "episode/length": 243.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 801808, "time": 36489.014159202576, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 801848, "time": 36492.285703897476, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 802152, "time": 36504.70709967613, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 802216, "time": 36508.93379187584, "episode/length": 319.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 802304, "time": 36513.57884097099, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 802376, "time": 36517.328394412994, "episode/length": 243.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 802808, "time": 36533.20247769356, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 802968, "time": 36541.61539173126, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 803472, "time": 36560.983680963516, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 803488, "time": 36563.16781044006, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 803928, "time": 36579.38763833046, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 803984, "time": 36583.10523271561, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 804024, "time": 36585.76593184471, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 804320, "time": 36597.34940743446, "episode/length": 188.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 804536, "time": 36605.92974567413, "episode/length": 195.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 805656, "time": 36644.93960094452, "episode/length": 418.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 805832, "time": 36652.28510379791, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 806184, "time": 36665.49391961098, "episode/length": 274.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 806328, "time": 36672.042744636536, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 806352, "time": 36674.714500427246, "episode/length": 302.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 806472, "time": 36679.9479162693, "episode/length": 374.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946666666666667, "episode/intrinsic_return": 0.0}
{"step": 807488, "time": 36715.50996565819, "episode/length": 368.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989159891598916, "episode/intrinsic_return": 0.0}
{"step": 807640, "time": 36722.10025572777, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 807848, "time": 36731.479609012604, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 808208, "time": 36746.12835121155, "episode/length": 589.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 808752, "time": 36766.126883268356, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 808808, "time": 36769.34346294403, "episode/length": 393.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9822335025380711, "episode/intrinsic_return": 0.0}
{"step": 808968, "time": 36776.31891012192, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 809048, "time": 36780.50983476639, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 809464, "time": 36796.015191316605, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 809720, "time": 36806.151185035706, "episode/length": 441.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 36834.884155750275, "eval_episode/length": 66.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9850746268656716}
{"step": 810056, "time": 36839.52629613876, "eval_episode/length": 136.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 810056, "time": 36842.89767765999, "eval_episode/length": 178.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9608938547486033}
{"step": 810056, "time": 36845.78543758392, "eval_episode/length": 205.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 810056, "time": 36847.79780125618, "eval_episode/length": 148.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 810056, "time": 36850.96917152405, "eval_episode/length": 247.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 810056, "time": 36855.38058066368, "eval_episode/length": 312.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9968051118210862}
{"step": 810056, "time": 36859.443353652954, "eval_episode/length": 157.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 810504, "time": 36874.32230234146, "episode/length": 286.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 810880, "time": 36888.72887015343, "episode/length": 228.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 810912, "time": 36891.33584547043, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 810928, "time": 36893.364624500275, "episode/length": 244.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 810984, "time": 36896.533982515335, "episode/length": 271.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 811056, "time": 36902.58896660805, "episode/length": 587.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 811064, "time": 36904.29871106148, "episode/length": 288.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9930795847750865, "episode/intrinsic_return": 0.0}
{"step": 811696, "time": 36926.98392009735, "episode/length": 246.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 811976, "time": 36937.37492799759, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 812128, "time": 36944.28789281845, "episode/length": 151.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 812216, "time": 36948.59196829796, "episode/length": 160.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 812856, "time": 36971.414294719696, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 813088, "time": 36980.92294430733, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 813248, "time": 36987.840106487274, "episode/length": 128.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 813256, "time": 36989.43174266815, "episode/length": 159.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 813256, "time": 36989.44062232971, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 813584, "time": 37003.8248898983, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 814376, "time": 37031.285556554794, "episode/length": 189.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 814544, "time": 37038.55563092232, "episode/length": 457.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9912663755458515, "episode/intrinsic_return": 0.0}
{"step": 814584, "time": 37041.31595993042, "episode/length": 439.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 814592, "time": 37043.40447998047, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 815072, "time": 37061.04654073715, "episode/length": 247.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 815112, "time": 37063.81341052055, "episode/length": 231.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 815432, "time": 37075.98055076599, "episode/length": 272.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 815720, "time": 37087.096373319626, "episode/length": 140.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 815856, "time": 37093.50900053978, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 816120, "time": 37103.64878320694, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 816264, "time": 37110.05956554413, "episode/length": 214.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 816488, "time": 37119.14677500725, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 816568, "time": 37123.40104460716, "episode/length": 186.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 816760, "time": 37131.40557527542, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 817176, "time": 37146.71192455292, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 817480, "time": 37158.413033246994, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 817632, "time": 37165.24274945259, "episode/length": 221.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 818080, "time": 37182.36655306816, "episode/length": 188.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 818232, "time": 37188.900196790695, "episode/length": 263.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 818264, "time": 37192.084708452225, "episode/length": 221.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 818720, "time": 37209.127744436264, "episode/length": 306.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 819128, "time": 37223.99234461784, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 819608, "time": 37242.851548433304, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 819856, "time": 37252.97816491127, "episode/length": 198.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 819968, "time": 37258.16046333313, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 37280.88041257858, "eval_episode/length": 142.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.958041958041958}
{"step": 820040, "time": 37282.6438472271, "eval_episode/length": 149.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 820040, "time": 37286.6508500576, "eval_episode/length": 207.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 820040, "time": 37288.40498638153, "eval_episode/length": 209.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 820040, "time": 37290.36688327789, "eval_episode/length": 219.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 820040, "time": 37296.869537591934, "eval_episode/length": 288.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9965397923875432}
{"step": 820040, "time": 37298.92937207222, "eval_episode/length": 152.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 820040, "time": 37303.59021568298, "eval_episode/length": 361.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.994475138121547}
{"step": 820088, "time": 37305.166983127594, "episode/length": 170.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 820168, "time": 37309.50415444374, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 820408, "time": 37318.937530756, "episode/length": 365.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 820800, "time": 37333.781591415405, "episode/length": 395.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 820952, "time": 37340.13541197777, "episode/length": 67.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 821240, "time": 37351.45910358429, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 821560, "time": 37363.7194108963, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 821720, "time": 37370.647042512894, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 821728, "time": 37372.726686000824, "episode/length": 324.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 821728, "time": 37372.73629784584, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 821976, "time": 37383.80774974823, "episode/length": 146.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 822200, "time": 37392.86737322807, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 822608, "time": 37408.08680438995, "episode/length": 170.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 822688, "time": 37412.27095937729, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 823384, "time": 37436.72725176811, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 823448, "time": 37440.361471414566, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 823504, "time": 37444.10299420357, "episode/length": 221.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 823544, "time": 37446.73034310341, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 823904, "time": 37460.46589899063, "episode/length": 240.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 823993, "time": 37465.77504324913, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.289950710910183, "train/action_min": 0.0, "train/action_std": 3.181002060016552, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037137785001651394, "train/actor_opt_grad_steps": 50690.0, "train/actor_opt_loss": -8.213479916871218, "train/adv_mag": 0.4939778278340827, "train/adv_max": 0.43063143875215437, "train/adv_mean": 0.002277965089341343, "train/adv_min": -0.42858708009019597, "train/adv_std": 0.053107215938242996, "train/cont_avg": 0.9952332823426573, "train/cont_loss_mean": 0.00019700455272039766, "train/cont_loss_std": 0.005847946610783781, "train/cont_neg_acc": 0.9910173170216434, "train/cont_neg_loss": 0.023313182932100007, "train/cont_pos_acc": 0.9999724889135028, "train/cont_pos_loss": 6.977425827690987e-05, "train/cont_pred": 0.9952359095320001, "train/cont_rate": 0.9952332823426573, "train/dyn_loss_mean": 13.026947081505835, "train/dyn_loss_std": 8.909137215647664, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8998119676863396, "train/extr_critic_critic_opt_grad_steps": 50690.0, "train/extr_critic_critic_opt_loss": 15183.92157451923, "train/extr_critic_mag": 9.46689647727913, "train/extr_critic_max": 9.46689647727913, "train/extr_critic_mean": 3.095402015672697, "train/extr_critic_min": -0.12092596750992995, "train/extr_critic_std": 2.140012998680968, "train/extr_return_normed_mag": 1.501181007265211, "train/extr_return_normed_max": 1.501181007265211, "train/extr_return_normed_mean": 0.3818224870658421, "train/extr_return_normed_min": -0.14807178543789404, "train/extr_return_normed_std": 0.3208619195681352, "train/extr_return_rate": 0.9466109876032476, "train/extr_return_raw_mag": 10.679739045096444, "train/extr_return_raw_max": 10.679739045096444, "train/extr_return_raw_mean": 3.1107880085498305, "train/extr_return_raw_min": -0.4719980692530012, "train/extr_return_raw_std": 2.16952361426987, "train/extr_reward_mag": 1.0405711894268757, "train/extr_reward_max": 1.0405711894268757, "train/extr_reward_mean": 0.05124189708564248, "train/extr_reward_min": -0.42351809915129124, "train/extr_reward_std": 0.2095946904037382, "train/image_loss_mean": 6.506024378996629, "train/image_loss_std": 11.407425687029646, "train/model_loss_mean": 14.381162356663417, "train/model_loss_std": 15.056129215480563, "train/model_opt_grad_norm": 53.65800013242068, "train/model_opt_grad_steps": 50645.0, "train/model_opt_loss": 13411.26014805507, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 935.3146853146853, "train/policy_entropy_mag": 2.3927346426290232, "train/policy_entropy_max": 2.3927346426290232, "train/policy_entropy_mean": 0.4769687100307091, "train/policy_entropy_min": 0.07937504903419867, "train/policy_entropy_std": 0.5384433282005203, "train/policy_logprob_mag": 7.4383838393471455, "train/policy_logprob_max": -0.009455660872578204, "train/policy_logprob_mean": -0.4774316332556985, "train/policy_logprob_min": -7.4383838393471455, "train/policy_logprob_std": 1.033325050677453, "train/policy_randomness_mag": 0.8445303235854302, "train/policy_randomness_max": 0.8445303235854302, "train/policy_randomness_mean": 0.16834902482016104, "train/policy_randomness_min": 0.02801590897403397, "train/policy_randomness_std": 0.19004686645694546, "train/post_ent_mag": 58.74993789779556, "train/post_ent_max": 58.74993789779556, "train/post_ent_mean": 42.375914860438634, "train/post_ent_min": 19.757322571494363, "train/post_ent_std": 7.418728001467832, "train/prior_ent_mag": 67.66794041987066, "train/prior_ent_max": 67.66794041987066, "train/prior_ent_mean": 55.464376916418544, "train/prior_ent_min": 40.835738308779845, "train/prior_ent_std": 4.510906909729218, "train/rep_loss_mean": 13.026947081505835, "train/rep_loss_std": 8.909137215647664, "train/reward_avg": 0.03122336618029154, "train/reward_loss_mean": 0.05877278250205767, "train/reward_loss_std": 0.25318526784023204, "train/reward_max_data": 1.0202797251147824, "train/reward_max_pred": 1.0145680912724742, "train/reward_neg_acc": 0.992239787028386, "train/reward_neg_loss": 0.030470783366346278, "train/reward_pos_acc": 0.9719746979800138, "train/reward_pos_loss": 0.8261162042617798, "train/reward_pred": 0.0303535270081325, "train/reward_rate": 0.03562062937062937, "train_stats/sum_log_reward": 9.270212981295078, "train_stats/max_log_achievement_collect_coal": 0.5319148936170213, "train_stats/max_log_achievement_collect_drink": 6.425531914893617, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.627659574468085, "train_stats/max_log_achievement_collect_stone": 12.27659574468085, "train_stats/max_log_achievement_collect_wood": 11.170212765957446, "train_stats/max_log_achievement_defeat_skeleton": 0.05319148936170213, "train_stats/max_log_achievement_defeat_zombie": 1.2127659574468086, "train_stats/max_log_achievement_eat_cow": 0.1595744680851064, "train_stats/max_log_achievement_eat_plant": 0.010638297872340425, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7234042553191489, "train_stats/max_log_achievement_make_wood_sword": 1.4361702127659575, "train_stats/max_log_achievement_place_furnace": 0.05319148936170213, "train_stats/max_log_achievement_place_plant": 1.6063829787234043, "train_stats/max_log_achievement_place_stone": 9.627659574468085, "train_stats/max_log_achievement_place_table": 3.074468085106383, "train_stats/max_log_achievement_wake_up": 1.4893617021276595, "train_stats/mean_log_entropy": 0.5061186228660827, "eval_stats/sum_log_reward": 9.100000262260437, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 4.1875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 12.25, "eval_stats/max_log_achievement_collect_wood": 9.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 9.3125, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 4.285754584998358e-06, "report/cont_loss_std": 7.926968100946397e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003232143062632531, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.774506245055818e-06, "report/cont_pred": 0.9921883344650269, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.570917129516602, "report/dyn_loss_std": 9.478728294372559, "report/image_loss_mean": 5.957302093505859, "report/image_loss_std": 11.054694175720215, "report/model_loss_mean": 13.554553031921387, "report/model_loss_std": 14.972963333129883, "report/post_ent_mag": 59.29847717285156, "report/post_ent_max": 59.29847717285156, "report/post_ent_mean": 43.30033493041992, "report/post_ent_min": 20.607074737548828, "report/post_ent_std": 8.095504760742188, "report/prior_ent_mag": 67.73443603515625, "report/prior_ent_max": 67.73443603515625, "report/prior_ent_mean": 55.910404205322266, "report/prior_ent_min": 43.88432312011719, "report/prior_ent_std": 3.6595067977905273, "report/rep_loss_mean": 12.570917129516602, "report/rep_loss_std": 9.478728294372559, "report/reward_avg": 0.01992187649011612, "report/reward_loss_mean": 0.05469589680433273, "report/reward_loss_std": 0.23139412701129913, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9999427795410156, "report/reward_neg_acc": 0.9959920048713684, "report/reward_neg_loss": 0.03782438859343529, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7023021578788757, "report/reward_pred": 0.0197068490087986, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.1782422916439828e-05, "eval/cont_loss_std": 0.00021256714535411447, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012037059059366584, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.933926786383381e-06, "eval/cont_pred": 0.9951171875, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.001867294311523, "eval/dyn_loss_std": 9.90260124206543, "eval/image_loss_mean": 9.787632942199707, "eval/image_loss_std": 13.94536018371582, "eval/model_loss_mean": 20.710922241210938, "eval/model_loss_std": 17.52820587158203, "eval/post_ent_mag": 59.093814849853516, "eval/post_ent_max": 59.093814849853516, "eval/post_ent_mean": 41.11824035644531, "eval/post_ent_min": 19.768993377685547, "eval/post_ent_std": 7.752181529998779, "eval/prior_ent_mag": 67.24492645263672, "eval/prior_ent_max": 67.24492645263672, "eval/prior_ent_mean": 56.35036849975586, "eval/prior_ent_min": 45.09117889404297, "eval/prior_ent_std": 4.008737087249756, "eval/rep_loss_mean": 18.001867294311523, "eval/rep_loss_std": 9.90260124206543, "eval/reward_avg": 0.03261718526482582, "eval/reward_loss_mean": 0.12215659022331238, "eval/reward_loss_std": 0.643285870552063, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001142978668213, "eval/reward_neg_acc": 0.9837563633918762, "eval/reward_neg_loss": 0.06209423765540123, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.639115810394287, "eval/reward_pred": 0.03114059567451477, "eval/reward_rate": 0.0380859375, "replay/size": 823489.0, "replay/inserts": 22784.0, "replay/samples": 22784.0, "replay/insert_wait_avg": 1.461946227577295e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.459098068515906e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2186153427414272e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.220762014389, "timer/env.step_count": 2848.0, "timer/env.step_total": 230.45139932632446, "timer/env.step_frac": 0.23040053563996027, "timer/env.step_avg": 0.08091692392076, "timer/env.step_min": 0.023064374923706055, "timer/env.step_max": 3.2651522159576416, "timer/replay._sample_count": 22784.0, "timer/replay._sample_total": 11.516340732574463, "timer/replay._sample_frac": 0.011513798923130923, "timer/replay._sample_avg": 0.0005054573706361685, "timer/replay._sample_min": 0.0004067420959472656, "timer/replay._sample_max": 0.009866952896118164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3584.0, "timer/agent.policy_total": 60.604689598083496, "timer/agent.policy_frac": 0.06059131333769659, "timer/agent.policy_avg": 0.01690979062446526, "timer/agent.policy_min": 0.009365081787109375, "timer/agent.policy_max": 0.11852312088012695, "timer/dataset_train_count": 1424.0, "timer/dataset_train_total": 0.1545093059539795, "timer/dataset_train_frac": 0.00015447520369683823, "timer/dataset_train_avg": 0.00010850372609127773, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0018849372863769531, "timer/agent.train_count": 1424.0, "timer/agent.train_total": 635.1812124252319, "timer/agent.train_frac": 0.6350410194905496, "timer/agent.train_avg": 0.4460542222087303, "timer/agent.train_min": 0.43435215950012207, "timer/agent.train_max": 1.6795566082000732, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47320985794067383, "timer/agent.report_frac": 0.00047310541423640866, "timer/agent.report_avg": 0.23660492897033691, "timer/agent.report_min": 0.2295224666595459, "timer/agent.report_max": 0.24368739128112793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.4836273193359375e-05, "timer/dataset_eval_frac": 5.482417009913108e-08, "timer/dataset_eval_avg": 5.4836273193359375e-05, "timer/dataset_eval_min": 5.4836273193359375e-05, "timer/dataset_eval_max": 5.4836273193359375e-05, "fps": 22.778654947524547}
{"step": 824392, "time": 37478.90085148811, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 824504, "time": 37484.16191148758, "episode/length": 236.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 824704, "time": 37492.49393773079, "episode/length": 38.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 824816, "time": 37497.76514387131, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 824952, "time": 37503.63833451271, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 825144, "time": 37511.52636432648, "episode/length": 427.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 825416, "time": 37522.22584080696, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 825728, "time": 37534.567556381226, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 825920, "time": 37542.60324716568, "episode/length": 251.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 825920, "time": 37542.617347717285, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 826744, "time": 37573.4182202816, "episode/length": 254.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 826848, "time": 37578.67749905586, "episode/length": 212.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 826864, "time": 37580.81534290314, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 827048, "time": 37588.34557032585, "episode/length": 203.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 827272, "time": 37597.314980983734, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 827712, "time": 37615.345975875854, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 827816, "time": 37620.115842819214, "episode/length": 260.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 828392, "time": 37640.8657810688, "episode/length": 139.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 828536, "time": 37647.224350214005, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 828944, "time": 37662.765491724014, "episode/length": 261.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 829040, "time": 37668.074092149734, "episode/length": 165.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 829288, "time": 37678.30509853363, "episode/length": 420.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9928741092636579, "episode/intrinsic_return": 0.0}
{"step": 829304, "time": 37680.45639896393, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 829544, "time": 37690.16672158241, "episode/length": 125.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 829640, "time": 37695.04074430466, "episode/length": 323.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 829864, "time": 37704.14121699333, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 37726.75827026367, "eval_episode/length": 55.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 830024, "time": 37736.58270263672, "eval_episode/length": 219.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 830024, "time": 37739.01384997368, "eval_episode/length": 230.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 830024, "time": 37740.777753829956, "eval_episode/length": 180.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 830024, "time": 37743.74818587303, "eval_episode/length": 268.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9739776951672863}
{"step": 830024, "time": 37747.05801177025, "eval_episode/length": 37.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 830024, "time": 37751.2725379467, "eval_episode/length": 59.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 830024, "time": 37754.533940553665, "eval_episode/length": 169.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 830344, "time": 37765.11013054848, "episode/length": 315.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 830520, "time": 37772.5485355854, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 830864, "time": 37785.971334934235, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 830920, "time": 37789.173328876495, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 831552, "time": 37812.07606983185, "episode/length": 280.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 831568, "time": 37814.09424781799, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 831672, "time": 37818.86415910721, "episode/length": 253.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 832160, "time": 37836.9735929966, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 832376, "time": 37845.659937143326, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 832584, "time": 37854.23033809662, "episode/length": 379.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 832744, "time": 37861.11831617355, "episode/length": 227.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 833352, "time": 37883.03541970253, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 833536, "time": 37890.89425325394, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 834056, "time": 37909.65829873085, "episode/length": 441.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9932126696832579, "episode/intrinsic_return": 0.0}
{"step": 834072, "time": 37911.797634124756, "episode/length": 211.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 834144, "time": 37916.007236003876, "episode/length": 323.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9845679012345679, "episode/intrinsic_return": 0.0}
{"step": 834416, "time": 37926.676008701324, "episode/length": 228.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 834440, "time": 37928.99399447441, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 834912, "time": 37946.40702319145, "episode/length": 194.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 834968, "time": 37949.548639535904, "episode/length": 65.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 835128, "time": 37956.46433019638, "episode/length": 297.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 835840, "time": 37983.826968193054, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 835888, "time": 37986.93378138542, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 836008, "time": 37992.403849840164, "episode/length": 308.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 836312, "time": 38004.17189049721, "episode/length": 236.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 836352, "time": 38007.70837569237, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 836936, "time": 38029.06615614891, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 837016, "time": 38033.210453271866, "episode/length": 255.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 837240, "time": 38042.12402224541, "episode/length": 263.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 837512, "time": 38052.79558515549, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 837808, "time": 38064.51746702194, "episode/length": 181.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 837920, "time": 38070.208408117294, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 838000, "time": 38074.45447778702, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 838424, "time": 38090.18223953247, "episode/length": 322.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 838768, "time": 38103.89245438576, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 838984, "time": 38112.62510561943, "episode/length": 183.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 839040, "time": 38116.30954551697, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 839160, "time": 38121.60063672066, "episode/length": 168.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 839360, "time": 38129.964139699936, "episode/length": 46.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 839432, "time": 38133.70505857468, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 839520, "time": 38138.55474948883, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776357827476039, "episode/intrinsic_return": 0.0}
{"step": 839952, "time": 38154.37592101097, "episode/length": 243.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 38174.13325214386, "eval_episode/length": 79.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.95}
{"step": 840008, "time": 38179.148210287094, "eval_episode/length": 159.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 840008, "time": 38181.935054540634, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 840008, "time": 38183.83416008949, "eval_episode/length": 189.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 840008, "time": 38185.407594680786, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 840008, "time": 38189.283690452576, "eval_episode/length": 243.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9795081967213115}
{"step": 840008, "time": 38191.69828438759, "eval_episode/length": 264.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 840008, "time": 38193.81517744064, "eval_episode/length": 275.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9746376811594203}
{"step": 840208, "time": 38200.71696281433, "episode/length": 179.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 840480, "time": 38211.26745033264, "episode/length": 65.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 840680, "time": 38219.1554582119, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 840704, "time": 38221.72186374664, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 840936, "time": 38231.02603149414, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 841024, "time": 38235.75858426094, "episode/length": 324.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 841600, "time": 38256.55501103401, "episode/length": 259.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 841824, "time": 38266.28806591034, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 842136, "time": 38278.13731765747, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 842152, "time": 38280.17990040779, "episode/length": 242.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 842600, "time": 38296.58754706383, "episode/length": 236.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 842832, "time": 38306.017552137375, "episode/length": 236.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 843144, "time": 38317.61234283447, "episode/length": 192.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 843192, "time": 38320.90932893753, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 843304, "time": 38326.16386580467, "episode/length": 492.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9979716024340771, "episode/intrinsic_return": 0.0}
{"step": 843640, "time": 38338.91659641266, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 843656, "time": 38340.9576458931, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 843736, "time": 38345.173649549484, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 843944, "time": 38355.238445043564, "episode/length": 167.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 844712, "time": 38382.33671474457, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 844800, "time": 38386.975226163864, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 845008, "time": 38395.58568763733, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 845536, "time": 38414.69791960716, "episode/length": 236.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 845608, "time": 38418.47369527817, "episode/length": 243.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 846000, "time": 38433.24452471733, "episode/length": 336.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 846176, "time": 38440.73981785774, "episode/length": 372.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9919571045576407, "episode/intrinsic_return": 0.0}
{"step": 846192, "time": 38442.8544614315, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 846400, "time": 38451.38705611229, "episode/length": 199.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 846400, "time": 38451.39610004425, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 846713, "time": 38465.868538856506, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.314739818304357, "train/action_min": 0.0, "train/action_std": 3.236675495832739, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037739039411847024, "train/actor_opt_grad_steps": 52115.0, "train/actor_opt_loss": -4.188801647299199, "train/adv_mag": 0.480852700455088, "train/adv_max": 0.44136627375240056, "train/adv_mean": 0.0033316172922356383, "train/adv_min": -0.3928731451152076, "train/adv_std": 0.053362166561501126, "train/cont_avg": 0.9950002750880281, "train/cont_loss_mean": 0.00017923794237107194, "train/cont_loss_std": 0.00550877812951641, "train/cont_neg_acc": 0.9976950355455385, "train/cont_neg_loss": 0.008438212736936816, "train/cont_pos_acc": 0.9999515775223853, "train/cont_pos_loss": 0.00013786562656663027, "train/cont_pred": 0.9949753569885039, "train/cont_rate": 0.9950002750880281, "train/dyn_loss_mean": 12.82386002742069, "train/dyn_loss_std": 8.981974991274551, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9008829203289999, "train/extr_critic_critic_opt_grad_steps": 52115.0, "train/extr_critic_critic_opt_loss": 15143.302012268927, "train/extr_critic_mag": 9.540619406901614, "train/extr_critic_max": 9.540619406901614, "train/extr_critic_mean": 3.2149211621620286, "train/extr_critic_min": -0.14197889012350162, "train/extr_critic_std": 2.189644609538602, "train/extr_return_normed_mag": 1.4899763213077062, "train/extr_return_normed_max": 1.4899763213077062, "train/extr_return_normed_mean": 0.3977313597857113, "train/extr_return_normed_min": -0.14597238878339108, "train/extr_return_normed_std": 0.32089349291693997, "train/extr_return_rate": 0.9359421352265587, "train/extr_return_raw_mag": 10.813794545724358, "train/extr_return_raw_max": 10.813794545724358, "train/extr_return_raw_mean": 3.238000172964284, "train/extr_return_raw_min": -0.5329236659995267, "train/extr_return_raw_std": 2.2265670030889377, "train/extr_reward_mag": 1.0424681079219764, "train/extr_reward_max": 1.0424681079219764, "train/extr_reward_mean": 0.05200235738458348, "train/extr_reward_min": -0.47877039120230874, "train/extr_reward_std": 0.2118510867298489, "train/image_loss_mean": 6.3094471676248896, "train/image_loss_std": 11.670177372408585, "train/model_loss_mean": 14.060469472911995, "train/model_loss_std": 15.336076776746292, "train/model_opt_grad_norm": 55.97478503912267, "train/model_opt_grad_steps": 52069.218309859156, "train/model_opt_loss": 19116.046895631604, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1364.4366197183099, "train/policy_entropy_mag": 2.4460100976514143, "train/policy_entropy_max": 2.4460100976514143, "train/policy_entropy_mean": 0.4834388935230148, "train/policy_entropy_min": 0.0793750695359539, "train/policy_entropy_std": 0.5645134799497228, "train/policy_logprob_mag": 7.438383760586591, "train/policy_logprob_max": -0.009455668392368185, "train/policy_logprob_mean": -0.48372883024350016, "train/policy_logprob_min": -7.438383760586591, "train/policy_logprob_std": 1.0410383146413615, "train/policy_randomness_mag": 0.8633342255169237, "train/policy_randomness_max": 0.8633342255169237, "train/policy_randomness_mean": 0.1706327153763301, "train/policy_randomness_min": 0.028015916209510515, "train/policy_randomness_std": 0.19924848537210008, "train/post_ent_mag": 58.976235725510286, "train/post_ent_max": 58.976235725510286, "train/post_ent_mean": 42.57627489869024, "train/post_ent_min": 19.777209161033092, "train/post_ent_std": 7.538843843298898, "train/prior_ent_mag": 67.68581406499298, "train/prior_ent_max": 67.68581406499298, "train/prior_ent_mean": 55.44940440755495, "train/prior_ent_min": 40.93636053380832, "train/prior_ent_std": 4.48997996222805, "train/rep_loss_mean": 12.82386002742069, "train/rep_loss_std": 8.981974991274551, "train/reward_avg": 0.031217676895657475, "train/reward_loss_mean": 0.05652711537837143, "train/reward_loss_std": 0.2449300075081033, "train/reward_max_data": 1.0204225400803795, "train/reward_max_pred": 1.0154496809126625, "train/reward_neg_acc": 0.9930590151900976, "train/reward_neg_loss": 0.02824920766108053, "train/reward_pos_acc": 0.9726088357643342, "train/reward_pos_loss": 0.8244890969404033, "train/reward_pred": 0.03042874786950333, "train/reward_rate": 0.0356720400528169, "train_stats/sum_log_reward": 9.450515663500914, "train_stats/max_log_achievement_collect_coal": 0.845360824742268, "train_stats/max_log_achievement_collect_drink": 5.484536082474227, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3195876288659794, "train_stats/max_log_achievement_collect_stone": 13.360824742268042, "train_stats/max_log_achievement_collect_wood": 10.525773195876289, "train_stats/max_log_achievement_defeat_skeleton": 0.08247422680412371, "train_stats/max_log_achievement_defeat_zombie": 1.0515463917525774, "train_stats/max_log_achievement_eat_cow": 0.1134020618556701, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.020618556701030927, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6701030927835052, "train_stats/max_log_achievement_make_wood_sword": 1.4123711340206186, "train_stats/max_log_achievement_place_furnace": 0.020618556701030927, "train_stats/max_log_achievement_place_plant": 1.268041237113402, "train_stats/max_log_achievement_place_stone": 10.164948453608247, "train_stats/max_log_achievement_place_table": 2.9690721649484537, "train_stats/max_log_achievement_wake_up": 1.3608247422680413, "train_stats/mean_log_entropy": 0.5157932805031845, "eval_stats/sum_log_reward": 8.725000232458115, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 9.875, "eval_stats/max_log_achievement_collect_wood": 8.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 6.8125, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00019944248197134584, "report/cont_loss_std": 0.006296876352280378, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.033664122223854065, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.204676775363623e-06, "report/cont_pred": 0.9943171739578247, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.430191040039062, "report/dyn_loss_std": 8.947373390197754, "report/image_loss_mean": 7.931304931640625, "report/image_loss_std": 12.296795845031738, "report/model_loss_mean": 16.067481994628906, "report/model_loss_std": 15.644783020019531, "report/post_ent_mag": 57.9771614074707, "report/post_ent_max": 57.9771614074707, "report/post_ent_mean": 42.07396697998047, "report/post_ent_min": 18.743091583251953, "report/post_ent_std": 7.726463317871094, "report/prior_ent_mag": 67.4518051147461, "report/prior_ent_max": 67.4518051147461, "report/prior_ent_mean": 55.65953063964844, "report/prior_ent_min": 39.66552734375, "report/prior_ent_std": 4.336967468261719, "report/rep_loss_mean": 13.430191040039062, "report/rep_loss_std": 8.947373390197754, "report/reward_avg": 0.0361328125, "report/reward_loss_mean": 0.07786376774311066, "report/reward_loss_std": 0.35441216826438904, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0124609470367432, "report/reward_neg_acc": 0.9898167252540588, "report/reward_neg_loss": 0.04899989441037178, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7527286410331726, "report/reward_pred": 0.03716615214943886, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.3998609322006814e-06, "eval/cont_loss_std": 4.232129140291363e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.684170562541112e-06, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.390902864135569e-06, "eval/cont_pred": 0.9960914850234985, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.881834030151367, "eval/dyn_loss_std": 10.39132308959961, "eval/image_loss_mean": 14.097421646118164, "eval/image_loss_std": 17.40284538269043, "eval/model_loss_mean": 24.92717170715332, "eval/model_loss_std": 21.53167724609375, "eval/post_ent_mag": 60.08598709106445, "eval/post_ent_max": 60.08598709106445, "eval/post_ent_mean": 41.849979400634766, "eval/post_ent_min": 17.55816650390625, "eval/post_ent_std": 7.895129680633545, "eval/prior_ent_mag": 67.85380554199219, "eval/prior_ent_max": 67.85380554199219, "eval/prior_ent_mean": 57.400108337402344, "eval/prior_ent_min": 43.3161506652832, "eval/prior_ent_std": 4.1878485679626465, "eval/rep_loss_mean": 17.881834030151367, "eval/rep_loss_std": 10.39132308959961, "eval/reward_avg": 0.03457031399011612, "eval/reward_loss_mean": 0.10064597427845001, "eval/reward_loss_std": 0.5110980272293091, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023627281188965, "eval/reward_neg_acc": 0.9888325333595276, "eval/reward_neg_loss": 0.05410224571824074, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.2761735916137695, "eval/reward_pred": 0.030173497274518013, "eval/reward_rate": 0.0380859375, "replay/size": 846209.0, "replay/inserts": 22720.0, "replay/samples": 22720.0, "replay/insert_wait_avg": 1.4732211408480792e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.516700052879226e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2352909909160386e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0787172317505, "timer/env.step_count": 2840.0, "timer/env.step_total": 233.76185512542725, "timer/env.step_frac": 0.23374345548767148, "timer/env.step_avg": 0.08231051236810819, "timer/env.step_min": 0.023415565490722656, "timer/env.step_max": 3.513840436935425, "timer/replay._sample_count": 22720.0, "timer/replay._sample_total": 11.549216270446777, "timer/replay._sample_frac": 0.01154830721967104, "timer/replay._sample_avg": 0.0005083281809175518, "timer/replay._sample_min": 0.00038933753967285156, "timer/replay._sample_max": 0.03133106231689453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3523.0, "timer/agent.policy_total": 58.197574853897095, "timer/agent.policy_frac": 0.05819299406249722, "timer/agent.policy_avg": 0.016519322978682117, "timer/agent.policy_min": 0.00951838493347168, "timer/agent.policy_max": 0.0938718318939209, "timer/dataset_train_count": 1420.0, "timer/dataset_train_total": 0.15183353424072266, "timer/dataset_train_frac": 0.00015182158326596798, "timer/dataset_train_avg": 0.00010692502411318497, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0008671283721923828, "timer/agent.train_count": 1420.0, "timer/agent.train_total": 634.5378043651581, "timer/agent.train_frac": 0.6344878592372997, "timer/agent.train_avg": 0.4468576087078578, "timer/agent.train_min": 0.43515515327453613, "timer/agent.train_max": 1.6803715229034424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4740486145019531, "timer/agent.report_frac": 0.0004740113016444692, "timer/agent.report_avg": 0.23702430725097656, "timer/agent.report_min": 0.23119354248046875, "timer/agent.report_max": 0.24285507202148438, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051517605481459e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 22.717874451115435}
{"step": 846904, "time": 38472.13646054268, "episode/length": 62.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 847160, "time": 38482.17236542702, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 847376, "time": 38491.0158598423, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 847568, "time": 38499.02615785599, "episode/length": 244.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 847608, "time": 38501.69566679001, "episode/length": 200.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 847744, "time": 38508.057679891586, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 847864, "time": 38513.36679625511, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 847928, "time": 38516.98131608963, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 848336, "time": 38532.31136894226, "episode/length": 178.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 848760, "time": 38547.58872938156, "episode/length": 199.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 849024, "time": 38558.33652353287, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 849200, "time": 38565.73298621178, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 849648, "time": 38582.24757170677, "episode/length": 55.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 849696, "time": 38585.413912534714, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 849792, "time": 38590.39641594887, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 849864, "time": 38594.11126756668, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 850072, "time": 38602.56601047516, "episode/length": 163.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 38620.690041065216, "eval_episode/length": 55.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 850096, "time": 38622.37580561638, "eval_episode/length": 56.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 850096, "time": 38629.993960142136, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9619565217391305}
{"step": 850096, "time": 38632.48694610596, "eval_episode/length": 195.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 850096, "time": 38634.75729513168, "eval_episode/length": 201.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 850096, "time": 38639.14184141159, "eval_episode/length": 237.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 850096, "time": 38643.58050990105, "eval_episode/length": 218.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 850096, "time": 38645.367943525314, "eval_episode/length": 227.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 850672, "time": 38666.647807598114, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 851104, "time": 38682.599244356155, "episode/length": 419.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 851216, "time": 38687.76983380318, "episode/length": 189.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 851488, "time": 38698.41530299187, "episode/length": 444.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932584269662922, "episode/intrinsic_return": 0.0}
{"step": 851592, "time": 38703.23791909218, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 851712, "time": 38709.17507195473, "episode/length": 239.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 851848, "time": 38714.97447299957, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 851880, "time": 38717.557218790054, "episode/length": 278.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 852256, "time": 38733.41041183472, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 852840, "time": 38754.12773871422, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 853216, "time": 38768.40659070015, "episode/length": 170.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 853216, "time": 38768.42407274246, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 853384, "time": 38777.048959732056, "episode/length": 140.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 853888, "time": 38795.44221782684, "episode/length": 250.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 853992, "time": 38800.30250811577, "episode/length": 312.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 854248, "time": 38810.237329244614, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 854712, "time": 38827.09661912918, "episode/length": 57.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 855216, "time": 38845.67173719406, "episode/length": 228.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 855416, "time": 38853.65784883499, "episode/length": 274.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 855504, "time": 38858.56474542618, "episode/length": 201.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 855600, "time": 38863.288412332535, "episode/length": 500.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 855704, "time": 38868.02694964409, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 855744, "time": 38871.11254000664, "episode/length": 362.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 855960, "time": 38879.64855790138, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 856552, "time": 38901.04291677475, "episode/length": 166.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 856696, "time": 38907.46759343147, "episode/length": 434.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 857128, "time": 38923.56695961952, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 857224, "time": 38928.3718149662, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 857296, "time": 38932.5088801384, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 857496, "time": 38940.40963244438, "episode/length": 259.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 858344, "time": 38970.12469315529, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 858464, "time": 38975.92337489128, "episode/length": 369.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9918918918918919, "episode/intrinsic_return": 0.0}
{"step": 858520, "time": 38979.21851015091, "episode/length": 346.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798270893371758, "episode/intrinsic_return": 0.0}
{"step": 858560, "time": 38982.267631053925, "episode/length": 250.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 858776, "time": 38990.80559134483, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 859024, "time": 39000.905366659164, "episode/length": 190.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 859040, "time": 39003.0070002079, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 859696, "time": 39026.27657818794, "episode/length": 299.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 859912, "time": 39034.74254202843, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39057.0905687809, "eval_episode/length": 33.0, "eval_episode/score": 3.1000000163912773, "eval_episode/reward_rate": 0.9117647058823529}
{"step": 860080, "time": 39063.72767448425, "eval_episode/length": 154.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 860080, "time": 39065.37023329735, "eval_episode/length": 156.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 860080, "time": 39068.59684729576, "eval_episode/length": 192.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 860080, "time": 39071.35917639732, "eval_episode/length": 186.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 860080, "time": 39076.38035583496, "eval_episode/length": 299.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 860080, "time": 39078.64226937294, "eval_episode/length": 315.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9810126582278481}
{"step": 860080, "time": 39080.26530909538, "eval_episode/length": 159.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 860176, "time": 39085.05773806572, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 860408, "time": 39094.220941782, "episode/length": 88.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 860584, "time": 39101.750494003296, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 860728, "time": 39108.01312661171, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 860920, "time": 39115.94045972824, "episode/length": 236.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 861232, "time": 39128.213514328, "episode/length": 333.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 861784, "time": 39147.973974466324, "episode/length": 233.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 861824, "time": 39151.224608421326, "episode/length": 412.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927360774818402, "episode/intrinsic_return": 0.0}
{"step": 861880, "time": 39154.50512909889, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 862152, "time": 39165.11874675751, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 862264, "time": 39170.41209149361, "episode/length": 231.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 862624, "time": 39184.044417858124, "episode/length": 236.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 862776, "time": 39190.52480697632, "episode/length": 231.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 863056, "time": 39201.46263432503, "episode/length": 227.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 863464, "time": 39216.390254974365, "episode/length": 209.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 863584, "time": 39222.295422554016, "episode/length": 178.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 863768, "time": 39229.785549879074, "episode/length": 235.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 863896, "time": 39235.63644480705, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 864152, "time": 39245.7282435894, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 864872, "time": 39271.5322265625, "episode/length": 226.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 864968, "time": 39276.35692548752, "episode/length": 337.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 865048, "time": 39280.669981479645, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 865176, "time": 39286.37875175476, "episode/length": 175.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 865192, "time": 39288.35745930672, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 866320, "time": 39327.697593688965, "episode/length": 442.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9977426636568849, "episode/intrinsic_return": 0.0}
{"step": 866472, "time": 39334.11812233925, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 866736, "time": 39344.90519499779, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 866944, "time": 39353.48263955116, "episode/length": 348.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9828080229226361, "episode/intrinsic_return": 0.0}
{"step": 867008, "time": 39357.17178988457, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 867040, "time": 39359.92983818054, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 867456, "time": 39375.25128698349, "episode/length": 444.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9865168539325843, "episode/intrinsic_return": 0.0}
{"step": 867520, "time": 39378.81853675842, "episode/length": 149.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 868024, "time": 39396.83021211624, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 868272, "time": 39407.0418305397, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 868968, "time": 39433.519538879395, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 869000, "time": 39436.171642541885, "episode/length": 503.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 869400, "time": 39451.45573806763, "episode/length": 171.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 869544, "time": 39458.37569618225, "episode/length": 252.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 869705, "time": 39466.244123220444, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.206905788845486, "train/action_min": 0.0, "train/action_std": 3.11258926987648, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.035425033782505326, "train/actor_opt_grad_steps": 53545.0, "train/actor_opt_loss": -10.94144993637585, "train/adv_mag": 0.4896854396081633, "train/adv_max": 0.42314885349737275, "train/adv_mean": 0.0014582027563013373, "train/adv_min": -0.4036162950926357, "train/adv_std": 0.05060904470479323, "train/cont_avg": 0.9950697157118056, "train/cont_loss_mean": 0.0002318660025759398, "train/cont_loss_std": 0.0070923442615825, "train/cont_neg_acc": 0.9897657912094276, "train/cont_neg_loss": 0.036362921335436824, "train/cont_pos_acc": 0.9999727172156175, "train/cont_pos_loss": 6.788855517426818e-05, "train/cont_pred": 0.9950774941179488, "train/cont_rate": 0.9950697157118056, "train/dyn_loss_mean": 12.8892303109169, "train/dyn_loss_std": 8.895909057723152, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8701792139973905, "train/extr_critic_critic_opt_grad_steps": 53545.0, "train/extr_critic_critic_opt_loss": 15019.769714355469, "train/extr_critic_mag": 9.63683236307568, "train/extr_critic_max": 9.63683236307568, "train/extr_critic_mean": 3.2184644871287875, "train/extr_critic_min": -0.14086793777015474, "train/extr_critic_std": 2.234413448307249, "train/extr_return_normed_mag": 1.4705344421996012, "train/extr_return_normed_max": 1.4705344421996012, "train/extr_return_normed_mean": 0.3995738048106432, "train/extr_return_normed_min": -0.11718494771048427, "train/extr_return_normed_std": 0.31565505721502835, "train/extr_return_rate": 0.9154215972456667, "train/extr_return_raw_mag": 10.903076920244429, "train/extr_return_raw_max": 10.903076920244429, "train/extr_return_raw_mean": 3.2289016577932568, "train/extr_return_raw_min": -0.473848527090417, "train/extr_return_raw_std": 2.262112637360891, "train/extr_reward_mag": 1.0472889062431123, "train/extr_reward_max": 1.0472889062431123, "train/extr_reward_mean": 0.051083397404808134, "train/extr_reward_min": -0.4395388588309288, "train/extr_reward_std": 0.20985340854773918, "train/image_loss_mean": 6.26836919453409, "train/image_loss_std": 11.452861150105795, "train/model_loss_mean": 14.060016797648537, "train/model_loss_std": 15.081185360749563, "train/model_opt_grad_norm": 57.03076110519729, "train/model_opt_grad_steps": 53497.86111111111, "train/model_opt_loss": 19125.293836805555, "train/model_opt_model_opt_grad_overflow": 0.006944444444444444, "train/model_opt_model_opt_grad_scale": 1354.1666666666667, "train/policy_entropy_mag": 2.4481254484918384, "train/policy_entropy_max": 2.4481254484918384, "train/policy_entropy_mean": 0.47557702515688205, "train/policy_entropy_min": 0.079375049771948, "train/policy_entropy_std": 0.5635489510993162, "train/policy_logprob_mag": 7.438383844163683, "train/policy_logprob_max": -0.009455660849602686, "train/policy_logprob_mean": -0.4762759349412388, "train/policy_logprob_min": -7.438383844163683, "train/policy_logprob_std": 1.0405315624343023, "train/policy_randomness_mag": 0.8640808512767156, "train/policy_randomness_max": 0.8640808512767156, "train/policy_randomness_mean": 0.16785782016813755, "train/policy_randomness_min": 0.028015909212020535, "train/policy_randomness_std": 0.1989080495097571, "train/post_ent_mag": 59.01085231039259, "train/post_ent_max": 59.01085231039259, "train/post_ent_mean": 42.480365965101456, "train/post_ent_min": 19.815800494617886, "train/post_ent_std": 7.501502745681339, "train/prior_ent_mag": 67.60664542516072, "train/prior_ent_max": 67.60664542516072, "train/prior_ent_mean": 55.45339126057095, "train/prior_ent_min": 40.66325121455722, "train/prior_ent_std": 4.4980163060956535, "train/rep_loss_mean": 12.8892303109169, "train/rep_loss_std": 8.895909057723152, "train/reward_avg": 0.03132459830440995, "train/reward_loss_mean": 0.057877636385253735, "train/reward_loss_std": 0.24708815405352247, "train/reward_max_data": 1.0180555598603354, "train/reward_max_pred": 1.0161620047357347, "train/reward_neg_acc": 0.992391710066133, "train/reward_neg_loss": 0.029534553779133905, "train/reward_pos_acc": 0.9740594066679478, "train/reward_pos_loss": 0.8231331594288349, "train/reward_pred": 0.030602700911307085, "train/reward_rate": 0.03567165798611111, "train_stats/sum_log_reward": 9.536170381180783, "train_stats/max_log_achievement_collect_coal": 0.5319148936170213, "train_stats/max_log_achievement_collect_drink": 5.9787234042553195, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.446808510638298, "train_stats/max_log_achievement_collect_stone": 11.085106382978724, "train_stats/max_log_achievement_collect_wood": 10.563829787234043, "train_stats/max_log_achievement_defeat_skeleton": 0.07446808510638298, "train_stats/max_log_achievement_defeat_zombie": 1.2659574468085106, "train_stats/max_log_achievement_eat_cow": 0.2127659574468085, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3617021276595744, "train_stats/max_log_achievement_make_wood_sword": 1.553191489361702, "train_stats/max_log_achievement_place_furnace": 0.0425531914893617, "train_stats/max_log_achievement_place_plant": 1.3297872340425532, "train_stats/max_log_achievement_place_stone": 8.48936170212766, "train_stats/max_log_achievement_place_table": 2.978723404255319, "train_stats/max_log_achievement_wake_up": 1.5319148936170213, "train_stats/mean_log_entropy": 0.5054509208557454, "eval_stats/sum_log_reward": 9.03750029206276, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 9.75, "eval_stats/max_log_achievement_collect_wood": 8.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 7.8125, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 9.076855462808453e-07, "report/cont_loss_std": 7.072091648296919e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011048550368286669, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.857135079168074e-07, "report/cont_pred": 0.9970701336860657, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.72768497467041, "report/dyn_loss_std": 8.911786079406738, "report/image_loss_mean": 5.302804946899414, "report/image_loss_std": 10.629778861999512, "report/model_loss_mean": 12.987105369567871, "report/model_loss_std": 13.95709228515625, "report/post_ent_mag": 60.17692184448242, "report/post_ent_max": 60.17692184448242, "report/post_ent_mean": 42.75260925292969, "report/post_ent_min": 19.256362915039062, "report/post_ent_std": 8.035953521728516, "report/prior_ent_mag": 67.7465591430664, "report/prior_ent_max": 67.7465591430664, "report/prior_ent_mean": 55.56071472167969, "report/prior_ent_min": 38.504425048828125, "report/prior_ent_std": 4.098937511444092, "report/rep_loss_mean": 12.72768497467041, "report/rep_loss_std": 8.911786079406738, "report/reward_avg": 0.03603515774011612, "report/reward_loss_mean": 0.047689054161310196, "report/reward_loss_std": 0.20152781903743744, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0046727657318115, "report/reward_neg_acc": 0.9969512820243835, "report/reward_neg_loss": 0.01588410884141922, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8300907015800476, "report/reward_pred": 0.034214891493320465, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.6374438018829096e-06, "eval/cont_loss_std": 2.1135951101314276e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002146417973563075, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.021326038942789e-07, "eval/cont_pred": 0.9960938692092896, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.825183868408203, "eval/dyn_loss_std": 10.24761962890625, "eval/image_loss_mean": 9.986961364746094, "eval/image_loss_std": 14.968669891357422, "eval/model_loss_mean": 20.210186004638672, "eval/model_loss_std": 18.677875518798828, "eval/post_ent_mag": 58.62654113769531, "eval/post_ent_max": 58.62654113769531, "eval/post_ent_mean": 40.79255294799805, "eval/post_ent_min": 21.23276138305664, "eval/post_ent_std": 7.489870071411133, "eval/prior_ent_mag": 67.7465591430664, "eval/prior_ent_max": 67.7465591430664, "eval/prior_ent_mean": 55.53455352783203, "eval/prior_ent_min": 42.29499053955078, "eval/prior_ent_std": 4.244903087615967, "eval/rep_loss_mean": 16.825183868408203, "eval/rep_loss_std": 10.24761962890625, "eval/reward_avg": 0.05185546725988388, "eval/reward_loss_mean": 0.12811262905597687, "eval/reward_loss_std": 0.6683887839317322, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012028217315674, "eval/reward_neg_acc": 0.9896587133407593, "eval/reward_neg_loss": 0.041854023933410645, "eval/reward_pos_acc": 0.8070175647735596, "eval/reward_pos_loss": 1.591482400894165, "eval/reward_pred": 0.042469389736652374, "eval/reward_rate": 0.0556640625, "replay/size": 869201.0, "replay/inserts": 22992.0, "replay/samples": 22992.0, "replay/insert_wait_avg": 1.4562903797784113e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.703486846732695e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.250804958248297e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3637993335724, "timer/env.step_count": 2874.0, "timer/env.step_total": 224.88479089736938, "timer/env.step_frac": 0.22480300771297834, "timer/env.step_avg": 0.07824801353422735, "timer/env.step_min": 0.023455142974853516, "timer/env.step_max": 3.308582067489624, "timer/replay._sample_count": 22992.0, "timer/replay._sample_total": 11.667346000671387, "timer/replay._sample_frac": 0.011663102971582939, "timer/replay._sample_avg": 0.0005074524182616296, "timer/replay._sample_min": 0.0004215240478515625, "timer/replay._sample_max": 0.022475719451904297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3475.0, "timer/agent.policy_total": 57.54246950149536, "timer/agent.policy_frac": 0.05752154320241227, "timer/agent.policy_avg": 0.0165589840292073, "timer/agent.policy_min": 0.009374856948852539, "timer/agent.policy_max": 0.1179206371307373, "timer/dataset_train_count": 1437.0, "timer/dataset_train_total": 0.15293025970458984, "timer/dataset_train_frac": 0.00015287464401097852, "timer/dataset_train_avg": 0.00010642328441516343, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0008981227874755859, "timer/agent.train_count": 1437.0, "timer/agent.train_total": 644.6083433628082, "timer/agent.train_frac": 0.6443739205599371, "timer/agent.train_avg": 0.44857922293862784, "timer/agent.train_min": 0.433579683303833, "timer/agent.train_max": 2.5128746032714844, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475433349609375, "timer/agent.report_frac": 0.0004752604501743283, "timer/agent.report_avg": 0.2377166748046875, "timer/agent.report_min": 0.22977256774902344, "timer/agent.report_max": 0.24566078186035156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.764649739845208e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.98329654848407}
{"step": 869984, "time": 39475.58170795441, "episode/length": 379.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 39500.20269155502, "eval_episode/length": 169.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 870064, "time": 39502.83598971367, "eval_episode/length": 190.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9685863874345549}
{"step": 870064, "time": 39505.10792398453, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9665071770334929}
{"step": 870064, "time": 39508.587191820145, "eval_episode/length": 252.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 870064, "time": 39510.627967357635, "eval_episode/length": 261.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 870064, "time": 39516.97511959076, "eval_episode/length": 372.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9919571045576407}
{"step": 870064, "time": 39519.72278165817, "eval_episode/length": 397.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.992462311557789}
{"step": 870064, "time": 39521.93454003334, "eval_episode/length": 242.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 870208, "time": 39526.726212739944, "episode/length": 154.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 870456, "time": 39536.28062224388, "episode/length": 374.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 870488, "time": 39539.02942228317, "episode/length": 430.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 870688, "time": 39547.36133480072, "episode/length": 301.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 870952, "time": 39557.58726024628, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 871632, "time": 39582.09552073479, "episode/length": 146.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 872032, "time": 39597.72383713722, "episode/length": 227.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 872208, "time": 39605.106840610504, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 872656, "time": 39621.44688463211, "episode/length": 406.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9901719901719902, "episode/intrinsic_return": 0.0}
{"step": 872824, "time": 39628.31412434578, "episode/length": 354.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9915492957746479, "episode/intrinsic_return": 0.0}
{"step": 872864, "time": 39631.47436118126, "episode/length": 414.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951807228915662, "episode/intrinsic_return": 0.0}
{"step": 872976, "time": 39636.64885687828, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 873296, "time": 39649.04352045059, "episode/length": 292.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 873848, "time": 39668.65522098541, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 874144, "time": 39680.24185347557, "episode/length": 241.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 874232, "time": 39684.48959112167, "episode/length": 442.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 874408, "time": 39691.90236902237, "episode/length": 178.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 874408, "time": 39691.91172719002, "episode/length": 197.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 874496, "time": 39698.416690826416, "episode/length": 229.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 874696, "time": 39706.41692471504, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 874736, "time": 39709.47094321251, "episode/length": 40.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 875336, "time": 39731.04185676575, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 875688, "time": 39744.41508722305, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 875760, "time": 39748.75642824173, "episode/length": 157.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 875760, "time": 39748.76526212692, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 875920, "time": 39757.42110800743, "episode/length": 327.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 876024, "time": 39762.42251825333, "episode/length": 223.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 876232, "time": 39770.98177361488, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 877016, "time": 39800.419979810715, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 877024, "time": 39802.54297065735, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 877104, "time": 39806.75236940384, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 877400, "time": 39818.0732023716, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 877512, "time": 39823.56021785736, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 877552, "time": 39826.69606804848, "episode/length": 223.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 877656, "time": 39831.56541132927, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 877672, "time": 39833.732808828354, "episode/length": 70.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 877888, "time": 39842.627212285995, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 878032, "time": 39849.11539149284, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 878520, "time": 39866.76922607422, "episode/length": 125.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 878528, "time": 39868.88899755478, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 878912, "time": 39883.366884469986, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 879544, "time": 39905.86096692085, "episode/length": 233.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 879648, "time": 39911.28137540817, "episode/length": 261.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 879920, "time": 39921.88239192963, "episode/length": 253.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 880008, "time": 39926.176416397095, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 39948.18751859665, "eval_episode/length": 141.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 880048, "time": 39950.92807483673, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9578313253012049}
{"step": 880048, "time": 39954.30294895172, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 880048, "time": 39956.07740330696, "eval_episode/length": 211.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 880048, "time": 39958.15816116333, "eval_episode/length": 224.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 880048, "time": 39960.11539268494, "eval_episode/length": 233.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 880048, "time": 39965.38276576996, "eval_episode/length": 274.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 880048, "time": 39967.84827041626, "eval_episode/length": 295.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9763513513513513}
{"step": 880216, "time": 39973.34823536873, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 880240, "time": 39975.893599271774, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 880400, "time": 39982.734810590744, "episode/length": 106.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 880416, "time": 39984.94775557518, "episode/length": 376.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9920424403183024, "episode/intrinsic_return": 0.0}
{"step": 880592, "time": 39992.31050372124, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 881360, "time": 40019.42828679085, "episode/length": 179.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 881576, "time": 40027.86081266403, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 881856, "time": 40039.09063053131, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 881936, "time": 40043.335453271866, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 881952, "time": 40045.50181770325, "episode/length": 242.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 882488, "time": 40064.6791870594, "episode/length": 283.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 882888, "time": 40079.40182685852, "episode/length": 404.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9901234567901235, "episode/intrinsic_return": 0.0}
{"step": 882896, "time": 40081.37226343155, "episode/length": 287.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 883640, "time": 40107.41592884064, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 883672, "time": 40110.092729091644, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 883920, "time": 40120.257174253464, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 884432, "time": 40139.05156493187, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 884560, "time": 40144.84531569481, "episode/length": 207.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 884744, "time": 40152.70709466934, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 885128, "time": 40168.79815149307, "episode/length": 398.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 885184, "time": 40172.46901631355, "episode/length": 157.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 885280, "time": 40177.175958395004, "episode/length": 200.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 885488, "time": 40185.907083272934, "episode/length": 515.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 885784, "time": 40197.098039865494, "episode/length": 267.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 886120, "time": 40209.98714756966, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 886256, "time": 40216.22939443588, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 886584, "time": 40228.381866931915, "episode/length": 57.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 886696, "time": 40233.879667282104, "episode/length": 176.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 887016, "time": 40246.739530324936, "episode/length": 153.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 887048, "time": 40249.353155612946, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 887480, "time": 40265.20562505722, "episode/length": 293.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 887552, "time": 40269.487110853195, "episode/length": 295.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 887904, "time": 40282.709877491, "episode/length": 433.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 888368, "time": 40299.75141763687, "episode/length": 263.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 888824, "time": 40316.24764609337, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 888920, "time": 40320.937918663025, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 888968, "time": 40324.091588020325, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 889192, "time": 40333.58935213089, "episode/length": 271.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 889528, "time": 40346.36882710457, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 890024, "time": 40364.69180440903, "episode/length": 415.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9927884615384616, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 40386.356362104416, "eval_episode/length": 145.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 890032, "time": 40390.56606769562, "eval_episode/length": 200.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 890032, "time": 40393.056014060974, "eval_episode/length": 222.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 890032, "time": 40395.18165874481, "eval_episode/length": 233.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9700854700854701}
{"step": 890032, "time": 40397.07193470001, "eval_episode/length": 238.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.99581589958159}
{"step": 890032, "time": 40400.90226769447, "eval_episode/length": 289.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 890032, "time": 40402.96633720398, "eval_episode/length": 300.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 890032, "time": 40404.847312927246, "eval_episode/length": 307.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.987012987012987}
{"step": 890208, "time": 40410.715804338455, "episode/length": 229.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 890240, "time": 40413.3383102417, "episode/length": 335.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 890672, "time": 40429.193024635315, "episode/length": 53.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 890968, "time": 40440.52716255188, "episode/length": 267.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 890992, "time": 40443.08395719528, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 891360, "time": 40456.85970711708, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 891416, "time": 40460.10201668739, "episode/length": 311.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 891529, "time": 40466.43471980095, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.2179255766027115, "train/action_min": 0.0, "train/action_std": 3.170922710615046, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03562778197502827, "train/actor_opt_grad_steps": 54945.0, "train/actor_opt_loss": -8.384020409601575, "train/adv_mag": 0.47400668635964394, "train/adv_max": 0.4195446021416608, "train/adv_mean": 0.002296371774244054, "train/adv_min": -0.4043823688784066, "train/adv_std": 0.05091190601096434, "train/cont_avg": 0.9952751608455882, "train/cont_loss_mean": 0.0003191396089786234, "train/cont_loss_std": 0.009694726509702137, "train/cont_neg_acc": 0.9879114163272521, "train/cont_neg_loss": 0.03681706460942865, "train/cont_pos_acc": 0.999971066327656, "train/cont_pos_loss": 0.00013237903806781633, "train/cont_pred": 0.995284795322839, "train/cont_rate": 0.9952751608455882, "train/dyn_loss_mean": 12.873359932618982, "train/dyn_loss_std": 8.947586115668802, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8905935484696837, "train/extr_critic_critic_opt_grad_steps": 54945.0, "train/extr_critic_critic_opt_loss": 15249.044562844669, "train/extr_critic_mag": 9.613282182637382, "train/extr_critic_max": 9.613282182637382, "train/extr_critic_mean": 3.0563111305236816, "train/extr_critic_min": -0.14359537380583146, "train/extr_critic_std": 2.2365647291435913, "train/extr_return_normed_mag": 1.4778003867934733, "train/extr_return_normed_max": 1.4778003867934733, "train/extr_return_normed_mean": 0.3881240441080402, "train/extr_return_normed_min": -0.10448137133875314, "train/extr_return_normed_std": 0.318568913046928, "train/extr_return_rate": 0.8981311763910687, "train/extr_return_raw_mag": 10.824161964304308, "train/extr_return_raw_max": 10.824161964304308, "train/extr_return_raw_mean": 3.0726409168804394, "train/extr_return_raw_min": -0.4311017120147453, "train/extr_return_raw_std": 2.2663103762794945, "train/extr_reward_mag": 1.0424095111734726, "train/extr_reward_max": 1.0424095111734726, "train/extr_reward_mean": 0.051870624836095995, "train/extr_reward_min": -0.41824984024552736, "train/extr_reward_std": 0.2114201727158883, "train/image_loss_mean": 6.262174104942995, "train/image_loss_std": 11.245193432359134, "train/model_loss_mean": 14.045601641430574, "train/model_loss_std": 14.922898278516882, "train/model_opt_grad_norm": 53.63263353179483, "train/model_opt_grad_steps": 54896.544117647056, "train/model_opt_loss": 18187.09572466682, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1295.9558823529412, "train/policy_entropy_mag": 2.4397109413848206, "train/policy_entropy_max": 2.4397109413848206, "train/policy_entropy_mean": 0.47976183211978746, "train/policy_entropy_min": 0.0793750343077323, "train/policy_entropy_std": 0.5670523148249177, "train/policy_logprob_mag": 7.438383842215819, "train/policy_logprob_max": -0.009455659303485471, "train/policy_logprob_mean": -0.47990748132852945, "train/policy_logprob_min": -7.438383842215819, "train/policy_logprob_std": 1.039368108353194, "train/policy_randomness_mag": 0.8611108998165411, "train/policy_randomness_max": 0.8611108998165411, "train/policy_randomness_mean": 0.16933487339273973, "train/policy_randomness_min": 0.028015903731369796, "train/policy_randomness_std": 0.2001445856602753, "train/post_ent_mag": 59.15522853065939, "train/post_ent_max": 59.15522853065939, "train/post_ent_mean": 42.497930358437934, "train/post_ent_min": 19.75353955521303, "train/post_ent_std": 7.519440440570607, "train/prior_ent_mag": 67.67579645269058, "train/prior_ent_max": 67.67579645269058, "train/prior_ent_mean": 55.453835375168744, "train/prior_ent_min": 40.61585678773768, "train/prior_ent_std": 4.47131867443814, "train/rep_loss_mean": 12.873359932618982, "train/rep_loss_std": 8.947586115668802, "train/reward_avg": 0.03274931043030366, "train/reward_loss_mean": 0.05909241084009409, "train/reward_loss_std": 0.2573156827951179, "train/reward_max_data": 1.0169117687379612, "train/reward_max_pred": 1.0146873365430271, "train/reward_neg_acc": 0.9924190513351384, "train/reward_neg_loss": 0.02923042235402938, "train/reward_pos_acc": 0.971702598473605, "train/reward_pos_loss": 0.8390828537590364, "train/reward_pred": 0.03177253584897913, "train/reward_rate": 0.03704474954044118, "train_stats/sum_log_reward": 9.702150755031134, "train_stats/max_log_achievement_collect_coal": 0.5483870967741935, "train_stats/max_log_achievement_collect_drink": 5.161290322580645, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7956989247311828, "train_stats/max_log_achievement_collect_stone": 10.10752688172043, "train_stats/max_log_achievement_collect_wood": 11.129032258064516, "train_stats/max_log_achievement_defeat_skeleton": 0.0967741935483871, "train_stats/max_log_achievement_defeat_zombie": 1.4623655913978495, "train_stats/max_log_achievement_eat_cow": 0.3225806451612903, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4086021505376345, "train_stats/max_log_achievement_make_wood_sword": 1.8602150537634408, "train_stats/max_log_achievement_place_furnace": 0.010752688172043012, "train_stats/max_log_achievement_place_plant": 1.6559139784946237, "train_stats/max_log_achievement_place_stone": 7.935483870967742, "train_stats/max_log_achievement_place_table": 3.021505376344086, "train_stats/max_log_achievement_wake_up": 1.3978494623655915, "train_stats/mean_log_entropy": 0.4957413559639326, "eval_stats/sum_log_reward": 9.68333355585734, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 3.9583333333333335, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 12.083333333333334, "eval_stats/max_log_achievement_collect_wood": 10.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.16666666666666666, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1666666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_stone": 7.416666666666667, "eval_stats/max_log_achievement_place_table": 2.9166666666666665, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00237353821285069, "report/cont_loss_std": 0.07253681123256683, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.5821982622146606, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.97161550913006e-05, "report/cont_pred": 0.996888279914856, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.808846473693848, "report/dyn_loss_std": 8.466935157775879, "report/image_loss_mean": 4.411932945251465, "report/image_loss_std": 7.701183795928955, "report/model_loss_mean": 12.148927688598633, "report/model_loss_std": 11.311500549316406, "report/post_ent_mag": 60.028018951416016, "report/post_ent_max": 60.028018951416016, "report/post_ent_mean": 42.67932891845703, "report/post_ent_min": 20.757341384887695, "report/post_ent_std": 7.407276153564453, "report/prior_ent_mag": 67.25203704833984, "report/prior_ent_max": 67.25203704833984, "report/prior_ent_mean": 55.46669006347656, "report/prior_ent_min": 40.19195556640625, "report/prior_ent_std": 4.333278656005859, "report/rep_loss_mean": 12.808846473693848, "report/rep_loss_std": 8.466935157775879, "report/reward_avg": 0.03671874850988388, "report/reward_loss_mean": 0.04931357875466347, "report/reward_loss_std": 0.20883174240589142, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023736953735352, "report/reward_neg_acc": 0.9969481229782104, "report/reward_neg_loss": 0.017676984891295433, "report/reward_pos_acc": 0.9756097197532654, "report/reward_pos_loss": 0.807820200920105, "report/reward_pred": 0.03478245809674263, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.746008825255558e-05, "eval/cont_loss_std": 0.0023117114324122667, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0032422319054603577, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.198033563327044e-05, "eval/cont_pred": 0.9950639009475708, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.75846290588379, "eval/dyn_loss_std": 10.25928783416748, "eval/image_loss_mean": 9.755125045776367, "eval/image_loss_std": 13.352065086364746, "eval/model_loss_mean": 19.896190643310547, "eval/model_loss_std": 17.351966857910156, "eval/post_ent_mag": 58.77204132080078, "eval/post_ent_max": 58.77204132080078, "eval/post_ent_mean": 41.19701385498047, "eval/post_ent_min": 18.68222427368164, "eval/post_ent_std": 7.303076267242432, "eval/prior_ent_mag": 67.25203704833984, "eval/prior_ent_max": 67.25203704833984, "eval/prior_ent_mean": 56.01802444458008, "eval/prior_ent_min": 42.85338592529297, "eval/prior_ent_std": 4.474050998687744, "eval/rep_loss_mean": 16.75846290588379, "eval/rep_loss_std": 10.25928783416748, "eval/reward_avg": 0.03691406175494194, "eval/reward_loss_mean": 0.08590026944875717, "eval/reward_loss_std": 0.41307327151298523, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.005380630493164, "eval/reward_neg_acc": 0.9877924919128418, "eval/reward_neg_loss": 0.04332536831498146, "eval/reward_pos_acc": 0.9024389982223511, "eval/reward_pos_loss": 1.1066596508026123, "eval/reward_pred": 0.03610388934612274, "eval/reward_rate": 0.0400390625, "replay/size": 891025.0, "replay/inserts": 21824.0, "replay/samples": 21824.0, "replay/insert_wait_avg": 1.45541957396566e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.827665394701916e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2348183488423845e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6391277313232422e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.175564289093, "timer/env.step_count": 2728.0, "timer/env.step_total": 223.8968985080719, "timer/env.step_frac": 0.22385759710817754, "timer/env.step_avg": 0.0820736431481202, "timer/env.step_min": 0.023074626922607422, "timer/env.step_max": 3.3430025577545166, "timer/replay._sample_count": 21824.0, "timer/replay._sample_total": 11.145264148712158, "timer/replay._sample_frac": 0.0111433077818033, "timer/replay._sample_avg": 0.0005106884232364442, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.010819673538208008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3745.0, "timer/agent.policy_total": 62.70888113975525, "timer/agent.policy_frac": 0.06269787363214338, "timer/agent.policy_avg": 0.016744694563352536, "timer/agent.policy_min": 0.009598970413208008, "timer/agent.policy_max": 0.12207460403442383, "timer/dataset_train_count": 1364.0, "timer/dataset_train_total": 0.14591526985168457, "timer/dataset_train_frac": 0.0001458896568377958, "timer/dataset_train_avg": 0.00010697600429009133, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.00034117698669433594, "timer/agent.train_count": 1364.0, "timer/agent.train_total": 607.9878454208374, "timer/agent.train_frac": 0.6078811232035891, "timer/agent.train_avg": 0.4457388896047195, "timer/agent.train_min": 0.4326448440551758, "timer/agent.train_max": 1.6178529262542725, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47470593452453613, "timer/agent.report_frac": 0.0004746226077438201, "timer/agent.report_avg": 0.23735296726226807, "timer/agent.report_min": 0.23017668724060059, "timer/agent.report_max": 0.24452924728393555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0750597997224994e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 21.819870750897007}
{"step": 891536, "time": 40466.458998441696, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 891936, "time": 40481.93749713898, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 892016, "time": 40486.24881029129, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 892408, "time": 40500.605718135834, "episode/length": 179.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 892536, "time": 40506.3399477005, "episode/length": 445.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910313901345291, "episode/intrinsic_return": 0.0}
{"step": 892952, "time": 40523.45308804512, "episode/length": 244.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 892984, "time": 40526.59537434578, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 893544, "time": 40547.65068268776, "episode/length": 272.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 893800, "time": 40558.05268549919, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 893936, "time": 40564.36689329147, "episode/length": 249.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 894336, "time": 40579.287224292755, "episode/length": 49.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 894416, "time": 40583.64962506294, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 894728, "time": 40595.35818052292, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 894880, "time": 40602.32267284393, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 895112, "time": 40611.35361146927, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 895288, "time": 40618.86344385147, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 895688, "time": 40633.91588330269, "episode/length": 458.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 896240, "time": 40654.15787911415, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 896576, "time": 40667.13501882553, "episode/length": 279.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 896776, "time": 40675.26738405228, "episode/length": 255.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 896904, "time": 40681.063955783844, "episode/length": 252.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 896904, "time": 40681.072549819946, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 896968, "time": 40686.57943844795, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 897448, "time": 40704.12703824043, "episode/length": 291.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 897808, "time": 40717.78169322014, "episode/length": 500.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900199600798403, "episode/intrinsic_return": 0.0}
{"step": 898144, "time": 40730.70675611496, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 898456, "time": 40742.33222913742, "episode/length": 276.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 898552, "time": 40747.07531642914, "episode/length": 246.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 898672, "time": 40753.064039468765, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 898680, "time": 40754.580300569534, "episode/length": 221.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 898784, "time": 40759.90212273598, "episode/length": 226.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 899568, "time": 40788.00494813919, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 899640, "time": 40792.28254199028, "episode/length": 273.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 899848, "time": 40801.514123916626, "episode/length": 212.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 40829.70637893677, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 900016, "time": 40831.64901089668, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 900016, "time": 40833.5374083519, "eval_episode/length": 182.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 900016, "time": 40835.57532501221, "eval_episode/length": 190.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9633507853403142}
{"step": 900016, "time": 40837.535343170166, "eval_episode/length": 199.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 900016, "time": 40839.38052773476, "eval_episode/length": 203.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 900016, "time": 40843.98918008804, "eval_episode/length": 271.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9963235294117647}
{"step": 900016, "time": 40846.154217004776, "eval_episode/length": 284.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 900232, "time": 40853.11682391167, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 900320, "time": 40857.781916856766, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 900608, "time": 40869.71592783928, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 900624, "time": 40871.866584062576, "episode/length": 243.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 901040, "time": 40887.20064854622, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 901288, "time": 40898.6066198349, "episode/length": 325.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 901416, "time": 40904.428575754166, "episode/length": 230.0, "episode/score": 10.10000005364418, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 901416, "time": 40904.43744087219, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 901680, "time": 40916.760798215866, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 901760, "time": 40920.95338797569, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 901800, "time": 40923.60244202614, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 902464, "time": 40947.958453416824, "episode/length": 229.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 902600, "time": 40953.87352204323, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 903064, "time": 40970.986953020096, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 903104, "time": 40974.154500722885, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 903304, "time": 40982.122066259384, "episode/length": 235.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 903920, "time": 41004.477952480316, "episode/length": 264.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 903928, "time": 41006.21528196335, "episode/length": 313.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 904216, "time": 41017.412824869156, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 904360, "time": 41023.89226555824, "episode/length": 334.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 904440, "time": 41028.13994002342, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 904592, "time": 41035.00906944275, "episode/length": 190.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 905120, "time": 41054.19218206406, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 905256, "time": 41060.12264370918, "episode/length": 268.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 906072, "time": 41089.14665412903, "episode/length": 231.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 906560, "time": 41108.33900618553, "episode/length": 274.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 906600, "time": 41111.322674274445, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 906664, "time": 41115.42180156708, "episode/length": 277.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 906728, "time": 41119.04701447487, "episode/length": 350.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 906784, "time": 41122.64238977432, "episode/length": 207.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 906784, "time": 41122.6513171196, "episode/length": 190.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 907352, "time": 41144.556913137436, "episode/length": 77.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 907536, "time": 41152.47763347626, "episode/length": 367.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 907864, "time": 41164.72740864754, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 907896, "time": 41167.343980550766, "episode/length": 227.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 908144, "time": 41177.45788383484, "episode/length": 169.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 908744, "time": 41198.843658685684, "episode/length": 244.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 908808, "time": 41202.59264540672, "episode/length": 280.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 908984, "time": 41209.98312544823, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 909344, "time": 41225.46736907959, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 909536, "time": 41233.60844254494, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 909624, "time": 41238.03081250191, "episode/length": 219.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41266.767362356186, "eval_episode/length": 34.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8571428571428571}
{"step": 910000, "time": 41275.33989191055, "eval_episode/length": 193.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 910000, "time": 41277.511605262756, "eval_episode/length": 206.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.966183574879227}
{"step": 910000, "time": 41279.254308223724, "eval_episode/length": 210.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.976303317535545}
{"step": 910000, "time": 41281.1581158638, "eval_episode/length": 218.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 910000, "time": 41284.11478686333, "eval_episode/length": 248.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9799196787148594}
{"step": 910000, "time": 41286.73655438423, "eval_episode/length": 64.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 910000, "time": 41288.491589307785, "eval_episode/length": 274.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 910080, "time": 41291.161584854126, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 910200, "time": 41296.470700740814, "episode/length": 181.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 910224, "time": 41299.07855439186, "episode/length": 259.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 910512, "time": 41310.37880706787, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 910760, "time": 41320.286027908325, "episode/length": 221.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 911552, "time": 41348.742062330246, "episode/length": 168.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 911800, "time": 41358.348088502884, "episode/length": 306.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 911872, "time": 41362.562334775925, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 911896, "time": 41364.63852310181, "episode/length": 172.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 911992, "time": 41369.28295779228, "episode/length": 220.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 912112, "time": 41374.93739724159, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 912464, "time": 41388.16555929184, "episode/length": 365.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 912744, "time": 41398.766988277435, "episode/length": 389.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 913072, "time": 41411.54821181297, "episode/length": 189.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 913480, "time": 41426.58406162262, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 913736, "time": 41436.58033370972, "episode/length": 202.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 913856, "time": 41442.58934831619, "episode/length": 244.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 914440, "time": 41463.365183115005, "episode/length": 211.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 914457, "time": 41466.486959934235, "train_stats/sum_log_reward": 9.79148964171714, "train_stats/max_log_achievement_collect_coal": 0.574468085106383, "train_stats/max_log_achievement_collect_drink": 6.276595744680851, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6170212765957446, "train_stats/max_log_achievement_collect_stone": 11.159574468085106, "train_stats/max_log_achievement_collect_wood": 10.829787234042554, "train_stats/max_log_achievement_defeat_skeleton": 0.06382978723404255, "train_stats/max_log_achievement_defeat_zombie": 1.4893617021276595, "train_stats/max_log_achievement_eat_cow": 0.2978723404255319, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.446808510638298, "train_stats/max_log_achievement_make_wood_sword": 1.5957446808510638, "train_stats/max_log_achievement_place_furnace": 0.02127659574468085, "train_stats/max_log_achievement_place_plant": 1.574468085106383, "train_stats/max_log_achievement_place_stone": 8.52127659574468, "train_stats/max_log_achievement_place_table": 2.893617021276596, "train_stats/max_log_achievement_wake_up": 1.3404255319148937, "train_stats/mean_log_entropy": 0.5166096167361482, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.206255719378278, "train/action_min": 0.0, "train/action_std": 3.1522435741824704, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.034882783407827356, "train/actor_opt_grad_steps": 56340.0, "train/actor_opt_loss": -7.822839377539141, "train/adv_mag": 0.46349863093216104, "train/adv_max": 0.42684005857347607, "train/adv_mean": 0.0021661132030623355, "train/adv_min": -0.37965096126903186, "train/adv_std": 0.049981841361606036, "train/cont_avg": 0.9949191433566433, "train/cont_loss_mean": 0.0001885836437339633, "train/cont_loss_std": 0.0057122895484585535, "train/cont_neg_acc": 0.9938741040901399, "train/cont_neg_loss": 0.01722992226903341, "train/cont_pos_acc": 0.9999725485181475, "train/cont_pos_loss": 6.605214644782687e-05, "train/cont_pred": 0.9949304169708199, "train/cont_rate": 0.9949191433566433, "train/dyn_loss_mean": 12.815681324138508, "train/dyn_loss_std": 8.96079009396213, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8535372360602959, "train/extr_critic_critic_opt_grad_steps": 56340.0, "train/extr_critic_critic_opt_loss": 14879.252636035839, "train/extr_critic_mag": 9.589963726230435, "train/extr_critic_max": 9.589963726230435, "train/extr_critic_mean": 3.010026016435423, "train/extr_critic_min": -0.14702274415876482, "train/extr_critic_std": 2.2408572218634863, "train/extr_return_normed_mag": 1.4940298770691132, "train/extr_return_normed_max": 1.4940298770691132, "train/extr_return_normed_mean": 0.38566557687896114, "train/extr_return_normed_min": -0.10626483010453777, "train/extr_return_normed_std": 0.3205927458259609, "train/extr_return_rate": 0.8899685415354642, "train/extr_return_raw_mag": 10.860051982052676, "train/extr_return_raw_max": 10.860051982052676, "train/extr_return_raw_mean": 3.0253333203442447, "train/extr_return_raw_min": -0.45225226847858696, "train/extr_return_raw_std": 2.266572657164994, "train/extr_reward_mag": 1.0463280060908178, "train/extr_reward_max": 1.0463280060908178, "train/extr_reward_mean": 0.052001412723447896, "train/extr_reward_min": -0.40899550581311844, "train/extr_reward_std": 0.21180900024784194, "train/image_loss_mean": 6.199089912267832, "train/image_loss_std": 11.40823375261747, "train/model_loss_mean": 13.94639291296472, "train/model_loss_std": 15.076161704696975, "train/model_opt_grad_norm": 51.933618092036745, "train/model_opt_grad_steps": 56290.32167832168, "train/model_opt_loss": 18381.04699792395, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1319.93006993007, "train/policy_entropy_mag": 2.475436068914987, "train/policy_entropy_max": 2.475436068914987, "train/policy_entropy_mean": 0.5015290567091295, "train/policy_entropy_min": 0.0793750405936808, "train/policy_entropy_std": 0.5876493572771966, "train/policy_logprob_mag": 7.43838383601262, "train/policy_logprob_max": -0.009455660045459554, "train/policy_logprob_mean": -0.5014126075731291, "train/policy_logprob_min": -7.43838383601262, "train/policy_logprob_std": 1.0540626124068573, "train/policy_randomness_mag": 0.8737202995306962, "train/policy_randomness_max": 0.8737202995306962, "train/policy_randomness_mean": 0.1770177480432537, "train/policy_randomness_min": 0.02801590596514565, "train/policy_randomness_std": 0.20741443586099398, "train/post_ent_mag": 59.010438185471756, "train/post_ent_max": 59.010438185471756, "train/post_ent_mean": 42.533830762743115, "train/post_ent_min": 19.862498043300388, "train/post_ent_std": 7.514135013927113, "train/prior_ent_mag": 67.68316810447853, "train/prior_ent_max": 67.68316810447853, "train/prior_ent_mean": 55.42407949487646, "train/prior_ent_min": 40.47606136081936, "train/prior_ent_std": 4.535948531610982, "train/rep_loss_mean": 12.815681324138508, "train/rep_loss_std": 8.96079009396213, "train/reward_avg": 0.032484702570559264, "train/reward_loss_mean": 0.0577056891695186, "train/reward_loss_std": 0.24856630780480124, "train/reward_max_data": 1.0237762294449173, "train/reward_max_pred": 1.0155361215551417, "train/reward_neg_acc": 0.9922214738138906, "train/reward_neg_loss": 0.02818770814113892, "train/reward_pos_acc": 0.9705887720301435, "train/reward_pos_loss": 0.8310318972680952, "train/reward_pred": 0.031673340647891686, "train/reward_rate": 0.03691133085664336, "eval_stats/sum_log_reward": 9.412500262260437, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 10.4375, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 7.5, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.7685064196703024e-06, "report/cont_loss_std": 3.644268144853413e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.311209679348394e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4717858195799636e-06, "report/cont_pred": 0.9941384792327881, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.638587951660156, "report/dyn_loss_std": 9.350655555725098, "report/image_loss_mean": 5.100444793701172, "report/image_loss_std": 10.627677917480469, "report/model_loss_mean": 12.750419616699219, "report/model_loss_std": 14.468856811523438, "report/post_ent_mag": 60.3001708984375, "report/post_ent_max": 60.3001708984375, "report/post_ent_mean": 43.32709884643555, "report/post_ent_min": 20.11969566345215, "report/post_ent_std": 7.788689613342285, "report/prior_ent_mag": 67.48856353759766, "report/prior_ent_max": 67.48856353759766, "report/prior_ent_mean": 56.122108459472656, "report/prior_ent_min": 44.36781311035156, "report/prior_ent_std": 4.122533798217773, "report/rep_loss_mean": 12.638587951660156, "report/rep_loss_std": 9.350655555725098, "report/reward_avg": 0.03818359225988388, "report/reward_loss_mean": 0.06681899726390839, "report/reward_loss_std": 0.3274037837982178, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029411315917969, "report/reward_neg_acc": 0.9989805817604065, "report/reward_neg_loss": 0.021443363279104233, "report/reward_pos_acc": 0.8837209343910217, "report/reward_pos_loss": 1.102016568183899, "report/reward_pred": 0.032045651227235794, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.81843141844729e-06, "eval/cont_loss_std": 8.324930240632966e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.697436715010554e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.5799710025894456e-06, "eval/cont_pred": 0.997065007686615, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.512598037719727, "eval/dyn_loss_std": 10.255743980407715, "eval/image_loss_mean": 10.164066314697266, "eval/image_loss_std": 12.663159370422363, "eval/model_loss_mean": 20.154457092285156, "eval/model_loss_std": 16.733598709106445, "eval/post_ent_mag": 60.870338439941406, "eval/post_ent_max": 60.870338439941406, "eval/post_ent_mean": 42.0933837890625, "eval/post_ent_min": 19.20484161376953, "eval/post_ent_std": 8.065149307250977, "eval/prior_ent_mag": 67.48856353759766, "eval/prior_ent_max": 67.48856353759766, "eval/prior_ent_mean": 57.038002014160156, "eval/prior_ent_min": 43.123748779296875, "eval/prior_ent_std": 4.455533981323242, "eval/rep_loss_mean": 16.512598037719727, "eval/rep_loss_std": 10.255743980407715, "eval/reward_avg": 0.02949218638241291, "eval/reward_loss_mean": 0.0828249529004097, "eval/reward_loss_std": 0.44291311502456665, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002826452255249, "eval/reward_neg_acc": 0.996966540813446, "eval/reward_neg_loss": 0.036333341151475906, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 1.3965449333190918, "eval/reward_pred": 0.02414005622267723, "eval/reward_rate": 0.0341796875, "replay/size": 913953.0, "replay/inserts": 22928.0, "replay/samples": 22928.0, "replay/insert_wait_avg": 1.4653363098069995e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.454698389589744e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4480.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2602124895368303e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.034895658493, "timer/env.step_count": 2866.0, "timer/env.step_total": 231.97714471817017, "timer/env.step_frac": 0.23196905000542023, "timer/env.step_avg": 0.08094108329315079, "timer/env.step_min": 0.023445844650268555, "timer/env.step_max": 3.393446683883667, "timer/replay._sample_count": 22928.0, "timer/replay._sample_total": 11.740583658218384, "timer/replay._sample_frac": 0.01174017397711663, "timer/replay._sample_avg": 0.0005120631393151772, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.011211395263671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3426.0, "timer/agent.policy_total": 56.715107679367065, "timer/agent.policy_frac": 0.05671312863739806, "timer/agent.policy_avg": 0.01655432214809313, "timer/agent.policy_min": 0.009640216827392578, "timer/agent.policy_max": 0.09796905517578125, "timer/dataset_train_count": 1433.0, "timer/dataset_train_total": 0.15439534187316895, "timer/dataset_train_frac": 0.00015438995433404774, "timer/dataset_train_avg": 0.0001077427368270544, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0010373592376708984, "timer/agent.train_count": 1433.0, "timer/agent.train_total": 641.836550951004, "timer/agent.train_frac": 0.6418141544234552, "timer/agent.train_avg": 0.44789710464131477, "timer/agent.train_min": 0.43648815155029297, "timer/agent.train_max": 1.715787649154663, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755418300628662, "timer/agent.report_frac": 0.0004755252362966156, "timer/agent.report_avg": 0.2377709150314331, "timer/agent.report_min": 0.23191189765930176, "timer/agent.report_max": 0.24362993240356445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8609231154227394e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.92688242555483}
{"step": 914600, "time": 41471.21772503853, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 914608, "time": 41473.2668864727, "episode/length": 326.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 914728, "time": 41478.57955813408, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 914840, "time": 41483.85479450226, "episode/length": 169.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 915224, "time": 41498.20065498352, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 916104, "time": 41529.418041944504, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 916120, "time": 41531.646404743195, "episode/length": 539.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9981481481481481, "episode/intrinsic_return": 0.0}
{"step": 916184, "time": 41535.34669446945, "episode/length": 290.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 916592, "time": 41550.755522727966, "episode/length": 170.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 916688, "time": 41555.63147830963, "episode/length": 259.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 916704, "time": 41557.71619725227, "episode/length": 262.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 917256, "time": 41577.55456709862, "episode/length": 301.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 917768, "time": 41597.91875290871, "episode/length": 146.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 917824, "time": 41601.579820632935, "episode/length": 141.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 917968, "time": 41607.855935812, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 918296, "time": 41620.2497689724, "episode/length": 445.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9865470852017937, "episode/intrinsic_return": 0.0}
{"step": 918464, "time": 41627.71702122688, "episode/length": 292.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 918512, "time": 41630.901082754135, "episode/length": 300.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 918512, "time": 41630.911870479584, "episode/length": 225.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 918600, "time": 41636.971539497375, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 919464, "time": 41667.164867162704, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 919536, "time": 41671.234580516815, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 919536, "time": 41671.24306178093, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 919856, "time": 41685.17603635788, "episode/length": 253.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 41715.923801898956, "eval_episode/length": 150.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 920088, "time": 41719.089205265045, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 920088, "time": 41721.257096767426, "eval_episode/length": 195.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 920088, "time": 41724.37553739548, "eval_episode/length": 229.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 920088, "time": 41726.27761363983, "eval_episode/length": 240.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.975103734439834}
{"step": 920088, "time": 41726.28632879257, "eval_episode/length": 240.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.975103734439834}
{"step": 920088, "time": 41729.89833712578, "eval_episode/length": 246.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.979757085020243}
{"step": 920088, "time": 41731.67922663689, "eval_episode/length": 56.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9298245614035088}
{"step": 920224, "time": 41736.4847009182, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 920296, "time": 41740.42089676857, "episode/length": 228.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 920504, "time": 41748.898446559906, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 921008, "time": 41767.30585837364, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 921168, "time": 41774.33286523819, "episode/length": 203.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 921640, "time": 41791.44839811325, "episode/length": 271.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 921744, "time": 41796.58652186394, "episode/length": 235.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 922232, "time": 41814.38046956062, "episode/length": 464.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 922248, "time": 41816.41336274147, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 922512, "time": 41826.970487594604, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 922672, "time": 41833.95040178299, "episode/length": 296.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 922848, "time": 41841.33219623566, "episode/length": 229.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 922960, "time": 41846.56881356239, "episode/length": 223.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 923128, "time": 41853.431377887726, "episode/length": 185.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 923752, "time": 41875.95914673805, "episode/length": 250.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 923792, "time": 41879.127720832825, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 924152, "time": 41892.752511262894, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 924320, "time": 41900.080397605896, "episode/length": 183.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 924400, "time": 41904.29767513275, "episode/length": 270.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 924680, "time": 41915.038918972015, "episode/length": 193.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 925000, "time": 41927.35006928444, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 925048, "time": 41930.61444067955, "episode/length": 316.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 925264, "time": 41939.60382246971, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 925744, "time": 41958.966485500336, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 925936, "time": 41967.00269627571, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 926072, "time": 41972.95424389839, "episode/length": 239.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 926128, "time": 41976.571442604065, "episode/length": 395.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 926400, "time": 41987.325849056244, "episode/length": 174.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 926672, "time": 41997.92321777344, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 926688, "time": 41999.97923707962, "episode/length": 204.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 927136, "time": 42016.546773433685, "episode/length": 233.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 927440, "time": 42028.21633267403, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 927584, "time": 42034.516285419464, "episode/length": 205.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 927848, "time": 42044.72571563721, "episode/length": 144.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 928312, "time": 42061.67596030235, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 928584, "time": 42072.35650205612, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 929016, "time": 42088.30765461922, "episode/length": 145.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 929232, "time": 42097.24871683121, "episode/length": 387.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 929336, "time": 42102.0646944046, "episode/length": 218.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 929696, "time": 42115.71726298332, "episode/length": 319.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 929960, "time": 42125.82055068016, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 42150.150975227356, "eval_episode/length": 44.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 930072, "time": 42157.83023190498, "eval_episode/length": 179.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 930072, "time": 42160.018990039825, "eval_episode/length": 190.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9685863874345549}
{"step": 930072, "time": 42163.240290641785, "eval_episode/length": 224.0, "eval_episode/score": 12.099999964237213, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 930072, "time": 42164.998404979706, "eval_episode/length": 227.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 930072, "time": 42171.22525572777, "eval_episode/length": 154.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.967741935483871}
{"step": 930072, "time": 42174.02868556976, "eval_episode/length": 317.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9968553459119497}
{"step": 930072, "time": 42176.00359249115, "eval_episode/length": 371.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 930208, "time": 42180.75232028961, "episode/length": 202.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 930600, "time": 42195.2147436142, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 930688, "time": 42199.83308887482, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 930960, "time": 42210.408898591995, "episode/length": 439.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 931176, "time": 42219.06029510498, "episode/length": 596.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 931656, "time": 42236.569625377655, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 931712, "time": 42240.13158583641, "episode/length": 251.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 932256, "time": 42260.04019832611, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 932784, "time": 42279.276717185974, "episode/length": 272.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 932872, "time": 42283.564553022385, "episode/length": 441.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.0}
{"step": 932960, "time": 42288.25087308884, "episode/length": 249.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 933008, "time": 42291.370752334595, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 933352, "time": 42304.05954289436, "episode/length": 392.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 933352, "time": 42304.068230867386, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 933544, "time": 42313.88542342186, "episode/length": 235.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 934184, "time": 42338.38656306267, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 934688, "time": 42357.05690956116, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 934760, "time": 42360.89297747612, "episode/length": 312.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 934792, "time": 42363.54146075249, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 934832, "time": 42366.75315308571, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 934912, "time": 42371.44919586182, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 935896, "time": 42405.61455106735, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 936056, "time": 42412.452995061874, "episode/length": 337.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.0}
{"step": 936280, "time": 42422.28509807587, "episode/length": 47.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 936360, "time": 42426.67790865898, "episode/length": 180.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 936392, "time": 42429.3784661293, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 936424, "time": 42432.12821793556, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 936456, "time": 42434.81698870659, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 936480, "time": 42437.32280874252, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 936920, "time": 42453.21658563614, "episode/length": 421.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 937241, "time": 42466.51756834984, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.177942235986669, "train/action_min": 0.0, "train/action_std": 3.127579602328214, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03544870299007093, "train/actor_opt_grad_steps": 57770.0, "train/actor_opt_loss": -8.39648229779897, "train/adv_mag": 0.4692264820312287, "train/adv_max": 0.41789715586008724, "train/adv_mean": 0.0021786979209378094, "train/adv_min": -0.39063734305905295, "train/adv_std": 0.050301129819004683, "train/cont_avg": 0.9950762128496503, "train/cont_loss_mean": 0.00026353090621775914, "train/cont_loss_std": 0.008080982350622334, "train/cont_neg_acc": 0.9927572437099643, "train/cont_neg_loss": 0.03826989976362717, "train/cont_pos_acc": 0.9999656706423192, "train/cont_pos_loss": 0.00010138320735685504, "train/cont_pred": 0.9950806477686742, "train/cont_rate": 0.9950762128496503, "train/dyn_loss_mean": 12.795414077652085, "train/dyn_loss_std": 8.941918419791268, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8782297289454853, "train/extr_critic_critic_opt_grad_steps": 57770.0, "train/extr_critic_critic_opt_loss": 15180.382020323426, "train/extr_critic_mag": 9.566755808316744, "train/extr_critic_max": 9.566755808316744, "train/extr_critic_mean": 2.9107799571710866, "train/extr_critic_min": -0.14862035371206858, "train/extr_critic_std": 2.2391297775548655, "train/extr_return_normed_mag": 1.489216716973098, "train/extr_return_normed_max": 1.489216716973098, "train/extr_return_normed_mean": 0.3775980485069168, "train/extr_return_normed_min": -0.1009089871198981, "train/extr_return_normed_std": 0.322567878799005, "train/extr_return_rate": 0.8752263167521337, "train/extr_return_raw_mag": 10.74357320211984, "train/extr_return_raw_max": 10.74357320211984, "train/extr_return_raw_mean": 2.9260942852580465, "train/extr_return_raw_min": -0.43913557625317073, "train/extr_return_raw_std": 2.268422296830824, "train/extr_reward_mag": 1.0453984887449892, "train/extr_reward_max": 1.0453984887449892, "train/extr_reward_mean": 0.05095722618792857, "train/extr_reward_min": -0.4167517957153854, "train/extr_reward_std": 0.2099016164983069, "train/image_loss_mean": 6.317895792580985, "train/image_loss_std": 11.423966744562962, "train/model_loss_mean": 14.054777092033333, "train/model_loss_std": 15.052482104801632, "train/model_opt_grad_norm": 50.33518391055661, "train/model_opt_grad_steps": 57718.58041958042, "train/model_opt_loss": 13774.189603365385, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 979.020979020979, "train/policy_entropy_mag": 2.4646196215302796, "train/policy_entropy_max": 2.4646196215302796, "train/policy_entropy_mean": 0.4916320424396675, "train/policy_entropy_min": 0.07937503288259039, "train/policy_entropy_std": 0.572917707733341, "train/policy_logprob_mag": 7.438383856019773, "train/policy_logprob_max": -0.009455659218340904, "train/policy_logprob_mean": -0.4920107484697462, "train/policy_logprob_min": -7.438383856019773, "train/policy_logprob_std": 1.051307522750401, "train/policy_randomness_mag": 0.8699025703476859, "train/policy_randomness_max": 0.8699025703476859, "train/policy_randomness_mean": 0.17352453634872303, "train/policy_randomness_min": 0.028015903190716163, "train/policy_randomness_std": 0.20221480956444374, "train/post_ent_mag": 59.33169665036502, "train/post_ent_max": 59.33169665036502, "train/post_ent_mean": 42.7244053553868, "train/post_ent_min": 19.815048137744824, "train/post_ent_std": 7.5568653686896905, "train/prior_ent_mag": 67.77534575562377, "train/prior_ent_max": 67.77534575562377, "train/prior_ent_mean": 55.576390299763716, "train/prior_ent_min": 40.7621016068892, "train/prior_ent_std": 4.4751487811962205, "train/rep_loss_mean": 12.795414077652085, "train/rep_loss_std": 8.941918419791268, "train/reward_avg": 0.03200120185143673, "train/reward_loss_mean": 0.05936942265167103, "train/reward_loss_std": 0.2528249649526356, "train/reward_max_data": 1.0230769285788903, "train/reward_max_pred": 1.0155259712592706, "train/reward_neg_acc": 0.9918122604176715, "train/reward_neg_loss": 0.03020954320949691, "train/reward_pos_acc": 0.970702696096647, "train/reward_pos_loss": 0.8289946967905218, "train/reward_pred": 0.031125112788400033, "train/reward_rate": 0.036446951486013984, "train_stats/sum_log_reward": 9.910526606911107, "train_stats/max_log_achievement_collect_coal": 0.4421052631578947, "train_stats/max_log_achievement_collect_drink": 6.842105263157895, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8526315789473684, "train_stats/max_log_achievement_collect_stone": 10.663157894736843, "train_stats/max_log_achievement_collect_wood": 11.126315789473685, "train_stats/max_log_achievement_defeat_skeleton": 0.06315789473684211, "train_stats/max_log_achievement_defeat_zombie": 1.4736842105263157, "train_stats/max_log_achievement_eat_cow": 0.16842105263157894, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.021052631578947368, "train_stats/max_log_achievement_make_stone_sword": 0.010526315789473684, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3578947368421053, "train_stats/max_log_achievement_make_wood_sword": 1.6421052631578947, "train_stats/max_log_achievement_place_furnace": 0.010526315789473684, "train_stats/max_log_achievement_place_plant": 1.8, "train_stats/max_log_achievement_place_stone": 9.063157894736841, "train_stats/max_log_achievement_place_table": 2.968421052631579, "train_stats/max_log_achievement_wake_up": 1.4842105263157894, "train_stats/mean_log_entropy": 0.5089001810864399, "eval_stats/sum_log_reward": 9.537500351667404, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 4.5625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 9.5625, "eval_stats/max_log_achievement_collect_wood": 9.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 6.9375, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.606040106911678e-05, "report/cont_loss_std": 0.0005075433873571455, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.538299875392113e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.6102270567207597e-05, "report/cont_pred": 0.996068000793457, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.474966049194336, "report/dyn_loss_std": 9.357659339904785, "report/image_loss_mean": 5.517177581787109, "report/image_loss_std": 8.48242473602295, "report/model_loss_mean": 13.672723770141602, "report/model_loss_std": 12.73401927947998, "report/post_ent_mag": 56.34239196777344, "report/post_ent_max": 56.34239196777344, "report/post_ent_mean": 41.88019561767578, "report/post_ent_min": 20.449546813964844, "report/post_ent_std": 7.117718696594238, "report/prior_ent_mag": 67.90354919433594, "report/prior_ent_max": 67.90354919433594, "report/prior_ent_mean": 55.641448974609375, "report/prior_ent_min": 43.871246337890625, "report/prior_ent_std": 4.358449459075928, "report/rep_loss_mean": 13.474966049194336, "report/rep_loss_std": 9.357659339904785, "report/reward_avg": 0.0400390625, "report/reward_loss_mean": 0.07054148614406586, "report/reward_loss_std": 0.30535978078842163, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.081791639328003, "report/reward_neg_acc": 0.991828441619873, "report/reward_neg_loss": 0.03212706372141838, "report/reward_pos_acc": 0.9555555582046509, "report/reward_pos_loss": 0.9062687754631042, "report/reward_pred": 0.03728771209716797, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.5744091797387227e-05, "eval/cont_loss_std": 0.0004070329014211893, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0026208048220723867, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.9616544452437665e-06, "eval/cont_pred": 0.9951270222663879, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.453628540039062, "eval/dyn_loss_std": 10.512266159057617, "eval/image_loss_mean": 9.919890403747559, "eval/image_loss_std": 14.742398262023926, "eval/model_loss_mean": 20.521286010742188, "eval/model_loss_std": 18.768810272216797, "eval/post_ent_mag": 58.545654296875, "eval/post_ent_max": 58.545654296875, "eval/post_ent_mean": 41.201995849609375, "eval/post_ent_min": 18.423505783081055, "eval/post_ent_std": 7.9399237632751465, "eval/prior_ent_mag": 67.90354919433594, "eval/prior_ent_max": 67.90354919433594, "eval/prior_ent_mean": 57.02356719970703, "eval/prior_ent_min": 39.25398254394531, "eval/prior_ent_std": 4.434823989868164, "eval/rep_loss_mean": 17.453628540039062, "eval/rep_loss_std": 10.512266159057617, "eval/reward_avg": 0.04628906399011612, "eval/reward_loss_mean": 0.1292036473751068, "eval/reward_loss_std": 0.6545489430427551, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0020461082458496, "eval/reward_neg_acc": 0.9876543879508972, "eval/reward_neg_loss": 0.0483844056725502, "eval/reward_pos_acc": 0.8653846383094788, "eval/reward_pos_loss": 1.639901876449585, "eval/reward_pred": 0.03721519932150841, "eval/reward_rate": 0.05078125, "replay/size": 936737.0, "replay/inserts": 22784.0, "replay/samples": 22784.0, "replay/insert_wait_avg": 1.4409443803047867e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.250335311621762e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2539386749267579e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0189418792725, "timer/env.step_count": 2848.0, "timer/env.step_total": 228.43047642707825, "timer/env.step_frac": 0.22842614960652974, "timer/env.step_avg": 0.08020733020613703, "timer/env.step_min": 0.023547649383544922, "timer/env.step_max": 3.3987820148468018, "timer/replay._sample_count": 22784.0, "timer/replay._sample_total": 11.547499418258667, "timer/replay._sample_frac": 0.011547280691061892, "timer/replay._sample_avg": 0.0005068249393547519, "timer/replay._sample_min": 0.0004184246063232422, "timer/replay._sample_max": 0.011489391326904297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3473.0, "timer/agent.policy_total": 58.91487526893616, "timer/agent.policy_frac": 0.05891375933161941, "timer/agent.policy_avg": 0.01696368421219008, "timer/agent.policy_min": 0.009580373764038086, "timer/agent.policy_max": 0.16542887687683105, "timer/dataset_train_count": 1424.0, "timer/dataset_train_total": 0.15320634841918945, "timer/dataset_train_frac": 0.00015320344645800252, "timer/dataset_train_avg": 0.0001075887278224645, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0003459453582763672, "timer/agent.train_count": 1424.0, "timer/agent.train_total": 637.1096379756927, "timer/agent.train_frac": 0.6370975701504342, "timer/agent.train_avg": 0.4474084536346157, "timer/agent.train_min": 0.43365025520324707, "timer/agent.train_max": 1.7097489833831787, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47191739082336426, "timer/agent.report_frac": 0.000471908451990439, "timer/agent.report_avg": 0.23595869541168213, "timer/agent.report_min": 0.2279524803161621, "timer/agent.report_max": 0.24396491050720215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051700007566881e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 22.783250032377488}
{"step": 937584, "time": 42478.30763792992, "episode/length": 190.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 937968, "time": 42492.95271039009, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 938032, "time": 42496.597516298294, "episode/length": 196.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 938256, "time": 42505.63946390152, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 938296, "time": 42508.78080368042, "episode/length": 237.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 939232, "time": 42542.482226610184, "episode/length": 288.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9688581314878892, "episode/intrinsic_return": 0.0}
{"step": 939264, "time": 42545.249569654465, "episode/length": 209.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 939728, "time": 42562.4109146595, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 939792, "time": 42566.16923284531, "episode/length": 420.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9881235154394299, "episode/intrinsic_return": 0.0}
{"step": 939944, "time": 42573.15797448158, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 42600.78127980232, "eval_episode/length": 208.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 940056, "time": 42602.505229234695, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 940056, "time": 42602.51400375366, "eval_episode/length": 209.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 940056, "time": 42606.46628451347, "eval_episode/length": 222.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 940056, "time": 42608.909471035004, "eval_episode/length": 237.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9621848739495799}
{"step": 940056, "time": 42610.86960530281, "eval_episode/length": 248.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 940056, "time": 42613.77817630768, "eval_episode/length": 281.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9964539007092199}
{"step": 940056, "time": 42616.69569826126, "eval_episode/length": 311.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9967948717948718}
{"step": 940120, "time": 42618.837814331055, "episode/length": 227.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 940720, "time": 42640.76546025276, "episode/length": 185.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 940824, "time": 42645.706037044525, "episode/length": 557.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 941552, "time": 42671.76832032204, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 941760, "time": 42680.27373075485, "episode/length": 245.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 941800, "time": 42682.89049267769, "episode/length": 258.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 941832, "time": 42685.5040705204, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 941856, "time": 42688.09781217575, "episode/length": 449.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9911111111111112, "episode/intrinsic_return": 0.0}
{"step": 942448, "time": 42710.990780353546, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 942552, "time": 42715.88240861893, "episode/length": 410.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 942952, "time": 42731.53938174248, "episode/length": 174.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 943256, "time": 42743.26529049873, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 943952, "time": 42768.25000119209, "episode/length": 261.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 944136, "time": 42775.68146443367, "episode/length": 296.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 944176, "time": 42778.66283941269, "episode/length": 202.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 944416, "time": 42788.17192006111, "episode/length": 448.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9977728285077951, "episode/intrinsic_return": 0.0}
{"step": 944824, "time": 42803.004757881165, "episode/length": 296.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 945104, "time": 42814.095933675766, "episode/length": 408.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853300733496333, "episode/intrinsic_return": 0.0}
{"step": 945368, "time": 42824.3267185688, "episode/length": 301.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 945448, "time": 42828.528054475784, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 945800, "time": 42841.91476607323, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 945888, "time": 42846.58614015579, "episode/length": 241.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 946304, "time": 42862.08670926094, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 946928, "time": 42884.41162443161, "episode/length": 227.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 947016, "time": 42888.6437394619, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 947136, "time": 42894.57241439819, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 947504, "time": 42908.30346989632, "episode/length": 60.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 947608, "time": 42913.083364486694, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 948064, "time": 42930.08354258537, "episode/length": 336.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 948216, "time": 42936.6587498188, "episode/length": 75.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9210526315789473, "episode/intrinsic_return": 0.0}
{"step": 948368, "time": 42943.60869073868, "episode/length": 638.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9827856025039123, "episode/intrinsic_return": 0.0}
{"step": 948616, "time": 42953.21930551529, "episode/length": 340.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 949136, "time": 42972.53073477745, "episode/length": 249.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 949216, "time": 42976.62551116943, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 949384, "time": 42983.498749017715, "episode/length": 145.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 949568, "time": 42991.33571124077, "episode/length": 407.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 949696, "time": 42997.13871574402, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 949792, "time": 43002.02306628227, "episode/length": 357.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9804469273743017, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 43026.43252825737, "eval_episode/length": 43.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 950040, "time": 43028.54962682724, "eval_episode/length": 51.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 950040, "time": 43038.49511909485, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 950040, "time": 43040.75846219063, "eval_episode/length": 215.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 950040, "time": 43042.995965480804, "eval_episode/length": 229.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 950040, "time": 43044.99588036537, "eval_episode/length": 239.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 950040, "time": 43048.91851735115, "eval_episode/length": 250.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 950040, "time": 43051.295568704605, "eval_episode/length": 310.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9967845659163987}
{"step": 950088, "time": 43052.87791347504, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 951176, "time": 43092.51205778122, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 951184, "time": 43095.07012438774, "episode/length": 320.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 951456, "time": 43106.40621948242, "episode/length": 289.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758620689655172, "episode/intrinsic_return": 0.0}
{"step": 951648, "time": 43114.588010549545, "episode/length": 231.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 951664, "time": 43116.696550130844, "episode/length": 261.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 951800, "time": 43122.70956325531, "episode/length": 322.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9938080495356038, "episode/intrinsic_return": 0.0}
{"step": 951928, "time": 43128.50201201439, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 952104, "time": 43135.91431641579, "episode/length": 300.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9667774086378738, "episode/intrinsic_return": 0.0}
{"step": 952848, "time": 43162.81869983673, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 952936, "time": 43167.11221575737, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 953048, "time": 43172.38991808891, "episode/length": 198.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 953216, "time": 43179.7280831337, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 953392, "time": 43187.14579510689, "episode/length": 182.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 953520, "time": 43192.90349149704, "episode/length": 233.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 953632, "time": 43198.14751625061, "episode/length": 228.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 953960, "time": 43210.45876455307, "episode/length": 231.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 954184, "time": 43219.53978061676, "episode/length": 166.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 954224, "time": 43222.71585845947, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 954496, "time": 43233.32382106781, "episode/length": 159.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 955032, "time": 43252.658356666565, "episode/length": 247.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 955344, "time": 43264.85736131668, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 955440, "time": 43269.7669365406, "episode/length": 239.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 955832, "time": 43284.29809999466, "episode/length": 60.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 955936, "time": 43289.53553533554, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 956120, "time": 43296.98787403107, "episode/length": 236.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 956464, "time": 43310.59506058693, "episode/length": 65.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 956552, "time": 43314.828756809235, "episode/length": 295.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 957608, "time": 43351.45556330681, "episode/length": 270.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 957848, "time": 43361.21457195282, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 958040, "time": 43369.1469681263, "episode/length": 442.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 958304, "time": 43379.69600725174, "episode/length": 583.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 958384, "time": 43383.90108370781, "episode/length": 318.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 958504, "time": 43391.10816979408, "episode/length": 297.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 958616, "time": 43396.313068151474, "episode/length": 268.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 958624, "time": 43398.339403152466, "episode/length": 448.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9799554565701559, "episode/intrinsic_return": 0.0}
{"step": 959000, "time": 43411.9717168808, "episode/length": 143.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 959768, "time": 43439.3928360939, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 959816, "time": 43442.55001997948, "episode/length": 275.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 43470.556148052216, "eval_episode/length": 157.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 960024, "time": 43470.56482887268, "eval_episode/length": 157.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 960024, "time": 43474.348125219345, "eval_episode/length": 166.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 960024, "time": 43476.30572724342, "eval_episode/length": 175.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 960024, "time": 43478.60970234871, "eval_episode/length": 190.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 960024, "time": 43483.526745557785, "eval_episode/length": 264.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.969811320754717}
{"step": 960024, "time": 43486.02630639076, "eval_episode/length": 287.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 960024, "time": 43489.73202419281, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 960025, "time": 43490.76075005531, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.318206787109375, "train/action_min": 0.0, "train/action_std": 3.2779187400576095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0356493729074866, "train/actor_opt_grad_steps": 59195.0, "train/actor_opt_loss": -4.631514218281692, "train/adv_mag": 0.44785757215929706, "train/adv_max": 0.4047971422403631, "train/adv_mean": 0.0025907730712429505, "train/adv_min": -0.3740586077033634, "train/adv_std": 0.050630585198671044, "train/cont_avg": 0.9951653279049296, "train/cont_loss_mean": 0.0001234773518082517, "train/cont_loss_std": 0.0036315607556074653, "train/cont_neg_acc": 0.9935362179514388, "train/cont_neg_loss": 0.0142576572895937, "train/cont_pos_acc": 0.9999723031487263, "train/cont_pos_loss": 5.256775649890444e-05, "train/cont_pred": 0.9951766443924165, "train/cont_rate": 0.9951653279049296, "train/dyn_loss_mean": 12.870123399815089, "train/dyn_loss_std": 8.966360025002922, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9026364940153041, "train/extr_critic_critic_opt_grad_steps": 59195.0, "train/extr_critic_critic_opt_loss": 15150.563125825263, "train/extr_critic_mag": 9.549999364664856, "train/extr_critic_max": 9.549999364664856, "train/extr_critic_mean": 2.8855168995722917, "train/extr_critic_min": -0.14319662560879345, "train/extr_critic_std": 2.2191946346994857, "train/extr_return_normed_mag": 1.4972792158664112, "train/extr_return_normed_max": 1.4972792158664112, "train/extr_return_normed_mean": 0.3759351121917577, "train/extr_return_normed_min": -0.09483008236217667, "train/extr_return_normed_std": 0.3203203559551441, "train/extr_return_rate": 0.8814930386946235, "train/extr_return_raw_mag": 10.774926937801737, "train/extr_return_raw_max": 10.774926937801737, "train/extr_return_raw_mean": 2.903691156649254, "train/extr_return_raw_min": -0.4012452596405023, "train/extr_return_raw_std": 2.2487705307947077, "train/extr_reward_mag": 1.0395892623444678, "train/extr_reward_max": 1.0395892623444678, "train/extr_reward_mean": 0.052106110221693216, "train/extr_reward_min": -0.3892807062243072, "train/extr_reward_std": 0.21184511230864994, "train/image_loss_mean": 6.273944780860148, "train/image_loss_std": 11.545837445997856, "train/model_loss_mean": 14.056440830230713, "train/model_loss_std": 15.215330076889254, "train/model_opt_grad_norm": 55.24101329857195, "train/model_opt_grad_steps": 59143.0, "train/model_opt_loss": 16088.987156827685, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1144.3661971830986, "train/policy_entropy_mag": 2.4779033778418955, "train/policy_entropy_max": 2.4779033778418955, "train/policy_entropy_mean": 0.533849899617719, "train/policy_entropy_min": 0.0793750404681958, "train/policy_entropy_std": 0.6225396615098899, "train/policy_logprob_mag": 7.438383784092648, "train/policy_logprob_max": -0.009455661728820751, "train/policy_logprob_mean": -0.5329167412620195, "train/policy_logprob_min": -7.438383784092648, "train/policy_logprob_std": 1.0752051758094572, "train/policy_randomness_mag": 0.8745911541119428, "train/policy_randomness_max": 0.8745911541119428, "train/policy_randomness_mean": 0.18842558741149767, "train/policy_randomness_min": 0.028015905886258876, "train/policy_randomness_std": 0.21972918164142421, "train/post_ent_mag": 59.092227156733124, "train/post_ent_max": 59.092227156733124, "train/post_ent_mean": 42.65360891315299, "train/post_ent_min": 19.719892286918533, "train/post_ent_std": 7.505754890576215, "train/prior_ent_mag": 67.782399889449, "train/prior_ent_max": 67.782399889449, "train/prior_ent_mean": 55.583059257184956, "train/prior_ent_min": 40.3064223813339, "train/prior_ent_std": 4.4767451319896, "train/rep_loss_mean": 12.870123399815089, "train/rep_loss_std": 8.966360025002922, "train/reward_avg": 0.033337230053008864, "train/reward_loss_mean": 0.06029858938615087, "train/reward_loss_std": 0.2608002549116041, "train/reward_max_data": 1.015492961440288, "train/reward_max_pred": 1.0142925171784951, "train/reward_neg_acc": 0.9915129475190606, "train/reward_neg_loss": 0.030134971653649086, "train/reward_pos_acc": 0.9719825731196874, "train/reward_pos_loss": 0.8373515769629412, "train/reward_pred": 0.03261606248987602, "train/reward_rate": 0.03759765625, "train_stats/sum_log_reward": 9.881609302827682, "train_stats/max_log_achievement_collect_coal": 0.4942528735632184, "train_stats/max_log_achievement_collect_drink": 7.0, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 10.482758620689655, "train_stats/max_log_achievement_collect_wood": 10.977011494252874, "train_stats/max_log_achievement_defeat_skeleton": 0.12643678160919541, "train_stats/max_log_achievement_defeat_zombie": 1.3908045977011494, "train_stats/max_log_achievement_eat_cow": 0.3103448275862069, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.022988505747126436, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4022988505747127, "train_stats/max_log_achievement_make_wood_sword": 1.9540229885057472, "train_stats/max_log_achievement_place_furnace": 0.06896551724137931, "train_stats/max_log_achievement_place_plant": 1.9885057471264367, "train_stats/max_log_achievement_place_stone": 8.655172413793103, "train_stats/max_log_achievement_place_table": 2.954022988505747, "train_stats/max_log_achievement_wake_up": 1.6206896551724137, "train_stats/mean_log_entropy": 0.5688385480436785, "eval_stats/sum_log_reward": 9.01666690905889, "eval_stats/max_log_achievement_collect_coal": 0.2916666666666667, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 4.958333333333333, "eval_stats/max_log_achievement_collect_wood": 10.833333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 4.0, "eval_stats/max_log_achievement_place_table": 3.0416666666666665, "eval_stats/max_log_achievement_wake_up": 1.1666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.90206094430323e-07, "report/cont_loss_std": 1.4733740272276918e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1978434486081824e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5556879873201979e-07, "report/cont_pred": 0.9970702528953552, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.618067741394043, "report/dyn_loss_std": 8.329188346862793, "report/image_loss_mean": 5.213587284088135, "report/image_loss_std": 12.439416885375977, "report/model_loss_mean": 12.23237419128418, "report/model_loss_std": 15.912824630737305, "report/post_ent_mag": 59.621028900146484, "report/post_ent_max": 59.621028900146484, "report/post_ent_mean": 43.539459228515625, "report/post_ent_min": 20.523454666137695, "report/post_ent_std": 7.439001560211182, "report/prior_ent_mag": 67.84571838378906, "report/prior_ent_max": 67.84571838378906, "report/prior_ent_mean": 55.61341094970703, "report/prior_ent_min": 37.24125671386719, "report/prior_ent_std": 3.998908758163452, "report/rep_loss_mean": 11.618067741394043, "report/rep_loss_std": 8.329188346862793, "report/reward_avg": 0.02773437462747097, "report/reward_loss_mean": 0.047946084290742874, "report/reward_loss_std": 0.26640182733535767, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000525951385498, "report/reward_neg_acc": 0.9919435977935791, "report/reward_neg_loss": 0.022537777200341225, "report/reward_pos_acc": 0.9354838132858276, "report/reward_pos_loss": 0.8618316054344177, "report/reward_pred": 0.026451846584677696, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0008306614472530782, "eval/cont_loss_std": 0.02617810294032097, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.4190399944782257, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2247760423633736e-05, "eval/cont_pred": 0.9985889196395874, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.1708984375, "eval/dyn_loss_std": 10.050862312316895, "eval/image_loss_mean": 9.011026382446289, "eval/image_loss_std": 12.01576042175293, "eval/model_loss_mean": 19.994224548339844, "eval/model_loss_std": 16.02834701538086, "eval/post_ent_mag": 58.07484436035156, "eval/post_ent_max": 58.07484436035156, "eval/post_ent_mean": 40.075218200683594, "eval/post_ent_min": 21.518390655517578, "eval/post_ent_std": 7.179710388183594, "eval/prior_ent_mag": 67.84571838378906, "eval/prior_ent_max": 67.84571838378906, "eval/prior_ent_mean": 56.10772705078125, "eval/prior_ent_min": 44.81632995605469, "eval/prior_ent_std": 3.8997318744659424, "eval/rep_loss_mean": 18.1708984375, "eval/rep_loss_std": 10.050862312316895, "eval/reward_avg": 0.04218749701976776, "eval/reward_loss_mean": 0.07982948422431946, "eval/reward_loss_std": 0.4393976032733917, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004799365997314, "eval/reward_neg_acc": 0.9877426624298096, "eval/reward_neg_loss": 0.01976734958589077, "eval/reward_pos_acc": 0.8444444537162781, "eval/reward_pos_loss": 1.3865147829055786, "eval/reward_pred": 0.03638637065887451, "eval/reward_rate": 0.0439453125, "replay/size": 959521.0, "replay/inserts": 22784.0, "replay/samples": 22784.0, "replay/insert_wait_avg": 1.4546107542648745e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.417973375052548e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2504220755463602e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1024.227546930313, "timer/env.step_count": 2848.0, "timer/env.step_total": 218.9762647151947, "timer/env.step_frac": 0.2137964999784306, "timer/env.step_avg": 0.07688773339718916, "timer/env.step_min": 0.023740768432617188, "timer/env.step_max": 2.144261598587036, "timer/replay._sample_count": 22784.0, "timer/replay._sample_total": 11.506635665893555, "timer/replay._sample_frac": 0.011234452442115822, "timer/replay._sample_avg": 0.0005050314108977157, "timer/replay._sample_min": 0.0004210472106933594, "timer/replay._sample_max": 0.011068344116210938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3806.0, "timer/agent.policy_total": 64.25002765655518, "timer/agent.policy_frac": 0.06273022811104557, "timer/agent.policy_avg": 0.01688124741370341, "timer/agent.policy_min": 0.009525537490844727, "timer/agent.policy_max": 0.12457585334777832, "timer/dataset_train_count": 1424.0, "timer/dataset_train_total": 0.15504002571105957, "timer/dataset_train_frac": 0.00015137263801947738, "timer/dataset_train_avg": 0.00010887642254990138, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0002739429473876953, "timer/agent.train_count": 1424.0, "timer/agent.train_total": 636.1738770008087, "timer/agent.train_frac": 0.621125529095043, "timer/agent.train_avg": 0.44675131811854546, "timer/agent.train_min": 0.43332958221435547, "timer/agent.train_max": 1.7989213466644287, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4740428924560547, "timer/agent.report_frac": 0.00046282966502589866, "timer/agent.report_avg": 0.23702144622802734, "timer/agent.report_min": 0.23119711875915527, "timer/agent.report_max": 0.24284577369689941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.886458570383016e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.24478042322461}
{"step": 960128, "time": 43494.24468135834, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 960272, "time": 43500.499016046524, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 960272, "time": 43500.51586961746, "episode/length": 220.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 960512, "time": 43511.848108530045, "episode/length": 188.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 960704, "time": 43519.731360435486, "episode/length": 260.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 960832, "time": 43525.5183160305, "episode/length": 275.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 961080, "time": 43535.132549762726, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 961416, "time": 43547.89840602875, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 961824, "time": 43563.2619638443, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 961952, "time": 43569.141741752625, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 962336, "time": 43583.43817949295, "episode/length": 114.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 962496, "time": 43590.353142499924, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 962584, "time": 43594.59238600731, "episode/length": 258.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 962656, "time": 43599.066396951675, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 962856, "time": 43607.13738036156, "episode/length": 322.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 963056, "time": 43615.53236603737, "episode/length": 277.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 963128, "time": 43619.22375488281, "episode/length": 67.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 963504, "time": 43633.61852836609, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 964248, "time": 43659.70127248764, "episode/length": 238.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 964392, "time": 43666.03711152077, "episode/length": 191.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 964432, "time": 43669.16562628746, "episode/length": 241.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 964656, "time": 43678.15465474129, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 964704, "time": 43681.39230179787, "episode/length": 56.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 964704, "time": 43681.403101205826, "episode/length": 343.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.997093023255814, "episode/intrinsic_return": 0.0}
{"step": 965144, "time": 43699.24235510826, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 965200, "time": 43702.89127492905, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 965480, "time": 43713.487857341766, "episode/length": 302.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 965800, "time": 43725.845445632935, "episode/length": 142.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 966536, "time": 43751.952053785324, "episode/length": 173.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 966704, "time": 43761.05204129219, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 966720, "time": 43763.25321960449, "episode/length": 290.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 967008, "time": 43774.695402383804, "episode/length": 150.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 967104, "time": 43779.579812049866, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 967192, "time": 43783.8572845459, "episode/length": 310.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.977491961414791, "episode/intrinsic_return": 0.0}
{"step": 967240, "time": 43786.96170449257, "episode/length": 350.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9857549857549858, "episode/intrinsic_return": 0.0}
{"step": 967288, "time": 43790.23428225517, "episode/length": 322.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 968088, "time": 43818.43897771835, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 968520, "time": 43834.38679766655, "episode/length": 226.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 968520, "time": 43834.39613342285, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 968600, "time": 43840.47826337814, "episode/length": 169.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 969064, "time": 43857.4515042305, "episode/length": 221.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 969136, "time": 43861.63269972801, "episode/length": 242.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 969208, "time": 43865.34240794182, "episode/length": 262.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9657794676806084, "episode/intrinsic_return": 0.0}
{"step": 969680, "time": 43882.781846284866, "episode/length": 333.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9850299401197605, "episode/intrinsic_return": 0.0}
{"step": 969880, "time": 43890.78542113304, "episode/length": 223.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 43912.43208670616, "eval_episode/length": 69.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 970008, "time": 43917.446944475174, "eval_episode/length": 80.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 970008, "time": 43919.88939881325, "eval_episode/length": 169.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 970008, "time": 43922.001873493195, "eval_episode/length": 29.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9}
{"step": 970008, "time": 43923.91630077362, "eval_episode/length": 188.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 970008, "time": 43925.76069664955, "eval_episode/length": 194.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 970008, "time": 43927.42571949959, "eval_episode/length": 195.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 970008, "time": 43930.668600320816, "eval_episode/length": 229.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 970032, "time": 43931.70651221275, "episode/length": 178.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 970088, "time": 43934.96288561821, "episode/length": 195.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 970384, "time": 43946.556624650955, "episode/length": 62.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 970456, "time": 43950.31444430351, "episode/length": 241.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 970520, "time": 43954.01390480995, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 971112, "time": 43975.35683965683, "episode/length": 237.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 971232, "time": 43981.0948677063, "episode/length": 261.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 971440, "time": 43989.6561794281, "episode/length": 219.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 972160, "time": 44015.07424354553, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 972224, "time": 44018.8440322876, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 972344, "time": 44024.1209499836, "episode/length": 235.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 972592, "time": 44034.06563448906, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 973016, "time": 44049.68197178841, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 973176, "time": 44056.56741809845, "episode/length": 242.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 973648, "time": 44073.97731542587, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 973816, "time": 44080.97760248184, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 973912, "time": 44085.82152223587, "episode/length": 477.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 974136, "time": 44094.70468044281, "episode/length": 60.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 974384, "time": 44104.705614328384, "episode/length": 254.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 974648, "time": 44114.982097387314, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 975408, "time": 44143.89917588234, "episode/length": 536.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9981378026070763, "episode/intrinsic_return": 0.0}
{"step": 975824, "time": 44159.415934324265, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 975904, "time": 44163.631759643555, "episode/length": 248.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 976248, "time": 44176.39311623573, "episode/length": 52.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 976272, "time": 44179.036164045334, "episode/length": 306.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 976504, "time": 44188.194439172745, "episode/length": 264.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 976608, "time": 44193.564723968506, "episode/length": 448.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9821826280623608, "episode/intrinsic_return": 0.0}
{"step": 976608, "time": 44193.57448005676, "episode/length": 308.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 976720, "time": 44200.95740032196, "episode/length": 515.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9786821705426356, "episode/intrinsic_return": 0.0}
{"step": 977112, "time": 44215.26304149628, "episode/length": 212.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 977424, "time": 44227.281599998474, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 977720, "time": 44238.8076980114, "episode/length": 180.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 978200, "time": 44256.27739691734, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 978264, "time": 44260.02229261398, "episode/length": 251.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 978480, "time": 44268.949521541595, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 978488, "time": 44270.539256095886, "episode/length": 247.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 978584, "time": 44275.23136520386, "episode/length": 232.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 978816, "time": 44284.707147836685, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 979232, "time": 44300.15733504295, "episode/length": 188.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 980072, "time": 44329.95603513718, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 44353.41456532478, "eval_episode/length": 177.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 980096, "time": 44354.98508524895, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 980096, "time": 44358.37662124634, "eval_episode/length": 220.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 980096, "time": 44361.145894527435, "eval_episode/length": 247.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 980096, "time": 44363.731825590134, "eval_episode/length": 268.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9851301115241635}
{"step": 980096, "time": 44369.048114061356, "eval_episode/length": 163.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 980096, "time": 44372.88272500038, "eval_episode/length": 361.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.988950276243094}
{"step": 980096, "time": 44376.48755669594, "eval_episode/length": 190.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 980408, "time": 44386.77610516548, "episode/length": 227.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 980504, "time": 44391.916662693024, "episode/length": 252.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 980616, "time": 44397.18677139282, "episode/length": 301.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 980744, "time": 44402.90641593933, "episode/length": 414.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951807228915662, "episode/intrinsic_return": 0.0}
{"step": 980896, "time": 44409.885981321335, "episode/length": 60.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 981000, "time": 44414.646931409836, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 981176, "time": 44422.00008249283, "episode/length": 335.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 981272, "time": 44426.8392457962, "episode/length": 306.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 981376, "time": 44431.99782657623, "episode/length": 46.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 982168, "time": 44459.565577983856, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 982240, "time": 44463.82913327217, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 982312, "time": 44467.533276081085, "episode/length": 225.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 982488, "time": 44475.041509866714, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 982856, "time": 44489.137315034866, "episode/length": 244.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 982857, "time": 44491.77217721939, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.38946533203125, "train/action_min": 0.0, "train/action_std": 3.348567447462282, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03541108793937243, "train/actor_opt_grad_steps": 60620.0, "train/actor_opt_loss": -7.8423673098685445, "train/adv_mag": 0.45730738268865573, "train/adv_max": 0.42576675148277016, "train/adv_mean": 0.0025285343935411856, "train/adv_min": -0.36688833084556605, "train/adv_std": 0.050662947128285896, "train/cont_avg": 0.9951649912587412, "train/cont_loss_mean": 0.00026621810804505606, "train/cont_loss_std": 0.008243636835946798, "train/cont_neg_acc": 0.993523144221806, "train/cont_neg_loss": 0.031893596108796635, "train/cont_pos_acc": 0.999999977908768, "train/cont_pos_loss": 2.284142464077004e-05, "train/cont_pred": 0.9951969560209688, "train/cont_rate": 0.9951649912587412, "train/dyn_loss_mean": 12.759759269394241, "train/dyn_loss_std": 8.898392470566543, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8841467516405599, "train/extr_critic_critic_opt_grad_steps": 60620.0, "train/extr_critic_critic_opt_loss": 15132.34162614729, "train/extr_critic_mag": 9.63267857211453, "train/extr_critic_max": 9.63267857211453, "train/extr_critic_mean": 2.8637236681851475, "train/extr_critic_min": -0.14384723626650298, "train/extr_critic_std": 2.2581258378662428, "train/extr_return_normed_mag": 1.5176116536547255, "train/extr_return_normed_max": 1.5176116536547255, "train/extr_return_normed_mean": 0.3753578096002966, "train/extr_return_normed_min": -0.09887064654718745, "train/extr_return_normed_std": 0.3260991576459858, "train/extr_return_rate": 0.8687596046007596, "train/extr_return_raw_mag": 10.900936947002277, "train/extr_return_raw_max": 10.900936947002277, "train/extr_return_raw_mean": 2.8815052309236324, "train/extr_return_raw_min": -0.4480138481496931, "train/extr_return_raw_std": 2.28931063121849, "train/extr_reward_mag": 1.042504105534587, "train/extr_reward_max": 1.042504105534587, "train/extr_reward_mean": 0.05206908349442732, "train/extr_reward_min": -0.4167362051410275, "train/extr_reward_std": 0.21263004881101888, "train/image_loss_mean": 6.224249259575264, "train/image_loss_std": 11.144883592645606, "train/model_loss_mean": 13.938473788174717, "train/model_loss_std": 14.730908000385845, "train/model_opt_grad_norm": 50.42905691453627, "train/model_opt_grad_steps": 60566.96503496503, "train/model_opt_loss": 21249.05622404939, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1529.7202797202797, "train/policy_entropy_mag": 2.4368865640013366, "train/policy_entropy_max": 2.4368865640013366, "train/policy_entropy_mean": 0.5438755304663332, "train/policy_entropy_min": 0.07937503001698247, "train/policy_entropy_std": 0.6257518336072668, "train/policy_logprob_mag": 7.4383838393471455, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.5451108515262604, "train/policy_logprob_min": -7.4383838393471455, "train/policy_logprob_std": 1.0843777118862925, "train/policy_randomness_mag": 0.8601140167329695, "train/policy_randomness_max": 0.8601140167329695, "train/policy_randomness_mean": 0.19196419584584404, "train/policy_randomness_min": 0.028015902265906334, "train/policy_randomness_std": 0.2208629368276863, "train/post_ent_mag": 59.219300036663775, "train/post_ent_max": 59.219300036663775, "train/post_ent_mean": 42.78022333958766, "train/post_ent_min": 19.980091388408955, "train/post_ent_std": 7.588651253626897, "train/prior_ent_mag": 67.796142578125, "train/prior_ent_max": 67.796142578125, "train/prior_ent_mean": 55.61088996833855, "train/prior_ent_min": 40.60295667848387, "train/prior_ent_std": 4.51551301329286, "train/rep_loss_mean": 12.759759269394241, "train/rep_loss_std": 8.898392470566543, "train/reward_avg": 0.03300439785853341, "train/reward_loss_mean": 0.05810283207810008, "train/reward_loss_std": 0.24810432053946116, "train/reward_max_data": 1.0223776277128633, "train/reward_max_pred": 1.0168061239736064, "train/reward_neg_acc": 0.9918462333979307, "train/reward_neg_loss": 0.028504826174072035, "train/reward_pos_acc": 0.970770609545541, "train/reward_pos_loss": 0.8287625158583367, "train/reward_pred": 0.032139726816774246, "train/reward_rate": 0.037218640734265736, "train_stats/sum_log_reward": 9.524242639541626, "train_stats/max_log_achievement_collect_coal": 0.46464646464646464, "train_stats/max_log_achievement_collect_drink": 5.363636363636363, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8383838383838385, "train_stats/max_log_achievement_collect_stone": 8.16161616161616, "train_stats/max_log_achievement_collect_wood": 10.797979797979798, "train_stats/max_log_achievement_defeat_skeleton": 0.050505050505050504, "train_stats/max_log_achievement_defeat_zombie": 1.4646464646464648, "train_stats/max_log_achievement_eat_cow": 0.23232323232323232, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010101010101010102, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2424242424242424, "train_stats/max_log_achievement_make_wood_sword": 1.8585858585858586, "train_stats/max_log_achievement_place_furnace": 0.030303030303030304, "train_stats/max_log_achievement_place_plant": 1.797979797979798, "train_stats/max_log_achievement_place_stone": 7.090909090909091, "train_stats/max_log_achievement_place_table": 2.8484848484848486, "train_stats/max_log_achievement_wake_up": 1.4545454545454546, "train_stats/mean_log_entropy": 0.5495336562997163, "eval_stats/sum_log_reward": 9.225000202655792, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 5.8125, "eval_stats/max_log_achievement_collect_wood": 9.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.5, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 1.4375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 5.5625, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.4733109310327563e-06, "report/cont_loss_std": 2.5776691472856328e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002187817299272865, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9251476146564528e-07, "report/cont_pred": 0.9941418170928955, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.45311164855957, "report/dyn_loss_std": 9.023124694824219, "report/image_loss_mean": 5.606658935546875, "report/image_loss_std": 7.80984354019165, "report/model_loss_mean": 13.143985748291016, "report/model_loss_std": 11.510210990905762, "report/post_ent_mag": 59.11604309082031, "report/post_ent_max": 59.11604309082031, "report/post_ent_mean": 42.53035354614258, "report/post_ent_min": 21.48027229309082, "report/post_ent_std": 7.700525283813477, "report/prior_ent_mag": 67.98078918457031, "report/prior_ent_max": 67.98078918457031, "report/prior_ent_mean": 55.08625793457031, "report/prior_ent_min": 41.24507141113281, "report/prior_ent_std": 4.4614949226379395, "report/rep_loss_mean": 12.45311164855957, "report/rep_loss_std": 9.023124694824219, "report/reward_avg": 0.03916015475988388, "report/reward_loss_mean": 0.06545894593000412, "report/reward_loss_std": 0.22457288205623627, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0979280471801758, "report/reward_neg_acc": 0.9877426624298096, "report/reward_neg_loss": 0.035430870950222015, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7187365293502808, "report/reward_pred": 0.042359646409749985, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.422425677650608e-05, "eval/cont_loss_std": 0.000622029765509069, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004815229214727879, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.43599753655144e-06, "eval/cont_pred": 0.9961071014404297, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.80466651916504, "eval/dyn_loss_std": 10.128067970275879, "eval/image_loss_mean": 8.511090278625488, "eval/image_loss_std": 9.519103050231934, "eval/model_loss_mean": 18.70854949951172, "eval/model_loss_std": 13.637401580810547, "eval/post_ent_mag": 58.88153839111328, "eval/post_ent_max": 58.88153839111328, "eval/post_ent_mean": 41.32176208496094, "eval/post_ent_min": 19.1695556640625, "eval/post_ent_std": 7.929896354675293, "eval/prior_ent_mag": 67.98078918457031, "eval/prior_ent_max": 67.98078918457031, "eval/prior_ent_mean": 56.23381042480469, "eval/prior_ent_min": 42.879608154296875, "eval/prior_ent_std": 4.551080226898193, "eval/rep_loss_mean": 16.80466651916504, "eval/rep_loss_std": 10.128067970275879, "eval/reward_avg": 0.04335937649011612, "eval/reward_loss_mean": 0.11463423073291779, "eval/reward_loss_std": 0.5793145298957825, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.1098151206970215, "eval/reward_neg_acc": 0.9897645711898804, "eval/reward_neg_loss": 0.053011827170848846, "eval/reward_pos_acc": 0.8510637879371643, "eval/reward_pos_loss": 1.395593523979187, "eval/reward_pred": 0.0398557111620903, "eval/reward_rate": 0.0458984375, "replay/size": 982353.0, "replay/inserts": 22832.0, "replay/samples": 22832.0, "replay/insert_wait_avg": 1.4319629542211094e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.297614508604118e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3190545025644273e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.0012137889862, "timer/env.step_count": 2854.0, "timer/env.step_total": 235.534747838974, "timer/env.step_frac": 0.23529916307236903, "timer/env.step_avg": 0.0825279424803693, "timer/env.step_min": 0.023641109466552734, "timer/env.step_max": 3.421410083770752, "timer/replay._sample_count": 22832.0, "timer/replay._sample_total": 11.435643672943115, "timer/replay._sample_frac": 0.011424205600767413, "timer/replay._sample_avg": 0.0005008603570840537, "timer/replay._sample_min": 0.00039958953857421875, "timer/replay._sample_max": 0.013991117477416992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3496.0, "timer/agent.policy_total": 57.59931445121765, "timer/agent.policy_frac": 0.05754170290482759, "timer/agent.policy_avg": 0.01647577644485631, "timer/agent.policy_min": 0.009552717208862305, "timer/agent.policy_max": 0.12503767013549805, "timer/dataset_train_count": 1427.0, "timer/dataset_train_total": 0.15807294845581055, "timer/dataset_train_frac": 0.00015791484193857606, "timer/dataset_train_avg": 0.00011077291412460445, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.004073619842529297, "timer/agent.train_count": 1427.0, "timer/agent.train_total": 635.1530025005341, "timer/agent.train_frac": 0.6345177146153052, "timer/agent.train_avg": 0.44509670812931607, "timer/agent.train_min": 0.43268871307373047, "timer/agent.train_max": 1.6894142627716064, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756455421447754, "timer/agent.report_frac": 0.00047516979559331763, "timer/agent.report_avg": 0.2378227710723877, "timer/agent.report_min": 0.23021459579467773, "timer/agent.report_max": 0.24543094635009766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8581613186953254e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.808865601410844}
{"step": 983152, "time": 44503.36793732643, "episode/length": 234.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 983192, "time": 44506.06297469139, "episode/length": 251.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 983352, "time": 44512.9559006691, "episode/length": 61.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 983560, "time": 44521.37175941467, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 983640, "time": 44525.56291127205, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 984032, "time": 44540.387974739075, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 984720, "time": 44564.691006183624, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 984992, "time": 44575.69609284401, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 985184, "time": 44583.657175540924, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 985424, "time": 44593.29977273941, "episode/length": 232.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 985512, "time": 44597.61772966385, "episode/length": 233.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 985608, "time": 44602.40942406654, "episode/length": 528.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9829867674858223, "episode/intrinsic_return": 0.0}
{"step": 986144, "time": 44622.24137091637, "episode/length": 487.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 986216, "time": 44626.400871515274, "episode/length": 75.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 986272, "time": 44630.00753259659, "episode/length": 279.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 986584, "time": 44642.32157921791, "episode/length": 54.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 986880, "time": 44654.13109111786, "episode/length": 269.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 987152, "time": 44665.04428601265, "episode/length": 204.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 987352, "time": 44672.94456124306, "episode/length": 270.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 987536, "time": 44680.983629226685, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 987728, "time": 44688.91946554184, "episode/length": 287.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 988056, "time": 44701.13877034187, "episode/length": 222.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 988088, "time": 44703.861879110336, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 988488, "time": 44718.62906289101, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9931350114416476, "episode/intrinsic_return": 0.0}
{"step": 988632, "time": 44725.01289796829, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 988872, "time": 44734.57904267311, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 989248, "time": 44748.8787112236, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 989288, "time": 44751.656819581985, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 989400, "time": 44756.9414100647, "episode/length": 314.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 989576, "time": 44764.28868722916, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 989936, "time": 44778.122193574905, "episode/length": 275.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 990064, "time": 44784.077968120575, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 44805.569278240204, "eval_episode/length": 140.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 990080, "time": 44807.87380337715, "eval_episode/length": 153.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.961038961038961}
{"step": 990080, "time": 44810.065057992935, "eval_episode/length": 166.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9520958083832335}
{"step": 990080, "time": 44812.74074077606, "eval_episode/length": 192.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 990080, "time": 44814.70493936539, "eval_episode/length": 201.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9851485148514851}
{"step": 990080, "time": 44814.711639881134, "eval_episode/length": 47.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9375}
{"step": 990080, "time": 44819.4877808094, "eval_episode/length": 235.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 990080, "time": 44822.051782131195, "eval_episode/length": 258.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 990288, "time": 44829.07834625244, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 990464, "time": 44836.53897213936, "episode/length": 198.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 990560, "time": 44841.32036566734, "episode/length": 163.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 990576, "time": 44843.48464155197, "episode/length": 160.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 991024, "time": 44862.287632226944, "episode/length": 91.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 991320, "time": 44875.009816646576, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 991592, "time": 44885.6556391716, "episode/length": 251.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 991800, "time": 44894.163709163666, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 991888, "time": 44898.780290842056, "episode/length": 310.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.977491961414791, "episode/intrinsic_return": 0.0}
{"step": 992056, "time": 44905.640505075455, "episode/length": 264.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 992080, "time": 44908.2804312706, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 992448, "time": 44922.04811859131, "episode/length": 48.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 992504, "time": 44925.16523838043, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 992968, "time": 44942.11280751228, "episode/length": 362.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9944903581267218, "episode/intrinsic_return": 0.0}
{"step": 993152, "time": 44950.14295601845, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 993160, "time": 44951.91234302521, "episode/length": 134.0, "episode/score": 9.099999949336052, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 993192, "time": 44954.37975811958, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 993296, "time": 44959.50241136551, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 994152, "time": 44989.25881266594, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 994384, "time": 44998.624007701874, "episode/length": 234.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 994480, "time": 45003.409752607346, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 994720, "time": 45013.089779376984, "episode/length": 190.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 994776, "time": 45016.30765914917, "episode/length": 201.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 994808, "time": 45018.961631298065, "episode/length": 364.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 995120, "time": 45031.088609457016, "episode/length": 245.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 995720, "time": 45052.574916124344, "episode/length": 302.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 996160, "time": 45069.115938425064, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 996240, "time": 45073.31326317787, "episode/length": 260.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 996432, "time": 45081.119970321655, "episode/length": 206.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 996512, "time": 45085.167127132416, "episode/length": 33.0, "episode/score": 3.100000038743019, "episode/reward_rate": 0.9117647058823529, "episode/intrinsic_return": 0.0}
{"step": 996544, "time": 45087.789196014404, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 996840, "time": 45098.95459294319, "episode/length": 264.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 997024, "time": 45106.826914548874, "episode/length": 317.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.0}
{"step": 997920, "time": 45138.30939602852, "episode/length": 185.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 998008, "time": 45142.48573207855, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 998072, "time": 45146.151980400085, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 998096, "time": 45148.83130502701, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 998392, "time": 45160.24484539032, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9850299401197605, "episode/intrinsic_return": 0.0}
{"step": 998400, "time": 45162.24473118782, "episode/length": 171.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 998680, "time": 45172.96167445183, "episode/length": 229.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 998768, "time": 45177.70800161362, "episode/length": 325.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 999424, "time": 45201.174401044846, "episode/length": 127.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9453125, "episode/intrinsic_return": 0.0}
{"step": 999520, "time": 45207.74471259117, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 999632, "time": 45213.12878322601, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1000040, "time": 45227.950164079666, "episode/length": 169.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45251.93357133865, "eval_episode/length": 188.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 1000064, "time": 45253.753328323364, "eval_episode/length": 192.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 1000064, "time": 45257.02069950104, "eval_episode/length": 231.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 1000064, "time": 45258.74459242821, "eval_episode/length": 234.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 1000064, "time": 45260.59265565872, "eval_episode/length": 239.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 1000064, "time": 45269.15924811363, "eval_episode/length": 402.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9875930521091811}
{"step": 1000064, "time": 45271.52000069618, "eval_episode/length": 225.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.995575221238938}
{"step": 1000064, "time": 45273.4413189888, "eval_episode/length": 194.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 1000168, "time": 45276.67674136162, "episode/length": 280.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1000360, "time": 45284.640433073044, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 1001224, "time": 45314.725730895996, "episode/length": 131.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 1001336, "time": 45319.91765809059, "episode/length": 367.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1001368, "time": 45322.47987866402, "episode/length": 230.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1001960, "time": 45343.59790492058, "episode/length": 485.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9979423868312757, "episode/intrinsic_return": 0.0}
{"step": 1002128, "time": 45350.89839577675, "episode/length": 311.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9775641025641025, "episode/intrinsic_return": 0.0}
{"step": 1002792, "time": 45374.256841897964, "episode/length": 420.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.997624703087886, "episode/intrinsic_return": 0.0}
{"step": 1002968, "time": 45381.72603940964, "episode/length": 125.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 1003072, "time": 45386.8569624424, "episode/length": 212.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1003112, "time": 45389.59454417229, "episode/length": 343.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9912790697674418, "episode/intrinsic_return": 0.0}
{"step": 1003112, "time": 45389.60440468788, "episode/length": 235.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1003448, "time": 45403.95834136009, "episode/length": 425.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 1003824, "time": 45418.26222205162, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 1003856, "time": 45420.71107888222, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 1004280, "time": 45436.26101613045, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 1004328, "time": 45439.299314022064, "episode/length": 169.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 1004592, "time": 45449.83591008186, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1005088, "time": 45467.902383089066, "episode/length": 286.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 1005104, "time": 45470.01992106438, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1005328, "time": 45479.00207567215, "episode/length": 234.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1005649, "time": 45491.827075242996, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.326144796022227, "train/action_min": 0.0, "train/action_std": 3.2541169767648404, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03539009283388585, "train/actor_opt_grad_steps": 62045.0, "train/actor_opt_loss": -9.149064770886596, "train/adv_mag": 0.4599340041758309, "train/adv_max": 0.4303510908929395, "train/adv_mean": 0.0018977600840616375, "train/adv_min": -0.3707695483741626, "train/adv_std": 0.04979940084084659, "train/cont_avg": 0.9954060299295775, "train/cont_loss_mean": 0.00012221678428273394, "train/cont_loss_std": 0.0035802054995975807, "train/cont_neg_acc": 0.9974178407393711, "train/cont_neg_loss": 0.0075475905857088745, "train/cont_pos_acc": 0.9999792684971447, "train/cont_pos_loss": 8.666309713799886e-05, "train/cont_pred": 0.9953913466191627, "train/cont_rate": 0.9954060299295775, "train/dyn_loss_mean": 12.734640363236549, "train/dyn_loss_std": 8.937166039372833, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8897324393332844, "train/extr_critic_critic_opt_grad_steps": 62045.0, "train/extr_critic_critic_opt_loss": 15111.289234430018, "train/extr_critic_mag": 9.654683066086031, "train/extr_critic_max": 9.654683066086031, "train/extr_critic_mean": 2.8888490468683377, "train/extr_critic_min": -0.1495506528397681, "train/extr_critic_std": 2.233006090345517, "train/extr_return_normed_mag": 1.5079483977505859, "train/extr_return_normed_max": 1.5079483977505859, "train/extr_return_normed_mean": 0.37673251928997714, "train/extr_return_normed_min": -0.08877416464014792, "train/extr_return_normed_std": 0.3162240291565237, "train/extr_return_rate": 0.8664603976296706, "train/extr_return_raw_mag": 10.99110285664948, "train/extr_return_raw_max": 10.99110285664948, "train/extr_return_raw_mean": 2.9024110486809636, "train/extr_return_raw_min": -0.4269731409952674, "train/extr_return_raw_std": 2.2614994200182634, "train/extr_reward_mag": 1.0529643549046046, "train/extr_reward_max": 1.0529643549046046, "train/extr_reward_mean": 0.05032315535444609, "train/extr_reward_min": -0.377120294201542, "train/extr_reward_std": 0.20890627664999223, "train/image_loss_mean": 6.242636171864792, "train/image_loss_std": 11.684924780482977, "train/model_loss_mean": 13.940435476706062, "train/model_loss_std": 15.290518075647489, "train/model_opt_grad_norm": 50.56528325148032, "train/model_opt_grad_steps": 61990.7323943662, "train/model_opt_loss": 19193.056613116198, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1382.0422535211267, "train/policy_entropy_mag": 2.4213224901279933, "train/policy_entropy_max": 2.4213224901279933, "train/policy_entropy_mean": 0.5212286135680239, "train/policy_entropy_min": 0.07937502572444123, "train/policy_entropy_std": 0.6002081867674707, "train/policy_logprob_mag": 7.438383851252811, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5220005892112222, "train/policy_logprob_min": -7.438383851252811, "train/policy_logprob_std": 1.072791380781523, "train/policy_randomness_mag": 0.8546205805221074, "train/policy_randomness_max": 0.8546205805221074, "train/policy_randomness_mean": 0.18397082682226745, "train/policy_randomness_min": 0.02801590067872279, "train/policy_randomness_std": 0.2118471509344141, "train/post_ent_mag": 59.238488613719674, "train/post_ent_max": 59.238488613719674, "train/post_ent_mean": 42.77264404296875, "train/post_ent_min": 19.659257559709147, "train/post_ent_std": 7.600460623351621, "train/prior_ent_mag": 67.76885690823407, "train/prior_ent_max": 67.76885690823407, "train/prior_ent_mean": 55.55563238976707, "train/prior_ent_min": 40.702866003546916, "train/prior_ent_std": 4.387059354446303, "train/rep_loss_mean": 12.734640363236549, "train/rep_loss_std": 8.937166039372833, "train/reward_avg": 0.031598674054716676, "train/reward_loss_mean": 0.05689299576194354, "train/reward_loss_std": 0.24767888620705672, "train/reward_max_data": 1.025352118720471, "train/reward_max_pred": 1.0198063707687486, "train/reward_neg_acc": 0.9923757365052129, "train/reward_neg_loss": 0.028398186420943116, "train/reward_pos_acc": 0.971793790518398, "train/reward_pos_loss": 0.8235847114677161, "train/reward_pred": 0.030785263745560194, "train/reward_rate": 0.03591274207746479, "train_stats/sum_log_reward": 9.75306143809338, "train_stats/max_log_achievement_collect_coal": 0.4897959183673469, "train_stats/max_log_achievement_collect_drink": 6.36734693877551, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.989795918367347, "train_stats/max_log_achievement_collect_stone": 7.1938775510204085, "train_stats/max_log_achievement_collect_wood": 11.122448979591837, "train_stats/max_log_achievement_defeat_skeleton": 0.07142857142857142, "train_stats/max_log_achievement_defeat_zombie": 1.4183673469387754, "train_stats/max_log_achievement_eat_cow": 0.21428571428571427, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02040816326530612, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4489795918367347, "train_stats/max_log_achievement_make_wood_sword": 1.4591836734693877, "train_stats/max_log_achievement_place_furnace": 0.1326530612244898, "train_stats/max_log_achievement_place_plant": 1.9489795918367347, "train_stats/max_log_achievement_place_stone": 5.775510204081633, "train_stats/max_log_achievement_place_table": 2.5510204081632653, "train_stats/max_log_achievement_wake_up": 1.3265306122448979, "train_stats/mean_log_entropy": 0.5447850850771885, "eval_stats/sum_log_reward": 9.72500017285347, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 6.6875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 5.5, "eval_stats/max_log_achievement_collect_wood": 10.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.75, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 4.375, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.4898539575369796e-06, "report/cont_loss_std": 2.4970604499685578e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00022074217849876732, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.1403293948860664e-07, "report/cont_pred": 0.9951179027557373, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.710281372070312, "report/dyn_loss_std": 8.889750480651855, "report/image_loss_mean": 5.718524932861328, "report/image_loss_std": 14.098426818847656, "report/model_loss_mean": 13.400903701782227, "report/model_loss_std": 17.501895904541016, "report/post_ent_mag": 58.63920593261719, "report/post_ent_max": 58.63920593261719, "report/post_ent_mean": 42.795570373535156, "report/post_ent_min": 20.787677764892578, "report/post_ent_std": 7.7361674308776855, "report/prior_ent_mag": 67.76068115234375, "report/prior_ent_max": 67.76068115234375, "report/prior_ent_mean": 55.60838317871094, "report/prior_ent_min": 41.14251708984375, "report/prior_ent_std": 4.526638507843018, "report/rep_loss_mean": 12.710281372070312, "report/rep_loss_std": 8.889750480651855, "report/reward_avg": 0.03125, "report/reward_loss_mean": 0.05620918050408363, "report/reward_loss_std": 0.21527983248233795, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0988407135009766, "report/reward_neg_acc": 0.9989867806434631, "report/reward_neg_loss": 0.02854696288704872, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.7941174507141113, "report/reward_pred": 0.02952072210609913, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0032867894042283297, "eval/cont_loss_std": 0.10511244833469391, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.6730913519859314, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.127097644688547e-07, "eval/cont_pred": 0.9960600137710571, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.840313911437988, "eval/dyn_loss_std": 10.57358169555664, "eval/image_loss_mean": 9.237334251403809, "eval/image_loss_std": 13.443690299987793, "eval/model_loss_mean": 18.819419860839844, "eval/model_loss_std": 17.67517852783203, "eval/post_ent_mag": 61.10451126098633, "eval/post_ent_max": 61.10451126098633, "eval/post_ent_mean": 42.34665298461914, "eval/post_ent_min": 20.73996925354004, "eval/post_ent_std": 7.929821014404297, "eval/prior_ent_mag": 67.76068115234375, "eval/prior_ent_max": 67.76068115234375, "eval/prior_ent_mean": 56.49199676513672, "eval/prior_ent_min": 45.47645568847656, "eval/prior_ent_std": 4.461790084838867, "eval/rep_loss_mean": 15.840313911437988, "eval/rep_loss_std": 10.57358169555664, "eval/reward_avg": 0.03310547024011612, "eval/reward_loss_mean": 0.0746113508939743, "eval/reward_loss_std": 0.3804026246070862, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001258373260498, "eval/reward_neg_acc": 0.9848023653030396, "eval/reward_neg_loss": 0.03439740464091301, "eval/reward_pos_acc": 0.8918918371200562, "eval/reward_pos_loss": 1.1473454236984253, "eval/reward_pred": 0.0342155396938324, "eval/reward_rate": 0.0361328125, "replay/size": 1000000.0, "replay/inserts": 22792.0, "replay/samples": 22784.0, "replay/insert_wait_avg": 1.433681044171843e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.386161907335345e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5488.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2140319229214949e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0226964950562, "timer/env.step_count": 2849.0, "timer/env.step_total": 235.01530075073242, "timer/env.step_frac": 0.2350099668481817, "timer/env.step_avg": 0.08249045305396013, "timer/env.step_min": 0.02327442169189453, "timer/env.step_max": 3.416518449783325, "timer/replay._sample_count": 22784.0, "timer/replay._sample_total": 11.402204751968384, "timer/replay._sample_frac": 0.011401945967758096, "timer/replay._sample_avg": 0.0005004478911502978, "timer/replay._sample_min": 0.00038909912109375, "timer/replay._sample_max": 0.006871938705444336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3535.0, "timer/agent.policy_total": 57.79732155799866, "timer/agent.policy_frac": 0.05779600979114817, "timer/agent.policy_avg": 0.01635002024271532, "timer/agent.policy_min": 0.009367942810058594, "timer/agent.policy_max": 0.11064982414245605, "timer/dataset_train_count": 1424.0, "timer/dataset_train_total": 0.15325164794921875, "timer/dataset_train_frac": 0.0001532481697528916, "timer/dataset_train_avg": 0.0001076205392901817, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0004181861877441406, "timer/agent.train_count": 1424.0, "timer/agent.train_total": 634.1796567440033, "timer/agent.train_frac": 0.6341652634152374, "timer/agent.train_avg": 0.44535088254494615, "timer/agent.train_min": 0.43084168434143066, "timer/agent.train_max": 2.7994611263275146, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47188663482666016, "timer/agent.report_frac": 0.00047187592489706363, "timer/agent.report_avg": 0.23594331741333008, "timer/agent.report_min": 0.2291877269744873, "timer/agent.report_max": 0.24269890785217285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8132753819076405e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.791166101571413}
{"step": 1005888, "time": 45500.02662372589, "episode/length": 253.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1006280, "time": 45514.360055208206, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 1006384, "time": 45519.72898888588, "episode/length": 223.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1006496, "time": 45525.0594599247, "episode/length": 276.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1006720, "time": 45534.15780997276, "episode/length": 361.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9861878453038674, "episode/intrinsic_return": 0.0}
{"step": 1006752, "time": 45536.82138156891, "episode/length": 177.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 1006808, "time": 45540.00069689751, "episode/length": 214.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 1007072, "time": 45550.47846865654, "episode/length": 245.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1007800, "time": 45577.4656419754, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9665271966527197, "episode/intrinsic_return": 0.0}
{"step": 1007808, "time": 45579.608916282654, "episode/length": 190.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1007872, "time": 45583.27828359604, "episode/length": 139.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1008088, "time": 45591.84115886688, "episode/length": 212.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1008432, "time": 45604.95445370674, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 1008816, "time": 45619.325942993164, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1008936, "time": 45624.600377082825, "episode/length": 304.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 1009072, "time": 45630.80561900139, "episode/length": 282.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 1009272, "time": 45638.87853360176, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1009344, "time": 45643.05919075012, "episode/length": 50.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1009904, "time": 45663.31242752075, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1009976, "time": 45667.07964468002, "episode/length": 270.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 45690.070476293564, "eval_episode/length": 133.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9626865671641791}
{"step": 1010048, "time": 45691.789897441864, "eval_episode/length": 136.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 1010048, "time": 45693.56691861153, "eval_episode/length": 142.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 1010048, "time": 45695.3968565464, "eval_episode/length": 150.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 1010048, "time": 45699.97383475304, "eval_episode/length": 216.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 1010048, "time": 45704.75383782387, "eval_episode/length": 136.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9562043795620438}
{"step": 1010048, "time": 45712.07323718071, "eval_episode/length": 380.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.994750656167979}
{"step": 1010048, "time": 45714.57342672348, "eval_episode/length": 252.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9644268774703557}
{"step": 1010136, "time": 45717.25088405609, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1010240, "time": 45722.55696773529, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 1010472, "time": 45732.06664395332, "episode/length": 324.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9938461538461538, "episode/intrinsic_return": 0.0}
{"step": 1011208, "time": 45758.03819537163, "episode/length": 232.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1011472, "time": 45768.6784620285, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1011632, "time": 45775.63608574867, "episode/length": 215.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1011768, "time": 45781.39481854439, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1012184, "time": 45796.71166014671, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 1012464, "time": 45807.77721118927, "episode/length": 277.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 1012720, "time": 45817.775663137436, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 1012848, "time": 45823.84450173378, "episode/length": 358.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972144846796658, "episode/intrinsic_return": 0.0}
{"step": 1012856, "time": 45825.47768831253, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1013232, "time": 45839.68590092659, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 1013456, "time": 45848.7271027565, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1013536, "time": 45852.879264593124, "episode/length": 85.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 1013656, "time": 45858.30079436302, "episode/length": 183.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1014424, "time": 45885.8237862587, "episode/length": 244.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 1014688, "time": 45896.31932377815, "episode/length": 245.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1014776, "time": 45900.61579537392, "episode/length": 239.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1014816, "time": 45903.70407581329, "episode/length": 417.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976076555023924, "episode/intrinsic_return": 0.0}
{"step": 1015248, "time": 45919.67577242851, "episode/length": 251.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1015392, "time": 45925.85288333893, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1015416, "time": 45927.952519893646, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 1016008, "time": 45951.13579964638, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1016288, "time": 45962.14038658142, "episode/length": 199.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1016720, "time": 45978.270401239395, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1017728, "time": 46013.26058220863, "episode/length": 288.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1017832, "time": 46018.093383312225, "episode/length": 304.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 1017888, "time": 46021.65540885925, "episode/length": 543.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9981617647058824, "episode/intrinsic_return": 0.0}
{"step": 1017960, "time": 46025.25628018379, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 1017960, "time": 46025.2655506134, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 1018160, "time": 46035.551002025604, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1018464, "time": 46047.132376194, "episode/length": 401.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1018960, "time": 46065.09395432472, "episode/length": 522.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.988527724665392, "episode/intrinsic_return": 0.0}
{"step": 1019224, "time": 46075.16774511337, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 1019552, "time": 46087.86040019989, "episode/length": 198.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 1019880, "time": 46100.31914186478, "episode/length": 248.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1019880, "time": 46100.32833147049, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 1020016, "time": 46108.39119553566, "episode/length": 272.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
