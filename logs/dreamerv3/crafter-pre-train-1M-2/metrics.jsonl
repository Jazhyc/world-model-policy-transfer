{"step": 992, "time": 106.37381100654602, "episode/length": 123.0, "episode/score": 0.12713826844992582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12713826844992582}
{"step": 1152, "time": 108.88795256614685, "episode/length": 143.0, "episode/score": 0.12117047281208215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12117047281208215}
{"step": 1160, "time": 110.29487299919128, "episode/length": 144.0, "episode/score": 0.16744464951261762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16744464951261762}
{"step": 1200, "time": 111.9873456954956, "episode/length": 149.0, "episode/score": 0.16412505369225983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16412505369225983}
{"step": 1232, "time": 113.59694004058838, "episode/length": 153.0, "episode/score": 0.13357862466364168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13357862466364168}
{"step": 1304, "time": 115.39613604545593, "episode/length": 162.0, "episode/score": 0.15869352437584894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15869352437584894}
{"step": 1440, "time": 117.65459394454956, "episode/length": 179.0, "episode/score": 0.16665729059604928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16665729059604928}
{"step": 1560, "time": 134.80845093727112, "eval_episode/length": 147.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1560, "time": 136.48533129692078, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 1560, "time": 138.13964748382568, "eval_episode/length": 170.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1560, "time": 139.7847490310669, "eval_episode/length": 182.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 1560, "time": 141.2307689189911, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1560, "time": 142.93600034713745, "eval_episode/length": 191.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 1560, "time": 144.76251602172852, "train_stats/sum_log_reward": 1.6714285356657845, "train_stats/max_log_achievement_collect_sapling": 0.7142857142857143, "train_stats/max_log_achievement_place_plant": 0.7142857142857143, "train_stats/max_log_achievement_wake_up": 1.8571428571428572, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_place_table": 0.5, "eval_stats/sum_log_reward": 1.4333332777023315, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_place_plant": 0.3333333333333333, "eval_stats/max_log_achievement_place_table": 0.16666666666666666, "eval_stats/max_log_achievement_wake_up": 2.3333333333333335}
{"step": 1560, "time": 183.71873378753662, "eval_episode/length": 159.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 1560, "time": 186.18308901786804, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 1560, "time": 187.98828601837158, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1560, "time": 189.95014882087708, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9602272727272727}
{"step": 1560, "time": 189.9572615623474, "eval_episode/length": 175.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 1560, "time": 193.5405831336975, "eval_episode/length": 181.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 1560, "time": 196.39990186691284, "eval_episode/length": 205.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 1560, "time": 202.49819040298462, "eval_episode/length": 310.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9903536977491961}
{"step": 1561, "time": 331.1938235759735, "eval_stats/sum_log_reward": 2.224999912083149, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.375, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.51861572265625, "train/action_min": 0.0, "train/action_std": 4.763615608215332, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010719658894231543, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.5429050922393799, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.99609375, "train/cont_loss_mean": 1.345510721206665, "train/cont_loss_std": 0.4237143099308014, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.3718247711658478, "train/cont_pos_acc": 0.0362745076417923, "train/cont_pos_loss": 1.3493289947509766, "train/cont_pred": 0.2815321087837219, "train/cont_rate": 0.99609375, "train/dyn_loss_mean": 10.910884857177734, "train/dyn_loss_std": 0.4573119878768921, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.9511479139328003, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 7832.99267578125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3589.09814453125, "train/image_loss_std": 134.33523559570312, "train/model_loss_mean": 3602.531494140625, "train/model_loss_std": 134.4417724609375, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36025316.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.773419141769409, "train/policy_entropy_max": 2.773419141769409, "train/policy_entropy_mean": 2.556089401245117, "train/policy_entropy_min": 1.8749943971633911, "train/policy_entropy_std": 0.09546874463558197, "train/policy_logprob_mag": 5.334964275360107, "train/policy_logprob_max": -0.6124130487442017, "train/policy_logprob_mean": -2.5485618114471436, "train/policy_logprob_min": -5.334964275360107, "train/policy_logprob_std": 0.7173213362693787, "train/policy_randomness_mag": 0.9788952469825745, "train/policy_randomness_max": 0.9788952469825745, "train/policy_randomness_mean": 0.9021874070167542, "train/policy_randomness_min": 0.6617907285690308, "train/policy_randomness_std": 0.03369627520442009, "train/post_ent_mag": 106.21018981933594, "train/post_ent_max": 106.21018981933594, "train/post_ent_mean": 105.36203002929688, "train/post_ent_min": 104.7637710571289, "train/post_ent_std": 0.21220356225967407, "train/prior_ent_mag": 106.43125915527344, "train/prior_ent_max": 106.43125915527344, "train/prior_ent_mean": 105.58149719238281, "train/prior_ent_min": 104.4679946899414, "train/prior_ent_std": 0.29261747002601624, "train/rep_loss_mean": 10.910884857177734, "train/rep_loss_std": 0.4573119878768921, "train/reward_avg": 0.0009316083160229027, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.813294354898972e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.3936432600021362, "report/cont_loss_std": 0.46437472105026245, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.2629987895488739, "report/cont_pos_acc": 0.047058820724487305, "report/cont_pos_loss": 1.3980770111083984, "report/cont_pred": 0.27219468355178833, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.902610778808594, "report/dyn_loss_std": 0.46960780024528503, "report/image_loss_mean": 3588.6611328125, "report/image_loss_std": 135.7281494140625, "report/model_loss_mean": 3602.1376953125, "report/model_loss_std": 135.82931518554688, "report/post_ent_mag": 106.31431579589844, "report/post_ent_max": 106.31431579589844, "report/post_ent_mean": 105.36994934082031, "report/post_ent_min": 104.79542541503906, "report/post_ent_std": 0.22440105676651, "report/prior_ent_mag": 106.34452819824219, "report/prior_ent_max": 106.34452819824219, "report/prior_ent_mean": 105.58633422851562, "report/prior_ent_min": 104.56234741210938, "report/prior_ent_std": 0.2914734184741974, "report/rep_loss_mean": 10.902610778808594, "report/rep_loss_std": 0.46960780024528503, "report/reward_avg": 0.0009316083160229027, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.813294354898972e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.3251457214355469, "eval/cont_loss_std": 0.4157264232635498, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.3936209976673126, "eval/cont_pos_acc": 0.055772993713617325, "eval/cont_pos_loss": 1.3269685506820679, "eval/cont_pred": 0.28821641206741333, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.847511291503906, "eval/dyn_loss_std": 0.4959633946418762, "eval/image_loss_mean": 3549.05322265625, "eval/image_loss_std": 169.29598999023438, "eval/model_loss_mean": 3562.42822265625, "eval/model_loss_std": 169.33120727539062, "eval/post_ent_mag": 105.97581481933594, "eval/post_ent_max": 105.97581481933594, "eval/post_ent_mean": 105.338623046875, "eval/post_ent_min": 104.74198913574219, "eval/post_ent_std": 0.20422661304473877, "eval/prior_ent_mag": 106.51145935058594, "eval/prior_ent_max": 106.51145935058594, "eval/prior_ent_mean": 105.55599975585938, "eval/prior_ent_min": 104.59514617919922, "eval/prior_ent_std": 0.2926422357559204, "eval/rep_loss_mean": 10.847511291503906, "eval/rep_loss_std": 0.4959633946418762, "eval/reward_avg": 0.00791015662252903, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0107421875, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 3.7463521100263495e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.302582059587751e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3544.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4718176279864515e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1388744626726423e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 243.0013256072998, "timer/env.step_count": 196.0, "timer/env.step_total": 25.629860401153564, "timer/env.step_frac": 0.10547210117928525, "timer/env.step_avg": 0.13076459388343656, "timer/env.step_min": 0.023771286010742188, "timer/env.step_max": 11.073854446411133, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.11449670791625977, "timer/replay._sample_frac": 0.0004711772976139693, "timer/replay._sample_avg": 0.001022292034966605, "timer/replay._sample_min": 0.00039196014404296875, "timer/replay._sample_max": 0.011401891708374023, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.878083944320679, "timer/agent.save_frac": 0.036535125568277885, "timer/agent.save_avg": 8.878083944320679, "timer/agent.save_min": 8.878083944320679, "timer/agent.save_max": 8.878083944320679, "timer/agent.policy_count": 312.0, "timer/agent.policy_total": 22.434433460235596, "timer/agent.policy_frac": 0.09232226780725702, "timer/agent.policy_avg": 0.07190523544947307, "timer/agent.policy_min": 0.01018977165222168, "timer/agent.policy_max": 14.674088954925537, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.315376281738281e-05, "timer/dataset_train_frac": 1.7758653254065402e-07, "timer/dataset_train_avg": 4.315376281738281e-05, "timer/dataset_train_min": 4.315376281738281e-05, "timer/dataset_train_max": 4.315376281738281e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 93.17895698547363, "timer/agent.train_frac": 0.38345040609389386, "timer/agent.train_avg": 93.17895698547363, "timer/agent.train_min": 93.17895698547363, "timer/agent.train_max": 93.17895698547363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 33.126659870147705, "timer/agent.report_frac": 0.13632295950385784, "timer/agent.report_avg": 16.563329935073853, "timer/agent.report_min": 8.313107967376709, "timer/agent.report_max": 24.813551902770996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.245208740234375e-05, "timer/dataset_eval_frac": 2.1585103402731428e-07, "timer/dataset_eval_avg": 5.245208740234375e-05, "timer/dataset_eval_min": 5.245208740234375e-05, "timer/dataset_eval_max": 5.245208740234375e-05}
{"step": 1992, "time": 347.85112285614014, "episode/length": 103.0, "episode/score": 0.10499669440105208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10499669440105208}
{"step": 2032, "time": 351.2550461292267, "episode/length": 253.0, "episode/score": 0.28574851960365777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28574851960365777}
{"step": 2464, "time": 369.4453670978546, "episode/length": 183.0, "episode/score": 0.19179521543628653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19179521543628653}
{"step": 2520, "time": 373.1461045742035, "episode/length": 151.0, "episode/score": 0.12287272062712873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12287272062712873}
{"step": 2720, "time": 382.6502504348755, "episode/length": 185.0, "episode/score": 0.18306496373770642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18306496373770642}
{"step": 2808, "time": 387.35811138153076, "episode/length": 170.0, "episode/score": 0.16398404889696394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16398404889696394}
{"step": 3032, "time": 397.5740051269531, "episode/length": 234.0, "episode/score": 0.26522239252335567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26522239252335567}
{"step": 3336, "time": 410.95993161201477, "episode/length": 167.0, "episode/score": 0.12415937276909972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12415937276909972}
{"step": 3384, "time": 414.40693163871765, "episode/length": 168.0, "episode/score": 0.16107552914490952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16107552914490952}
{"step": 3552, "time": 422.6637878417969, "episode/length": 293.0, "episode/score": 0.30123869324415864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30123869324415864}
{"step": 3608, "time": 426.16014862060547, "episode/length": 142.0, "episode/score": 0.15046251888634288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15046251888634288}
{"step": 3992, "time": 442.65022683143616, "episode/length": 158.0, "episode/score": 0.13298497000869247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13298497000869247}
{"step": 4104, "time": 448.5500180721283, "episode/length": 197.0, "episode/score": 0.21485358280824585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21485358280824585}
{"step": 4224, "time": 455.0030634403229, "episode/length": 110.0, "episode/score": 0.12924999772803858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12924999772803858}
{"step": 4560, "time": 469.56826305389404, "episode/length": 190.0, "episode/score": 0.1895853624373558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1895853624373558}
{"step": 4608, "time": 473.06694531440735, "episode/length": 152.0, "episode/score": 0.15373506973355688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15373506973355688}
{"step": 4744, "time": 479.55811405181885, "episode/length": 148.0, "episode/score": 0.11465011364543898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11465011364543898}
{"step": 5040, "time": 492.6718113422394, "episode/length": 278.0, "episode/score": 0.2556480034827473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2556480034827473}
{"step": 5152, "time": 498.9148087501526, "episode/length": 144.0, "episode/score": 0.14814167955864832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14814167955864832}
{"step": 5312, "time": 506.67473101615906, "episode/length": 212.0, "episode/score": 0.22031604615949618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22031604615949618}
{"step": 5328, "time": 508.8981120586395, "episode/length": 152.0, "episode/score": 0.13233800207945023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13233800207945023}
{"step": 5368, "time": 511.94441080093384, "episode/length": 77.0, "episode/score": 0.09266666485927999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09266666485927999}
{"step": 5536, "time": 520.240777015686, "episode/length": 163.0, "episode/score": 0.18539701300187517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18539701300187517}
{"step": 6008, "time": 539.8385486602783, "episode/length": 180.0, "episode/score": 0.159420436205437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159420436205437}
{"step": 6088, "time": 544.5014975070953, "episode/length": 184.0, "episode/score": 0.17463072081682185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17463072081682185}
{"step": 6304, "time": 554.7277450561523, "episode/length": 157.0, "episode/score": 0.12878374799265657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12878374799265657}
{"step": 6480, "time": 563.0714848041534, "episode/length": 165.0, "episode/score": 0.1652312138844536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1652312138844536}
{"step": 6656, "time": 571.4703533649445, "episode/length": 165.0, "episode/score": 0.1096764538710886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1096764538710886}
{"step": 6712, "time": 575.0022902488708, "episode/length": 174.0, "episode/score": 0.1920323878907766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1920323878907766}
{"step": 6936, "time": 585.2887027263641, "episode/length": 174.0, "episode/score": 0.12152025442446757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12152025442446757}
{"step": 7160, "time": 595.5123398303986, "episode/length": 223.0, "episode/score": 0.22935676631050228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22935676631050228}
{"step": 7336, "time": 603.7747275829315, "episode/length": 155.0, "episode/score": 0.15071742703639757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15071742703639757}
{"step": 7584, "time": 615.0113835334778, "episode/length": 196.0, "episode/score": 0.15795859036416005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15795859036416005}
{"step": 7648, "time": 619.0630915164948, "episode/length": 167.0, "episode/score": 0.1496172489160017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1496172489160017}
{"step": 7848, "time": 628.0505719184875, "episode/length": 170.0, "episode/score": 0.1869123135747941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1869123135747941}
{"step": 7912, "time": 632.080620765686, "episode/length": 156.0, "episode/score": 0.11644551907147616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11644551907147616}
{"step": 8080, "time": 640.2265481948853, "episode/length": 170.0, "episode/score": 0.1592951177285613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1592951177285613}
{"step": 8096, "time": 642.3129677772522, "episode/length": 144.0, "episode/score": 0.1555062062570869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1555062062570869}
{"step": 8744, "time": 669.2865941524506, "episode/length": 144.0, "episode/score": 0.1362203954809047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1362203954809047}
{"step": 8752, "time": 671.5290875434875, "episode/length": 176.0, "episode/score": 0.13659261379143572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13659261379143572}
{"step": 8912, "time": 679.1636536121368, "episode/length": 157.0, "episode/score": 0.13866817809412169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13866817809412169}
{"step": 8984, "time": 683.2255914211273, "episode/length": 110.0, "episode/score": 0.06487248013445424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06487248013445424}
{"step": 9072, "time": 688.3651766777039, "episode/length": 144.0, "episode/score": 0.15718532619484904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15718532619484904}
{"step": 9224, "time": 695.4126620292664, "episode/length": 142.0, "episode/score": 0.09856012039813322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09856012039813322}
{"step": 9304, "time": 700.1079518795013, "episode/length": 267.0, "episode/score": 0.2749425268129926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2749425268129926}
{"step": 9424, "time": 706.5793118476868, "episode/length": 196.0, "episode/score": 0.19273772302676662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19273772302676662}
{"step": 9448, "time": 708.8711287975311, "episode/length": 66.0, "episode/score": 0.07938150880318062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07938150880318062}
{"step": 10048, "time": 732.9950065612793, "episode/length": 162.0, "episode/score": 0.132496361163021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.132496361163021}
{"step": 10088, "time": 755.2029416561127, "eval_episode/length": 137.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 10088, "time": 756.903167963028, "eval_episode/length": 140.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 10088, "time": 759.0322227478027, "eval_episode/length": 152.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 10088, "time": 760.9872624874115, "eval_episode/length": 159.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.95625}
{"step": 10088, "time": 764.4444053173065, "eval_episode/length": 197.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 10088, "time": 766.4948742389679, "eval_episode/length": 205.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 10088, "time": 768.5942316055298, "eval_episode/length": 215.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 10088, "time": 770.9854898452759, "eval_episode/length": 232.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 10136, "time": 772.7785320281982, "episode/length": 172.0, "episode/score": 0.15903928816510415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15903928816510415}
{"step": 10448, "time": 786.2781155109406, "episode/length": 152.0, "episode/score": 0.11095113372562082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11095113372562082}
{"step": 10504, "time": 789.6437456607819, "episode/length": 189.0, "episode/score": 0.15585446543104808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15585446543104808}
{"step": 10664, "time": 797.1960380077362, "episode/length": 154.0, "episode/score": 0.15109571579955627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15109571579955627}
{"step": 10776, "time": 803.036967754364, "episode/length": 212.0, "episode/score": 0.2068023201154574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2068023201154574}
{"step": 10920, "time": 809.9965982437134, "episode/length": 201.0, "episode/score": 0.173189314537467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.173189314537467}
{"step": 10928, "time": 812.1958303451538, "episode/length": 184.0, "episode/score": 0.1698398959201768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1698398959201768}
{"step": 11304, "time": 827.7810263633728, "episode/length": 156.0, "episode/score": 0.1070896483620345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1070896483620345}
{"step": 11368, "time": 831.7779748439789, "episode/length": 153.0, "episode/score": 0.16457049925247702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16457049925247702}
{"step": 11680, "time": 845.5890784263611, "episode/length": 153.0, "episode/score": 0.10494656746573128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10494656746573128}
{"step": 11904, "time": 856.1451244354248, "episode/length": 154.0, "episode/score": 0.1349092523237232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1349092523237232}
{"step": 11944, "time": 859.0293476581573, "episode/length": 179.0, "episode/score": 0.17547019576318235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17547019576318235}
{"step": 12080, "time": 866.4640974998474, "episode/length": 144.0, "episode/score": 0.11378844719888548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11378844719888548}
{"step": 12208, "time": 872.8545250892639, "episode/length": 178.0, "episode/score": 0.15368561936247715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15368561936247715}
{"step": 12584, "time": 888.5183317661285, "episode/length": 206.0, "episode/score": 0.21470460487080345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21470460487080345}
{"step": 12632, "time": 891.9449424743652, "episode/length": 52.0, "episode/score": 0.04380105091649966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04380105091649966}
{"step": 12704, "time": 896.4869780540466, "episode/length": 174.0, "episode/score": 0.14882960710133375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14882960710133375}
{"step": 12832, "time": 903.0168671607971, "episode/length": 182.0, "episode/score": 0.1629748875079713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1629748875079713}
{"step": 13280, "time": 921.6057999134064, "episode/length": 171.0, "episode/score": 0.16505441985259495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16505441985259495}
{"step": 13448, "time": 929.3633208274841, "episode/length": 187.0, "episode/score": 0.1719118827015791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1719118827015791}
{"step": 13616, "time": 937.5488650798798, "episode/length": 191.0, "episode/score": 0.16991023862851762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16991023862851762}
{"step": 13816, "time": 946.6141245365143, "episode/length": 153.0, "episode/score": 0.16198417158034317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16198417158034317}
{"step": 13896, "time": 951.1991987228394, "episode/length": 276.0, "episode/score": 0.2881725644119797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2881725644119797}
{"step": 13936, "time": 954.5083606243134, "episode/length": 39.0, "episode/score": 0.03813994551592259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03813994551592259}
{"step": 14176, "time": 965.1489944458008, "episode/length": 183.0, "episode/score": 0.13105074831969432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13105074831969432}
{"step": 14320, "time": 972.1840720176697, "episode/length": 210.0, "episode/score": 0.16958056305293212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16958056305293212}
{"step": 14456, "time": 979.4077582359314, "episode/length": 202.0, "episode/score": 0.21476142532310405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21476142532310405}
{"step": 14576, "time": 986.5784313678741, "episode/length": 161.0, "episode/score": 0.10941837547488831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10941837547488831}
{"step": 14776, "time": 996.2907898426056, "episode/length": 165.0, "episode/score": 0.12680984702092246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12680984702092246}
{"step": 15160, "time": 1012.3147194385529, "episode/length": 167.0, "episode/score": 0.16453321018548195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16453321018548195}
{"step": 15456, "time": 1025.303150653839, "episode/length": 159.0, "episode/score": 0.15037797080719884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15037797080719884}
{"step": 15704, "time": 1036.012555360794, "episode/length": 225.0, "episode/score": 0.23728587780988164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23728587780988164}
{"step": 15856, "time": 1043.5852708816528, "episode/length": 174.0, "episode/score": 0.16932355100470886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16932355100470886}
{"step": 15880, "time": 1045.8547286987305, "episode/length": 162.0, "episode/score": 0.14722926928061497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14722926928061497}
{"step": 16016, "time": 1052.9925832748413, "episode/length": 259.0, "episode/score": 0.28096680102748905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28096680102748905}
{"step": 16032, "time": 1055.1884815692902, "episode/length": 213.0, "episode/score": 0.23022610117845943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23022610117845943}
{"step": 16320, "time": 1067.7624065876007, "episode/length": 35.0, "episode/score": 0.03729166623088531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03729166623088531}
{"step": 16600, "time": 1080.8866412639618, "episode/length": 227.0, "episode/score": 0.219710327993198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.219710327993198}
{"step": 16720, "time": 1087.232313156128, "episode/length": 194.0, "episode/score": 0.15804312985028446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15804312985028446}
{"step": 16776, "time": 1090.69185090065, "episode/length": 164.0, "episode/score": 0.16166536543994425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16166536543994425}
{"step": 17016, "time": 1101.4056642055511, "episode/length": 141.0, "episode/score": 0.14782988455613122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14782988455613122}
{"step": 17216, "time": 1110.800133228302, "episode/length": 149.0, "episode/score": 0.11241170955702273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11241170955702273}
{"step": 17240, "time": 1113.036239862442, "episode/length": 172.0, "episode/score": 0.14985692351876878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14985692351876878}
{"step": 17296, "time": 1116.9969022274017, "episode/length": 198.0, "episode/score": 0.1900257381918209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1900257381918209}
{"step": 17760, "time": 1136.124683856964, "episode/length": 144.0, "episode/score": 0.13797439066979678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13797439066979678}
{"step": 17992, "time": 1146.304309129715, "episode/length": 208.0, "episode/score": 0.19304867580535756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19304867580535756}
{"step": 18032, "time": 1149.6106207370758, "episode/length": 163.0, "episode/score": 0.12476923866699963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12476923866699963}
{"step": 18208, "time": 1157.8004231452942, "episode/length": 178.0, "episode/score": 0.16156226586508637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16156226586508637}
{"step": 18248, "time": 1160.680011510849, "episode/length": 153.0, "episode/score": 0.1314928196964047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1314928196964047}
{"step": 18368, "time": 1167.0660436153412, "episode/length": 143.0, "episode/score": 0.15324565789023836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15324565789023836}
{"step": 18528, "time": 1174.8030395507812, "episode/length": 160.0, "episode/score": 0.14662553384982857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14662553384982857}
{"step": 18568, "time": 1177.7783596515656, "episode/length": 158.0, "episode/score": 0.12112367723466377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12112367723466377}
{"step": 19104, "time": 1199.7998135089874, "episode/length": 167.0, "episode/score": 0.15213520952943327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15213520952943327}
{"step": 19200, "time": 1204.9079117774963, "episode/length": 103.0, "episode/score": 0.10030643320681065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10030643320681065}
{"step": 19240, "time": 1207.7892138957977, "episode/length": 155.0, "episode/score": 0.12781718394717245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12781718394717245}
{"step": 19432, "time": 1216.6339347362518, "episode/length": 147.0, "episode/score": 0.14168751521401646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14168751521401646}
{"step": 19584, "time": 1224.1520109176636, "episode/length": 171.0, "episode/score": 0.13992037735363283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13992037735363283}
{"step": 19672, "time": 1228.9914982318878, "episode/length": 204.0, "episode/score": 0.17272561763206795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17272561763206795}
{"step": 19992, "time": 1242.577844619751, "episode/length": 177.0, "episode/score": 0.15778142844976628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15778142844976628}
{"step": 20072, "time": 1263.8327610492706, "eval_episode/length": 63.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.921875}
{"step": 20072, "time": 1267.0238523483276, "eval_episode/length": 99.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 20072, "time": 1270.8067164421082, "eval_episode/length": 149.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 20072, "time": 1272.638150215149, "eval_episode/length": 154.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 20072, "time": 1274.4207153320312, "eval_episode/length": 156.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 20072, "time": 1277.3911337852478, "eval_episode/length": 187.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 20072, "time": 1279.4701063632965, "eval_episode/length": 197.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.98989898989899}
{"step": 20072, "time": 1281.8638052940369, "eval_episode/length": 152.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 20144, "time": 1284.8130633831024, "episode/length": 201.0, "episode/score": 0.1776432827617782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1776432827617782}
{"step": 20432, "time": 1297.2965660095215, "episode/length": 153.0, "episode/score": 0.14531580321795445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14531580321795445}
{"step": 20433, "time": 1299.5231728553772, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.027975308693062, "train/action_min": 0.0, "train/action_std": 4.902077537471965, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0028993117986089094, "train/actor_opt_grad_steps": 595.0, "train/actor_opt_loss": 118.66413457716925, "train/adv_mag": 0.03764592322952043, "train/adv_max": 0.008619231569740558, "train/adv_mean": 0.004632421632808381, "train/adv_min": -0.03217697125697761, "train/adv_std": 0.003161017896688417, "train/cont_avg": 0.9946951138771186, "train/cont_loss_mean": 0.032881518360227346, "train/cont_loss_std": 0.23968822363827189, "train/cont_neg_acc": 0.07249798366831521, "train/cont_neg_loss": 3.147867192908869, "train/cont_pos_acc": 0.9917322398179164, "train/cont_pos_loss": 0.016829284624999656, "train/cont_pred": 0.9880183796256276, "train/cont_rate": 0.9946951138771186, "train/dyn_loss_mean": 5.784032955008038, "train/dyn_loss_std": 8.31585513004812, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.867310314612873, "train/extr_critic_critic_opt_grad_steps": 595.0, "train/extr_critic_critic_opt_loss": 19102.256653866527, "train/extr_critic_mag": 0.05439309548523467, "train/extr_critic_max": 0.05439309346473823, "train/extr_critic_mean": 0.05421842551676063, "train/extr_critic_min": 0.053969595391871565, "train/extr_critic_std": 5.8537426499905765e-05, "train/extr_return_normed_mag": 0.0387259655266061, "train/extr_return_normed_max": 0.015992314361876384, "train/extr_return_normed_mean": 0.012072583166088207, "train/extr_return_normed_min": -0.024708241277286276, "train/extr_return_normed_std": 0.00316155929896799, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06277056447140501, "train/extr_return_raw_max": 0.06277056447140501, "train/extr_return_raw_mean": 0.05885083560022364, "train/extr_return_raw_min": 0.02207000881543983, "train/extr_return_raw_std": 0.003161559296994849, "train/extr_reward_mag": 0.0009786183551206426, "train/extr_reward_max": 0.0009786183551206426, "train/extr_reward_mean": 0.0009101605150968002, "train/extr_reward_min": 0.0008205185502262439, "train/extr_reward_std": 3.375830253214013e-05, "train/image_loss_mean": 100.38152920997749, "train/image_loss_std": 53.49826099912999, "train/model_loss_mean": 104.09133086770268, "train/model_loss_std": 55.063300940950036, "train/model_opt_grad_norm": 420.2469711303711, "train/model_opt_grad_steps": 586.0, "train/model_opt_loss": 2143.3312067581437, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 22.510593220338983, "train/policy_entropy_mag": 2.8244061550851596, "train/policy_entropy_max": 2.8244061550851596, "train/policy_entropy_mean": 2.767713047690311, "train/policy_entropy_min": 2.526823088274164, "train/policy_entropy_std": 0.030121314497191017, "train/policy_logprob_mag": 4.735455161434109, "train/policy_logprob_max": -1.471553871187113, "train/policy_logprob_mean": -2.767744234052755, "train/policy_logprob_min": -4.735455161434109, "train/policy_logprob_std": 0.3470750405626782, "train/policy_randomness_mag": 0.9968914273431746, "train/policy_randomness_max": 0.9968914273431746, "train/policy_randomness_mean": 0.976881252507032, "train/policy_randomness_min": 0.8918576629485114, "train/policy_randomness_std": 0.010631502189641913, "train/post_ent_mag": 51.21608268608481, "train/post_ent_max": 51.21608268608481, "train/post_ent_mean": 31.593873686709646, "train/post_ent_min": 14.898974022622836, "train/post_ent_std": 8.017051040747408, "train/prior_ent_mag": 56.418207459530585, "train/prior_ent_max": 56.418207459530585, "train/prior_ent_mean": 38.01156522459903, "train/prior_ent_min": 19.60610125428539, "train/prior_ent_std": 7.7290056835291745, "train/rep_loss_mean": 5.784032955008038, "train/rep_loss_std": 8.31585513004812, "train/reward_avg": 0.0009429209941595603, "train/reward_loss_mean": 0.20649869799992795, "train/reward_loss_std": 0.013227695806685492, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0009745874647366799, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.20649870257761518, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0009063521155424542, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.4944953722281193, "train_stats/max_log_achievement_collect_drink": 0.26605504587155965, "train_stats/max_log_achievement_collect_sapling": 0.7339449541284404, "train_stats/max_log_achievement_collect_wood": 0.3944954128440367, "train_stats/max_log_achievement_place_plant": 0.6422018348623854, "train_stats/max_log_achievement_place_table": 0.05504587155963303, "train_stats/max_log_achievement_wake_up": 1.724770642201835, "train_stats/mean_log_entropy": 2.748388108857181, "eval_stats/sum_log_reward": 1.1624999670311809, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.14285714285714285, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.016055557876825333, "report/cont_loss_std": 0.16515113413333893, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 1.5233078002929688, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004187429789453745, "report/cont_pred": 0.9935274124145508, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.958617210388184, "report/dyn_loss_std": 6.029480934143066, "report/image_loss_mean": 37.59820556640625, "report/image_loss_std": 34.17771530151367, "report/model_loss_mean": 41.82483673095703, "report/model_loss_std": 36.15645217895508, "report/post_ent_mag": 50.351905822753906, "report/post_ent_max": 50.351905822753906, "report/post_ent_mean": 29.544349670410156, "report/post_ent_min": 13.680524826049805, "report/post_ent_std": 6.315098762512207, "report/prior_ent_mag": 56.92121887207031, "report/prior_ent_max": 56.92121887207031, "report/prior_ent_mean": 38.014183044433594, "report/prior_ent_min": 17.491924285888672, "report/prior_ent_std": 7.918984413146973, "report/rep_loss_mean": 6.958617210388184, "report/rep_loss_std": 6.029480934143066, "report/reward_avg": 0.00087810552213341, "report/reward_loss_mean": 0.035405706614255905, "report/reward_loss_std": 0.015359223820269108, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012426376342773438, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.035405710339546204, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008599230786785483, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.01041223295032978, "eval/cont_loss_std": 0.1848955750465393, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.4172351360321045, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00040197925409302115, "eval/cont_pred": 0.9995078444480896, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 8.794367790222168, "eval/dyn_loss_std": 6.334001541137695, "eval/image_loss_mean": 59.12919998168945, "eval/image_loss_std": 44.20750427246094, "eval/model_loss_mean": 64.79432678222656, "eval/model_loss_std": 46.63351058959961, "eval/post_ent_mag": 56.99424743652344, "eval/post_ent_max": 56.99424743652344, "eval/post_ent_mean": 31.386747360229492, "eval/post_ent_min": 12.82443904876709, "eval/post_ent_std": 8.110099792480469, "eval/prior_ent_mag": 58.55078125, "eval/prior_ent_max": 58.55078125, "eval/prior_ent_mean": 37.79388427734375, "eval/prior_ent_min": 15.782764434814453, "eval/prior_ent_std": 8.96867847442627, "eval/rep_loss_mean": 8.794367790222168, "eval/rep_loss_std": 6.334001541137695, "eval/reward_avg": 0.01279296912252903, "eval/reward_loss_mean": 0.37809857726097107, "eval/reward_loss_std": 2.083204507827759, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0011736154556274414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1879713088274002, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.356119155883789, "eval/reward_pred": 0.0008789123967289925, "eval/reward_rate": 0.015625, "replay/size": 19929.0, "replay/inserts": 18872.0, "replay/samples": 18864.0, "replay/insert_wait_avg": 1.4181433213166435e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.059852989170893e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7144.0, "eval_replay/inserts": 3600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2499756283230251e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 968.3200464248657, "timer/env.step_count": 2359.0, "timer/env.step_total": 241.9631781578064, "timer/env.step_frac": 0.24987934418084043, "timer/env.step_avg": 0.10257023236871828, "timer/env.step_min": 0.023836612701416016, "timer/env.step_max": 2.2589917182922363, "timer/replay._sample_count": 18864.0, "timer/replay._sample_total": 9.862037181854248, "timer/replay._sample_frac": 0.010184687612598617, "timer/replay._sample_avg": 0.0005227967123544449, "timer/replay._sample_min": 0.00034546852111816406, "timer/replay._sample_max": 0.01789402961730957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2809.0, "timer/agent.policy_total": 47.4750599861145, "timer/agent.policy_frac": 0.04902827341166504, "timer/agent.policy_avg": 0.01690105375084176, "timer/agent.policy_min": 0.009680986404418945, "timer/agent.policy_max": 0.1016693115234375, "timer/dataset_train_count": 1179.0, "timer/dataset_train_total": 0.1359090805053711, "timer/dataset_train_frac": 0.00014035553741468122, "timer/dataset_train_avg": 0.00011527487744306285, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.00021529197692871094, "timer/agent.train_count": 1179.0, "timer/agent.train_total": 532.5395956039429, "timer/agent.train_frac": 0.5499623782138273, "timer/agent.train_avg": 0.4516875280779838, "timer/agent.train_min": 0.4388704299926758, "timer/agent.train_max": 0.8275794982910156, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47393107414245605, "timer/agent.report_frac": 0.0004894363964602994, "timer/agent.report_avg": 0.23696553707122803, "timer/agent.report_min": 0.23124432563781738, "timer/agent.report_max": 0.24268674850463867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.8623809814453125e-05, "timer/dataset_eval_frac": 3.988744212934152e-08, "timer/dataset_eval_avg": 3.8623809814453125e-05, "timer/dataset_eval_min": 3.8623809814453125e-05, "timer/dataset_eval_max": 3.8623809814453125e-05, "fps": 19.489190798501117}
{"step": 20584, "time": 1305.372218132019, "episode/length": 167.0, "episode/score": 0.1422888912347844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1422888912347844}
{"step": 20664, "time": 1309.9384219646454, "episode/length": 194.0, "episode/score": 0.20677800518546974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20677800518546974}
{"step": 20664, "time": 1309.9450809955597, "episode/length": 83.0, "episode/score": 0.07697443090444267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07697443090444267}
{"step": 20736, "time": 1316.432849407196, "episode/length": 143.0, "episode/score": 0.13829472744441773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13829472744441773}
{"step": 20992, "time": 1327.6247863769531, "episode/length": 194.0, "episode/score": 0.21793631573268613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21793631573268613}
{"step": 21328, "time": 1342.0008051395416, "episode/length": 206.0, "episode/score": 0.19920988924582161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19920988924582161}
{"step": 21488, "time": 1350.240734577179, "episode/length": 167.0, "episode/score": 0.13370077141075853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13370077141075853}
{"step": 21800, "time": 1364.1127495765686, "episode/length": 170.0, "episode/score": 0.15735807689634385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15735807689634385}
{"step": 21960, "time": 1372.3903691768646, "episode/length": 161.0, "episode/score": 0.15264490919798845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15264490919798845}
{"step": 22040, "time": 1377.1045796871185, "episode/length": 181.0, "episode/score": 0.1853546059301152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1853546059301152}
{"step": 22064, "time": 1379.8730070590973, "episode/length": 133.0, "episode/score": 0.11643822033147444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11643822033147444}
{"step": 22296, "time": 1389.828447818756, "episode/length": 194.0, "episode/score": 0.17692102195906045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17692102195906045}
{"step": 22360, "time": 1393.8787078857422, "episode/length": 211.0, "episode/score": 0.18799817740182334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18799817740182334}
{"step": 22984, "time": 1419.9252026081085, "episode/length": 206.0, "episode/score": 0.18559420233032142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18559420233032142}
{"step": 23136, "time": 1427.6466302871704, "episode/length": 166.0, "episode/score": 0.15901907141414995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15901907141414995}
{"step": 23160, "time": 1430.3036324977875, "episode/length": 136.0, "episode/score": 0.10822980769080459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10822980769080459}
{"step": 23376, "time": 1440.9465622901917, "episode/length": 166.0, "episode/score": 0.1609615046172621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1609615046172621}
{"step": 23392, "time": 1443.6106214523315, "episode/length": 178.0, "episode/score": 0.17853031230060878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17853031230060878}
{"step": 23416, "time": 1446.4629311561584, "episode/length": 240.0, "episode/score": 0.21391935621431912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21391935621431912}
{"step": 23560, "time": 1453.855320930481, "episode/length": 157.0, "episode/score": 0.1864691993514498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1864691993514498}
{"step": 23800, "time": 1464.7530364990234, "episode/length": 179.0, "episode/score": 0.15713353936280328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15713353936280328}
{"step": 24032, "time": 1475.2799355983734, "episode/length": 130.0, "episode/score": 0.14561621407028724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14561621407028724}
{"step": 24488, "time": 1493.6726660728455, "episode/length": 165.0, "episode/score": 0.18787499703466892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18787499703466892}
{"step": 24768, "time": 1506.9398291110992, "episode/length": 173.0, "episode/score": 0.17455823173713725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17455823173713725}
{"step": 24800, "time": 1509.7712547779083, "episode/length": 172.0, "episode/score": 0.15197975676346687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15197975676346687}
{"step": 24800, "time": 1509.7795119285583, "episode/length": 175.0, "episode/score": 0.1675513021136794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1675513021136794}
{"step": 25024, "time": 1521.7886638641357, "episode/length": 182.0, "episode/score": 0.1509321685557552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1509321685557552}
{"step": 25040, "time": 1524.0807602405548, "episode/length": 237.0, "episode/score": 0.23201084520133008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23201084520133008}
{"step": 25096, "time": 1527.7482392787933, "episode/length": 161.0, "episode/score": 0.15177468373622105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15177468373622105}
{"step": 25464, "time": 1543.0823826789856, "episode/length": 178.0, "episode/score": 0.154488026699255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.154488026699255}
{"step": 25920, "time": 1562.0617332458496, "episode/length": 143.0, "episode/score": 0.16438897590705892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16438897590705892}
{"step": 26152, "time": 1572.0533638000488, "episode/length": 168.0, "episode/score": 0.1564341362277446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1564341362277446}
{"step": 26192, "time": 1575.6242325305939, "episode/length": 212.0, "episode/score": 0.18749963580921758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18749963580921758}
{"step": 26504, "time": 1588.7737746238708, "episode/length": 175.0, "episode/score": 0.17386602745455093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17386602745455093}
{"step": 26576, "time": 1593.279002904892, "episode/length": 193.0, "episode/score": 0.20329981490704085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20329981490704085}
{"step": 26688, "time": 1599.1115407943726, "episode/length": 235.0, "episode/score": 0.2597822607890521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2597822607890521}
{"step": 26712, "time": 1601.2994446754456, "episode/length": 208.0, "episode/score": 0.24104120666333984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24104120666333984}
{"step": 27032, "time": 1614.9849545955658, "episode/length": 195.0, "episode/score": 0.21886892209704456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21886892209704456}
{"step": 27208, "time": 1623.160594701767, "episode/length": 61.0, "episode/score": 0.07258333201752976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07258333201752976}
{"step": 27528, "time": 1637.1328029632568, "episode/length": 166.0, "episode/score": 0.15869798504218124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15869798504218124}
{"step": 27632, "time": 1642.930896282196, "episode/length": 213.0, "episode/score": 0.20872657415156937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20872657415156937}
{"step": 27944, "time": 1655.961788892746, "episode/length": 179.0, "episode/score": 0.15868466613756027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15868466613756027}
{"step": 28000, "time": 1659.8819274902344, "episode/length": 230.0, "episode/score": 0.24524999417417348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24524999417417348}
{"step": 28096, "time": 1665.268212556839, "episode/length": 189.0, "episode/score": 0.2044150811448162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2044150811448162}
{"step": 28112, "time": 1667.6246342658997, "episode/length": 177.0, "episode/score": 0.16527462437534268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16527462437534268}
{"step": 28832, "time": 1696.3904941082, "episode/length": 224.0, "episode/score": 0.21972852713270186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21972852713270186}
{"step": 29096, "time": 1707.60586476326, "episode/length": 235.0, "episode/score": 0.23967096888463857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23967096888463857}
{"step": 29136, "time": 1711.0200989246368, "episode/length": 187.0, "episode/score": 0.22537499549798667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22537499549798667}
{"step": 29224, "time": 1715.7328190803528, "episode/length": 152.0, "episode/score": 0.17053628207941074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17053628207941074}
{"step": 29456, "time": 1726.202297449112, "episode/length": 188.0, "episode/score": 0.21282142482232302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21282142482232302}
{"step": 29496, "time": 1729.0562524795532, "episode/length": 174.0, "episode/score": 0.17795915812894236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17795915812894236}
{"step": 30016, "time": 1750.113088130951, "episode/length": 98.0, "episode/score": 0.11752380724647082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11752380724647082}
{"step": 30024, "time": 1751.791207075119, "episode/length": 238.0, "episode/score": 0.25350489181801095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25350489181801095}
{"step": 30056, "time": 1772.8730654716492, "eval_episode/length": 83.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9404761904761905}
{"step": 30056, "time": 1777.7494413852692, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 30056, "time": 1779.5323264598846, "eval_episode/length": 164.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 30056, "time": 1781.9765319824219, "eval_episode/length": 181.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 30056, "time": 1784.5401947498322, "eval_episode/length": 185.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 30056, "time": 1786.913105726242, "eval_episode/length": 194.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 30056, "time": 1791.273293018341, "eval_episode/length": 247.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9879032258064516}
{"step": 30056, "time": 1791.2809150218964, "eval_episode/length": 247.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 30384, "time": 1803.6657454967499, "episode/length": 155.0, "episode/score": 0.16781505463586655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16781505463586655}
{"step": 30408, "time": 1805.9019367694855, "episode/length": 196.0, "episode/score": 0.20013909089175286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20013909089175286}
{"step": 30408, "time": 1805.9113903045654, "episode/length": 359.0, "episode/score": 0.39213281094453123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39213281094453123}
{"step": 30528, "time": 1814.0496366024017, "episode/length": 133.0, "episode/score": 0.12643102724359778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12643102724359778}
{"step": 30568, "time": 1816.8658256530762, "episode/length": 183.0, "episode/score": 0.20878274413189502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20878274413189502}
{"step": 31176, "time": 1841.200430393219, "episode/length": 209.0, "episode/score": 0.20977330637833802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20977330637833802}
{"step": 31360, "time": 1850.0839054584503, "episode/length": 167.0, "episode/score": 0.1926349328696233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1926349328696233}
{"step": 31472, "time": 1855.997701883316, "episode/length": 180.0, "episode/score": 0.19383030661629164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19383030661629164}
{"step": 31552, "time": 1860.6505835056305, "episode/length": 145.0, "episode/score": 0.1505643425789458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1505643425789458}
{"step": 31584, "time": 1864.0062038898468, "episode/length": 131.0, "episode/score": 0.12209346848612768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12209346848612768}
{"step": 31792, "time": 1874.1702332496643, "episode/length": 172.0, "episode/score": 0.1952174931011541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952174931011541}
{"step": 31968, "time": 1883.0586488246918, "episode/length": 194.0, "episode/score": 0.19847962167659716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19847962167659716}
{"step": 32040, "time": 1887.7799685001373, "episode/length": 183.0, "episode/score": 0.1882912197170299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1882912197170299}
{"step": 32544, "time": 1909.0965025424957, "episode/length": 170.0, "episode/score": 0.15975336741212232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15975336741212232}
{"step": 32704, "time": 1916.7624652385712, "episode/length": 153.0, "episode/score": 0.15930038368151145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15930038368151145}
{"step": 32736, "time": 1919.5509283542633, "episode/length": 147.0, "episode/score": 0.14887867265861132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14887867265861132}
{"step": 32928, "time": 1929.8194584846497, "episode/length": 195.0, "episode/score": 0.18898613585224666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18898613585224666}
{"step": 33008, "time": 1934.6497383117676, "episode/length": 151.0, "episode/score": 0.14405130252907838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14405130252907838}
{"step": 33016, "time": 1936.2484533786774, "episode/length": 178.0, "episode/score": 0.206159544500224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.206159544500224}
{"step": 33408, "time": 1952.6909153461456, "episode/length": 170.0, "episode/score": 0.17334639949331176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17334639949331176}
{"step": 33472, "time": 1956.775672197342, "episode/length": 187.0, "episode/score": 0.17773104721527488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17773104721527488}
{"step": 33704, "time": 1966.9875328540802, "episode/length": 144.0, "episode/score": 0.14784169895210653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14784169895210653}
{"step": 34112, "time": 1984.010493516922, "episode/length": 137.0, "episode/score": 0.1632176239054388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1632176239054388}
{"step": 34208, "time": 1989.23650598526, "episode/length": 187.0, "episode/score": 0.19636894308587216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19636894308587216}
{"step": 34216, "time": 1990.9406578540802, "episode/length": 149.0, "episode/score": 0.15440334284994606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15440334284994606}
{"step": 34616, "time": 2007.6111743450165, "episode/length": 210.0, "episode/score": 0.2047523126248052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2047523126248052}
{"step": 34624, "time": 2009.7265360355377, "episode/length": 235.0, "episode/score": 0.26716513503833994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26716513503833994}
{"step": 34696, "time": 2013.8653774261475, "episode/length": 123.0, "episode/score": 0.14937499695224687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14937499695224687}
{"step": 34912, "time": 2023.9065670967102, "episode/length": 179.0, "episode/score": 0.18312420196616586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18312420196616586}
{"step": 34912, "time": 2023.915028333664, "episode/length": 187.0, "episode/score": 0.1785258554500615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785258554500615}
{"step": 35416, "time": 2046.3383586406708, "episode/length": 162.0, "episode/score": 0.17519828431750284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17519828431750284}
{"step": 35480, "time": 2050.290061712265, "episode/length": 158.0, "episode/score": 0.1497166622516488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1497166622516488}
{"step": 35784, "time": 2063.4041883945465, "episode/length": 195.0, "episode/score": 0.18791448019192103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18791448019192103}
{"step": 35984, "time": 2072.6621396541595, "episode/length": 169.0, "episode/score": 0.16320351220247176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16320351220247176}
{"step": 36072, "time": 2077.283223390579, "episode/length": 181.0, "episode/score": 0.18742628528661953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18742628528661953}
{"step": 36112, "time": 2080.6251680850983, "episode/length": 149.0, "episode/score": 0.16377208001495092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16377208001495092}
{"step": 36152, "time": 2083.483365535736, "episode/length": 154.0, "episode/score": 0.15502072259550914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15502072259550914}
{"step": 36864, "time": 2111.949014902115, "episode/length": 172.0, "episode/score": 0.19176894726524552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19176894726524552}
{"step": 36872, "time": 2113.6950027942657, "episode/length": 271.0, "episode/score": 0.2795016886548183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2795016886548183}
{"step": 36960, "time": 2118.982676744461, "episode/length": 192.0, "episode/score": 0.19741293904689883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19741293904689883}
{"step": 37176, "time": 2128.486446619034, "episode/length": 173.0, "episode/score": 0.17355482463517546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17355482463517546}
{"step": 37336, "time": 2136.798444509506, "episode/length": 157.0, "episode/score": 0.1617790233794949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1617790233794949}
{"step": 37368, "time": 2140.127706050873, "episode/length": 156.0, "episode/score": 0.18002932493345725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18002932493345725}
{"step": 37520, "time": 2148.3798608779907, "episode/length": 170.0, "episode/score": 0.18466515933778282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18466515933778282}
{"step": 37632, "time": 2154.6972308158875, "episode/length": 205.0, "episode/score": 0.20838274603784157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20838274603784157}
{"step": 38208, "time": 2178.571405172348, "episode/length": 166.0, "episode/score": 0.196775637276005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.196775637276005}
{"step": 38344, "time": 2185.559324502945, "episode/length": 172.0, "episode/score": 0.15843332224176265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15843332224176265}
{"step": 38360, "time": 2187.932785987854, "episode/length": 186.0, "episode/score": 0.20091151659289608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20091151659289608}
{"step": 38432, "time": 2192.603034257889, "episode/length": 136.0, "episode/score": 0.15831948399136309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15831948399136309}
{"step": 38552, "time": 2198.541655063629, "episode/length": 171.0, "episode/score": 0.17787382388996775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17787382388996775}
{"step": 38736, "time": 2207.408219575882, "episode/length": 170.0, "episode/score": 0.17477572903953842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17477572903953842}
{"step": 38840, "time": 2212.6228148937225, "episode/length": 164.0, "episode/score": 0.15562415830572718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15562415830572718}
{"step": 39200, "time": 2228.2625727653503, "episode/length": 104.0, "episode/score": 0.1299999972106889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1299999972106889}
{"step": 39240, "time": 2231.5435264110565, "episode/length": 200.0, "episode/score": 0.1945485770193045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1945485770193045}
{"step": 39608, "time": 2247.8060834407806, "episode/length": 157.0, "episode/score": 0.15721662690157245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15721662690157245}
{"step": 39744, "time": 2254.7774107456207, "episode/length": 163.0, "episode/score": 0.1609032347005268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1609032347005268}
{"step": 39768, "time": 2257.072675228119, "episode/length": 151.0, "episode/score": 0.16024947441655968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16024947441655968}
{"step": 39896, "time": 2263.445637702942, "episode/length": 210.0, "episode/score": 0.22360659043442865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22360659043442865}
{"step": 39904, "time": 2265.739501953125, "episode/length": 145.0, "episode/score": 0.15151841995611903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15151841995611903}
{"step": 40040, "time": 2291.4619126319885, "eval_episode/length": 150.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 40040, "time": 2293.3160626888275, "eval_episode/length": 155.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 40040, "time": 2295.67941737175, "eval_episode/length": 169.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 40040, "time": 2298.28258395195, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 40040, "time": 2298.2913012504578, "eval_episode/length": 193.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 40040, "time": 2302.239373445511, "eval_episode/length": 203.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 40040, "time": 2304.175654411316, "eval_episode/length": 210.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 40040, "time": 2307.9971311092377, "eval_episode/length": 260.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9846743295019157}
{"step": 40041, "time": 2309.058817386627, "train_stats/sum_log_reward": 1.2874999680955495, "train_stats/max_log_achievement_collect_drink": 0.30357142857142855, "train_stats/max_log_achievement_collect_sapling": 0.7142857142857143, "train_stats/max_log_achievement_collect_wood": 0.48214285714285715, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.5714285714285714, "train_stats/max_log_achievement_place_table": 0.0625, "train_stats/max_log_achievement_wake_up": 0.6785714285714286, "train_stats/mean_log_entropy": 2.5497172070401057, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.399292492475666, "train/action_min": 0.0, "train/action_std": 4.825104541465884, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003504786847472252, "train/actor_opt_grad_steps": 1795.0, "train/actor_opt_loss": 71.50904406411726, "train/adv_mag": 0.1295297550739812, "train/adv_max": 0.013667611191507245, "train/adv_mean": 0.0029424853835466743, "train/adv_min": -0.12876536062017815, "train/adv_std": 0.008494124071267968, "train/cont_avg": 0.9943647540983607, "train/cont_loss_mean": 0.005896732913406893, "train/cont_loss_std": 0.07853572736414327, "train/cont_neg_acc": 0.7121552244805899, "train/cont_neg_loss": 0.7171114468119264, "train/cont_pos_acc": 0.9996617021130734, "train/cont_pos_loss": 0.0018127366462723613, "train/cont_pred": 0.9944989050998062, "train/cont_rate": 0.9943647540983607, "train/dyn_loss_mean": 8.71118501366162, "train/dyn_loss_std": 6.2675695497481545, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16915478777201448, "train/extr_critic_critic_opt_grad_steps": 1795.0, "train/extr_critic_critic_opt_loss": 7001.034096639664, "train/extr_critic_mag": 0.14575666677756388, "train/extr_critic_max": 0.14575666677756388, "train/extr_critic_mean": 0.14472455604643117, "train/extr_critic_min": 0.13092687872589612, "train/extr_critic_std": 0.0017297096015741384, "train/extr_return_normed_mag": 0.12648646362492297, "train/extr_return_normed_max": 0.017098114688376912, "train/extr_return_normed_mean": 0.010508736414208885, "train/extr_return_normed_min": -0.1248297214385916, "train/extr_return_normed_std": 0.009315189626831257, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1542564116296221, "train/extr_return_raw_max": 0.1542564116296221, "train/extr_return_raw_mean": 0.14766704205606804, "train/extr_return_raw_min": 0.01232857550265359, "train/extr_return_raw_std": 0.00931518972225365, "train/extr_reward_mag": 0.0015154168254039326, "train/extr_reward_max": 0.0015154168254039326, "train/extr_reward_mean": 0.0010345910249285584, "train/extr_reward_min": 0.0001672789698741475, "train/extr_reward_std": 0.0002072246355905396, "train/image_loss_mean": 29.738352462893626, "train/image_loss_std": 23.71261968769011, "train/model_loss_mean": 35.00793664963519, "train/model_loss_std": 25.69616536625096, "train/model_opt_grad_norm": 141.57038225893115, "train/model_opt_grad_steps": 1786.0, "train/model_opt_loss": 1765.9707086281699, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 51.54969262295082, "train/policy_entropy_mag": 2.809230710639328, "train/policy_entropy_max": 2.809230710639328, "train/policy_entropy_mean": 2.555201102475651, "train/policy_entropy_min": 1.715907251004313, "train/policy_entropy_std": 0.1510618729364188, "train/policy_logprob_mag": 6.642069339752197, "train/policy_logprob_max": -0.6612701590066073, "train/policy_logprob_mean": -2.554679008780933, "train/policy_logprob_min": -6.642069339752197, "train/policy_logprob_std": 0.7195082314190318, "train/policy_randomness_mag": 0.991535160873757, "train/policy_randomness_max": 0.991535160873757, "train/policy_randomness_mean": 0.9018738489659106, "train/policy_randomness_min": 0.605639960250405, "train/policy_randomness_std": 0.05331821174773037, "train/post_ent_mag": 46.58106791386839, "train/post_ent_max": 46.58106791386839, "train/post_ent_mean": 30.538508852974314, "train/post_ent_min": 12.757072167318375, "train/post_ent_std": 5.571515059861981, "train/prior_ent_mag": 57.11706858775655, "train/prior_ent_max": 57.11706858775655, "train/prior_ent_mean": 39.67208759120253, "train/prior_ent_min": 16.530977170975483, "train/prior_ent_std": 7.56117793380237, "train/rep_loss_mean": 8.71118501366162, "train/rep_loss_std": 6.2675695497481545, "train/reward_avg": 0.0009459832937983399, "train/reward_loss_mean": 0.03697636836498487, "train/reward_loss_std": 0.014082566384592505, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013936484446291065, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03697636857873104, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0009434905616932961, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.2875000042840838, "eval_stats/max_log_achievement_collect_drink": 0.25, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0002669117820914835, "report/cont_loss_std": 0.0046584028750658035, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00785752385854721, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00022217338846530765, "report/cont_pred": 0.9939753413200378, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.62662124633789, "report/dyn_loss_std": 6.331610202789307, "report/image_loss_mean": 24.853511810302734, "report/image_loss_std": 18.96442413330078, "report/model_loss_mean": 31.269020080566406, "report/model_loss_std": 21.209941864013672, "report/post_ent_mag": 45.21038055419922, "report/post_ent_max": 45.21038055419922, "report/post_ent_mean": 32.56005859375, "report/post_ent_min": 16.81547737121582, "report/post_ent_std": 4.48718786239624, "report/prior_ent_mag": 55.933773040771484, "report/prior_ent_max": 55.933773040771484, "report/prior_ent_mean": 43.24074935913086, "report/prior_ent_min": 18.481094360351562, "report/prior_ent_std": 6.309659004211426, "report/rep_loss_mean": 10.62662124633789, "report/rep_loss_std": 6.331610202789307, "report/reward_avg": 0.0010233540087938309, "report/reward_loss_mean": 0.03926747292280197, "report/reward_loss_std": 0.01171750109642744, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0014100074768066406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03926747292280197, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010241357376798987, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 4.62683237856254e-06, "eval/cont_loss_std": 6.388089968822896e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001997532555833459, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.6787326987687266e-06, "eval/cont_pred": 0.9990227222442627, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 11.37149429321289, "eval/dyn_loss_std": 6.574282646179199, "eval/image_loss_mean": 44.28984069824219, "eval/image_loss_std": 53.058170318603516, "eval/model_loss_mean": 51.50239944458008, "eval/model_loss_std": 54.901771545410156, "eval/post_ent_mag": 46.5134391784668, "eval/post_ent_max": 46.5134391784668, "eval/post_ent_mean": 32.35612487792969, "eval/post_ent_min": 15.330099105834961, "eval/post_ent_std": 6.72291898727417, "eval/prior_ent_mag": 57.962890625, "eval/prior_ent_max": 57.962890625, "eval/prior_ent_mean": 41.05906677246094, "eval/prior_ent_min": 17.175785064697266, "eval/prior_ent_std": 9.866456985473633, "eval/rep_loss_mean": 11.37149429321289, "eval/rep_loss_std": 6.574282646179199, "eval/reward_avg": 0.01318359375, "eval/reward_loss_mean": 0.38965678215026855, "eval/reward_loss_std": 2.252037525177002, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0015774965286254883, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.17810213565826416, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.717599868774414, "eval/reward_pred": 0.0009389669867232442, "eval/reward_rate": 0.015625, "replay/size": 39537.0, "replay/inserts": 19608.0, "replay/samples": 19616.0, "replay/insert_wait_avg": 1.4164189035578292e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0263691329644904e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 11216.0, "eval_replay/inserts": 4072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2386407271349594e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1009.5219504833221, "timer/env.step_count": 2451.0, "timer/env.step_total": 260.0405397415161, "timer/env.step_frac": 0.25758780145099197, "timer/env.step_avg": 0.10609569144900698, "timer/env.step_min": 0.0239565372467041, "timer/env.step_max": 3.5863728523254395, "timer/replay._sample_count": 19616.0, "timer/replay._sample_total": 9.906946897506714, "timer/replay._sample_frac": 0.009813503205912096, "timer/replay._sample_avg": 0.0005050441933883928, "timer/replay._sample_min": 0.0003590583801269531, "timer/replay._sample_max": 0.026953697204589844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2960.0, "timer/agent.policy_total": 49.85143280029297, "timer/agent.policy_frac": 0.04938122720008805, "timer/agent.policy_avg": 0.016841700270369245, "timer/agent.policy_min": 0.009539365768432617, "timer/agent.policy_max": 0.12230324745178223, "timer/dataset_train_count": 1226.0, "timer/dataset_train_total": 0.13988184928894043, "timer/dataset_train_frac": 0.0001385624643644154, "timer/dataset_train_avg": 0.00011409612503176218, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.00030684471130371094, "timer/agent.train_count": 1226.0, "timer/agent.train_total": 552.5022621154785, "timer/agent.train_frac": 0.5472909844614678, "timer/agent.train_avg": 0.45065437366678507, "timer/agent.train_min": 0.4365420341491699, "timer/agent.train_max": 0.8696467876434326, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775550365447998, "timer/agent.report_frac": 0.0004730506714749134, "timer/agent.report_avg": 0.2387775182723999, "timer/agent.report_min": 0.23266983032226562, "timer/agent.report_max": 0.24488520622253418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.5425467319568896e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 19.422802983776467}
{"step": 40152, "time": 2313.1577229499817, "episode/length": 163.0, "episode/score": 0.15514457963217865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15514457963217865}
{"step": 40352, "time": 2322.4076199531555, "episode/length": 143.0, "episode/score": 0.16051613345371152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16051613345371152}
{"step": 40856, "time": 2342.702880859375, "episode/length": 201.0, "episode/score": 0.2270332792722911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2270332792722911}
{"step": 40856, "time": 2342.712549686432, "episode/length": 155.0, "episode/score": 0.16308301335811848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16308301335811848}
{"step": 40960, "time": 2350.424245119095, "episode/length": 151.0, "episode/score": 0.15960611323589546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15960611323589546}
{"step": 41144, "time": 2360.1087806224823, "episode/length": 154.0, "episode/score": 0.17057162694709405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17057162694709405}
{"step": 41232, "time": 2365.2156863212585, "episode/length": 182.0, "episode/score": 0.19198258210235508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19198258210235508}
{"step": 41400, "time": 2372.892480134964, "episode/length": 187.0, "episode/score": 0.2058916362175296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2058916362175296}
{"step": 41424, "time": 2375.5043139457703, "episode/length": 158.0, "episode/score": 0.15920765899136313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15920765899136313}
{"step": 41872, "time": 2394.1190514564514, "episode/length": 189.0, "episode/score": 0.1832529508137668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832529508137668}
{"step": 42320, "time": 2413.089716911316, "episode/length": 169.0, "episode/score": 0.16770072292183613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16770072292183613}
{"step": 42472, "time": 2420.3430092334747, "episode/length": 201.0, "episode/score": 0.20607062409271748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20607062409271748}
{"step": 42528, "time": 2424.307995080948, "episode/length": 161.0, "episode/score": 0.18277313102589687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18277313102589687}
{"step": 42720, "time": 2433.938525915146, "episode/length": 196.0, "episode/score": 0.18734258146650973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18734258146650973}
{"step": 42800, "time": 2438.9745857715607, "episode/length": 171.0, "episode/score": 0.18787735786918347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18787735786918347}
{"step": 42840, "time": 2442.3899433612823, "episode/length": 64.0, "episode/score": 0.07091666565975174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07091666565975174}
{"step": 43056, "time": 2453.1116483211517, "episode/length": 206.0, "episode/score": 0.24191520975455205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24191520975455205}
{"step": 43216, "time": 2461.1999773979187, "episode/length": 46.0, "episode/score": 0.05148766758793499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05148766758793499}
{"step": 43288, "time": 2465.4203610420227, "episode/length": 176.0, "episode/score": 0.17454766071659833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17454766071659833}
{"step": 43312, "time": 2468.166003227234, "episode/length": 306.0, "episode/score": 0.3516486035041453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3516486035041453}
{"step": 43664, "time": 2483.6689808368683, "episode/length": 148.0, "episode/score": 0.15813518639788526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15813518639788526}
{"step": 43680, "time": 2485.78173494339, "episode/length": 77.0, "episode/score": 0.07460234760492312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07460234760492312}
{"step": 43872, "time": 2494.7393786907196, "episode/length": 167.0, "episode/score": 0.18796220394506236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18796220394506236}
{"step": 44160, "time": 2507.2202186584473, "episode/length": 108.0, "episode/score": 0.122455841131341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.122455841131341}
{"step": 44200, "time": 2510.1922295093536, "episode/length": 174.0, "episode/score": 0.17174046467334847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17174046467334847}
{"step": 44624, "time": 2528.0342750549316, "episode/length": 175.0, "episode/score": 0.18855187010831287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18855187010831287}
{"step": 44936, "time": 2541.404101371765, "episode/length": 276.0, "episode/score": 0.2658055234260246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2658055234260246}
{"step": 45040, "time": 2547.1056628227234, "episode/length": 171.0, "episode/score": 0.18068155582341205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18068155582341205}
{"step": 45176, "time": 2553.7552626132965, "episode/length": 162.0, "episode/score": 0.1715363277439792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1715363277439792}
{"step": 45200, "time": 2556.4609310626984, "episode/length": 189.0, "episode/score": 0.20385642676183124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20385642676183124}
{"step": 45376, "time": 2564.8151409626007, "episode/length": 257.0, "episode/score": 0.2656089969864297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2656089969864297}
{"step": 45416, "time": 2567.7712004184723, "episode/length": 156.0, "episode/score": 0.15644023909408133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15644023909408133}
{"step": 45744, "time": 2581.991545677185, "episode/length": 192.0, "episode/score": 0.21788852441386553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21788852441386553}
{"step": 45800, "time": 2586.067651748657, "episode/length": 74.0, "episode/score": 0.09133333148201928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09133333148201928}
{"step": 46120, "time": 2600.447510242462, "episode/length": 186.0, "episode/score": 0.19328306497482117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19328306497482117}
{"step": 46152, "time": 2603.3293223381042, "episode/length": 138.0, "episode/score": 0.15441003271916998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15441003271916998}
{"step": 46592, "time": 2621.6582205295563, "episode/length": 176.0, "episode/score": 0.19922225189657183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19922225189657183}
{"step": 46720, "time": 2628.0518083572388, "episode/length": 222.0, "episode/score": 0.24997769931724179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24997769931724179}
{"step": 46760, "time": 2630.8679614067078, "episode/length": 167.0, "episode/score": 0.17978255169145996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17978255169145996}
{"step": 46984, "time": 2640.982228755951, "episode/length": 200.0, "episode/score": 0.20354080225297366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20354080225297366}
{"step": 46984, "time": 2640.9898405075073, "episode/length": 147.0, "episode/score": 0.1256760481683159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1256760481683159}
{"step": 47376, "time": 2659.522964477539, "episode/length": 203.0, "episode/score": 0.19977455630396435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19977455630396435}
{"step": 47576, "time": 2668.642115831375, "episode/length": 73.0, "episode/score": 0.07572011933007161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07572011933007161}
{"step": 47624, "time": 2672.0962533950806, "episode/length": 183.0, "episode/score": 0.18555434593326936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18555434593326936}
{"step": 47928, "time": 2685.3113312721252, "episode/length": 225.0, "episode/score": 0.25001967592652363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25001967592652363}
{"step": 48128, "time": 2694.8030865192413, "episode/length": 191.0, "episode/score": 0.1973217582599318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1973217582599318}
{"step": 48320, "time": 2704.1273941993713, "episode/length": 194.0, "episode/score": 0.21087048060508096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21087048060508096}
{"step": 48688, "time": 2719.837979078293, "episode/length": 245.0, "episode/score": 0.26081365179379645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26081365179379645}
{"step": 48720, "time": 2722.6583325862885, "episode/length": 216.0, "episode/score": 0.23814165406110988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23814165406110988}
{"step": 48840, "time": 2728.6014635562897, "episode/length": 151.0, "episode/score": 0.15235240658967086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15235240658967086}
{"step": 49232, "time": 2746.862607240677, "episode/length": 231.0, "episode/score": 0.2623914803880325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2623914803880325}
{"step": 49328, "time": 2752.1789157390594, "episode/length": 218.0, "episode/score": 0.2211617867296809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2211617867296809}
{"step": 49440, "time": 2758.12504863739, "episode/length": 163.0, "episode/score": 0.1651911516846667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1651911516846667}
{"step": 49808, "time": 2773.6524198055267, "episode/length": 234.0, "episode/score": 0.25669410896716727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25669410896716727}
{"step": 50016, "time": 2783.3915724754333, "episode/length": 211.0, "episode/score": 0.23267108290110627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23267108290110627}
{"step": 50024, "time": 2804.967324256897, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 50024, "time": 2807.042851448059, "eval_episode/length": 163.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 50024, "time": 2808.9856717586517, "eval_episode/length": 170.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 50024, "time": 2810.8984014987946, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 50024, "time": 2812.683124065399, "eval_episode/length": 179.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 50024, "time": 2815.425459623337, "eval_episode/length": 53.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9074074074074074}
{"step": 50024, "time": 2817.1719257831573, "eval_episode/length": 208.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 50024, "time": 2818.876075029373, "eval_episode/length": 211.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 50136, "time": 2823.1213808059692, "episode/length": 40.0, "episode/score": 0.045916665985714644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045916665985714644}
{"step": 50160, "time": 2825.835974216461, "episode/length": 179.0, "episode/score": 0.19746924454375403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19746924454375403}
{"step": 50376, "time": 2835.6991848945618, "episode/length": 210.0, "episode/score": 0.21216872085551586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21216872085551586}
{"step": 50432, "time": 2840.140944957733, "episode/length": 198.0, "episode/score": 0.20787742792163044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20787742792163044}
{"step": 50640, "time": 2849.6708211898804, "episode/length": 175.0, "episode/score": 0.20544980024897086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20544980024897086}
{"step": 50720, "time": 2854.408993959427, "episode/length": 173.0, "episode/score": 0.16297087453222048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16297087453222048}
{"step": 50736, "time": 2856.7450909614563, "episode/length": 161.0, "episode/score": 0.166553243452654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166553243452654}
{"step": 51192, "time": 2875.603353738785, "episode/length": 101.0, "episode/score": 0.12282342406979296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12282342406979296}
{"step": 51248, "time": 2879.5694386959076, "episode/length": 153.0, "episode/score": 0.1739502412674483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1739502412674483}
{"step": 51752, "time": 2900.276109933853, "episode/length": 198.0, "episode/score": 0.22484188931048266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22484188931048266}
{"step": 51864, "time": 2906.1756529808044, "episode/length": 142.0, "episode/score": 0.1301602482526505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1301602482526505}
{"step": 52128, "time": 2918.049055337906, "episode/length": 116.0, "episode/score": 0.13291024680802366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13291024680802366}
{"step": 52168, "time": 2920.9165279865265, "episode/length": 216.0, "episode/score": 0.2289839232180384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2289839232180384}
{"step": 52200, "time": 2923.763567686081, "episode/length": 257.0, "episode/score": 0.27861784189008176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27861784189008176}
{"step": 52448, "time": 2935.1438205242157, "episode/length": 213.0, "episode/score": 0.23135620962420944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23135620962420944}
{"step": 52584, "time": 2941.5229530334473, "episode/length": 166.0, "episode/score": 0.1768300892545085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768300892545085}
{"step": 52776, "time": 2950.4762890338898, "episode/length": 266.0, "episode/score": 0.2936795519453881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2936795519453881}
{"step": 53160, "time": 2967.665990829468, "episode/length": 175.0, "episode/score": 0.1834284728483908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1834284728483908}
{"step": 53376, "time": 2978.258344888687, "episode/length": 146.0, "episode/score": 0.17200297288945876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17200297288945876}
{"step": 53448, "time": 2982.7457010746, "episode/length": 124.0, "episode/score": 0.140467421260837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.140467421260837}
{"step": 53456, "time": 2984.949113368988, "episode/length": 165.0, "episode/score": 0.15556339870818192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15556339870818192}
{"step": 53576, "time": 2990.804582834244, "episode/length": 175.0, "episode/score": 0.19846536578188534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19846536578188534}
{"step": 53640, "time": 2994.823150396347, "episode/length": 221.0, "episode/score": 0.23872375005339563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23872375005339563}
{"step": 53720, "time": 2999.386900663376, "episode/length": 32.0, "episode/score": 0.03127647218570928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03127647218570928}
{"step": 54080, "time": 3014.6835210323334, "episode/length": 186.0, "episode/score": 0.20313766231265618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20313766231265618}
{"step": 54184, "time": 3019.9875819683075, "episode/length": 175.0, "episode/score": 0.17156282189534977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17156282189534977}
{"step": 54768, "time": 3043.7955718040466, "episode/length": 200.0, "episode/score": 0.19601649078504124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19601649078504124}
{"step": 55128, "time": 3059.008315563202, "episode/length": 175.0, "episode/score": 0.19063631021435867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19063631021435867}
{"step": 55136, "time": 3061.138848543167, "episode/length": 210.0, "episode/score": 0.2150794186636631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2150794186636631}
{"step": 55160, "time": 3063.526843070984, "episode/length": 189.0, "episode/score": 0.21005390985374106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21005390985374106}
{"step": 55376, "time": 3073.5429792404175, "episode/length": 148.0, "episode/score": 0.146037390985839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.146037390985839}
{"step": 55712, "time": 3088.1143283843994, "episode/length": 291.0, "episode/score": 0.2979668862426479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2979668862426479}
{"step": 55936, "time": 3098.1693394184113, "episode/length": 231.0, "episode/score": 0.23584235663656727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23584235663656727}
{"step": 56048, "time": 3103.9831080436707, "episode/length": 308.0, "episode/score": 0.3557460281372187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3557460281372187}
{"step": 56360, "time": 3117.1598160266876, "episode/length": 152.0, "episode/score": 0.15708916170024168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15708916170024168}
{"step": 56464, "time": 3122.8050339221954, "episode/length": 162.0, "episode/score": 0.1826547513346668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1826547513346668}
{"step": 56632, "time": 3130.5267763137817, "episode/length": 187.0, "episode/score": 0.19311323337115027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19311323337115027}
{"step": 56888, "time": 3141.8157958984375, "episode/length": 188.0, "episode/score": 0.19919608483996853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19919608483996853}
{"step": 57200, "time": 3155.5610008239746, "episode/length": 104.0, "episode/score": 0.1285523476317394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1285523476317394}
{"step": 57312, "time": 3161.398940563202, "episode/length": 157.0, "episode/score": 0.17762867681813077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17762867681813077}
{"step": 57344, "time": 3164.607672214508, "episode/length": 203.0, "episode/score": 0.2376514655570645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2376514655570645}
{"step": 57496, "time": 3173.0497579574585, "episode/length": 194.0, "episode/score": 0.20187871908456145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20187871908456145}
{"step": 57984, "time": 3193.4372911453247, "episode/length": 168.0, "episode/score": 0.1766844537705765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1766844537705765}
{"step": 57992, "time": 3195.2699460983276, "episode/length": 402.0, "episode/score": 0.4204989241225121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4204989241225121}
{"step": 58072, "time": 3199.940500974655, "episode/length": 200.0, "episode/score": 0.2188868285747958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2188868285747958}
{"step": 58648, "time": 3223.3224387168884, "episode/length": 166.0, "episode/score": 0.18167487394748605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18167487394748605}
{"step": 58712, "time": 3227.3829231262207, "episode/length": 151.0, "episode/score": 0.15730953122329083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15730953122329083}
{"step": 58888, "time": 3235.614228248596, "episode/length": 249.0, "episode/score": 0.2836360519504524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2836360519504524}
{"step": 59024, "time": 3242.5750658512115, "episode/length": 227.0, "episode/score": 0.252402584956144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.252402584956144}
{"step": 59072, "time": 3245.9771921634674, "episode/length": 215.0, "episode/score": 0.2328022273577517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2328022273577517}
{"step": 59104, "time": 3248.6943430900574, "episode/length": 138.0, "episode/score": 0.1548783604739583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1548783604739583}
{"step": 59264, "time": 3256.5049822330475, "episode/length": 159.0, "episode/score": 0.1675128229053371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1675128229053371}
{"step": 59768, "time": 3276.7453846931458, "episode/length": 211.0, "episode/score": 0.2399057602560788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2399057602560788}
{"step": 60008, "time": 3312.4823122024536, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.958904109589041}
{"step": 60008, "time": 3315.169365167618, "eval_episode/length": 154.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.967741935483871}
{"step": 60008, "time": 3317.335653066635, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 60008, "time": 3319.36083650589, "eval_episode/length": 157.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 60008, "time": 3319.3675351142883, "eval_episode/length": 157.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 60008, "time": 3323.863716363907, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 60008, "time": 3326.2462418079376, "eval_episode/length": 204.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 60008, "time": 3329.5185074806213, "eval_episode/length": 242.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9876543209876543}
{"step": 60009, "time": 3330.5801305770874, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.009740234375, "train/action_min": 0.0, "train/action_std": 4.864167217254638, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003586790935136378, "train/actor_opt_grad_steps": 3030.0, "train/actor_opt_loss": 23.414241705179215, "train/adv_mag": 0.1569675575494766, "train/adv_max": 0.04534002721309662, "train/adv_mean": 0.0009976339302083944, "train/adv_min": -0.1567586032152176, "train/adv_std": 0.010072992373257875, "train/cont_avg": 0.994125, "train/cont_loss_mean": 0.0010386249876482908, "train/cont_loss_std": 0.02641516974903061, "train/cont_neg_acc": 0.969475905418396, "train/cont_neg_loss": 0.09388823780085659, "train/cont_pos_acc": 0.9998350467681885, "train/cont_pos_loss": 0.0005139212908397894, "train/cont_pred": 0.994062132358551, "train/cont_rate": 0.994125, "train/dyn_loss_mean": 11.130333923339844, "train/dyn_loss_std": 6.574892074584961, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17926482546329497, "train/extr_critic_critic_opt_grad_steps": 3030.0, "train/extr_critic_critic_opt_loss": 6896.71115234375, "train/extr_critic_mag": 0.2063078727722168, "train/extr_critic_max": 0.2063078727722168, "train/extr_critic_mean": 0.18791672933101655, "train/extr_critic_min": 0.0952471399307251, "train/extr_critic_std": 0.0172056570565328, "train/extr_return_normed_mag": 0.15096221804618837, "train/extr_return_normed_max": 0.0549772857427597, "train/extr_return_normed_mean": 0.035713783159852026, "train/extr_return_normed_min": -0.15089065599441528, "train/extr_return_normed_std": 0.02209362491592765, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2081778482198715, "train/extr_return_raw_max": 0.2081778482198715, "train/extr_return_raw_mean": 0.18891435420513153, "train/extr_return_raw_min": 0.0023099064826965334, "train/extr_return_raw_std": 0.02209362481161952, "train/extr_reward_mag": 0.0014951505661010742, "train/extr_reward_max": 0.0014951505661010742, "train/extr_reward_mean": 0.001058475485537201, "train/extr_reward_min": 2.9153823852539063e-05, "train/extr_reward_std": 0.0002441893139621243, "train/image_loss_mean": 23.689116767883302, "train/image_loss_std": 19.9297914352417, "train/model_loss_mean": 30.406160018920897, "train/model_loss_std": 22.264490051269533, "train/model_opt_grad_norm": 118.38149334716798, "train/model_opt_grad_steps": 3021.0, "train/model_opt_loss": 3540.9870263671874, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 118.125, "train/policy_entropy_mag": 2.8100110721588134, "train/policy_entropy_max": 2.8100110721588134, "train/policy_entropy_mean": 2.3756842155456543, "train/policy_entropy_min": 0.20728890734910965, "train/policy_entropy_std": 0.4776325215101242, "train/policy_logprob_mag": 7.158376884460449, "train/policy_logprob_max": -0.031851519048213955, "train/policy_logprob_mean": -2.3767093315124512, "train/policy_logprob_min": -7.158376884460449, "train/policy_logprob_std": 0.9641981735229492, "train/policy_randomness_mag": 0.9918105945587158, "train/policy_randomness_max": 0.9918105945587158, "train/policy_randomness_mean": 0.8385122737884522, "train/policy_randomness_min": 0.07316388764977455, "train/policy_randomness_std": 0.1685833202600479, "train/post_ent_mag": 45.11442047119141, "train/post_ent_max": 45.11442047119141, "train/post_ent_mean": 32.10842887878418, "train/post_ent_min": 15.207081001281738, "train/post_ent_std": 5.007845245361328, "train/prior_ent_mag": 56.686414337158205, "train/prior_ent_max": 56.686414337158205, "train/prior_ent_mean": 43.62405642700195, "train/prior_ent_min": 18.567344451904297, "train/prior_ent_std": 6.92825997543335, "train/rep_loss_mean": 11.130333923339844, "train/rep_loss_std": 6.574892074584961, "train/reward_avg": 0.0009857369414530694, "train/reward_loss_mean": 0.03780409714579582, "train/reward_loss_std": 0.013449447490274906, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0014306373596191407, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0378040971159935, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00098966452665627, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.9425925588994114, "train_stats/max_log_achievement_collect_drink": 0.5925925925925926, "train_stats/max_log_achievement_collect_sapling": 0.7037037037037037, "train_stats/max_log_achievement_collect_wood": 0.6851851851851852, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018518518518518517, "train_stats/max_log_achievement_make_wood_sword": 0.009259259259259259, "train_stats/max_log_achievement_place_plant": 0.5185185185185185, "train_stats/max_log_achievement_place_table": 0.08333333333333333, "train_stats/max_log_achievement_wake_up": 0.14814814814814814, "train_stats/mean_log_entropy": 2.3760816333470522, "eval_stats/sum_log_reward": 0.9749999567866325, "eval_stats/max_log_achievement_collect_drink": 0.3125, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.8125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 0.00048129603965207934, "report/cont_loss_std": 0.01444218773394823, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0023057053331285715, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00046148509136401117, "report/cont_pred": 0.9889156818389893, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 12.668333053588867, "report/dyn_loss_std": 5.990760326385498, "report/image_loss_mean": 25.209274291992188, "report/image_loss_std": 16.90373992919922, "report/model_loss_mean": 32.85224151611328, "report/model_loss_std": 18.83831787109375, "report/post_ent_mag": 43.45736312866211, "report/post_ent_max": 43.45736312866211, "report/post_ent_mean": 32.84144592285156, "report/post_ent_min": 17.66338348388672, "report/post_ent_std": 4.497013568878174, "report/prior_ent_mag": 57.514217376708984, "report/prior_ent_max": 57.514217376708984, "report/prior_ent_mean": 46.34199523925781, "report/prior_ent_min": 22.006250381469727, "report/prior_ent_std": 5.576052665710449, "report/rep_loss_mean": 12.668333053588867, "report/rep_loss_std": 5.990760326385498, "report/reward_avg": 0.0010978293139487505, "report/reward_loss_mean": 0.04148472845554352, "report/reward_loss_std": 0.010318557731807232, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0014435052871704102, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04148472845554352, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00111959979403764, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.0096818186866585e-05, "eval/cont_loss_std": 0.00026087110745720565, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0030660824850201607, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1174286100867903e-06, "eval/cont_pred": 0.9970782399177551, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 12.59434700012207, "eval/dyn_loss_std": 7.099547386169434, "eval/image_loss_mean": 26.8358154296875, "eval/image_loss_std": 34.81214904785156, "eval/model_loss_mean": 34.828765869140625, "eval/model_loss_std": 37.184783935546875, "eval/post_ent_mag": 45.88718795776367, "eval/post_ent_max": 45.88718795776367, "eval/post_ent_mean": 32.22118377685547, "eval/post_ent_min": 14.382102012634277, "eval/post_ent_std": 5.584369659423828, "eval/prior_ent_mag": 57.91486358642578, "eval/prior_ent_max": 57.91486358642578, "eval/prior_ent_mean": 43.471961975097656, "eval/prior_ent_min": 20.939605712890625, "eval/prior_ent_std": 7.842681884765625, "eval/rep_loss_mean": 12.59434700012207, "eval/rep_loss_std": 7.099547386169434, "eval/reward_avg": 0.00957031175494194, "eval/reward_loss_mean": 0.4363335967063904, "eval/reward_loss_std": 2.437485933303833, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0014688968658447266, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.25344571471214294, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.659381866455078, "eval/reward_pred": 0.0009718240471556783, "eval/reward_rate": 0.0126953125, "replay/size": 59505.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.4563616460714584e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0153326468589978e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14856.0, "eval_replay/inserts": 3640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.269709932935107e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1021.5028076171875, "timer/env.step_count": 2496.0, "timer/env.step_total": 252.45050477981567, "timer/env.step_frac": 0.24713637877187566, "timer/env.step_avg": 0.10114202915857999, "timer/env.step_min": 0.023811817169189453, "timer/env.step_max": 3.452932834625244, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 10.36349892616272, "timer/replay._sample_frac": 0.010145345513378642, "timer/replay._sample_avg": 0.0005190053548759375, "timer/replay._sample_min": 0.0003616809844970703, "timer/replay._sample_max": 0.026118993759155273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2951.0, "timer/agent.policy_total": 49.81113386154175, "timer/agent.policy_frac": 0.04876260103262357, "timer/agent.policy_avg": 0.01687940828923814, "timer/agent.policy_min": 0.009942293167114258, "timer/agent.policy_max": 0.09380531311035156, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14287710189819336, "timer/dataset_train_frac": 0.0001398695146335194, "timer/dataset_train_avg": 0.00011448485729021904, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0005195140838623047, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 564.50111079216, "timer/agent.train_frac": 0.5526182665214066, "timer/agent.train_avg": 0.4523246080065385, "timer/agent.train_min": 0.438274621963501, "timer/agent.train_max": 1.0463621616363525, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754645824432373, "timer/agent.report_frac": 0.00046545597221835507, "timer/agent.report_avg": 0.23773229122161865, "timer/agent.report_min": 0.22930359840393066, "timer/agent.report_max": 0.24616098403930664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.290937567928686e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 19.547419529040912}
{"step": 60048, "time": 3332.1045463085175, "episode/length": 166.0, "episode/score": 0.18153339646778477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18153339646778477}
{"step": 60080, "time": 3334.925063610077, "episode/length": 178.0, "episode/score": 0.20082356853527017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20082356853527017}
{"step": 60192, "time": 3340.7894082069397, "episode/length": 162.0, "episode/score": 0.15953346800233703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15953346800233703}
{"step": 60360, "time": 3348.8304228782654, "episode/length": 160.0, "episode/score": 0.15824619027625886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15824619027625886}
{"step": 60496, "time": 3356.362854719162, "episode/length": 173.0, "episode/score": 0.17835855641533271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17835855641533271}
{"step": 60608, "time": 3362.1787343025208, "episode/length": 167.0, "episode/score": 0.19083915881310531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19083915881310531}
{"step": 61008, "time": 3378.927266359329, "episode/length": 63.0, "episode/score": 0.07042490281583014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07042490281583014}
{"step": 61056, "time": 3382.467669725418, "episode/length": 253.0, "episode/score": 0.28781379930842377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28781379930842377}
{"step": 61088, "time": 3385.4314234256744, "episode/length": 164.0, "episode/score": 0.18574926288238203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18574926288238203}
{"step": 61456, "time": 3400.9480373859406, "episode/length": 136.0, "episode/score": 0.13357693697889772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13357693697889772}
{"step": 61496, "time": 3403.9852962493896, "episode/length": 176.0, "episode/score": 0.15650980296231864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15650980296231864}
{"step": 61568, "time": 3408.6263914108276, "episode/length": 189.0, "episode/score": 0.21361742355475144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21361742355475144}
{"step": 61632, "time": 3412.6069571971893, "episode/length": 179.0, "episode/score": 0.21032188765911997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21032188765911997}
{"step": 62352, "time": 3441.6231412887573, "episode/length": 167.0, "episode/score": 0.1908060224923247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1908060224923247}
{"step": 62368, "time": 3443.73872423172, "episode/length": 163.0, "episode/score": 0.19676308510770468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19676308510770468}
{"step": 62392, "time": 3445.9078896045685, "episode/length": 162.0, "episode/score": 0.1731319548935062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731319548935062}
{"step": 62760, "time": 3461.4331188201904, "episode/length": 148.0, "episode/score": 0.16809214680870355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16809214680870355}
{"step": 62760, "time": 3461.440681695938, "episode/length": 157.0, "episode/score": 0.17434096748456795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17434096748456795}
{"step": 62960, "time": 3472.6026034355164, "episode/length": 165.0, "episode/score": 0.17117174431950843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17117174431950843}
{"step": 63128, "time": 3480.3817553520203, "episode/length": 208.0, "episode/score": 0.22663392067806853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22663392067806853}
{"step": 63168, "time": 3483.7734820842743, "episode/length": 319.0, "episode/score": 0.34487708036522235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34487708036522235}
{"step": 63432, "time": 3495.0828907489777, "episode/length": 58.0, "episode/score": 0.055542148773383815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055542148773383815}
{"step": 63696, "time": 3506.9141170978546, "episode/length": 116.0, "episode/score": 0.13635403549960756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13635403549960756}
{"step": 63776, "time": 3511.5603029727936, "episode/length": 172.0, "episode/score": 0.18406897004570055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18406897004570055}
{"step": 63880, "time": 3516.8904638290405, "episode/length": 190.0, "episode/score": 0.19374355985382863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19374355985382863}
{"step": 64192, "time": 3530.606961250305, "episode/length": 227.0, "episode/score": 0.25946080714038544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25946080714038544}
{"step": 64312, "time": 3536.4161026477814, "episode/length": 193.0, "episode/score": 0.20811217362188472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20811217362188472}
{"step": 64560, "time": 3547.8110699653625, "episode/length": 178.0, "episode/score": 0.20901628655064997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20901628655064997}
{"step": 64640, "time": 3552.5244607925415, "episode/length": 183.0, "episode/score": 0.19364093106196378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19364093106196378}
{"step": 64856, "time": 3562.906349658966, "episode/length": 177.0, "episode/score": 0.19331852620234713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19331852620234713}
{"step": 64920, "time": 3566.969249725342, "episode/length": 142.0, "episode/score": 0.12839859793439246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12839859793439246}
{"step": 65168, "time": 3578.2050981521606, "episode/length": 183.0, "episode/score": 0.19497066662461293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19497066662461293}
{"step": 65320, "time": 3585.3915932178497, "episode/length": 179.0, "episode/score": 0.1875743545106161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1875743545106161}
{"step": 65400, "time": 3590.0081930160522, "episode/length": 150.0, "episode/score": 0.17130915213601838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17130915213601838}
{"step": 65832, "time": 3609.0808987617493, "episode/length": 189.0, "episode/score": 0.2116993570507475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2116993570507475}
{"step": 65952, "time": 3615.533195734024, "episode/length": 173.0, "episode/score": 0.16957970106705034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16957970106705034}
{"step": 66104, "time": 3622.7104682922363, "episode/length": 182.0, "episode/score": 0.18722364903533162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18722364903533162}
{"step": 66256, "time": 3630.889418363571, "episode/length": 166.0, "episode/score": 0.1706347221975193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706347221975193}
{"step": 66416, "time": 3638.6183190345764, "episode/length": 155.0, "episode/score": 0.161331440984668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.161331440984668}
{"step": 66496, "time": 3643.2936465740204, "episode/length": 204.0, "episode/score": 0.22925902756924188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22925902756924188}
{"step": 66536, "time": 3646.4716494083405, "episode/length": 151.0, "episode/score": 0.15962049521340305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15962049521340305}
{"step": 67048, "time": 3667.339597225189, "episode/length": 205.0, "episode/score": 0.2060596329092732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2060596329092732}
{"step": 67136, "time": 3672.4594519138336, "episode/length": 162.0, "episode/score": 0.15808054831632035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15808054831632035}
{"step": 67232, "time": 3677.7412526607513, "episode/length": 140.0, "episode/score": 0.15230151814648707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15230151814648707}
{"step": 67640, "time": 3694.4669754505157, "episode/length": 210.0, "episode/score": 0.23513668757141204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23513668757141204}
{"step": 67704, "time": 3698.570333957672, "episode/length": 160.0, "episode/score": 0.17388325732326848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17388325732326848}
{"step": 67816, "time": 3704.456727743149, "episode/length": 159.0, "episode/score": 0.1470939163368712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1470939163368712}
{"step": 67888, "time": 3709.012786626816, "episode/length": 173.0, "episode/score": 0.18770476226973187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18770476226973187}
{"step": 68632, "time": 3738.633401155472, "episode/length": 186.0, "episode/score": 0.18569214014678437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18569214014678437}
{"step": 68840, "time": 3748.1126000881195, "episode/length": 322.0, "episode/score": 0.31709944667181844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31709944667181844}
{"step": 68872, "time": 3750.9812722206116, "episode/length": 153.0, "episode/score": 0.14383971540200946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14383971540200946}
{"step": 69016, "time": 3758.0797157287598, "episode/length": 140.0, "episode/score": 0.1666904730082024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1666904730082024}
{"step": 69128, "time": 3763.901447534561, "episode/length": 236.0, "episode/score": 0.2639454891564128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2639454891564128}
{"step": 69136, "time": 3766.064715385437, "episode/length": 178.0, "episode/score": 0.1858148281389731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1858148281389731}
{"step": 69248, "time": 3771.8677656650543, "episode/length": 274.0, "episode/score": 0.31307514381023793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31307514381023793}
{"step": 69448, "time": 3780.6913237571716, "episode/length": 203.0, "episode/score": 0.23995014664069458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23995014664069458}
{"step": 70096, "time": 3828.28302359581, "eval_episode/length": 142.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.993006993006993}
{"step": 70096, "time": 3831.2506034374237, "eval_episode/length": 172.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 70096, "time": 3833.177469968796, "eval_episode/length": 179.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 70096, "time": 3834.9412236213684, "eval_episode/length": 184.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 70096, "time": 3836.71018409729, "eval_episode/length": 188.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 70096, "time": 3839.291767835617, "eval_episode/length": 210.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.981042654028436}
{"step": 70096, "time": 3841.113289117813, "eval_episode/length": 216.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 70096, "time": 3844.3338751792908, "eval_episode/length": 250.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9840637450199203}
{"step": 70216, "time": 3848.6193540096283, "episode/length": 197.0, "episode/score": 0.21792693035695265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21792693035695265}
{"step": 70232, "time": 3850.785046815872, "episode/length": 173.0, "episode/score": 0.19350706192790312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19350706192790312}
{"step": 70264, "time": 3853.673506498337, "episode/length": 173.0, "episode/score": 0.18745678780533126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18745678780533126}
{"step": 70888, "time": 3879.0085973739624, "episode/length": 219.0, "episode/score": 0.21491189343760198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21491189343760198}
{"step": 70888, "time": 3879.0167541503906, "episode/length": 233.0, "episode/score": 0.2699425152572985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2699425152572985}
{"step": 70944, "time": 3884.8142943382263, "episode/length": 186.0, "episode/score": 0.20238453373303855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20238453373303855}
{"step": 71176, "time": 3894.848039865494, "episode/length": 119.0, "episode/score": 0.14273196914109576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14273196914109576}
{"step": 71264, "time": 3900.6478226184845, "episode/length": 265.0, "episode/score": 0.29564275861548595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29564275861548595}
{"step": 71320, "time": 3904.065366268158, "episode/length": 258.0, "episode/score": 0.29178000990441433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29178000990441433}
{"step": 71448, "time": 3910.527575969696, "episode/length": 151.0, "episode/score": 0.16861162469012925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16861162469012925}
{"step": 71728, "time": 3923.954802274704, "episode/length": 97.0, "episode/score": 0.09970407834680373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09970407834680373}
{"step": 71784, "time": 3927.4256517887115, "episode/length": 189.0, "episode/score": 0.20404178897479142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20404178897479142}
{"step": 72232, "time": 3945.9898614883423, "episode/length": 167.0, "episode/score": 0.18861172681454264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18861172681454264}
{"step": 72528, "time": 3958.992733001709, "episode/length": 168.0, "episode/score": 0.1654873230290832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1654873230290832}
{"step": 72640, "time": 3964.8985681533813, "episode/length": 218.0, "episode/score": 0.22277210106631173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22277210106631173}
{"step": 72784, "time": 3971.8867678642273, "episode/length": 166.0, "episode/score": 0.16875756258968977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16875756258968977}
{"step": 72856, "time": 3976.1440992355347, "episode/length": 198.0, "episode/score": 0.2089837010262272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2089837010262272}
{"step": 73040, "time": 3984.8342406749725, "episode/length": 214.0, "episode/score": 0.223797650664892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.223797650664892}
{"step": 73056, "time": 3986.943129301071, "episode/length": 158.0, "episode/score": 0.18522726946684998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18522726946684998}
{"step": 73176, "time": 3992.830727815628, "episode/length": 180.0, "episode/score": 0.18931127730684238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18931127730684238}
{"step": 73608, "time": 4010.798457622528, "episode/length": 171.0, "episode/score": 0.1914780188089935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1914780188089935}
{"step": 74072, "time": 4031.315242767334, "episode/length": 192.0, "episode/score": 0.22162708133691922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22162708133691922}
{"step": 74080, "time": 4033.4883217811584, "episode/length": 161.0, "episode/score": 0.18721108773024753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18721108773024753}
{"step": 74248, "time": 4041.3615596294403, "episode/length": 173.0, "episode/score": 0.19491230301719042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19491230301719042}
{"step": 74288, "time": 4044.679402589798, "episode/length": 205.0, "episode/score": 0.2199787317731534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2199787317731534}
{"step": 74368, "time": 4049.461196422577, "episode/length": 165.0, "episode/score": 0.18379996259318432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18379996259318432}
{"step": 74488, "time": 4055.375443458557, "episode/length": 178.0, "episode/score": 0.18608976486939355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18608976486939355}
{"step": 74600, "time": 4061.2596068382263, "episode/length": 177.0, "episode/score": 0.18437038818228757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18437038818228757}
{"step": 75000, "time": 4077.9641110897064, "episode/length": 173.0, "episode/score": 0.20466666290303692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20466666290303692}
{"step": 75080, "time": 4082.574742794037, "episode/length": 59.0, "episode/score": 0.05995397218794096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05995397218794096}
{"step": 75616, "time": 4104.62112903595, "episode/length": 170.0, "episode/score": 0.2013956561786472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2013956561786472}
{"step": 75656, "time": 4107.4652988910675, "episode/length": 170.0, "episode/score": 0.1714152870772523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714152870772523}
{"step": 75760, "time": 4113.135670661926, "episode/length": 210.0, "episode/score": 0.2388065436098259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2388065436098259}
{"step": 75848, "time": 4118.398626565933, "episode/length": 220.0, "episode/score": 0.2411789139659959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2411789139659959}
{"step": 76072, "time": 4129.0774257183075, "episode/length": 212.0, "episode/score": 0.22957542848598678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22957542848598678}
{"step": 76296, "time": 4139.032260417938, "episode/length": 161.0, "episode/score": 0.17745069944794523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17745069944794523}
{"step": 76560, "time": 4150.792783021927, "episode/length": 184.0, "episode/score": 0.20406472163813305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20406472163813305}
{"step": 76688, "time": 4157.352577924728, "episode/length": 274.0, "episode/score": 0.29490164046001155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29490164046001155}
{"step": 77016, "time": 4171.112679481506, "episode/length": 174.0, "episode/score": 0.17737902353110258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17737902353110258}
{"step": 77160, "time": 4178.142322540283, "episode/length": 163.0, "episode/score": 0.1682899964889657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1682899964889657}
{"step": 77232, "time": 4182.75493311882, "episode/length": 196.0, "episode/score": 0.2085581880837708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2085581880837708}
{"step": 77264, "time": 4185.727228403091, "episode/length": 187.0, "episode/score": 0.18662368759942183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18662368759942183}
{"step": 77696, "time": 4203.62878537178, "episode/length": 202.0, "episode/score": 0.22263129898055922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22263129898055922}
{"step": 77752, "time": 4207.176537036896, "episode/length": 181.0, "episode/score": 0.2135096958518261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2135096958518261}
{"step": 77864, "time": 4212.992177248001, "episode/length": 146.0, "episode/score": 0.1505861842942977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1505861842942977}
{"step": 78360, "time": 4233.712156057358, "episode/length": 224.0, "episode/score": 0.2522190316922206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2522190316922206}
{"step": 78448, "time": 4238.813186168671, "episode/length": 151.0, "episode/score": 0.1573876085858501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1573876085858501}
{"step": 78480, "time": 4241.512857437134, "episode/length": 182.0, "episode/score": 0.20260996195247571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20260996195247571}
{"step": 78656, "time": 4249.963618516922, "episode/length": 173.0, "episode/score": 0.19550949423319253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19550949423319253}
{"step": 78848, "time": 4259.577930450439, "episode/length": 210.0, "episode/score": 0.22776834657634026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22776834657634026}
{"step": 79232, "time": 4276.132581949234, "episode/length": 184.0, "episode/score": 0.19909641218146135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19909641218146135}
{"step": 79704, "time": 4295.365875482559, "episode/length": 167.0, "episode/score": 0.1727815778904187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1727815778904187}
{"step": 79720, "time": 4297.647205352783, "episode/length": 252.0, "episode/score": 0.28115197575061757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28115197575061757}
{"step": 79736, "time": 4299.8601632118225, "episode/length": 156.0, "episode/score": 0.16261753981325455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16261753981325455}
{"step": 79760, "time": 4302.552856683731, "episode/length": 163.0, "episode/score": 0.12835059357712453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12835059357712453}
{"step": 79784, "time": 4305.041836977005, "episode/length": 239.0, "episode/score": 0.24975743359118496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24975743359118496}
{"step": 80072, "time": 4317.547369480133, "episode/length": 152.0, "episode/score": 0.14607719547348097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14607719547348097}
{"step": 80080, "time": 4335.857555389404, "eval_episode/length": 60.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 80080, "time": 4340.364496707916, "eval_episode/length": 130.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9694656488549618}
{"step": 80080, "time": 4342.93202662468, "eval_episode/length": 154.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 80080, "time": 4344.827235221863, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.968944099378882}
{"step": 80080, "time": 4346.650307416916, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 80080, "time": 4348.290879487991, "eval_episode/length": 162.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 80080, "time": 4353.023784160614, "eval_episode/length": 174.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 80080, "time": 4354.991016387939, "eval_episode/length": 239.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 80081, "time": 4355.60222697258, "train_stats/sum_log_reward": 0.6044247534818354, "train_stats/max_log_achievement_collect_drink": 0.37168141592920356, "train_stats/max_log_achievement_collect_sapling": 0.6814159292035398, "train_stats/max_log_achievement_collect_wood": 0.34513274336283184, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.45132743362831856, "train_stats/max_log_achievement_place_table": 0.061946902654867256, "train_stats/max_log_achievement_wake_up": 0.08849557522123894, "train_stats/mean_log_entropy": 2.2764499124172515, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.89917236328125, "train/action_min": 0.0, "train/action_std": 4.914651485443115, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004347596883773804, "train/actor_opt_grad_steps": 4280.0, "train/actor_opt_loss": -14.943833532810212, "train/adv_mag": 0.13094391173124315, "train/adv_max": 0.055860244631767274, "train/adv_mean": -0.0004847720806646976, "train/adv_min": -0.13058047837018966, "train/adv_std": 0.009904847487807273, "train/cont_avg": 0.994578125, "train/cont_loss_mean": 0.0007278274798936763, "train/cont_loss_std": 0.019463627370223547, "train/cont_neg_acc": 0.9689100134757257, "train/cont_neg_loss": 0.08320428300182005, "train/cont_pos_acc": 0.9999214277267456, "train/cont_pos_loss": 0.0003323333821781489, "train/cont_pred": 0.9945499720573425, "train/cont_rate": 0.994578125, "train/dyn_loss_mean": 12.665904159545898, "train/dyn_loss_std": 6.849288131713867, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18815691885352134, "train/extr_critic_critic_opt_grad_steps": 4280.0, "train/extr_critic_critic_opt_loss": 9715.038578125, "train/extr_critic_mag": 0.24028314876556398, "train/extr_critic_max": 0.24028314876556398, "train/extr_critic_mean": 0.19273105883598327, "train/extr_critic_min": 0.0379500150680542, "train/extr_critic_std": 0.04144609527289867, "train/extr_return_normed_mag": 0.1407463036775589, "train/extr_return_normed_max": 0.13856242883205414, "train/extr_return_normed_mean": 0.09126367837190628, "train/extr_return_normed_min": -0.09777922356128693, "train/extr_return_normed_std": 0.04384752313792706, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2395449677705765, "train/extr_return_raw_max": 0.2395449677705765, "train/extr_return_raw_mean": 0.19224622070789338, "train/extr_return_raw_min": 0.0032033155560493467, "train/extr_return_raw_std": 0.04384752310812473, "train/extr_reward_mag": 0.0014082956314086913, "train/extr_reward_max": 0.0014082956314086913, "train/extr_reward_mean": 0.0010742928842082619, "train/extr_reward_min": 2.7494430541992188e-06, "train/extr_reward_std": 0.00024069896806031465, "train/image_loss_mean": 19.12720376586914, "train/image_loss_std": 16.859358627319335, "train/model_loss_mean": 26.765928115844726, "train/model_loss_std": 19.441905616760256, "train/model_opt_grad_norm": 102.850365234375, "train/model_opt_grad_steps": 4271.0, "train/model_opt_loss": 7078.90794140625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 267.5, "train/policy_entropy_mag": 2.7853293514251707, "train/policy_entropy_max": 2.7853293514251707, "train/policy_entropy_mean": 2.234154399871826, "train/policy_entropy_min": 0.13878217208385468, "train/policy_entropy_std": 0.5292769248485565, "train/policy_logprob_mag": 7.3499977569580075, "train/policy_logprob_max": -0.01900848790258169, "train/policy_logprob_mean": -2.2343320808410643, "train/policy_logprob_min": -7.3499977569580075, "train/policy_logprob_std": 1.0768111276626586, "train/policy_randomness_mag": 0.9830990319252014, "train/policy_randomness_max": 0.9830990319252014, "train/policy_randomness_mean": 0.7885584678649903, "train/policy_randomness_min": 0.04898401640355587, "train/policy_randomness_std": 0.1868115295767784, "train/post_ent_mag": 46.892136840820314, "train/post_ent_max": 46.892136840820314, "train/post_ent_mean": 32.96182518005371, "train/post_ent_min": 16.367239517211914, "train/post_ent_std": 5.062564266204834, "train/prior_ent_mag": 57.75315576171875, "train/prior_ent_max": 57.75315576171875, "train/prior_ent_mean": 45.940207427978514, "train/prior_ent_min": 19.818757751464844, "train/prior_ent_std": 6.576441257476807, "train/rep_loss_mean": 12.665904159545898, "train/rep_loss_std": 6.849288131713867, "train/reward_avg": 0.0010094383358955383, "train/reward_loss_mean": 0.03845398142933845, "train/reward_loss_std": 0.01292211002856493, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001359969139099121, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03845398157835007, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010148375025019049, "train/reward_rate": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.010101010101010102, "eval_stats/sum_log_reward": 0.22499997820705175, "eval_stats/max_log_achievement_collect_drink": 0.5, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 3.656238550320268e-05, "report/cont_loss_std": 0.0010921208886429667, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010832311818376184, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.599734554882161e-05, "report/cont_pred": 0.9921532869338989, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 14.51547622680664, "report/dyn_loss_std": 7.243729591369629, "report/image_loss_mean": 16.397918701171875, "report/image_loss_std": 14.50537395477295, "report/model_loss_mean": 25.146873474121094, "report/model_loss_std": 17.243471145629883, "report/post_ent_mag": 49.162235260009766, "report/post_ent_max": 49.162235260009766, "report/post_ent_mean": 34.44252014160156, "report/post_ent_min": 16.26487922668457, "report/post_ent_std": 5.023582458496094, "report/prior_ent_mag": 58.07176971435547, "report/prior_ent_max": 58.07176971435547, "report/prior_ent_mean": 47.930362701416016, "report/prior_ent_min": 19.843936920166016, "report/prior_ent_std": 5.083046913146973, "report/rep_loss_mean": 14.51547622680664, "report/rep_loss_std": 7.243729591369629, "report/reward_avg": 0.001044264528900385, "report/reward_loss_mean": 0.039632946252822876, "report/reward_loss_std": 0.011715919710695744, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013256072998046875, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039632946252822876, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001036117784678936, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.002221597358584404, "eval/cont_loss_std": 0.07055351883172989, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007626301143318415, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0022110205609351397, "eval/cont_pred": 0.9971863031387329, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.107223510742188, "eval/dyn_loss_std": 7.869163990020752, "eval/image_loss_mean": 20.24951934814453, "eval/image_loss_std": 19.438528060913086, "eval/model_loss_mean": 29.215137481689453, "eval/model_loss_std": 23.032331466674805, "eval/post_ent_mag": 44.36247253417969, "eval/post_ent_max": 44.36247253417969, "eval/post_ent_mean": 32.50059127807617, "eval/post_ent_min": 15.901272773742676, "eval/post_ent_std": 5.643536567687988, "eval/prior_ent_mag": 57.972190856933594, "eval/prior_ent_max": 57.972190856933594, "eval/prior_ent_mean": 43.517845153808594, "eval/prior_ent_min": 19.246116638183594, "eval/prior_ent_std": 9.095725059509277, "eval/rep_loss_mean": 14.107223510742188, "eval/rep_loss_std": 7.869163990020752, "eval/reward_avg": 0.01152343675494194, "eval/reward_loss_mean": 0.49906498193740845, "eval/reward_loss_std": 2.687533140182495, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.001323103904724121, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.27589911222457886, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 15.510689735412598, "eval/reward_pred": 0.0008893371559679508, "eval/reward_rate": 0.0146484375, "replay/size": 79577.0, "replay/inserts": 20072.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.4230282290516834e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.30704663624984e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18784.0, "eval_replay/inserts": 3928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2592239923729674e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1025.019146680832, "timer/env.step_count": 2509.0, "timer/env.step_total": 255.10087084770203, "timer/env.step_frac": 0.24887424949451675, "timer/env.step_avg": 0.10167432078425748, "timer/env.step_min": 0.02377486228942871, "timer/env.step_max": 3.4670188426971436, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 10.212143659591675, "timer/replay._sample_frac": 0.009962880881454899, "timer/replay._sample_avg": 0.0005089784519333968, "timer/replay._sample_min": 0.0003674030303955078, "timer/replay._sample_max": 0.01787567138671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3000.0, "timer/agent.policy_total": 50.56766414642334, "timer/agent.policy_frac": 0.04933338495204615, "timer/agent.policy_avg": 0.01685588804880778, "timer/agent.policy_min": 0.009505987167358398, "timer/agent.policy_max": 0.1321420669555664, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.1385512351989746, "timer/dataset_train_frac": 0.00013516941185696347, "timer/dataset_train_avg": 0.00011048742838833701, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0005254745483398438, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 568.6816802024841, "timer/agent.train_frac": 0.5548010318089784, "timer/agent.train_avg": 0.45349416284089644, "timer/agent.train_min": 0.44108080863952637, "timer/agent.train_max": 0.9329235553741455, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48084115982055664, "timer/agent.report_frac": 0.0004691045639270189, "timer/agent.report_avg": 0.24042057991027832, "timer/agent.report_min": 0.23671627044677734, "timer/agent.report_max": 0.2441248893737793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.326167801052745e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 19.581845323699728}
{"step": 80144, "time": 4358.248777627945, "episode/length": 185.0, "episode/score": 0.1869737431024987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1869737431024987}
{"step": 80760, "time": 4382.721032857895, "episode/length": 190.0, "episode/score": 0.19370666818485915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19370666818485915}
{"step": 81016, "time": 4394.236698389053, "episode/length": 163.0, "episode/score": 0.16688955746849388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16688955746849388}
{"step": 81024, "time": 4396.950655221939, "episode/length": 162.0, "episode/score": 0.16790573705839051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16790573705839051}
{"step": 81232, "time": 4406.760936260223, "episode/length": 180.0, "episode/score": 0.18767685637794784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18767685637794784}
{"step": 81248, "time": 4408.886855602264, "episode/length": 188.0, "episode/score": 0.1826895638341739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1826895638341739}
{"step": 81376, "time": 4415.393952846527, "episode/length": 162.0, "episode/score": 0.143911288300842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.143911288300842}
{"step": 81456, "time": 4419.920942544937, "episode/length": 211.0, "episode/score": 0.23376628138339584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23376628138339584}
{"step": 81464, "time": 4421.564740180969, "episode/length": 164.0, "episode/score": 0.17580018790613394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17580018790613394}
{"step": 82088, "time": 4448.033256053925, "episode/length": 165.0, "episode/score": 0.17434918962680968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17434918962680968}
{"step": 82256, "time": 4456.524133443832, "episode/length": 153.0, "episode/score": 0.17501559432275826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17501559432275826}
{"step": 82472, "time": 4466.714841365814, "episode/length": 181.0, "episode/score": 0.20266908485882595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20266908485882595}
{"step": 82552, "time": 4471.994254827499, "episode/length": 162.0, "episode/score": 0.17268358833189268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17268358833189268}
{"step": 82608, "time": 4476.445309638977, "episode/length": 171.0, "episode/score": 0.17825548895507382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17825548895507382}
{"step": 82912, "time": 4490.163357973099, "episode/length": 191.0, "episode/score": 0.21084001325834834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21084001325834834}
{"step": 83048, "time": 4496.679701328278, "episode/length": 197.0, "episode/score": 0.22611051316562225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22611051316562225}
{"step": 83272, "time": 4506.677487611771, "episode/length": 226.0, "episode/score": 0.26298021083948697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26298021083948697}
{"step": 83736, "time": 4525.935707330704, "episode/length": 205.0, "episode/score": 0.23237182328739436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23237182328739436}
{"step": 83752, "time": 4528.209983825684, "episode/length": 186.0, "episode/score": 0.21556790690556227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21556790690556227}
{"step": 83768, "time": 4530.3782522678375, "episode/length": 161.0, "episode/score": 0.16962792113463365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16962792113463365}
{"step": 83872, "time": 4536.113471984863, "episode/length": 164.0, "episode/score": 0.16729591410285138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16729591410285138}
{"step": 84192, "time": 4550.088529348373, "episode/length": 159.0, "episode/score": 0.17422988244470616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17422988244470616}
{"step": 84448, "time": 4561.241657495499, "episode/length": 229.0, "episode/score": 0.2277312853057083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2277312853057083}
{"step": 84736, "time": 4573.622910737991, "episode/length": 210.0, "episode/score": 0.24624340707487136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24624340707487136}
{"step": 85080, "time": 4588.137657403946, "episode/length": 163.0, "episode/score": 0.1753934249404665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1753934249404665}
{"step": 85448, "time": 4603.602494716644, "episode/length": 196.0, "episode/score": 0.2201775866724347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2201775866724347}
{"step": 85712, "time": 4615.387009859085, "episode/length": 189.0, "episode/score": 0.2146249965298921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2146249965298921}
{"step": 85848, "time": 4621.992772102356, "episode/length": 261.0, "episode/score": 0.28441640774144616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28441640774144616}
{"step": 85984, "time": 4628.838556289673, "episode/length": 338.0, "episode/score": 0.3504458716101908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3504458716101908}
{"step": 86096, "time": 4634.746596574783, "episode/length": 205.0, "episode/score": 0.23196337981789839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23196337981789839}
{"step": 86424, "time": 4648.407136917114, "episode/length": 210.0, "episode/score": 0.23076301882247208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23076301882247208}
{"step": 86448, "time": 4651.116829633713, "episode/length": 338.0, "episode/score": 0.3114410503549152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3114410503549152}
{"step": 86608, "time": 4658.843168973923, "episode/length": 190.0, "episode/score": 0.20607183731044643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20607183731044643}
{"step": 87048, "time": 4676.772728919983, "episode/length": 199.0, "episode/score": 0.23176827337010764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23176827337010764}
{"step": 87232, "time": 4685.460745096207, "episode/length": 172.0, "episode/score": 0.2025417081094929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2025417081094929}
{"step": 87304, "time": 4689.577881336212, "episode/length": 164.0, "episode/score": 0.17368432797593414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17368432797593414}
{"step": 87408, "time": 4695.313375234604, "episode/length": 211.0, "episode/score": 0.24338156722660642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24338156722660642}
{"step": 87864, "time": 4713.86678647995, "episode/length": 176.0, "episode/score": 0.20205032711965032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20205032711965032}
{"step": 87960, "time": 4719.248249530792, "episode/length": 191.0, "episode/score": 0.19530964515070082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19530964515070082}
{"step": 87960, "time": 4719.25671339035, "episode/length": 232.0, "episode/score": 0.2538146568185766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2538146568185766}
{"step": 88400, "time": 4739.543045759201, "episode/length": 54.0, "episode/score": 0.06306547499843873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06306547499843873}
{"step": 88584, "time": 4747.831176280975, "episode/length": 246.0, "episode/score": 0.2963153786913608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2963153786913608}
{"step": 88704, "time": 4754.34113240242, "episode/length": 206.0, "episode/score": 0.21339277999504702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21339277999504702}
{"step": 88864, "time": 4761.825163841248, "episode/length": 181.0, "episode/score": 0.18725538232320105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18725538232320105}
{"step": 89288, "time": 4779.370024204254, "episode/length": 165.0, "episode/score": 0.19116851557555492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19116851557555492}
{"step": 89472, "time": 4788.209122657776, "episode/length": 200.0, "episode/score": 0.19187943793258455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19187943793258455}
{"step": 89520, "time": 4791.62793636322, "episode/length": 285.0, "episode/score": 0.31026362378725025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31026362378725025}
{"step": 89760, "time": 4802.096389532089, "episode/length": 306.0, "episode/score": 0.3089679091608559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3089679091608559}
{"step": 89888, "time": 4808.412461519241, "episode/length": 185.0, "episode/score": 0.18750747916055843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18750747916055843}
{"step": 89896, "time": 4810.0908443927765, "episode/length": 163.0, "episode/score": 0.16322605433560966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16322605433560966}
{"step": 90064, "time": 4834.5695967674255, "eval_episode/length": 66.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9253731343283582}
{"step": 90064, "time": 4840.567964553833, "eval_episode/length": 167.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 90064, "time": 4842.436465024948, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 90064, "time": 4844.434270143509, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 90064, "time": 4846.52379488945, "eval_episode/length": 186.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 90064, "time": 4848.982540369034, "eval_episode/length": 206.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 90064, "time": 4850.773868322372, "eval_episode/length": 208.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 90064, "time": 4852.420056819916, "eval_episode/length": 210.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 90408, "time": 4866.5288870334625, "episode/length": 212.0, "episode/score": 0.22423291142513335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22423291142513335}
{"step": 90520, "time": 4872.311301708221, "episode/length": 206.0, "episode/score": 0.2259442217018659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2259442217018659}
{"step": 90680, "time": 4880.0513463020325, "episode/length": 173.0, "episode/score": 0.19329948718223022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19329948718223022}
{"step": 90792, "time": 4885.777503490448, "episode/length": 158.0, "episode/score": 0.16173524138048379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16173524138048379}
{"step": 91120, "time": 4900.146825790405, "episode/length": 169.0, "episode/score": 0.17798538110946538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17798538110946538}
{"step": 91120, "time": 4900.154967546463, "episode/length": 205.0, "episode/score": 0.2246732936528133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2246732936528133}
{"step": 91576, "time": 4920.890963315964, "episode/length": 210.0, "episode/score": 0.23560070805979194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23560070805979194}
{"step": 91608, "time": 4923.69207239151, "episode/length": 213.0, "episode/score": 0.2515788403043189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2515788403043189}
{"step": 91760, "time": 4931.169229269028, "episode/length": 168.0, "episode/score": 0.17510326825686207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17510326825686207}
{"step": 91952, "time": 4940.0590806007385, "episode/length": 178.0, "episode/score": 0.199522517911646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.199522517911646}
{"step": 92016, "time": 4943.982346057892, "episode/length": 152.0, "episode/score": 0.17106646567299322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17106646567299322}
{"step": 92200, "time": 4952.4212148189545, "episode/length": 189.0, "episode/score": 0.21884701162616693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21884701162616693}
{"step": 92448, "time": 4963.540713787079, "episode/length": 165.0, "episode/score": 0.19074247900971386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19074247900971386}
{"step": 92648, "time": 4972.623452663422, "episode/length": 190.0, "episode/score": 0.1907850015841177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1907850015841177}
{"step": 92824, "time": 4980.852180480957, "episode/length": 46.0, "episode/score": 0.050458332552807406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050458332552807406}
{"step": 92928, "time": 4986.707177400589, "episode/length": 164.0, "episode/score": 0.1904736106225755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1904736106225755}
{"step": 93008, "time": 4991.83301448822, "episode/length": 155.0, "episode/score": 0.17885713974828832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17885713974828832}
{"step": 93192, "time": 5000.75573182106, "episode/length": 201.0, "episode/score": 0.23601100888390647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23601100888390647}
{"step": 93320, "time": 5007.184227228165, "episode/length": 170.0, "episode/score": 0.18124304759476217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18124304759476217}
{"step": 93352, "time": 5010.587849617004, "episode/length": 166.0, "episode/score": 0.177659685821709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.177659685821709}
{"step": 93832, "time": 5031.141981840134, "episode/length": 203.0, "episode/score": 0.24295832857023925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24295832857023925}
{"step": 93920, "time": 5036.341167211533, "episode/length": 158.0, "episode/score": 0.1628230908563637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1628230908563637}
{"step": 94104, "time": 5044.634434461594, "episode/length": 146.0, "episode/score": 0.153201292247104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.153201292247104}
{"step": 94208, "time": 5050.439368009567, "episode/length": 149.0, "episode/score": 0.14944354686576844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14944354686576844}
{"step": 94344, "time": 5057.56661605835, "episode/length": 189.0, "episode/score": 0.18940584474057687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18940584474057687}
{"step": 95040, "time": 5086.4077179431915, "episode/length": 230.0, "episode/score": 0.26250234566305153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26250234566305153}
{"step": 95040, "time": 5086.415526866913, "episode/length": 214.0, "episode/score": 0.2364281713626042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2364281713626042}
{"step": 95144, "time": 5093.334898710251, "episode/length": 163.0, "episode/score": 0.1853124967601616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1853124967601616}
{"step": 95328, "time": 5102.129855394363, "episode/length": 246.0, "episode/score": 0.26681245655436214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26681245655436214}
{"step": 95584, "time": 5113.332637548447, "episode/length": 207.0, "episode/score": 0.2414404718147125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2414404718147125}
{"step": 95608, "time": 5115.759587526321, "episode/length": 174.0, "episode/score": 0.1877862075198209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1877862075198209}
{"step": 95608, "time": 5115.767308473587, "episode/length": 187.0, "episode/score": 0.19402252991858404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19402252991858404}
{"step": 95632, "time": 5120.166987419128, "episode/length": 160.0, "episode/score": 0.1852761330374051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1852761330374051}
{"step": 96456, "time": 5152.5204203128815, "episode/length": 176.0, "episode/score": 0.17904700065992074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17904700065992074}
{"step": 96480, "time": 5155.225368738174, "episode/length": 179.0, "episode/score": 0.19574919176739058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19574919176739058}
{"step": 96656, "time": 5163.363339185715, "episode/length": 188.0, "episode/score": 0.19823054333755863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19823054333755863}
{"step": 96720, "time": 5167.351188421249, "episode/length": 138.0, "episode/score": 0.1599055793521984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1599055793521984}
{"step": 96800, "time": 5172.049529314041, "episode/length": 183.0, "episode/score": 0.2112675793687231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2112675793687231}
{"step": 96856, "time": 5175.721542835236, "episode/length": 158.0, "episode/score": 0.16092381167618441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16092381167618441}
{"step": 97240, "time": 5191.73938369751, "episode/length": 200.0, "episode/score": 0.21210204728413373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21210204728413373}
{"step": 97792, "time": 5214.328457117081, "episode/length": 163.0, "episode/score": 0.1694242303055944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1694242303055944}
{"step": 97896, "time": 5219.631485462189, "episode/length": 154.0, "episode/score": 0.15814408843652927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15814408843652927}
{"step": 97952, "time": 5223.598685503006, "episode/length": 186.0, "episode/score": 0.21783332944323774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21783332944323774}
{"step": 98184, "time": 5233.646606683731, "episode/length": 182.0, "episode/score": 0.1845638005870569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1845638005870569}
{"step": 98304, "time": 5240.422662973404, "episode/length": 63.0, "episode/score": 0.07874999835621566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07874999835621566}
{"step": 98344, "time": 5245.174141168594, "episode/length": 192.0, "episode/score": 0.23250291811928037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23250291811928037}
{"step": 98456, "time": 5251.52680015564, "episode/length": 151.0, "episode/score": 0.1548890662161284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1548890662161284}
{"step": 98712, "time": 5262.853371143341, "episode/length": 231.0, "episode/score": 0.2463735925994115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2463735925994115}
{"step": 98768, "time": 5266.83549952507, "episode/length": 394.0, "episode/score": 0.36238803967717104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36238803967717104}
{"step": 99112, "time": 5281.14817404747, "episode/length": 151.0, "episode/score": 0.1763431066647172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1763431066647172}
{"step": 99424, "time": 5295.107112407684, "episode/length": 154.0, "episode/score": 0.1840650275007647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1840650275007647}
{"step": 99816, "time": 5312.069725751877, "episode/length": 183.0, "episode/score": 0.21274999604793265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21274999604793265}
{"step": 99856, "time": 5315.262621879578, "episode/length": 174.0, "episode/score": 0.18791344706187374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18791344706187374}
{"step": 100008, "time": 5322.4466824531555, "episode/length": 154.0, "episode/score": 0.17382843643645174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17382843643645174}
{"step": 100048, "time": 5344.124130725861, "eval_episode/length": 120.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9504132231404959}
{"step": 100048, "time": 5347.752244710922, "eval_episode/length": 168.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 100048, "time": 5347.760945796967, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 100048, "time": 5351.913214683533, "eval_episode/length": 183.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 100048, "time": 5354.191350221634, "eval_episode/length": 195.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 100048, "time": 5356.289141178131, "eval_episode/length": 210.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 100048, "time": 5358.747974872589, "eval_episode/length": 61.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 100048, "time": 5361.610095977783, "eval_episode/length": 258.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9845559845559846}
{"step": 100049, "time": 5362.211405038834, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.87493603515625, "train/action_min": 0.0, "train/action_std": 4.993007064819336, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004916296102106571, "train/actor_opt_grad_steps": 5530.0, "train/actor_opt_loss": -15.720223297834396, "train/adv_mag": 0.1185606734752655, "train/adv_max": 0.07040843963623047, "train/adv_mean": -0.0003379270439836546, "train/adv_min": -0.11775279003381729, "train/adv_std": 0.010494308609515429, "train/cont_avg": 0.9943125, "train/cont_loss_mean": 0.0005704993487597676, "train/cont_loss_std": 0.014281960539647117, "train/cont_neg_acc": 0.9729174637794494, "train/cont_neg_loss": 0.06667762809677151, "train/cont_pos_acc": 0.9999292168617249, "train/cont_pos_loss": 0.00020714899876509208, "train/cont_pred": 0.9943409662246704, "train/cont_rate": 0.9943125, "train/dyn_loss_mean": 13.610543174743652, "train/dyn_loss_std": 7.057649616241455, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.219342967659235, "train/extr_critic_critic_opt_grad_steps": 5530.0, "train/extr_critic_critic_opt_loss": 9222.578546875, "train/extr_critic_mag": 0.24328722095489502, "train/extr_critic_max": 0.24328722095489502, "train/extr_critic_mean": 0.17942133438587188, "train/extr_critic_min": 0.019168581008911133, "train/extr_critic_std": 0.050499550104141235, "train/extr_return_normed_mag": 0.16912021505832672, "train/extr_return_normed_max": 0.16912021505832672, "train/extr_return_normed_mean": 0.10755467522144317, "train/extr_return_normed_min": -0.07039959150552749, "train/extr_return_normed_std": 0.051925673007965086, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24064894342422485, "train/extr_return_raw_max": 0.24064894342422485, "train/extr_return_raw_mean": 0.17908340692520142, "train/extr_return_raw_min": 0.0011291370391845704, "train/extr_return_raw_std": 0.05192567312717438, "train/extr_reward_mag": 0.0013825349807739258, "train/extr_reward_max": 0.0013825349807739258, "train/extr_reward_mean": 0.001087306994944811, "train/extr_reward_min": 1.1454582214355468e-05, "train/extr_reward_std": 0.0002325309137813747, "train/image_loss_mean": 15.488092758178711, "train/image_loss_std": 15.349119354248048, "train/model_loss_mean": 23.694056030273437, "train/model_loss_std": 18.03982981109619, "train/model_opt_grad_norm": 96.44091006469726, "train/model_opt_grad_steps": 5520.904, "train/model_opt_loss": 14324.83808984375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 607.5, "train/policy_entropy_mag": 2.759328742980957, "train/policy_entropy_max": 2.759328742980957, "train/policy_entropy_mean": 2.12843022441864, "train/policy_entropy_min": 0.12556883901357652, "train/policy_entropy_std": 0.525847635269165, "train/policy_logprob_mag": 7.369686382293701, "train/policy_logprob_max": -0.01683550976961851, "train/policy_logprob_mean": -2.1267726221084593, "train/policy_logprob_min": -7.369686382293701, "train/policy_logprob_std": 1.1339837679862976, "train/policy_randomness_mag": 0.9739219560623169, "train/policy_randomness_max": 0.9739219560623169, "train/policy_randomness_mean": 0.7512424612045288, "train/policy_randomness_min": 0.044320289850234985, "train/policy_randomness_std": 0.18560113960504532, "train/post_ent_mag": 48.33215603637695, "train/post_ent_max": 48.33215603637695, "train/post_ent_mean": 33.643774169921876, "train/post_ent_min": 17.090261657714844, "train/post_ent_std": 5.201783817291259, "train/prior_ent_mag": 59.14283865356445, "train/prior_ent_max": 59.14283865356445, "train/prior_ent_mean": 47.535120880126954, "train/prior_ent_min": 20.595388748168947, "train/prior_ent_std": 6.16867138671875, "train/rep_loss_mean": 13.610543174743652, "train/rep_loss_std": 7.057649616241455, "train/reward_avg": 0.0010297248917631805, "train/reward_loss_mean": 0.03906710788607597, "train/reward_loss_std": 0.012430953912436963, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013091449737548829, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03906710821390152, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010296849766746163, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.744230744214012, "train_stats/max_log_achievement_collect_drink": 0.5865384615384616, "train_stats/max_log_achievement_collect_sapling": 0.7019230769230769, "train_stats/max_log_achievement_collect_wood": 0.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_sword": 0.009615384615384616, "train_stats/max_log_achievement_place_plant": 0.36538461538461536, "train_stats/max_log_achievement_place_table": 0.07692307692307693, "train_stats/max_log_achievement_wake_up": 0.04807692307692308, "train_stats/mean_log_entropy": 2.1929688361974864, "eval_stats/sum_log_reward": 0.6624999595806003, "eval_stats/max_log_achievement_collect_drink": 1.0625, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.963671017321758e-05, "report/cont_loss_std": 0.0011064858408644795, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010992623720085248, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.940027793054469e-05, "report/cont_pred": 0.9960455894470215, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.899702072143555, "report/dyn_loss_std": 7.29791784286499, "report/image_loss_mean": 15.515423774719238, "report/image_loss_std": 13.970396995544434, "report/model_loss_mean": 23.894638061523438, "report/model_loss_std": 17.10517692565918, "report/post_ent_mag": 49.33574676513672, "report/post_ent_max": 49.33574676513672, "report/post_ent_mean": 33.69495391845703, "report/post_ent_min": 17.677209854125977, "report/post_ent_std": 5.477838516235352, "report/prior_ent_mag": 59.660823822021484, "report/prior_ent_max": 59.660823822021484, "report/prior_ent_mean": 47.9375114440918, "report/prior_ent_min": 20.950702667236328, "report/prior_ent_std": 6.254622936248779, "report/rep_loss_mean": 13.899702072143555, "report/rep_loss_std": 7.29791784286499, "report/reward_avg": 0.0010380870662629604, "report/reward_loss_mean": 0.039343152195215225, "report/reward_loss_std": 0.012115719728171825, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0015065670013427734, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039343152195215225, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010854915017262101, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.003982486668974161, "eval/cont_loss_std": 0.09079726040363312, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.8771936297416687, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.002273658523336053, "eval/cont_pred": 0.997974693775177, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.854125022888184, "eval/dyn_loss_std": 8.654288291931152, "eval/image_loss_mean": 19.515954971313477, "eval/image_loss_std": 17.165292739868164, "eval/model_loss_mean": 29.05677604675293, "eval/model_loss_std": 21.33761978149414, "eval/post_ent_mag": 46.966556549072266, "eval/post_ent_max": 46.966556549072266, "eval/post_ent_mean": 31.404441833496094, "eval/post_ent_min": 15.745080947875977, "eval/post_ent_std": 5.785369396209717, "eval/prior_ent_mag": 59.50666809082031, "eval/prior_ent_max": 59.50666809082031, "eval/prior_ent_mean": 43.63623046875, "eval/prior_ent_min": 19.48957061767578, "eval/prior_ent_std": 10.361653327941895, "eval/rep_loss_mean": 14.854125022888184, "eval/rep_loss_std": 8.654288291931152, "eval/reward_avg": 0.01601562649011612, "eval/reward_loss_mean": 0.6243644952774048, "eval/reward_loss_std": 3.07214617729187, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013386011123657227, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.3131921589374542, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 16.24521827697754, "eval/reward_pred": 0.0009402818977832794, "eval/reward_rate": 0.01953125, "replay/size": 99545.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.4182013005782396e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.783088280604436e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22544.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2209440799469644e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1006.5974173545837, "timer/env.step_count": 2496.0, "timer/env.step_total": 240.84672236442566, "timer/env.step_frac": 0.23926817038472994, "timer/env.step_avg": 0.09649307787036285, "timer/env.step_min": 0.02280569076538086, "timer/env.step_max": 3.4481186866760254, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 10.265300273895264, "timer/replay._sample_frac": 0.010198019681863749, "timer/replay._sample_avg": 0.0005140875537808125, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.012187004089355469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2966.0, "timer/agent.policy_total": 48.481544733047485, "timer/agent.policy_frac": 0.048163788121432655, "timer/agent.policy_avg": 0.016345766936293825, "timer/agent.policy_min": 0.009414434432983398, "timer/agent.policy_max": 0.10414695739746094, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.1358020305633545, "timer/dataset_train_frac": 0.00013491196005673527, "timer/dataset_train_avg": 0.00010881572961807251, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0007956027984619141, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 565.6438887119293, "timer/agent.train_frac": 0.5619365587073385, "timer/agent.train_avg": 0.4532402954422511, "timer/agent.train_min": 0.4406585693359375, "timer/agent.train_max": 1.0112717151641846, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47364091873168945, "timer/agent.report_frac": 0.0004705365924506886, "timer/agent.report_avg": 0.23682045936584473, "timer/agent.report_min": 0.23060059547424316, "timer/agent.report_max": 0.2430403232574463, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1501840233052945e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 19.836881272117033}
{"step": 100064, "time": 5362.944428920746, "episode/length": 219.0, "episode/score": 0.2338321978240856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2338321978240856}
{"step": 100128, "time": 5367.094453334808, "episode/length": 271.0, "episode/score": 0.3039334904515272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3039334904515272}
{"step": 100424, "time": 5379.651325941086, "episode/length": 213.0, "episode/score": 0.22785257576288132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22785257576288132}
{"step": 100448, "time": 5382.330106019974, "episode/length": 166.0, "episode/score": 0.1962679818061588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1962679818061588}
{"step": 100568, "time": 5388.26496553421, "episode/length": 69.0, "episode/score": 0.08314005861575424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08314005861575424}
{"step": 100848, "time": 5400.567039966583, "episode/length": 177.0, "episode/score": 0.18980437808932038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18980437808932038}
{"step": 101192, "time": 5414.940422534943, "episode/length": 171.0, "episode/score": 0.19188994013529737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19188994013529737}
{"step": 101264, "time": 5419.501601696014, "episode/length": 175.0, "episode/score": 0.19565360117485397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19565360117485397}
{"step": 101288, "time": 5421.7233374118805, "episode/length": 144.0, "episode/score": 0.15782400360694737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15782400360694737}
{"step": 101760, "time": 5441.400191545486, "episode/length": 211.0, "episode/score": 0.2206189960370466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2206189960370466}
{"step": 101776, "time": 5443.608345985413, "episode/length": 165.0, "episode/score": 0.18827569356926688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18827569356926688}
{"step": 101904, "time": 5450.279126882553, "episode/length": 166.0, "episode/score": 0.17350272347266582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17350272347266582}
{"step": 102104, "time": 5459.195740699768, "episode/length": 209.0, "episode/score": 0.2246986483633009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2246986483633009}
{"step": 102288, "time": 5467.882572650909, "episode/length": 179.0, "episode/score": 0.1875647985152682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1875647985152682}
{"step": 102616, "time": 5481.854546546936, "episode/length": 168.0, "episode/score": 0.18066575176817423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18066575176817423}
{"step": 103216, "time": 5506.463093280792, "episode/length": 181.0, "episode/score": 0.19366492817152903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19366492817152903}
{"step": 103296, "time": 5510.980097532272, "episode/length": 189.0, "episode/score": 0.20551099967269693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20551099967269693}
{"step": 103416, "time": 5516.914815664291, "episode/length": 265.0, "episode/score": 0.3052960705535952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3052960705535952}
{"step": 103608, "time": 5525.691335439682, "episode/length": 212.0, "episode/score": 0.23665854902992578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23665854902992578}
{"step": 103824, "time": 5535.69891500473, "episode/length": 191.0, "episode/score": 0.22420752631114738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22420752631114738}
{"step": 103856, "time": 5538.512770652771, "episode/length": 218.0, "episode/score": 0.238148911663302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.238148911663302}
{"step": 103904, "time": 5541.83309006691, "episode/length": 338.0, "episode/score": 0.3234833503183836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3234833503183836}
{"step": 104368, "time": 5561.300982713699, "episode/length": 218.0, "episode/score": 0.23552222021589841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23552222021589841}
{"step": 104448, "time": 5565.932311296463, "episode/length": 153.0, "episode/score": 0.13500120262779092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13500120262779092}
{"step": 104920, "time": 5585.203107833862, "episode/length": 187.0, "episode/score": 0.18582989894002822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18582989894002822}
{"step": 104936, "time": 5587.497185707092, "episode/length": 165.0, "episode/score": 0.17458703267493547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17458703267493547}
{"step": 105200, "time": 5599.383345365524, "episode/length": 167.0, "episode/score": 0.1765115998850888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1765115998850888}
{"step": 105336, "time": 5605.810373067856, "episode/length": 178.0, "episode/score": 0.18533395778194972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18533395778194972}
{"step": 105512, "time": 5614.029700040817, "episode/length": 210.0, "episode/score": 0.24928273120895028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24928273120895028}
{"step": 105552, "time": 5617.4294900894165, "episode/length": 281.0, "episode/score": 0.29707680229057587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29707680229057587}
{"step": 105776, "time": 5627.595772266388, "episode/length": 165.0, "episode/score": 0.1705607929134203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1705607929134203}
{"step": 106280, "time": 5647.956712961197, "episode/length": 238.0, "episode/score": 0.25110137491810747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25110137491810747}
{"step": 106496, "time": 5658.178913354874, "episode/length": 194.0, "episode/score": 0.20354478162789746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20354478162789746}
{"step": 106736, "time": 5670.290259599686, "episode/length": 191.0, "episode/score": 0.2095796393373348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2095796393373348}
{"step": 106736, "time": 5670.298643112183, "episode/length": 226.0, "episode/score": 0.2265740989655569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2265740989655569}
{"step": 107168, "time": 5689.826127052307, "episode/length": 228.0, "episode/score": 0.25939157828270254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25939157828270254}
{"step": 107240, "time": 5693.947881937027, "episode/length": 210.0, "episode/score": 0.23209835446868965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23209835446868965}
{"step": 107424, "time": 5702.737883090973, "episode/length": 205.0, "episode/score": 0.21408358227154167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21408358227154167}
{"step": 108088, "time": 5729.1158883571625, "episode/length": 168.0, "episode/score": 0.17560654667704512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17560654667704512}
{"step": 108160, "time": 5733.647180318832, "episode/length": 177.0, "episode/score": 0.18015882330382738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18015882330382738}
{"step": 108160, "time": 5733.6555869579315, "episode/length": 207.0, "episode/score": 0.23162744327783003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23162744327783003}
{"step": 108224, "time": 5739.240154981613, "episode/length": 338.0, "episode/score": 0.3626998795361942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3626998795361942}
{"step": 108552, "time": 5753.102619886398, "episode/length": 140.0, "episode/score": 0.15251219288347784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15251219288347784}
{"step": 108808, "time": 5764.391742944717, "episode/length": 204.0, "episode/score": 0.24105939301534818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24105939301534818}
{"step": 108848, "time": 5767.647582054138, "episode/length": 200.0, "episode/score": 0.21155288668887806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21155288668887806}
{"step": 109040, "time": 5776.565079212189, "episode/length": 344.0, "episode/score": 0.3394399391954721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3394399391954721}
{"step": 109384, "time": 5790.918936491013, "episode/length": 152.0, "episode/score": 0.1539307231296334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1539307231296334}
{"step": 109696, "time": 5804.736751079559, "episode/length": 191.0, "episode/score": 0.20430034361515936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20430034361515936}
{"step": 109824, "time": 5811.066613674164, "episode/length": 216.0, "episode/score": 0.2518197974695795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2518197974695795}
{"step": 109912, "time": 5815.8150379657745, "episode/length": 210.0, "episode/score": 0.24013639487520777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24013639487520777}
{"step": 109960, "time": 5819.126837015152, "episode/length": 175.0, "episode/score": 0.18366342910894673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18366342910894673}
{"step": 110032, "time": 5843.008478879929, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 110032, "time": 5845.264843702316, "eval_episode/length": 163.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 110032, "time": 5846.915662288666, "eval_episode/length": 164.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 110032, "time": 5848.794078111649, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 110032, "time": 5850.816740512848, "eval_episode/length": 181.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 110032, "time": 5852.410674333572, "eval_episode/length": 182.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 110032, "time": 5855.130176544189, "eval_episode/length": 194.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 110032, "time": 5859.243104934692, "eval_episode/length": 231.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 110192, "time": 5865.307974815369, "episode/length": 167.0, "episode/score": 0.1758195822376365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1758195822376365}
{"step": 110376, "time": 5873.550101518631, "episode/length": 195.0, "episode/score": 0.2250585013566706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2250585013566706}
{"step": 110568, "time": 5882.319568634033, "episode/length": 190.0, "episode/score": 0.21634671158653873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21634671158653873}
{"step": 110656, "time": 5887.991406202316, "episode/length": 158.0, "episode/score": 0.15573998758463858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15573998758463858}
{"step": 110904, "time": 5899.336086034775, "episode/length": 88.0, "episode/score": 0.0868962246013325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0868962246013325}
{"step": 111184, "time": 5911.754661083221, "episode/length": 185.0, "episode/score": 0.20726998742838987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20726998742838987}
{"step": 111296, "time": 5917.531996250153, "episode/length": 166.0, "episode/score": 0.1910639383995658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1910639383995658}
{"step": 111352, "time": 5921.018991470337, "episode/length": 190.0, "episode/score": 0.19523853624059484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19523853624059484}
{"step": 111672, "time": 5934.669636011124, "episode/length": 161.0, "episode/score": 0.15143178576772698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15143178576772698}
{"step": 111800, "time": 5941.073842763901, "episode/length": 235.0, "episode/score": 0.25259399704737007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25259399704737007}
{"step": 111896, "time": 5946.228549480438, "episode/length": 165.0, "episode/score": 0.14709060818995567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14709060818995567}
{"step": 112184, "time": 5958.910032749176, "episode/length": 159.0, "episode/score": 0.1640935343948513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1640935343948513}
{"step": 112200, "time": 5960.963466882706, "episode/length": 192.0, "episode/score": 0.17785024683917072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17785024683917072}
{"step": 112432, "time": 5971.470065832138, "episode/length": 155.0, "episode/score": 0.1748124009463936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748124009463936}
{"step": 112472, "time": 5974.331125497818, "episode/length": 139.0, "episode/score": 0.1521415369998067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1521415369998067}
{"step": 112584, "time": 5980.123229026794, "episode/length": 160.0, "episode/score": 0.14001070013500794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14001070013500794}
{"step": 113104, "time": 6002.53799200058, "episode/length": 178.0, "episode/score": 0.18511997249925116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18511997249925116}
{"step": 113136, "time": 6005.792684555054, "episode/length": 154.0, "episode/score": 0.15445755508699222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15445755508699222}
{"step": 113208, "time": 6009.980060577393, "episode/length": 175.0, "episode/score": 0.20556535901596362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20556535901596362}
{"step": 113456, "time": 6021.234647035599, "episode/length": 156.0, "episode/score": 0.16368636410356885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16368636410356885}
{"step": 113696, "time": 6031.842702865601, "episode/length": 157.0, "episode/score": 0.13906313495431277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13906313495431277}
{"step": 114128, "time": 6049.750864267349, "episode/length": 206.0, "episode/score": 0.21563828804983132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21563828804983132}
{"step": 114256, "time": 6056.0823802948, "episode/length": 208.0, "episode/score": 0.22378202949903425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22378202949903425}
{"step": 114480, "time": 6065.994442224503, "episode/length": 286.0, "episode/score": 0.30869370911136684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30869370911136684}
{"step": 114536, "time": 6069.381830453873, "episode/length": 174.0, "episode/score": 0.18520494004974353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18520494004974353}
{"step": 114656, "time": 6075.892316579819, "episode/length": 180.0, "episode/score": 0.19936452195361198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19936452195361198}
{"step": 114688, "time": 6078.989219427109, "episode/length": 197.0, "episode/score": 0.2178679787539295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2178679787539295}
{"step": 114872, "time": 6088.570267915726, "episode/length": 176.0, "episode/score": 0.1973840988689517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1973840988689517}
{"step": 115360, "time": 6108.8123660087585, "episode/length": 207.0, "episode/score": 0.2392857244942661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2392857244942661}
{"step": 115384, "time": 6111.072451591492, "episode/length": 156.0, "episode/score": 0.15162229537099847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15162229537099847}
{"step": 115688, "time": 6124.008622169495, "episode/length": 178.0, "episode/score": 0.19066406532056135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19066406532056135}
{"step": 115720, "time": 6126.779320478439, "episode/length": 147.0, "episode/score": 0.1444413248498222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1444413248498222}
{"step": 116040, "time": 6140.456715106964, "episode/length": 168.0, "episode/score": 0.17689547052532362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17689547052532362}
{"step": 116128, "time": 6145.655761241913, "episode/length": 156.0, "episode/score": 0.162623780680633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.162623780680633}
{"step": 116360, "time": 6155.705542564392, "episode/length": 234.0, "episode/score": 0.2614555685584037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2614555685584037}
{"step": 116576, "time": 6165.653191566467, "episode/length": 148.0, "episode/score": 0.12505040438622927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12505040438622927}
{"step": 116744, "time": 6173.299968957901, "episode/length": 172.0, "episode/score": 0.19800572511439896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19800572511439896}
{"step": 117232, "time": 6193.578098535538, "episode/length": 108.0, "episode/score": 0.13333333062473685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13333333062473685}
{"step": 117376, "time": 6201.148684024811, "episode/length": 210.0, "episode/score": 0.22469525782003075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22469525782003075}
{"step": 117400, "time": 6203.418492794037, "episode/length": 158.0, "episode/score": 0.15956800233925605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15956800233925605}
{"step": 117600, "time": 6212.645662546158, "episode/length": 194.0, "episode/score": 0.21920762700642626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21920762700642626}
{"step": 117880, "time": 6224.57453083992, "episode/length": 402.0, "episode/score": 0.42965744183288734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42965744183288734}
{"step": 118072, "time": 6233.2378170490265, "episode/length": 165.0, "episode/score": 0.1740955790010048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1740955790010048}
{"step": 118176, "time": 6239.131339073181, "episode/length": 199.0, "episode/score": 0.20773114784969948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20773114784969948}
{"step": 118360, "time": 6247.632258892059, "episode/length": 329.0, "episode/score": 0.3370041150060388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3370041150060388}
{"step": 118464, "time": 6253.931315660477, "episode/length": 153.0, "episode/score": 0.16617314126779092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16617314126779092}
{"step": 118648, "time": 6262.215554475784, "episode/length": 155.0, "episode/score": 0.16667294242870412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16667294242870412}
{"step": 119160, "time": 6283.098148345947, "episode/length": 194.0, "episode/score": 0.21588281304502743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21588281304502743}
{"step": 119328, "time": 6291.296647310257, "episode/length": 180.0, "episode/score": 0.18370681998931104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18370681998931104}
{"step": 119352, "time": 6293.560534000397, "episode/length": 246.0, "episode/score": 0.26225377534137806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26225377534137806}
{"step": 119512, "time": 6301.201072692871, "episode/length": 166.0, "episode/score": 0.16354979949392145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16354979949392145}
{"step": 119720, "time": 6310.596140861511, "episode/length": 156.0, "episode/score": 0.1771366933171521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1771366933171521}
{"step": 119744, "time": 6313.377572774887, "episode/length": 208.0, "episode/score": 0.21755588119776803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21755588119776803}
{"step": 119848, "time": 6318.713289499283, "episode/length": 185.0, "episode/score": 0.19130604465135548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19130604465135548}
{"step": 120016, "time": 6346.4945232868195, "eval_episode/length": 154.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 120016, "time": 6347.976939916611, "eval_episode/length": 155.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 120016, "time": 6350.653652429581, "eval_episode/length": 177.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 120016, "time": 6352.5278215408325, "eval_episode/length": 183.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 120016, "time": 6354.463990449905, "eval_episode/length": 192.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 120016, "time": 6354.471380233765, "eval_episode/length": 192.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 120016, "time": 6358.756955862045, "eval_episode/length": 216.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 120016, "time": 6361.60039973259, "eval_episode/length": 248.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9799196787148594}
{"step": 120025, "time": 6362.730403661728, "train_stats/sum_log_reward": 0.8999999702686355, "train_stats/max_log_achievement_collect_drink": 0.6666666666666666, "train_stats/max_log_achievement_collect_sapling": 0.7142857142857143, "train_stats/max_log_achievement_collect_wood": 0.6, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3523809523809524, "train_stats/max_log_achievement_place_table": 0.047619047619047616, "train_stats/max_log_achievement_wake_up": 0.08571428571428572, "train_stats/mean_log_entropy": 2.175968486922128, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.010564453125, "train/action_min": 0.0, "train/action_std": 5.001663913726807, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005250465244054794, "train/actor_opt_grad_steps": 6780.0, "train/actor_opt_loss": -9.170890339851379, "train/adv_mag": 0.13753576982021332, "train/adv_max": 0.0721616044640541, "train/adv_mean": -8.186826061137254e-05, "train/adv_min": -0.13697008329629898, "train/adv_std": 0.010891044724732638, "train/cont_avg": 0.994671875, "train/cont_loss_mean": 0.0006789251955833606, "train/cont_loss_std": 0.01917462759297632, "train/cont_neg_acc": 0.981939685344696, "train/cont_neg_loss": 0.06635995069624914, "train/cont_pos_acc": 0.9999213805198669, "train/cont_pos_loss": 0.00027761481995366923, "train/cont_pred": 0.9946573343276978, "train/cont_rate": 0.994671875, "train/dyn_loss_mean": 14.157661209106445, "train/dyn_loss_std": 7.274625263214111, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18728608778119088, "train/extr_critic_critic_opt_grad_steps": 6780.0, "train/extr_critic_critic_opt_loss": 9098.2370703125, "train/extr_critic_mag": 0.2412384672164917, "train/extr_critic_max": 0.2412384672164917, "train/extr_critic_mean": 0.18110183715820313, "train/extr_critic_min": 0.013517685890197754, "train/extr_critic_std": 0.048289144352078435, "train/extr_return_normed_mag": 0.1679494035243988, "train/extr_return_normed_max": 0.1679494035243988, "train/extr_return_normed_mean": 0.11034564000368119, "train/extr_return_normed_min": -0.06957919088006019, "train/extr_return_normed_std": 0.0500362466275692, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2386236926317215, "train/extr_return_raw_max": 0.2386236926317215, "train/extr_return_raw_mean": 0.18101993298530578, "train/extr_return_raw_min": 0.001095097541809082, "train/extr_return_raw_std": 0.05003624647855759, "train/extr_reward_mag": 0.001388178825378418, "train/extr_reward_max": 0.001388178825378418, "train/extr_reward_mean": 0.0010828936225734651, "train/extr_reward_min": 1.068878173828125e-05, "train/extr_reward_std": 0.00023947547585703434, "train/image_loss_mean": 13.399383064270019, "train/image_loss_std": 15.061438186645507, "train/model_loss_mean": 21.933713455200195, "train/model_loss_std": 17.86983632659912, "train/model_opt_grad_norm": 86.31975283813476, "train/model_opt_grad_steps": 6769.752, "train/model_opt_loss": 14270.254890625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 655.0, "train/policy_entropy_mag": 2.7615972900390626, "train/policy_entropy_max": 2.7615972900390626, "train/policy_entropy_mean": 2.0885239744186403, "train/policy_entropy_min": 0.13530180078744888, "train/policy_entropy_std": 0.5562059063911438, "train/policy_logprob_mag": 7.397037227630615, "train/policy_logprob_max": -0.018670915216207503, "train/policy_logprob_mean": -2.087951464653015, "train/policy_logprob_min": -7.397037227630615, "train/policy_logprob_std": 1.1665335369110108, "train/policy_randomness_mag": 0.9747226557731629, "train/policy_randomness_max": 0.9747226557731629, "train/policy_randomness_mean": 0.7371573133468627, "train/policy_randomness_min": 0.047755598112940785, "train/policy_randomness_std": 0.19631627786159517, "train/post_ent_mag": 50.04121688842773, "train/post_ent_max": 50.04121688842773, "train/post_ent_mean": 34.10399758911133, "train/post_ent_min": 17.614487258911133, "train/post_ent_std": 5.401275531768799, "train/prior_ent_mag": 60.34379849243164, "train/prior_ent_max": 60.34379849243164, "train/prior_ent_mean": 48.44409866333008, "train/prior_ent_min": 21.216936477661132, "train/prior_ent_std": 6.151651779174805, "train/rep_loss_mean": 14.157661209106445, "train/rep_loss_std": 7.274625263214111, "train/reward_avg": 0.0010302468105219305, "train/reward_loss_mean": 0.03905472263693809, "train/reward_loss_std": 0.012392760455608368, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013287944793701173, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039054722547531125, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001030091275461018, "train/reward_rate": 0.0, "train_stats/max_log_achievement_eat_cow": 0.03896103896103896, "eval_stats/sum_log_reward": 0.7874999726191163, "eval_stats/max_log_achievement_collect_drink": 0.5, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00010957558697555214, "report/cont_loss_std": 0.0010969712166115642, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0027113391552120447, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.166766540147364e-05, "report/cont_pred": 0.9930918216705322, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.302600860595703, "report/dyn_loss_std": 7.322091102600098, "report/image_loss_mean": 9.546428680419922, "report/image_loss_std": 9.50574016571045, "report/model_loss_mean": 17.568363189697266, "report/model_loss_std": 12.42444896697998, "report/post_ent_mag": 53.349212646484375, "report/post_ent_max": 53.349212646484375, "report/post_ent_mean": 34.727725982666016, "report/post_ent_min": 14.564929008483887, "report/post_ent_std": 5.6524577140808105, "report/prior_ent_mag": 60.2913932800293, "report/prior_ent_max": 60.2913932800293, "report/prior_ent_mean": 47.95899963378906, "report/prior_ent_min": 22.214492797851562, "report/prior_ent_std": 6.344671249389648, "report/rep_loss_mean": 13.302600860595703, "report/rep_loss_std": 7.322091102600098, "report/reward_avg": 0.0010653190547600389, "report/reward_loss_mean": 0.0402643047273159, "report/reward_loss_std": 0.011291537433862686, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013257265090942383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0402643084526062, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010819018352776766, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00010722644219640642, "eval/cont_loss_std": 0.0018625952070578933, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016287047765217721, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00010689849295886233, "eval/cont_pred": 0.9940370321273804, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 15.593157768249512, "eval/dyn_loss_std": 8.393691062927246, "eval/image_loss_mean": 17.31258773803711, "eval/image_loss_std": 21.94257354736328, "eval/model_loss_mean": 27.17650604248047, "eval/model_loss_std": 24.98699951171875, "eval/post_ent_mag": 54.859161376953125, "eval/post_ent_max": 54.859161376953125, "eval/post_ent_mean": 33.89636993408203, "eval/post_ent_min": 15.702192306518555, "eval/post_ent_std": 6.403908729553223, "eval/prior_ent_mag": 60.2913932800293, "eval/prior_ent_max": 60.2913932800293, "eval/prior_ent_mean": 46.338409423828125, "eval/prior_ent_min": 19.60702896118164, "eval/prior_ent_std": 8.398845672607422, "eval/rep_loss_mean": 15.593157768249512, "eval/rep_loss_std": 8.393691062927246, "eval/reward_avg": 0.005761719308793545, "eval/reward_loss_mean": 0.5079159140586853, "eval/reward_loss_std": 2.8153767585754395, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013129711151123047, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.3458263874053955, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 16.94379997253418, "eval/reward_pred": 0.0009625256061553955, "eval/reward_rate": 0.009765625, "replay/size": 119521.0, "replay/inserts": 19976.0, "replay/samples": 19984.0, "replay/insert_wait_avg": 1.3824601530503596e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.128720976048416e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26392.0, "eval_replay/inserts": 3848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.243147185835174e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5042405128479, "timer/env.step_count": 2497.0, "timer/env.step_total": 237.17593026161194, "timer/env.step_frac": 0.2370563968225043, "timer/env.step_avg": 0.09498435332863914, "timer/env.step_min": 0.022768735885620117, "timer/env.step_max": 3.2611489295959473, "timer/replay._sample_count": 19984.0, "timer/replay._sample_total": 10.437455177307129, "timer/replay._sample_frac": 0.010432194842029854, "timer/replay._sample_avg": 0.0005222905913384271, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.01213216781616211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2978.0, "timer/agent.policy_total": 49.033671379089355, "timer/agent.policy_frac": 0.04900895907643051, "timer/agent.policy_avg": 0.01646530267934498, "timer/agent.policy_min": 0.009706735610961914, "timer/agent.policy_max": 0.1233663558959961, "timer/dataset_train_count": 1249.0, "timer/dataset_train_total": 0.14349818229675293, "timer/dataset_train_frac": 0.00014342586116696245, "timer/dataset_train_avg": 0.00011489045820396551, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010771751403808594, "timer/agent.train_count": 1249.0, "timer/agent.train_total": 563.8758697509766, "timer/agent.train_frac": 0.5635916839912041, "timer/agent.train_avg": 0.4514618652930157, "timer/agent.train_min": 0.4395275115966797, "timer/agent.train_max": 0.5770401954650879, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47391438484191895, "timer/agent.report_frac": 0.0004736755384454897, "timer/agent.report_avg": 0.23695719242095947, "timer/agent.report_min": 0.22812342643737793, "timer/agent.report_max": 0.24579095840454102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.407667397196366e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 19.965679967264922}
{"step": 120216, "time": 6369.785388946533, "episode/length": 195.0, "episode/score": 0.19564710542545072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19564710542545072}
{"step": 120800, "time": 6393.698613643646, "episode/length": 180.0, "episode/score": 0.2019056564076891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2019056564076891}
{"step": 120840, "time": 6396.63161277771, "episode/length": 209.0, "episode/score": 0.23371160240640165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23371160240640165}
{"step": 120976, "time": 6403.685252666473, "episode/length": 156.0, "episode/score": 0.15217875386042579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15217875386042579}
{"step": 121016, "time": 6407.175797224045, "episode/length": 187.0, "episode/score": 0.20822493782179663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20822493782179663}
{"step": 121184, "time": 6415.971541881561, "episode/length": 231.0, "episode/score": 0.2523414916577167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2523414916577167}
{"step": 121312, "time": 6423.060846567154, "episode/length": 195.0, "episode/score": 0.21892527776617499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21892527776617499}
{"step": 121536, "time": 6433.814362049103, "episode/length": 210.0, "episode/score": 0.2123390642900631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2123390642900631}
{"step": 122048, "time": 6456.21298289299, "episode/length": 228.0, "episode/score": 0.24832885911382618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24832885911382618}
{"step": 122184, "time": 6462.70764875412, "episode/length": 108.0, "episode/score": 0.12105576040630694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12105576040630694}
{"step": 122288, "time": 6468.4898335933685, "episode/length": 180.0, "episode/score": 0.1785935079869887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785935079869887}
{"step": 122552, "time": 6479.691764116287, "episode/length": 170.0, "episode/score": 0.17479006852772727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17479006852772727}
{"step": 122632, "time": 6484.263197898865, "episode/length": 201.0, "episode/score": 0.213709813807327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.213709813807327}
{"step": 122744, "time": 6490.015772819519, "episode/length": 220.0, "episode/score": 0.23130103178755235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23130103178755235}
{"step": 123480, "time": 6520.683663368225, "episode/length": 242.0, "episode/score": 0.2633229801003836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2633229801003836}
{"step": 123512, "time": 6523.509250640869, "episode/length": 338.0, "episode/score": 0.3817956418124595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3817956418124595}
{"step": 123776, "time": 6535.39679980278, "episode/length": 152.0, "episode/score": 0.15904818396666087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15904818396666087}
{"step": 123896, "time": 6541.221566438675, "episode/length": 213.0, "episode/score": 0.23037043275235192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23037043275235192}
{"step": 123912, "time": 6543.474343061447, "episode/length": 159.0, "episode/score": 0.16701214276326937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16701214276326937}
{"step": 124192, "time": 6555.924151420593, "episode/length": 237.0, "episode/score": 0.275605403492591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.275605403492591}
{"step": 124416, "time": 6566.011210680008, "episode/length": 208.0, "episode/score": 0.2124575507486952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2124575507486952}
{"step": 124520, "time": 6571.384578943253, "episode/length": 308.0, "episode/score": 0.3358621493762257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3358621493762257}
{"step": 124864, "time": 6586.430954456329, "episode/length": 172.0, "episode/score": 0.17917930156909279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17917930156909279}
{"step": 125064, "time": 6595.383671283722, "episode/length": 193.0, "episode/score": 0.20628654275424196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20628654275424196}
{"step": 125240, "time": 6603.634077787399, "episode/length": 165.0, "episode/score": 0.19437244602158898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19437244602158898}
{"step": 125400, "time": 6611.189589500427, "episode/length": 202.0, "episode/score": 0.20187976346460346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20187976346460346}
{"step": 125448, "time": 6614.642463445663, "episode/length": 193.0, "episode/score": 0.21568646195009933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21568646195009933}
{"step": 125784, "time": 6629.088901281357, "episode/length": 157.0, "episode/score": 0.1504851011941355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1504851011941355}
{"step": 125896, "time": 6635.480124235153, "episode/length": 212.0, "episode/score": 0.22484999982225418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22484999982225418}
{"step": 125960, "time": 6639.381871938705, "episode/length": 89.0, "episode/score": 0.09522265656687523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09522265656687523}
{"step": 126472, "time": 6660.257386684418, "episode/length": 175.0, "episode/score": 0.1871489089107854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871489089107854}
{"step": 126608, "time": 6667.10342502594, "episode/length": 217.0, "episode/score": 0.24915841376878234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24915841376878234}
{"step": 126648, "time": 6669.915877580643, "episode/length": 155.0, "episode/score": 0.1825397550883281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1825397550883281}
{"step": 126896, "time": 6681.287377119064, "episode/length": 180.0, "episode/score": 0.18938431892638619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18938431892638619}
{"step": 127128, "time": 6691.5157198905945, "episode/length": 153.0, "episode/score": 0.16913657758323097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16913657758323097}
{"step": 127168, "time": 6694.833700895309, "episode/length": 172.0, "episode/score": 0.16620909876155565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16620909876155565}
{"step": 127280, "time": 6700.532739400864, "episode/length": 164.0, "episode/score": 0.17600270220737002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17600270220737002}
{"step": 127384, "time": 6705.919640302658, "episode/length": 370.0, "episode/score": 0.3533343997555676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3533343997555676}
{"step": 128128, "time": 6735.885819196701, "episode/length": 184.0, "episode/score": 0.19959559484323108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19959559484323108}
{"step": 128152, "time": 6738.255318164825, "episode/length": 192.0, "episode/score": 0.20884855665008217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20884855665008217}
{"step": 128248, "time": 6743.542142152786, "episode/length": 168.0, "episode/score": 0.15343541226275192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15343541226275192}
{"step": 128288, "time": 6746.841961622238, "episode/length": 226.0, "episode/score": 0.2512731760148199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2512731760148199}
{"step": 128544, "time": 6758.242341756821, "episode/length": 157.0, "episode/score": 0.15686630593654627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15686630593654627}
{"step": 128776, "time": 6768.403838634491, "episode/length": 200.0, "episode/score": 0.19629305943681175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19629305943681175}
{"step": 128944, "time": 6776.485085725784, "episode/length": 194.0, "episode/score": 0.20825675003561628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20825675003561628}
{"step": 129200, "time": 6787.59957575798, "episode/length": 133.0, "episode/score": 0.16070651854124662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16070651854124662}
{"step": 129624, "time": 6804.952072381973, "episode/length": 183.0, "episode/score": 0.1863641384766197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1863641384766197}
{"step": 129680, "time": 6808.905620574951, "episode/length": 173.0, "episode/score": 0.1752949088013338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1752949088013338}
{"step": 129688, "time": 6810.555872678757, "episode/length": 179.0, "episode/score": 0.20501292179187658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20501292179187658}
{"step": 129840, "time": 6818.038160085678, "episode/length": 338.0, "episode/score": 0.39047219633994246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39047219633994246}
{"step": 130000, "time": 6844.598552465439, "eval_episode/length": 140.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 130000, "time": 6846.302186965942, "eval_episode/length": 144.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 130000, "time": 6848.10693025589, "eval_episode/length": 148.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 130000, "time": 6849.978872537613, "eval_episode/length": 152.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 130000, "time": 6852.091270685196, "eval_episode/length": 162.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 130000, "time": 6853.850481748581, "eval_episode/length": 166.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9880239520958084}
{"step": 130000, "time": 6857.496946811676, "eval_episode/length": 210.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.985781990521327}
{"step": 130000, "time": 6860.060838222504, "eval_episode/length": 232.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 130160, "time": 6866.054906845093, "episode/length": 151.0, "episode/score": 0.15994714100179408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15994714100179408}
{"step": 130256, "time": 6871.196907520294, "episode/length": 213.0, "episode/score": 0.21979638530638113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21979638530638113}
{"step": 130408, "time": 6878.217998981476, "episode/length": 203.0, "episode/score": 0.20760534736928093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20760534736928093}
{"step": 130528, "time": 6884.690871953964, "episode/length": 165.0, "episode/score": 0.16784174479516878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16784174479516878}
{"step": 131464, "time": 6923.75895857811, "episode/length": 162.0, "episode/score": 0.15414060874627467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15414060874627467}
{"step": 131472, "time": 6925.901232004166, "episode/length": 151.0, "episode/score": 0.1747946397808846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1747946397808846}
{"step": 131496, "time": 6928.2855134010315, "episode/length": 206.0, "episode/score": 0.2155505205018926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2155505205018926}
{"step": 131512, "time": 6930.421054124832, "episode/length": 228.0, "episode/score": 0.24289523187508166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24289523187508166}
{"step": 131544, "time": 6933.204994916916, "episode/length": 231.0, "episode/score": 0.25007925395948405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25007925395948405}
{"step": 131736, "time": 6942.070808887482, "episode/length": 165.0, "episode/score": 0.16480365008101217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16480365008101217}
{"step": 132056, "time": 6955.868780612946, "episode/length": 303.0, "episode/score": 0.32229642067022723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32229642067022723}
{"step": 132256, "time": 6965.230387926102, "episode/length": 215.0, "episode/score": 0.23756276833455559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23756276833455559}
{"step": 132712, "time": 6983.814616918564, "episode/length": 149.0, "episode/score": 0.15830854723390075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15830854723390075}
{"step": 132744, "time": 6986.621649980545, "episode/length": 149.0, "episode/score": 0.17255917444708757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17255917444708757}
{"step": 133040, "time": 7000.240540504456, "episode/length": 162.0, "episode/score": 0.172146338722996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.172146338722996}
{"step": 133088, "time": 7003.716774225235, "episode/length": 198.0, "episode/score": 0.22310698930277795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22310698930277795}
{"step": 133096, "time": 7005.493088722229, "episode/length": 203.0, "episode/score": 0.1988431121449139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1988431121449139}
{"step": 133152, "time": 7009.426987409592, "episode/length": 209.0, "episode/score": 0.2012999117760046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2012999117760046}
{"step": 133488, "time": 7023.58910036087, "episode/length": 153.0, "episode/score": 0.16014126384470728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16014126384470728}
{"step": 133584, "time": 7028.688435316086, "episode/length": 190.0, "episode/score": 0.1995953884966184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1995953884966184}
{"step": 134304, "time": 7057.4840965271, "episode/length": 198.0, "episode/score": 0.1938456244720328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1938456244720328}
{"step": 134488, "time": 7065.953392267227, "episode/length": 173.0, "episode/score": 0.17663364232976164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17663364232976164}
{"step": 134608, "time": 7072.37726688385, "episode/length": 181.0, "episode/score": 0.18422168015285934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18422168015285934}
{"step": 134864, "time": 7083.997030258179, "episode/length": 227.0, "episode/score": 0.26301076705340165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26301076705340165}
{"step": 134904, "time": 7087.324828386307, "episode/length": 176.0, "episode/score": 0.1991539009304688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1991539009304688}
{"step": 134904, "time": 7087.333474159241, "episode/length": 226.0, "episode/score": 0.2326471172264064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2326471172264064}
{"step": 134936, "time": 7092.151483774185, "episode/length": 273.0, "episode/score": 0.2771488166049494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2771488166049494}
{"step": 134952, "time": 7094.40802693367, "episode/length": 170.0, "episode/score": 0.16794646126845691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16794646126845691}
{"step": 135336, "time": 7110.435634851456, "episode/length": 105.0, "episode/score": 0.11665398162904239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11665398162904239}
{"step": 136040, "time": 7138.647096633911, "episode/length": 141.0, "episode/score": 0.16052262563948716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16052262563948716}
{"step": 136176, "time": 7145.605918884277, "episode/length": 152.0, "episode/score": 0.15667627259608707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15667627259608707}
{"step": 136192, "time": 7147.863116979599, "episode/length": 235.0, "episode/score": 0.23586230106593575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23586230106593575}
{"step": 136480, "time": 7160.644376039505, "episode/length": 192.0, "episode/score": 0.218204500220736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.218204500220736}
{"step": 136528, "time": 7164.42494726181, "episode/length": 239.0, "episode/score": 0.25785694774867807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25785694774867807}
{"step": 136552, "time": 7166.649266719818, "episode/length": 210.0, "episode/score": 0.23619522638296075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23619522638296075}
{"step": 136632, "time": 7171.121061086655, "episode/length": 161.0, "episode/score": 0.15865168543837171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15865168543837171}
{"step": 136976, "time": 7186.445684909821, "episode/length": 258.0, "episode/score": 0.2974672273144279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2974672273144279}
{"step": 137304, "time": 7200.083315849304, "episode/length": 140.0, "episode/score": 0.15947160251266723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15947160251266723}
{"step": 137408, "time": 7205.770668268204, "episode/length": 151.0, "episode/score": 0.15487244038922654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15487244038922654}
{"step": 137488, "time": 7210.27569437027, "episode/length": 119.0, "episode/score": 0.1363848850935483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1363848850935483}
{"step": 137512, "time": 7212.486810684204, "episode/length": 183.0, "episode/score": 0.19194379590726385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19194379590726385}
{"step": 137912, "time": 7229.350904941559, "episode/length": 159.0, "episode/score": 0.15940856544852977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15940856544852977}
{"step": 138136, "time": 7239.287533283234, "episode/length": 206.0, "episode/score": 0.21574778506510484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21574778506510484}
{"step": 138248, "time": 7245.1769416332245, "episode/length": 158.0, "episode/score": 0.1629878032963461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1629878032963461}
{"step": 138328, "time": 7249.793038606644, "episode/length": 221.0, "episode/score": 0.23859767147541788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23859767147541788}
{"step": 138864, "time": 7271.6301963329315, "episode/length": 171.0, "episode/score": 0.18334305445046084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18334305445046084}
{"step": 139056, "time": 7280.483725309372, "episode/length": 218.0, "episode/score": 0.25025337419924654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25025337419924654}
{"step": 139136, "time": 7285.122419118881, "episode/length": 152.0, "episode/score": 0.1714425477111945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714425477111945}
{"step": 139256, "time": 7291.101507902145, "episode/length": 217.0, "episode/score": 0.2514128404745861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2514128404745861}
{"step": 139376, "time": 7298.776109457016, "episode/length": 245.0, "episode/score": 0.2717073639191767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2717073639191767}
{"step": 139408, "time": 7301.559031486511, "episode/length": 158.0, "episode/score": 0.18336927767086308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18336927767086308}
{"step": 139848, "time": 7319.328043937683, "episode/length": 73.0, "episode/score": 0.08221856591990218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08221856591990218}
{"step": 139920, "time": 7323.679442644119, "episode/length": 208.0, "episode/score": 0.21998371521476656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21998371521476656}
{"step": 139976, "time": 7327.0649654865265, "episode/length": 205.0, "episode/score": 0.23027418518904597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23027418518904597}
{"step": 140088, "time": 7356.552269697189, "eval_episode/length": 149.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.96}
{"step": 140088, "time": 7358.453473567963, "eval_episode/length": 154.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 140088, "time": 7360.683933019638, "eval_episode/length": 168.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 140088, "time": 7362.653905391693, "eval_episode/length": 177.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 140088, "time": 7365.230625152588, "eval_episode/length": 197.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 140088, "time": 7367.238609075546, "eval_episode/length": 206.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 140088, "time": 7370.343822956085, "eval_episode/length": 240.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.983402489626556}
{"step": 140088, "time": 7373.063576936722, "eval_episode/length": 265.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.981203007518797}
{"step": 140089, "time": 7374.117774963379, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.83541455078125, "train/action_min": 0.0, "train/action_std": 4.868293506622314, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005301684295758605, "train/actor_opt_grad_steps": 8030.0, "train/actor_opt_loss": -11.548816814541818, "train/adv_mag": 0.1350037776827812, "train/adv_max": 0.07681400233507156, "train/adv_mean": -9.135479799442692e-05, "train/adv_min": -0.13451777213811875, "train/adv_std": 0.010782786060124635, "train/cont_avg": 0.9946171875, "train/cont_loss_mean": 0.000581905567103604, "train/cont_loss_std": 0.01632849850237835, "train/cont_neg_acc": 0.9791809544563294, "train/cont_neg_loss": 0.06724914173078286, "train/cont_pos_acc": 0.9999214248657227, "train/cont_pos_loss": 0.00023527550743494884, "train/cont_pred": 0.994620174407959, "train/cont_rate": 0.9946171875, "train/dyn_loss_mean": 14.172368019104004, "train/dyn_loss_std": 7.350573875427246, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1905238142311573, "train/extr_critic_critic_opt_grad_steps": 8030.0, "train/extr_critic_critic_opt_loss": 9105.56221484375, "train/extr_critic_mag": 0.24306052780151366, "train/extr_critic_max": 0.24306052780151366, "train/extr_critic_mean": 0.17888102030754088, "train/extr_critic_min": 0.013047749519348145, "train/extr_critic_std": 0.05120825070142746, "train/extr_return_normed_mag": 0.1757251980304718, "train/extr_return_normed_max": 0.1757251980304718, "train/extr_return_normed_mean": 0.11465142756700515, "train/extr_return_normed_min": -0.06302432045340538, "train/extr_return_normed_std": 0.05237644797563553, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.239863431930542, "train/extr_return_raw_max": 0.239863431930542, "train/extr_return_raw_mean": 0.1787896671295166, "train/extr_return_raw_min": 0.0011139135360717773, "train/extr_return_raw_std": 0.05237644788622856, "train/extr_reward_mag": 0.0014173517227172852, "train/extr_reward_max": 0.0014173517227172852, "train/extr_reward_mean": 0.0010903339814394713, "train/extr_reward_min": 7.050514221191406e-06, "train/extr_reward_std": 0.0002401008971501142, "train/image_loss_mean": 12.159150909423827, "train/image_loss_std": 14.025832427978516, "train/model_loss_mean": 20.702377227783202, "train/model_loss_std": 16.883752487182615, "train/model_opt_grad_norm": 94.77231535339355, "train/model_opt_grad_steps": 8018.152, "train/model_opt_loss": 10451.1891171875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 505.0, "train/policy_entropy_mag": 2.7599808826446535, "train/policy_entropy_max": 2.7599808826446535, "train/policy_entropy_mean": 2.1189847221374514, "train/policy_entropy_min": 0.12973061925172805, "train/policy_entropy_std": 0.5384401144981384, "train/policy_logprob_mag": 7.417108367919922, "train/policy_logprob_max": -0.017454728931188584, "train/policy_logprob_mean": -2.118921977043152, "train/policy_logprob_min": -7.417108367919922, "train/policy_logprob_std": 1.1397798757553101, "train/policy_randomness_mag": 0.9741521339416503, "train/policy_randomness_max": 0.9741521339416503, "train/policy_randomness_mean": 0.7479086155891419, "train/policy_randomness_min": 0.04578921534121037, "train/policy_randomness_std": 0.19004573225975036, "train/post_ent_mag": 50.939888916015626, "train/post_ent_max": 50.939888916015626, "train/post_ent_mean": 34.641099304199216, "train/post_ent_min": 18.209216819763185, "train/post_ent_std": 5.6236210060119625, "train/prior_ent_mag": 61.25227444458008, "train/prior_ent_max": 61.25227444458008, "train/prior_ent_mean": 49.006961822509766, "train/prior_ent_min": 22.316843521118162, "train/prior_ent_std": 6.09652262878418, "train/rep_loss_mean": 14.172368019104004, "train/rep_loss_std": 7.350573875427246, "train/reward_avg": 0.0010358830634504556, "train/reward_loss_mean": 0.03922350937128067, "train/reward_loss_std": 0.012253950640559197, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013482789993286132, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03922350949048996, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010354451322928072, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.43653842692191785, "train_stats/max_log_achievement_collect_drink": 0.4423076923076923, "train_stats/max_log_achievement_collect_sapling": 0.6057692307692307, "train_stats/max_log_achievement_collect_wood": 0.22115384615384615, "train_stats/max_log_achievement_defeat_skeleton": 0.009615384615384616, "train_stats/max_log_achievement_eat_cow": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.33653846153846156, "train_stats/max_log_achievement_place_table": 0.028846153846153848, "train_stats/max_log_achievement_wake_up": 0.07692307692307693, "train_stats/mean_log_entropy": 2.17859780559173, "eval_stats/sum_log_reward": 0.41249998193234205, "eval_stats/max_log_achievement_collect_drink": 0.375, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.1285917935310863e-05, "report/cont_loss_std": 0.000272231554845348, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.412791405338794e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0961047337332275e-05, "report/cont_pred": 0.9960832595825195, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.191852569580078, "report/dyn_loss_std": 7.079422473907471, "report/image_loss_mean": 12.30495834350586, "report/image_loss_std": 13.058099746704102, "report/model_loss_mean": 21.461326599121094, "report/model_loss_std": 15.806259155273438, "report/post_ent_mag": 53.48552703857422, "report/post_ent_max": 53.48552703857422, "report/post_ent_mean": 34.82461929321289, "report/post_ent_min": 16.622861862182617, "report/post_ent_std": 5.121192455291748, "report/prior_ent_mag": 62.692115783691406, "report/prior_ent_max": 62.692115783691406, "report/prior_ent_mean": 49.89625930786133, "report/prior_ent_min": 24.14666748046875, "report/prior_ent_std": 5.391839504241943, "report/rep_loss_mean": 15.191852569580078, "report/rep_loss_std": 7.079422473907471, "report/reward_avg": 0.0010966333793476224, "report/reward_loss_mean": 0.04124581068754196, "report/reward_loss_std": 0.010559248737990856, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012704133987426758, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04124581068754196, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001057538902387023, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0029810441192239523, "eval/cont_loss_std": 0.09493152797222137, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.6100165843963623, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.459899633322493e-06, "eval/cont_pred": 0.9960551261901855, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.19069480895996, "eval/dyn_loss_std": 9.063312530517578, "eval/image_loss_mean": 24.80795669555664, "eval/image_loss_std": 29.91554832458496, "eval/model_loss_mean": 35.64366149902344, "eval/model_loss_std": 33.29940414428711, "eval/post_ent_mag": 48.742713928222656, "eval/post_ent_max": 48.742713928222656, "eval/post_ent_mean": 34.02398681640625, "eval/post_ent_min": 18.08507537841797, "eval/post_ent_std": 5.281405925750732, "eval/prior_ent_mag": 62.692115783691406, "eval/prior_ent_max": 62.692115783691406, "eval/prior_ent_mean": 46.9326286315918, "eval/prior_ent_min": 20.850353240966797, "eval/prior_ent_std": 8.387088775634766, "eval/rep_loss_mean": 17.19069480895996, "eval/rep_loss_std": 9.063312530517578, "eval/reward_avg": 0.00996093824505806, "eval/reward_loss_mean": 0.5183071494102478, "eval/reward_loss_std": 2.8772261142730713, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012557506561279297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.285421222448349, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 17.319364547729492, "eval/reward_pred": 0.0008711093105375767, "eval/reward_rate": 0.013671875, "replay/size": 139585.0, "replay/inserts": 20064.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.3797001785448674e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.285063264472633e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30384.0, "eval_replay/inserts": 3992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2691369754279067e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1011.375364780426, "timer/env.step_count": 2508.0, "timer/env.step_total": 235.36490750312805, "timer/env.step_frac": 0.23271765923844387, "timer/env.step_avg": 0.09384565689917386, "timer/env.step_min": 0.02288055419921875, "timer/env.step_max": 3.6369850635528564, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 10.604942083358765, "timer/replay._sample_frac": 0.010485663832301416, "timer/replay._sample_avg": 0.0005285557258452335, "timer/replay._sample_min": 0.00038361549377441406, "timer/replay._sample_max": 0.02271580696105957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3007.0, "timer/agent.policy_total": 50.059858083724976, "timer/agent.policy_frac": 0.04949681377160416, "timer/agent.policy_avg": 0.01664777455394911, "timer/agent.policy_min": 0.009584426879882812, "timer/agent.policy_max": 0.11156725883483887, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.1410684585571289, "timer/dataset_train_frac": 0.0001394818021771328, "timer/dataset_train_avg": 0.00011249478353838031, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010788440704345703, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 568.9028148651123, "timer/agent.train_frac": 0.5625041252499002, "timer/agent.train_avg": 0.4536705062720194, "timer/agent.train_min": 0.43762826919555664, "timer/agent.train_max": 1.1027336120605469, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47373199462890625, "timer/agent.report_frac": 0.0004684037313206215, "timer/agent.report_avg": 0.23686599731445312, "timer/agent.report_min": 0.2304689884185791, "timer/agent.report_max": 0.24326300621032715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.182449296231253e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 19.838061649498645}
{"step": 140336, "time": 7383.425399065018, "episode/length": 159.0, "episode/score": 0.18318987616657978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18318987616657978}
{"step": 140360, "time": 7385.703462839127, "episode/length": 186.0, "episode/score": 0.2123786138909054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2123786138909054}
{"step": 140680, "time": 7399.42020201683, "episode/length": 192.0, "episode/score": 0.21368163976148935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21368163976148935}
{"step": 140704, "time": 7402.064908981323, "episode/length": 161.0, "episode/score": 0.17481964996113675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17481964996113675}
{"step": 140712, "time": 7403.741468906403, "episode/length": 91.0, "episode/score": 0.09187107336765621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09187107336765621}
{"step": 141104, "time": 7420.36859536171, "episode/length": 156.0, "episode/score": 0.17219266664687893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17219266664687893}
{"step": 141624, "time": 7441.3448138237, "episode/length": 157.0, "episode/score": 0.15712944850019994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15712944850019994}
{"step": 141744, "time": 7447.74880194664, "episode/length": 295.0, "episode/score": 0.3190725242966437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3190725242966437}
{"step": 141840, "time": 7452.974509477615, "episode/length": 239.0, "episode/score": 0.2514680945314467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2514680945314467}
{"step": 141896, "time": 7456.515665531158, "episode/length": 194.0, "episode/score": 0.23068118101582513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23068118101582513}
{"step": 142024, "time": 7462.902813196182, "episode/length": 164.0, "episode/score": 0.1771799348953209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1771799348953209}
{"step": 142240, "time": 7472.863254070282, "episode/length": 194.0, "episode/score": 0.21700165966649365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21700165966649365}
{"step": 142912, "time": 7499.658757209778, "episode/length": 274.0, "episode/score": 0.29915685324158403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29915685324158403}
{"step": 142960, "time": 7503.017042160034, "episode/length": 139.0, "episode/score": 0.15860605790294358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15860605790294358}
{"step": 143248, "time": 7515.427586317062, "episode/length": 168.0, "episode/score": 0.1699357011802931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1699357011802931}
{"step": 143296, "time": 7518.868975877762, "episode/length": 193.0, "episode/score": 0.23233740136674896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23233740136674896}
{"step": 143320, "time": 7521.013360500336, "episode/length": 211.0, "episode/score": 0.2383853533774527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2383853533774527}
{"step": 143480, "time": 7528.558555603027, "episode/length": 64.0, "episode/score": 0.06954576217322028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06954576217322028}
{"step": 143560, "time": 7533.121134757996, "episode/length": 306.0, "episode/score": 0.33664700392546365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33664700392546365}
{"step": 143592, "time": 7535.8555560112, "episode/length": 195.0, "episode/score": 0.21037626715769875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21037626715769875}
{"step": 143840, "time": 7547.07648730278, "episode/length": 199.0, "episode/score": 0.20979859243016108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20979859243016108}
{"step": 144576, "time": 7576.136024951935, "episode/length": 136.0, "episode/score": 0.1685416630934924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1685416630934924}
{"step": 144688, "time": 7581.888685464859, "episode/length": 221.0, "episode/score": 0.24640591286879499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24640591286879499}
{"step": 144848, "time": 7589.663985013962, "episode/length": 193.0, "episode/score": 0.2220638987928396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2220638987928396}
{"step": 144856, "time": 7591.879905223846, "episode/length": 191.0, "episode/score": 0.1937084068540571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1937084068540571}
{"step": 144992, "time": 7599.195380449295, "episode/length": 217.0, "episode/score": 0.24431375389758614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24431375389758614}
{"step": 145016, "time": 7601.497763156891, "episode/length": 181.0, "episode/score": 0.19544674062035483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19544674062035483}
{"step": 145160, "time": 7608.538421630859, "episode/length": 164.0, "episode/score": 0.1866902103938628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1866902103938628}
{"step": 145288, "time": 7614.902362585068, "episode/length": 88.0, "episode/score": 0.09497593116793723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09497593116793723}
{"step": 145544, "time": 7626.056564092636, "episode/length": 243.0, "episode/score": 0.24723323056332447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24723323056332447}
{"step": 146120, "time": 7649.100029706955, "episode/length": 158.0, "episode/score": 0.19333332940004766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19333332940004766}
{"step": 146384, "time": 7660.715703010559, "episode/length": 173.0, "episode/score": 0.19965751938798348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19965751938798348}
{"step": 146400, "time": 7662.857013463974, "episode/length": 192.0, "episode/score": 0.20119982167943817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20119982167943817}
{"step": 146440, "time": 7665.866831064224, "episode/length": 218.0, "episode/score": 0.2393167562850067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2393167562850067}
{"step": 146496, "time": 7669.711423397064, "episode/length": 184.0, "episode/score": 0.20751051432398526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20751051432398526}
{"step": 146704, "time": 7679.144264936447, "episode/length": 176.0, "episode/score": 0.20785416271246504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20785416271246504}
{"step": 146912, "time": 7688.324912071228, "episode/length": 218.0, "episode/score": 0.24756755324779078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24756755324779078}
{"step": 147424, "time": 7709.108592271805, "episode/length": 234.0, "episode/score": 0.24380304616897774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24380304616897774}
{"step": 148000, "time": 7733.624049425125, "episode/length": 201.0, "episode/score": 0.22860108475288143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22860108475288143}
{"step": 148056, "time": 7737.01873922348, "episode/length": 168.0, "episode/score": 0.18760116890916834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18760116890916834}
{"step": 148200, "time": 7744.016672372818, "episode/length": 219.0, "episode/score": 0.2529822555870851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2529822555870851}
{"step": 148256, "time": 7747.852963685989, "episode/length": 167.0, "episode/score": 0.19797584565640136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19797584565640136}
{"step": 148312, "time": 7751.329385042191, "episode/length": 226.0, "episode/score": 0.2612243173562092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2612243173562092}
{"step": 148432, "time": 7757.6271686553955, "episode/length": 253.0, "episode/score": 0.27112601843236916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27112601843236916}
{"step": 148832, "time": 7774.056458473206, "episode/length": 175.0, "episode/score": 0.19973548862162716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19973548862162716}
{"step": 149072, "time": 7784.660006523132, "episode/length": 368.0, "episode/score": 0.40193625939718913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40193625939718913}
{"step": 149384, "time": 7797.507332086563, "episode/length": 140.0, "episode/score": 0.16123214006074704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16123214006074704}
{"step": 149432, "time": 7800.947865009308, "episode/length": 171.0, "episode/score": 0.19871378331754386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19871378331754386}
{"step": 149448, "time": 7803.046262741089, "episode/length": 155.0, "episode/score": 0.17778731682028592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17778731682028592}
{"step": 149576, "time": 7809.351493835449, "episode/length": 196.0, "episode/score": 0.22301919002711657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22301919002711657}
{"step": 150000, "time": 7827.050556898117, "episode/length": 210.0, "episode/score": 0.23816374448506394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23816374448506394}
{"step": 150016, "time": 7829.250963449478, "episode/length": 197.0, "episode/score": 0.21910297021440783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21910297021440783}
{"step": 150072, "time": 7851.955830335617, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 150072, "time": 7854.9980273246765, "eval_episode/length": 188.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 150072, "time": 7856.8692278862, "eval_episode/length": 195.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 150072, "time": 7858.4959580898285, "eval_episode/length": 196.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 150072, "time": 7860.569433927536, "eval_episode/length": 209.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 150072, "time": 7862.5200572013855, "eval_episode/length": 218.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 150072, "time": 7864.141748905182, "eval_episode/length": 221.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 150072, "time": 7867.173951625824, "eval_episode/length": 239.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 150136, "time": 7870.320718765259, "episode/length": 162.0, "episode/score": 0.1582104457411333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1582104457411333}
{"step": 150624, "time": 7890.432243108749, "episode/length": 193.0, "episode/score": 0.20201270843062957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20201270843062957}
{"step": 150632, "time": 7892.001953125, "episode/length": 155.0, "episode/score": 0.17302545548500348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17302545548500348}
{"step": 151048, "time": 7909.021916389465, "episode/length": 201.0, "episode/score": 0.19724652031527512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19724652031527512}
{"step": 151120, "time": 7913.42843413353, "episode/length": 192.0, "episode/score": 0.21304363446597563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21304363446597563}
{"step": 151344, "time": 7923.414132595062, "episode/length": 165.0, "episode/score": 0.17600664607653016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17600664607653016}
{"step": 151488, "time": 7930.243625402451, "episode/length": 254.0, "episode/score": 0.2955876640317001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2955876640317001}
{"step": 151536, "time": 7933.544983148575, "episode/length": 174.0, "episode/score": 0.18871667090934352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18871667090934352}
{"step": 151560, "time": 7935.849623441696, "episode/length": 194.0, "episode/score": 0.17623590082712326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17623590082712326}
{"step": 152344, "time": 7966.626923084259, "episode/length": 214.0, "episode/score": 0.2229454425246331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2229454425246331}
{"step": 152520, "time": 7974.743009567261, "episode/length": 235.0, "episode/score": 0.24601744557139682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24601744557139682}
{"step": 152640, "time": 7981.027177333832, "episode/length": 161.0, "episode/score": 0.17923191023101026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17923191023101026}
{"step": 152880, "time": 7991.70010972023, "episode/length": 164.0, "episode/score": 0.16443011593037227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16443011593037227}
{"step": 153064, "time": 8000.060162782669, "episode/length": 251.0, "episode/score": 0.2722676541752662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2722676541752662}
{"step": 153248, "time": 8008.830376625061, "episode/length": 219.0, "episode/score": 0.22710925487763234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22710925487763234}
{"step": 153464, "time": 8018.170751094818, "episode/length": 102.0, "episode/score": 0.1065331785575836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1065331785575836}
{"step": 153640, "time": 8026.2903707027435, "episode/length": 161.0, "episode/score": 0.1731035153643461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731035153643461}
{"step": 153808, "time": 8034.322749376297, "episode/length": 160.0, "episode/score": 0.163438401032181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.163438401032181}
{"step": 154344, "time": 8055.611480951309, "episode/length": 402.0, "episode/score": 0.4085218973546034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4085218973546034}
{"step": 154392, "time": 8059.092947721481, "episode/length": 356.0, "episode/score": 0.3855464699749973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3855464699749973}
{"step": 154552, "time": 8066.686822414398, "episode/length": 162.0, "episode/score": 0.17290351331757847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17290351331757847}
{"step": 154736, "time": 8075.289412021637, "episode/length": 208.0, "episode/score": 0.2264238842690247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2264238842690247}
{"step": 154856, "time": 8081.149309873581, "episode/length": 246.0, "episode/score": 0.260367089373176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.260367089373176}
{"step": 155016, "time": 8088.899266719818, "episode/length": 193.0, "episode/score": 0.2267742018084391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2267742018084391}
{"step": 155608, "time": 8113.024844408035, "episode/length": 224.0, "episode/score": 0.24216251453981386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24216251453981386}
{"step": 155752, "time": 8121.62194943428, "episode/length": 126.0, "episode/score": 0.14673516133188969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14673516133188969}
{"step": 155840, "time": 8126.791571855545, "episode/length": 160.0, "episode/score": 0.15786007829592563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15786007829592563}
{"step": 156000, "time": 8134.196542739868, "episode/length": 206.0, "episode/score": 0.2176598736186861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2176598736186861}
{"step": 156152, "time": 8141.230296373367, "episode/length": 161.0, "episode/score": 0.17071056399436202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17071056399436202}
{"step": 156352, "time": 8150.60135436058, "episode/length": 338.0, "episode/score": 0.3815044807852246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3815044807852246}
{"step": 156416, "time": 8154.677706480026, "episode/length": 174.0, "episode/score": 0.2033349321282003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2033349321282003}
{"step": 156464, "time": 8158.063813686371, "episode/length": 258.0, "episode/score": 0.2909604024607688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2909604024607688}
{"step": 157232, "time": 8188.578181505203, "episode/length": 184.0, "episode/score": 0.21744326822954463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21744326822954463}
{"step": 157440, "time": 8198.01848077774, "episode/length": 228.0, "episode/score": 0.257526975703513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.257526975703513}
{"step": 157696, "time": 8209.396445035934, "episode/length": 167.0, "episode/score": 0.18469094740066794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18469094740066794}
{"step": 157792, "time": 8214.754715204239, "episode/length": 243.0, "episode/score": 0.27031072813042556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27031072813042556}
{"step": 157976, "time": 8223.581200361252, "episode/length": 246.0, "episode/score": 0.2650773399254831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2650773399254831}
{"step": 158024, "time": 8227.350257635117, "episode/length": 233.0, "episode/score": 0.26315768520726124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26315768520726124}
{"step": 158256, "time": 8238.35552406311, "episode/length": 229.0, "episode/score": 0.23030707639918546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23030707639918546}
{"step": 158728, "time": 8257.964625835419, "episode/length": 282.0, "episode/score": 0.28098557092016563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28098557092016563}
{"step": 158816, "time": 8262.991842985153, "episode/length": 197.0, "episode/score": 0.19595310868862725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19595310868862725}
{"step": 158872, "time": 8266.668914794922, "episode/length": 146.0, "episode/score": 0.1536361578873766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1536361578873766}
{"step": 158960, "time": 8272.322678089142, "episode/length": 189.0, "episode/score": 0.19619245776448224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19619245776448224}
{"step": 159072, "time": 8278.100734949112, "episode/length": 159.0, "episode/score": 0.16256776832597097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16256776832597097}
{"step": 159288, "time": 8287.477942705154, "episode/length": 163.0, "episode/score": 0.1717789114518382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1717789114518382}
{"step": 159856, "time": 8311.020876646042, "episode/length": 140.0, "episode/score": 0.1515163532585575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1515163532585575}
{"step": 159976, "time": 8317.56269288063, "episode/length": 243.0, "episode/score": 0.2566132029915025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2566132029915025}
{"step": 160032, "time": 8321.464815616608, "episode/length": 151.0, "episode/score": 0.14417628340288502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14417628340288502}
{"step": 160056, "time": 8341.28583574295, "eval_episode/length": 96.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 160056, "time": 8345.172964334488, "eval_episode/length": 138.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 160056, "time": 8348.604935646057, "eval_episode/length": 165.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 160056, "time": 8350.783195257187, "eval_episode/length": 169.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 160056, "time": 8353.044036626816, "eval_episode/length": 184.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 160056, "time": 8355.298959255219, "eval_episode/length": 197.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 160056, "time": 8357.28592634201, "eval_episode/length": 208.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 160056, "time": 8359.941879272461, "eval_episode/length": 229.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9826086956521739}
{"step": 160112, "time": 8362.270491600037, "episode/length": 154.0, "episode/score": 0.15616494854657503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15616494854657503}
{"step": 160168, "time": 8365.768360853195, "episode/length": 238.0, "episode/score": 0.24066615717492823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24066615717492823}
{"step": 160240, "time": 8370.317355632782, "episode/length": 159.0, "episode/score": 0.17563411861556233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17563411861556233}
{"step": 160272, "time": 8373.200559854507, "episode/length": 149.0, "episode/score": 0.1735090956226486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1735090956226486}
{"step": 160273, "time": 8375.34678530693, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.859649417907234, "train/action_min": 0.0, "train/action_std": 4.834421060216709, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0060472846779180325, "train/actor_opt_grad_steps": 9290.0, "train/actor_opt_loss": -9.307570244383625, "train/adv_mag": 0.13777633375070225, "train/adv_max": 0.08287874691364333, "train/adv_mean": -5.17826528245112e-05, "train/adv_min": -0.13735556579011632, "train/adv_std": 0.0114909404206757, "train/cont_avg": 0.9943174827755905, "train/cont_loss_mean": 0.0004788800024710588, "train/cont_loss_std": 0.013190382720847806, "train/cont_neg_acc": 0.9867141626951262, "train/cont_neg_loss": 0.04059916911934647, "train/cont_pos_acc": 0.9999226425576397, "train/cont_pos_loss": 0.00023190907103097326, "train/cont_pred": 0.9943041059914537, "train/cont_rate": 0.9943174827755905, "train/dyn_loss_mean": 13.993978492856964, "train/dyn_loss_std": 7.451520600656825, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18759932518592032, "train/extr_critic_critic_opt_grad_steps": 9290.0, "train/extr_critic_critic_opt_loss": 8809.206116203248, "train/extr_critic_mag": 0.24142426768625816, "train/extr_critic_max": 0.24142426768625816, "train/extr_critic_mean": 0.1769531838537201, "train/extr_critic_min": 0.008832572013374389, "train/extr_critic_std": 0.05168208003220126, "train/extr_return_normed_mag": 0.17799875198856113, "train/extr_return_normed_max": 0.17799875198856113, "train/extr_return_normed_mean": 0.11625161843271706, "train/extr_return_normed_min": -0.0596062740765688, "train/extr_return_normed_std": 0.05322762980587839, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.23864851739462906, "train/extr_return_raw_max": 0.23864851739462906, "train/extr_return_raw_mean": 0.17690138495343877, "train/extr_return_raw_min": 0.0010434914761640894, "train/extr_return_raw_std": 0.05322762992321037, "train/extr_reward_mag": 0.0014109282981692338, "train/extr_reward_max": 0.0014109282981692338, "train/extr_reward_mean": 0.0010937506133162482, "train/extr_reward_min": 1.03965518981453e-05, "train/extr_reward_std": 0.00023369334180249032, "train/image_loss_mean": 10.53052714490515, "train/image_loss_std": 13.179223897888905, "train/model_loss_mean": 18.966814814590094, "train/model_loss_std": 16.115720223254105, "train/model_opt_grad_norm": 78.76468886728362, "train/model_opt_grad_steps": 9277.0, "train/model_opt_loss": 9604.856141578493, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 506.8897637795276, "train/policy_entropy_mag": 2.761583559156403, "train/policy_entropy_max": 2.761583559156403, "train/policy_entropy_mean": 2.1127051621910153, "train/policy_entropy_min": 0.1386060410245197, "train/policy_entropy_std": 0.5096671792465871, "train/policy_logprob_mag": 7.388140130230761, "train/policy_logprob_max": -0.018729487258031613, "train/policy_logprob_mean": -2.1133741966382726, "train/policy_logprob_min": -7.388140130230761, "train/policy_logprob_std": 1.134598078690176, "train/policy_randomness_mag": 0.9747178066433884, "train/policy_randomness_max": 0.9747178066433884, "train/policy_randomness_mean": 0.7456922136892484, "train/policy_randomness_min": 0.04892184987194895, "train/policy_randomness_std": 0.1798901480483258, "train/post_ent_mag": 52.35134208859421, "train/post_ent_max": 52.35134208859421, "train/post_ent_mean": 35.309055628739, "train/post_ent_min": 19.261968132079115, "train/post_ent_std": 5.8312300922363764, "train/prior_ent_mag": 61.92915245116226, "train/prior_ent_max": 61.92915245116226, "train/prior_ent_mean": 49.52944498737966, "train/prior_ent_min": 24.095089514424483, "train/prior_ent_std": 5.67450891892741, "train/rep_loss_mean": 13.993978492856964, "train/rep_loss_std": 7.451520600656825, "train/reward_avg": 0.0010411111595783765, "train/reward_loss_mean": 0.03942171648496718, "train/reward_loss_std": 0.012089159559663824, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013448966769721564, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0394217163676352, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010405877058753583, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.6384615120119773, "train_stats/max_log_achievement_collect_drink": 0.47115384615384615, "train_stats/max_log_achievement_collect_sapling": 0.7596153846153846, "train_stats/max_log_achievement_collect_wood": 0.41346153846153844, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_sword": 0.009615384615384616, "train_stats/max_log_achievement_place_plant": 0.3173076923076923, "train_stats/max_log_achievement_place_table": 0.04807692307692308, "train_stats/max_log_achievement_wake_up": 0.09615384615384616, "train_stats/mean_log_entropy": 2.1725459649012637, "eval_stats/sum_log_reward": 0.47500000102445483, "eval_stats/max_log_achievement_collect_drink": 0.5625, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.31598348566331e-05, "report/cont_loss_std": 0.0008535055676475167, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009251476149074733, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8783058951376006e-05, "report/cont_pred": 0.9950934648513794, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.161519050598145, "report/dyn_loss_std": 6.960813999176025, "report/image_loss_mean": 8.50169849395752, "report/image_loss_std": 9.650829315185547, "report/model_loss_mean": 17.03847885131836, "report/model_loss_std": 12.189882278442383, "report/post_ent_mag": 52.28974914550781, "report/post_ent_max": 52.28974914550781, "report/post_ent_mean": 34.9658203125, "report/post_ent_min": 16.11553192138672, "report/post_ent_std": 5.536725044250488, "report/prior_ent_mag": 61.90614318847656, "report/prior_ent_max": 61.90614318847656, "report/prior_ent_mean": 49.92359161376953, "report/prior_ent_min": 25.50769805908203, "report/prior_ent_std": 4.757493019104004, "report/rep_loss_mean": 14.161519050598145, "report/rep_loss_std": 6.960813999176025, "report/reward_avg": 0.0010546545963734388, "report/reward_loss_mean": 0.039834849536418915, "report/reward_loss_std": 0.01189628429710865, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013309717178344727, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039834849536418915, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010399939492344856, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.9329361495911144e-05, "eval/cont_loss_std": 0.000590472889598459, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007247892790473998, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.5916899176081643e-05, "eval/cont_pred": 0.9950951337814331, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.493614196777344, "eval/dyn_loss_std": 9.237435340881348, "eval/image_loss_mean": 14.949398040771484, "eval/image_loss_std": 16.477609634399414, "eval/model_loss_mean": 26.816852569580078, "eval/model_loss_std": 20.813526153564453, "eval/post_ent_mag": 49.46530532836914, "eval/post_ent_max": 49.46530532836914, "eval/post_ent_mean": 33.596282958984375, "eval/post_ent_min": 19.46591567993164, "eval/post_ent_std": 5.250424861907959, "eval/prior_ent_mag": 61.90614318847656, "eval/prior_ent_max": 61.90614318847656, "eval/prior_ent_mean": 48.56973648071289, "eval/prior_ent_min": 20.872623443603516, "eval/prior_ent_std": 6.43740177154541, "eval/rep_loss_mean": 18.493614196777344, "eval/rep_loss_std": 9.237435340881348, "eval/reward_avg": 0.007519531063735485, "eval/reward_loss_mean": 0.7712568640708923, "eval/reward_loss_std": 3.559638261795044, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013309717178344727, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.5528866052627563, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 17.75374412536621, "eval/reward_pred": 0.0010199419921264052, "eval/reward_rate": 0.0126953125, "replay/size": 159769.0, "replay/inserts": 20184.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.367871079991084e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.000017754526766e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34144.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.278075766056142e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2024123668671, "timer/env.step_count": 2523.0, "timer/env.step_total": 233.96035742759705, "timer/env.step_frac": 0.23367937845306327, "timer/env.step_avg": 0.0927310176090357, "timer/env.step_min": 0.023102998733520508, "timer/env.step_max": 2.2461750507354736, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 10.219249725341797, "timer/replay._sample_frac": 0.010206976730292968, "timer/replay._sample_avg": 0.0005065052401537369, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.010007381439208984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2993.0, "timer/agent.policy_total": 48.76924419403076, "timer/agent.policy_frac": 0.04871067387736219, "timer/agent.policy_avg": 0.016294435079863268, "timer/agent.policy_min": 0.009281635284423828, "timer/agent.policy_max": 0.13660097122192383, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.13560271263122559, "timer/dataset_train_frac": 0.0001354398580709144, "timer/dataset_train_avg": 0.00010753585458463567, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0004742145538330078, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 566.0633327960968, "timer/agent.train_frac": 0.5653835086732454, "timer/agent.train_avg": 0.44890034321657163, "timer/agent.train_min": 0.43492960929870605, "timer/agent.train_max": 1.0673072338104248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47823095321655273, "timer/agent.report_frac": 0.00047765661299796816, "timer/agent.report_avg": 0.23911547660827637, "timer/agent.report_min": 0.23094868659973145, "timer/agent.report_max": 0.2472822666168213, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.4291043415948886e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 20.15947674065166}
{"step": 160376, "time": 8379.21601843834, "episode/length": 49.0, "episode/score": 0.05545310146681004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05545310146681004}
{"step": 160648, "time": 8390.997336149216, "episode/length": 169.0, "episode/score": 0.17653791458269552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17653791458269552}
{"step": 161184, "time": 8413.160342931747, "episode/length": 165.0, "episode/score": 0.1702553500290378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1702553500290378}
{"step": 161384, "time": 8422.153190612793, "episode/length": 142.0, "episode/score": 0.17106547273579054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17106547273579054}
{"step": 161424, "time": 8425.992913007736, "episode/length": 173.0, "episode/score": 0.19012303493309446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19012303493309446}
{"step": 161464, "time": 8429.25381565094, "episode/length": 168.0, "episode/score": 0.17433672986862803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17433672986862803}
{"step": 161504, "time": 8432.952434778214, "episode/length": 166.0, "episode/score": 0.18590868256615067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18590868256615067}
{"step": 161688, "time": 8441.903330802917, "episode/length": 163.0, "episode/score": 0.1540299019907252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1540299019907252}
{"step": 162064, "time": 8458.640251636505, "episode/length": 74.0, "episode/score": 0.08217378059634939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08217378059634939}
{"step": 162088, "time": 8460.919955253601, "episode/length": 226.0, "episode/score": 0.2673372600120274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2673372600120274}
{"step": 162240, "time": 8468.411890268326, "episode/length": 198.0, "episode/score": 0.20594781093041092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20594781093041092}
{"step": 162512, "time": 8480.64976143837, "episode/length": 165.0, "episode/score": 0.1697004051920885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1697004051920885}
{"step": 162712, "time": 8489.392386436462, "episode/length": 165.0, "episode/score": 0.17280434031272307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17280434031272307}
{"step": 163184, "time": 8509.035747051239, "episode/length": 219.0, "episode/score": 0.22067539946328907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22067539946328907}
{"step": 163384, "time": 8518.490240335464, "episode/length": 161.0, "episode/score": 0.15494902818409173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15494902818409173}
{"step": 163432, "time": 8522.259577989578, "episode/length": 217.0, "episode/score": 0.2606488043384161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2606488043384161}
{"step": 163696, "time": 8534.417167186737, "episode/length": 273.0, "episode/score": 0.2990803797811168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2990803797811168}
{"step": 163752, "time": 8538.315524816513, "episode/length": 188.0, "episode/score": 0.19324761007737834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19324761007737834}
{"step": 164160, "time": 8557.018285274506, "episode/length": 180.0, "episode/score": 0.16931933546584332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16931933546584332}
{"step": 164256, "time": 8562.107517242432, "episode/length": 273.0, "episode/score": 0.29328615447047923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29328615447047923}
{"step": 164552, "time": 8574.475511074066, "episode/length": 170.0, "episode/score": 0.200990417212779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.200990417212779}
{"step": 164704, "time": 8581.860666275024, "episode/length": 164.0, "episode/score": 0.18585355748655275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18585355748655275}
{"step": 164704, "time": 8581.869378566742, "episode/length": 273.0, "episode/score": 0.2937160568417312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2937160568417312}
{"step": 164768, "time": 8587.558239221573, "episode/length": 166.0, "episode/score": 0.17304916502598644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17304916502598644}
{"step": 165512, "time": 8616.744900465012, "episode/length": 226.0, "episode/score": 0.2565013361781894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2565013361781894}
{"step": 165584, "time": 8621.393380880356, "episode/length": 177.0, "episode/score": 0.1874627716829309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1874627716829309}
{"step": 165864, "time": 8633.19707942009, "episode/length": 136.0, "episode/score": 0.14220857243935825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14220857243935825}
{"step": 165928, "time": 8637.142735242844, "episode/length": 171.0, "episode/score": 0.1863888898001278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1863888898001278}
{"step": 166216, "time": 8649.697966814041, "episode/length": 188.0, "episode/score": 0.2113289942294614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2113289942294614}
{"step": 166496, "time": 8662.891231060028, "episode/length": 223.0, "episode/score": 0.23884448871240238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23884448871240238}
{"step": 166832, "time": 8677.599652290344, "episode/length": 321.0, "episode/score": 0.3470709736511708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3470709736511708}
{"step": 166832, "time": 8677.607474803925, "episode/length": 155.0, "episode/score": 0.14721556577205774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14721556577205774}
{"step": 166848, "time": 8681.355122089386, "episode/length": 386.0, "episode/score": 0.3803733129889224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3803733129889224}
{"step": 166928, "time": 8685.957494735718, "episode/length": 176.0, "episode/score": 0.17797108401646256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17797108401646256}
{"step": 167136, "time": 8695.263640165329, "episode/length": 158.0, "episode/score": 0.18493452039547265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18493452039547265}
{"step": 167256, "time": 8701.086672067642, "episode/length": 165.0, "episode/score": 0.15965396273486476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15965396273486476}
{"step": 167624, "time": 8716.328057050705, "episode/length": 86.0, "episode/score": 0.10443749779369682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10443749779369682}
{"step": 167680, "time": 8720.149120092392, "episode/length": 182.0, "episode/score": 0.19521439964410092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19521439964410092}
{"step": 167912, "time": 8730.210114002228, "episode/length": 176.0, "episode/score": 0.1749255167414958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1749255167414958}
{"step": 168112, "time": 8739.498663663864, "episode/length": 157.0, "episode/score": 0.16396825810852533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16396825810852533}
{"step": 168488, "time": 8754.91337299347, "episode/length": 206.0, "episode/score": 0.21454863389226375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21454863389226375}
{"step": 168504, "time": 8757.098259925842, "episode/length": 170.0, "episode/score": 0.16494183018630793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16494183018630793}
{"step": 168656, "time": 8764.552954912186, "episode/length": 174.0, "episode/score": 0.18417713734561403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18417713734561403}
{"step": 169184, "time": 8786.161123275757, "episode/length": 187.0, "episode/score": 0.19401910601072814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19401910601072814}
{"step": 169576, "time": 8802.047946214676, "episode/length": 182.0, "episode/score": 0.187659647460805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187659647460805}
{"step": 169760, "time": 8810.845378637314, "episode/length": 156.0, "episode/score": 0.17407266663485643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17407266663485643}
{"step": 169792, "time": 8813.573092460632, "episode/length": 369.0, "episode/score": 0.3711823372436811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3711823372436811}
{"step": 169888, "time": 8818.70603609085, "episode/length": 153.0, "episode/score": 0.16962462170113213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16962462170113213}
{"step": 169992, "time": 8823.942827224731, "episode/length": 259.0, "episode/score": 0.3078955917849271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3078955917849271}
{"step": 170040, "time": 8848.588314533234, "eval_episode/length": 141.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9577464788732394}
{"step": 170040, "time": 8851.006578922272, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 170040, "time": 8852.889048814774, "eval_episode/length": 170.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 170040, "time": 8854.768513679504, "eval_episode/length": 177.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 170040, "time": 8856.605844974518, "eval_episode/length": 182.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.994535519125683}
{"step": 170040, "time": 8858.663258552551, "eval_episode/length": 197.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 170040, "time": 8862.20412015915, "eval_episode/length": 245.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9878048780487805}
{"step": 170040, "time": 8864.557361125946, "eval_episode/length": 258.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9845559845559846}
{"step": 170248, "time": 8872.218974113464, "episode/length": 219.0, "episode/score": 0.22613313252622902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22613313252622902}
{"step": 170376, "time": 8878.496583938599, "episode/length": 343.0, "episode/score": 0.34344706841329753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34344706841329753}
{"step": 170640, "time": 8890.12587761879, "episode/length": 181.0, "episode/score": 0.19612949110069167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19612949110069167}
{"step": 171088, "time": 8908.28982591629, "episode/length": 165.0, "episode/score": 0.17631739599755747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17631739599755747}
{"step": 171176, "time": 8912.929954767227, "episode/length": 172.0, "episode/score": 0.17358204258698606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17358204258698606}
{"step": 171224, "time": 8916.256355524063, "episode/length": 153.0, "episode/score": 0.15945178377160119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15945178377160119}
{"step": 171232, "time": 8918.29875612259, "episode/length": 206.0, "episode/score": 0.20541258930006734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20541258930006734}
{"step": 171624, "time": 8934.314444541931, "episode/length": 216.0, "episode/score": 0.25100200694578234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25100200694578234}
{"step": 171920, "time": 8947.132020235062, "episode/length": 192.0, "episode/score": 0.18970553298095183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18970553298095183}
{"step": 172072, "time": 8956.361347198486, "episode/length": 55.0, "episode/score": 0.055303717427250376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055303717427250376}
{"step": 172088, "time": 8958.574276447296, "episode/length": 180.0, "episode/score": 0.1788844189363772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1788844189363772}
{"step": 172288, "time": 8967.7855219841, "episode/length": 138.0, "episode/score": 0.16488743475520096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16488743475520096}
{"step": 172376, "time": 8972.437126159668, "episode/length": 160.0, "episode/score": 0.15681480968669348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15681480968669348}
{"step": 172400, "time": 8975.117187023163, "episode/length": 146.0, "episode/score": 0.14856672971473017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14856672971473017}
{"step": 172496, "time": 8980.36741399765, "episode/length": 157.0, "episode/score": 0.16214657937416632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16214657937416632}
{"step": 173360, "time": 9014.284013986588, "episode/length": 179.0, "episode/score": 0.2004839781920964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2004839781920964}
{"step": 173464, "time": 9019.522093057632, "episode/length": 173.0, "episode/score": 0.198595222187123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.198595222187123}
{"step": 173488, "time": 9022.269808530807, "episode/length": 404.0, "episode/score": 0.36559121643449544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36559121643449544}
{"step": 173640, "time": 9029.410041570663, "episode/length": 142.0, "episode/score": 0.15632045004167594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15632045004167594}
{"step": 173720, "time": 9033.944933891296, "episode/length": 167.0, "episode/score": 0.18352357517187556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18352357517187556}
{"step": 174064, "time": 9048.568179130554, "episode/length": 246.0, "episode/score": 0.2804408024608165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2804408024608165}
{"step": 174264, "time": 9057.276070356369, "episode/length": 246.0, "episode/score": 0.2581636252152748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2581636252152748}
{"step": 174632, "time": 9072.443814516068, "episode/length": 278.0, "episode/score": 0.30107165588560747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30107165588560747}
{"step": 174768, "time": 9079.4911403656, "episode/length": 162.0, "episode/score": 0.1732135772545007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1732135772545007}
{"step": 174776, "time": 9081.116328001022, "episode/length": 160.0, "episode/score": 0.16299577580866753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16299577580866753}
{"step": 174808, "time": 9083.9511551857, "episode/length": 180.0, "episode/score": 0.18425906431366457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18425906431366457}
{"step": 175056, "time": 9095.038636446, "episode/length": 176.0, "episode/score": 0.19656145606495556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19656145606495556}
{"step": 175096, "time": 9097.909026145935, "episode/length": 171.0, "episode/score": 0.1869742632334237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1869742632334237}
{"step": 175624, "time": 9119.295532226562, "episode/length": 169.0, "episode/score": 0.18620290152648522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18620290152648522}
{"step": 175632, "time": 9121.486362695694, "episode/length": 195.0, "episode/score": 0.20387402901360474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20387402901360474}
{"step": 175920, "time": 9133.763655424118, "episode/length": 160.0, "episode/score": 0.17768435610742017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17768435610742017}
{"step": 176032, "time": 9139.631811857224, "episode/length": 157.0, "episode/score": 0.16362042557921086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16362042557921086}
{"step": 176088, "time": 9143.14460515976, "episode/length": 159.0, "episode/score": 0.16168375370034482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16168375370034482}
{"step": 176504, "time": 9160.331263303757, "episode/length": 175.0, "episode/score": 0.18232846614773734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18232846614773734}
{"step": 176928, "time": 9178.080308198929, "episode/length": 125.0, "episode/score": 0.14089468475140166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14089468475140166}
{"step": 176976, "time": 9181.459688663483, "episode/length": 110.0, "episode/score": 0.12259112429092056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12259112429092056}
{"step": 177000, "time": 9183.739925384521, "episode/length": 171.0, "episode/score": 0.19588783296421752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19588783296421752}
{"step": 177256, "time": 9194.970859527588, "episode/length": 152.0, "episode/score": 0.16309851402365894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16309851402365894}
{"step": 177256, "time": 9194.980165481567, "episode/length": 309.0, "episode/score": 0.3186656125544687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3186656125544687}
{"step": 177616, "time": 9211.842316627502, "episode/length": 44.0, "episode/score": 0.05008333257865161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05008333257865161}
{"step": 178016, "time": 9228.524100542068, "episode/length": 369.0, "episode/score": 0.3762047956188326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3762047956188326}
{"step": 178024, "time": 9230.307661056519, "episode/length": 189.0, "episode/score": 0.20733020111219957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20733020111219957}
{"step": 178064, "time": 9233.599791526794, "episode/length": 141.0, "episode/score": 0.14935704612435075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14935704612435075}
{"step": 178104, "time": 9236.415681362152, "episode/length": 308.0, "episode/score": 0.3418892840945773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3418892840945773}
{"step": 178216, "time": 9242.15590262413, "episode/length": 151.0, "episode/score": 0.16923192469403148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16923192469403148}
{"step": 178312, "time": 9247.302208900452, "episode/length": 166.0, "episode/score": 0.15507891371817095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15507891371817095}
{"step": 178832, "time": 9268.521802663803, "episode/length": 196.0, "episode/score": 0.1738976773704053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1738976773704053}
{"step": 179000, "time": 9276.063538074493, "episode/length": 172.0, "episode/score": 0.18243176347459666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18243176347459666}
{"step": 179400, "time": 9292.713436126709, "episode/length": 166.0, "episode/score": 0.1734233176903217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1734233176903217}
{"step": 179400, "time": 9292.721177816391, "episode/length": 171.0, "episode/score": 0.18909671775327297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18909671775327297}
{"step": 179480, "time": 9299.010485649109, "episode/length": 171.0, "episode/score": 0.18728433479191153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18728433479191153}
{"step": 180000, "time": 9320.250527620316, "episode/length": 210.0, "episode/score": 0.23806775450429996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23806775450429996}
{"step": 180024, "time": 9341.59157538414, "eval_episode/length": 146.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 180024, "time": 9343.793169498444, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 180024, "time": 9345.553722858429, "eval_episode/length": 163.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 180024, "time": 9347.227337360382, "eval_episode/length": 165.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 180024, "time": 9349.319472312927, "eval_episode/length": 176.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 180024, "time": 9353.432688951492, "eval_episode/length": 219.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 180024, "time": 9355.830070972443, "eval_episode/length": 239.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 180024, "time": 9358.469360589981, "eval_episode/length": 260.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9961685823754789}
{"step": 180040, "time": 9359.06716966629, "episode/length": 227.0, "episode/score": 0.2784999943105504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2784999943105504}
{"step": 180377, "time": 9375.8019759655, "train_stats/sum_log_reward": 0.3254901779925122, "train_stats/max_log_achievement_collect_drink": 0.21568627450980393, "train_stats/max_log_achievement_collect_sapling": 0.5294117647058824, "train_stats/max_log_achievement_collect_wood": 0.20588235294117646, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.00980392156862745, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.24509803921568626, "train_stats/max_log_achievement_place_table": 0.029411764705882353, "train_stats/max_log_achievement_wake_up": 0.35294117647058826, "train_stats/mean_log_entropy": 2.2247414705800077, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.95492138671875, "train/action_min": 0.0, "train/action_std": 4.832610157012939, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006724698627367616, "train/actor_opt_grad_steps": 10550.0, "train/actor_opt_loss": 2.317102339167148, "train/adv_mag": 0.1450950073003769, "train/adv_max": 0.09300778725743294, "train/adv_mean": 0.0004961456187229487, "train/adv_min": -0.14410366600751875, "train/adv_std": 0.012431858610361814, "train/cont_avg": 0.9943515625, "train/cont_loss_mean": 0.0005348088938328602, "train/cont_loss_std": 0.015366733587081398, "train/cont_neg_acc": 0.9839809551239014, "train/cont_neg_loss": 0.05855054373180883, "train/cont_pos_acc": 0.9999371085166932, "train/cont_pos_loss": 0.00022352116116807963, "train/cont_pred": 0.9943498015403748, "train/cont_rate": 0.9943515625, "train/dyn_loss_mean": 13.888024169921875, "train/dyn_loss_std": 7.60749193572998, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1849234116077423, "train/extr_critic_critic_opt_grad_steps": 10550.0, "train/extr_critic_critic_opt_loss": 9708.06631640625, "train/extr_critic_mag": 0.23869109058380128, "train/extr_critic_max": 0.23869109058380128, "train/extr_critic_mean": 0.18588511669635774, "train/extr_critic_min": 0.008011761665344239, "train/extr_critic_std": 0.0527202025949955, "train/extr_return_normed_mag": 0.17977430129051208, "train/extr_return_normed_max": 0.17977430129051208, "train/extr_return_normed_mean": 0.12721806174516678, "train/extr_return_normed_min": -0.05810659757256508, "train/extr_return_normed_std": 0.05453699776530266, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.23893744003772735, "train/extr_return_raw_max": 0.23893744003772735, "train/extr_return_raw_mean": 0.18638120555877685, "train/extr_return_raw_min": 0.0010565404891967774, "train/extr_return_raw_std": 0.05453699754178524, "train/extr_reward_mag": 0.0014131431579589844, "train/extr_reward_max": 0.0014131431579589844, "train/extr_reward_mean": 0.001091048477217555, "train/extr_reward_min": 6.061553955078125e-06, "train/extr_reward_std": 0.00023650318593718112, "train/image_loss_mean": 9.99198564529419, "train/image_loss_std": 12.874622589111327, "train/model_loss_mean": 18.364848068237304, "train/model_loss_std": 15.932073593139648, "train/model_opt_grad_norm": 77.72604336547852, "train/model_opt_grad_steps": 10536.472, "train/model_opt_loss": 14958.9850390625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 815.0, "train/policy_entropy_mag": 2.772920570373535, "train/policy_entropy_max": 2.772920570373535, "train/policy_entropy_mean": 2.151064292907715, "train/policy_entropy_min": 0.11979973101615905, "train/policy_entropy_std": 0.5462101981639862, "train/policy_logprob_mag": 7.395496780395508, "train/policy_logprob_max": -0.015655205987393856, "train/policy_logprob_mean": -2.151680064201355, "train/policy_logprob_min": -7.395496780395508, "train/policy_logprob_std": 1.123984782218933, "train/policy_randomness_mag": 0.9787192749977112, "train/policy_randomness_max": 0.9787192749977112, "train/policy_randomness_mean": 0.7592313041687012, "train/policy_randomness_min": 0.042284047797322276, "train/policy_randomness_std": 0.19278823053836822, "train/post_ent_mag": 52.88370275878906, "train/post_ent_max": 52.88370275878906, "train/post_ent_mean": 35.671277374267575, "train/post_ent_min": 19.197630096435546, "train/post_ent_std": 5.9644254837036135, "train/prior_ent_mag": 62.36460330200195, "train/prior_ent_max": 62.36460330200195, "train/prior_ent_mean": 49.6991318359375, "train/prior_ent_min": 24.15374938964844, "train/prior_ent_std": 5.846325069427491, "train/rep_loss_mean": 13.888024169921875, "train/rep_loss_std": 7.60749193572998, "train/reward_avg": 0.0010443791984580458, "train/reward_loss_mean": 0.03951308375597, "train/reward_loss_std": 0.011868924364447593, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013508367538452148, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0395130840241909, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010453912876546383, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.28749999590218067, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.375, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 2.331152791157365e-05, "report/cont_loss_std": 0.00028860082966275513, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011916644871234894, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0624576134432573e-05, "report/cont_pred": 0.9892601370811462, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 13.173247337341309, "report/dyn_loss_std": 7.561787128448486, "report/image_loss_mean": 10.157523155212402, "report/image_loss_std": 16.97376823425293, "report/model_loss_mean": 18.101350784301758, "report/model_loss_std": 19.53607177734375, "report/post_ent_mag": 55.951812744140625, "report/post_ent_max": 55.951812744140625, "report/post_ent_mean": 37.84916305541992, "report/post_ent_min": 22.38235855102539, "report/post_ent_std": 6.826551914215088, "report/prior_ent_mag": 62.07638931274414, "report/prior_ent_max": 62.07638931274414, "report/prior_ent_mean": 51.134178161621094, "report/prior_ent_min": 27.72979736328125, "report/prior_ent_std": 5.298051357269287, "report/rep_loss_mean": 13.173247337341309, "report/rep_loss_std": 7.561787128448486, "report/reward_avg": 0.0010559693910181522, "report/reward_loss_mean": 0.039856091141700745, "report/reward_loss_std": 0.01183130219578743, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0014215707778930664, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039856091141700745, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001105636009015143, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.109339154936606e-05, "eval/cont_loss_std": 0.00028952924185432494, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010817478178068995, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.998176781460643e-06, "eval/cont_pred": 0.9980400800704956, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.63445281982422, "eval/dyn_loss_std": 10.145363807678223, "eval/image_loss_mean": 20.4222412109375, "eval/image_loss_std": 20.41602325439453, "eval/model_loss_mean": 32.24952697753906, "eval/model_loss_std": 25.098552703857422, "eval/post_ent_mag": 56.42839813232422, "eval/post_ent_max": 56.42839813232422, "eval/post_ent_mean": 36.50914001464844, "eval/post_ent_min": 18.42154312133789, "eval/post_ent_std": 6.739908218383789, "eval/prior_ent_mag": 62.38688278198242, "eval/prior_ent_max": 62.38688278198242, "eval/prior_ent_mean": 51.02934265136719, "eval/prior_ent_min": 24.510421752929688, "eval/prior_ent_std": 6.745485305786133, "eval/rep_loss_mean": 18.63445281982422, "eval/rep_loss_std": 10.145363807678223, "eval/reward_avg": 0.006640624720603228, "eval/reward_loss_mean": 0.6466026306152344, "eval/reward_loss_std": 3.2809910774230957, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013412237167358398, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.456437349319458, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 18.159103393554688, "eval/reward_pred": 0.0010564877884462476, "eval/reward_rate": 0.0107421875, "replay/size": 179873.0, "replay/inserts": 20104.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.367384629376704e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.817646554660115e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38304.0, "eval_replay/inserts": 4160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.227282560788668e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4531707763672, "timer/env.step_count": 2513.0, "timer/env.step_total": 232.8548502922058, "timer/env.step_frac": 0.23274937507720309, "timer/env.step_avg": 0.09266010755758289, "timer/env.step_min": 0.02297234535217285, "timer/env.step_max": 3.3291304111480713, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 10.102001190185547, "timer/replay._sample_frac": 0.010097425332108485, "timer/replay._sample_avg": 0.0005022872509042138, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.009899139404296875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3033.0, "timer/agent.policy_total": 49.50845241546631, "timer/agent.policy_frac": 0.04948602679428461, "timer/agent.policy_avg": 0.016323261594284967, "timer/agent.policy_min": 0.00956416130065918, "timer/agent.policy_max": 0.733201265335083, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.14306855201721191, "timer/dataset_train_frac": 0.00014300374689820664, "timer/dataset_train_avg": 0.00011381746381639771, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010690689086914062, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 564.9145810604095, "timer/agent.train_frac": 0.5646586942415576, "timer/agent.train_avg": 0.44941494117773234, "timer/agent.train_min": 0.43625688552856445, "timer/agent.train_max": 1.1064701080322266, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.466219425201416, "timer/agent.report_frac": 0.0004660082438837417, "timer/agent.report_avg": 0.233109712600708, "timer/agent.report_min": 0.22291803359985352, "timer/agent.report_max": 0.2433013916015625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002713354737513e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 20.094617097631353}
{"step": 180400, "time": 9376.648960113525, "episode/length": 195.0, "episode/score": 0.20789468027214753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20789468027214753}
{"step": 180560, "time": 9384.44595193863, "episode/length": 194.0, "episode/score": 0.20011670319945551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20011670319945551}
{"step": 180712, "time": 9391.556020975113, "episode/length": 163.0, "episode/score": 0.18928507690179686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18928507690179686}
{"step": 180872, "time": 9399.089095115662, "episode/length": 183.0, "episode/score": 0.22083332913462073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22083332913462073}
{"step": 180968, "time": 9404.320368528366, "episode/length": 185.0, "episode/score": 0.20400950641851523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20400950641851523}
{"step": 181120, "time": 9411.682443380356, "episode/length": 387.0, "episode/score": 0.41322386244064546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41322386244064546}
{"step": 181216, "time": 9416.801953554153, "episode/length": 151.0, "episode/score": 0.15220887266696081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15220887266696081}
{"step": 181688, "time": 9435.867012023926, "episode/length": 160.0, "episode/score": 0.17167225151570165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17167225151570165}
{"step": 181856, "time": 9443.892420053482, "episode/length": 226.0, "episode/score": 0.24403781368710042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24403781368710042}
{"step": 181912, "time": 9447.375261545181, "episode/length": 168.0, "episode/score": 0.1788322185893776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1788322185893776}
{"step": 182056, "time": 9454.286759376526, "episode/length": 167.0, "episode/score": 0.1909921219557873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1909921219557873}
{"step": 182088, "time": 9457.022530555725, "episode/length": 151.0, "episode/score": 0.15181359719463217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15181359719463217}
{"step": 182256, "time": 9465.09843659401, "episode/length": 160.0, "episode/score": 0.16787499315432797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16787499315432797}
{"step": 182472, "time": 9474.390098810196, "episode/length": 156.0, "episode/score": 0.15748215176790836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15748215176790836}
{"step": 182544, "time": 9478.854601621628, "episode/length": 177.0, "episode/score": 0.15660433469111013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15660433469111013}
{"step": 183048, "time": 9499.390439510345, "episode/length": 169.0, "episode/score": 0.1796291954588014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1796291954588014}
{"step": 183192, "time": 9507.069463968277, "episode/length": 166.0, "episode/score": 0.1838273755629416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1838273755629416}
{"step": 183448, "time": 9518.780421733856, "episode/length": 148.0, "episode/score": 0.14964817959025822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14964817959025822}
{"step": 183480, "time": 9521.500534534454, "episode/length": 173.0, "episode/score": 0.17256614375219215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17256614375219215}
{"step": 183496, "time": 9523.713821649551, "episode/length": 197.0, "episode/score": 0.2017236621977645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2017236621977645}
{"step": 183672, "time": 9532.628522396088, "episode/length": 201.0, "episode/score": 0.21971297721211158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21971297721211158}
{"step": 183856, "time": 9541.811032533646, "episode/length": 172.0, "episode/score": 0.1871820477399524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871820477399524}
{"step": 184520, "time": 9568.515567541122, "episode/length": 183.0, "episode/score": 0.21905282312127383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21905282312127383}
{"step": 184536, "time": 9571.088359594345, "episode/length": 248.0, "episode/score": 0.2577731669143759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2577731669143759}
{"step": 184584, "time": 9574.94397687912, "episode/length": 173.0, "episode/score": 0.18834668427916768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18834668427916768}
{"step": 184776, "time": 9584.412393331528, "episode/length": 159.0, "episode/score": 0.14664869107855338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14664869107855338}
{"step": 184800, "time": 9587.586460590363, "episode/length": 164.0, "episode/score": 0.18473727192485967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18473727192485967}
{"step": 185160, "time": 9602.819306612015, "episode/length": 162.0, "episode/score": 0.18732211064343574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18732211064343574}
{"step": 185592, "time": 9620.807091712952, "episode/length": 239.0, "episode/score": 0.26275606726085243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26275606726085243}
{"step": 185848, "time": 9631.946602582932, "episode/length": 163.0, "episode/score": 0.15176786343727144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15176786343727144}
{"step": 185864, "time": 9634.061900377274, "episode/length": 167.0, "episode/score": 0.17996329885772866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17996329885772866}
{"step": 185912, "time": 9637.450520515442, "episode/length": 307.0, "episode/score": 0.3380806826908156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3380806826908156}
{"step": 185920, "time": 9639.600151062012, "episode/length": 166.0, "episode/score": 0.17251211285929458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17251211285929458}
{"step": 185992, "time": 9643.628701925278, "episode/length": 148.0, "episode/score": 0.14865487374481745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14865487374481745}
{"step": 186160, "time": 9651.662477493286, "episode/length": 124.0, "episode/score": 0.1423767005580885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1423767005580885}
{"step": 186496, "time": 9665.79613661766, "episode/length": 78.0, "episode/score": 0.08615888108852232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08615888108852232}
{"step": 186528, "time": 9668.540677070618, "episode/length": 218.0, "episode/score": 0.24981761808885494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24981761808885494}
{"step": 186744, "time": 9677.991551160812, "episode/length": 143.0, "episode/score": 0.14831351560405892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14831351560405892}
{"step": 186936, "time": 9686.738868951797, "episode/length": 54.0, "episode/score": 0.05738600187760312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05738600187760312}
{"step": 187280, "time": 9701.368397474289, "episode/length": 169.0, "episode/score": 0.17809607255912852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17809607255912852}
{"step": 187304, "time": 9703.589153289795, "episode/length": 173.0, "episode/score": 0.1964571424505266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1964571424505266}
{"step": 187384, "time": 9708.255285263062, "episode/length": 173.0, "episode/score": 0.1929920719085203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1929920719085203}
{"step": 187472, "time": 9713.33266711235, "episode/length": 163.0, "episode/score": 0.19034940714664117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19034940714664117}
{"step": 187784, "time": 9726.171508073807, "episode/length": 62.0, "episode/score": 0.0760416651610285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0760416651610285}
{"step": 187808, "time": 9728.777215480804, "episode/length": 244.0, "episode/score": 0.26495833806347946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26495833806347946}
{"step": 187920, "time": 9734.692169427872, "episode/length": 173.0, "episode/score": 0.17259358453156892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17259358453156892}
{"step": 188376, "time": 9753.185827255249, "episode/length": 179.0, "episode/score": 0.18874290023813955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18874290023813955}
{"step": 188528, "time": 9762.130970716476, "episode/length": 152.0, "episode/score": 0.15150561350310454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15150561350310454}
{"step": 188552, "time": 9764.51718878746, "episode/length": 134.0, "episode/score": 0.1358281248685671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1358281248685671}
{"step": 188984, "time": 9782.56690120697, "episode/length": 199.0, "episode/score": 0.22743086354603292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22743086354603292}
{"step": 189120, "time": 9789.47556090355, "episode/length": 166.0, "episode/score": 0.1864072234093328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1864072234093328}
{"step": 189168, "time": 9792.876974105835, "episode/length": 155.0, "episode/score": 0.17514095304431976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17514095304431976}
{"step": 189168, "time": 9792.884821653366, "episode/length": 169.0, "episode/score": 0.177317002628115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.177317002628115}
{"step": 189280, "time": 9800.632961273193, "episode/length": 316.0, "episode/score": 0.3758205195335904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3758205195335904}
{"step": 189608, "time": 9814.330796718597, "episode/length": 153.0, "episode/score": 0.15029273696927703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15029273696927703}
{"step": 189864, "time": 9825.579473257065, "episode/length": 166.0, "episode/score": 0.1711684307338146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1711684307338146}
{"step": 189872, "time": 9827.802357673645, "episode/length": 164.0, "episode/score": 0.18669042618421372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18669042618421372}
{"step": 190008, "time": 9850.260813236237, "eval_episode/length": 78.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9493670886075949}
{"step": 190008, "time": 9854.857698917389, "eval_episode/length": 147.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 190008, "time": 9856.516188621521, "eval_episode/length": 148.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 190008, "time": 9858.198528289795, "eval_episode/length": 149.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 190008, "time": 9859.818136930466, "eval_episode/length": 150.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 190008, "time": 9861.674263715744, "eval_episode/length": 157.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 190008, "time": 9863.311679840088, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 190008, "time": 9865.11118221283, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 190416, "time": 9880.51053929329, "episode/length": 155.0, "episode/score": 0.1532869426846446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1532869426846446}
{"step": 190488, "time": 9884.722105026245, "episode/length": 150.0, "episode/score": 0.16979829209958552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16979829209958552}
{"step": 190584, "time": 9889.87477684021, "episode/length": 182.0, "episode/score": 0.19711347275369917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19711347275369917}
{"step": 190760, "time": 9898.00110077858, "episode/length": 221.0, "episode/score": 0.2395373067829496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2395373067829496}
{"step": 190856, "time": 9903.094046354294, "episode/length": 210.0, "episode/score": 0.23274567089720222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23274567089720222}
{"step": 191080, "time": 9912.996611833572, "episode/length": 183.0, "episode/score": 0.19946550376880623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19946550376880623}
{"step": 191088, "time": 9915.146676540375, "episode/length": 151.0, "episode/score": 0.15211483077109733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15211483077109733}
{"step": 191344, "time": 9926.44631934166, "episode/length": 184.0, "episode/score": 0.22291666234377772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22291666234377772}
{"step": 191672, "time": 9940.863638877869, "episode/length": 156.0, "episode/score": 0.16647258197554038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16647258197554038}
{"step": 191808, "time": 9948.401725053787, "episode/length": 164.0, "episode/score": 0.16476488742227957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16476488742227957}
{"step": 192208, "time": 9964.761142015457, "episode/length": 168.0, "episode/score": 0.1642027469642926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1642027469642926}
{"step": 192240, "time": 9967.542113542557, "episode/length": 143.0, "episode/score": 0.1459353077079868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1459353077079868}
{"step": 192432, "time": 9977.042384624481, "episode/length": 168.0, "episode/score": 0.17034690224409132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17034690224409132}
{"step": 192440, "time": 9978.759779691696, "episode/length": 209.0, "episode/score": 0.22552778134559048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22552778134559048}
{"step": 192536, "time": 9983.891893148422, "episode/length": 243.0, "episode/score": 0.2734633090603893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2734633090603893}
{"step": 192640, "time": 9989.54033446312, "episode/length": 161.0, "episode/score": 0.1862656387465904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1862656387465904}
{"step": 192840, "time": 9998.31040596962, "episode/length": 145.0, "episode/score": 0.18124999606516212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18124999606516212}
{"step": 193568, "time": 10027.809643745422, "episode/length": 165.0, "episode/score": 0.16983354719104682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16983354719104682}
{"step": 193704, "time": 10034.283702850342, "episode/length": 158.0, "episode/score": 0.16184800304563396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16184800304563396}
{"step": 193728, "time": 10037.009577274323, "episode/length": 160.0, "episode/score": 0.16979879217888083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16979879217888083}
{"step": 193784, "time": 10040.417331457138, "episode/length": 196.0, "episode/score": 0.20765001196559751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20765001196559751}
{"step": 193856, "time": 10044.882611989975, "episode/length": 255.0, "episode/score": 0.2864884110394996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2864884110394996}
{"step": 194016, "time": 10052.536031007767, "episode/length": 184.0, "episode/score": 0.19952880548589746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19952880548589746}
{"step": 194400, "time": 10068.53347325325, "episode/length": 219.0, "episode/score": 0.23614354577057384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23614354577057384}
{"step": 194416, "time": 10070.66322350502, "episode/length": 196.0, "episode/score": 0.1944524850041489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1944524850041489}
{"step": 194936, "time": 10091.49917292595, "episode/length": 150.0, "episode/score": 0.1414359524860629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1414359524860629}
{"step": 195024, "time": 10096.80659031868, "episode/length": 181.0, "episode/score": 0.19529998232155776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19529998232155776}
{"step": 195032, "time": 10098.851222038269, "episode/length": 146.0, "episode/score": 0.15362049019313417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15362049019313417}
{"step": 195064, "time": 10102.115441799164, "episode/length": 159.0, "episode/score": 0.16993886796262814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16993886796262814}
{"step": 195128, "time": 10106.399262428284, "episode/length": 138.0, "episode/score": 0.1325862295634579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1325862295634579}
{"step": 195312, "time": 10115.088676691055, "episode/length": 113.0, "episode/score": 0.1117987787220045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1117987787220045}
{"step": 195520, "time": 10124.641255378723, "episode/length": 226.0, "episode/score": 0.2470065363231697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2470065363231697}
{"step": 195664, "time": 10131.530871391296, "episode/length": 155.0, "episode/score": 0.1657390849031799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1657390849031799}
{"step": 196224, "time": 10154.063676834106, "episode/length": 144.0, "episode/score": 0.15936835076354328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15936835076354328}
{"step": 196288, "time": 10158.006437540054, "episode/length": 157.0, "episode/score": 0.17971343149474706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17971343149474706}
{"step": 196376, "time": 10162.654070138931, "episode/length": 179.0, "episode/score": 0.19947924376174342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19947924376174342}
{"step": 196416, "time": 10165.936799287796, "episode/length": 172.0, "episode/score": 0.18025055010002689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18025055010002689}
{"step": 196680, "time": 10178.550551891327, "episode/length": 170.0, "episode/score": 0.18688176177420246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18688176177420246}
{"step": 196864, "time": 10187.188839435577, "episode/length": 167.0, "episode/score": 0.17589603372107376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17589603372107376}
{"step": 196952, "time": 10191.924560070038, "episode/length": 160.0, "episode/score": 0.1601548440175975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1601548440175975}
{"step": 197480, "time": 10213.116212844849, "episode/length": 293.0, "episode/score": 0.30986971442689537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30986971442689537}
{"step": 197520, "time": 10216.555965423584, "episode/length": 161.0, "episode/score": 0.16148419697128702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16148419697128702}
{"step": 197568, "time": 10219.966264247894, "episode/length": 159.0, "episode/score": 0.15480570410181826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15480570410181826}
{"step": 197696, "time": 10226.476129770279, "episode/length": 164.0, "episode/score": 0.1708993843931239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1708993843931239}
{"step": 197896, "time": 10235.925462961197, "episode/length": 151.0, "episode/score": 0.15259156456158962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15259156456158962}
{"step": 198176, "time": 10248.210996389389, "episode/length": 163.0, "episode/score": 0.16725132259671227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16725132259671227}
{"step": 198208, "time": 10250.963788986206, "episode/length": 223.0, "episode/score": 0.24219557238393463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24219557238393463}
{"step": 198352, "time": 10257.915697574615, "episode/length": 174.0, "episode/score": 0.16919303327813395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16919303327813395}
{"step": 198696, "time": 10272.024894475937, "episode/length": 146.0, "episode/score": 0.16560653451597318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16560653451597318}
{"step": 198792, "time": 10277.333669662476, "episode/length": 163.0, "episode/score": 0.19045155847925344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19045155847925344}
{"step": 199160, "time": 10292.679957866669, "episode/length": 198.0, "episode/score": 0.21600280513666803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21600280513666803}
{"step": 199464, "time": 10305.640390872955, "episode/length": 156.0, "episode/score": 0.1733685680464987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733685680464987}
{"step": 199480, "time": 10307.901545286179, "episode/length": 162.0, "episode/score": 0.17750194187829038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17750194187829038}
{"step": 199752, "time": 10319.626459360123, "episode/length": 174.0, "episode/score": 0.17870244267760427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17870244267760427}
{"step": 199800, "time": 10323.058797836304, "episode/length": 237.0, "episode/score": 0.27637080825297744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27637080825297744}
{"step": 199912, "time": 10328.679565191269, "episode/length": 151.0, "episode/score": 0.14230124168898328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14230124168898328}
{"step": 199960, "time": 10332.071743965149, "episode/length": 145.0, "episode/score": 0.13364568204269744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13364568204269744}
{"step": 200096, "time": 10360.516459703445, "eval_episode/length": 141.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9577464788732394}
{"step": 200096, "time": 10362.281514406204, "eval_episode/length": 145.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 200096, "time": 10364.73703289032, "eval_episode/length": 163.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 200096, "time": 10367.432029008865, "eval_episode/length": 189.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 200096, "time": 10369.494487762451, "eval_episode/length": 200.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9601990049751243}
{"step": 200096, "time": 10371.325949907303, "eval_episode/length": 207.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 200096, "time": 10374.18057012558, "eval_episode/length": 237.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 200096, "time": 10377.802899360657, "eval_episode/length": 146.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 200097, "time": 10378.395742177963, "train_stats/sum_log_reward": 0.23157893153920509, "train_stats/max_log_achievement_collect_drink": 0.16666666666666666, "train_stats/max_log_achievement_collect_sapling": 0.5, "train_stats/max_log_achievement_collect_wood": 0.21052631578947367, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.008771929824561403, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.24561403508771928, "train_stats/max_log_achievement_place_table": 0.043859649122807015, "train_stats/max_log_achievement_wake_up": 0.23684210526315788, "train_stats/mean_log_entropy": 2.25590797892788, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.995297315644055, "train/action_min": 0.0, "train/action_std": 4.809389265572152, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0071229397648627435, "train/actor_opt_grad_steps": 11790.0, "train/actor_opt_loss": -1.1947026916635715, "train/adv_mag": 0.15469737859760843, "train/adv_max": 0.09860193196350966, "train/adv_mean": 0.000296464189502545, "train/adv_min": -0.15414251387119293, "train/adv_std": 0.013043178082633068, "train/cont_avg": 0.9946805132113821, "train/cont_loss_mean": 0.00028550522686871557, "train/cont_loss_std": 0.007755754921967443, "train/cont_neg_acc": 0.9875822702074438, "train/cont_neg_loss": 0.04447118661228456, "train/cont_pos_acc": 0.9999760277872163, "train/cont_pos_loss": 9.668560206212026e-05, "train/cont_pred": 0.9947094975448236, "train/cont_rate": 0.9946805132113821, "train/dyn_loss_mean": 13.558767838206718, "train/dyn_loss_std": 7.6348060747472255, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17791488348710827, "train/extr_critic_critic_opt_grad_steps": 11790.0, "train/extr_critic_critic_opt_loss": 10890.94691628557, "train/extr_critic_mag": 0.2495393336303835, "train/extr_critic_max": 0.2495393336303835, "train/extr_critic_mean": 0.2010438769328885, "train/extr_critic_min": 0.0076745845438019045, "train/extr_critic_std": 0.054357047215467545, "train/extr_return_normed_mag": 0.18649046886258008, "train/extr_return_normed_max": 0.18649046886258008, "train/extr_return_normed_mean": 0.13784123109123572, "train/extr_return_normed_min": -0.062423772019584, "train/extr_return_normed_std": 0.05633432412050604, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24998960286621155, "train/extr_return_raw_max": 0.24998960286621155, "train/extr_return_raw_mean": 0.2013403680024108, "train/extr_return_raw_min": 0.0010753618023259853, "train/extr_return_raw_std": 0.05633432430222752, "train/extr_reward_mag": 0.0014100917955724205, "train/extr_reward_max": 0.0014100917955724205, "train/extr_reward_mean": 0.0010812712645885058, "train/extr_reward_min": 7.128327842650375e-06, "train/extr_reward_std": 0.0002396000424736914, "train/image_loss_mean": 8.941510487378128, "train/image_loss_std": 12.003884734177008, "train/model_loss_mean": 17.116522750234218, "train/model_loss_std": 15.059875139376013, "train/model_opt_grad_norm": 69.72526863532337, "train/model_opt_grad_steps": 11775.577235772358, "train/model_opt_loss": 13932.139287188771, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 813.0081300813008, "train/policy_entropy_mag": 2.7666732392660003, "train/policy_entropy_max": 2.7666732392660003, "train/policy_entropy_mean": 2.189623209519115, "train/policy_entropy_min": 0.09813121712304712, "train/policy_entropy_std": 0.5406954303020384, "train/policy_logprob_mag": 7.423468380439572, "train/policy_logprob_max": -0.01219350184366955, "train/policy_logprob_mean": -2.188586546153557, "train/policy_logprob_min": -7.423468380439572, "train/policy_logprob_std": 1.0956405643525162, "train/policy_randomness_mag": 0.9765142420443093, "train/policy_randomness_max": 0.9765142420443093, "train/policy_randomness_mean": 0.7728409112953558, "train/policy_randomness_min": 0.03463601325525016, "train/policy_randomness_std": 0.19084175972919154, "train/post_ent_mag": 53.55541027658354, "train/post_ent_max": 53.55541027658354, "train/post_ent_mean": 35.91539910169152, "train/post_ent_min": 19.575576983816255, "train/post_ent_std": 6.071058505918922, "train/prior_ent_mag": 62.69930546458175, "train/prior_ent_max": 62.69930546458175, "train/prior_ent_mean": 49.646672442676575, "train/prior_ent_min": 25.155207114491038, "train/prior_ent_std": 5.7128228831097365, "train/rep_loss_mean": 13.558767838206718, "train/rep_loss_std": 7.6348060747472255, "train/reward_avg": 0.0010433469797726871, "train/reward_loss_mean": 0.039466166732514775, "train/reward_loss_std": 0.011947901109309217, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001339547033232402, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03946616682337552, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010396369905173173, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": -0.025000013411045074, "eval_stats/max_log_achievement_collect_drink": 0.0625, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.3689675799687393e-05, "report/cont_loss_std": 0.0006871967343613505, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00036665922380052507, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1668243789463304e-05, "report/cont_pred": 0.9941214323043823, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.021821975708008, "report/dyn_loss_std": 8.261465072631836, "report/image_loss_mean": 10.848740577697754, "report/image_loss_std": 16.041088104248047, "report/model_loss_mean": 19.901906967163086, "report/model_loss_std": 19.59955406188965, "report/post_ent_mag": 55.6203727722168, "report/post_ent_max": 55.6203727722168, "report/post_ent_mean": 36.493980407714844, "report/post_ent_min": 18.75334358215332, "report/post_ent_std": 5.811709880828857, "report/prior_ent_mag": 62.81087875366211, "report/prior_ent_max": 62.81087875366211, "report/prior_ent_mean": 51.549095153808594, "report/prior_ent_min": 33.77260971069336, "report/prior_ent_std": 5.017871379852295, "report/rep_loss_mean": 15.021821975708008, "report/rep_loss_std": 8.261465072631836, "report/reward_avg": 0.0010563505347818136, "report/reward_loss_mean": 0.04005017876625061, "report/reward_loss_std": 0.010702083818614483, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001295328140258789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04005017876625061, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010753831593319774, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0002620150917209685, "eval/cont_loss_std": 0.007965740747749805, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006051032105460763, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0002610070223454386, "eval/cont_pred": 0.9968410730361938, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.674518585205078, "eval/dyn_loss_std": 9.889999389648438, "eval/image_loss_mean": 18.76211929321289, "eval/image_loss_std": 30.939340591430664, "eval/model_loss_mean": 31.06760025024414, "eval/model_loss_std": 34.568458557128906, "eval/post_ent_mag": 44.81755065917969, "eval/post_ent_max": 44.81755065917969, "eval/post_ent_mean": 33.34516143798828, "eval/post_ent_min": 19.683547973632812, "eval/post_ent_std": 4.760875701904297, "eval/prior_ent_mag": 62.81087875366211, "eval/prior_ent_max": 62.81087875366211, "eval/prior_ent_mean": 49.154972076416016, "eval/prior_ent_min": 20.207393646240234, "eval/prior_ent_std": 6.516173362731934, "eval/rep_loss_mean": 19.674518585205078, "eval/rep_loss_std": 9.889999389648438, "eval/reward_avg": 0.01054687425494194, "eval/reward_loss_mean": 0.5005086064338684, "eval/reward_loss_std": 2.9304702281951904, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013053417205810547, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.2692923843860626, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 18.482017517089844, "eval/reward_pred": 0.0009760900866240263, "eval/reward_rate": 0.0126953125, "replay/size": 199593.0, "replay/inserts": 19720.0, "replay/samples": 19712.0, "replay/insert_wait_avg": 1.3839763269946734e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.388797377611135e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 41928.0, "eval_replay/inserts": 3624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4377482416350848e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.5795884132385, "timer/env.step_count": 2465.0, "timer/env.step_total": 251.90367579460144, "timer/env.step_frac": 0.25125553991507454, "timer/env.step_avg": 0.10219216056576123, "timer/env.step_min": 0.023017406463623047, "timer/env.step_max": 3.5888590812683105, "timer/replay._sample_count": 19712.0, "timer/replay._sample_total": 9.637545824050903, "timer/replay._sample_frac": 0.009612748888399018, "timer/replay._sample_avg": 0.0004889177061714135, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.007787227630615234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2918.0, "timer/agent.policy_total": 47.56025147438049, "timer/agent.policy_frac": 0.04743788126551937, "timer/agent.policy_avg": 0.016298920998759594, "timer/agent.policy_min": 0.009278297424316406, "timer/agent.policy_max": 0.1030268669128418, "timer/dataset_train_count": 1232.0, "timer/dataset_train_total": 0.13928556442260742, "timer/dataset_train_frac": 0.00013892718945440703, "timer/dataset_train_avg": 0.00011305646462873979, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010745525360107422, "timer/agent.train_count": 1232.0, "timer/agent.train_total": 554.8873381614685, "timer/agent.train_frac": 0.5534596400867057, "timer/agent.train_avg": 0.45039556668950365, "timer/agent.train_min": 0.4352736473083496, "timer/agent.train_max": 0.9790441989898682, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46225571632385254, "timer/agent.report_frac": 0.00046106635489702604, "timer/agent.report_avg": 0.23112785816192627, "timer/agent.report_min": 0.22005748748779297, "timer/agent.report_max": 0.24219822883605957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.281710928115797e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 19.669028611866164}
{"step": 200136, "time": 10379.969485759735, "episode/length": 304.0, "episode/score": 0.35620315933192614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35620315933192614}
{"step": 200576, "time": 10398.15514588356, "episode/length": 138.0, "episode/score": 0.15538212646606553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15538212646606553}
{"step": 200952, "time": 10413.713111639023, "episode/length": 143.0, "episode/score": 0.1602665871323552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1602665871323552}
{"step": 201144, "time": 10423.13630247116, "episode/length": 247.0, "episode/score": 0.28705664649169194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28705664649169194}
{"step": 201184, "time": 10426.514741420746, "episode/length": 152.0, "episode/score": 0.15267821092129452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15267821092129452}
{"step": 201280, "time": 10431.683560848236, "episode/length": 170.0, "episode/score": 0.17757387061283225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17757387061283225}
{"step": 201520, "time": 10442.080514431, "episode/length": 46.0, "episode/score": 0.0479546124333865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0479546124333865}
{"step": 201608, "time": 10446.785457849503, "episode/length": 183.0, "episode/score": 0.21315089717973024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21315089717973024}
{"step": 201616, "time": 10449.320430278778, "episode/length": 266.0, "episode/score": 0.309368790469307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.309368790469307}
{"step": 201768, "time": 10456.932333946228, "episode/length": 251.0, "episode/score": 0.27927700727741467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27927700727741467}
{"step": 201872, "time": 10463.174591302872, "episode/length": 161.0, "episode/score": 0.1671706717752386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1671706717752386}
{"step": 202208, "time": 10477.819371461868, "episode/length": 156.0, "episode/score": 0.16005025573031162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16005025573031162}
{"step": 202568, "time": 10492.65553188324, "episode/length": 160.0, "episode/score": 0.1720357964914001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1720357964914001}
{"step": 202568, "time": 10492.663647413254, "episode/length": 99.0, "episode/score": 0.12145833089016378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12145833089016378}
{"step": 202832, "time": 10506.01344370842, "episode/length": 163.0, "episode/score": 0.16340139746534987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16340139746534987}
{"step": 202936, "time": 10511.242496013641, "episode/length": 218.0, "episode/score": 0.25425832872497267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25425832872497267}
{"step": 203016, "time": 10515.941314220428, "episode/length": 142.0, "episode/score": 0.15768630984894116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15768630984894116}
{"step": 203176, "time": 10523.577811956406, "episode/length": 195.0, "episode/score": 0.1898829802921682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898829802921682}
{"step": 203512, "time": 10537.527892112732, "episode/length": 162.0, "episode/score": 0.16124149084134842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16124149084134842}
{"step": 203608, "time": 10543.226323366165, "episode/length": 248.0, "episode/score": 0.29366215385744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29366215385744}
{"step": 203760, "time": 10551.111040830612, "episode/length": 148.0, "episode/score": 0.15223092869564425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15223092869564425}
{"step": 203920, "time": 10558.566044092178, "episode/length": 112.0, "episode/score": 0.11680712673842208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11680712673842208}
{"step": 203944, "time": 10560.822394371033, "episode/length": 171.0, "episode/score": 0.17578535088614444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17578535088614444}
{"step": 204240, "time": 10573.727470874786, "episode/length": 162.0, "episode/score": 0.17839442860713461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17839442860713461}
{"step": 204752, "time": 10594.950001478195, "episode/length": 239.0, "episode/score": 0.26238350870698923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26238350870698923}
{"step": 204920, "time": 10604.75104355812, "episode/length": 163.0, "episode/score": 0.1777702264189429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1777702264189429}
{"step": 204952, "time": 10607.996587991714, "episode/length": 179.0, "episode/score": 0.17816922982456163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17816922982456163}
{"step": 205024, "time": 10612.97049999237, "episode/length": 230.0, "episode/score": 0.26032087768180645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26032087768180645}
{"step": 205088, "time": 10617.336872816086, "episode/length": 165.0, "episode/score": 0.1656041097085108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1656041097085108}
{"step": 205320, "time": 10627.863870620728, "episode/length": 174.0, "episode/score": 0.19157664043450495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19157664043450495}
{"step": 205496, "time": 10636.141055822372, "episode/length": 193.0, "episode/score": 0.1731714891429874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731714891429874}
{"step": 205552, "time": 10640.057599544525, "episode/length": 163.0, "episode/score": 0.14925779261466232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14925779261466232}
{"step": 205872, "time": 10654.010341405869, "episode/length": 139.0, "episode/score": 0.16769230441423133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16769230441423133}
{"step": 206136, "time": 10665.240545511246, "episode/length": 151.0, "episode/score": 0.14562768126234005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14562768126234005}
{"step": 206216, "time": 10669.711870193481, "episode/length": 148.0, "episode/score": 0.16600679344992386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16600679344992386}
{"step": 206344, "time": 10676.053172111511, "episode/length": 156.0, "episode/score": 0.1632399000809528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1632399000809528}
{"step": 206368, "time": 10678.830529928207, "episode/length": 176.0, "episode/score": 0.1909197832992504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1909197832992504}
{"step": 206824, "time": 10697.086014986038, "episode/length": 165.0, "episode/score": 0.18411066550288524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18411066550288524}
{"step": 206936, "time": 10702.76492023468, "episode/length": 172.0, "episode/score": 0.17474845938522776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17474845938522776}
{"step": 207288, "time": 10717.440520524979, "episode/length": 143.0, "episode/score": 0.16786689396030852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16786689396030852}
{"step": 207296, "time": 10719.521466493607, "episode/length": 246.0, "episode/score": 0.2633707735039934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2633707735039934}
{"step": 207560, "time": 10730.651909351349, "episode/length": 167.0, "episode/score": 0.17087744293530704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17087744293530704}
{"step": 207592, "time": 10733.572016239166, "episode/length": 152.0, "episode/score": 0.1576164382022398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1576164382022398}
{"step": 207608, "time": 10735.783789157867, "episode/length": 216.0, "episode/score": 0.22991641304906807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22991641304906807}
{"step": 207680, "time": 10740.208094358444, "episode/length": 166.0, "episode/score": 0.1561196335569548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1561196335569548}
{"step": 208040, "time": 10754.992654561996, "episode/length": 151.0, "episode/score": 0.15807084545031103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15807084545031103}
{"step": 208488, "time": 10773.19266796112, "episode/length": 193.0, "episode/score": 0.20891226313142397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20891226313142397}
{"step": 208616, "time": 10779.527198553085, "episode/length": 164.0, "episode/score": 0.17918948143869784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17918948143869784}
{"step": 208712, "time": 10784.725553035736, "episode/length": 143.0, "episode/score": 0.15493046321535076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15493046321535076}
{"step": 208768, "time": 10788.57012295723, "episode/length": 184.0, "episode/score": 0.21281341310896096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21281341310896096}
{"step": 208888, "time": 10794.255688905716, "episode/length": 150.0, "episode/score": 0.15719619616629643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15719619616629643}
{"step": 208920, "time": 10796.940750837326, "episode/length": 163.0, "episode/score": 0.14352285264612874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14352285264612874}
{"step": 209072, "time": 10804.360862731934, "episode/length": 184.0, "episode/score": 0.20288611110663624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20288611110663624}
{"step": 209672, "time": 10828.035981416702, "episode/length": 203.0, "episode/score": 0.22958764113263896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22958764113263896}
{"step": 209712, "time": 10831.314654111862, "episode/length": 98.0, "episode/score": 0.11895833094604313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11895833094604313}
{"step": 209840, "time": 10837.698470115662, "episode/length": 168.0, "episode/score": 0.1944026323290018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1944026323290018}
{"step": 209968, "time": 10844.217539548874, "episode/length": 168.0, "episode/score": 0.18416291074936453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18416291074936453}
{"step": 210008, "time": 10846.992858886719, "episode/length": 154.0, "episode/score": 0.16892716778784234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16892716778784234}
{"step": 210024, "time": 10849.161485433578, "episode/length": 163.0, "episode/score": 0.18452410650752427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18452410650752427}
{"step": 210080, "time": 10869.420679330826, "eval_episode/length": 85.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9418604651162791}
{"step": 210080, "time": 10873.679358005524, "eval_episode/length": 148.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 210080, "time": 10875.949927091599, "eval_episode/length": 159.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.99375}
{"step": 210080, "time": 10877.561519622803, "eval_episode/length": 161.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 210080, "time": 10879.188341379166, "eval_episode/length": 164.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 210080, "time": 10880.868480205536, "eval_episode/length": 166.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 210080, "time": 10880.875372171402, "eval_episode/length": 166.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 210080, "time": 10884.471301317215, "eval_episode/length": 172.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 210384, "time": 10895.97535777092, "episode/length": 163.0, "episode/score": 0.14646409382021375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14646409382021375}
{"step": 210536, "time": 10903.441472053528, "episode/length": 205.0, "episode/score": 0.20857100578359677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20857100578359677}
{"step": 210832, "time": 10916.164788246155, "episode/length": 144.0, "episode/score": 0.15417416951822815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15417416951822815}
{"step": 211184, "time": 10930.666500806808, "episode/length": 151.0, "episode/score": 0.1520602575110388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1520602575110388}
{"step": 211376, "time": 10939.425341844559, "episode/length": 191.0, "episode/score": 0.1855713773147727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1855713773147727}
{"step": 211392, "time": 10941.582340478897, "episode/length": 170.0, "episode/score": 0.18499316511588404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18499316511588404}
{"step": 211560, "time": 10949.325190544128, "episode/length": 230.0, "episode/score": 0.25019961944781244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25019961944781244}
{"step": 211672, "time": 10955.693556070328, "episode/length": 160.0, "episode/score": 0.1733159055984288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733159055984288}
{"step": 211736, "time": 10960.070460319519, "episode/length": 149.0, "episode/score": 0.15656467057124246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15656467057124246}
{"step": 211824, "time": 10965.853924512863, "episode/length": 226.0, "episode/score": 0.25128435302030994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25128435302030994}
{"step": 212248, "time": 10983.707411050797, "episode/length": 176.0, "episode/score": 0.1989529607744771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1989529607744771}
{"step": 212472, "time": 10993.455212116241, "episode/length": 160.0, "episode/score": 0.17805958578537684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17805958578537684}
{"step": 212680, "time": 11002.927399873734, "episode/length": 160.0, "episode/score": 0.16930719076299283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16930719076299283}
{"step": 212688, "time": 11005.55169725418, "episode/length": 163.0, "episode/score": 0.173359514290496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.173359514290496}
{"step": 212736, "time": 11009.372589588165, "episode/length": 146.0, "episode/score": 0.1561172586898465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1561172586898465}
{"step": 213080, "time": 11025.59696483612, "episode/length": 175.0, "episode/score": 0.19018515204697906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19018515204697906}
{"step": 213096, "time": 11027.790947437286, "episode/length": 158.0, "episode/score": 0.18049662636985886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18049662636985886}
{"step": 213104, "time": 11029.793197393417, "episode/length": 170.0, "episode/score": 0.20021748851468146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20021748851468146}
{"step": 213512, "time": 11046.140826702118, "episode/length": 157.0, "episode/score": 0.1861485814788466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1861485814788466}
{"step": 213536, "time": 11048.90754699707, "episode/length": 132.0, "episode/score": 0.12786134643829428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12786134643829428}
{"step": 213992, "time": 11067.160154104233, "episode/length": 162.0, "episode/score": 0.16910066128366452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16910066128366452}
{"step": 214000, "time": 11069.254835605621, "episode/length": 157.0, "episode/score": 0.15886986073746812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15886986073746812}
{"step": 214176, "time": 11077.366758584976, "episode/length": 186.0, "episode/score": 0.19459256893424026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19459256893424026}
{"step": 214408, "time": 11087.36303472519, "episode/length": 165.0, "episode/score": 0.16915064431486826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16915064431486826}
{"step": 214424, "time": 11089.551201820374, "episode/length": 164.0, "episode/score": 0.17471867036692856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17471867036692856}
{"step": 214536, "time": 11095.366023302078, "episode/length": 179.0, "episode/score": 0.20125331892813847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20125331892813847}
{"step": 214600, "time": 11099.740663290024, "episode/length": 135.0, "episode/score": 0.15225827865833708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15225827865833708}
{"step": 214656, "time": 11104.075479269028, "episode/length": 139.0, "episode/score": 0.14540781408686598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14540781408686598}
{"step": 214928, "time": 11116.507540225983, "episode/length": 40.0, "episode/score": 0.0446053914638469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0446053914638469}
{"step": 215304, "time": 11132.378435134888, "episode/length": 163.0, "episode/score": 0.1751666837008088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1751666837008088}
{"step": 215336, "time": 11135.202714443207, "episode/length": 166.0, "episode/score": 0.16655424233613303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16655424233613303}
{"step": 215528, "time": 11143.834979057312, "episode/length": 168.0, "episode/score": 0.1826275554840322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1826275554840322}
{"step": 215680, "time": 11151.38840675354, "episode/length": 158.0, "episode/score": 0.16870211786954314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16870211786954314}
{"step": 215776, "time": 11156.487548351288, "episode/length": 168.0, "episode/score": 0.17395354955806397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17395354955806397}
{"step": 215816, "time": 11159.281737565994, "episode/length": 144.0, "episode/score": 0.17053954146103933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17053954146103933}
{"step": 215864, "time": 11162.575405597687, "episode/length": 165.0, "episode/score": 0.17885614701481245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17885614701481245}
{"step": 216200, "time": 11176.686630010605, "episode/length": 41.0, "episode/score": 0.04431693217338761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04431693217338761}
{"step": 216232, "time": 11179.566757202148, "episode/length": 162.0, "episode/score": 0.178503928176724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.178503928176724}
{"step": 216400, "time": 11187.569738864899, "episode/length": 72.0, "episode/score": 0.07339332711217139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07339332711217139}
{"step": 216640, "time": 11198.051831245422, "episode/length": 166.0, "episode/score": 0.1695444854321977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1695444854321977}
{"step": 216776, "time": 11204.69465303421, "episode/length": 155.0, "episode/score": 0.16216343861287896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16216343861287896}
{"step": 216944, "time": 11212.616641283035, "episode/length": 157.0, "episode/score": 0.16561916761384055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16561916761384055}
{"step": 217144, "time": 11221.403433322906, "episode/length": 170.0, "episode/score": 0.1752761267725873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1752761267725873}
{"step": 217200, "time": 11225.316188097, "episode/length": 232.0, "episode/score": 0.27343055041274056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27343055041274056}
{"step": 217576, "time": 11240.687041521072, "episode/length": 167.0, "episode/score": 0.15625571074360778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15625571074360778}
{"step": 217656, "time": 11245.336762189865, "episode/length": 63.0, "episode/score": 0.05551461356662912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05551461356662912}
{"step": 217944, "time": 11257.576598882675, "episode/length": 217.0, "episode/score": 0.24542145381565206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24542145381565206}
{"step": 218144, "time": 11266.929225444794, "episode/length": 187.0, "episode/score": 0.1834061480140008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1834061480140008}
{"step": 218328, "time": 11274.918294429779, "episode/length": 193.0, "episode/score": 0.18810171979566803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18810171979566803}
{"step": 218584, "time": 11285.91843175888, "episode/length": 172.0, "episode/score": 0.1708177614491433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1708177614491433}
{"step": 218664, "time": 11290.428694486618, "episode/length": 282.0, "episode/score": 0.3099594248451467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3099594248451467}
{"step": 218792, "time": 11296.851143836975, "episode/length": 151.0, "episode/score": 0.17365956978210306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17365956978210306}
{"step": 218880, "time": 11302.552198648453, "episode/length": 241.0, "episode/score": 0.26877313221848453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26877313221848453}
{"step": 219272, "time": 11318.914564847946, "episode/length": 165.0, "episode/score": 0.19308332999935374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19308332999935374}
{"step": 219752, "time": 11338.291362285614, "episode/length": 145.0, "episode/score": 0.1550168715766631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1550168715766631}
{"step": 220008, "time": 11349.339322805405, "episode/length": 167.0, "episode/score": 0.17276230321840558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17276230321840558}
{"step": 220064, "time": 11372.452905654907, "eval_episode/length": 148.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 220064, "time": 11374.804651498795, "eval_episode/length": 166.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 220064, "time": 11376.620977401733, "eval_episode/length": 170.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 220064, "time": 11378.17249917984, "eval_episode/length": 171.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 220064, "time": 11380.64294052124, "eval_episode/length": 192.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 220064, "time": 11382.411706209183, "eval_episode/length": 193.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 220064, "time": 11385.00237250328, "eval_episode/length": 214.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 220064, "time": 11387.568353891373, "eval_episode/length": 237.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9747899159663865}
{"step": 220065, "time": 11388.174207925797, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.00828759765625, "train/action_min": 0.0, "train/action_std": 4.826653629302979, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0071169503554701806, "train/actor_opt_grad_steps": 13030.0, "train/actor_opt_loss": -10.503471151590347, "train/adv_mag": 0.15969396781921386, "train/adv_max": 0.10380224388837814, "train/adv_mean": -0.0001518383865477517, "train/adv_min": -0.15879227203130722, "train/adv_std": 0.013147514432668686, "train/cont_avg": 0.994640625, "train/cont_loss_mean": 0.00042047753774022566, "train/cont_loss_std": 0.011834658011521242, "train/cont_neg_acc": 0.982352382183075, "train/cont_neg_loss": 0.03817737989545822, "train/cont_pos_acc": 0.9999528460502625, "train/cont_pos_loss": 0.00021157554020791736, "train/cont_pred": 0.9946556954383851, "train/cont_rate": 0.994640625, "train/dyn_loss_mean": 13.578866928100586, "train/dyn_loss_std": 7.7575127868652345, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19436361955106257, "train/extr_critic_critic_opt_grad_steps": 13030.0, "train/extr_critic_critic_opt_loss": 11296.689265625, "train/extr_critic_mag": 0.2607175426483154, "train/extr_critic_max": 0.2607175426483154, "train/extr_critic_mean": 0.2065385032892227, "train/extr_critic_min": 0.005399918556213379, "train/extr_critic_std": 0.0595584152340889, "train/extr_return_normed_mag": 0.2060020990371704, "train/extr_return_normed_max": 0.2060020990371704, "train/extr_return_normed_mean": 0.1515317153930664, "train/extr_return_normed_min": -0.053808104515075686, "train/extr_return_normed_std": 0.06145830848813057, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2608570861816406, "train/extr_return_raw_max": 0.2608570861816406, "train/extr_return_raw_mean": 0.20638670766353606, "train/extr_return_raw_min": 0.0010468826293945313, "train/extr_return_raw_std": 0.06145830872654915, "train/extr_reward_mag": 0.0014316911697387696, "train/extr_reward_max": 0.0014316911697387696, "train/extr_reward_mean": 0.0010861134007573128, "train/extr_reward_min": 7.517814636230469e-06, "train/extr_reward_std": 0.0002380951860686764, "train/image_loss_mean": 8.545518650054932, "train/image_loss_std": 12.04049136352539, "train/model_loss_mean": 16.73304451751709, "train/model_loss_std": 15.188571960449218, "train/model_opt_grad_norm": 70.21838121032715, "train/model_opt_grad_steps": 13015.0, "train/model_opt_loss": 16865.6509765625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1010.0, "train/policy_entropy_mag": 2.761973539352417, "train/policy_entropy_max": 2.761973539352417, "train/policy_entropy_mean": 2.141030590057373, "train/policy_entropy_min": 0.08659016561508179, "train/policy_entropy_std": 0.5989138994216919, "train/policy_logprob_mag": 7.433507949829101, "train/policy_logprob_max": -0.010481505900621415, "train/policy_logprob_mean": -2.140222625732422, "train/policy_logprob_min": -7.433507949829101, "train/policy_logprob_std": 1.1322566361427306, "train/policy_randomness_mag": 0.9748554539680481, "train/policy_randomness_max": 0.9748554539680481, "train/policy_randomness_mean": 0.75568985080719, "train/policy_randomness_min": 0.03056252858042717, "train/policy_randomness_std": 0.2113903263807297, "train/post_ent_mag": 53.682302642822265, "train/post_ent_max": 53.682302642822265, "train/post_ent_mean": 36.138388763427734, "train/post_ent_min": 19.922913024902343, "train/post_ent_std": 6.038515460968018, "train/prior_ent_mag": 63.04672018432617, "train/prior_ent_max": 63.04672018432617, "train/prior_ent_mean": 49.83855499267578, "train/prior_ent_min": 26.197419876098632, "train/prior_ent_std": 5.466253065109253, "train/rep_loss_mean": 13.578866928100586, "train/rep_loss_std": 7.7575127868652345, "train/reward_avg": 0.00105242617148906, "train/reward_loss_mean": 0.0397852668762207, "train/reward_loss_std": 0.011605619385838508, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013335504531860351, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039785266518592835, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010525465607643127, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.08260868904383287, "train_stats/max_log_achievement_collect_drink": 0.19130434782608696, "train_stats/max_log_achievement_collect_sapling": 0.33043478260869563, "train_stats/max_log_achievement_collect_wood": 0.16521739130434782, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 0.24347826086956523, "train_stats/max_log_achievement_place_table": 0.02608695652173913, "train_stats/max_log_achievement_wake_up": 0.19130434782608696, "train_stats/mean_log_entropy": 2.240728093230206, "eval_stats/sum_log_reward": -0.21249999525025487, "eval_stats/max_log_achievement_collect_drink": 0.1875, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 0.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.7456643440236803e-06, "report/cont_loss_std": 4.77748217235785e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0038907021225896e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.714784725161735e-06, "report/cont_pred": 0.9951134920120239, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.933581352233887, "report/dyn_loss_std": 7.9079365730285645, "report/image_loss_mean": 8.922677993774414, "report/image_loss_std": 10.397829055786133, "report/model_loss_mean": 16.12286376953125, "report/model_loss_std": 13.482035636901855, "report/post_ent_mag": 56.30768585205078, "report/post_ent_max": 56.30768585205078, "report/post_ent_mean": 38.62769317626953, "report/post_ent_min": 20.498268127441406, "report/post_ent_std": 7.230197429656982, "report/prior_ent_mag": 63.160255432128906, "report/prior_ent_max": 63.160255432128906, "report/prior_ent_mean": 50.973411560058594, "report/prior_ent_min": 27.81604766845703, "report/prior_ent_std": 4.957093238830566, "report/rep_loss_mean": 11.933581352233887, "report/rep_loss_std": 7.9079365730285645, "report/reward_avg": 0.0010613673366606236, "report/reward_loss_mean": 0.04003296047449112, "report/reward_loss_std": 0.01181226409971714, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0016789436340332031, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04003295674920082, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010594024788588285, "report/reward_rate": 0.0, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.00391431013122201, "eval/cont_loss_std": 0.07039143890142441, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.4007459878921509, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.0007896511233411729, "eval/cont_pred": 0.9933713674545288, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 18.468162536621094, "eval/dyn_loss_std": 9.800780296325684, "eval/image_loss_mean": 23.683828353881836, "eval/image_loss_std": 36.99365997314453, "eval/model_loss_mean": 35.456050872802734, "eval/model_loss_std": 40.195770263671875, "eval/post_ent_mag": 50.14139938354492, "eval/post_ent_max": 50.14139938354492, "eval/post_ent_mean": 35.56976318359375, "eval/post_ent_min": 19.833126068115234, "eval/post_ent_std": 5.603270053863525, "eval/prior_ent_mag": 63.160255432128906, "eval/prior_ent_max": 63.160255432128906, "eval/prior_ent_mean": 50.79365539550781, "eval/prior_ent_min": 27.517200469970703, "eval/prior_ent_std": 5.660055160522461, "eval/rep_loss_mean": 18.468162536621094, "eval/rep_loss_std": 9.800780296325684, "eval/reward_avg": 0.009960937313735485, "eval/reward_loss_mean": 0.687410831451416, "eval/reward_loss_std": 3.4479360580444336, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4177885055541992, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 18.824007034301758, "eval/reward_pred": 0.0009421457070857286, "eval/reward_rate": 0.0146484375, "replay/size": 219561.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3808289972635416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.0524776608516e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 45216.0, "eval_replay/inserts": 3288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.145540362727033e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1009.7701280117035, "timer/env.step_count": 2496.0, "timer/env.step_total": 258.80696725845337, "timer/env.step_frac": 0.25630285554996507, "timer/env.step_avg": 0.1036886888054701, "timer/env.step_min": 0.023065567016601562, "timer/env.step_max": 3.2511794567108154, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.509053707122803, "timer/replay._sample_frac": 0.009417047943225143, "timer/replay._sample_avg": 0.0004762146287621596, "timer/replay._sample_min": 0.00035881996154785156, "timer/replay._sample_max": 0.010498523712158203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2907.0, "timer/agent.policy_total": 46.215089082717896, "timer/agent.policy_frac": 0.04576793054248704, "timer/agent.policy_avg": 0.015897863461547264, "timer/agent.policy_min": 0.009401798248291016, "timer/agent.policy_max": 0.10175490379333496, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.13865923881530762, "timer/dataset_train_frac": 0.00013731762801137302, "timer/dataset_train_avg": 0.00011110515930713751, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0005009174346923828, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 561.0269410610199, "timer/agent.train_frac": 0.5555986709229701, "timer/agent.train_avg": 0.4495408181578685, "timer/agent.train_min": 0.43443727493286133, "timer/agent.train_max": 0.9854516983032227, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4800851345062256, "timer/agent.report_frac": 0.0004754400246039575, "timer/agent.report_avg": 0.2400425672531128, "timer/agent.report_min": 0.23185110092163086, "timer/agent.report_max": 0.24823403358459473, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.211119625974585e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 19.774546269330084}
{"step": 220104, "time": 11389.748370170593, "episode/length": 221.0, "episode/score": 0.23208658261228265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23208658261228265}
{"step": 220192, "time": 11394.914201974869, "episode/length": 255.0, "episode/score": 0.2791811439265075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2791811439265075}
{"step": 220384, "time": 11403.7273478508, "episode/length": 198.0, "episode/score": 0.1903323300653028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1903323300653028}
{"step": 220632, "time": 11415.193496465683, "episode/length": 218.0, "episode/score": 0.20356300385810755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20356300385810755}
{"step": 220664, "time": 11418.377580881119, "episode/length": 173.0, "episode/score": 0.1554222059357926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1554222059357926}
{"step": 220704, "time": 11422.088602304459, "episode/length": 380.0, "episode/score": 0.368987628598461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.368987628598461}
{"step": 220800, "time": 11427.185378789902, "episode/length": 98.0, "episode/score": 0.11878043828528462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11878043828528462}
{"step": 221144, "time": 11441.261644601822, "episode/length": 173.0, "episode/score": 0.19027832462825245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19027832462825245}
{"step": 221872, "time": 11471.922616958618, "episode/length": 220.0, "episode/score": 0.23833874282445322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23833874282445322}
{"step": 221920, "time": 11475.43219280243, "episode/length": 151.0, "episode/score": 0.1543667944633853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1543667944633853}
{"step": 222040, "time": 11481.318143367767, "episode/length": 175.0, "episode/score": 0.1862520732770463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1862520732770463}
{"step": 222048, "time": 11483.336750507355, "episode/length": 231.0, "episode/score": 0.24397016199873178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24397016199873178}
{"step": 222248, "time": 11492.204048156738, "episode/length": 137.0, "episode/score": 0.15759502644732493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15759502644732493}
{"step": 222256, "time": 11494.245613574982, "episode/length": 233.0, "episode/score": 0.24375027712312658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24375027712312658}
{"step": 222288, "time": 11496.984323740005, "episode/length": 202.0, "episode/score": 0.22361641250608955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22361641250608955}
{"step": 222792, "time": 11517.118352651596, "episode/length": 248.0, "episode/score": 0.2671021406094951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2671021406094951}
{"step": 223256, "time": 11535.959713935852, "episode/length": 166.0, "episode/score": 0.178625959350029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.178625959350029}
{"step": 223336, "time": 11540.474561214447, "episode/length": 160.0, "episode/score": 0.1659852188527111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1659852188527111}
{"step": 223392, "time": 11544.356008768082, "episode/length": 141.0, "episode/score": 0.14795346801338383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14795346801338383}
{"step": 223440, "time": 11547.705139875412, "episode/length": 195.0, "episode/score": 0.20901352850614785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20901352850614785}
{"step": 223584, "time": 11554.540253400803, "episode/length": 161.0, "episode/score": 0.16096848173310718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16096848173310718}
{"step": 223592, "time": 11556.18848156929, "episode/length": 193.0, "episode/score": 0.21892235787481695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21892235787481695}
{"step": 223648, "time": 11560.192457437515, "episode/length": 174.0, "episode/score": 0.16627142013658158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16627142013658158}
{"step": 224096, "time": 11579.484966278076, "episode/length": 162.0, "episode/score": 0.1676149558634279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1676149558634279}
{"step": 224664, "time": 11601.798413991928, "episode/length": 165.0, "episode/score": 0.1685848193228594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1685848193228594}
{"step": 224672, "time": 11603.920087575912, "episode/length": 176.0, "episode/score": 0.1670884950144682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1670884950144682}
{"step": 224848, "time": 11612.084407806396, "episode/length": 156.0, "episode/score": 0.17868654007543228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17868654007543228}
{"step": 224912, "time": 11616.076571464539, "episode/length": 157.0, "episode/score": 0.15012329985256656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15012329985256656}
{"step": 224976, "time": 11620.494901657104, "episode/length": 191.0, "episode/score": 0.2061631137621589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2061631137621589}
{"step": 225136, "time": 11628.616846084595, "episode/length": 193.0, "episode/score": 0.19426950345587102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19426950345587102}
{"step": 225136, "time": 11628.62563419342, "episode/length": 217.0, "episode/score": 0.24079707523196703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24079707523196703}
{"step": 225424, "time": 11642.50995850563, "episode/length": 165.0, "episode/score": 0.1831660965035553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1831660965035553}
{"step": 225704, "time": 11654.152400255203, "episode/length": 70.0, "episode/score": 0.08666666480712593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08666666480712593}
{"step": 226008, "time": 11666.996832370758, "episode/length": 166.0, "episode/score": 0.1622934646657086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1622934646657086}
{"step": 226224, "time": 11676.81813287735, "episode/length": 171.0, "episode/score": 0.18689575853204587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18689575853204587}
{"step": 226488, "time": 11687.999220848083, "episode/length": 196.0, "episode/score": 0.2054157928650966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2054157928650966}
{"step": 226648, "time": 11695.546521425247, "episode/length": 188.0, "episode/score": 0.1969236169661599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1969236169661599}
{"step": 226832, "time": 11704.158931016922, "episode/length": 175.0, "episode/score": 0.19470681910206622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19470681910206622}
{"step": 227056, "time": 11713.913691043854, "episode/length": 168.0, "episode/score": 0.17710762873139174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17710762873139174}
{"step": 227312, "time": 11724.988170146942, "episode/length": 162.0, "episode/score": 0.14405600996906287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14405600996906287}
{"step": 227320, "time": 11726.834109067917, "episode/length": 136.0, "episode/score": 0.15650426399042772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15650426399042772}
{"step": 227768, "time": 11745.045734167099, "episode/length": 387.0, "episode/score": 0.42257444614551787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42257444614551787}
{"step": 227808, "time": 11748.441547393799, "episode/length": 164.0, "episode/score": 0.16002690698587685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16002690698587685}
{"step": 227872, "time": 11752.405642747879, "episode/length": 152.0, "episode/score": 0.16296089915704215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16296089915704215}
{"step": 228064, "time": 11761.040701150894, "episode/length": 385.0, "episode/score": 0.4214175916968088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4214175916968088}
{"step": 228280, "time": 11770.381186962128, "episode/length": 152.0, "episode/score": 0.16085057403324754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16085057403324754}
{"step": 228360, "time": 11774.9848883152, "episode/length": 190.0, "episode/score": 0.187658130626005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187658130626005}
{"step": 228632, "time": 11786.65723657608, "episode/length": 164.0, "episode/score": 0.1661580598247383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661580598247383}
{"step": 228816, "time": 11795.197982311249, "episode/length": 186.0, "episode/score": 0.19689142674360482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19689142674360482}
{"step": 228896, "time": 11799.835519313812, "episode/length": 140.0, "episode/score": 0.1656688941966422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1656688941966422}
{"step": 229240, "time": 11814.253333091736, "episode/length": 170.0, "episode/score": 0.16811025989136397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16811025989136397}
{"step": 229384, "time": 11822.29871916771, "episode/length": 164.0, "episode/score": 0.17205733236733067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17205733236733067}
{"step": 229416, "time": 11826.136945724487, "episode/length": 64.0, "episode/score": 0.07645833189599216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07645833189599216}
{"step": 229648, "time": 11836.4566924572, "episode/length": 160.0, "episode/score": 0.1570902877865592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1570902877865592}
{"step": 229664, "time": 11838.560309410095, "episode/length": 105.0, "episode/score": 0.12051759901805781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12051759901805781}
{"step": 229896, "time": 11848.438790082932, "episode/length": 260.0, "episode/score": 0.25311721177149593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25311721177149593}
{"step": 230048, "time": 11875.206352472305, "eval_episode/length": 151.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 230048, "time": 11877.634348392487, "eval_episode/length": 172.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 230048, "time": 11879.636317014694, "eval_episode/length": 176.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 230048, "time": 11881.506654977798, "eval_episode/length": 182.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.994535519125683}
{"step": 230048, "time": 11884.608032941818, "eval_episode/length": 220.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.995475113122172}
{"step": 230048, "time": 11887.498405218124, "eval_episode/length": 251.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 230048, "time": 11887.505709648132, "eval_episode/length": 251.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 230048, "time": 11891.821466684341, "eval_episode/length": 279.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9892857142857143}
{"step": 230440, "time": 11906.200966835022, "episode/length": 225.0, "episode/score": 0.23712153781525558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23712153781525558}
{"step": 230488, "time": 11909.551501750946, "episode/length": 155.0, "episode/score": 0.15556337312955293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15556337312955293}
{"step": 230632, "time": 11916.56664776802, "episode/length": 151.0, "episode/score": 0.14946977501313086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14946977501313086}
{"step": 230640, "time": 11919.158505916595, "episode/length": 294.0, "episode/score": 0.3263757464474111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3263757464474111}
{"step": 230928, "time": 11932.292815685272, "episode/length": 192.0, "episode/score": 0.20767439985502278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20767439985502278}
{"step": 230952, "time": 11935.119415044785, "episode/length": 162.0, "episode/score": 0.15758535513668903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15758535513668903}
{"step": 231072, "time": 11941.869293689728, "episode/length": 175.0, "episode/score": 0.1948862938770617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1948862938770617}
{"step": 231120, "time": 11945.656675338745, "episode/length": 152.0, "episode/score": 0.15959296879373142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15959296879373142}
{"step": 231696, "time": 11968.731837034225, "episode/length": 150.0, "episode/score": 0.15124389325501397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15124389325501397}
{"step": 231856, "time": 11976.258741855621, "episode/length": 176.0, "episode/score": 0.1961857462010812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1961857462010812}
{"step": 231944, "time": 11980.948887109756, "episode/length": 163.0, "episode/score": 0.17838431381824194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17838431381824194}
{"step": 231968, "time": 11983.715734958649, "episode/length": 165.0, "episode/score": 0.16886114178487333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16886114178487333}
{"step": 232200, "time": 11993.706463575363, "episode/length": 158.0, "episode/score": 0.16853826467922772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16853826467922772}
{"step": 232408, "time": 12002.910365343094, "episode/length": 166.0, "episode/score": 0.16545466993193259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16545466993193259}
{"step": 232456, "time": 12006.27443099022, "episode/length": 166.0, "episode/score": 0.17455132440227317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17455132440227317}
{"step": 232936, "time": 12025.65326833725, "episode/length": 154.0, "episode/score": 0.1674489303441078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1674489303441078}
{"step": 232992, "time": 12029.539889097214, "episode/length": 254.0, "episode/score": 0.2757242023362778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2757242023362778}
{"step": 233240, "time": 12040.24254488945, "episode/length": 172.0, "episode/score": 0.18500344925632817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18500344925632817}
{"step": 233248, "time": 12042.3076338768, "episode/length": 162.0, "episode/score": 0.16873143296106718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16873143296106718}
{"step": 233352, "time": 12047.656792640686, "episode/length": 172.0, "episode/score": 0.1802324138734548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1802324138734548}
{"step": 233656, "time": 12060.650397539139, "episode/length": 155.0, "episode/score": 0.16376346962897514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16376346962897514}
{"step": 233848, "time": 12069.26793551445, "episode/length": 173.0, "episode/score": 0.19196743697648344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19196743697648344}
{"step": 234040, "time": 12078.013463497162, "episode/length": 229.0, "episode/score": 0.2486941907882283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2486941907882283}
{"step": 234240, "time": 12087.234810352325, "episode/length": 155.0, "episode/score": 0.16301696868322324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16301696868322324}
{"step": 234576, "time": 12101.225260019302, "episode/length": 165.0, "episode/score": 0.15966291850963898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15966291850963898}
{"step": 234600, "time": 12103.392147779465, "episode/length": 169.0, "episode/score": 0.17149247024644865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17149247024644865}
{"step": 234704, "time": 12109.100916147232, "episode/length": 168.0, "episode/score": 0.19233434644775116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19233434644775116}
{"step": 234776, "time": 12113.050008058548, "episode/length": 229.0, "episode/score": 0.26195399673270003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26195399673270003}
{"step": 235024, "time": 12124.00536608696, "episode/length": 170.0, "episode/score": 0.1971653610416979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1971653610416979}
{"step": 235136, "time": 12129.614290714264, "episode/length": 53.0, "episode/score": 0.05845405533364101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05845405533364101}
{"step": 235232, "time": 12134.930778503418, "episode/length": 148.0, "episode/score": 0.16598011793939804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16598011793939804}
{"step": 235272, "time": 12137.7817466259, "episode/length": 177.0, "episode/score": 0.19982932402126607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19982932402126607}
{"step": 235536, "time": 12149.392054796219, "episode/length": 161.0, "episode/score": 0.16505137873718922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16505137873718922}
{"step": 235760, "time": 12159.837214708328, "episode/length": 147.0, "episode/score": 0.14485063798110787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14485063798110787}
{"step": 235968, "time": 12169.28165268898, "episode/length": 170.0, "episode/score": 0.17149651138970512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17149651138970512}
{"step": 236056, "time": 12174.408006429672, "episode/length": 159.0, "episode/score": 0.16671015358133445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16671015358133445}
{"step": 236296, "time": 12185.216627597809, "episode/length": 144.0, "episode/score": 0.13960667728224507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13960667728224507}
{"step": 236424, "time": 12191.40887260437, "episode/length": 174.0, "episode/score": 0.18008824690150504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18008824690150504}
{"step": 236576, "time": 12199.005444049835, "episode/length": 167.0, "episode/score": 0.17464097838819725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17464097838819725}
{"step": 237024, "time": 12217.054680347443, "episode/length": 218.0, "episode/score": 0.24347789365219796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24347789365219796}
{"step": 237112, "time": 12221.73808646202, "episode/length": 168.0, "episode/score": 0.16623389292180946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16623389292180946}
{"step": 237168, "time": 12225.765181779861, "episode/length": 149.0, "episode/score": 0.14801732538944634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14801732538944634}
{"step": 237328, "time": 12233.219745635986, "episode/length": 223.0, "episode/score": 0.23555597187987587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23555597187987587}
{"step": 237528, "time": 12241.928038358688, "episode/length": 153.0, "episode/score": 0.13740007823616907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13740007823616907}
{"step": 237552, "time": 12244.58997797966, "episode/length": 186.0, "episode/score": 0.18165967920958792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18165967920958792}
{"step": 237576, "time": 12247.442032337189, "episode/length": 143.0, "episode/score": 0.1598755024797356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1598755024797356}
{"step": 237880, "time": 12261.240951776505, "episode/length": 162.0, "episode/score": 0.16552137977305392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16552137977305392}
{"step": 238048, "time": 12269.287426948547, "episode/length": 89.0, "episode/score": 0.09783596587021748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09783596587021748}
{"step": 238424, "time": 12284.679235696793, "episode/length": 174.0, "episode/score": 0.1693803021325948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1693803021325948}
{"step": 238448, "time": 12287.895071029663, "episode/length": 159.0, "episode/score": 0.17094798641846864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17094798641846864}
{"step": 238736, "time": 12300.55282330513, "episode/length": 202.0, "episode/score": 0.21907498794553248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21907498794553248}
{"step": 238984, "time": 12311.076469421387, "episode/length": 178.0, "episode/score": 0.20067923963506473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20067923963506473}
{"step": 238984, "time": 12311.08393573761, "episode/length": 181.0, "episode/score": 0.19556733004719717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19556733004719717}
{"step": 239120, "time": 12319.653643608093, "episode/length": 133.0, "episode/score": 0.13991235775029054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13991235775029054}
{"step": 239216, "time": 12324.738814592361, "episode/length": 204.0, "episode/score": 0.22141076735715615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22141076735715615}
{"step": 239672, "time": 12342.887027025223, "episode/length": 152.0, "episode/score": 0.1679262611978629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1679262611978629}
{"step": 240032, "time": 12384.668816566467, "eval_episode/length": 161.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 240032, "time": 12386.451340436935, "eval_episode/length": 163.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 240032, "time": 12388.181785821915, "eval_episode/length": 167.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 240032, "time": 12390.145176172256, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 240032, "time": 12391.881081104279, "eval_episode/length": 177.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 240032, "time": 12394.421319007874, "eval_episode/length": 199.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.975}
{"step": 240032, "time": 12398.290666341782, "eval_episode/length": 254.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9686274509803922}
{"step": 240032, "time": 12400.615906238556, "eval_episode/length": 270.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.988929889298893}
{"step": 240033, "time": 12401.210079908371, "train_stats/sum_log_reward": 0.20714285051716225, "train_stats/max_log_achievement_collect_drink": 0.21428571428571427, "train_stats/max_log_achievement_collect_sapling": 0.38392857142857145, "train_stats/max_log_achievement_collect_wood": 0.16964285714285715, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.008928571428571428, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.25, "train_stats/max_log_achievement_place_table": 0.017857142857142856, "train_stats/max_log_achievement_wake_up": 0.29464285714285715, "train_stats/mean_log_entropy": 2.218736410140991, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.01713623046875, "train/action_min": 0.0, "train/action_std": 4.7538219871521, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007179397530853749, "train/actor_opt_grad_steps": 14280.0, "train/actor_opt_loss": -14.769323662638664, "train/adv_mag": 0.1597256664633751, "train/adv_max": 0.10036598637700081, "train/adv_mean": -0.00032319468274727116, "train/adv_min": -0.15936116856336593, "train/adv_std": 0.013170022755861282, "train/cont_avg": 0.9944375, "train/cont_loss_mean": 0.0003970087159459581, "train/cont_loss_std": 0.010675442198775273, "train/cont_neg_acc": 0.9841842997458673, "train/cont_neg_loss": 0.05086556735736372, "train/cont_pos_acc": 0.9999842977523804, "train/cont_pos_loss": 0.00011765288710159893, "train/cont_pred": 0.9944635667800903, "train/cont_rate": 0.9944375, "train/dyn_loss_mean": 13.268602661132812, "train/dyn_loss_std": 7.906133247375489, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1984847618341446, "train/extr_critic_critic_opt_grad_steps": 14280.0, "train/extr_critic_critic_opt_loss": 10770.646578125, "train/extr_critic_mag": 0.2627443809509277, "train/extr_critic_max": 0.2627443809509277, "train/extr_critic_mean": 0.20001296150684356, "train/extr_critic_min": 0.004745979309082032, "train/extr_critic_std": 0.06109588208794594, "train/extr_return_normed_mag": 0.21470336282253266, "train/extr_return_normed_max": 0.21470336282253266, "train/extr_return_normed_mean": 0.15225734603405, "train/extr_return_normed_min": -0.046394361436367035, "train/extr_return_normed_std": 0.06272681483626366, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.26213578796386716, "train/extr_return_raw_max": 0.26213578796386716, "train/extr_return_raw_mean": 0.19968977546691893, "train/extr_return_raw_min": 0.0010380640029907227, "train/extr_return_raw_std": 0.06272681483626366, "train/extr_reward_mag": 0.001394275665283203, "train/extr_reward_max": 0.001394275665283203, "train/extr_reward_mean": 0.0010873318407684566, "train/extr_reward_min": 6.817817687988281e-06, "train/extr_reward_std": 0.00023567854147404433, "train/image_loss_mean": 8.33408148574829, "train/image_loss_std": 12.292325275421142, "train/model_loss_mean": 16.33535196685791, "train/model_loss_std": 15.490969871520996, "train/model_opt_grad_norm": 73.05386455597416, "train/model_opt_grad_steps": 14263.44, "train/model_opt_loss": 12892.79673828125, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 790.0, "train/policy_entropy_mag": 2.7585578231811523, "train/policy_entropy_max": 2.7585578231811523, "train/policy_entropy_mean": 2.111087099075317, "train/policy_entropy_min": 0.08448274797201157, "train/policy_entropy_std": 0.6202778782844544, "train/policy_logprob_mag": 7.435221267700196, "train/policy_logprob_max": -0.010176587089896202, "train/policy_logprob_mean": -2.1116898822784425, "train/policy_logprob_min": -7.435221267700196, "train/policy_logprob_std": 1.1515748224258422, "train/policy_randomness_mag": 0.9736498556137085, "train/policy_randomness_max": 0.9736498556137085, "train/policy_randomness_mean": 0.7451210999488831, "train/policy_randomness_min": 0.029818702608346938, "train/policy_randomness_std": 0.21893087196350097, "train/post_ent_mag": 53.95849691772461, "train/post_ent_max": 53.95849691772461, "train/post_ent_mean": 36.51531546020508, "train/post_ent_min": 19.694894790649414, "train/post_ent_std": 6.121328365325928, "train/prior_ent_mag": 63.256237365722654, "train/prior_ent_max": 63.256237365722654, "train/prior_ent_mean": 49.86536791992187, "train/prior_ent_min": 26.263765533447266, "train/prior_ent_std": 5.613433376312256, "train/rep_loss_mean": 13.268602661132812, "train/rep_loss_std": 7.906133247375489, "train/reward_avg": 0.0010502899591811, "train/reward_loss_mean": 0.03971186912059784, "train/reward_loss_std": 0.011649226732552052, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013392667770385743, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039711869418621065, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010514713674783707, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.1000000019557774, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0012885348405689, "report/cont_loss_std": 0.041063860058784485, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.3286994993686676, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.5701262934016995e-06, "report/cont_pred": 0.9968035817146301, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.165834426879883, "report/dyn_loss_std": 7.631762504577637, "report/image_loss_mean": 6.082817554473877, "report/image_loss_std": 11.989109992980957, "report/model_loss_mean": 14.622754096984863, "report/model_loss_std": 15.195470809936523, "report/post_ent_mag": 49.45964431762695, "report/post_ent_max": 49.45964431762695, "report/post_ent_mean": 35.42681121826172, "report/post_ent_min": 21.6805477142334, "report/post_ent_std": 5.367743968963623, "report/prior_ent_mag": 63.90829849243164, "report/prior_ent_max": 63.90829849243164, "report/prior_ent_mean": 50.183902740478516, "report/prior_ent_min": 29.578153610229492, "report/prior_ent_std": 4.428339004516602, "report/rep_loss_mean": 14.165834426879883, "report/rep_loss_std": 7.631762504577637, "report/reward_avg": 0.0010327940108254552, "report/reward_loss_mean": 0.03914768248796463, "report/reward_loss_std": 0.011852243915200233, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013412237167358398, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03914768248796463, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010785255581140518, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.51697542303009e-06, "eval/cont_loss_std": 2.3465845515602268e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.116987838642672e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.445248123374768e-06, "eval/cont_pred": 0.9980425238609314, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.349592208862305, "eval/dyn_loss_std": 9.746586799621582, "eval/image_loss_mean": 12.85666275024414, "eval/image_loss_std": 17.413177490234375, "eval/model_loss_mean": 23.89990997314453, "eval/model_loss_std": 21.89112663269043, "eval/post_ent_mag": 51.09391784667969, "eval/post_ent_max": 51.09391784667969, "eval/post_ent_mean": 35.855316162109375, "eval/post_ent_min": 21.601177215576172, "eval/post_ent_std": 5.295018672943115, "eval/prior_ent_mag": 63.90829849243164, "eval/prior_ent_max": 63.90829849243164, "eval/prior_ent_mean": 50.3670768737793, "eval/prior_ent_min": 21.298023223876953, "eval/prior_ent_std": 5.176766395568848, "eval/rep_loss_mean": 17.349592208862305, "eval/rep_loss_std": 9.746586799621582, "eval/reward_avg": 0.0126953125, "eval/reward_loss_mean": 0.6334881782531738, "eval/reward_loss_std": 3.3385653495788574, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.001356959342956543, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.3418348729610443, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.007652282714844, "eval/reward_pred": 0.0010542290983721614, "eval/reward_rate": 0.015625, "replay/size": 239529.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3651159138251574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.623786004690023e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49624.0, "eval_replay/inserts": 4408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.226438584647897e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1013.0231115818024, "timer/env.step_count": 2496.0, "timer/env.step_total": 250.3426594734192, "timer/env.step_frac": 0.2471243317267632, "timer/env.step_avg": 0.1002975398531327, "timer/env.step_min": 0.022561311721801758, "timer/env.step_max": 3.334359884262085, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.605744361877441, "timer/replay._sample_frac": 0.00948225588543423, "timer/replay._sample_avg": 0.0004810569091485097, "timer/replay._sample_min": 0.0003600120544433594, "timer/replay._sample_max": 0.010763883590698242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3047.0, "timer/agent.policy_total": 49.759814739227295, "timer/agent.policy_frac": 0.04912011796209563, "timer/agent.policy_avg": 0.016330756396201934, "timer/agent.policy_min": 0.009523391723632812, "timer/agent.policy_max": 0.12786436080932617, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.13756752014160156, "timer/dataset_train_frac": 0.00013579899468117208, "timer/dataset_train_avg": 0.0001102303847288474, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0005316734313964844, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 560.3668236732483, "timer/agent.train_frac": 0.5531629212271908, "timer/agent.train_avg": 0.44901187794330794, "timer/agent.train_min": 0.4356575012207031, "timer/agent.train_max": 0.9265613555908203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4662158489227295, "timer/agent.report_frac": 0.00046022232226740486, "timer/agent.report_avg": 0.23310792446136475, "timer/agent.report_min": 0.22216582298278809, "timer/agent.report_max": 0.2440500259399414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.177272839160872e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 19.71105774643224}
{"step": 240096, "time": 12403.846002340317, "episode/length": 208.0, "episode/score": 0.21939621719138813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21939621719138813}
{"step": 240184, "time": 12408.59016919136, "episode/length": 180.0, "episode/score": 0.16563720153499162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16563720153499162}
{"step": 240184, "time": 12408.596751451492, "episode/length": 149.0, "episode/score": 0.16322084442072082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16322084442072082}
{"step": 240248, "time": 12414.441454172134, "episode/length": 157.0, "episode/score": 0.1768957377244078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768957377244078}
{"step": 240280, "time": 12417.173764705658, "episode/length": 299.0, "episode/score": 0.3238911396256299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3238911396256299}
{"step": 240288, "time": 12419.295134782791, "episode/length": 145.0, "episode/score": 0.14685438487140345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14685438487140345}
{"step": 240408, "time": 12425.101031780243, "episode/length": 148.0, "episode/score": 0.16519433342909906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16519433342909906}
{"step": 240992, "time": 12449.479685544968, "episode/length": 164.0, "episode/score": 0.1577834445706685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577834445706685}
{"step": 241328, "time": 12463.594016075134, "episode/length": 153.0, "episode/score": 0.1520659290599724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1520659290599724}
{"step": 241504, "time": 12471.80007815361, "episode/length": 164.0, "episode/score": 0.17656122379958106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17656122379958106}
{"step": 241704, "time": 12480.732681035995, "episode/length": 161.0, "episode/score": 0.17049654708353046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17049654708353046}
{"step": 241704, "time": 12480.740640163422, "episode/length": 177.0, "episode/score": 0.20962499611778185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20962499611778185}
{"step": 241712, "time": 12485.573921442032, "episode/length": 177.0, "episode/score": 0.1784923686482216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1784923686482216}
{"step": 241720, "time": 12487.821771144867, "episode/length": 183.0, "episode/score": 0.18434391419759777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18434391419759777}
{"step": 241824, "time": 12493.881544589996, "episode/length": 204.0, "episode/score": 0.23006525700293423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23006525700293423}
{"step": 242160, "time": 12507.993527650833, "episode/length": 145.0, "episode/score": 0.16377471877967764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16377471877967764}
{"step": 242512, "time": 12522.581016778946, "episode/length": 147.0, "episode/score": 0.15639282045231084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15639282045231084}
{"step": 242608, "time": 12527.822173595428, "episode/length": 111.0, "episode/score": 0.1340416640159674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1340416640159674}
{"step": 242832, "time": 12537.729042053223, "episode/length": 165.0, "episode/score": 0.16451554439299798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16451554439299798}
{"step": 242896, "time": 12541.63971233368, "episode/length": 146.0, "episode/score": 0.14614622459248494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14614622459248494}
{"step": 242992, "time": 12546.822010993958, "episode/length": 160.0, "episode/score": 0.18051183594343456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18051183594343456}
{"step": 243032, "time": 12549.714965105057, "episode/length": 165.0, "episode/score": 0.1817638882303072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1817638882303072}
{"step": 243144, "time": 12555.427744150162, "episode/length": 164.0, "episode/score": 0.1617742786929739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1617742786929739}
{"step": 243416, "time": 12567.147031784058, "episode/length": 156.0, "episode/score": 0.1581165518000489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1581165518000489}
{"step": 243944, "time": 12589.171617984772, "episode/length": 118.0, "episode/score": 0.13638346265634027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13638346265634027}
{"step": 244016, "time": 12593.587991476059, "episode/length": 147.0, "episode/score": 0.15880895421287278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15880895421287278}
{"step": 244200, "time": 12601.76859164238, "episode/length": 145.0, "episode/score": 0.14740493734916527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14740493734916527}
{"step": 244544, "time": 12616.424437761307, "episode/length": 253.0, "episode/score": 0.28380564224335103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28380564224335103}
{"step": 244648, "time": 12621.547106981277, "episode/length": 187.0, "episode/score": 0.19648441669869499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19648441669869499}
{"step": 244752, "time": 12627.245195388794, "episode/length": 231.0, "episode/score": 0.24195400299049652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24195400299049652}
{"step": 244840, "time": 12632.362344026566, "episode/length": 177.0, "episode/score": 0.19033998630675342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19033998630675342}
{"step": 245088, "time": 12643.876197338104, "episode/length": 142.0, "episode/score": 0.1535357058965019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1535357058965019}
{"step": 245328, "time": 12654.417905807495, "episode/length": 163.0, "episode/score": 0.17250330831211613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17250330831211613}
{"step": 245544, "time": 12664.589765310287, "episode/length": 111.0, "episode/score": 0.12885752292640973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12885752292640973}
{"step": 245552, "time": 12666.634230136871, "episode/length": 168.0, "episode/score": 0.18211608533329127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18211608533329127}
{"step": 245664, "time": 12672.295600414276, "episode/length": 139.0, "episode/score": 0.13032908267450694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13032908267450694}
{"step": 245696, "time": 12675.142181396484, "episode/length": 385.0, "episode/score": 0.397932135127121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.397932135127121}
{"step": 245888, "time": 12685.257825136185, "episode/length": 141.0, "episode/score": 0.14314011180977104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14314011180977104}
{"step": 246232, "time": 12699.831499576569, "episode/length": 173.0, "episode/score": 0.1781503731963312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1781503731963312}
{"step": 246472, "time": 12710.455224275589, "episode/length": 142.0, "episode/score": 0.1564416664705277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1564416664705277}
{"step": 246800, "time": 12724.527943611145, "episode/length": 137.0, "episode/score": 0.15317215468348877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15317215468348877}
{"step": 246832, "time": 12727.809081792831, "episode/length": 145.0, "episode/score": 0.15485740915300994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15485740915300994}
{"step": 246888, "time": 12731.67265701294, "episode/length": 224.0, "episode/score": 0.22513735793199885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22513735793199885}
{"step": 247016, "time": 12738.094483852386, "episode/length": 183.0, "episode/score": 0.2041456239667241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2041456239667241}
{"step": 247232, "time": 12747.789246320724, "episode/length": 167.0, "episode/score": 0.1608895027793551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1608895027793551}
{"step": 247704, "time": 12766.873030900955, "episode/length": 108.0, "episode/score": 0.10631313326985037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10631313326985037}
{"step": 247792, "time": 12771.908534288406, "episode/length": 279.0, "episode/score": 0.2760040001703601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2760040001703601}
{"step": 247984, "time": 12780.486095190048, "episode/length": 218.0, "episode/score": 0.22382080498391588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22382080498391588}
{"step": 248176, "time": 12789.150835514069, "episode/length": 171.0, "episode/score": 0.1826740611600144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1826740611600144}
{"step": 248592, "time": 12806.244833946228, "episode/length": 264.0, "episode/score": 0.29258723820839805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29258723820839805}
{"step": 248608, "time": 12808.443464040756, "episode/length": 171.0, "episode/score": 0.1725712485326767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1725712485326767}
{"step": 249104, "time": 12828.498138427734, "episode/length": 139.0, "episode/score": 0.1706312464189068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706312464189068}
{"step": 249240, "time": 12834.843683719635, "episode/length": 293.0, "episode/score": 0.3102581662255943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3102581662255943}
{"step": 249248, "time": 12836.9345536232, "episode/length": 192.0, "episode/score": 0.22420329266924455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22420329266924455}
{"step": 249328, "time": 12841.537747383118, "episode/length": 191.0, "episode/score": 0.20793485803233125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20793485803233125}
{"step": 249424, "time": 12846.62506723404, "episode/length": 300.0, "episode/score": 0.3266279507092804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3266279507092804}
{"step": 249880, "time": 12865.115716695786, "episode/length": 158.0, "episode/score": 0.1792901124299533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1792901124299533}
{"step": 250016, "time": 12886.624943494797, "eval_episode/length": 41.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9047619047619048}
{"step": 250016, "time": 12892.276062011719, "eval_episode/length": 145.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 250016, "time": 12893.886085271835, "eval_episode/length": 146.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 250016, "time": 12895.541642665863, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 250016, "time": 12897.876792669296, "eval_episode/length": 170.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 250016, "time": 12900.513454914093, "eval_episode/length": 196.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 250016, "time": 12903.70895576477, "eval_episode/length": 235.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 250016, "time": 12905.474658727646, "eval_episode/length": 242.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 250024, "time": 12905.559237480164, "episode/length": 178.0, "episode/score": 0.2031324790527833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2031324790527833}
{"step": 250192, "time": 12913.64479470253, "episode/length": 251.0, "episode/score": 0.2594493180149584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2594493180149584}
{"step": 250440, "time": 12924.221698760986, "episode/length": 148.0, "episode/score": 0.1551785055989967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1551785055989967}
{"step": 250648, "time": 12934.237478494644, "episode/length": 164.0, "episode/score": 0.17249695048212743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17249695048212743}
{"step": 250680, "time": 12937.369385957718, "episode/length": 156.0, "episode/score": 0.182229163357988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.182229163357988}
{"step": 250720, "time": 12940.533144712448, "episode/length": 184.0, "episode/score": 0.1910206768034186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1910206768034186}
{"step": 250960, "time": 12951.124481201172, "episode/length": 231.0, "episode/score": 0.25871228985488415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25871228985488415}
{"step": 251216, "time": 12962.09310913086, "episode/length": 166.0, "episode/score": 0.17834438836371191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17834438836371191}
{"step": 251536, "time": 12975.499804019928, "episode/length": 167.0, "episode/score": 0.17051980484575324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17051980484575324}
{"step": 251632, "time": 12980.605195760727, "episode/length": 200.0, "episode/score": 0.20513676974042028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20513676974042028}
{"step": 251904, "time": 12992.327817201614, "episode/length": 156.0, "episode/score": 0.17864092232184703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17864092232184703}
{"step": 252024, "time": 12998.082380771637, "episode/length": 167.0, "episode/score": 0.177563700734936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.177563700734936}
{"step": 252392, "time": 13013.294569015503, "episode/length": 178.0, "episode/score": 0.1827899818322294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1827899818322294}
{"step": 252440, "time": 13016.783625364304, "episode/length": 249.0, "episode/score": 0.27424722075056707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27424722075056707}
{"step": 252560, "time": 13022.994983434677, "episode/length": 167.0, "episode/score": 0.18083065584869473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18083065584869473}
{"step": 252712, "time": 13029.97329711914, "episode/length": 248.0, "episode/score": 0.2601404572806132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2601404572806132}
{"step": 253144, "time": 13047.815371274948, "episode/length": 154.0, "episode/score": 0.17561908609059174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17561908609059174}
{"step": 253160, "time": 13050.00811958313, "episode/length": 202.0, "episode/score": 0.23382736389794445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23382736389794445}
{"step": 253488, "time": 13063.969893217087, "episode/length": 182.0, "episode/score": 0.1947454219489373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1947454219489373}
{"step": 253808, "time": 13078.191693544388, "episode/length": 155.0, "episode/score": 0.18812499626073986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18812499626073986}
{"step": 253808, "time": 13078.201115369797, "episode/length": 271.0, "episode/score": 0.3023613647874299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3023613647874299}
{"step": 253952, "time": 13086.864569187164, "episode/length": 188.0, "episode/score": 0.20296268958009023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20296268958009023}
{"step": 254224, "time": 13100.300226688385, "episode/length": 188.0, "episode/score": 0.21709761531610638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21709761531610638}
{"step": 254472, "time": 13110.894346475601, "episode/length": 259.0, "episode/score": 0.28246682492545006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28246682492545006}
{"step": 254600, "time": 13117.242934942245, "episode/length": 181.0, "episode/score": 0.2079196392733138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2079196392733138}
{"step": 254872, "time": 13128.885891914368, "episode/length": 213.0, "episode/score": 0.22837264311556282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22837264311556282}
{"step": 254976, "time": 13134.465523719788, "episode/length": 185.0, "episode/score": 0.1853144131218869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1853144131218869}
{"step": 255008, "time": 13137.276908636093, "episode/length": 149.0, "episode/score": 0.14869177463197047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14869177463197047}
{"step": 255096, "time": 13141.724440097809, "episode/length": 142.0, "episode/score": 0.1650230182544874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1650230182544874}
{"step": 255344, "time": 13152.671905040741, "episode/length": 139.0, "episode/score": 0.16820832999655977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16820832999655977}
{"step": 255552, "time": 13162.003961801529, "episode/length": 217.0, "episode/score": 0.24942417527290672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24942417527290672}
{"step": 256136, "time": 13185.069210290909, "episode/length": 207.0, "episode/score": 0.2414613051514607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2414613051514607}
{"step": 256256, "time": 13191.273980140686, "episode/length": 155.0, "episode/score": 0.16979900318528962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16979900318528962}
{"step": 256424, "time": 13198.816148757935, "episode/length": 193.0, "episode/score": 0.21010300399530024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21010300399530024}
{"step": 256632, "time": 13208.10504412651, "episode/length": 206.0, "episode/score": 0.21962054831146816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21962054831146816}
{"step": 256792, "time": 13215.771057128906, "episode/length": 154.0, "episode/score": 0.1642136810824013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1642136810824013}
{"step": 257024, "time": 13226.14337348938, "episode/length": 209.0, "episode/score": 0.20462310453694954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20462310453694954}
{"step": 257120, "time": 13231.326703310013, "episode/length": 314.0, "episode/score": 0.3478513863456101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3478513863456101}
{"step": 257128, "time": 13233.070878982544, "episode/length": 253.0, "episode/score": 0.26869970668531096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26869970668531096}
{"step": 257424, "time": 13245.88036441803, "episode/length": 37.0, "episode/score": 0.03995833278167993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03995833278167993}
{"step": 257576, "time": 13252.875399112701, "episode/length": 179.0, "episode/score": 0.19531474291261475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19531474291261475}
{"step": 257640, "time": 13256.831818342209, "episode/length": 172.0, "episode/score": 0.18395311874928666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18395311874928666}
{"step": 257784, "time": 13263.82852935791, "episode/length": 169.0, "episode/score": 0.1671759450969148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1671759450969148}
{"step": 257944, "time": 13271.332062721252, "episode/length": 143.0, "episode/score": 0.14974490491340475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14974490491340475}
{"step": 257960, "time": 13273.457453489304, "episode/length": 165.0, "episode/score": 0.18933731103288665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18933731103288665}
{"step": 258472, "time": 13294.126834392548, "episode/length": 167.0, "episode/score": 0.19799999630777165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19799999630777165}
{"step": 258696, "time": 13304.935332536697, "episode/length": 139.0, "episode/score": 0.15576163149444255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15576163149444255}
{"step": 258752, "time": 13308.859799146652, "episode/length": 165.0, "episode/score": 0.18006115856496763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18006115856496763}
{"step": 258840, "time": 13313.536742210388, "episode/length": 226.0, "episode/score": 0.25063474208127445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25063474208127445}
{"step": 259040, "time": 13322.711631536484, "episode/length": 70.0, "episode/score": 0.08173759748751763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08173759748751763}
{"step": 259064, "time": 13324.887391805649, "episode/length": 177.0, "episode/score": 0.20327084405198548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20327084405198548}
{"step": 259136, "time": 13329.357679605484, "episode/length": 148.0, "episode/score": 0.15210047477648914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15210047477648914}
{"step": 259144, "time": 13330.991997003555, "episode/length": 147.0, "episode/score": 0.16470844678178764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16470844678178764}
{"step": 259720, "time": 13354.11551976204, "episode/length": 120.0, "episode/score": 0.1470833303174004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1470833303174004}
{"step": 259888, "time": 13362.074508428574, "episode/length": 262.0, "episode/score": 0.2912259653990077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2912259653990077}
{"step": 260000, "time": 13386.437448978424, "eval_episode/length": 138.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 260000, "time": 13388.169344186783, "eval_episode/length": 141.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 260000, "time": 13390.04636335373, "eval_episode/length": 149.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 260000, "time": 13392.316182374954, "eval_episode/length": 164.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 260000, "time": 13393.960756540298, "eval_episode/length": 165.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 260000, "time": 13397.9202876091, "eval_episode/length": 218.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 260000, "time": 13400.634947538376, "eval_episode/length": 241.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 260000, "time": 13402.96583890915, "eval_episode/length": 250.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9760956175298805}
{"step": 260001, "time": 13403.578568220139, "train_stats/sum_log_reward": -0.02500000363215804, "train_stats/max_log_achievement_collect_drink": 0.14285714285714285, "train_stats/max_log_achievement_collect_sapling": 0.26785714285714285, "train_stats/max_log_achievement_collect_wood": 0.19642857142857142, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.17857142857142858, "train_stats/max_log_achievement_place_table": 0.008928571428571428, "train_stats/max_log_achievement_wake_up": 0.26785714285714285, "train_stats/mean_log_entropy": 2.2161032589418546, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.0022158203125, "train/action_min": 0.0, "train/action_std": 4.9566329536437985, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007434026287868619, "train/actor_opt_grad_steps": 15530.0, "train/actor_opt_loss": -9.649418071985245, "train/adv_mag": 0.1600529734492302, "train/adv_max": 0.1070879157781601, "train/adv_mean": -0.00010301747263929429, "train/adv_min": -0.1591944962143898, "train/adv_std": 0.013262246400117875, "train/cont_avg": 0.9944296875, "train/cont_loss_mean": 0.0004964273019149914, "train/cont_loss_std": 0.014571485383035905, "train/cont_neg_acc": 0.9895609324016879, "train/cont_neg_loss": 0.029795513628465824, "train/cont_pos_acc": 0.9999214291572571, "train/cont_pos_loss": 0.00033498445191696644, "train/cont_pred": 0.9943841314315796, "train/cont_rate": 0.9944296875, "train/dyn_loss_mean": 13.156923042297363, "train/dyn_loss_std": 7.947374698638916, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20604998731613158, "train/extr_critic_critic_opt_grad_steps": 15530.0, "train/extr_critic_critic_opt_loss": 10756.1695859375, "train/extr_critic_mag": 0.2583942880630493, "train/extr_critic_max": 0.2583942880630493, "train/extr_critic_mean": 0.19977885830402375, "train/extr_critic_min": 0.004292845726013184, "train/extr_critic_std": 0.059909176528453824, "train/extr_return_normed_mag": 0.2112918977737427, "train/extr_return_normed_max": 0.2112918977737427, "train/extr_return_normed_mean": 0.152989035487175, "train/extr_return_normed_min": -0.04567640125751495, "train/extr_return_normed_std": 0.06183097749948502, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.25797872090339663, "train/extr_return_raw_max": 0.25797872090339663, "train/extr_return_raw_mean": 0.19967586052417755, "train/extr_return_raw_min": 0.0010104217529296874, "train/extr_return_raw_std": 0.061830977588891986, "train/extr_reward_mag": 0.0013979291915893555, "train/extr_reward_max": 0.0013979291915893555, "train/extr_reward_mean": 0.0010866489680483938, "train/extr_reward_min": 9.626388549804687e-06, "train/extr_reward_std": 0.0002363363397307694, "train/image_loss_mean": 7.73482600402832, "train/image_loss_std": 11.635686798095703, "train/model_loss_mean": 15.669176582336426, "train/model_loss_std": 14.859082015991211, "train/model_opt_grad_norm": 66.4072346496582, "train/model_opt_grad_steps": 15512.064, "train/model_opt_loss": 11272.9920859375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 720.0, "train/policy_entropy_mag": 2.762667665481567, "train/policy_entropy_max": 2.762667665481567, "train/policy_entropy_mean": 2.135301257133484, "train/policy_entropy_min": 0.08484063738584519, "train/policy_entropy_std": 0.5683969144821167, "train/policy_logprob_mag": 7.435925720214843, "train/policy_logprob_max": -0.010224674671888352, "train/policy_logprob_mean": -2.1344415769577028, "train/policy_logprob_min": -7.435925720214843, "train/policy_logprob_std": 1.1274852113723755, "train/policy_randomness_mag": 0.9751004505157471, "train/policy_randomness_max": 0.9751004505157471, "train/policy_randomness_mean": 0.7536676435470581, "train/policy_randomness_min": 0.02994502194225788, "train/policy_randomness_std": 0.20061916971206664, "train/post_ent_mag": 54.50672894287109, "train/post_ent_max": 54.50672894287109, "train/post_ent_mean": 36.749433227539065, "train/post_ent_min": 19.940226791381836, "train/post_ent_std": 6.198632911682129, "train/prior_ent_mag": 63.66586944580078, "train/prior_ent_max": 63.66586944580078, "train/prior_ent_mean": 50.02253231811523, "train/prior_ent_min": 26.90147787475586, "train/prior_ent_std": 5.580152088165283, "train/rep_loss_mean": 13.156923042297363, "train/rep_loss_std": 7.947374698638916, "train/reward_avg": 0.0010499810026958585, "train/reward_loss_mean": 0.03970039200782776, "train/reward_loss_std": 0.011669644832611084, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013403024673461915, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03970039197802543, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010494635105133057, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.16250000707805157, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_wood": 0.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 9.334531205240637e-05, "report/cont_loss_std": 0.0010102485539391637, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019938701298087835, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.838055171305314e-05, "report/cont_pred": 0.9921257495880127, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.16321849822998, "report/dyn_loss_std": 7.769122123718262, "report/image_loss_mean": 5.593039512634277, "report/image_loss_std": 10.196688652038574, "report/model_loss_mean": 13.531828880310059, "report/model_loss_std": 13.426411628723145, "report/post_ent_mag": 55.168880462646484, "report/post_ent_max": 55.168880462646484, "report/post_ent_mean": 36.69050598144531, "report/post_ent_min": 18.628860473632812, "report/post_ent_std": 5.959490776062012, "report/prior_ent_mag": 63.66179656982422, "report/prior_ent_max": 63.66179656982422, "report/prior_ent_mean": 50.38627624511719, "report/prior_ent_min": 38.46126174926758, "report/prior_ent_std": 4.432484149932861, "report/rep_loss_mean": 13.16321849822998, "report/rep_loss_std": 7.769122123718262, "report/reward_avg": 0.001079007051885128, "report/reward_loss_mean": 0.040764838457107544, "report/reward_loss_std": 0.010119055397808552, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012902021408081055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040764838457107544, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010862008202821016, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0002851243771146983, "eval/cont_loss_std": 0.0065604099072515965, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005926530342549086, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00025744331651367247, "eval/cont_pred": 0.9949097633361816, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.20721435546875, "eval/dyn_loss_std": 10.052668571472168, "eval/image_loss_mean": 17.927722930908203, "eval/image_loss_std": 21.972721099853516, "eval/model_loss_mean": 29.007875442504883, "eval/model_loss_std": 26.029638290405273, "eval/post_ent_mag": 57.384918212890625, "eval/post_ent_max": 57.384918212890625, "eval/post_ent_mean": 37.006568908691406, "eval/post_ent_min": 18.445375442504883, "eval/post_ent_std": 6.718461990356445, "eval/prior_ent_mag": 63.66179656982422, "eval/prior_ent_max": 63.66179656982422, "eval/prior_ent_mean": 51.149925231933594, "eval/prior_ent_min": 23.216869354248047, "eval/prior_ent_std": 6.257542133331299, "eval/rep_loss_mean": 17.20721435546875, "eval/rep_loss_std": 10.052668571472168, "eval/reward_avg": 0.01162109337747097, "eval/reward_loss_mean": 0.7555392980575562, "eval/reward_loss_std": 3.622727632522583, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4633357524871826, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.164365768432617, "eval/reward_pred": 0.0010572411119937897, "eval/reward_rate": 0.015625, "replay/size": 259497.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3572474320729573e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.355038097271553e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 53576.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1929374957374233e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.3520796298981, "timer/env.step_count": 2496.0, "timer/env.step_total": 249.66198205947876, "timer/env.step_frac": 0.24907613515568533, "timer/env.step_avg": 0.10002483255588092, "timer/env.step_min": 0.02304863929748535, "timer/env.step_max": 4.305606842041016, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.648879051208496, "timer/replay._sample_frac": 0.009626237374367682, "timer/replay._sample_avg": 0.0004832170999202973, "timer/replay._sample_min": 0.000377655029296875, "timer/replay._sample_max": 0.01066446304321289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2990.0, "timer/agent.policy_total": 47.27621865272522, "timer/agent.policy_frac": 0.047165282153333966, "timer/agent.policy_avg": 0.01581144436545994, "timer/agent.policy_min": 0.009505748748779297, "timer/agent.policy_max": 0.09238862991333008, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.13833022117614746, "timer/dataset_train_frac": 0.00013800562096626128, "timer/dataset_train_avg": 0.00011084152337832328, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0003597736358642578, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 561.014246225357, "timer/agent.train_frac": 0.5596977924488392, "timer/agent.train_avg": 0.4495306460139079, "timer/agent.train_min": 0.43717503547668457, "timer/agent.train_max": 1.3117260932922363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47293758392333984, "timer/agent.report_frac": 0.0004718278073488551, "timer/agent.report_avg": 0.23646879196166992, "timer/agent.report_min": 0.22765278816223145, "timer/agent.report_max": 0.2452847957611084, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.377599440400466e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 19.92088225453092}
{"step": 260200, "time": 13411.329927921295, "episode/length": 187.0, "episode/score": 0.19032191451060498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19032191451060498}
{"step": 260328, "time": 13418.284476280212, "episode/length": 148.0, "episode/score": 0.16698735313502766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16698735313502766}
{"step": 260368, "time": 13422.103672742844, "episode/length": 152.0, "episode/score": 0.15354928575470694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15354928575470694}
{"step": 260456, "time": 13426.821323871613, "episode/length": 201.0, "episode/score": 0.21897648843878414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21897648843878414}
{"step": 260616, "time": 13434.427206277847, "episode/length": 193.0, "episode/score": 0.21521065372053272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21521065372053272}
{"step": 260656, "time": 13437.755687236786, "episode/length": 201.0, "episode/score": 0.21845767413924477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21845767413924477}
{"step": 261296, "time": 13463.45852303505, "episode/length": 175.0, "episode/score": 0.185750269695518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185750269695518}
{"step": 261488, "time": 13472.883220911026, "episode/length": 220.0, "episode/score": 0.23622410465668509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23622410465668509}
{"step": 261568, "time": 13477.490182876587, "episode/length": 154.0, "episode/score": 0.15463895941434203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15463895941434203}
{"step": 261680, "time": 13483.14502954483, "episode/length": 163.0, "episode/score": 0.18665727762413553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18665727762413553}
{"step": 261936, "time": 13494.260154008865, "episode/length": 159.0, "episode/score": 0.17756805586213886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17756805586213886}
{"step": 261984, "time": 13497.570253372192, "episode/length": 170.0, "episode/score": 0.16485532538445113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16485532538445113}
{"step": 262032, "time": 13500.99309515953, "episode/length": 228.0, "episode/score": 0.27059037040362455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27059037040362455}
{"step": 262088, "time": 13504.394093513489, "episode/length": 203.0, "episode/score": 0.22375788037379607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22375788037379607}
{"step": 262936, "time": 13539.356678724289, "episode/length": 170.0, "episode/score": 0.17920571710465083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17920571710465083}
{"step": 263008, "time": 13543.936019897461, "episode/length": 189.0, "episode/score": 0.1837549212666545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1837549212666545}
{"step": 263240, "time": 13553.969689369202, "episode/length": 162.0, "episode/score": 0.16609979441113865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16609979441113865}
{"step": 263240, "time": 13553.977643489838, "episode/length": 242.0, "episode/score": 0.2562686250828392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2562686250828392}
{"step": 263304, "time": 13559.716046571732, "episode/length": 202.0, "episode/score": 0.21433230350930899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21433230350930899}
{"step": 263512, "time": 13568.981080055237, "episode/length": 184.0, "episode/score": 0.19261044718132325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19261044718132325}
{"step": 263744, "time": 13579.793752670288, "episode/length": 206.0, "episode/score": 0.19648144181383032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19648144181383032}
{"step": 263864, "time": 13585.779513597488, "episode/length": 234.0, "episode/score": 0.25426090449809635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25426090449809635}
{"step": 264016, "time": 13593.905400276184, "episode/length": 134.0, "episode/score": 0.1413897400652786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1413897400652786}
{"step": 264376, "time": 13609.485503435135, "episode/length": 170.0, "episode/score": 0.1833615315492807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1833615315492807}
{"step": 264616, "time": 13619.975550889969, "episode/length": 171.0, "episode/score": 0.18424553304794244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18424553304794244}
{"step": 264768, "time": 13627.48748254776, "episode/length": 190.0, "episode/score": 0.21283870639308589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21283870639308589}
{"step": 264800, "time": 13630.282959461212, "episode/length": 186.0, "episode/score": 0.19261178468877915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19261178468877915}
{"step": 265080, "time": 13642.11221408844, "episode/length": 166.0, "episode/score": 0.18214899232407333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18214899232407333}
{"step": 265168, "time": 13647.200446128845, "episode/length": 206.0, "episode/score": 0.24421428106870735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24421428106870735}
{"step": 265216, "time": 13650.562961816788, "episode/length": 168.0, "episode/score": 0.195468250385602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.195468250385602}
{"step": 265408, "time": 13659.29391169548, "episode/length": 173.0, "episode/score": 0.2008383803331526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2008383803331526}
{"step": 266032, "time": 13684.275112628937, "episode/length": 157.0, "episode/score": 0.16841300087980926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16841300087980926}
{"step": 266344, "time": 13697.40506863594, "episode/length": 146.0, "episode/score": 0.1688516513677314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1688516513677314}
{"step": 266368, "time": 13700.126754760742, "episode/length": 218.0, "episode/score": 0.2596371279141749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2596371279141749}
{"step": 266456, "time": 13704.644495010376, "episode/length": 206.0, "episode/score": 0.21044498249830212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21044498249830212}
{"step": 266688, "time": 13715.13201546669, "episode/length": 159.0, "episode/score": 0.1753111832185823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1753111832185823}
{"step": 267064, "time": 13730.51805973053, "episode/length": 230.0, "episode/score": 0.24254860007204115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24254860007204115}
{"step": 267448, "time": 13746.478642463684, "episode/length": 176.0, "episode/score": 0.2087134986941237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2087134986941237}
{"step": 267472, "time": 13749.796667337418, "episode/length": 386.0, "episode/score": 0.37629745024423755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.37629745024423755}
{"step": 267504, "time": 13752.589171171188, "episode/length": 302.0, "episode/score": 0.35533492898684926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35533492898684926}
{"step": 267592, "time": 13757.313733816147, "episode/length": 152.0, "episode/score": 0.1543774487945484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1543774487945484}
{"step": 267624, "time": 13760.05049753189, "episode/length": 145.0, "episode/score": 0.13747518801756087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13747518801756087}
{"step": 267720, "time": 13765.224254846573, "episode/length": 171.0, "episode/score": 0.16004055261873873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16004055261873873}
{"step": 268024, "time": 13778.203688383102, "episode/length": 166.0, "episode/score": 0.18694539940952382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18694539940952382}
{"step": 268296, "time": 13790.089981555939, "episode/length": 153.0, "episode/score": 0.174561504740268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.174561504740268}
{"step": 268576, "time": 13802.851181983948, "episode/length": 106.0, "episode/score": 0.11905195876170183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11905195876170183}
{"step": 268584, "time": 13804.544368743896, "episode/length": 141.0, "episode/score": 0.1448852856610756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1448852856610756}
{"step": 268648, "time": 13808.595024824142, "episode/length": 142.0, "episode/score": 0.15375906142980966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15375906142980966}
{"step": 268704, "time": 13813.023658514023, "episode/length": 153.0, "episode/score": 0.16873296695484896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16873296695484896}
{"step": 269096, "time": 13829.892976999283, "episode/length": 133.0, "episode/score": 0.16135184855193074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16135184855193074}
{"step": 269272, "time": 13837.980785608292, "episode/length": 205.0, "episode/score": 0.21285026226905757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21285026226905757}
{"step": 269384, "time": 13843.730112791061, "episode/length": 99.0, "episode/score": 0.09822618460384547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09822618460384547}
{"step": 269584, "time": 13853.085034132004, "episode/length": 38.0, "episode/score": 0.04791666567325592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04791666567325592}
{"step": 269752, "time": 13860.73462343216, "episode/length": 146.0, "episode/score": 0.14264210611690942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14264210611690942}
{"step": 269928, "time": 13869.023271799088, "episode/length": 152.0, "episode/score": 0.16350926612540206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16350926612540206}
{"step": 269960, "time": 13871.811718463898, "episode/length": 207.0, "episode/score": 0.23273939497266838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23273939497266838}
{"step": 269976, "time": 13874.170306682587, "episode/length": 297.0, "episode/score": 0.3438969237049605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3438969237049605}
{"step": 270088, "time": 13899.09942150116, "eval_episode/length": 99.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 270088, "time": 13902.91084909439, "eval_episode/length": 139.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 270088, "time": 13905.114493608475, "eval_episode/length": 151.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.993421052631579}
{"step": 270088, "time": 13907.21464395523, "eval_episode/length": 164.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 270088, "time": 13909.132086753845, "eval_episode/length": 172.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 270088, "time": 13910.912694454193, "eval_episode/length": 176.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 270088, "time": 13913.12917137146, "eval_episode/length": 192.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 270088, "time": 13918.61627483368, "eval_episode/length": 288.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9896193771626297}
{"step": 270288, "time": 13926.258986473083, "episode/length": 148.0, "episode/score": 0.16131007732474245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16131007732474245}
{"step": 270352, "time": 13931.697231054306, "episode/length": 212.0, "episode/score": 0.23620259159361012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23620259159361012}
{"step": 270800, "time": 13950.016117095947, "episode/length": 151.0, "episode/score": 0.16029843492924556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16029843492924556}
{"step": 270888, "time": 13954.568735599518, "episode/length": 187.0, "episode/score": 0.18967354481719667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18967354481719667}
{"step": 271104, "time": 13964.31925702095, "episode/length": 168.0, "episode/score": 0.16689469371613086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16689469371613086}
{"step": 271112, "time": 13965.903803825378, "episode/length": 141.0, "episode/score": 0.13485083782870788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13485083782870788}
{"step": 271144, "time": 13968.658406496048, "episode/length": 147.0, "episode/score": 0.1541550209176421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1541550209176421}
{"step": 271488, "time": 13983.102515935898, "episode/length": 42.0, "episode/score": 0.044711308990372345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044711308990372345}
{"step": 271736, "time": 13993.677801132202, "episode/length": 180.0, "episode/score": 0.18633911685537896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18633911685537896}
{"step": 271864, "time": 14000.139922380447, "episode/length": 241.0, "episode/score": 0.28719237655968755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28719237655968755}
{"step": 272040, "time": 14008.319702148438, "episode/length": 154.0, "episode/score": 0.15709536105714506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15709536105714506}
{"step": 272072, "time": 14011.596897602081, "episode/length": 119.0, "episode/score": 0.11664411566925992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11664411566925992}
{"step": 272160, "time": 14017.181180477142, "episode/length": 225.0, "episode/score": 0.2357065823616722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2357065823616722}
{"step": 272208, "time": 14020.981463432312, "episode/length": 164.0, "episode/score": 0.17102392826836876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17102392826836876}
{"step": 272224, "time": 14023.450367689133, "episode/length": 139.0, "episode/score": 0.1427849536830763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1427849536830763}
{"step": 272912, "time": 14050.657906770706, "episode/length": 130.0, "episode/score": 0.1419912280907738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1419912280907738}
{"step": 273040, "time": 14057.043813705444, "episode/length": 193.0, "episode/score": 0.20492635624123068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20492635624123068}
{"step": 273048, "time": 14058.747013807297, "episode/length": 163.0, "episode/score": 0.1826018717374609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1826018717374609}
{"step": 273384, "time": 14072.817469835281, "episode/length": 146.0, "episode/score": 0.16345952217307058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16345952217307058}
{"step": 273448, "time": 14076.833474874496, "episode/length": 171.0, "episode/score": 0.1840297590533737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1840297590533737}
{"step": 273528, "time": 14081.413567066193, "episode/length": 170.0, "episode/score": 0.192834666941053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.192834666941053}
{"step": 273632, "time": 14087.144922971725, "episode/length": 175.0, "episode/score": 0.2010886728321566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2010886728321566}
{"step": 273832, "time": 14095.976744413376, "episode/length": 223.0, "episode/score": 0.2491866107993701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2491866107993701}
{"step": 274360, "time": 14117.593464374542, "episode/length": 163.0, "episode/score": 0.17610764663095324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17610764663095324}
{"step": 274376, "time": 14120.28579735756, "episode/length": 182.0, "episode/score": 0.18605513641887228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18605513641887228}
{"step": 274408, "time": 14123.494598150253, "episode/length": 170.0, "episode/score": 0.19362320152504253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19362320152504253}
{"step": 274680, "time": 14135.66670680046, "episode/length": 161.0, "episode/score": 0.17476150009224511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17476150009224511}
{"step": 274888, "time": 14145.058238983154, "episode/length": 169.0, "episode/score": 0.17350428401005047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17350428401005047}
{"step": 274992, "time": 14150.748798131943, "episode/length": 169.0, "episode/score": 0.18683103359035158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18683103359035158}
{"step": 275240, "time": 14161.587470531464, "episode/length": 223.0, "episode/score": 0.23834984159748274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23834984159748274}
{"step": 275272, "time": 14164.747239351273, "episode/length": 179.0, "episode/score": 0.20169979264937865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20169979264937865}
{"step": 275552, "time": 14177.691770076752, "episode/length": 148.0, "episode/score": 0.16824618287228077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16824618287228077}
{"step": 275576, "time": 14179.859691143036, "episode/length": 149.0, "episode/score": 0.15463633645867958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15463633645867958}
{"step": 276136, "time": 14202.50402188301, "episode/length": 142.0, "episode/score": 0.1520458034551666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1520458034551666}
{"step": 276280, "time": 14210.203043699265, "episode/length": 199.0, "episode/score": 0.22735272562840692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22735272562840692}
{"step": 276328, "time": 14214.057881355286, "episode/length": 239.0, "episode/score": 0.252712326380788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.252712326380788}
{"step": 276360, "time": 14217.3358066082, "episode/length": 183.0, "episode/score": 0.20373135487716354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20373135487716354}
{"step": 276616, "time": 14228.961676359177, "episode/length": 167.0, "episode/score": 0.17579422965354752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17579422965354752}
{"step": 276640, "time": 14231.673241853714, "episode/length": 174.0, "episode/score": 0.17630427871290522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17630427871290522}
{"step": 276896, "time": 14243.10798215866, "episode/length": 167.0, "episode/score": 0.18786325056134956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18786325056134956}
{"step": 276960, "time": 14247.560028553009, "episode/length": 172.0, "episode/score": 0.1984967610806052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1984967610806052}
{"step": 277368, "time": 14264.753406047821, "episode/length": 153.0, "episode/score": 0.16916765236373976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16916765236373976}
{"step": 277720, "time": 14279.385930776596, "episode/length": 173.0, "episode/score": 0.1695338808804081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1695338808804081}
{"step": 277792, "time": 14283.899592876434, "episode/length": 188.0, "episode/score": 0.20602083023595696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20602083023595696}
{"step": 277896, "time": 14289.105008363724, "episode/length": 191.0, "episode/score": 0.2037809274220308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2037809274220308}
{"step": 277928, "time": 14291.850566148758, "episode/length": 160.0, "episode/score": 0.15762038810635204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15762038810635204}
{"step": 277984, "time": 14295.849348783493, "episode/length": 170.0, "episode/score": 0.18881731951387337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18881731951387337}
{"step": 278120, "time": 14302.260222434998, "episode/length": 144.0, "episode/score": 0.1630199451487897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1630199451487897}
{"step": 278200, "time": 14306.772818565369, "episode/length": 162.0, "episode/score": 0.17348651788324787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17348651788324787}
{"step": 279216, "time": 14347.947875261307, "episode/length": 230.0, "episode/score": 0.22491264239806696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22491264239806696}
{"step": 279232, "time": 14350.214399337769, "episode/length": 166.0, "episode/score": 0.16018135657350285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16018135657350285}
{"step": 279272, "time": 14353.015634059906, "episode/length": 143.0, "episode/score": 0.16981586473229981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16981586473229981}
{"step": 279368, "time": 14358.372328281403, "episode/length": 172.0, "episode/score": 0.17130661039891493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17130661039891493}
{"step": 279528, "time": 14366.583050012589, "episode/length": 216.0, "episode/score": 0.23050349874756648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23050349874756648}
{"step": 279552, "time": 14369.351507425308, "episode/length": 168.0, "episode/score": 0.17630875851955352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17630875851955352}
{"step": 280072, "time": 14405.547087669373, "eval_episode/length": 53.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9259259259259259}
{"step": 280072, "time": 14412.334239721298, "eval_episode/length": 142.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.993006993006993}
{"step": 280072, "time": 14414.81667470932, "eval_episode/length": 157.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 280072, "time": 14416.907129526138, "eval_episode/length": 168.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 280072, "time": 14418.658565998077, "eval_episode/length": 171.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 280072, "time": 14420.949421167374, "eval_episode/length": 188.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 280072, "time": 14422.809820890427, "eval_episode/length": 50.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 280072, "time": 14424.713722467422, "eval_episode/length": 41.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9047619047619048}
{"step": 280073, "time": 14425.771349191666, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.32200439453125, "train/action_min": 0.0, "train/action_std": 5.103873779296875, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007164980756118894, "train/actor_opt_grad_steps": 16780.0, "train/actor_opt_loss": -8.785837853193284, "train/adv_mag": 0.16309525644779205, "train/adv_max": 0.10644944262504577, "train/adv_mean": 3.798568421370874e-05, "train/adv_min": -0.16241002207994462, "train/adv_std": 0.012672227468341589, "train/cont_avg": 0.99465625, "train/cont_loss_mean": 0.00040727529043761023, "train/cont_loss_std": 0.012486779145863693, "train/cont_neg_acc": 0.9931111121177674, "train/cont_neg_loss": 0.03857625214828658, "train/cont_pos_acc": 0.9999449892044068, "train/cont_pos_loss": 0.00021177427451627296, "train/cont_pred": 0.9946467289924622, "train/cont_rate": 0.99465625, "train/dyn_loss_mean": 12.83562484741211, "train/dyn_loss_std": 7.956417789459229, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17531900343298912, "train/extr_critic_critic_opt_grad_steps": 16780.0, "train/extr_critic_critic_opt_loss": 10740.7200859375, "train/extr_critic_mag": 0.26022041606903074, "train/extr_critic_max": 0.26022041606903074, "train/extr_critic_mean": 0.2014932689666748, "train/extr_critic_min": 0.004057473182678223, "train/extr_critic_std": 0.05783636148273945, "train/extr_return_normed_mag": 0.20784043765068055, "train/extr_return_normed_max": 0.20784043765068055, "train/extr_return_normed_mean": 0.1505348210334778, "train/extr_return_normed_min": -0.04999466308951378, "train/extr_return_normed_std": 0.05928182058036327, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.25883694958686826, "train/extr_return_raw_max": 0.25883694958686826, "train/extr_return_raw_mean": 0.20153133487701416, "train/extr_return_raw_min": 0.0010018482208251952, "train/extr_return_raw_std": 0.05928182055056095, "train/extr_reward_mag": 0.001390310287475586, "train/extr_reward_max": 0.001390310287475586, "train/extr_reward_mean": 0.0010890230955556035, "train/extr_reward_min": 9.929656982421876e-06, "train/extr_reward_std": 0.0002344735226361081, "train/image_loss_mean": 7.363970119476319, "train/image_loss_std": 11.627503295898437, "train/model_loss_mean": 15.105477561950684, "train/model_loss_std": 14.873686210632325, "train/model_opt_grad_norm": 66.75731262207032, "train/model_opt_grad_steps": 16761.672, "train/model_opt_loss": 19034.9274765625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1260.0, "train/policy_entropy_mag": 2.76216015625, "train/policy_entropy_max": 2.76216015625, "train/policy_entropy_mean": 2.123242474555969, "train/policy_entropy_min": 0.08853706276416778, "train/policy_entropy_std": 0.5678012166023254, "train/policy_logprob_mag": 7.435681739807129, "train/policy_logprob_max": -0.010768057756125927, "train/policy_logprob_mean": -2.124443976402283, "train/policy_logprob_min": -7.435681739807129, "train/policy_logprob_std": 1.1309092211723328, "train/policy_randomness_mag": 0.9749213190078735, "train/policy_randomness_max": 0.9749213190078735, "train/policy_randomness_mean": 0.7494114155769348, "train/policy_randomness_min": 0.031249697744846344, "train/policy_randomness_std": 0.20040891253948212, "train/post_ent_mag": 54.72796411132813, "train/post_ent_max": 54.72796411132813, "train/post_ent_mean": 37.06429867553711, "train/post_ent_min": 20.232528060913086, "train/post_ent_std": 6.22585615158081, "train/prior_ent_mag": 63.70146133422852, "train/prior_ent_max": 63.70146133422852, "train/prior_ent_mean": 50.034750244140625, "train/prior_ent_min": 27.926028884887696, "train/prior_ent_std": 5.5458090877532955, "train/rep_loss_mean": 12.83562484741211, "train/rep_loss_std": 7.956417789459229, "train/reward_avg": 0.0010506599824875594, "train/reward_loss_mean": 0.039725291520357135, "train/reward_loss_std": 0.011627589195966721, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013316564559936524, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039725291699171064, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010506347808986903, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.11785713024437428, "train_stats/max_log_achievement_collect_drink": 0.07142857142857142, "train_stats/max_log_achievement_collect_sapling": 0.4107142857142857, "train_stats/max_log_achievement_collect_wood": 0.14285714285714285, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3125, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.2857142857142857, "train_stats/mean_log_entropy": 2.1995084392172948, "eval_stats/sum_log_reward": -0.08750000596046448, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 6.809561455156654e-06, "report/cont_loss_std": 5.263431012281217e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00013792757818009704, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.424298135243589e-06, "report/cont_pred": 0.9970643520355225, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.785953521728516, "report/dyn_loss_std": 8.222816467285156, "report/image_loss_mean": 6.2548699378967285, "report/image_loss_std": 10.164482116699219, "report/model_loss_mean": 13.96550178527832, "report/model_loss_std": 13.62717342376709, "report/post_ent_mag": 55.880516052246094, "report/post_ent_max": 55.880516052246094, "report/post_ent_mean": 37.260398864746094, "report/post_ent_min": 20.29549789428711, "report/post_ent_std": 6.223230838775635, "report/prior_ent_mag": 63.76901626586914, "report/prior_ent_max": 63.76901626586914, "report/prior_ent_mean": 50.21795654296875, "report/prior_ent_min": 25.506526947021484, "report/prior_ent_std": 6.028746604919434, "report/rep_loss_mean": 12.785953521728516, "report/rep_loss_std": 8.222816467285156, "report/reward_avg": 0.0010328399948775768, "report/reward_loss_mean": 0.03905324637889862, "report/reward_loss_std": 0.012655742466449738, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001295328140258789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03905324637889862, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010147830471396446, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.223415741464123e-05, "eval/cont_loss_std": 0.0021275291219353676, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00029001233633607626, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.159425149438903e-05, "eval/cont_pred": 0.9970019459724426, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.323657989501953, "eval/dyn_loss_std": 9.243454933166504, "eval/image_loss_mean": 20.371686935424805, "eval/image_loss_std": 34.06382751464844, "eval/model_loss_mean": 31.916173934936523, "eval/model_loss_std": 36.76309585571289, "eval/post_ent_mag": 54.73313903808594, "eval/post_ent_max": 54.73313903808594, "eval/post_ent_mean": 37.33778381347656, "eval/post_ent_min": 19.14842987060547, "eval/post_ent_std": 6.5463080406188965, "eval/prior_ent_mag": 63.76901626586914, "eval/prior_ent_max": 63.76901626586914, "eval/prior_ent_mean": 51.823646545410156, "eval/prior_ent_min": 22.7036190032959, "eval/prior_ent_std": 5.703606605529785, "eval/rep_loss_mean": 18.323657989501953, "eval/rep_loss_std": 9.243454933166504, "eval/reward_avg": 0.0042968750931322575, "eval/reward_loss_mean": 0.5502209663391113, "eval/reward_loss_std": 3.1361160278320312, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012412071228027344, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.40241384506225586, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.321720123291016, "eval/reward_pred": 0.0010554257314652205, "eval/reward_rate": 0.0078125, "replay/size": 279569.0, "replay/inserts": 20072.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.405697982593474e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.487606428533911e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57488.0, "eval_replay/inserts": 3912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2671167377557736e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1022.1792461872101, "timer/env.step_count": 2509.0, "timer/env.step_total": 256.4537920951843, "timer/env.step_frac": 0.2508892574876396, "timer/env.step_avg": 0.10221354806503959, "timer/env.step_min": 0.023282766342163086, "timer/env.step_max": 3.3656013011932373, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 9.839474439620972, "timer/replay._sample_frac": 0.009625977514533583, "timer/replay._sample_avg": 0.0004900136673118014, "timer/replay._sample_min": 0.0003521442413330078, "timer/replay._sample_max": 0.021813392639160156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2998.0, "timer/agent.policy_total": 50.09160852432251, "timer/agent.policy_frac": 0.04900472075828893, "timer/agent.policy_avg": 0.016708341735931456, "timer/agent.policy_min": 0.00934910774230957, "timer/agent.policy_max": 0.11999082565307617, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.14392614364624023, "timer/dataset_train_frac": 0.00014080323405419684, "timer/dataset_train_avg": 0.00011468218617230298, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0003743171691894531, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 566.0438582897186, "timer/agent.train_frac": 0.5537618381522578, "timer/agent.train_avg": 0.4510309627806523, "timer/agent.train_min": 0.43761467933654785, "timer/agent.train_max": 1.1259751319885254, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47733211517333984, "timer/agent.report_frac": 0.00046697496251642484, "timer/agent.report_avg": 0.23866605758666992, "timer/agent.report_min": 0.23093008995056152, "timer/agent.report_max": 0.24640202522277832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.452031513910105e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 19.636210466297022}
{"step": 280080, "time": 14425.79354429245, "episode/length": 65.0, "episode/score": 0.07286475247747148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07286475247747148}
{"step": 280272, "time": 14434.977490186691, "episode/length": 318.0, "episode/score": 0.35831765929151516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35831765929151516}
{"step": 280320, "time": 14438.40538406372, "episode/length": 130.0, "episode/score": 0.14704166415322106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14704166415322106}
{"step": 280488, "time": 14446.009465456009, "episode/length": 158.0, "episode/score": 0.17432420703244134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17432420703244134}
{"step": 280536, "time": 14449.352507591248, "episode/length": 162.0, "episode/score": 0.17848777929248172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17848777929248172}
{"step": 280704, "time": 14457.2483355999, "episode/length": 166.0, "episode/score": 0.17777672070951667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17777672070951667}
{"step": 280808, "time": 14462.605081796646, "episode/length": 159.0, "episode/score": 0.17238094974891283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17238094974891283}
{"step": 281264, "time": 14481.57479929924, "episode/length": 56.0, "episode/score": 0.05966170530882664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05966170530882664}
{"step": 281368, "time": 14487.335856437683, "episode/length": 429.0, "episode/score": 0.38927635355958046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38927635355958046}
{"step": 281472, "time": 14493.712050199509, "episode/length": 173.0, "episode/score": 0.1974017823158647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974017823158647}
{"step": 281744, "time": 14506.32276892662, "episode/length": 177.0, "episode/score": 0.18729414395056665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18729414395056665}
{"step": 281856, "time": 14512.599895477295, "episode/length": 143.0, "episode/score": 0.14668668341619195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14668668341619195}
{"step": 281904, "time": 14515.979744672775, "episode/length": 170.0, "episode/score": 0.18304485126282088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18304485126282088}
{"step": 282032, "time": 14522.218429803848, "episode/length": 219.0, "episode/score": 0.24980776890879497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24980776890879497}
{"step": 282328, "time": 14534.560997962952, "episode/length": 229.0, "episode/score": 0.23518510683788918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23518510683788918}
{"step": 282608, "time": 14546.833902835846, "episode/length": 167.0, "episode/score": 0.18305941276048543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18305941276048543}
{"step": 282624, "time": 14549.028020858765, "episode/length": 156.0, "episode/score": 0.17985477829279262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17985477829279262}
{"step": 282960, "time": 14563.226165056229, "episode/length": 137.0, "episode/score": 0.1578640886255016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1578640886255016}
{"step": 283016, "time": 14567.26533460617, "episode/length": 192.0, "episode/score": 0.20314928120205877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20314928120205877}
{"step": 283272, "time": 14578.948417901993, "episode/length": 190.0, "episode/score": 0.21817902737893746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21817902737893746}
{"step": 283352, "time": 14583.944435358047, "episode/length": 180.0, "episode/score": 0.20260754788978375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20260754788978375}
{"step": 283664, "time": 14597.441843509674, "episode/length": 203.0, "episode/score": 0.21178739966489957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21178739966489957}
{"step": 283664, "time": 14597.449424505234, "episode/length": 129.0, "episode/score": 0.14361408501281403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14361408501281403}
{"step": 284232, "time": 14621.963467359543, "episode/length": 237.0, "episode/score": 0.2565751615074987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2565751615074987}
{"step": 284288, "time": 14626.554820775986, "episode/length": 158.0, "episode/score": 0.17688163402635837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17688163402635837}
{"step": 284384, "time": 14631.75140953064, "episode/length": 221.0, "episode/score": 0.24782711386069423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24782711386069423}
{"step": 284440, "time": 14635.307390451431, "episode/length": 184.0, "episode/score": 0.19736470624775393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19736470624775393}
{"step": 284584, "time": 14642.326826334, "episode/length": 163.0, "episode/score": 0.16785280481781228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16785280481781228}
{"step": 284776, "time": 14651.694053649902, "episode/length": 177.0, "episode/score": 0.19485383048231597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19485383048231597}
{"step": 284912, "time": 14658.784719944, "episode/length": 155.0, "episode/score": 0.1592753683362389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1592753683362389}
{"step": 285456, "time": 14680.656211614609, "episode/length": 152.0, "episode/score": 0.16894673919887282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16894673919887282}
{"step": 285488, "time": 14683.42924785614, "episode/length": 130.0, "episode/score": 0.14780952116416302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14780952116416302}
{"step": 285672, "time": 14691.71377491951, "episode/length": 160.0, "episode/score": 0.159330700753344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159330700753344}
{"step": 285784, "time": 14697.409741640091, "episode/length": 125.0, "episode/score": 0.15366736959913396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15366736959913396}
{"step": 285864, "time": 14701.90861916542, "episode/length": 274.0, "episode/score": 0.2815944414069236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2815944414069236}
{"step": 286056, "time": 14710.661199569702, "episode/length": 142.0, "episode/score": 0.155203011156118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.155203011156118}
{"step": 286128, "time": 14715.821192502975, "episode/length": 192.0, "episode/score": 0.18378457806102233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18378457806102233}
{"step": 286200, "time": 14719.885110855103, "episode/length": 238.0, "episode/score": 0.2660002689808607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2660002689808607}
{"step": 286712, "time": 14741.612003803253, "episode/length": 156.0, "episode/score": 0.16234669491677778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16234669491677778}
{"step": 286816, "time": 14748.939596414566, "episode/length": 165.0, "episode/score": 0.1966067575449415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1966067575449415}
{"step": 287128, "time": 14761.875940561295, "episode/length": 181.0, "episode/score": 0.19547426969074877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19547426969074877}
{"step": 287144, "time": 14764.136206388474, "episode/length": 169.0, "episode/score": 0.17308224087355484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17308224087355484}
{"step": 287320, "time": 14772.216145515442, "episode/length": 139.0, "episode/score": 0.1307250603567809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1307250603567809}
{"step": 287392, "time": 14776.724255800247, "episode/length": 157.0, "episode/score": 0.18644141558797855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18644141558797855}
{"step": 287464, "time": 14780.732276439667, "episode/length": 175.0, "episode/score": 0.1832272746032686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832272746032686}
{"step": 287848, "time": 14796.636351108551, "episode/length": 247.0, "episode/score": 0.2503811033730017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2503811033730017}
{"step": 288024, "time": 14804.703815937042, "episode/length": 150.0, "episode/score": 0.1711900283007708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1711900283007708}
{"step": 288168, "time": 14811.528115987778, "episode/length": 181.0, "episode/score": 0.20542775960166182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20542775960166182}
{"step": 288424, "time": 14822.51819062233, "episode/length": 159.0, "episode/score": 0.1577383627773088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577383627773088}
{"step": 288576, "time": 14829.98809671402, "episode/length": 50.0, "episode/score": 0.049745624644856434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049745624644856434}
{"step": 288696, "time": 14835.93779540062, "episode/length": 195.0, "episode/score": 0.189798379833519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.189798379833519}
{"step": 288856, "time": 14843.412086248398, "episode/length": 173.0, "episode/score": 0.19243032679514727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19243032679514727}
{"step": 289040, "time": 14852.18135213852, "episode/length": 214.0, "episode/score": 0.21014907123208104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21014907123208104}
{"step": 289176, "time": 14858.625654459, "episode/length": 165.0, "episode/score": 0.1822859626445279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1822859626445279}
{"step": 289520, "time": 14873.194189310074, "episode/length": 186.0, "episode/score": 0.21977380538010038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21977380538010038}
{"step": 289528, "time": 14874.854592084885, "episode/length": 266.0, "episode/score": 0.30445721270370996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30445721270370996}
{"step": 289576, "time": 14878.138653039932, "episode/length": 124.0, "episode/score": 0.1353494892737217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1353494892737217}
{"step": 289632, "time": 14881.994272470474, "episode/length": 150.0, "episode/score": 0.15983404769576737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15983404769576737}
{"step": 290056, "time": 14922.800149917603, "eval_episode/length": 131.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 290056, "time": 14926.160021066666, "eval_episode/length": 157.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 290056, "time": 14928.993026971817, "eval_episode/length": 173.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 290056, "time": 14931.193974733353, "eval_episode/length": 175.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 290056, "time": 14933.898790836334, "eval_episode/length": 189.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 290056, "time": 14935.83542394638, "eval_episode/length": 191.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 290056, "time": 14937.795073270798, "eval_episode/length": 42.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8837209302325582}
{"step": 290056, "time": 14939.763734817505, "eval_episode/length": 207.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 290128, "time": 14942.64498090744, "episode/length": 178.0, "episode/score": 0.18234861028213345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18234861028213345}
{"step": 290280, "time": 14949.744012832642, "episode/length": 177.0, "episode/score": 0.18518959412904223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18518959412904223}
{"step": 290496, "time": 14960.300549268723, "episode/length": 181.0, "episode/score": 0.19719019155854767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19719019155854767}
{"step": 290696, "time": 14969.08166384697, "episode/length": 139.0, "episode/score": 0.12705000974801806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12705000974801806}
{"step": 290712, "time": 14971.300862312317, "episode/length": 147.0, "episode/score": 0.17304932219667535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17304932219667535}
{"step": 291384, "time": 14997.989037752151, "episode/length": 218.0, "episode/score": 0.21212401528282498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21212401528282498}
{"step": 291464, "time": 15002.462796211243, "episode/length": 166.0, "episode/score": 0.1685607774888922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1685607774888922}
{"step": 291536, "time": 15006.921115159988, "episode/length": 294.0, "episode/score": 0.3325803869138326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3325803869138326}
{"step": 291768, "time": 15016.769248247147, "episode/length": 185.0, "episode/score": 0.18589403753867373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18589403753867373}
{"step": 292000, "time": 15027.160031080246, "episode/length": 162.0, "episode/score": 0.16304943037539488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16304943037539488}
{"step": 292040, "time": 15029.93827199936, "episode/length": 165.0, "episode/score": 0.19079012696784048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19079012696784048}
{"step": 292048, "time": 15031.962904930115, "episode/length": 193.0, "episode/score": 0.21662711863882578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21662711863882578}
{"step": 292488, "time": 15049.621807336807, "episode/length": 137.0, "episode/score": 0.14107474025149713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14107474025149713}
{"step": 292680, "time": 15058.42838191986, "episode/length": 394.0, "episode/score": 0.3984232395532672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3984232395532672}
{"step": 292840, "time": 15066.038345813751, "episode/length": 171.0, "episode/score": 0.2009610123013772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2009610123013772}
{"step": 293152, "time": 15079.62140750885, "episode/length": 143.0, "episode/score": 0.1540198587172199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1540198587172199}
{"step": 293272, "time": 15085.368884801865, "episode/length": 187.0, "episode/score": 0.20117257669153332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20117257669153332}
{"step": 293416, "time": 15092.328561306, "episode/length": 171.0, "episode/score": 0.19514711984265887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19514711984265887}
{"step": 293632, "time": 15102.114448308945, "episode/length": 261.0, "episode/score": 0.2967622028781989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2967622028781989}
{"step": 293976, "time": 15116.255714654922, "episode/length": 240.0, "episode/score": 0.2524876014531401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2524876014531401}
{"step": 293992, "time": 15118.439301490784, "episode/length": 187.0, "episode/score": 0.18886458737324574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18886458737324574}
{"step": 294040, "time": 15121.720329284668, "episode/length": 149.0, "episode/score": 0.18000594872864895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18000594872864895}
{"step": 294584, "time": 15143.576010227203, "episode/length": 237.0, "episode/score": 0.27016333795927494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27016333795927494}
{"step": 294832, "time": 15154.657721996307, "episode/length": 209.0, "episode/score": 0.2272766640599002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2272766640599002}
{"step": 294912, "time": 15159.45330452919, "episode/length": 186.0, "episode/score": 0.19821687792500597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19821687792500597}
{"step": 294976, "time": 15164.996025323868, "episode/length": 212.0, "episode/score": 0.21487093769064813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21487093769064813}
{"step": 295112, "time": 15171.378661632538, "episode/length": 139.0, "episode/score": 0.15600311513298948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15600311513298948}
{"step": 295192, "time": 15175.902025461197, "episode/length": 194.0, "episode/score": 0.22381504295844934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22381504295844934}
{"step": 295824, "time": 15201.2327542305, "episode/length": 230.0, "episode/score": 0.25179378472876124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25179378472876124}
{"step": 295960, "time": 15207.608620405197, "episode/length": 239.0, "episode/score": 0.241966507750476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.241966507750476}
{"step": 295992, "time": 15210.313460350037, "episode/length": 144.0, "episode/score": 0.15975327307387488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15975327307387488}
{"step": 296160, "time": 15218.318746089935, "episode/length": 196.0, "episode/score": 0.2006687573975796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2006687573975796}
{"step": 296328, "time": 15225.91791176796, "episode/length": 176.0, "episode/score": 0.18822059056219587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18822059056219587}
{"step": 296472, "time": 15232.718039512634, "episode/length": 159.0, "episode/score": 0.1728278944142403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1728278944142403}
{"step": 296504, "time": 15235.448883771896, "episode/length": 173.0, "episode/score": 0.18518046121289444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18518046121289444}
{"step": 296600, "time": 15240.577097654343, "episode/length": 202.0, "episode/score": 0.2170887185520769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2170887185520769}
{"step": 297208, "time": 15264.626913309097, "episode/length": 172.0, "episode/score": 0.14321583450782782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14321583450782782}
{"step": 297336, "time": 15270.862027645111, "episode/length": 167.0, "episode/score": 0.1796350940899174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1796350940899174}
{"step": 297368, "time": 15273.719539642334, "episode/length": 150.0, "episode/score": 0.14306305466379854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14306305466379854}
{"step": 297480, "time": 15279.54141664505, "episode/length": 189.0, "episode/score": 0.18391487655298988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18391487655298988}
{"step": 297504, "time": 15282.702692985535, "episode/length": 112.0, "episode/score": 0.11280797611243543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11280797611243543}
{"step": 297568, "time": 15287.312360286713, "episode/length": 154.0, "episode/score": 0.16851174198245644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16851174198245644}
{"step": 298016, "time": 15306.6130797863, "episode/length": 188.0, "episode/score": 0.20026977513316524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20026977513316524}
{"step": 298208, "time": 15316.178629398346, "episode/length": 216.0, "episode/score": 0.21388377654329815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21388377654329815}
{"step": 298232, "time": 15318.836455583572, "episode/length": 111.0, "episode/score": 0.1343194418004714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1343194418004714}
{"step": 298464, "time": 15330.10087108612, "episode/length": 136.0, "episode/score": 0.15879166376544163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15879166376544163}
{"step": 298768, "time": 15343.574852466583, "episode/length": 194.0, "episode/score": 0.2118419312437254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2118419312437254}
{"step": 299024, "time": 15354.79682970047, "episode/length": 192.0, "episode/score": 0.20120210905997737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20120210905997737}
{"step": 299120, "time": 15359.995643854141, "episode/length": 193.0, "episode/score": 0.19913411206789533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19913411206789533}
{"step": 299336, "time": 15370.053152799606, "episode/length": 137.0, "episode/score": 0.1259032691664288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1259032691664288}
{"step": 299344, "time": 15372.08448433876, "episode/length": 165.0, "episode/score": 0.15920865452790167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15920865452790167}
{"step": 299360, "time": 15374.340658426285, "episode/length": 231.0, "episode/score": 0.2566748588455994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2566748588455994}
{"step": 299664, "time": 15387.258689641953, "episode/length": 181.0, "episode/score": 0.18679300815483657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18679300815483657}
{"step": 300040, "time": 15402.663907766342, "episode/length": 158.0, "episode/score": 0.15194195369303998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15194195369303998}
{"step": 300040, "time": 15420.816683769226, "eval_episode/length": 127.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.953125}
{"step": 300040, "time": 15423.577877759933, "eval_episode/length": 156.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 300040, "time": 15425.567085266113, "eval_episode/length": 164.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 300040, "time": 15427.192812681198, "eval_episode/length": 167.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 300040, "time": 15428.912003278732, "eval_episode/length": 171.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 300040, "time": 15430.52075958252, "eval_episode/length": 172.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.976878612716763}
{"step": 300040, "time": 15432.985249042511, "eval_episode/length": 192.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 300040, "time": 15437.453224420547, "eval_episode/length": 260.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 300041, "time": 15440.105905771255, "train_stats/sum_log_reward": 0.3499999983635332, "train_stats/max_log_achievement_collect_drink": 0.09821428571428571, "train_stats/max_log_achievement_collect_sapling": 0.49107142857142855, "train_stats/max_log_achievement_collect_wood": 0.25, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.008928571428571428, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.375, "train_stats/max_log_achievement_place_table": 0.008928571428571428, "train_stats/max_log_achievement_wake_up": 0.38392857142857145, "train_stats/mean_log_entropy": 2.2322470151952336, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.25112548828125, "train/action_min": 0.0, "train/action_std": 5.082288146972656, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007540842555463314, "train/actor_opt_grad_steps": 18030.0, "train/actor_opt_loss": -6.017641277074814, "train/adv_mag": 0.17142265784740449, "train/adv_max": 0.11990003627538681, "train/adv_mean": 0.00013925335777457805, "train/adv_min": -0.16916643953323365, "train/adv_std": 0.013474218890070916, "train/cont_avg": 0.994390625, "train/cont_loss_mean": 0.00039936483494943786, "train/cont_loss_std": 0.011549389543215511, "train/cont_neg_acc": 0.9863047642707825, "train/cont_neg_loss": 0.03808538795253844, "train/cont_pos_acc": 0.9999527821540832, "train/cont_pos_loss": 0.00016222035544757318, "train/cont_pred": 0.9943934464454651, "train/cont_rate": 0.994390625, "train/dyn_loss_mean": 12.749395332336427, "train/dyn_loss_std": 7.975685699462891, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1858444886803627, "train/extr_critic_critic_opt_grad_steps": 18030.0, "train/extr_critic_critic_opt_loss": 11205.3896484375, "train/extr_critic_mag": 0.2611098279953003, "train/extr_critic_max": 0.2611098279953003, "train/extr_critic_mean": 0.20491440200805663, "train/extr_critic_min": 0.0027939348220825193, "train/extr_critic_std": 0.06127642858028412, "train/extr_return_normed_mag": 0.2143771401643753, "train/extr_return_normed_max": 0.2143771401643753, "train/extr_return_normed_mean": 0.1587541800737381, "train/extr_return_normed_min": -0.045327603697776796, "train/extr_return_normed_std": 0.06311373153328896, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2606765613555908, "train/extr_return_raw_max": 0.2606765613555908, "train/extr_return_raw_mean": 0.20505360507965087, "train/extr_return_raw_min": 0.0009718179702758789, "train/extr_return_raw_std": 0.06311373150348663, "train/extr_reward_mag": 0.0013776082992553711, "train/extr_reward_max": 0.0013776082992553711, "train/extr_reward_mean": 0.0010893508782610297, "train/extr_reward_min": 9.3231201171875e-06, "train/extr_reward_std": 0.00022962963569443673, "train/image_loss_mean": 6.992225086212158, "train/image_loss_std": 11.471025184631348, "train/model_loss_mean": 14.682101440429687, "train/model_loss_std": 14.744844261169433, "train/model_opt_grad_norm": 62.924738189697266, "train/model_opt_grad_steps": 18010.072, "train/model_opt_loss": 11024.66968359375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 750.0, "train/policy_entropy_mag": 2.7615161838531495, "train/policy_entropy_max": 2.7615161838531495, "train/policy_entropy_mean": 2.1159705333709717, "train/policy_entropy_min": 0.0862237759232521, "train/policy_entropy_std": 0.5745064873695374, "train/policy_logprob_mag": 7.435433937072754, "train/policy_logprob_max": -0.010427106447517872, "train/policy_logprob_mean": -2.1161307315826416, "train/policy_logprob_min": -7.435433937072754, "train/policy_logprob_std": 1.1407109928131103, "train/policy_randomness_mag": 0.9746940293312073, "train/policy_randomness_max": 0.9746940293312073, "train/policy_randomness_mean": 0.7468447389602662, "train/policy_randomness_min": 0.030433209106326103, "train/policy_randomness_std": 0.20277558076381683, "train/post_ent_mag": 55.23466751098633, "train/post_ent_max": 55.23466751098633, "train/post_ent_mean": 37.4370387878418, "train/post_ent_min": 20.09904635620117, "train/post_ent_std": 6.336658020019531, "train/prior_ent_mag": 63.95717886352539, "train/prior_ent_max": 63.95717886352539, "train/prior_ent_mean": 50.308875366210934, "train/prior_ent_min": 28.420467346191405, "train/prior_ent_std": 5.422184692382812, "train/rep_loss_mean": 12.749395332336427, "train/rep_loss_std": 7.975685699462891, "train/reward_avg": 0.0010537949055433274, "train/reward_loss_mean": 0.03983982133865356, "train/reward_loss_std": 0.011401616223156451, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013123521804809571, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039839821010828017, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010533731011673807, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.47499997820705175, "eval_stats/max_log_achievement_collect_drink": 0.1875, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.912090950412676e-06, "report/cont_loss_std": 0.0002303637593286112, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.568622560123913e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.775809535814915e-06, "report/cont_pred": 0.9951096773147583, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.28152084350586, "report/dyn_loss_std": 8.216235160827637, "report/image_loss_mean": 5.646304130554199, "report/image_loss_std": 10.376219749450684, "report/model_loss_mean": 12.452718734741211, "report/model_loss_std": 14.015868186950684, "report/post_ent_mag": 53.916412353515625, "report/post_ent_max": 53.916412353515625, "report/post_ent_mean": 36.3153076171875, "report/post_ent_min": 19.50791358947754, "report/post_ent_std": 5.884932041168213, "report/prior_ent_mag": 62.751319885253906, "report/prior_ent_max": 62.751319885253906, "report/prior_ent_mean": 47.44652557373047, "report/prior_ent_min": 25.244243621826172, "report/prior_ent_std": 6.628451824188232, "report/rep_loss_mean": 11.28152084350586, "report/rep_loss_std": 8.216235160827637, "report/reward_avg": 0.0009868821362033486, "report/reward_loss_mean": 0.037493981420993805, "report/reward_loss_std": 0.013535571284592152, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013053417205810547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.037493981420993805, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0009934266563504934, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.154166723921662e-06, "eval/cont_loss_std": 0.00021056561672594398, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.3322632841882296e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.09075993654551e-06, "eval/cont_pred": 0.9960868954658508, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.877958297729492, "eval/dyn_loss_std": 10.62267017364502, "eval/image_loss_mean": 18.738754272460938, "eval/image_loss_std": 22.143342971801758, "eval/model_loss_mean": 30.783447265625, "eval/model_loss_std": 26.82587242126465, "eval/post_ent_mag": 55.239898681640625, "eval/post_ent_max": 55.239898681640625, "eval/post_ent_mean": 36.55180358886719, "eval/post_ent_min": 19.65975570678711, "eval/post_ent_std": 6.143775463104248, "eval/prior_ent_mag": 62.751319885253906, "eval/prior_ent_max": 62.751319885253906, "eval/prior_ent_mean": 51.37908172607422, "eval/prior_ent_min": 28.20707130432129, "eval/prior_ent_std": 5.625478267669678, "eval/rep_loss_mean": 18.877958297729492, "eval/rep_loss_std": 10.62267017364502, "eval/reward_avg": 0.003808593610301614, "eval/reward_loss_mean": 0.7179102897644043, "eval/reward_loss_std": 3.596176862716675, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013517141342163086, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5519809722900391, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.431047439575195, "eval/reward_pred": 0.0010461454512551427, "eval/reward_rate": 0.0087890625, "replay/size": 299537.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.395551057962271e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.547869630348988e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61240.0, "eval_replay/inserts": 3752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2416575254916127e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1014.3228378295898, "timer/env.step_count": 2496.0, "timer/env.step_total": 253.09665703773499, "timer/env.step_frac": 0.24952278268652786, "timer/env.step_avg": 0.10140090426191306, "timer/env.step_min": 0.023107528686523438, "timer/env.step_max": 3.413200855255127, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.882571935653687, "timer/replay._sample_frac": 0.009743024180348779, "timer/replay._sample_avg": 0.0004949204695339387, "timer/replay._sample_min": 0.0003705024719238281, "timer/replay._sample_max": 0.010434150695800781, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2965.0, "timer/agent.policy_total": 47.69686436653137, "timer/agent.policy_frac": 0.04702335645778354, "timer/agent.policy_avg": 0.016086632164091525, "timer/agent.policy_min": 0.009508132934570312, "timer/agent.policy_max": 0.08974790573120117, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14175748825073242, "timer/dataset_train_frac": 0.00013975578875268134, "timer/dataset_train_avg": 0.00011358773097013816, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0003981590270996094, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 561.653463602066, "timer/agent.train_frac": 0.5537225848171488, "timer/agent.train_avg": 0.4500428394247324, "timer/agent.train_min": 0.4383220672607422, "timer/agent.train_max": 1.0484058856964111, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47193193435668945, "timer/agent.report_frac": 0.00046526797658082093, "timer/agent.report_avg": 0.23596596717834473, "timer/agent.report_min": 0.22997546195983887, "timer/agent.report_max": 0.24195647239685059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7501080242431922e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 19.68580113010336}
{"step": 300072, "time": 15441.061361312866, "episode/length": 200.0, "episode/score": 0.21265317370671255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21265317370671255}
{"step": 300128, "time": 15445.17310833931, "episode/length": 97.0, "episode/score": 0.10562976211713249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10562976211713249}
{"step": 300304, "time": 15453.278656721115, "episode/length": 147.0, "episode/score": 0.1741249967017211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1741249967017211}
{"step": 300600, "time": 15466.030916929245, "episode/length": 196.0, "episode/score": 0.17546523199371222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17546523199371222}
{"step": 300608, "time": 15468.696165800095, "episode/length": 158.0, "episode/score": 0.15083530628271546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15083530628271546}
{"step": 300864, "time": 15480.47409081459, "episode/length": 187.0, "episode/score": 0.1731737542427254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731737542427254}
{"step": 300976, "time": 15486.179654121399, "episode/length": 163.0, "episode/score": 0.15795079438566972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15795079438566972}
{"step": 301272, "time": 15498.726792812347, "episode/length": 36.0, "episode/score": 0.039863635720394086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039863635720394086}
{"step": 301408, "time": 15505.59802031517, "episode/length": 170.0, "episode/score": 0.17399042227680184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17399042227680184}
{"step": 301528, "time": 15511.435408830643, "episode/length": 181.0, "episode/score": 0.20959125606805173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20959125606805173}
{"step": 301600, "time": 15515.964307308197, "episode/length": 183.0, "episode/score": 0.187675385309376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187675385309376}
{"step": 301920, "time": 15530.156846523285, "episode/length": 163.0, "episode/score": 0.1778782088549633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1778782088549633}
{"step": 301968, "time": 15533.5583486557, "episode/length": 170.0, "episode/score": 0.17734723917328665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17734723917328665}
{"step": 302040, "time": 15537.57916545868, "episode/length": 216.0, "episode/score": 0.21941119841721957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21941119841721957}
{"step": 302096, "time": 15541.453764677048, "episode/length": 153.0, "episode/score": 0.16201509463371622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16201509463371622}
{"step": 302296, "time": 15550.883244752884, "episode/length": 40.0, "episode/score": 0.04106718437105883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04106718437105883}
{"step": 302416, "time": 15557.31623339653, "episode/length": 110.0, "episode/score": 0.13210714029264636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13210714029264636}
{"step": 302720, "time": 15570.511991024017, "episode/length": 163.0, "episode/score": 0.17707010230060405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17707010230060405}
{"step": 303248, "time": 15593.306447505951, "episode/length": 205.0, "episode/score": 0.201271780676052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.201271780676052}
{"step": 303336, "time": 15597.877629518509, "episode/length": 161.0, "episode/score": 0.1662989977826328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1662989977826328}
{"step": 303336, "time": 15597.885741949081, "episode/length": 176.0, "episode/score": 0.19632110714701412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19632110714701412}
{"step": 303584, "time": 15610.783554792404, "episode/length": 288.0, "episode/score": 0.34098063084093155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34098063084093155}
{"step": 303632, "time": 15614.13239979744, "episode/length": 191.0, "episode/score": 0.20016186681550607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20016186681550607}
{"step": 303712, "time": 15618.747935056686, "episode/length": 161.0, "episode/score": 0.15545187395173343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15545187395173343}
{"step": 303760, "time": 15622.22351026535, "episode/length": 182.0, "episode/score": 0.20448362395336517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20448362395336517}
{"step": 304648, "time": 15656.738654136658, "episode/length": 163.0, "episode/score": 0.17990277521312237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17990277521312237}
{"step": 304648, "time": 15656.746239900589, "episode/length": 174.0, "episode/score": 0.17399263424158562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17399263424158562}
{"step": 304752, "time": 15664.13799571991, "episode/length": 253.0, "episode/score": 0.2903499024869234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2903499024869234}
{"step": 304888, "time": 15670.460983276367, "episode/length": 156.0, "episode/score": 0.16376753226359142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16376753226359142}
{"step": 305008, "time": 15676.78605055809, "episode/length": 177.0, "episode/score": 0.2000378255324904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2000378255324904}
{"step": 305112, "time": 15682.051320314407, "episode/length": 221.0, "episode/score": 0.25558630490559153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25558630490559153}
{"step": 305352, "time": 15692.603821992874, "episode/length": 42.0, "episode/score": 0.04410921654198319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04410921654198319}
{"step": 305584, "time": 15703.036865472794, "episode/length": 233.0, "episode/score": 0.2716738615199574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2716738615199574}
{"step": 305680, "time": 15708.437685728073, "episode/length": 239.0, "episode/score": 0.2661624762858992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2661624762858992}
{"step": 305832, "time": 15715.404478788376, "episode/length": 147.0, "episode/score": 0.1643005926234764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1643005926234764}
{"step": 306064, "time": 15725.83968782425, "episode/length": 176.0, "episode/score": 0.18943175634922227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18943175634922227}
{"step": 306304, "time": 15736.373121738434, "episode/length": 176.0, "episode/score": 0.16553556743019726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16553556743019726}
{"step": 306608, "time": 15749.267944335938, "episode/length": 231.0, "episode/score": 0.2551444097334752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2551444097334752}
{"step": 306680, "time": 15753.314202785492, "episode/length": 136.0, "episode/score": 0.15495348197146086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15495348197146086}
{"step": 306688, "time": 15755.29826593399, "episode/length": 166.0, "episode/score": 0.18377032799617155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18377032799617155}
{"step": 306968, "time": 15767.131707668304, "episode/length": 141.0, "episode/score": 0.15492830242510536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15492830242510536}
{"step": 307128, "time": 15774.521656751633, "episode/length": 251.0, "episode/score": 0.2882333683555771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2882333683555771}
{"step": 307208, "time": 15779.103888988495, "episode/length": 190.0, "episode/score": 0.21297720176517032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21297720176517032}
{"step": 307344, "time": 15785.960967540741, "episode/length": 159.0, "episode/score": 0.16810750724107493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16810750724107493}
{"step": 308008, "time": 15812.168816328049, "episode/length": 212.0, "episode/score": 0.22635783803707454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22635783803707454}
{"step": 308096, "time": 15817.317289352417, "episode/length": 185.0, "episode/score": 0.19425574033084558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19425574033084558}
{"step": 308104, "time": 15819.4580950737, "episode/length": 177.0, "episode/score": 0.1945348139561247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1945348139561247}
{"step": 308384, "time": 15832.479008436203, "episode/length": 211.0, "episode/score": 0.2204564459007088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2204564459007088}
{"step": 308528, "time": 15839.493192434311, "episode/length": 194.0, "episode/score": 0.21827652649881202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21827652649881202}
{"step": 308528, "time": 15839.500656366348, "episode/length": 164.0, "episode/score": 0.19262109193914512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19262109193914512}
{"step": 308720, "time": 15849.859560728073, "episode/length": 171.0, "episode/score": 0.18679408751995652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18679408751995652}
{"step": 308872, "time": 15857.049753427505, "episode/length": 217.0, "episode/score": 0.22883474675836624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22883474675836624}
{"step": 309184, "time": 15870.724789142609, "episode/length": 146.0, "episode/score": 0.15902625637318124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15902625637318124}
{"step": 309392, "time": 15879.95664525032, "episode/length": 160.0, "episode/score": 0.16177074728693697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16177074728693697}
{"step": 309656, "time": 15891.13219499588, "episode/length": 140.0, "episode/score": 0.13594217810441478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13594217810441478}
{"step": 309792, "time": 15897.955701351166, "episode/length": 175.0, "episode/score": 0.20261428974299633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20261428974299633}
{"step": 310016, "time": 15907.806039571762, "episode/length": 185.0, "episode/score": 0.2101286039041952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2101286039041952}
{"step": 310024, "time": 15925.2528693676, "eval_episode/length": 67.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9264705882352942}
{"step": 310024, "time": 15930.332168579102, "eval_episode/length": 144.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.993103448275862}
{"step": 310024, "time": 15933.050251722336, "eval_episode/length": 160.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 310024, "time": 15935.107241392136, "eval_episode/length": 164.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 310024, "time": 15937.618124723434, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 310024, "time": 15939.939169168472, "eval_episode/length": 177.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 310024, "time": 15942.127080202103, "eval_episode/length": 180.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 310024, "time": 15944.893402814865, "eval_episode/length": 202.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 310112, "time": 15948.373876571655, "episode/length": 251.0, "episode/score": 0.2928729959385237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2928729959385237}
{"step": 310304, "time": 15957.003392219543, "episode/length": 197.0, "episode/score": 0.21705245974044374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21705245974044374}
{"step": 310344, "time": 15959.730101585388, "episode/length": 144.0, "episode/score": 0.1637502307366958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637502307366958}
{"step": 310368, "time": 15962.402613639832, "episode/length": 186.0, "episode/score": 0.21376046801742632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21376046801742632}
{"step": 310760, "time": 15978.403137683868, "episode/length": 170.0, "episode/score": 0.1888814843205182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1888814843205182}
{"step": 310952, "time": 15987.074587583542, "episode/length": 161.0, "episode/score": 0.1734136968589155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1734136968589155}
{"step": 311088, "time": 15993.890355587006, "episode/length": 161.0, "episode/score": 0.18247726994741242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18247726994741242}
{"step": 311440, "time": 16010.394084215164, "episode/length": 177.0, "episode/score": 0.18258420626261795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18258420626261795}
{"step": 311584, "time": 16017.89761519432, "episode/length": 159.0, "episode/score": 0.16298011933395173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16298011933395173}
{"step": 311616, "time": 16021.119069337845, "episode/length": 158.0, "episode/score": 0.16055338550086162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16055338550086162}
{"step": 311944, "time": 16034.567086458206, "episode/length": 147.0, "episode/score": 0.14748304663862655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14748304663862655}
{"step": 311984, "time": 16037.822934627533, "episode/length": 233.0, "episode/score": 0.2759547461346301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2759547461346301}
{"step": 312384, "time": 16054.262674093246, "episode/length": 178.0, "episode/score": 0.1943391286813494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1943391286813494}
{"step": 312400, "time": 16056.499997615814, "episode/length": 163.0, "episode/score": 0.18519809052941127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18519809052941127}
{"step": 312568, "time": 16064.275481939316, "episode/length": 140.0, "episode/score": 0.14821168778689753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14821168778689753}
{"step": 312568, "time": 16064.284017324448, "episode/length": 274.0, "episode/score": 0.3095247983792433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3095247983792433}
{"step": 312872, "time": 16079.000368356705, "episode/length": 156.0, "episode/score": 0.16467310761890985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16467310761890985}
{"step": 312960, "time": 16084.013526201248, "episode/length": 171.0, "episode/score": 0.2001833997092035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2001833997092035}
{"step": 313064, "time": 16089.164560317993, "episode/length": 139.0, "episode/score": 0.1371196793998024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1371196793998024}
{"step": 313336, "time": 16101.017524242401, "episode/length": 168.0, "episode/score": 0.17740435658652132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17740435658652132}
{"step": 313704, "time": 16116.433122634888, "episode/length": 162.0, "episode/score": 0.19043471749318996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19043471749318996}
{"step": 313888, "time": 16125.184342622757, "episode/length": 164.0, "episode/score": 0.16759166494102828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16759166494102828}
{"step": 313976, "time": 16130.01191663742, "episode/length": 175.0, "episode/score": 0.19297774796905287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19297774796905287}
{"step": 314352, "time": 16145.817423343658, "episode/length": 160.0, "episode/score": 0.1828883936004786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1828883936004786}
{"step": 314416, "time": 16149.760327577591, "episode/length": 192.0, "episode/score": 0.2119562279285674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2119562279285674}
{"step": 314520, "time": 16155.176508903503, "episode/length": 147.0, "episode/score": 0.15983608953320072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15983608953320072}
{"step": 314720, "time": 16164.373759508133, "episode/length": 291.0, "episode/score": 0.32074772251598915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32074772251598915}
{"step": 314744, "time": 16166.654774188995, "episode/length": 222.0, "episode/score": 0.2243359592584966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2243359592584966}
{"step": 314816, "time": 16171.146452665329, "episode/length": 138.0, "episode/score": 0.1577284778759349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577284778759349}
{"step": 315192, "time": 16186.590030908585, "episode/length": 46.0, "episode/score": 0.05466666567372158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05466666567372158}
{"step": 315432, "time": 16197.078077793121, "episode/length": 126.0, "episode/score": 0.15029166382737458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15029166382737458}
{"step": 315600, "time": 16205.171543836594, "episode/length": 213.0, "episode/score": 0.2165452485842252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2165452485842252}
{"step": 315744, "time": 16212.138382196426, "episode/length": 173.0, "episode/score": 0.18015627393424438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18015627393424438}
{"step": 315792, "time": 16215.558050632477, "episode/length": 158.0, "episode/score": 0.17338936991109222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17338936991109222}
{"step": 315856, "time": 16219.505437850952, "episode/length": 138.0, "episode/score": 0.1590804211973591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1590804211973591}
{"step": 316024, "time": 16227.237639904022, "episode/length": 162.0, "episode/score": 0.17250336273036737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17250336273036737}
{"step": 316280, "time": 16238.638107061386, "episode/length": 287.0, "episode/score": 0.3333768531319947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3333768531319947}
{"step": 316416, "time": 16245.85122704506, "episode/length": 48.0, "episode/score": 0.05222077838698169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05222077838698169}
{"step": 316464, "time": 16249.223962783813, "episode/length": 75.0, "episode/score": 0.08784010676208709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08784010676208709}
{"step": 316656, "time": 16257.835032463074, "episode/length": 152.0, "episode/score": 0.1771738682450632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1771738682450632}
{"step": 316792, "time": 16264.203707933426, "episode/length": 199.0, "episode/score": 0.2142090127154006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2142090127154006}
{"step": 316968, "time": 16272.3861951828, "episode/length": 152.0, "episode/score": 0.16507500475154302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16507500475154302}
{"step": 316968, "time": 16272.393597364426, "episode/length": 170.0, "episode/score": 0.17954547912222552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17954547912222552}
{"step": 317064, "time": 16279.39677810669, "episode/length": 158.0, "episode/score": 0.17059650999772202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17059650999772202}
{"step": 317544, "time": 16299.407296419144, "episode/length": 71.0, "episode/score": 0.07613893286179518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07613893286179518}
{"step": 317640, "time": 16305.013354063034, "episode/length": 169.0, "episode/score": 0.16323100256158796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16323100256158796}
{"step": 317896, "time": 16316.074258565903, "episode/length": 137.0, "episode/score": 0.15201968628389295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15201968628389295}
{"step": 317928, "time": 16318.859246492386, "episode/length": 182.0, "episode/score": 0.21829860686557367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21829860686557367}
{"step": 318088, "time": 16326.389717578888, "episode/length": 208.0, "episode/score": 0.22552374559609234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22552374559609234}
{"step": 318320, "time": 16337.043161869049, "episode/length": 207.0, "episode/score": 0.2502916615922004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2502916615922004}
{"step": 318336, "time": 16339.207449674606, "episode/length": 170.0, "episode/score": 0.18388131214305758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18388131214305758}
{"step": 318568, "time": 16349.15675854683, "episode/length": 187.0, "episode/score": 0.20784383580758004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20784383580758004}
{"step": 318840, "time": 16360.72032737732, "episode/length": 161.0, "episode/score": 0.1969583293539472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1969583293539472}
{"step": 319160, "time": 16374.260384321213, "episode/length": 189.0, "episode/score": 0.2190747314671171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2190747314671171}
{"step": 319304, "time": 16381.185433626175, "episode/length": 171.0, "episode/score": 0.18782320834725397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18782320834725397}
{"step": 319336, "time": 16383.877885103226, "episode/length": 179.0, "episode/score": 0.18826411164627643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18826411164627643}
{"step": 319472, "time": 16391.765594005585, "episode/length": 38.0, "episode/score": 0.04645833245012909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04645833245012909}
{"step": 319568, "time": 16398.60347867012, "episode/length": 184.0, "episode/score": 0.19415953162751975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19415953162751975}
{"step": 319696, "time": 16405.037993192673, "episode/length": 169.0, "episode/score": 0.1884013607595989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1884013607595989}
{"step": 319872, "time": 16413.18544626236, "episode/length": 66.0, "episode/score": 0.0787499985890463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0787499985890463}
{"step": 319896, "time": 16415.352318286896, "episode/length": 165.0, "episode/score": 0.17259139620000497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17259139620000497}
{"step": 319936, "time": 16418.623308181763, "episode/length": 201.0, "episode/score": 0.21850643391735503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21850643391735503}
{"step": 320008, "time": 16440.910746335983, "eval_episode/length": 125.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9920634920634921}
{"step": 320008, "time": 16442.874737262726, "eval_episode/length": 132.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 320008, "time": 16444.574271678925, "eval_episode/length": 137.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 320008, "time": 16446.998569250107, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 320008, "time": 16449.44610977173, "eval_episode/length": 179.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 320008, "time": 16451.181127548218, "eval_episode/length": 180.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.994475138121547}
{"step": 320008, "time": 16452.793127059937, "eval_episode/length": 181.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 320008, "time": 16455.56214427948, "eval_episode/length": 207.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 320009, "time": 16456.60845708847, "train_stats/sum_log_reward": 0.2512604973020674, "train_stats/max_log_achievement_collect_drink": 0.1092436974789916, "train_stats/max_log_achievement_collect_sapling": 0.5210084033613446, "train_stats/max_log_achievement_collect_wood": 0.16806722689075632, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008403361344537815, "train_stats/max_log_achievement_place_plant": 0.40336134453781514, "train_stats/max_log_achievement_place_table": 0.01680672268907563, "train_stats/max_log_achievement_wake_up": 0.23529411764705882, "train_stats/mean_log_entropy": 2.1946582443573894, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.961984375, "train/action_min": 0.0, "train/action_std": 4.954743560791016, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007957192659378052, "train/actor_opt_grad_steps": 19280.0, "train/actor_opt_loss": -5.763120080649853, "train/adv_mag": 0.17190834361314775, "train/adv_max": 0.11408408713340759, "train/adv_mean": 0.00023795391713792924, "train/adv_min": -0.17074126714468002, "train/adv_std": 0.013616515766829252, "train/cont_avg": 0.9947890625, "train/cont_loss_mean": 0.00040239354523737345, "train/cont_loss_std": 0.011181065970152304, "train/cont_neg_acc": 0.9874808004786891, "train/cont_neg_loss": 0.042219664602751644, "train/cont_pos_acc": 0.9999607520103455, "train/cont_pos_loss": 0.00013228075611837654, "train/cont_pred": 0.9948247485160827, "train/cont_rate": 0.9947890625, "train/dyn_loss_mean": 12.639209953308105, "train/dyn_loss_std": 8.005696147918702, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16458587551116943, "train/extr_critic_critic_opt_grad_steps": 19280.0, "train/extr_critic_critic_opt_loss": 11268.72475, "train/extr_critic_mag": 0.26720881938934327, "train/extr_critic_max": 0.26720881938934327, "train/extr_critic_mean": 0.208923899769783, "train/extr_critic_min": 0.0028293724060058593, "train/extr_critic_std": 0.06010756912827492, "train/extr_return_normed_mag": 0.21652589404582978, "train/extr_return_normed_max": 0.21652589404582978, "train/extr_return_normed_mean": 0.15897911262512207, "train/extr_return_normed_min": -0.04921015864610672, "train/extr_return_normed_std": 0.0615951659977436, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.26670862817764285, "train/extr_return_raw_max": 0.26670862817764285, "train/extr_return_raw_mean": 0.20916184771060944, "train/extr_return_raw_min": 0.0009725751876831054, "train/extr_return_raw_std": 0.0615951661169529, "train/extr_reward_mag": 0.001373739242553711, "train/extr_reward_max": 0.001373739242553711, "train/extr_reward_mean": 0.0010974707892164588, "train/extr_reward_min": 1.0379791259765625e-05, "train/extr_reward_std": 0.0002301420213188976, "train/image_loss_mean": 6.839498691558838, "train/image_loss_std": 11.159386997222901, "train/model_loss_mean": 14.463240699768066, "train/model_loss_std": 14.47267995452881, "train/model_opt_grad_norm": 64.38621362304687, "train/model_opt_grad_steps": 19259.68, "train/model_opt_loss": 18212.55459375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1260.0, "train/policy_entropy_mag": 2.7594069595336914, "train/policy_entropy_max": 2.7594069595336914, "train/policy_entropy_mean": 2.1011687240600585, "train/policy_entropy_min": 0.08427860283851624, "train/policy_entropy_std": 0.569854645729065, "train/policy_logprob_mag": 7.437153175354004, "train/policy_logprob_max": -0.010147809989750385, "train/policy_logprob_mean": -2.1007052631378174, "train/policy_logprob_min": -7.437153175354004, "train/policy_logprob_std": 1.1527166147232055, "train/policy_randomness_mag": 0.9739495639801026, "train/policy_randomness_max": 0.9739495639801026, "train/policy_randomness_mean": 0.7416203575134277, "train/policy_randomness_min": 0.02974664834141731, "train/policy_randomness_std": 0.2011336853504181, "train/post_ent_mag": 55.1398512878418, "train/post_ent_max": 55.1398512878418, "train/post_ent_mean": 37.547685150146485, "train/post_ent_min": 20.171702629089356, "train/post_ent_std": 6.3036350212097165, "train/prior_ent_mag": 64.07870663452148, "train/prior_ent_max": 64.07870663452148, "train/prior_ent_mean": 50.254677825927736, "train/prior_ent_min": 28.75589810180664, "train/prior_ent_std": 5.434040193557739, "train/rep_loss_mean": 12.639209953308105, "train/rep_loss_std": 8.005696147918702, "train/reward_avg": 0.0010532703273929656, "train/reward_loss_mean": 0.03981358301639557, "train/reward_loss_std": 0.011497598588466645, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013186731338500977, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039813582926988604, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010537081453949214, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": -0.5875000064261258, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.1875, "eval_stats/max_log_achievement_collect_wood": 0.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00019323719607200474, "report/cont_loss_std": 0.005645946133881807, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03605329617857933, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7280121028306894e-05, "report/cont_pred": 0.9952613115310669, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.440695762634277, "report/dyn_loss_std": 8.490927696228027, "report/image_loss_mean": 5.352400779724121, "report/image_loss_std": 8.386650085449219, "report/model_loss_mean": 12.2567138671875, "report/model_loss_std": 11.928625106811523, "report/post_ent_mag": 54.65170669555664, "report/post_ent_max": 54.65170669555664, "report/post_ent_mean": 38.74586486816406, "report/post_ent_min": 19.914207458496094, "report/post_ent_std": 6.408360004425049, "report/prior_ent_mag": 63.81085205078125, "report/prior_ent_max": 63.81085205078125, "report/prior_ent_mean": 50.175445556640625, "report/prior_ent_min": 31.565841674804688, "report/prior_ent_std": 6.39813756942749, "report/rep_loss_mean": 11.440695762634277, "report/rep_loss_std": 8.490927696228027, "report/reward_avg": 0.00104822451248765, "report/reward_loss_mean": 0.03970302268862724, "report/reward_loss_std": 0.011139961890876293, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03970302268862724, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010315303225070238, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.0009530999232084e-05, "eval/cont_loss_std": 0.000588269205763936, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004064998589456081, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.616968177131639e-07, "eval/cont_pred": 0.9951367378234863, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.896830558776855, "eval/dyn_loss_std": 10.371776580810547, "eval/image_loss_mean": 12.6644287109375, "eval/image_loss_std": 19.792373657226562, "eval/model_loss_mean": 22.67512321472168, "eval/model_loss_std": 24.067615509033203, "eval/post_ent_mag": 56.777870178222656, "eval/post_ent_max": 56.777870178222656, "eval/post_ent_mean": 37.373626708984375, "eval/post_ent_min": 20.515792846679688, "eval/post_ent_std": 6.852381229400635, "eval/prior_ent_mag": 63.81085205078125, "eval/prior_ent_max": 63.81085205078125, "eval/prior_ent_mean": 50.559898376464844, "eval/prior_ent_min": 27.036951065063477, "eval/prior_ent_std": 5.923903465270996, "eval/rep_loss_mean": 15.896830558776855, "eval/rep_loss_std": 10.371776580810547, "eval/reward_avg": 0.005175781436264515, "eval/reward_loss_mean": 0.47257494926452637, "eval/reward_loss_std": 2.947981595993042, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012655258178710938, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.28351572155952454, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.64318084716797, "eval/reward_pred": 0.0009963185293599963, "eval/reward_rate": 0.009765625, "replay/size": 319505.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3938555732751504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.8942742966688597e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 64528.0, "eval_replay/inserts": 3288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.223417964294879e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1016.4886384010315, "timer/env.step_count": 2496.0, "timer/env.step_total": 257.95510721206665, "timer/env.step_frac": 0.2537707727041968, "timer/env.step_avg": 0.10334739872278312, "timer/env.step_min": 0.023293256759643555, "timer/env.step_max": 3.4718658924102783, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.930876016616821, "timer/replay._sample_frac": 0.009769785555339212, "timer/replay._sample_avg": 0.0004973395441014033, "timer/replay._sample_min": 0.00040078163146972656, "timer/replay._sample_max": 0.021088838577270508, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2907.0, "timer/agent.policy_total": 47.209038734436035, "timer/agent.policy_frac": 0.04644325273393841, "timer/agent.policy_avg": 0.016239779406410745, "timer/agent.policy_min": 0.00958871841430664, "timer/agent.policy_max": 0.11125707626342773, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14371943473815918, "timer/dataset_train_frac": 0.00014138813687503124, "timer/dataset_train_avg": 0.00011515980347608909, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010836124420166016, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 564.0163128376007, "timer/agent.train_frac": 0.5548673064608141, "timer/agent.train_avg": 0.45193614810705185, "timer/agent.train_min": 0.4346957206726074, "timer/agent.train_max": 1.4861712455749512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4669966697692871, "timer/agent.report_frac": 0.00045942143584003806, "timer/agent.report_avg": 0.23349833488464355, "timer/agent.report_min": 0.22199463844299316, "timer/agent.report_max": 0.24500203132629395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.049164950034101e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 19.643849216153928}
{"step": 320376, "time": 16470.120772361755, "episode/length": 133.0, "episode/score": 0.15508333063917235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15508333063917235}
{"step": 320808, "time": 16487.946766853333, "episode/length": 166.0, "episode/score": 0.19574122452468146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19574122452468146}
{"step": 320944, "time": 16495.605052947998, "episode/length": 133.0, "episode/score": 0.15799999705632217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15799999705632217}
{"step": 320968, "time": 16498.270489692688, "episode/length": 174.0, "episode/score": 0.17270997217929107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17270997217929107}
{"step": 321288, "time": 16512.479861974716, "episode/length": 305.0, "episode/score": 0.3324842252441158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3324842252441158}
{"step": 321312, "time": 16515.39594101906, "episode/length": 176.0, "episode/score": 0.19055496490909718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19055496490909718}
{"step": 321336, "time": 16517.597245931625, "episode/length": 174.0, "episode/score": 0.20299020617676433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20299020617676433}
{"step": 321576, "time": 16528.428708076477, "episode/length": 234.0, "episode/score": 0.2694821382756345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2694821382756345}
{"step": 321688, "time": 16534.667685747147, "episode/length": 89.0, "episode/score": 0.1084166644141078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1084166644141078}
{"step": 321720, "time": 16537.92562031746, "episode/length": 53.0, "episode/score": 0.06258333224104717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06258333224104717}
{"step": 321960, "time": 16549.248708963394, "episode/length": 77.0, "episode/score": 0.08924861410196172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08924861410196172}
{"step": 322120, "time": 16556.76465010643, "episode/length": 146.0, "episode/score": 0.15414995596802328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15414995596802328}
{"step": 322136, "time": 16558.95921063423, "episode/length": 165.0, "episode/score": 0.17621092982881237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17621092982881237}
{"step": 322448, "time": 16572.612498283386, "episode/length": 258.0, "episode/score": 0.2923669697556761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2923669697556761}
{"step": 322456, "time": 16574.915024757385, "episode/length": 61.0, "episode/score": 0.07083333213813603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07083333213813603}
{"step": 322744, "time": 16587.74113893509, "episode/length": 127.0, "episode/score": 0.1494760176501586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1494760176501586}
{"step": 322864, "time": 16593.992463111877, "episode/length": 193.0, "episode/score": 0.19849276564491447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19849276564491447}
{"step": 322944, "time": 16598.525732278824, "episode/length": 156.0, "episode/score": 0.1499515391260502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1499515391260502}
{"step": 323000, "time": 16601.914200544357, "episode/length": 177.0, "episode/score": 0.18408144159184303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18408144159184303}
{"step": 323288, "time": 16614.120044708252, "episode/length": 143.0, "episode/score": 0.16175910601305077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16175910601305077}
{"step": 323360, "time": 16618.59775161743, "episode/length": 113.0, "episode/score": 0.13466666411841288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13466666411841288}
{"step": 323712, "time": 16633.40001153946, "episode/length": 88.0, "episode/score": 0.10122397050872678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10122397050872678}
{"step": 323768, "time": 16636.858048677444, "episode/length": 205.0, "episode/score": 0.22694718812635983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22694718812635983}
{"step": 323784, "time": 16638.996165275574, "episode/length": 165.0, "episode/score": 0.17373284773202613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17373284773202613}
{"step": 324512, "time": 16668.436413764954, "episode/length": 152.0, "episode/score": 0.15493173080903944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15493173080903944}
{"step": 324704, "time": 16677.05514407158, "episode/length": 167.0, "episode/score": 0.1871191119789728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871191119789728}
{"step": 324752, "time": 16680.428141117096, "episode/length": 250.0, "episode/score": 0.2665665931053809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2665665931053809}
{"step": 324800, "time": 16683.680346250534, "episode/length": 241.0, "episode/score": 0.2709550960935303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2709550960935303}
{"step": 325224, "time": 16700.960926532745, "episode/length": 188.0, "episode/score": 0.20716139013893553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20716139013893553}
{"step": 325248, "time": 16703.81523180008, "episode/length": 287.0, "episode/score": 0.3253224150830647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3253224150830647}
{"step": 325280, "time": 16707.224480867386, "episode/length": 186.0, "episode/score": 0.18826645048466162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18826645048466162}
{"step": 325320, "time": 16710.048098802567, "episode/length": 193.0, "episode/score": 0.22465922219998902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22465922219998902}
{"step": 325824, "time": 16731.22799062729, "episode/length": 163.0, "episode/score": 0.17597010889221565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17597010889221565}
{"step": 326160, "time": 16745.295949935913, "episode/length": 175.0, "episode/score": 0.20441736906286678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20441736906286678}
{"step": 326296, "time": 16751.72001695633, "episode/length": 198.0, "episode/score": 0.22197558675179607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22197558675179607}
{"step": 326472, "time": 16759.997009515762, "episode/length": 148.0, "episode/score": 0.15929242689162493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15929242689162493}
{"step": 326600, "time": 16766.22553920746, "episode/length": 159.0, "episode/score": 0.17699240623551304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17699240623551304}
{"step": 326640, "time": 16769.496354818344, "episode/length": 229.0, "episode/score": 0.27612499467795715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27612499467795715}
{"step": 326904, "time": 16780.626466989517, "episode/length": 75.0, "episode/score": 0.08698919601010857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08698919601010857}
{"step": 327072, "time": 16789.008333206177, "episode/length": 58.0, "episode/score": 0.07091666531050578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07091666531050578}
{"step": 327280, "time": 16798.995998620987, "episode/length": 253.0, "episode/score": 0.3001944386633113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3001944386633113}
{"step": 327344, "time": 16803.49414372444, "episode/length": 189.0, "episode/score": 0.2209942002518801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2209942002518801}
{"step": 327640, "time": 16816.903478860855, "episode/length": 145.0, "episode/score": 0.1459272245192551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1459272245192551}
{"step": 327728, "time": 16824.061544179916, "episode/length": 135.0, "episode/score": 0.125726367761672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.125726367761672}
{"step": 327904, "time": 16832.926380634308, "episode/length": 334.0, "episode/score": 0.3513717100213398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3513717100213398}
{"step": 328024, "time": 16839.28268098831, "episode/length": 139.0, "episode/score": 0.15624999749707058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15624999749707058}
{"step": 328048, "time": 16842.218624591827, "episode/length": 235.0, "episode/score": 0.2648438901560439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2648438901560439}
{"step": 328576, "time": 16864.688115358353, "episode/length": 187.0, "episode/score": 0.21719931573534268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21719931573534268}
{"step": 328904, "time": 16878.32863354683, "episode/length": 194.0, "episode/score": 0.2071035446588212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2071035446588212}
{"step": 328936, "time": 16881.116040468216, "episode/length": 206.0, "episode/score": 0.21358709689047828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21358709689047828}
{"step": 329208, "time": 16893.025294065475, "episode/length": 184.0, "episode/score": 0.19904004065210756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19904004065210756}
{"step": 329328, "time": 16899.89334464073, "episode/length": 162.0, "episode/score": 0.1828731982059253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1828731982059253}
{"step": 329496, "time": 16907.63260126114, "episode/length": 180.0, "episode/score": 0.19896234387124423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19896234387124423}
{"step": 329568, "time": 16912.07136940956, "episode/length": 207.0, "episode/score": 0.2248963642759918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2248963642759918}
{"step": 329584, "time": 16914.101833581924, "episode/length": 242.0, "episode/score": 0.252480427188857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.252480427188857}
{"step": 330096, "time": 16953.87719130516, "eval_episode/length": 107.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9537037037037037}
{"step": 330096, "time": 16956.892199993134, "eval_episode/length": 140.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 330096, "time": 16958.755638599396, "eval_episode/length": 141.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 330096, "time": 16960.588245391846, "eval_episode/length": 146.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 330096, "time": 16962.437043905258, "eval_episode/length": 154.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9548387096774194}
{"step": 330096, "time": 16964.695806264877, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 330096, "time": 16967.226086616516, "eval_episode/length": 191.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 330096, "time": 16969.79821753502, "eval_episode/length": 217.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 330192, "time": 16973.365132570267, "episode/length": 201.0, "episode/score": 0.2401216432444926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2401216432444926}
{"step": 330400, "time": 16982.723222494125, "episode/length": 186.0, "episode/score": 0.2107321392686572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2107321392686572}
{"step": 330576, "time": 16990.843194007874, "episode/length": 155.0, "episode/score": 0.17333806387068762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17333806387068762}
{"step": 330640, "time": 16995.250517845154, "episode/length": 178.0, "episode/score": 0.2021462073098519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2021462073098519}
{"step": 330768, "time": 17001.547925949097, "episode/length": 147.0, "episode/score": 0.15605296388639545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15605296388639545}
{"step": 330792, "time": 17003.789944648743, "episode/length": 231.0, "episode/score": 0.25462666560633807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25462666560633807}
{"step": 330952, "time": 17011.428220033646, "episode/length": 172.0, "episode/score": 0.19715304451801785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19715304451801785}
{"step": 331192, "time": 17021.915835380554, "episode/length": 211.0, "episode/score": 0.22207635055383435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22207635055383435}
{"step": 331408, "time": 17031.77095770836, "episode/length": 151.0, "episode/score": 0.17110831130230508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17110831130230508}
{"step": 331568, "time": 17039.312433481216, "episode/length": 145.0, "episode/score": 0.14672884347237414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14672884347237414}
{"step": 331736, "time": 17046.974860191345, "episode/length": 120.0, "episode/score": 0.13755594995473075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13755594995473075}
{"step": 331984, "time": 17058.19080877304, "episode/length": 167.0, "episode/score": 0.1774062020931524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1774062020931524}
{"step": 332088, "time": 17063.390832662582, "episode/length": 141.0, "episode/score": 0.12758230252711655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12758230252711655}
{"step": 332112, "time": 17066.13896226883, "episode/length": 164.0, "episode/score": 0.16325550936198852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16325550936198852}
{"step": 332312, "time": 17075.115067243576, "episode/length": 216.0, "episode/score": 0.24946035561242752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24946035561242752}
{"step": 332368, "time": 17079.03653693199, "episode/length": 99.0, "episode/score": 0.11436556163971545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11436556163971545}
{"step": 332832, "time": 17097.95889210701, "episode/length": 204.0, "episode/score": 0.2177135181200356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2177135181200356}
{"step": 333120, "time": 17110.20524787903, "episode/length": 172.0, "episode/score": 0.16926190856611356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16926190856611356}
{"step": 333208, "time": 17114.985249996185, "episode/length": 139.0, "episode/score": 0.1319431735755643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1319431735755643}
{"step": 333312, "time": 17120.602675914764, "episode/length": 124.0, "episode/score": 0.13918781992106233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13918781992106233}
{"step": 333488, "time": 17128.79349064827, "episode/length": 139.0, "episode/score": 0.13004831097714487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13004831097714487}
{"step": 333680, "time": 17137.52744603157, "episode/length": 211.0, "episode/score": 0.24910922977142036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24910922977142036}
{"step": 334248, "time": 17160.165401935577, "episode/length": 140.0, "episode/score": 0.14858301077765645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14858301077765645}
{"step": 334384, "time": 17167.540054798126, "episode/length": 133.0, "episode/score": 0.14352417102782056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14352417102782056}
{"step": 334480, "time": 17172.702113628387, "episode/length": 158.0, "episode/score": 0.1790791991952574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1790791991952574}
{"step": 334552, "time": 17176.826732873917, "episode/length": 392.0, "episode/score": 0.4214459973736666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4214459973736666}
{"step": 334632, "time": 17181.42543411255, "episode/length": 224.0, "episode/score": 0.2536557496059686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2536557496059686}
{"step": 334712, "time": 17186.051917552948, "episode/length": 324.0, "episode/score": 0.35583610648973263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35583610648973263}
{"step": 334720, "time": 17188.11622786522, "episode/length": 153.0, "episode/score": 0.18466666311724111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18466666311724111}
{"step": 335016, "time": 17200.55704855919, "episode/length": 166.0, "episode/score": 0.18854453705716878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18854453705716878}
{"step": 335144, "time": 17207.009478330612, "episode/length": 94.0, "episode/score": 0.11134863248298643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11134863248298643}
{"step": 335376, "time": 17217.440804243088, "episode/length": 82.0, "episode/score": 0.0989166647195816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0989166647195816}
{"step": 335512, "time": 17223.75631427765, "episode/length": 157.0, "episode/score": 0.1515717115071311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1515717115071311}
{"step": 335648, "time": 17230.71469974518, "episode/length": 145.0, "episode/score": 0.1429460998479044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1429460998479044}
{"step": 336200, "time": 17254.11940050125, "episode/length": 184.0, "episode/score": 0.18133909937205317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18133909937205317}
{"step": 336384, "time": 17262.714900493622, "episode/length": 228.0, "episode/score": 0.23689506166920182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23689506166920182}
{"step": 336448, "time": 17266.79307603836, "episode/length": 226.0, "episode/score": 0.2262788676271157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2262788676271157}
{"step": 336552, "time": 17271.971728801727, "episode/length": 191.0, "episode/score": 0.18643295279071026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18643295279071026}
{"step": 336680, "time": 17278.26842021942, "episode/length": 145.0, "episode/score": 0.15325056621077238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15325056621077238}
{"step": 336824, "time": 17285.293159008026, "episode/length": 180.0, "episode/score": 0.1852679101357353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1852679101357353}
{"step": 336912, "time": 17290.879256248474, "episode/length": 220.0, "episode/score": 0.2467698370164726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2467698370164726}
{"step": 337368, "time": 17309.213866710663, "episode/length": 214.0, "episode/score": 0.2446679341919662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2446679341919662}
{"step": 337408, "time": 17312.511014461517, "episode/length": 150.0, "episode/score": 0.15249729885545094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15249729885545094}
{"step": 337624, "time": 17321.777416467667, "episode/length": 146.0, "episode/score": 0.16327369345708576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16327369345708576}
{"step": 337624, "time": 17321.78331375122, "episode/length": 99.0, "episode/score": 0.10481226177034841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10481226177034841}
{"step": 337776, "time": 17331.16086125374, "episode/length": 173.0, "episode/score": 0.17357026945137477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17357026945137477}
{"step": 337864, "time": 17335.69564461708, "episode/length": 163.0, "episode/score": 0.17688659207487945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17688659207487945}
{"step": 338048, "time": 17344.292397499084, "episode/length": 170.0, "episode/score": 0.20052082952315686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20052082952315686}
{"step": 338272, "time": 17354.063101053238, "episode/length": 169.0, "episode/score": 0.18299173496961885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18299173496961885}
{"step": 338416, "time": 17360.920505285263, "episode/length": 98.0, "episode/score": 0.11539178831753816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11539178831753816}
{"step": 338776, "time": 17375.886464834213, "episode/length": 170.0, "episode/score": 0.1870135215922346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1870135215922346}
{"step": 338920, "time": 17383.53780078888, "episode/length": 193.0, "episode/score": 0.20535046554687142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20535046554687142}
{"step": 338960, "time": 17387.58729314804, "episode/length": 136.0, "episode/score": 0.1544704471143632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1544704471143632}
{"step": 339024, "time": 17392.137885570526, "episode/length": 174.0, "episode/score": 0.15693497077791108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15693497077791108}
{"step": 339296, "time": 17403.80522441864, "episode/length": 127.0, "episode/score": 0.14990356951238937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14990356951238937}
{"step": 339488, "time": 17413.236226797104, "episode/length": 179.0, "episode/score": 0.19816871080001874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19816871080001874}
{"step": 339528, "time": 17416.707552194595, "episode/length": 218.0, "episode/score": 0.2450932448164167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2450932448164167}
{"step": 339960, "time": 17434.84772181511, "episode/length": 53.0, "episode/score": 0.06095833235303871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06095833235303871}
{"step": 340080, "time": 17455.539643526077, "eval_episode/length": 36.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8648648648648649}
{"step": 340080, "time": 17460.88489818573, "eval_episode/length": 131.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 340080, "time": 17463.2937874794, "eval_episode/length": 141.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 340080, "time": 17465.6498336792, "eval_episode/length": 150.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 340080, "time": 17468.686809778214, "eval_episode/length": 172.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 340080, "time": 17470.76873230934, "eval_episode/length": 173.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 340080, "time": 17472.717579126358, "eval_episode/length": 174.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 340080, "time": 17475.242838859558, "eval_episode/length": 155.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 340081, "time": 17475.85234093666, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.13255908203125, "train/action_min": 0.0, "train/action_std": 4.904267612457275, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007854427549988031, "train/actor_opt_grad_steps": 20530.0, "train/actor_opt_loss": -5.792039980724454, "train/adv_mag": 0.18160991322994233, "train/adv_max": 0.1206268326640129, "train/adv_mean": 0.00020095213945751312, "train/adv_min": -0.18100355219841002, "train/adv_std": 0.014521823041141033, "train/cont_avg": 0.994296875, "train/cont_loss_mean": 0.0002799054949678066, "train/cont_loss_std": 0.00830587470244427, "train/cont_neg_acc": 0.988085717201233, "train/cont_neg_loss": 0.029036930244734322, "train/cont_pos_acc": 0.9999528141021728, "train/cont_pos_loss": 0.00012021115616397538, "train/cont_pred": 0.9943067903518676, "train/cont_rate": 0.994296875, "train/dyn_loss_mean": 12.566582458496093, "train/dyn_loss_std": 8.095150875091553, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16954383423924446, "train/extr_critic_critic_opt_grad_steps": 20530.0, "train/extr_critic_critic_opt_loss": 11598.867328125, "train/extr_critic_mag": 0.2680398607254028, "train/extr_critic_max": 0.2680398607254028, "train/extr_critic_mean": 0.21451674771308898, "train/extr_critic_min": 0.00358820915222168, "train/extr_critic_std": 0.05844345834851265, "train/extr_return_normed_mag": 0.20511570835113527, "train/extr_return_normed_max": 0.20511570835113527, "train/extr_return_normed_mean": 0.15186807811260222, "train/extr_return_normed_min": -0.06186518928408623, "train/extr_return_normed_std": 0.06036464753746986, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2679653494358063, "train/extr_return_raw_max": 0.2679653494358063, "train/extr_return_raw_mean": 0.21471772313117982, "train/extr_return_raw_min": 0.0009844512939453124, "train/extr_return_raw_std": 0.06036464747786522, "train/extr_reward_mag": 0.0013779573440551758, "train/extr_reward_max": 0.0013779573440551758, "train/extr_reward_mean": 0.0010940364170819521, "train/extr_reward_min": 1.0251998901367188e-05, "train/extr_reward_std": 0.00023089774209074677, "train/image_loss_mean": 6.75082511138916, "train/image_loss_std": 11.178430438995361, "train/model_loss_mean": 14.331117126464843, "train/model_loss_std": 14.542418289184571, "train/model_opt_grad_norm": 65.80679985046386, "train/model_opt_grad_steps": 20508.512, "train/model_opt_loss": 18486.3175546875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1290.0, "train/policy_entropy_mag": 2.76102427482605, "train/policy_entropy_max": 2.76102427482605, "train/policy_entropy_mean": 2.126095325469971, "train/policy_entropy_min": 0.08181400001049041, "train/policy_entropy_std": 0.5746777005195618, "train/policy_logprob_mag": 7.4344381370544435, "train/policy_logprob_max": -0.009798342429101468, "train/policy_logprob_mean": -2.1252783489227296, "train/policy_logprob_min": -7.4344381370544435, "train/policy_logprob_std": 1.1409569416046144, "train/policy_randomness_mag": 0.9745204062461853, "train/policy_randomness_max": 0.9745204062461853, "train/policy_randomness_mean": 0.7504183392524719, "train/policy_randomness_min": 0.028876751750707627, "train/policy_randomness_std": 0.20283601129055023, "train/post_ent_mag": 55.141840179443356, "train/post_ent_max": 55.141840179443356, "train/post_ent_mean": 37.76466995239258, "train/post_ent_min": 20.185416122436525, "train/post_ent_std": 6.367462959289551, "train/prior_ent_mag": 64.24094674682617, "train/prior_ent_max": 64.24094674682617, "train/prior_ent_mean": 50.41914944458008, "train/prior_ent_min": 28.971000457763672, "train/prior_ent_std": 5.450191089630127, "train/rep_loss_mean": 12.566582458496093, "train/rep_loss_std": 8.095150875091553, "train/reward_avg": 0.0010605835048481823, "train/reward_loss_mean": 0.040062710136175156, "train/reward_loss_std": 0.011236810006201267, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001329498291015625, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04006270986795425, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010601967228576542, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.5159291819529196, "train_stats/max_log_achievement_collect_drink": 0.24778761061946902, "train_stats/max_log_achievement_collect_sapling": 0.5309734513274337, "train_stats/max_log_achievement_collect_wood": 0.24778761061946902, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.017699115044247787, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008849557522123894, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.415929203539823, "train_stats/max_log_achievement_place_table": 0.02654867256637168, "train_stats/max_log_achievement_wake_up": 0.36283185840707965, "train_stats/mean_log_entropy": 2.243188470865773, "eval_stats/sum_log_reward": -0.1500000017695129, "eval_stats/max_log_achievement_collect_drink": 0.0625, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.6446417652769014e-06, "report/cont_loss_std": 7.563655526610091e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005395587650127709, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0150333764613606e-06, "report/cont_pred": 0.9951188564300537, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.92715072631836, "report/dyn_loss_std": 7.4445343017578125, "report/image_loss_mean": 5.199820518493652, "report/image_loss_std": 8.366156578063965, "report/model_loss_mean": 11.796100616455078, "report/model_loss_std": 11.426918983459473, "report/post_ent_mag": 55.596946716308594, "report/post_ent_max": 55.596946716308594, "report/post_ent_mean": 39.81471252441406, "report/post_ent_min": 18.182947158813477, "report/post_ent_std": 6.7237629890441895, "report/prior_ent_mag": 64.26005554199219, "report/prior_ent_max": 64.26005554199219, "report/prior_ent_mean": 51.099876403808594, "report/prior_ent_min": 29.58722686767578, "report/prior_ent_std": 4.825974464416504, "report/rep_loss_mean": 10.92715072631836, "report/rep_loss_std": 7.4445343017578125, "report/reward_avg": 0.0010591124882921576, "report/reward_loss_mean": 0.03998652100563049, "report/reward_loss_std": 0.011344946920871735, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012412071228027344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03998652473092079, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010135754710063338, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 6.745822815901192e-07, "eval/cont_loss_std": 9.489147487329319e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.109108992153779e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.8990624539583223e-07, "eval/cont_pred": 0.9931643605232239, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 15.740961074829102, "eval/dyn_loss_std": 9.684070587158203, "eval/image_loss_mean": 9.959104537963867, "eval/image_loss_std": 13.335987091064453, "eval/model_loss_mean": 19.94500732421875, "eval/model_loss_std": 17.458524703979492, "eval/post_ent_mag": 55.11732482910156, "eval/post_ent_max": 55.11732482910156, "eval/post_ent_mean": 37.96277618408203, "eval/post_ent_min": 20.915069580078125, "eval/post_ent_std": 6.710287570953369, "eval/prior_ent_mag": 64.26005554199219, "eval/prior_ent_max": 64.26005554199219, "eval/prior_ent_mean": 51.440677642822266, "eval/prior_ent_min": 25.146587371826172, "eval/prior_ent_std": 5.442590236663818, "eval/rep_loss_mean": 15.740961074829102, "eval/rep_loss_std": 9.684070587158203, "eval/reward_avg": 0.0014648435171693563, "eval/reward_loss_mean": 0.5413258075714111, "eval/reward_loss_std": 3.1346864700317383, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012079477310180664, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.40829774737358093, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.868391036987305, "eval/reward_pred": 0.0009969815146178007, "eval/reward_rate": 0.0068359375, "replay/size": 339577.0, "replay/inserts": 20072.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.4068026521758e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.594072416448517e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67816.0, "eval_replay/inserts": 3288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.233497095224051e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1019.2314765453339, "timer/env.step_count": 2509.0, "timer/env.step_total": 257.39522910118103, "timer/env.step_frac": 0.25253854009063514, "timer/env.step_avg": 0.10258877206105262, "timer/env.step_min": 0.02261495590209961, "timer/env.step_max": 3.5233073234558105, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 10.004934549331665, "timer/replay._sample_frac": 0.00981615538723667, "timer/replay._sample_avg": 0.0004986510441253821, "timer/replay._sample_min": 0.0003390312194824219, "timer/replay._sample_max": 0.0110015869140625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2920.0, "timer/agent.policy_total": 48.973663330078125, "timer/agent.policy_frac": 0.04804959860155952, "timer/agent.policy_avg": 0.016771802510300728, "timer/agent.policy_min": 0.00959467887878418, "timer/agent.policy_max": 0.15520882606506348, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.14524078369140625, "timer/dataset_train_frac": 0.00014250029265549881, "timer/dataset_train_avg": 0.00011582199656411982, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0004391670227050781, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 566.3767023086548, "timer/agent.train_frac": 0.5556899638032943, "timer/agent.train_avg": 0.4516560624470931, "timer/agent.train_min": 0.43677401542663574, "timer/agent.train_max": 1.099611759185791, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472825288772583, "timer/agent.report_frac": 0.00046390373497413515, "timer/agent.report_avg": 0.2364126443862915, "timer/agent.report_min": 0.22896218299865723, "timer/agent.report_max": 0.24386310577392578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.1813113609595525e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 19.69300631161872}
{"step": 340144, "time": 17478.49978208542, "episode/length": 147.0, "episode/score": 0.17300100120246498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17300100120246498}
{"step": 340144, "time": 17478.506894350052, "episode/length": 152.0, "episode/score": 0.14859802191040217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14859802191040217}
{"step": 340176, "time": 17483.060317754745, "episode/length": 143.0, "episode/score": 0.14297379216441186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14297379216441186}
{"step": 340528, "time": 17497.769257307053, "episode/length": 263.0, "episode/score": 0.2684374277623647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2684374277623647}
{"step": 340728, "time": 17506.55791401863, "episode/length": 95.0, "episode/score": 0.10460494721337454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10460494721337454}
{"step": 340800, "time": 17510.897264957428, "episode/length": 163.0, "episode/score": 0.16336831178068678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16336831178068678}
{"step": 340960, "time": 17518.35462284088, "episode/length": 207.0, "episode/score": 0.22110421355955623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22110421355955623}
{"step": 341072, "time": 17524.024075746536, "episode/length": 286.0, "episode/score": 0.3020660356487497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3020660356487497}
{"step": 341440, "time": 17539.118095636368, "episode/length": 161.0, "episode/score": 0.17362308775682322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17362308775682322}
{"step": 341856, "time": 17556.097100019455, "episode/length": 165.0, "episode/score": 0.16160019409653614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16160019409653614}
{"step": 341920, "time": 17560.037848711014, "episode/length": 221.0, "episode/score": 0.2240867177497421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2240867177497421}
{"step": 341976, "time": 17563.44567990303, "episode/length": 224.0, "episode/score": 0.2618542062245979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2618542062245979}
{"step": 341976, "time": 17563.453365325928, "episode/length": 155.0, "episode/score": 0.1645585635142197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1645585635142197}
{"step": 342104, "time": 17571.661066055298, "episode/length": 142.0, "episode/score": 0.16747741435392527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16747741435392527}
{"step": 342784, "time": 17598.78543996811, "episode/length": 167.0, "episode/score": 0.1814998781092072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1814998781092072}
{"step": 342832, "time": 17602.146404743195, "episode/length": 253.0, "episode/score": 0.2721595415223419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2721595415223419}
{"step": 342928, "time": 17607.39416718483, "episode/length": 231.0, "episode/score": 0.25412704266727815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25412704266727815}
{"step": 343136, "time": 17616.701143741608, "episode/length": 144.0, "episode/score": 0.13692187618653406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13692187618653406}
{"step": 343200, "time": 17620.66090655327, "episode/length": 159.0, "episode/score": 0.18136772256821132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18136772256821132}
{"step": 343248, "time": 17624.01432132721, "episode/length": 142.0, "episode/score": 0.13286831255209108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13286831255209108}
{"step": 343328, "time": 17628.559596538544, "episode/length": 183.0, "episode/score": 0.18957271457838942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18957271457838942}
{"step": 343328, "time": 17628.566491127014, "episode/length": 168.0, "episode/score": 0.17800136475761974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17800136475761974}
{"step": 343992, "time": 17656.270850658417, "episode/length": 132.0, "episode/score": 0.1554166638525203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1554166638525203}
{"step": 344184, "time": 17666.53091955185, "episode/length": 174.0, "episode/score": 0.18001766795623553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18001766795623553}
{"step": 344280, "time": 17671.732852458954, "episode/length": 180.0, "episode/score": 0.17563946744803616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17563946744803616}
{"step": 344552, "time": 17683.299035072327, "episode/length": 152.0, "episode/score": 0.16916588142066757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16916588142066757}
{"step": 344656, "time": 17688.950504541397, "episode/length": 189.0, "episode/score": 0.1874797553764438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1874797553764438}
{"step": 344720, "time": 17692.874079227448, "episode/length": 189.0, "episode/score": 0.18969367807630988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18969367807630988}
{"step": 344824, "time": 17698.07681298256, "episode/length": 186.0, "episode/score": 0.1860396425208819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1860396425208819}
{"step": 344920, "time": 17703.154472112656, "episode/length": 208.0, "episode/score": 0.21408282347374552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21408282347374552}
{"step": 345488, "time": 17726.195230722427, "episode/length": 186.0, "episode/score": 0.16713262892790226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16713262892790226}
{"step": 345688, "time": 17734.943499326706, "episode/length": 187.0, "episode/score": 0.21122058015998846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21122058015998846}
{"step": 345760, "time": 17739.533439397812, "episode/length": 150.0, "episode/score": 0.1655029736139113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1655029736139113}
{"step": 345928, "time": 17747.197341918945, "episode/length": 158.0, "episode/score": 0.14654514676476538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14654514676476538}
{"step": 346016, "time": 17752.196994543076, "episode/length": 161.0, "episode/score": 0.17514326337231978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17514326337231978}
{"step": 346144, "time": 17758.551630735397, "episode/length": 152.0, "episode/score": 0.17378023902847417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17378023902847417}
{"step": 346536, "time": 17774.48453617096, "episode/length": 281.0, "episode/score": 0.3013538418508688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3013538418508688}
{"step": 347000, "time": 17793.267836093903, "episode/length": 122.0, "episode/score": 0.12525639908926678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12525639908926678}
{"step": 347056, "time": 17797.102761268616, "episode/length": 140.0, "episode/score": 0.13824614258783186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13824614258783186}
{"step": 347280, "time": 17807.04556965828, "episode/length": 223.0, "episode/score": 0.23015468703852093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23015468703852093}
{"step": 347440, "time": 17814.40568304062, "episode/length": 161.0, "episode/score": 0.12387127922102081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12387127922102081}
{"step": 347640, "time": 17822.989527463913, "episode/length": 137.0, "episode/score": 0.14620027350883902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14620027350883902}
{"step": 347904, "time": 17834.596851825714, "episode/length": 384.0, "episode/score": 0.41530948852641814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41530948852641814}
{"step": 347920, "time": 17836.861046791077, "episode/length": 278.0, "episode/score": 0.3099935262393956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3099935262393956}
{"step": 348224, "time": 17849.84053993225, "episode/length": 307.0, "episode/score": 0.34760800275807924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34760800275807924}
{"step": 348288, "time": 17853.73642539978, "episode/length": 160.0, "episode/score": 0.1793023361201449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793023361201449}
{"step": 348584, "time": 17866.093792915344, "episode/length": 162.0, "episode/score": 0.18305249801551327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18305249801551327}
{"step": 348624, "time": 17869.381322145462, "episode/length": 195.0, "episode/score": 0.20795433245530148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20795433245530148}
{"step": 348864, "time": 17879.743560791016, "episode/length": 177.0, "episode/score": 0.19886333815793478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19886333815793478}
{"step": 349096, "time": 17889.70041155815, "episode/length": 181.0, "episode/score": 0.18830251868803316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18830251868803316}
{"step": 349128, "time": 17892.484268665314, "episode/length": 152.0, "episode/score": 0.17228313338910084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17228313338910084}
{"step": 349448, "time": 17906.301901578903, "episode/length": 43.0, "episode/score": 0.033440999481172184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033440999481172184}
{"step": 349568, "time": 17913.095566749573, "episode/length": 205.0, "episode/score": 0.18055734108520483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18055734108520483}
{"step": 349600, "time": 17916.025099515915, "episode/length": 163.0, "episode/score": 0.16102141940564252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16102141940564252}
{"step": 349728, "time": 17922.235490322113, "episode/length": 142.0, "episode/score": 0.1438071183001739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1438071183001739}
{"step": 350064, "time": 17951.74035000801, "eval_episode/length": 57.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9310344827586207}
{"step": 350064, "time": 17956.93976712227, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 350064, "time": 17958.58430504799, "eval_episode/length": 143.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 350064, "time": 17961.197810649872, "eval_episode/length": 170.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 350064, "time": 17963.337688684464, "eval_episode/length": 183.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 350064, "time": 17965.0653693676, "eval_episode/length": 187.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 350064, "time": 17967.10083580017, "eval_episode/length": 141.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 350064, "time": 17969.932624340057, "eval_episode/length": 229.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9739130434782609}
{"step": 350216, "time": 17975.393253564835, "episode/length": 168.0, "episode/score": 0.17059347782651457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17059347782651457}
{"step": 350264, "time": 17978.7128572464, "episode/length": 254.0, "episode/score": 0.2369782562968794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2369782562968794}
{"step": 350560, "time": 17991.751083612442, "episode/length": 178.0, "episode/score": 0.1660045675780566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1660045675780566}
{"step": 350608, "time": 17995.29157090187, "episode/length": 144.0, "episode/score": 0.15088129918922277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15088129918922277}
{"step": 350632, "time": 17997.476418733597, "episode/length": 250.0, "episode/score": 0.229774789494968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.229774789494968}
{"step": 351008, "time": 18013.250700235367, "episode/length": 179.0, "episode/score": 0.19832611929132327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19832611929132327}
{"step": 351056, "time": 18017.22084569931, "episode/length": 181.0, "episode/score": 0.1794706220093758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1794706220093758}
{"step": 351088, "time": 18020.38048696518, "episode/length": 169.0, "episode/score": 0.16206842607925864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16206842607925864}
{"step": 351104, "time": 18022.603219509125, "episode/length": 58.0, "episode/score": 0.06912499875761569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06912499875761569}
{"step": 351336, "time": 18032.861936092377, "episode/length": 139.0, "episode/score": 0.14553076597121617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14553076597121617}
{"step": 351576, "time": 18043.76797437668, "episode/length": 163.0, "episode/score": 0.18044481740480478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18044481740480478}
{"step": 351880, "time": 18056.793524503708, "episode/length": 164.0, "episode/score": 0.1961744467553217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1961744467553217}
{"step": 352016, "time": 18063.59305047989, "episode/length": 84.0, "episode/score": 0.08952055731060682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08952055731060682}
{"step": 352152, "time": 18069.958092927933, "episode/length": 132.0, "episode/score": 0.14400085776287597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14400085776287597}
{"step": 352464, "time": 18084.989132642746, "episode/length": 181.0, "episode/score": 0.2043188569441554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2043188569441554}
{"step": 352552, "time": 18089.806981801987, "episode/length": 186.0, "episode/score": 0.20891666307579726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20891666307579726}
{"step": 352616, "time": 18093.879719018936, "episode/length": 188.0, "episode/score": 0.213366132498777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.213366132498777}
{"step": 352648, "time": 18096.722086668015, "episode/length": 254.0, "episode/score": 0.2854642810707446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2854642810707446}
{"step": 352808, "time": 18104.257014751434, "episode/length": 153.0, "episode/score": 0.1764585155979148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1764585155979148}
{"step": 353160, "time": 18119.217606782913, "episode/length": 159.0, "episode/score": 0.17305851462879218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17305851462879218}
{"step": 353272, "time": 18125.56007361412, "episode/length": 156.0, "episode/score": 0.161393627851794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.161393627851794}
{"step": 353584, "time": 18139.88462996483, "episode/length": 178.0, "episode/score": 0.20709137359517626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20709137359517626}
{"step": 353688, "time": 18145.87307024002, "episode/length": 133.0, "episode/score": 0.14984863269273774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14984863269273774}
{"step": 353760, "time": 18150.95496225357, "episode/length": 138.0, "episode/score": 0.1704166631679982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704166631679982}
{"step": 353768, "time": 18152.522526741028, "episode/length": 61.0, "episode/score": 0.06575063022683025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06575063022683025}
{"step": 354128, "time": 18167.84324145317, "episode/length": 196.0, "episode/score": 0.21380045048499596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21380045048499596}
{"step": 354520, "time": 18183.70944905281, "episode/length": 256.0, "episode/score": 0.2913077812299889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2913077812299889}
{"step": 354808, "time": 18195.977716207504, "episode/length": 139.0, "episode/score": 0.1169338090094243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1169338090094243}
{"step": 355128, "time": 18209.43731713295, "episode/length": 170.0, "episode/score": 0.18104757530090865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18104757530090865}
{"step": 355128, "time": 18209.445122241974, "episode/length": 192.0, "episode/score": 0.19790049597577308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19790049597577308}
{"step": 355224, "time": 18216.174023389816, "episode/length": 87.0, "episode/score": 0.10296361406835786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10296361406835786}
{"step": 355400, "time": 18224.59705901146, "episode/length": 323.0, "episode/score": 0.338080798923329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.338080798923329}
{"step": 355584, "time": 18234.050376415253, "episode/length": 181.0, "episode/score": 0.20164126908457547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20164126908457547}
{"step": 356264, "time": 18261.237621068954, "episode/length": 387.0, "episode/score": 0.41992067039791436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41992067039791436}
{"step": 356368, "time": 18266.906910181046, "episode/length": 154.0, "episode/score": 0.168712801509173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.168712801509173}
{"step": 356584, "time": 18276.140575408936, "episode/length": 221.0, "episode/score": 0.24720372753836273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24720372753836273}
{"step": 356736, "time": 18283.559329509735, "episode/length": 370.0, "episode/score": 0.4083326906174989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4083326906174989}
{"step": 356768, "time": 18286.495175600052, "episode/length": 204.0, "episode/score": 0.2243760554229084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2243760554229084}
{"step": 357040, "time": 18298.226936340332, "episode/length": 226.0, "episode/score": 0.24364977935874776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24364977935874776}
{"step": 357168, "time": 18304.76341342926, "episode/length": 197.0, "episode/score": 0.20385666518268408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20385666518268408}
{"step": 357200, "time": 18308.156148672104, "episode/length": 224.0, "episode/score": 0.25137403172448103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25137403172448103}
{"step": 357288, "time": 18313.258286476135, "episode/length": 127.0, "episode/score": 0.1439594130642945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1439594130642945}
{"step": 357640, "time": 18328.163672208786, "episode/length": 58.0, "episode/score": 0.06300498587734182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06300498587734182}
{"step": 357680, "time": 18331.39912557602, "episode/length": 113.0, "episode/score": 0.12441270484214328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12441270484214328}
{"step": 357712, "time": 18334.201189994812, "episode/length": 167.0, "episode/score": 0.17604184471019835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17604184471019835}
{"step": 357744, "time": 18336.99589753151, "episode/length": 144.0, "episode/score": 0.14428475861950574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14428475861950574}
{"step": 358168, "time": 18354.203155517578, "episode/length": 178.0, "episode/score": 0.19981380195531528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19981380195531528}
{"step": 358496, "time": 18368.080464601517, "episode/length": 150.0, "episode/score": 0.15925645543029532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15925645543029532}
{"step": 358568, "time": 18372.21066069603, "episode/length": 190.0, "episode/score": 0.20068232844005252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20068232844005252}
{"step": 358720, "time": 18379.736634016037, "episode/length": 134.0, "episode/score": 0.1514644777380454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1514644777380454}
{"step": 359016, "time": 18392.162331342697, "episode/length": 226.0, "episode/score": 0.24771928832433332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24771928832433332}
{"step": 359056, "time": 18395.419525146484, "episode/length": 167.0, "episode/score": 0.19372356078292796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19372356078292796}
{"step": 359296, "time": 18406.68679213524, "episode/length": 193.0, "episode/score": 0.18912695949893532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18912695949893532}
{"step": 359320, "time": 18409.02369737625, "episode/length": 143.0, "episode/score": 0.17499999655410647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17499999655410647}
{"step": 359624, "time": 18421.83392906189, "episode/length": 242.0, "episode/score": 0.26470593699832534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26470593699832534}
{"step": 359824, "time": 18431.22626018524, "episode/length": 156.0, "episode/score": 0.16178267337090801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16178267337090801}
{"step": 360048, "time": 18456.265524864197, "eval_episode/length": 31.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.875}
{"step": 360048, "time": 18459.093007087708, "eval_episode/length": 59.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 360048, "time": 18464.06975698471, "eval_episode/length": 139.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9571428571428572}
{"step": 360048, "time": 18465.896055221558, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 360048, "time": 18467.735020160675, "eval_episode/length": 148.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 360048, "time": 18469.617530822754, "eval_episode/length": 155.0, "eval_episode/score": 0.09999996423721313, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 360048, "time": 18472.03101825714, "eval_episode/length": 174.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 360048, "time": 18474.71279358864, "eval_episode/length": 46.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 360065, "time": 18475.90461587906, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.189255859375, "train/action_min": 0.0, "train/action_std": 4.9788604125976565, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0073144521079957486, "train/actor_opt_grad_steps": 21780.0, "train/actor_opt_loss": -11.835914702057838, "train/adv_mag": 0.17236946487426758, "train/adv_max": 0.11662297970056534, "train/adv_mean": 2.481166709185345e-05, "train/adv_min": -0.17126498878002167, "train/adv_std": 0.013483477860689163, "train/cont_avg": 0.9944609375, "train/cont_loss_mean": 0.0004344253050599036, "train/cont_loss_std": 0.012730649593155249, "train/cont_neg_acc": 0.9857333369255066, "train/cont_neg_loss": 0.05567469453853118, "train/cont_pos_acc": 0.9999842467308044, "train/cont_pos_loss": 8.543910719146197e-05, "train/cont_pred": 0.9945052351951599, "train/cont_rate": 0.9944609375, "train/dyn_loss_mean": 12.385358352661132, "train/dyn_loss_std": 8.109211277008056, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17191664630174636, "train/extr_critic_critic_opt_grad_steps": 21780.0, "train/extr_critic_critic_opt_loss": 11683.9702578125, "train/extr_critic_mag": 0.27204204177856445, "train/extr_critic_max": 0.27204204177856445, "train/extr_critic_mean": 0.21684115958213807, "train/extr_critic_min": 0.004253916740417481, "train/extr_critic_std": 0.05700408646464348, "train/extr_return_normed_mag": 0.19943292725086212, "train/extr_return_normed_max": 0.19943292725086212, "train/extr_return_normed_mean": 0.1446295263171196, "train/extr_return_normed_min": -0.0711937627196312, "train/extr_return_normed_std": 0.05833787304162979, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2716693103313446, "train/extr_return_raw_max": 0.2716693103313446, "train/extr_return_raw_mean": 0.21686591291427612, "train/extr_return_raw_min": 0.0010426206588745118, "train/extr_return_raw_std": 0.058337873101234436, "train/extr_reward_mag": 0.001372025489807129, "train/extr_reward_max": 0.001372025489807129, "train/extr_reward_mean": 0.0010947926472872497, "train/extr_reward_min": 1.0196685791015625e-05, "train/extr_reward_std": 0.0002333931140601635, "train/image_loss_mean": 6.489013214111328, "train/image_loss_std": 10.380191886901855, "train/model_loss_mean": 13.960736541748046, "train/model_loss_std": 13.733437744140625, "train/model_opt_grad_norm": 61.882601830267134, "train/model_opt_grad_steps": 21757.336, "train/model_opt_loss": 18037.0705390625, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 1280.0, "train/policy_entropy_mag": 2.7619148502349855, "train/policy_entropy_max": 2.7619148502349855, "train/policy_entropy_mean": 2.1442102003097534, "train/policy_entropy_min": 0.0841182034611702, "train/policy_entropy_std": 0.576746169090271, "train/policy_logprob_mag": 7.43780559539795, "train/policy_logprob_max": -0.01012043147534132, "train/policy_logprob_mean": -2.1437702388763427, "train/policy_logprob_min": -7.43780559539795, "train/policy_logprob_std": 1.1249556670188903, "train/policy_randomness_mag": 0.9748347401618958, "train/policy_randomness_max": 0.9748347401618958, "train/policy_randomness_mean": 0.7568120989799499, "train/policy_randomness_min": 0.029690034419298173, "train/policy_randomness_std": 0.2035660890340805, "train/post_ent_mag": 55.594592895507816, "train/post_ent_max": 55.594592895507816, "train/post_ent_mean": 38.146010192871096, "train/post_ent_min": 20.111609466552736, "train/post_ent_std": 6.51606844329834, "train/prior_ent_mag": 64.33842309570312, "train/prior_ent_max": 64.33842309570312, "train/prior_ent_mean": 50.59733218383789, "train/prior_ent_min": 28.886184127807617, "train/prior_ent_std": 5.449985729217529, "train/rep_loss_mean": 12.385358352661132, "train/rep_loss_std": 8.109211277008056, "train/reward_avg": 0.0010612266063690185, "train/reward_loss_mean": 0.040074001371860506, "train/reward_loss_std": 0.011300281882286071, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013198556900024415, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040074001431465146, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010616074036806822, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.4063062984664161, "train_stats/max_log_achievement_collect_drink": 0.7657657657657657, "train_stats/max_log_achievement_collect_sapling": 0.4864864864864865, "train_stats/max_log_achievement_collect_wood": 0.22522522522522523, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009009009009009009, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.3153153153153153, "train_stats/mean_log_entropy": 2.2704583320531757, "eval_stats/sum_log_reward": 0.5374999893829226, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.043478260869565216, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0007795137353241444, "report/cont_loss_std": 0.019711069762706757, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.11331737041473389, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.916994384984719e-06, "report/cont_pred": 0.9937715530395508, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.837000846862793, "report/dyn_loss_std": 8.078886032104492, "report/image_loss_mean": 4.876243591308594, "report/image_loss_std": 10.749885559082031, "report/model_loss_mean": 12.619256973266602, "report/model_loss_std": 14.426316261291504, "report/post_ent_mag": 55.65398406982422, "report/post_ent_max": 55.65398406982422, "report/post_ent_mean": 37.37596893310547, "report/post_ent_min": 21.175922393798828, "report/post_ent_std": 5.646416187286377, "report/prior_ent_mag": 64.12236022949219, "report/prior_ent_max": 64.12236022949219, "report/prior_ent_mean": 50.3939323425293, "report/prior_ent_min": 29.297039031982422, "report/prior_ent_std": 4.954897403717041, "report/rep_loss_mean": 12.837000846862793, "report/rep_loss_std": 8.078886032104492, "report/reward_avg": 0.0010606051655486226, "report/reward_loss_mean": 0.040033355355262756, "report/reward_loss_std": 0.011604009196162224, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012557506561279297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040033355355262756, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001058159046806395, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00022115890169516206, "eval/cont_loss_std": 0.006418128497898579, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04299108311533928, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1296688171569258e-05, "eval/cont_pred": 0.9952967166900635, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.81749153137207, "eval/dyn_loss_std": 9.753905296325684, "eval/image_loss_mean": 11.680734634399414, "eval/image_loss_std": 14.206221580505371, "eval/model_loss_mean": 22.53394317626953, "eval/model_loss_std": 18.90617561340332, "eval/post_ent_mag": 56.268821716308594, "eval/post_ent_max": 56.268821716308594, "eval/post_ent_mean": 37.685508728027344, "eval/post_ent_min": 19.41897201538086, "eval/post_ent_std": 5.663572788238525, "eval/prior_ent_mag": 64.12236022949219, "eval/prior_ent_max": 64.12236022949219, "eval/prior_ent_mean": 51.35277557373047, "eval/prior_ent_min": 26.777502059936523, "eval/prior_ent_std": 5.946093559265137, "eval/rep_loss_mean": 16.81749153137207, "eval/rep_loss_std": 9.753905296325684, "eval/reward_avg": 0.001269531319849193, "eval/reward_loss_mean": 0.7624942064285278, "eval/reward_loss_std": 3.7324934005737305, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.6302506923675537, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.975570678710938, "eval/reward_pred": 0.0010117270285263658, "eval/reward_rate": 0.0068359375, "replay/size": 359561.0, "replay/inserts": 19984.0, "replay/samples": 19984.0, "replay/insert_wait_avg": 1.3664686937538312e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.66844331483253e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 71280.0, "eval_replay/inserts": 3464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1842465565881883e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0406816005707, "timer/env.step_count": 2498.0, "timer/env.step_total": 247.34837889671326, "timer/env.step_frac": 0.24733831677810428, "timer/env.step_avg": 0.09901856641181475, "timer/env.step_min": 0.02295374870300293, "timer/env.step_max": 3.4838051795959473, "timer/replay._sample_count": 19984.0, "timer/replay._sample_total": 10.028039455413818, "timer/replay._sample_frac": 0.010027631515313842, "timer/replay._sample_avg": 0.0005018034155030934, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.010677337646484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2931.0, "timer/agent.policy_total": 47.229554176330566, "timer/agent.policy_frac": 0.047227632880633814, "timer/agent.policy_avg": 0.01611380217547955, "timer/agent.policy_min": 0.009526491165161133, "timer/agent.policy_max": 0.10399198532104492, "timer/dataset_train_count": 1249.0, "timer/dataset_train_total": 0.14263129234313965, "timer/dataset_train_frac": 0.0001426254901099198, "timer/dataset_train_avg": 0.00011419639098730157, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0003459453582763672, "timer/agent.train_count": 1249.0, "timer/agent.train_total": 561.179765701294, "timer/agent.train_frac": 0.5611569369389279, "timer/agent.train_avg": 0.4493032551651673, "timer/agent.train_min": 0.4358546733856201, "timer/agent.train_max": 1.032517910003662, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4705996513366699, "timer/agent.report_frac": 0.0004705805073684328, "timer/agent.report_avg": 0.23529982566833496, "timer/agent.report_min": 0.22731828689575195, "timer/agent.report_max": 0.24328136444091797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1231563312320815e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 19.982944148985514}
{"step": 360168, "time": 18479.763217687607, "episode/length": 138.0, "episode/score": 0.15227865466295043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15227865466295043}
{"step": 360304, "time": 18486.543625354767, "episode/length": 160.0, "episode/score": 0.16350588618661277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16350588618661277}
{"step": 360448, "time": 18493.672419309616, "episode/length": 215.0, "episode/score": 0.25370832858607173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25370832858607173}
{"step": 360736, "time": 18507.65788793564, "episode/length": 179.0, "episode/score": 0.19617934965936001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19617934965936001}
{"step": 360944, "time": 18516.98601412773, "episode/length": 202.0, "episode/score": 0.22986270970432088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22986270970432088}
{"step": 361056, "time": 18522.65604376793, "episode/length": 319.0, "episode/score": 0.33434681114158593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33434681114158593}
{"step": 361256, "time": 18531.52364063263, "episode/length": 178.0, "episode/score": 0.19787874423127505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19787874423127505}
{"step": 361584, "time": 18545.315737247467, "episode/length": 141.0, "episode/score": 0.1519609221686551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1519609221686551}
{"step": 361800, "time": 18554.72097468376, "episode/length": 203.0, "episode/score": 0.2065947827322816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2065947827322816}
{"step": 362088, "time": 18567.141185998917, "episode/length": 168.0, "episode/score": 0.1860549534576421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1860549534576421}
{"step": 362128, "time": 18570.43239593506, "episode/length": 312.0, "episode/score": 0.35103514585716766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35103514585716766}
{"step": 362160, "time": 18573.25555753708, "episode/length": 231.0, "episode/score": 0.24138650115128257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24138650115128257}
{"step": 362264, "time": 18578.410363197327, "episode/length": 164.0, "episode/score": 0.18452639820679906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18452639820679906}
{"step": 362936, "time": 18605.035088539124, "episode/length": 168.0, "episode/score": 0.19066039738572726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19066039738572726}
{"step": 363048, "time": 18610.821774959564, "episode/length": 223.0, "episode/score": 0.24394939921148762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24394939921148762}
{"step": 363336, "time": 18623.297140836716, "episode/length": 284.0, "episode/score": 0.31703232965992356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31703232965992356}
{"step": 363448, "time": 18629.09007883072, "episode/length": 169.0, "episode/score": 0.19402212047680223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19402212047680223}
{"step": 363472, "time": 18631.85961675644, "episode/length": 167.0, "episode/score": 0.1759852105024038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1759852105024038}
{"step": 363496, "time": 18634.021782398224, "episode/length": 211.0, "episode/score": 0.2341585921803926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2341585921803926}
{"step": 363600, "time": 18639.70531630516, "episode/length": 179.0, "episode/score": 0.18986576476345363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18986576476345363}
{"step": 363632, "time": 18642.547236442566, "episode/length": 170.0, "episode/score": 0.1709410316125286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1709410316125286}
{"step": 363792, "time": 18650.201176404953, "episode/length": 36.0, "episode/score": 0.042166665953118354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042166665953118354}
{"step": 364264, "time": 18669.030397176743, "episode/length": 165.0, "episode/score": 0.18263809489872074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18263809489872074}
{"step": 364328, "time": 18672.904702425003, "episode/length": 109.0, "episode/score": 0.12292392789095175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12292392789095175}
{"step": 364424, "time": 18678.11312699318, "episode/length": 171.0, "episode/score": 0.17897558242657396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17897558242657396}
{"step": 364584, "time": 18685.78298997879, "episode/length": 138.0, "episode/score": 0.1527516730075149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1527516730075149}
{"step": 364936, "time": 18700.696939706802, "episode/length": 162.0, "episode/score": 0.18422385818303155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18422385818303155}
{"step": 365032, "time": 18705.930972099304, "episode/length": 211.0, "episode/score": 0.220042765906328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.220042765906328}
{"step": 365104, "time": 18710.43096923828, "episode/length": 163.0, "episode/score": 0.18294481980410637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18294481980410637}
{"step": 365128, "time": 18712.598487377167, "episode/length": 190.0, "episode/score": 0.1999362668248068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1999362668248068}
{"step": 365880, "time": 18742.243410348892, "episode/length": 201.0, "episode/score": 0.2152599021928836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2152599021928836}
{"step": 366096, "time": 18752.02460002899, "episode/length": 188.0, "episode/score": 0.2096779147068446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2096779147068446}
{"step": 366184, "time": 18756.654821395874, "episode/length": 155.0, "episode/score": 0.15308805008226045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15308805008226045}
{"step": 366184, "time": 18756.66228723526, "episode/length": 143.0, "episode/score": 0.16125531394754944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16125531394754944}
{"step": 366192, "time": 18760.54259777069, "episode/length": 232.0, "episode/score": 0.238787916743604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.238787916743604}
{"step": 366216, "time": 18762.89872956276, "episode/length": 138.0, "episode/score": 0.14861262715658086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14861262715658086}
{"step": 366520, "time": 18775.85587954521, "episode/length": 173.0, "episode/score": 0.1785314628859851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785314628859851}
{"step": 367064, "time": 18797.79846405983, "episode/length": 329.0, "episode/score": 0.3593920304638232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3593920304638232}
{"step": 367280, "time": 18808.253526449203, "episode/length": 136.0, "episode/score": 0.14985855959912442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14985855959912442}
{"step": 367336, "time": 18812.221586942673, "episode/length": 154.0, "episode/score": 0.17419024918399373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17419024918399373}
{"step": 367408, "time": 18817.170756340027, "episode/length": 152.0, "episode/score": 0.16293464418231451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16293464418231451}
{"step": 367488, "time": 18822.09433913231, "episode/length": 161.0, "episode/score": 0.1589355744617933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1589355744617933}
{"step": 367600, "time": 18827.926826000214, "episode/length": 172.0, "episode/score": 0.1746275040140972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1746275040140972}
{"step": 367736, "time": 18834.37703371048, "episode/length": 231.0, "episode/score": 0.22908998120055912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22908998120055912}
{"step": 367792, "time": 18838.18950009346, "episode/length": 158.0, "episode/score": 0.1582624607390244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1582624607390244}
{"step": 368288, "time": 18858.222865343094, "episode/length": 85.0, "episode/score": 0.08370158002071548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08370158002071548}
{"step": 368288, "time": 18858.22979736328, "episode/length": 109.0, "episode/score": 0.11452591215493158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11452591215493158}
{"step": 368536, "time": 18870.64874768257, "episode/length": 149.0, "episode/score": 0.15338428453105735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15338428453105735}
{"step": 368864, "time": 18886.19714283943, "episode/length": 140.0, "episode/score": 0.14010807795420988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14010807795420988}
{"step": 368920, "time": 18889.599191904068, "episode/length": 178.0, "episode/score": 0.1920629108644789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1920629108644789}
{"step": 369048, "time": 18895.948817014694, "episode/length": 156.0, "episode/score": 0.15733458342583617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15733458342583617}
{"step": 369312, "time": 18907.415867328644, "episode/length": 127.0, "episode/score": 0.1479861218649603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1479861218649603}
{"step": 369608, "time": 18919.792811632156, "episode/length": 133.0, "episode/score": 0.1579166636802256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1579166636802256}
{"step": 369968, "time": 18934.97826075554, "episode/length": 362.0, "episode/score": 0.3367841954313917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3367841954313917}
{"step": 370032, "time": 18957.59806752205, "eval_episode/length": 127.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.953125}
{"step": 370032, "time": 18959.779767036438, "eval_episode/length": 140.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 370032, "time": 18961.448982715607, "eval_episode/length": 142.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.993006993006993}
{"step": 370032, "time": 18963.81583213806, "eval_episode/length": 159.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.96875}
{"step": 370032, "time": 18965.89002084732, "eval_episode/length": 168.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 370032, "time": 18968.60037612915, "eval_episode/length": 195.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 370032, "time": 18970.547753334045, "eval_episode/length": 202.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 370032, "time": 18977.62844491005, "eval_episode/length": 159.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.99375}
{"step": 370112, "time": 18980.571224927902, "episode/length": 148.0, "episode/score": 0.15445364121114835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15445364121114835}
{"step": 370216, "time": 18985.821286678314, "episode/length": 30.0, "episode/score": 0.030114735804090742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030114735804090742}
{"step": 370296, "time": 18990.28660440445, "episode/length": 155.0, "episode/score": 0.18919325860952085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18919325860952085}
{"step": 370360, "time": 18994.16499018669, "episode/length": 384.0, "episode/score": 0.3533814470283687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3533814470283687}
{"step": 370616, "time": 19005.21009039879, "episode/length": 218.0, "episode/score": 0.22815504672871612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22815504672871612}
{"step": 370936, "time": 19018.77172088623, "episode/length": 165.0, "episode/score": 0.16300877060530183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16300877060530183}
{"step": 371064, "time": 19025.130610704422, "episode/length": 346.0, "episode/score": 0.374581914207738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.374581914207738}
{"step": 371336, "time": 19036.949011325836, "episode/length": 252.0, "episode/score": 0.2669012966834998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2669012966834998}
{"step": 371472, "time": 19044.33776974678, "episode/length": 169.0, "episode/score": 0.18771757234026154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18771757234026154}
{"step": 371800, "time": 19058.07047510147, "episode/length": 179.0, "episode/score": 0.20814880591933616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20814880591933616}
{"step": 372032, "time": 19068.57716345787, "episode/length": 136.0, "episode/score": 0.1280511720888171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1280511720888171}
{"step": 372080, "time": 19071.79411458969, "episode/length": 232.0, "episode/score": 0.24662687429736252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24662687429736252}
{"step": 372104, "time": 19074.032807826996, "episode/length": 185.0, "episode/score": 0.19913252728565567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19913252728565567}
{"step": 372656, "time": 19096.44225168228, "episode/length": 164.0, "episode/score": 0.17997651080804644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17997651080804644}
{"step": 372848, "time": 19105.13742542267, "episode/length": 92.0, "episode/score": 0.11129464060650207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11129464060650207}
{"step": 373000, "time": 19112.27229452133, "episode/length": 190.0, "episode/score": 0.2132338296414673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2132338296414673}
{"step": 373552, "time": 19134.72822856903, "episode/length": 189.0, "episode/score": 0.21484500033238874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21484500033238874}
{"step": 373560, "time": 19136.413293123245, "episode/length": 407.0, "episode/score": 0.45526441165020515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45526441165020515}
{"step": 373608, "time": 19139.798752069473, "episode/length": 225.0, "episode/score": 0.2434209910197751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2434209910197751}
{"step": 373808, "time": 19149.022520303726, "episode/length": 215.0, "episode/score": 0.21847376113873906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21847376113873906}
{"step": 373920, "time": 19154.714502811432, "episode/length": 356.0, "episode/score": 0.3844299987258637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3844299987258637}
{"step": 374192, "time": 19166.496743440628, "episode/length": 191.0, "episode/score": 0.21510785299415147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21510785299415147}
{"step": 374248, "time": 19169.962752342224, "episode/length": 174.0, "episode/score": 0.17157413842232927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17157413842232927}
{"step": 374272, "time": 19172.577106952667, "episode/length": 158.0, "episode/score": 0.16357480953956838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16357480953956838}
{"step": 374424, "time": 19179.558372974396, "episode/length": 101.0, "episode/score": 0.11354286079858866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11354286079858866}
{"step": 374904, "time": 19198.898362398148, "episode/length": 167.0, "episode/score": 0.19017433483531931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19017433483531931}
{"step": 375352, "time": 19217.528431892395, "episode/length": 192.0, "episode/score": 0.21571275856695138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21571275856695138}
{"step": 375384, "time": 19220.742916107178, "episode/length": 228.0, "episode/score": 0.23557784398690274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23557784398690274}
{"step": 375440, "time": 19225.05584025383, "episode/length": 145.0, "episode/score": 0.15134718387707835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15134718387707835}
{"step": 375600, "time": 19232.92759346962, "episode/length": 146.0, "episode/score": 0.1513486733811078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1513486733811078}
{"step": 375896, "time": 19245.45458674431, "episode/length": 246.0, "episode/score": 0.27579670900740894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27579670900740894}
{"step": 375968, "time": 19250.07345533371, "episode/length": 214.0, "episode/score": 0.23140112004966795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23140112004966795}
{"step": 375992, "time": 19252.348304271698, "episode/length": 135.0, "episode/score": 0.14894540768727893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14894540768727893}
{"step": 376600, "time": 19276.529757261276, "episode/length": 300.0, "episode/score": 0.3397867003805004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3397867003805004}
{"step": 376696, "time": 19281.49972128868, "episode/length": 167.0, "episode/score": 0.19673946007060295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19673946007060295}
{"step": 376776, "time": 19286.052257299423, "episode/length": 173.0, "episode/score": 0.1945918047631494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1945918047631494}
{"step": 376912, "time": 19294.34196949005, "episode/length": 183.0, "episode/score": 0.20502812179529428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20502812179529428}
{"step": 376992, "time": 19298.914437532425, "episode/length": 173.0, "episode/score": 0.17946310671322863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17946310671322863}
{"step": 377112, "time": 19304.714126825333, "episode/length": 151.0, "episode/score": 0.16630001024986996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16630001024986996}
{"step": 377144, "time": 19307.499976873398, "episode/length": 143.0, "episode/score": 0.16008343982684892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16008343982684892}
{"step": 377544, "time": 19324.219944000244, "episode/length": 196.0, "episode/score": 0.22155591668979469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22155591668979469}
{"step": 377984, "time": 19342.418172121048, "episode/length": 150.0, "episode/score": 0.15423940404753012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15423940404753012}
{"step": 378224, "time": 19352.949182748795, "episode/length": 202.0, "episode/score": 0.23230726323345152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23230726323345152}
{"step": 378344, "time": 19358.797643899918, "episode/length": 205.0, "episode/score": 0.24029606345175125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24029606345175125}
{"step": 378440, "time": 19363.848720788956, "episode/length": 190.0, "episode/score": 0.21344883864639996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21344883864639996}
{"step": 378816, "time": 19379.664222955704, "episode/length": 212.0, "episode/score": 0.2542689343827078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2542689343827078}
{"step": 378944, "time": 19385.981649637222, "episode/length": 224.0, "episode/score": 0.25768163244219977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25768163244219977}
{"step": 379240, "time": 19398.51807785034, "episode/length": 211.0, "episode/score": 0.23079572162532713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23079572162532713}
{"step": 379264, "time": 19401.218089342117, "episode/length": 159.0, "episode/score": 0.16341842063411605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16341842063411605}
{"step": 379616, "time": 19415.85708618164, "episode/length": 146.0, "episode/score": 0.165783160358842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.165783160358842}
{"step": 379808, "time": 19424.671788692474, "episode/length": 182.0, "episode/score": 0.204406314624066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.204406314624066}
{"step": 379864, "time": 19428.018815994263, "episode/length": 204.0, "episode/score": 0.21467145952919964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21467145952919964}
{"step": 380016, "time": 19450.26267361641, "eval_episode/length": 49.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.92}
{"step": 380016, "time": 19455.992482423782, "eval_episode/length": 151.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.993421052631579}
{"step": 380016, "time": 19457.88892531395, "eval_episode/length": 158.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 380016, "time": 19459.81074643135, "eval_episode/length": 167.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 380016, "time": 19461.48379278183, "eval_episode/length": 170.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 380016, "time": 19466.346731185913, "eval_episode/length": 93.0, "eval_episode/score": 1.100000023841858, "eval_episode/reward_rate": 0.9893617021276596}
{"step": 380016, "time": 19468.289967536926, "eval_episode/length": 252.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 380016, "time": 19471.60984969139, "eval_episode/length": 237.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 380032, "time": 19472.215062856674, "episode/length": 151.0, "episode/score": 0.1616741168545559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1616741168545559}
{"step": 380073, "time": 19476.251533031464, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.07779248046875, "train/action_min": 0.0, "train/action_std": 4.976902088165283, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006957933064550162, "train/actor_opt_grad_steps": 23030.0, "train/actor_opt_loss": -9.046759942188858, "train/adv_mag": 0.16748242193460464, "train/adv_max": 0.11282639396190643, "train/adv_mean": 8.525221379386494e-06, "train/adv_min": -0.16514594596624374, "train/adv_std": 0.01305901774764061, "train/cont_avg": 0.9945390625, "train/cont_loss_mean": 0.0002357887557166123, "train/cont_loss_std": 0.007127845527964382, "train/cont_neg_acc": 0.9886253991127014, "train/cont_neg_loss": 0.030941991645420785, "train/cont_pos_acc": 0.9999921245574951, "train/cont_pos_loss": 5.980659803617527e-05, "train/cont_pred": 0.9945945339202881, "train/cont_rate": 0.9945390625, "train/dyn_loss_mean": 12.337236465454101, "train/dyn_loss_std": 8.109290584564208, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14810808132588862, "train/extr_critic_critic_opt_grad_steps": 23030.0, "train/extr_critic_critic_opt_loss": 11612.7660625, "train/extr_critic_mag": 0.27081315898895264, "train/extr_critic_max": 0.27081315898895264, "train/extr_critic_mean": 0.21574216365814208, "train/extr_critic_min": 0.0048344449996948246, "train/extr_critic_std": 0.05511046966910362, "train/extr_return_normed_mag": 0.1928455160856247, "train/extr_return_normed_max": 0.1928455160856247, "train/extr_return_normed_mean": 0.13847646647691728, "train/extr_return_normed_min": -0.07626166814565659, "train/extr_return_normed_std": 0.05675186914205551, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.27011981582641603, "train/extr_return_raw_max": 0.27011981582641603, "train/extr_return_raw_mean": 0.21575077080726623, "train/extr_return_raw_min": 0.0010126314163208007, "train/extr_return_raw_std": 0.056751869186758994, "train/extr_reward_mag": 0.0013829679489135742, "train/extr_reward_max": 0.0013829679489135742, "train/extr_reward_mean": 0.0010966317495331168, "train/extr_reward_min": 1.006317138671875e-05, "train/extr_reward_std": 0.00022950302727986127, "train/image_loss_mean": 6.490887571334839, "train/image_loss_std": 10.990007511138916, "train/model_loss_mean": 13.933433464050292, "train/model_loss_std": 14.373154075622558, "train/model_opt_grad_norm": 63.1037151184082, "train/model_opt_grad_steps": 23006.104, "train/model_opt_loss": 17116.1406484375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1230.0, "train/policy_entropy_mag": 2.7617913074493408, "train/policy_entropy_max": 2.7617913074493408, "train/policy_entropy_mean": 2.1145544834136962, "train/policy_entropy_min": 0.08343113452196121, "train/policy_entropy_std": 0.6037073378562927, "train/policy_logprob_mag": 7.438018272399902, "train/policy_logprob_max": -0.010020733289420604, "train/policy_logprob_mean": -2.114342948913574, "train/policy_logprob_min": -7.438018272399902, "train/policy_logprob_std": 1.1462099056243897, "train/policy_randomness_mag": 0.9747911357879638, "train/policy_randomness_max": 0.9747911357879638, "train/policy_randomness_mean": 0.7463449330329895, "train/policy_randomness_min": 0.029447529196739198, "train/policy_randomness_std": 0.2130821976661682, "train/post_ent_mag": 55.13754608154297, "train/post_ent_max": 55.13754608154297, "train/post_ent_mean": 38.23565325927734, "train/post_ent_min": 20.240117462158203, "train/post_ent_std": 6.468417087554932, "train/prior_ent_mag": 64.49094552612304, "train/prior_ent_max": 64.49094552612304, "train/prior_ent_mean": 50.62590612792969, "train/prior_ent_min": 29.097879608154297, "train/prior_ent_std": 5.461577732086182, "train/rep_loss_mean": 12.337236465454101, "train/rep_loss_std": 8.109290584564208, "train/reward_avg": 0.0010578295895829796, "train/reward_loss_mean": 0.03996824678778648, "train/reward_loss_std": 0.011313500605523587, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013148059844970703, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039968247026205064, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010605858666822314, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.6140186781777399, "train_stats/max_log_achievement_collect_drink": 1.7476635514018692, "train_stats/max_log_achievement_collect_sapling": 0.6448598130841121, "train_stats/max_log_achievement_collect_wood": 0.29906542056074764, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.018691588785046728, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3644859813084112, "train_stats/max_log_achievement_place_table": 0.009345794392523364, "train_stats/max_log_achievement_wake_up": 0.3177570093457944, "train_stats/mean_log_entropy": 2.2307959304791747, "eval_stats/sum_log_reward": 0.6624999814666808, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.201566894655116e-05, "report/cont_loss_std": 0.0003370814665686339, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000319390237564221, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0262970792828128e-05, "report/cont_pred": 0.9941224455833435, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.47887897491455, "report/dyn_loss_std": 8.029158592224121, "report/image_loss_mean": 7.1449432373046875, "report/image_loss_std": 12.334012031555176, "report/model_loss_mean": 14.67065143585205, "report/model_loss_std": 15.737968444824219, "report/post_ent_mag": 54.44767761230469, "report/post_ent_max": 54.44767761230469, "report/post_ent_mean": 37.482147216796875, "report/post_ent_min": 20.33526611328125, "report/post_ent_std": 5.834549903869629, "report/prior_ent_mag": 64.18543243408203, "report/prior_ent_max": 64.18543243408203, "report/prior_ent_mean": 49.77874755859375, "report/prior_ent_min": 27.44169044494629, "report/prior_ent_std": 5.759987831115723, "report/rep_loss_mean": 12.47887897491455, "report/rep_loss_std": 8.029158592224121, "report/reward_avg": 0.001010444015264511, "report/reward_loss_mean": 0.038358621299266815, "report/reward_loss_std": 0.012681341730058193, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001231551170349121, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.038358625024557114, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001003325218334794, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.6560097467154264e-05, "eval/cont_loss_std": 0.000754882232286036, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008248287253081799, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4022299385251245e-06, "eval/cont_pred": 0.9970918297767639, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.59642219543457, "eval/dyn_loss_std": 10.265868186950684, "eval/image_loss_mean": 15.939088821411133, "eval/image_loss_std": 29.593217849731445, "eval/model_loss_mean": 26.363840103149414, "eval/model_loss_std": 33.35085678100586, "eval/post_ent_mag": 55.040260314941406, "eval/post_ent_max": 55.040260314941406, "eval/post_ent_mean": 37.08998489379883, "eval/post_ent_min": 20.77128791809082, "eval/post_ent_std": 6.425041675567627, "eval/prior_ent_mag": 64.18543243408203, "eval/prior_ent_max": 64.18543243408203, "eval/prior_ent_mean": 50.15974426269531, "eval/prior_ent_min": 22.25970458984375, "eval/prior_ent_std": 6.147044658660889, "eval/rep_loss_mean": 16.59642219543457, "eval/rep_loss_std": 10.265868186950684, "eval/reward_avg": 0.0087890625, "eval/reward_loss_mean": 0.4668714702129364, "eval/reward_loss_std": 2.930126905441284, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.23436658084392548, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.074785232543945, "eval/reward_pred": 0.0009854153031483293, "eval/reward_rate": 0.01171875, "replay/size": 379569.0, "replay/inserts": 20008.0, "replay/samples": 20016.0, "replay/insert_wait_avg": 1.3751132351929833e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.818366640000988e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75992.0, "eval_replay/inserts": 4712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2178473642605068e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3320634365082, "timer/env.step_count": 2501.0, "timer/env.step_total": 240.24190545082092, "timer/env.step_frac": 0.24016215637985422, "timer/env.step_avg": 0.09605833884479045, "timer/env.step_min": 0.02298736572265625, "timer/env.step_max": 3.435781240463257, "timer/replay._sample_count": 20016.0, "timer/replay._sample_total": 10.101170778274536, "timer/replay._sample_frac": 0.010097817662240379, "timer/replay._sample_avg": 0.0005046548150616774, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.010376930236816406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3090.0, "timer/agent.policy_total": 51.21737861633301, "timer/agent.policy_frac": 0.05120037684324792, "timer/agent.policy_avg": 0.016575203435706475, "timer/agent.policy_min": 0.009668827056884766, "timer/agent.policy_max": 0.16396427154541016, "timer/dataset_train_count": 1251.0, "timer/dataset_train_total": 0.14600634574890137, "timer/dataset_train_frac": 0.0001459578784741898, "timer/dataset_train_avg": 0.00011671170723333442, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0010769367218017578, "timer/agent.train_count": 1251.0, "timer/agent.train_total": 559.767580986023, "timer/agent.train_frac": 0.5595817643423481, "timer/agent.train_avg": 0.44745609990889124, "timer/agent.train_min": 0.4320495128631592, "timer/agent.train_max": 1.0916364192962646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47508955001831055, "timer/agent.report_frac": 0.00047493184251857666, "timer/agent.report_avg": 0.23754477500915527, "timer/agent.report_min": 0.22867345809936523, "timer/agent.report_max": 0.2464160919189453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.336752094054747e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 20.001088994445695}
{"step": 380104, "time": 19477.230358839035, "episode/length": 388.0, "episode/score": 0.3767272936734116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3767272936734116}
{"step": 380360, "time": 19488.600110292435, "episode/length": 176.0, "episode/score": 0.1893241349098389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1893241349098389}
{"step": 380416, "time": 19492.425126791, "episode/length": 146.0, "episode/score": 0.15083239967862028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15083239967862028}
{"step": 380752, "time": 19506.40400338173, "episode/length": 141.0, "episode/score": 0.14709012877028727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14709012877028727}
{"step": 380856, "time": 19511.614250421524, "episode/length": 198.0, "episode/score": 0.21312093866072246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21312093866072246}
{"step": 381104, "time": 19522.74306869507, "episode/length": 161.0, "episode/score": 0.1554456245376059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1554456245376059}
{"step": 381184, "time": 19527.306998491287, "episode/length": 164.0, "episode/score": 0.16676777824068267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16676777824068267}
{"step": 381656, "time": 19546.80190229416, "episode/length": 161.0, "episode/score": 0.17205134083087614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17205134083087614}
{"step": 381728, "time": 19551.31655406952, "episode/length": 202.0, "episode/score": 0.19198767033594777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19198767033594777}
{"step": 381984, "time": 19562.534219503403, "episode/length": 243.0, "episode/score": 0.2727110801752133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2727110801752133}
{"step": 382000, "time": 19564.789249420166, "episode/length": 155.0, "episode/score": 0.1648224417676829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1648224417676829}
{"step": 382088, "time": 19569.354067325592, "episode/length": 208.0, "episode/score": 0.22360405115068716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22360405115068716}
{"step": 382400, "time": 19582.84923005104, "episode/length": 161.0, "episode/score": 0.1694701642882137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1694701642882137}
{"step": 382424, "time": 19585.09637451172, "episode/length": 154.0, "episode/score": 0.16941258299084438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16941258299084438}
{"step": 383200, "time": 19616.19565320015, "episode/length": 149.0, "episode/score": 0.14191306739030551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14191306739030551}
{"step": 383272, "time": 19620.27702355385, "episode/length": 201.0, "episode/score": 0.2046469233591779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2046469233591779}
{"step": 383344, "time": 19624.800765752792, "episode/length": 169.0, "episode/score": 0.16913402348836826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16913402348836826}
{"step": 383424, "time": 19629.424079418182, "episode/length": 166.0, "episode/score": 0.17594955472486618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17594955472486618}
{"step": 383480, "time": 19632.78824019432, "episode/length": 218.0, "episode/score": 0.23042248904857843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23042248904857843}
{"step": 383600, "time": 19639.041089773178, "episode/length": 149.0, "episode/score": 0.15582486503171822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15582486503171822}
{"step": 383704, "time": 19644.183524608612, "episode/length": 355.0, "episode/score": 0.40157851003550604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40157851003550604}
{"step": 383864, "time": 19651.736272096634, "episode/length": 179.0, "episode/score": 0.19360447132112313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19360447132112313}
{"step": 384424, "time": 19674.190408945084, "episode/length": 152.0, "episode/score": 0.1756313051091638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1756313051091638}
{"step": 384784, "time": 19689.375497817993, "episode/length": 147.0, "episode/score": 0.16730454374737747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16730454374737747}
{"step": 384784, "time": 19689.382605552673, "episode/length": 44.0, "episode/score": 0.04965277714654803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04965277714654803}
{"step": 384816, "time": 19693.783920049667, "episode/length": 173.0, "episode/score": 0.17500583660421398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17500583660421398}
{"step": 384816, "time": 19693.792728424072, "episode/length": 166.0, "episode/score": 0.19346825036336668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19346825036336668}
{"step": 384824, "time": 19697.435673236847, "episode/length": 184.0, "episode/score": 0.2025180281025314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2025180281025314}
{"step": 385216, "time": 19715.318947076797, "episode/length": 242.0, "episode/score": 0.27718998202090006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27718998202090006}
{"step": 385296, "time": 19719.804959774017, "episode/length": 198.0, "episode/score": 0.2026387337655251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2026387337655251}
{"step": 385696, "time": 19736.48675942421, "episode/length": 228.0, "episode/score": 0.24496420474588376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24496420474588376}
{"step": 386024, "time": 19750.308822155, "episode/length": 150.0, "episode/score": 0.18133332981960848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18133332981960848}
{"step": 386024, "time": 19750.321641921997, "episode/length": 154.0, "episode/score": 0.166470166351246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166470166351246}
{"step": 386064, "time": 19755.971593141556, "episode/length": 159.0, "episode/score": 0.1793911122922509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793911122922509}
{"step": 386104, "time": 19758.79184627533, "episode/length": 159.0, "episode/score": 0.18369350988632505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18369350988632505}
{"step": 386336, "time": 19769.246155500412, "episode/length": 189.0, "episode/score": 0.2263529369583921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2263529369583921}
{"step": 386384, "time": 19772.50086426735, "episode/length": 145.0, "episode/score": 0.15774282228176162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15774282228176162}
{"step": 386480, "time": 19777.665062904358, "episode/length": 147.0, "episode/score": 0.16124005995061452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16124005995061452}
{"step": 387224, "time": 19807.01003098488, "episode/length": 144.0, "episode/score": 0.16153328557265922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16153328557265922}
{"step": 387320, "time": 19812.489172697067, "episode/length": 202.0, "episode/score": 0.2200216299343083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2200216299343083}
{"step": 387344, "time": 19815.287650585175, "episode/length": 119.0, "episode/score": 0.14025735042741871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14025735042741871}
{"step": 387400, "time": 19818.823461294174, "episode/length": 171.0, "episode/score": 0.19119524058623938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19119524058623938}
{"step": 387592, "time": 19827.602114200592, "episode/length": 195.0, "episode/score": 0.16023164155194536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16023164155194536}
{"step": 387752, "time": 19835.040684700012, "episode/length": 176.0, "episode/score": 0.18492851292467094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18492851292467094}
{"step": 387848, "time": 19840.170455932617, "episode/length": 170.0, "episode/score": 0.1953619310297654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1953619310297654}
{"step": 387960, "time": 19846.04372549057, "episode/length": 231.0, "episode/score": 0.2512128454982303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2512128454982303}
{"step": 388656, "time": 19873.780238866806, "episode/length": 163.0, "episode/score": 0.17079965925586293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17079965925586293}
{"step": 388776, "time": 19879.7514462471, "episode/length": 147.0, "episode/score": 0.164578634659847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.164578634659847}
{"step": 388824, "time": 19883.0504155159, "episode/length": 177.0, "episode/score": 0.1774608237647044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1774608237647044}
{"step": 388856, "time": 19885.79719519615, "episode/length": 203.0, "episode/score": 0.21313120953345788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21313120953345788}
{"step": 388920, "time": 19889.762617349625, "episode/length": 145.0, "episode/score": 0.1604003985921736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1604003985921736}
{"step": 389192, "time": 19901.751620531082, "episode/length": 153.0, "episode/score": 0.1714262137447804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714262137447804}
{"step": 389264, "time": 19906.409910202026, "episode/length": 242.0, "episode/score": 0.27589608999551274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27589608999551274}
{"step": 389808, "time": 19928.27524137497, "episode/length": 143.0, "episode/score": 0.1575834314298845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1575834314298845}
{"step": 389912, "time": 19934.10328578949, "episode/length": 257.0, "episode/score": 0.2751766384753864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2751766384753864}
{"step": 390000, "time": 19958.088347673416, "eval_episode/length": 135.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9632352941176471}
{"step": 390000, "time": 19960.727180719376, "eval_episode/length": 159.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.99375}
{"step": 390000, "time": 19962.85684299469, "eval_episode/length": 170.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 390000, "time": 19962.863786697388, "eval_episode/length": 170.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 390000, "time": 19966.838925600052, "eval_episode/length": 180.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.994475138121547}
{"step": 390000, "time": 19968.599607229233, "eval_episode/length": 183.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 390000, "time": 19970.37362599373, "eval_episode/length": 188.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 390000, "time": 19972.555681943893, "eval_episode/length": 69.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 390072, "time": 19975.015721321106, "episode/length": 143.0, "episode/score": 0.1405267028239905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1405267028239905}
{"step": 390104, "time": 19977.776226997375, "episode/length": 165.0, "episode/score": 0.17832133606862044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17832133606862044}
{"step": 390368, "time": 19989.375497817993, "episode/length": 137.0, "episode/score": 0.14989875721039425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14989875721039425}
{"step": 390424, "time": 19992.826511621475, "episode/length": 199.0, "episode/score": 0.20935493312208564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20935493312208564}
{"step": 390536, "time": 19998.630658626556, "episode/length": 167.0, "episode/score": 0.17189515494465013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17189515494465013}
{"step": 390864, "time": 20012.56362581253, "episode/length": 250.0, "episode/score": 0.2918739891229052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2918739891229052}
{"step": 391176, "time": 20025.61922097206, "episode/length": 157.0, "episode/score": 0.15766988940777082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15766988940777082}
{"step": 391360, "time": 20034.896743297577, "episode/length": 193.0, "episode/score": 0.19778792325269023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19778792325269023}
{"step": 391760, "time": 20052.08103442192, "episode/length": 210.0, "episode/score": 0.22241535766897869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22241535766897869}
{"step": 392008, "time": 20062.76590204239, "episode/length": 237.0, "episode/score": 0.23544931353808352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23544931353808352}
{"step": 392120, "time": 20068.532936811447, "episode/length": 211.0, "episode/score": 0.2160520337865819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2160520337865819}
{"step": 392376, "time": 20079.70178127289, "episode/length": 149.0, "episode/score": 0.15356873820655892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15356873820655892}
{"step": 392384, "time": 20081.85895228386, "episode/length": 189.0, "episode/score": 0.19615211883592565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19615211883592565}
{"step": 392680, "time": 20094.250581026077, "episode/length": 267.0, "episode/score": 0.30027048384727095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30027048384727095}
{"step": 392704, "time": 20097.586297273636, "episode/length": 291.0, "episode/score": 0.3128300498410681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3128300498410681}
{"step": 392768, "time": 20102.169219732285, "episode/length": 175.0, "episode/score": 0.19205397907353472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19205397907353472}
{"step": 392880, "time": 20108.290743350983, "episode/length": 139.0, "episode/score": 0.15795833070296794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15795833070296794}
{"step": 392952, "time": 20112.39368748665, "episode/length": 117.0, "episode/score": 0.14029166393447667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14029166393447667}
{"step": 393032, "time": 20117.10265660286, "episode/length": 32.0, "episode/score": 0.03674999944632873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03674999944632873}
{"step": 393408, "time": 20134.225525856018, "episode/length": 160.0, "episode/score": 0.18227444706735696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18227444706735696}
{"step": 393824, "time": 20151.31654691696, "episode/length": 180.0, "episode/score": 0.19695868124290428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19695868124290428}
{"step": 393984, "time": 20158.909429311752, "episode/length": 199.0, "episode/score": 0.22895832947688177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22895832947688177}
{"step": 394000, "time": 20161.053183555603, "episode/length": 161.0, "episode/score": 0.1683168222043605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1683168222043605}
{"step": 394152, "time": 20168.075830698013, "episode/length": 183.0, "episode/score": 0.20301388758980465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20301388758980465}
{"step": 394232, "time": 20172.697875976562, "episode/length": 168.0, "episode/score": 0.17429794704275992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17429794704275992}
{"step": 394400, "time": 20180.900612831116, "episode/length": 170.0, "episode/score": 0.18111453410438116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18111453410438116}
{"step": 394824, "time": 20198.284611701965, "episode/length": 233.0, "episode/score": 0.2514878455613143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2514878455613143}
{"step": 395040, "time": 20208.34086537361, "episode/length": 203.0, "episode/score": 0.23717769892482465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23717769892482465}
{"step": 395088, "time": 20212.227118253708, "episode/length": 137.0, "episode/score": 0.1485616673808181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1485616673808181}
{"step": 395216, "time": 20219.104709625244, "episode/length": 132.0, "episode/score": 0.16112499666633084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16112499666633084}
{"step": 395240, "time": 20221.482059001923, "episode/length": 176.0, "episode/score": 0.19996766245640174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19996766245640174}
{"step": 395336, "time": 20226.632603168488, "episode/length": 116.0, "episode/score": 0.13932909419872885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13932909419872885}
{"step": 395408, "time": 20231.05710029602, "episode/length": 146.0, "episode/score": 0.1642440451105358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1642440451105358}
{"step": 395648, "time": 20241.532574415207, "episode/length": 205.0, "episode/score": 0.2111872447794667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2111872447794667}
{"step": 395928, "time": 20253.2479262352, "episode/length": 88.0, "episode/score": 0.08089244180609967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08089244180609967}
{"step": 396320, "time": 20269.966110229492, "episode/length": 186.0, "episode/score": 0.21560549949572305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21560549949572305}
{"step": 396672, "time": 20284.53619980812, "episode/length": 178.0, "episode/score": 0.18903787661747629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18903787661747629}
{"step": 396728, "time": 20288.02842283249, "episode/length": 173.0, "episode/score": 0.1979507519181425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1979507519181425}
{"step": 397008, "time": 20300.416459798813, "episode/length": 239.0, "episode/score": 0.24488053589811898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24488053589811898}
{"step": 397016, "time": 20301.99238038063, "episode/length": 170.0, "episode/score": 0.1710276037492804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1710276037492804}
{"step": 397288, "time": 20313.717339992523, "episode/length": 169.0, "episode/score": 0.16940105718458653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16940105718458653}
{"step": 397680, "time": 20330.227047920227, "episode/length": 125.0, "episode/score": 0.11888849960041625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11888849960041625}
{"step": 397856, "time": 20338.34729361534, "episode/length": 140.0, "episode/score": 0.1501061615854269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1501061615854269}
{"step": 398128, "time": 20349.958582162857, "episode/length": 139.0, "episode/score": 0.15391986699660265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15391986699660265}
{"step": 398144, "time": 20352.113403081894, "episode/length": 387.0, "episode/score": 0.4035628969259051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4035628969259051}
{"step": 398280, "time": 20358.592427253723, "episode/length": 244.0, "episode/score": 0.25044066384316466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25044066384316466}
{"step": 398424, "time": 20365.6118183136, "episode/length": 175.0, "episode/score": 0.19662095171634064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19662095171634064}
{"step": 398672, "time": 20376.638649463654, "episode/length": 407.0, "episode/score": 0.4391445929436486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4391445929436486}
{"step": 398776, "time": 20381.852211475372, "episode/length": 185.0, "episode/score": 0.207789298811349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.207789298811349}
{"step": 398976, "time": 20391.18941092491, "episode/length": 105.0, "episode/score": 0.12717296134042044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12717296134042044}
{"step": 399032, "time": 20394.597576856613, "episode/length": 168.0, "episode/score": 0.1686122840005737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1686122840005737}
{"step": 399112, "time": 20399.159588575363, "episode/length": 156.0, "episode/score": 0.15291094514350334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15291094514350334}
{"step": 399520, "time": 20416.276359796524, "episode/length": 154.0, "episode/score": 0.15365334172111034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15365334172111034}
{"step": 399664, "time": 20423.104519367218, "episode/length": 68.0, "episode/score": 0.05936055957363351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05936055957363351}
{"step": 399920, "time": 20434.70879983902, "episode/length": 142.0, "episode/score": 0.15164957327124284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15164957327124284}
{"step": 399976, "time": 20438.33210492134, "episode/length": 228.0, "episode/score": 0.24248272973682106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24248272973682106}
{"step": 400088, "time": 20461.059545993805, "eval_episode/length": 101.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9509803921568627}
{"step": 400088, "time": 20463.736380815506, "eval_episode/length": 129.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9769230769230769}
{"step": 400088, "time": 20465.789834976196, "eval_episode/length": 139.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 400088, "time": 20468.659247875214, "eval_episode/length": 165.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 400088, "time": 20470.897099256516, "eval_episode/length": 180.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.994475138121547}
{"step": 400088, "time": 20472.676026821136, "eval_episode/length": 185.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 400088, "time": 20475.319722414017, "eval_episode/length": 203.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 400088, "time": 20477.62569832802, "eval_episode/length": 221.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.963963963963964}
{"step": 400089, "time": 20479.979908943176, "train_stats/sum_log_reward": 0.4963963860729793, "train_stats/max_log_achievement_collect_drink": 0.6936936936936937, "train_stats/max_log_achievement_collect_sapling": 0.5855855855855856, "train_stats/max_log_achievement_collect_wood": 0.35135135135135137, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.009009009009009009, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3783783783783784, "train_stats/max_log_achievement_place_table": 0.02702702702702703, "train_stats/max_log_achievement_wake_up": 0.21621621621621623, "train_stats/mean_log_entropy": 2.24403267293363, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.99854833984375, "train/action_min": 0.0, "train/action_std": 5.017987396240234, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0073817744813859465, "train/actor_opt_grad_steps": 24280.0, "train/actor_opt_loss": -1.5918345210552216, "train/adv_mag": 0.17813697677850723, "train/adv_max": 0.12426758146286011, "train/adv_mean": 0.0003931439832531396, "train/adv_min": -0.17707590585947036, "train/adv_std": 0.01394702846929431, "train/cont_avg": 0.9945390625, "train/cont_loss_mean": 0.00040695090345957397, "train/cont_loss_std": 0.011249707435971004, "train/cont_neg_acc": 0.9925587320327759, "train/cont_neg_loss": 0.025028941846372617, "train/cont_pos_acc": 0.9999056067466736, "train/cont_pos_loss": 0.00025905368600263043, "train/cont_pred": 0.9945130348205566, "train/cont_rate": 0.9945390625, "train/dyn_loss_mean": 12.415409431457519, "train/dyn_loss_std": 8.133488117218018, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15727018076181412, "train/extr_critic_critic_opt_grad_steps": 24280.0, "train/extr_critic_critic_opt_loss": 12073.409625, "train/extr_critic_mag": 0.27160370540618894, "train/extr_critic_max": 0.27160370540618894, "train/extr_critic_mean": 0.2238937816619873, "train/extr_critic_min": 0.0039645109176635746, "train/extr_critic_std": 0.052603119671344754, "train/extr_return_normed_mag": 0.18550112020969392, "train/extr_return_normed_max": 0.18550112020969392, "train/extr_return_normed_mean": 0.13864531856775283, "train/extr_return_normed_min": -0.08460097271203995, "train/extr_return_normed_std": 0.05451493683457374, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2711426990032196, "train/extr_return_raw_max": 0.2711426990032196, "train/extr_return_raw_mean": 0.22428690135478974, "train/extr_return_raw_min": 0.0010406064987182617, "train/extr_return_raw_std": 0.05451493702828884, "train/extr_reward_mag": 0.0013854398727416992, "train/extr_reward_max": 0.0013854398727416992, "train/extr_reward_mean": 0.0010938394498080015, "train/extr_reward_min": 1.0087966918945312e-05, "train/extr_reward_std": 0.0002291586676146835, "train/image_loss_mean": 6.4747178230285645, "train/image_loss_std": 10.867876705169678, "train/model_loss_mean": 13.964301277160645, "train/model_loss_std": 14.226242530822754, "train/model_opt_grad_norm": 60.385399169921875, "train/model_opt_grad_steps": 24255.0, "train/model_opt_loss": 10907.01651171875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 780.0, "train/policy_entropy_mag": 2.760683717727661, "train/policy_entropy_max": 2.760683717727661, "train/policy_entropy_mean": 2.1285437850952147, "train/policy_entropy_min": 0.08269211095571517, "train/policy_entropy_std": 0.580761785030365, "train/policy_logprob_mag": 7.4380498886108395, "train/policy_logprob_max": -0.0099301273599267, "train/policy_logprob_mean": -2.1281121187210084, "train/policy_logprob_min": -7.4380498886108395, "train/policy_logprob_std": 1.1318047575950623, "train/policy_randomness_mag": 0.9744002022743226, "train/policy_randomness_max": 0.9744002022743226, "train/policy_randomness_mean": 0.7512825422286987, "train/policy_randomness_min": 0.029186686336994172, "train/policy_randomness_std": 0.20498342537879943, "train/post_ent_mag": 55.55212176513672, "train/post_ent_max": 55.55212176513672, "train/post_ent_mean": 38.31429602050781, "train/post_ent_min": 20.133771942138672, "train/post_ent_std": 6.482365352630615, "train/prior_ent_mag": 64.60142434692384, "train/prior_ent_max": 64.60142434692384, "train/prior_ent_mean": 50.806629791259766, "train/prior_ent_min": 29.606355880737304, "train/prior_ent_std": 5.466643241882324, "train/rep_loss_mean": 12.415409431457519, "train/rep_loss_std": 8.133488117218018, "train/reward_avg": 0.001056800696067512, "train/reward_loss_mean": 0.03993089044094086, "train/reward_loss_std": 0.011345722109079361, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001326054573059082, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03993089047074318, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001055601755157113, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.3499999828636646, "eval_stats/max_log_achievement_collect_drink": 0.5, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.533138740545837e-06, "report/cont_loss_std": 4.0870436350815e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014755774463992566, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.39121254960628e-06, "report/cont_pred": 0.9921873211860657, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.642533302307129, "report/dyn_loss_std": 7.248916149139404, "report/image_loss_mean": 5.327613830566406, "report/image_loss_std": 8.46570873260498, "report/model_loss_mean": 12.953713417053223, "report/model_loss_std": 11.796539306640625, "report/post_ent_mag": 54.40828323364258, "report/post_ent_max": 54.40828323364258, "report/post_ent_mean": 38.57984161376953, "report/post_ent_min": 20.809024810791016, "report/post_ent_std": 6.190589427947998, "report/prior_ent_mag": 64.54298400878906, "report/prior_ent_max": 64.54298400878906, "report/prior_ent_mean": 51.317176818847656, "report/prior_ent_min": 27.262828826904297, "report/prior_ent_std": 4.682834148406982, "report/rep_loss_mean": 12.642533302307129, "report/rep_loss_std": 7.248916149139404, "report/reward_avg": 0.0010755163384601474, "report/reward_loss_mean": 0.04057800769805908, "report/reward_loss_std": 0.010408822447061539, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013412237167358398, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04057800769805908, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00105528614949435, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.004235838074237108, "eval/cont_loss_std": 0.13547676801681519, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 2.1686899662017822, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1610974581799383e-07, "eval/cont_pred": 0.9990105628967285, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.820114135742188, "eval/dyn_loss_std": 9.96639633178711, "eval/image_loss_mean": 12.006158828735352, "eval/image_loss_std": 15.329554557800293, "eval/model_loss_mean": 23.71343421936035, "eval/model_loss_std": 19.429794311523438, "eval/post_ent_mag": 51.55152893066406, "eval/post_ent_max": 51.55152893066406, "eval/post_ent_mean": 36.9834098815918, "eval/post_ent_min": 19.119544982910156, "eval/post_ent_std": 5.993101119995117, "eval/prior_ent_mag": 64.54298400878906, "eval/prior_ent_max": 64.54298400878906, "eval/prior_ent_mean": 51.82817840576172, "eval/prior_ent_min": 31.149049758911133, "eval/prior_ent_std": 4.308103084564209, "eval/rep_loss_mean": 18.820114135742188, "eval/rep_loss_std": 9.96639633178711, "eval/reward_avg": 0.0049804686568677425, "eval/reward_loss_mean": 0.41097140312194824, "eval/reward_loss_std": 2.7110910415649414, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.2755259871482849, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.089252471923828, "eval/reward_pred": 0.0010452481219545007, "eval/reward_rate": 0.0068359375, "replay/size": 399585.0, "replay/inserts": 20016.0, "replay/samples": 20016.0, "replay/insert_wait_avg": 1.3966830990773787e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.839211589712605e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 79416.0, "eval_replay/inserts": 3424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.201771687124377e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.4262416362762, "timer/env.step_count": 2502.0, "timer/env.step_total": 246.13893818855286, "timer/env.step_frac": 0.2455431910748629, "timer/env.step_avg": 0.09837687377640002, "timer/env.step_min": 0.022871732711791992, "timer/env.step_max": 3.9429469108581543, "timer/replay._sample_count": 20016.0, "timer/replay._sample_total": 10.172352313995361, "timer/replay._sample_frac": 0.010147731465400257, "timer/replay._sample_avg": 0.0005082110468622782, "timer/replay._sample_min": 0.00038909912109375, "timer/replay._sample_max": 0.02204585075378418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2930.0, "timer/agent.policy_total": 47.4052517414093, "timer/agent.policy_frac": 0.0472905135284856, "timer/agent.policy_avg": 0.01617926680594174, "timer/agent.policy_min": 0.009733438491821289, "timer/agent.policy_max": 0.11101579666137695, "timer/dataset_train_count": 1251.0, "timer/dataset_train_total": 0.14524483680725098, "timer/dataset_train_frac": 0.00014489329067260404, "timer/dataset_train_avg": 0.00011610298705615585, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0010673999786376953, "timer/agent.train_count": 1251.0, "timer/agent.train_total": 563.9212334156036, "timer/agent.train_frac": 0.5625563358109082, "timer/agent.train_avg": 0.4507763656399709, "timer/agent.train_min": 0.43673229217529297, "timer/agent.train_max": 1.0562241077423096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47722649574279785, "timer/agent.report_frac": 0.00047607143141405943, "timer/agent.report_avg": 0.23861324787139893, "timer/agent.report_min": 0.23210930824279785, "timer/agent.report_max": 0.2451171875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0443714317759354e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 19.96727856333013}
{"step": 400248, "time": 20485.991324424744, "episode/length": 227.0, "episode/score": 0.21869718386005843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21869718386005843}
{"step": 400640, "time": 20502.848630428314, "episode/length": 207.0, "episode/score": 0.22987408204744497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22987408204744497}
{"step": 400728, "time": 20507.590723991394, "episode/length": 150.0, "episode/score": 0.15590282395714894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15590282395714894}
{"step": 400944, "time": 20517.31440091133, "episode/length": 159.0, "episode/score": 0.16033035512373317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16033035512373317}
{"step": 401440, "time": 20538.71504664421, "episode/length": 182.0, "episode/score": 0.20006601415661862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20006601415661862}
{"step": 401504, "time": 20542.598124027252, "episode/length": 308.0, "episode/score": 0.3465739947419024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3465739947419024}
{"step": 401680, "time": 20550.59956741333, "episode/length": 375.0, "episode/score": 0.39674028603940314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39674028603940314}
{"step": 401688, "time": 20552.208906173706, "episode/length": 220.0, "episode/score": 0.2412246563617373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2412246563617373}
{"step": 401768, "time": 20556.72217106819, "episode/length": 189.0, "episode/score": 0.20727948395506246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20727948395506246}
{"step": 401936, "time": 20564.83722138405, "episode/length": 150.0, "episode/score": 0.16638059393881122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16638059393881122}
{"step": 402120, "time": 20573.11662006378, "episode/length": 184.0, "episode/score": 0.20233659446239471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20233659446239471}
{"step": 402152, "time": 20575.82809329033, "episode/length": 150.0, "episode/score": 0.1814583296654746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1814583296654746}
{"step": 402728, "time": 20599.502967119217, "episode/length": 160.0, "episode/score": 0.17939880650374107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17939880650374107}
{"step": 403216, "time": 20619.725905656815, "episode/length": 136.0, "episode/score": 0.14264848753009574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14264848753009574}
{"step": 403264, "time": 20623.116267204285, "episode/length": 165.0, "episode/score": 0.17895208147456287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17895208147456287}
{"step": 403296, "time": 20625.967735528946, "episode/length": 223.0, "episode/score": 0.2565712535288185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2565712535288185}
{"step": 403336, "time": 20628.699026107788, "episode/length": 147.0, "episode/score": 0.17085713983397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17085713983397}
{"step": 403560, "time": 20638.622659683228, "episode/length": 223.0, "episode/score": 0.24872360387962544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24872360387962544}
{"step": 403568, "time": 20640.764749765396, "episode/length": 235.0, "episode/score": 0.25596591388239176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25596591388239176}
{"step": 403688, "time": 20646.56279039383, "episode/length": 249.0, "episode/score": 0.28077838052558945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28077838052558945}
{"step": 403936, "time": 20657.65412569046, "episode/length": 150.0, "episode/score": 0.17369871495247935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17369871495247935}
{"step": 404304, "time": 20673.03086900711, "episode/length": 120.0, "episode/score": 0.14109539968922036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14109539968922036}
{"step": 404376, "time": 20677.513164281845, "episode/length": 134.0, "episode/score": 0.15708732973325823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15708732973325823}
{"step": 404520, "time": 20685.066639900208, "episode/length": 162.0, "episode/score": 0.15646449792620842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15646449792620842}
{"step": 404792, "time": 20697.37895822525, "episode/length": 153.0, "episode/score": 0.13123020085549797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13123020085549797}
{"step": 404832, "time": 20700.70349049568, "episode/length": 142.0, "episode/score": 0.1469763074128423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1469763074128423}
{"step": 405336, "time": 20720.963355064392, "episode/length": 258.0, "episode/score": 0.26117404646902287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26117404646902287}
{"step": 405480, "time": 20727.939888715744, "episode/length": 137.0, "episode/score": 0.160862190372427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.160862190372427}
{"step": 405480, "time": 20727.94746685028, "episode/length": 238.0, "episode/score": 0.25374602341253194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25374602341253194}
{"step": 405496, "time": 20731.750626325607, "episode/length": 148.0, "episode/score": 0.1649578345241025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1649578345241025}
{"step": 406032, "time": 20753.59096813202, "episode/length": 261.0, "episode/score": 0.29047320864083304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29047320864083304}
{"step": 406224, "time": 20762.34509921074, "episode/length": 178.0, "episode/score": 0.18574377897311933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18574377897311933}
{"step": 406328, "time": 20767.555107831955, "episode/length": 105.0, "episode/score": 0.1301388861029409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1301388861029409}
{"step": 406512, "time": 20776.269612789154, "episode/length": 248.0, "episode/score": 0.27417559109744616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27417559109744616}
{"step": 406592, "time": 20780.68076825142, "episode/length": 138.0, "episode/score": 0.15265258771250956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15265258771250956}
{"step": 406720, "time": 20787.035462856293, "episode/length": 152.0, "episode/score": 0.16369433452928206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16369433452928206}
{"step": 406976, "time": 20798.03984928131, "episode/length": 267.0, "episode/score": 0.29254636898986064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29254636898986064}
{"step": 407200, "time": 20807.953778028488, "episode/length": 145.0, "episode/score": 0.14294520175462821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14294520175462821}
{"step": 407392, "time": 20816.582165956497, "episode/length": 145.0, "episode/score": 0.13638629799243063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13638629799243063}
{"step": 407464, "time": 20820.558354377747, "episode/length": 265.0, "episode/score": 0.27188789304636884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27188789304636884}
{"step": 407584, "time": 20826.79430413246, "episode/length": 156.0, "episode/score": 0.18058489160102908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18058489160102908}
{"step": 408512, "time": 20863.14347052574, "episode/length": 191.0, "episode/score": 0.22895832895301282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22895832895301282}
{"step": 408608, "time": 20868.473032951355, "episode/length": 235.0, "episode/score": 0.27205632680488634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27205632680488634}
{"step": 408640, "time": 20871.20249414444, "episode/length": 146.0, "episode/score": 0.16591964002873283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16591964002873283}
{"step": 408736, "time": 20876.26164674759, "episode/length": 167.0, "episode/score": 0.19170252069670823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19170252069670823}
{"step": 408872, "time": 20882.640532255173, "episode/length": 294.0, "episode/score": 0.3181189871029346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3181189871029346}
{"step": 408936, "time": 20886.70454478264, "episode/length": 168.0, "episode/score": 0.1746239411768329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1746239411768329}
{"step": 409288, "time": 20901.533766269684, "episode/length": 260.0, "episode/score": 0.2936338804065599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2936338804065599}
{"step": 409576, "time": 20914.163956165314, "episode/length": 120.0, "episode/score": 0.11994352854890167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11994352854890167}
{"step": 409808, "time": 20926.449825048447, "episode/length": 161.0, "episode/score": 0.17253054314460314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17253054314460314}
{"step": 409936, "time": 20932.73925614357, "episode/length": 161.0, "episode/score": 0.1791095673579548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1791095673579548}
{"step": 409952, "time": 20934.927191734314, "episode/length": 419.0, "episode/score": 0.47873231849371223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47873231849371223}
{"step": 410072, "time": 20955.126615285873, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 410072, "time": 20957.52257490158, "eval_episode/length": 55.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 410072, "time": 20959.998854875565, "eval_episode/length": 79.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9875}
{"step": 410072, "time": 20962.849563598633, "eval_episode/length": 109.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.990909090909091}
{"step": 410072, "time": 20966.994568109512, "eval_episode/length": 170.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 410072, "time": 20969.361737966537, "eval_episode/length": 186.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 410072, "time": 20971.32472205162, "eval_episode/length": 195.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 410072, "time": 20973.358915567398, "eval_episode/length": 170.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 410176, "time": 20977.4904358387, "episode/length": 162.0, "episode/score": 0.1624480507471162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1624480507471162}
{"step": 410328, "time": 20984.486506938934, "episode/length": 173.0, "episode/score": 0.1850677269630978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1850677269630978}
{"step": 410344, "time": 20986.60419535637, "episode/length": 200.0, "episode/score": 0.22256205924713868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22256205924713868}
{"step": 410456, "time": 20992.32174015045, "episode/length": 145.0, "episode/score": 0.1676869889106456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1676869889106456}
{"step": 410848, "time": 21008.493547439575, "episode/length": 158.0, "episode/score": 0.17081877961209102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17081877961209102}
{"step": 410904, "time": 21011.82123351097, "episode/length": 136.0, "episode/score": 0.14936867266442277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14936867266442277}
{"step": 411488, "time": 21035.551861763, "episode/length": 191.0, "episode/score": 0.21388120234587404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21388120234587404}
{"step": 411520, "time": 21038.78611087799, "episode/length": 167.0, "episode/score": 0.17136249838040385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17136249838040385}
{"step": 411552, "time": 21042.05066561699, "episode/length": 201.0, "episode/score": 0.21936202182405395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21936202182405395}
{"step": 411616, "time": 21046.419305562973, "episode/length": 144.0, "episode/score": 0.16363001383797382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16363001383797382}
{"step": 411648, "time": 21049.19996237755, "episode/length": 162.0, "episode/score": 0.18974823616008507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18974823616008507}
{"step": 411736, "time": 21053.865360736847, "episode/length": 175.0, "episode/score": 0.18374174264499743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18374174264499743}
{"step": 412176, "time": 21072.108234882355, "episode/length": 165.0, "episode/score": 0.19211038379307865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19211038379307865}
{"step": 412840, "time": 21098.383358716965, "episode/length": 241.0, "episode/score": 0.2662110031787961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2662110031787961}
{"step": 412872, "time": 21101.20648741722, "episode/length": 156.0, "episode/score": 0.16834006919089006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16834006919089006}
{"step": 412896, "time": 21103.926648378372, "episode/length": 175.0, "episode/score": 0.1953477874139935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1953477874139935}
{"step": 412928, "time": 21106.82759308815, "episode/length": 171.0, "episode/score": 0.18219004556613072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18219004556613072}
{"step": 413024, "time": 21111.891740322113, "episode/length": 171.0, "episode/score": 0.19516942770223977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19516942770223977}
{"step": 413048, "time": 21114.145185232162, "episode/length": 163.0, "episode/score": 0.1850416636443697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1850416636443697}
{"step": 413232, "time": 21122.83136987686, "episode/length": 213.0, "episode/score": 0.23986936929668445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23986936929668445}
{"step": 413584, "time": 21137.66207265854, "episode/length": 175.0, "episode/score": 0.1763115060821292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1763115060821292}
{"step": 413728, "time": 21144.51824736595, "episode/length": 87.0, "episode/score": 0.09362299416170572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09362299416170572}
{"step": 414016, "time": 21156.791214466095, "episode/length": 146.0, "episode/score": 0.16765685994323576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16765685994323576}
{"step": 414128, "time": 21162.593804359436, "episode/length": 149.0, "episode/score": 0.1614129519330163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1614129519330163}
{"step": 414208, "time": 21167.216619729996, "episode/length": 166.0, "episode/score": 0.1723950948471611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1723950948471611}
{"step": 414240, "time": 21170.08055973053, "episode/length": 148.0, "episode/score": 0.17629807356570382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17629807356570382}
{"step": 414760, "time": 21190.721796035767, "episode/length": 190.0, "episode/score": 0.20528826477311668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20528826477311668}
{"step": 414912, "time": 21198.283546447754, "episode/length": 165.0, "episode/score": 0.17701353094162187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17701353094162187}
{"step": 414960, "time": 21201.56245970726, "episode/length": 257.0, "episode/score": 0.2945042808241851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2945042808241851}
{"step": 414976, "time": 21203.67982983589, "episode/length": 155.0, "episode/score": 0.17070138607232366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17070138607232366}
{"step": 415088, "time": 21209.43969964981, "episode/length": 133.0, "episode/score": 0.13191970105981454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13191970105981454}
{"step": 415536, "time": 21228.49565386772, "episode/length": 165.0, "episode/score": 0.15462607017616392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15462607017616392}
{"step": 415888, "time": 21243.089209079742, "episode/length": 205.0, "episode/score": 0.20593328335962724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20593328335962724}
{"step": 416008, "time": 21248.93747472763, "episode/length": 234.0, "episode/score": 0.2603031439175538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2603031439175538}
{"step": 416056, "time": 21252.272054195404, "episode/length": 161.0, "episode/score": 0.18131547336815856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18131547336815856}
{"step": 416080, "time": 21254.98454618454, "episode/length": 139.0, "episode/score": 0.13728453461953904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13728453461953904}
{"step": 416288, "time": 21264.266151189804, "episode/length": 163.0, "episode/score": 0.1666632277538156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1666632277538156}
{"step": 416368, "time": 21268.74010515213, "episode/length": 159.0, "episode/score": 0.13665216719164164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13665216719164164}
{"step": 416984, "time": 21293.129625082016, "episode/length": 180.0, "episode/score": 0.19335477405729762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19335477405729762}
{"step": 417080, "time": 21298.298846006393, "episode/length": 98.0, "episode/score": 0.10358476772034919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10358476772034919}
{"step": 417288, "time": 21307.548679590225, "episode/length": 150.0, "episode/score": 0.16118325514435128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16118325514435128}
{"step": 417360, "time": 21312.12782239914, "episode/length": 168.0, "episode/score": 0.1629362568273791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1629362568273791}
{"step": 417600, "time": 21322.708817005157, "episode/length": 192.0, "episode/score": 0.20526896526735072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20526896526735072}
{"step": 417712, "time": 21328.564769506454, "episode/length": 349.0, "episode/score": 0.399739080137806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.399739080137806}
{"step": 417880, "time": 21337.583258867264, "episode/length": 188.0, "episode/score": 0.2019240825839006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2019240825839006}
{"step": 418112, "time": 21348.232387065887, "episode/length": 277.0, "episode/score": 0.33066666027298197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33066666027298197}
{"step": 418224, "time": 21353.88783144951, "episode/length": 63.0, "episode/score": 0.06838636253269215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06838636253269215}
{"step": 418352, "time": 21360.28243279457, "episode/length": 170.0, "episode/score": 0.18857107259373151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18857107259373151}
{"step": 418424, "time": 21364.354714393616, "episode/length": 141.0, "episode/score": 0.1498171687389913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1498171687389913}
{"step": 418456, "time": 21367.16208910942, "episode/length": 136.0, "episode/score": 0.14686468029503885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14686468029503885}
{"step": 418624, "time": 21375.273362874985, "episode/length": 33.0, "episode/score": 0.04083333257585764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04083333257585764}
{"step": 419232, "time": 21399.763666152954, "episode/length": 168.0, "episode/score": 0.1681045255427307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1681045255427307}
{"step": 419528, "time": 21412.147148370743, "episode/length": 176.0, "episode/score": 0.19646915253906627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19646915253906627}
{"step": 419536, "time": 21414.27073764801, "episode/length": 163.0, "episode/score": 0.1833461566529877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1833461566529877}
{"step": 419896, "time": 21428.905346155167, "episode/length": 158.0, "episode/score": 0.16624935768322757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16624935768322757}
{"step": 419984, "time": 21434.143650770187, "episode/length": 194.0, "episode/score": 0.2104804956316002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2104804956316002}
{"step": 420016, "time": 21436.93177461624, "episode/length": 301.0, "episode/score": 0.3276798496935953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3276798496935953}
{"step": 420056, "time": 21459.818569898605, "eval_episode/length": 135.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9632352941176471}
{"step": 420056, "time": 21461.87292408943, "eval_episode/length": 147.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 420056, "time": 21463.569003105164, "eval_episode/length": 149.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 420056, "time": 21465.683045625687, "eval_episode/length": 157.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 420056, "time": 21467.622746944427, "eval_episode/length": 165.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 420056, "time": 21469.627916812897, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 420056, "time": 21473.76473402977, "eval_episode/length": 237.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 420056, "time": 21475.676508426666, "eval_episode/length": 245.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 420121, "time": 21479.21309185028, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.07690914093502, "train/action_min": 0.0, "train/action_std": 5.090968389359731, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008117904707360717, "train/actor_opt_grad_steps": 25535.0, "train/actor_opt_loss": -5.273086082190275, "train/adv_mag": 0.18792974239303953, "train/adv_max": 0.13624918490411744, "train/adv_mean": 0.00021471912975992756, "train/adv_min": -0.18739741106355, "train/adv_std": 0.01474758485953013, "train/cont_avg": 0.9947296626984127, "train/cont_loss_mean": 0.00027535137261565303, "train/cont_loss_std": 0.00823507770505532, "train/cont_neg_acc": 0.9912194529223064, "train/cont_neg_loss": 0.02183761535049764, "train/cont_pos_acc": 0.9999532226532225, "train/cont_pos_loss": 0.00014127668232703848, "train/cont_pred": 0.9947124639200786, "train/cont_rate": 0.9947296626984127, "train/dyn_loss_mean": 12.113078230903263, "train/dyn_loss_std": 8.166318200883412, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16082337649450415, "train/extr_critic_critic_opt_grad_steps": 25535.0, "train/extr_critic_critic_opt_loss": 12437.654134114584, "train/extr_critic_mag": 0.2774062686496311, "train/extr_critic_max": 0.2774062686496311, "train/extr_critic_mean": 0.232541653017203, "train/extr_critic_min": 0.0025371190101381334, "train/extr_critic_std": 0.05629929001369174, "train/extr_return_normed_mag": 0.19591865901436126, "train/extr_return_normed_max": 0.19591865901436126, "train/extr_return_normed_mean": 0.15090601217179073, "train/extr_return_normed_min": -0.08083162261616617, "train/extr_return_normed_std": 0.05840569276303526, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2777689969728863, "train/extr_return_raw_max": 0.2777689969728863, "train/extr_return_raw_mean": 0.2327563522590531, "train/extr_return_raw_min": 0.0010187152832273453, "train/extr_return_raw_std": 0.05840569291086424, "train/extr_reward_mag": 0.0014035134088425409, "train/extr_reward_max": 0.0014035134088425409, "train/extr_reward_mean": 0.001093761420749601, "train/extr_reward_min": 1.0145088982960535e-05, "train/extr_reward_std": 0.000236945790848473, "train/image_loss_mean": 6.089490023870317, "train/image_loss_std": 10.135183493296305, "train/model_loss_mean": 13.397581319960336, "train/model_loss_std": 13.567872229076567, "train/model_opt_grad_norm": 56.79745330507793, "train/model_opt_grad_steps": 25509.579365079364, "train/model_opt_loss": 17270.30177331349, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1289.6825396825398, "train/policy_entropy_mag": 2.7566109309120783, "train/policy_entropy_max": 2.7566109309120783, "train/policy_entropy_mean": 2.1635868473658486, "train/policy_entropy_min": 0.08134914160011307, "train/policy_entropy_std": 0.5533383862366752, "train/policy_logprob_mag": 7.437858392321874, "train/policy_logprob_max": -0.009729404009819503, "train/policy_logprob_mean": -2.1625556993106057, "train/policy_logprob_min": -7.437858392321874, "train/policy_logprob_std": 1.1013523553098952, "train/policy_randomness_mag": 0.9729626874128977, "train/policy_randomness_max": 0.9729626874128977, "train/policy_randomness_mean": 0.7636512035415286, "train/policy_randomness_min": 0.028712677089349617, "train/policy_randomness_std": 0.19530416800389214, "train/post_ent_mag": 55.55138030884758, "train/post_ent_max": 55.55138030884758, "train/post_ent_mean": 38.596744658455016, "train/post_ent_min": 20.01048960004534, "train/post_ent_std": 6.480739604859125, "train/prior_ent_mag": 64.84502162630596, "train/prior_ent_max": 64.84502162630596, "train/prior_ent_mean": 50.77942163982089, "train/prior_ent_min": 29.515696192544603, "train/prior_ent_std": 5.49407172203064, "train/rep_loss_mean": 12.113078230903263, "train/rep_loss_std": 8.166318200883412, "train/reward_avg": 0.001058281471376263, "train/reward_loss_mean": 0.03996893834500086, "train/reward_loss_std": 0.01139082448438756, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013200687983679392, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039968938492829835, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010591403725335286, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.7972476826211728, "train_stats/max_log_achievement_collect_drink": 0.48623853211009177, "train_stats/max_log_achievement_collect_sapling": 0.6238532110091743, "train_stats/max_log_achievement_collect_wood": 0.46788990825688076, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.47706422018348627, "train_stats/max_log_achievement_place_table": 0.03669724770642202, "train_stats/max_log_achievement_wake_up": 0.28440366972477066, "train_stats/mean_log_entropy": 2.252689088156464, "eval_stats/sum_log_reward": 0.3499999903142452, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.338079063221812e-06, "report/cont_loss_std": 8.292185520986095e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00031265345751307905, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.132919912080979e-06, "report/cont_pred": 0.9960908889770508, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.564085006713867, "report/dyn_loss_std": 8.484328269958496, "report/image_loss_mean": 6.32628059387207, "report/image_loss_std": 10.735562324523926, "report/model_loss_mean": 13.902320861816406, "report/model_loss_std": 14.457047462463379, "report/post_ent_mag": 57.09812927246094, "report/post_ent_max": 57.09812927246094, "report/post_ent_mean": 38.70793151855469, "report/post_ent_min": 21.669687271118164, "report/post_ent_std": 6.712680816650391, "report/prior_ent_mag": 64.74604034423828, "report/prior_ent_max": 64.74604034423828, "report/prior_ent_mean": 51.0369987487793, "report/prior_ent_min": 26.754989624023438, "report/prior_ent_std": 5.809603214263916, "report/rep_loss_mean": 12.564085006713867, "report/rep_loss_std": 8.484328269958496, "report/reward_avg": 0.0009871042566373944, "report/reward_loss_mean": 0.0375824049115181, "report/reward_loss_std": 0.013009580783545971, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013003349304199219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0375824049115181, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010011038975790143, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.122158770769602e-06, "eval/cont_loss_std": 3.488756556180306e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00014770877896808088, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.275872359154164e-06, "eval/cont_pred": 0.9941381812095642, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.544906616210938, "eval/dyn_loss_std": 9.763092041015625, "eval/image_loss_mean": 11.155496597290039, "eval/image_loss_std": 17.42839813232422, "eval/model_loss_mean": 21.868324279785156, "eval/model_loss_std": 21.90682029724121, "eval/post_ent_mag": 51.875125885009766, "eval/post_ent_max": 51.875125885009766, "eval/post_ent_mean": 37.54962921142578, "eval/post_ent_min": 20.750520706176758, "eval/post_ent_std": 6.035813808441162, "eval/prior_ent_mag": 64.74604034423828, "eval/prior_ent_max": 64.74604034423828, "eval/prior_ent_mean": 50.937232971191406, "eval/prior_ent_min": 29.794689178466797, "eval/prior_ent_std": 5.027007102966309, "eval/rep_loss_mean": 16.544906616210938, "eval/rep_loss_std": 9.763092041015625, "eval/reward_avg": 0.01025390625, "eval/reward_loss_mean": 0.7858806848526001, "eval/reward_loss_std": 3.785181999206543, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4973791539669037, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.192420959472656, "eval/reward_pred": 0.0010194136993959546, "eval/reward_rate": 0.0146484375, "replay/size": 419617.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.3993999447685461e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.790613934635735e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83032.0, "eval_replay/inserts": 3616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2236754451177816e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5110242366791, "timer/env.step_count": 2504.0, "timer/env.step_total": 240.43409156799316, "timer/env.step_frac": 0.24031128667615412, "timer/env.step_avg": 0.09602000461980557, "timer/env.step_min": 0.02326345443725586, "timer/env.step_max": 3.222839593887329, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 10.120039701461792, "timer/replay._sample_frac": 0.010114870757353909, "timer/replay._sample_avg": 0.0005051936751927812, "timer/replay._sample_min": 0.0003445148468017578, "timer/replay._sample_max": 0.010428667068481445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2956.0, "timer/agent.policy_total": 48.788957595825195, "timer/agent.policy_frac": 0.04876403799053369, "timer/agent.policy_avg": 0.016505060079778484, "timer/agent.policy_min": 0.009412765502929688, "timer/agent.policy_max": 0.13733935356140137, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.14409899711608887, "timer/dataset_train_frac": 0.00014402539664770458, "timer/dataset_train_avg": 0.00011509504561987929, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010805130004882812, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 564.9172422885895, "timer/agent.train_frac": 0.5646287033364599, "timer/agent.train_avg": 0.4512118548630906, "timer/agent.train_min": 0.43547725677490234, "timer/agent.train_max": 1.1070382595062256, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47913694381713867, "timer/agent.report_frac": 0.0004788922182868371, "timer/agent.report_avg": 0.23956847190856934, "timer/agent.report_min": 0.23132920265197754, "timer/agent.report_max": 0.24780774116516113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4076442923289823e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 20.02150707530125}
{"step": 420128, "time": 21479.240025520325, "episode/length": 380.0, "episode/score": 0.36151088394399267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36151088394399267}
{"step": 420560, "time": 21497.637545347214, "episode/length": 262.0, "episode/score": 0.273848689596889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.273848689596889}
{"step": 420624, "time": 21501.578412771225, "episode/length": 173.0, "episode/score": 0.17843817774519266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17843817774519266}
{"step": 420960, "time": 21515.87913966179, "episode/length": 177.0, "episode/score": 0.19227146206321777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19227146206321777}
{"step": 421048, "time": 21520.47732400894, "episode/length": 128.0, "episode/score": 0.15131249715341255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15131249715341255}
{"step": 421312, "time": 21532.341116189957, "episode/length": 165.0, "episode/score": 0.15493813961620617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15493813961620617}
{"step": 421312, "time": 21532.348537921906, "episode/length": 176.0, "episode/score": 0.19531688183724327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19531688183724327}
{"step": 421320, "time": 21535.71587228775, "episode/length": 148.0, "episode/score": 0.17572362072496617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17572362072496617}
{"step": 421624, "time": 21548.56064105034, "episode/length": 261.0, "episode/score": 0.27354145230674476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27354145230674476}
{"step": 421840, "time": 21558.51779603958, "episode/length": 159.0, "episode/score": 0.16218689073366477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16218689073366477}
{"step": 421984, "time": 21565.429792404175, "episode/length": 169.0, "episode/score": 0.17837513752510858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17837513752510858}
{"step": 422176, "time": 21574.09977865219, "episode/length": 140.0, "episode/score": 0.14285476381246554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14285476381246554}
{"step": 422472, "time": 21586.62447166443, "episode/length": 188.0, "episode/score": 0.19817326460861295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19817326460861295}
{"step": 422632, "time": 21594.135059833527, "episode/length": 98.0, "episode/score": 0.10806372926299446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10806372926299446}
{"step": 422680, "time": 21597.590088367462, "episode/length": 170.0, "episode/score": 0.18260351606022596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18260351606022596}
{"step": 422720, "time": 21600.83075237274, "episode/length": 174.0, "episode/score": 0.18786715083251693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18786715083251693}
{"step": 422728, "time": 21602.44347167015, "episode/length": 176.0, "episode/score": 0.2097002087684814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2097002087684814}
{"step": 423296, "time": 21625.447286128998, "episode/length": 163.0, "episode/score": 0.18674705903868016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18674705903868016}
{"step": 423344, "time": 21628.900260448456, "episode/length": 214.0, "episode/score": 0.21858642782763127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21858642782763127}
{"step": 423696, "time": 21643.623643875122, "episode/length": 120.0, "episode/score": 0.1379350626220912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1379350626220912}
{"step": 423912, "time": 21653.079531669617, "episode/length": 148.0, "episode/score": 0.1597284946410582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1597284946410582}
{"step": 424040, "time": 21659.48438644409, "episode/length": 175.0, "episode/score": 0.18478465685620904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18478465685620904}
{"step": 424192, "time": 21666.95844745636, "episode/length": 214.0, "episode/score": 0.2267652970049312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2267652970049312}
{"step": 424200, "time": 21668.572593212128, "episode/length": 252.0, "episode/score": 0.254499109813878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.254499109813878}
{"step": 424688, "time": 21688.670785188675, "episode/length": 250.0, "episode/score": 0.28008740434916035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28008740434916035}
{"step": 424728, "time": 21691.593026161194, "episode/length": 178.0, "episode/score": 0.19115488816805737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19115488816805737}
{"step": 424992, "time": 21703.332139253616, "episode/length": 205.0, "episode/score": 0.2249861220816456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2249861220816456}
{"step": 425344, "time": 21718.38595867157, "episode/length": 178.0, "episode/score": 0.1956352287070331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1956352287070331}
{"step": 425464, "time": 21724.13989663124, "episode/length": 158.0, "episode/score": 0.16065170545152796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16065170545152796}
{"step": 425736, "time": 21735.938756227493, "episode/length": 191.0, "episode/score": 0.1907446246887048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1907446246887048}
{"step": 426000, "time": 21749.080548763275, "episode/length": 287.0, "episode/score": 0.31975277484025355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31975277484025355}
{"step": 426032, "time": 21751.82877755165, "episode/length": 162.0, "episode/score": 0.1546391615952416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1546391615952416}
{"step": 426104, "time": 21755.809130191803, "episode/length": 257.0, "episode/score": 0.29857880903637124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29857880903637124}
{"step": 426288, "time": 21764.43636083603, "episode/length": 161.0, "episode/score": 0.14910584909557656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14910584909557656}
{"step": 426416, "time": 21770.73550581932, "episode/length": 215.0, "episode/score": 0.22277676695648552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22277676695648552}
{"step": 426744, "time": 21784.18842625618, "episode/length": 174.0, "episode/score": 0.1859024982536539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1859024982536539}
{"step": 427056, "time": 21797.662393331528, "episode/length": 198.0, "episode/score": 0.18431025929885436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18431025929885436}
{"step": 427088, "time": 21800.425776958466, "episode/length": 168.0, "episode/score": 0.18464227103231678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18464227103231678}
{"step": 427200, "time": 21806.139686346054, "episode/length": 149.0, "episode/score": 0.17184753100309536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17184753100309536}
{"step": 427480, "time": 21817.966898441315, "episode/length": 180.0, "episode/score": 0.1917475033719711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1917475033719711}
{"step": 427544, "time": 21821.934404850006, "episode/length": 179.0, "episode/score": 0.20543677417208528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20543677417208528}
{"step": 427552, "time": 21824.068724155426, "episode/length": 157.0, "episode/score": 0.18883831961375108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18883831961375108}
{"step": 428368, "time": 21856.111320495605, "episode/length": 202.0, "episode/score": 0.20865388314769007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20865388314769007}
{"step": 428648, "time": 21867.863480567932, "episode/length": 194.0, "episode/score": 0.21696297438757028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21696297438757028}
{"step": 428664, "time": 21870.13532924652, "episode/length": 280.0, "episode/score": 0.2999334979899686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2999334979899686}
{"step": 428704, "time": 21873.675447940826, "episode/length": 187.0, "episode/score": 0.19849711094866507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19849711094866507}
{"step": 428784, "time": 21878.754470586777, "episode/length": 154.0, "episode/score": 0.1468729694825015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1468729694825015}
{"step": 428832, "time": 21882.66546344757, "episode/length": 221.0, "episode/score": 0.2491726956650382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2491726956650382}
{"step": 429408, "time": 21906.90255880356, "episode/length": 231.0, "episode/score": 0.24072058833553456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24072058833553456}
{"step": 429680, "time": 21918.768498659134, "episode/length": 128.0, "episode/score": 0.14801901648388593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14801901648388593}
{"step": 429840, "time": 21926.23996281624, "episode/length": 183.0, "episode/score": 0.1783712395481416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1783712395481416}
{"step": 429992, "time": 21933.23392176628, "episode/length": 150.0, "episode/score": 0.16143659277622646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16143659277622646}
{"step": 430000, "time": 21935.312500476837, "episode/length": 145.0, "episode/score": 0.13554463388027216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13554463388027216}
{"step": 430040, "time": 21957.149743795395, "eval_episode/length": 144.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.993103448275862}
{"step": 430040, "time": 21957.15617632866, "eval_episode/length": 144.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.993103448275862}
{"step": 430040, "time": 21960.641102313995, "eval_episode/length": 147.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 430040, "time": 21962.924300193787, "eval_episode/length": 162.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 430040, "time": 21964.84490275383, "eval_episode/length": 169.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9588235294117647}
{"step": 430040, "time": 21966.509355545044, "eval_episode/length": 172.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 430040, "time": 21968.5670003891, "eval_episode/length": 184.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 430040, "time": 21971.20708990097, "eval_episode/length": 210.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.976303317535545}
{"step": 430128, "time": 21974.77810716629, "episode/length": 177.0, "episode/score": 0.19014265942314523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19014265942314523}
{"step": 430264, "time": 21981.217929124832, "episode/length": 199.0, "episode/score": 0.22769308208444272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22769308208444272}
{"step": 430608, "time": 21995.909952402115, "episode/length": 390.0, "episode/score": 0.35734230345224205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35734230345224205}
{"step": 430704, "time": 22001.039192914963, "episode/length": 161.0, "episode/score": 0.1707635672755714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1707635672755714}
{"step": 430928, "time": 22010.965475320816, "episode/length": 155.0, "episode/score": 0.16094457741564838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16094457741564838}
{"step": 431040, "time": 22016.756949424744, "episode/length": 149.0, "episode/score": 0.14029009101432166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14029009101432166}
{"step": 431088, "time": 22020.152005434036, "episode/length": 136.0, "episode/score": 0.1371947300285683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1371947300285683}
{"step": 431576, "time": 22040.074687480927, "episode/length": 163.0, "episode/score": 0.1857959945773473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1857959945773473}
{"step": 431648, "time": 22045.22144818306, "episode/length": 189.0, "episode/score": 0.20086839978102944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20086839978102944}
{"step": 431832, "time": 22054.096548318863, "episode/length": 140.0, "episode/score": 0.15136976839676208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15136976839676208}
{"step": 432224, "time": 22070.61005282402, "episode/length": 161.0, "episode/score": 0.1739445580069514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1739445580069514}
{"step": 432504, "time": 22082.35488820076, "episode/length": 176.0, "episode/score": 0.19313510757365293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19313510757365293}
{"step": 432600, "time": 22087.497396230698, "episode/length": 248.0, "episode/score": 0.2603835059944686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2603835059944686}
{"step": 432744, "time": 22094.46644425392, "episode/length": 212.0, "episode/score": 0.23402689105205354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23402689105205354}
{"step": 432960, "time": 22104.300512075424, "episode/length": 172.0, "episode/score": 0.17697098043299775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17697098043299775}
{"step": 433016, "time": 22107.72516655922, "episode/length": 376.0, "episode/score": 0.375203324812901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.375203324812901}
{"step": 433200, "time": 22116.465661764145, "episode/length": 193.0, "episode/score": 0.20495157969980937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20495157969980937}
{"step": 433232, "time": 22119.239054203033, "episode/length": 174.0, "episode/score": 0.18745645350372797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18745645350372797}
{"step": 433400, "time": 22126.889899015427, "episode/length": 111.0, "episode/score": 0.11351693445612909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11351693445612909}
{"step": 433440, "time": 22130.12772679329, "episode/length": 86.0, "episode/score": 0.09471024747472256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09471024747472256}
{"step": 433456, "time": 22132.274216651917, "episode/length": 106.0, "episode/score": 0.12067130678042304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12067130678042304}
{"step": 433856, "time": 22148.72207379341, "episode/length": 56.0, "episode/score": 0.06587179367124918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06587179367124918}
{"step": 433864, "time": 22150.35716366768, "episode/length": 204.0, "episode/score": 0.23470832937164232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23470832937164232}
{"step": 434120, "time": 22161.70185804367, "episode/length": 144.0, "episode/score": 0.14378516010765452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14378516010765452}
{"step": 434488, "time": 22178.558474302292, "episode/length": 156.0, "episode/score": 0.16300798255906557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16300798255906557}
{"step": 434520, "time": 22181.287575483322, "episode/length": 164.0, "episode/score": 0.18070395220638602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18070395220638602}
{"step": 434672, "time": 22188.817540168762, "episode/length": 153.0, "episode/score": 0.16731978894677013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16731978894677013}
{"step": 434760, "time": 22193.410987377167, "episode/length": 162.0, "episode/score": 0.1899474755373376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1899474755373376}
{"step": 434896, "time": 22200.946511268616, "episode/length": 234.0, "episode/score": 0.27132569091554615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27132569091554615}
{"step": 435112, "time": 22210.938749551773, "episode/length": 155.0, "episode/score": 0.1536762504692888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1536762504692888}
{"step": 435240, "time": 22217.390262126923, "episode/length": 172.0, "episode/score": 0.1952367624398903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952367624398903}
{"step": 435440, "time": 22226.623430490494, "episode/length": 164.0, "episode/score": 0.17331650773667207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17331650773667207}
{"step": 436104, "time": 22253.207585334778, "episode/length": 167.0, "episode/score": 0.18748382155354193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18748382155354193}
{"step": 436136, "time": 22256.08477449417, "episode/length": 205.0, "episode/score": 0.2078130203517503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2078130203517503}
{"step": 436248, "time": 22262.322986602783, "episode/length": 168.0, "episode/score": 0.1751498842768342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1751498842768342}
{"step": 436256, "time": 22264.395115852356, "episode/length": 197.0, "episode/score": 0.20838310355065914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20838310355065914}
{"step": 436320, "time": 22268.31938815117, "episode/length": 224.0, "episode/score": 0.2523719055134279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2523719055134279}
{"step": 436800, "time": 22288.020400762558, "episode/length": 210.0, "episode/score": 0.24329281303107564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24329281303107564}
{"step": 436864, "time": 22292.469356298447, "episode/length": 202.0, "episode/score": 0.233045927447165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.233045927447165}
{"step": 437080, "time": 22302.32890510559, "episode/length": 204.0, "episode/score": 0.2293175467493711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2293175467493711}
{"step": 437392, "time": 22316.243690013885, "episode/length": 156.0, "episode/score": 0.15878039037852432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15878039037852432}
{"step": 437568, "time": 22324.888845443726, "episode/length": 87.0, "episode/score": 0.10466147534316406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10466147534316406}
{"step": 437616, "time": 22328.17203092575, "episode/length": 188.0, "episode/score": 0.21647421923989896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21647421923989896}
{"step": 437632, "time": 22330.361390829086, "episode/length": 172.0, "episode/score": 0.1530728227517102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1530728227517102}
{"step": 438080, "time": 22349.05293059349, "episode/length": 227.0, "episode/score": 0.2404534483102907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2404534483102907}
{"step": 438256, "time": 22357.74917435646, "episode/length": 241.0, "episode/score": 0.26723425717136706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26723425717136706}
{"step": 438472, "time": 22367.17456459999, "episode/length": 208.0, "episode/score": 0.23258107320725685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23258107320725685}
{"step": 438496, "time": 22369.898589372635, "episode/length": 176.0, "episode/score": 0.16703930048606708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16703930048606708}
{"step": 438568, "time": 22373.958294391632, "episode/length": 38.0, "episode/score": 0.040374999516643584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040374999516643584}
{"step": 438936, "time": 22389.13228726387, "episode/length": 164.0, "episode/score": 0.18146090787740832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18146090787740832}
{"step": 438960, "time": 22391.698147058487, "episode/length": 195.0, "episode/score": 0.21021957701668725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21021957701668725}
{"step": 438992, "time": 22394.63776087761, "episode/length": 64.0, "episode/score": 0.07575182318760199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07575182318760199}
{"step": 439600, "time": 22418.953511238098, "episode/length": 189.0, "episode/score": 0.20622161326537025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20622161326537025}
{"step": 439928, "time": 22432.540530204773, "episode/length": 294.0, "episode/score": 0.33476517922645144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33476517922645144}
{"step": 439968, "time": 22435.803262233734, "episode/length": 291.0, "episode/score": 0.3174449480520707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3174449480520707}
{"step": 440024, "time": 22458.306971549988, "eval_episode/length": 150.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 440024, "time": 22460.083530902863, "eval_episode/length": 153.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 440024, "time": 22462.073475837708, "eval_episode/length": 160.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 440024, "time": 22462.081233501434, "eval_episode/length": 160.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.968944099378882}
{"step": 440024, "time": 22465.390204191208, "eval_episode/length": 161.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 440024, "time": 22466.993749141693, "eval_episode/length": 163.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9817073170731707}
{"step": 440024, "time": 22469.484982013702, "eval_episode/length": 182.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.994535519125683}
{"step": 440024, "time": 22471.55598974228, "eval_episode/length": 183.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 440184, "time": 22477.72587132454, "episode/length": 152.0, "episode/score": 0.157352774458559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.157352774458559}
{"step": 440185, "time": 22480.815071582794, "train_stats/sum_log_reward": 0.4211009029264844, "train_stats/max_log_achievement_collect_drink": 0.6972477064220184, "train_stats/max_log_achievement_collect_sapling": 0.4954128440366973, "train_stats/max_log_achievement_collect_wood": 0.29357798165137616, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3486238532110092, "train_stats/max_log_achievement_place_table": 0.027522935779816515, "train_stats/max_log_achievement_wake_up": 0.26605504587155965, "train_stats/mean_log_entropy": 2.2629595951202814, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.20286376953125, "train/action_min": 0.0, "train/action_std": 5.039296669006347, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008556788232177495, "train/actor_opt_grad_steps": 26790.0, "train/actor_opt_loss": -6.860498663157225, "train/adv_mag": 0.19214355897903443, "train/adv_max": 0.13450373953580858, "train/adv_mean": 0.00011092977316002361, "train/adv_min": -0.19148860430717468, "train/adv_std": 0.014890327140688896, "train/cont_avg": 0.9944375, "train/cont_loss_mean": 0.0002970290222986023, "train/cont_loss_std": 0.00907576273307859, "train/cont_neg_acc": 0.9885904779434204, "train/cont_neg_loss": 0.03739157387569139, "train/cont_pos_acc": 0.99996067237854, "train/cont_pos_loss": 0.00010184346579217163, "train/cont_pred": 0.9944570045471192, "train/cont_rate": 0.9944375, "train/dyn_loss_mean": 12.15905916595459, "train/dyn_loss_std": 8.18968249130249, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15073235258460044, "train/extr_critic_critic_opt_grad_steps": 26790.0, "train/extr_critic_critic_opt_loss": 12439.427453125, "train/extr_critic_mag": 0.282267728805542, "train/extr_critic_max": 0.282267728805542, "train/extr_critic_mean": 0.23636878073215484, "train/extr_critic_min": 0.0028797502517700197, "train/extr_critic_std": 0.057058973014354704, "train/extr_return_normed_mag": 0.2013818712234497, "train/extr_return_normed_max": 0.2013818712234497, "train/extr_return_normed_mean": 0.1554451551437378, "train/extr_return_normed_min": -0.0800582151412964, "train/extr_return_normed_std": 0.05927240428328514, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28241648435592653, "train/extr_return_raw_max": 0.28241648435592653, "train/extr_return_raw_mean": 0.2364797693490982, "train/extr_return_raw_min": 0.0009763975143432617, "train/extr_return_raw_std": 0.059272404462099075, "train/extr_reward_mag": 0.001365321159362793, "train/extr_reward_max": 0.001365321159362793, "train/extr_reward_mean": 0.0010912610311061145, "train/extr_reward_min": 9.778976440429687e-06, "train/extr_reward_std": 0.0002408799360273406, "train/image_loss_mean": 6.06620489692688, "train/image_loss_std": 10.287874988555908, "train/model_loss_mean": 13.401887634277344, "train/model_loss_std": 13.723603122711182, "train/model_opt_grad_norm": 59.47906852722168, "train/model_opt_grad_steps": 26763.096, "train/model_opt_loss": 15440.92166796875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1140.0, "train/policy_entropy_mag": 2.762304946899414, "train/policy_entropy_max": 2.762304946899414, "train/policy_entropy_mean": 2.1627016525268554, "train/policy_entropy_min": 0.08136692404747009, "train/policy_entropy_std": 0.558396404504776, "train/policy_logprob_mag": 7.438092643737793, "train/policy_logprob_max": -0.00973609734326601, "train/policy_logprob_mean": -2.162613157272339, "train/policy_logprob_min": -7.438092643737793, "train/policy_logprob_std": 1.1098104934692383, "train/policy_randomness_mag": 0.9749724254608154, "train/policy_randomness_max": 0.9749724254608154, "train/policy_randomness_mean": 0.7633387761116028, "train/policy_randomness_min": 0.02871895344555378, "train/policy_randomness_std": 0.19708942568302154, "train/post_ent_mag": 56.092350708007814, "train/post_ent_max": 56.092350708007814, "train/post_ent_mean": 38.68080947875976, "train/post_ent_min": 20.079530120849608, "train/post_ent_std": 6.541952491760254, "train/prior_ent_mag": 64.97885711669922, "train/prior_ent_max": 64.97885711669922, "train/prior_ent_mean": 50.894864227294924, "train/prior_ent_min": 29.585804214477537, "train/prior_ent_std": 5.503997760772705, "train/rep_loss_mean": 12.15905916595459, "train/rep_loss_std": 8.18968249130249, "train/reward_avg": 0.0010577819505706429, "train/reward_loss_mean": 0.03995028072595596, "train/reward_loss_std": 0.011415288724005223, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013176813125610352, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03995028042793274, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010582065200433134, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.47499998519197106, "eval_stats/max_log_achievement_collect_drink": 0.375, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0010218741372227669, "report/cont_loss_std": 0.031382158398628235, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.822880434105173e-05, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.0010283690644428134, "report/cont_pred": 0.9925054311752319, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.989757537841797, "report/dyn_loss_std": 8.648154258728027, "report/image_loss_mean": 6.78172492980957, "report/image_loss_std": 10.556313514709473, "report/model_loss_mean": 14.617228507995605, "report/model_loss_std": 14.536434173583984, "report/post_ent_mag": 55.79454040527344, "report/post_ent_max": 55.79454040527344, "report/post_ent_mean": 37.21381378173828, "report/post_ent_min": 19.477638244628906, "report/post_ent_std": 6.02897310256958, "report/prior_ent_mag": 64.39566802978516, "report/prior_ent_max": 64.39566802978516, "report/prior_ent_mean": 50.272674560546875, "report/prior_ent_min": 31.808879852294922, "report/prior_ent_std": 5.292640209197998, "report/rep_loss_mean": 12.989757537841797, "report/rep_loss_std": 8.648154258728027, "report/reward_avg": 0.0010780824813991785, "report/reward_loss_mean": 0.04062722250819206, "report/reward_loss_std": 0.010874864645302296, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012704133987426758, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040627218782901764, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010857096640393138, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.646701250341721e-05, "eval/cont_loss_std": 4.466213795240037e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.7874077204614878e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.646425855346024e-05, "eval/cont_pred": 0.9980205297470093, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.119943618774414, "eval/dyn_loss_std": 9.422757148742676, "eval/image_loss_mean": 8.400762557983398, "eval/image_loss_std": 14.557785987854004, "eval/model_loss_mean": 17.952877044677734, "eval/model_loss_std": 18.179365158081055, "eval/post_ent_mag": 57.61559295654297, "eval/post_ent_max": 57.61559295654297, "eval/post_ent_mean": 39.40680694580078, "eval/post_ent_min": 20.54267120361328, "eval/post_ent_std": 7.304648399353027, "eval/prior_ent_mag": 64.39566802978516, "eval/prior_ent_max": 64.39566802978516, "eval/prior_ent_mean": 52.267311096191406, "eval/prior_ent_min": 25.804054260253906, "eval/prior_ent_std": 4.9142889976501465, "eval/rep_loss_mean": 15.119943618774414, "eval/rep_loss_std": 9.422757148742676, "eval/reward_avg": 0.006835937034338713, "eval/reward_loss_mean": 0.48012030124664307, "eval/reward_loss_std": 2.9868900775909424, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2850418984889984, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.261075973510742, "eval/reward_pred": 0.0010272860527038574, "eval/reward_rate": 0.009765625, "replay/size": 439681.0, "replay/inserts": 20064.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.4076606508647426e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.942003835711563e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86192.0, "eval_replay/inserts": 3160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2179718741887732e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.5889835357666, "timer/env.step_count": 2508.0, "timer/env.step_total": 243.74421167373657, "timer/env.step_frac": 0.2433575205802296, "timer/env.step_avg": 0.09718668727022989, "timer/env.step_min": 0.022832155227661133, "timer/env.step_max": 3.314016342163086, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 10.287767887115479, "timer/replay._sample_frac": 0.010271446727377172, "timer/replay._sample_avg": 0.0005127476020292802, "timer/replay._sample_min": 0.0003745555877685547, "timer/replay._sample_max": 0.032302141189575195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2903.0, "timer/agent.policy_total": 47.07874798774719, "timer/agent.policy_frac": 0.0470040593113872, "timer/agent.policy_avg": 0.01621727453935487, "timer/agent.policy_min": 0.009549856185913086, "timer/agent.policy_max": 0.09107065200805664, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.14469552040100098, "timer/dataset_train_frac": 0.00014446596635897795, "timer/dataset_train_avg": 0.00011538717735327032, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.00028324127197265625, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 565.9470796585083, "timer/agent.train_frac": 0.5650492257419067, "timer/agent.train_avg": 0.45131346065271793, "timer/agent.train_min": 0.43643975257873535, "timer/agent.train_max": 1.065551519393921, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780690670013428, "timer/agent.report_frac": 0.00047731062827157284, "timer/agent.report_avg": 0.2390345335006714, "timer/agent.report_min": 0.23358368873596191, "timer/agent.report_max": 0.24448537826538086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.070720346336883e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 20.031905544171526}
{"step": 440400, "time": 22488.995124340057, "episode/length": 228.0, "episode/score": 0.2595008948119357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2595008948119357}
{"step": 440440, "time": 22491.895377635956, "episode/length": 242.0, "episode/score": 0.28966956654585374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28966956654585374}
{"step": 440856, "time": 22508.842566251755, "episode/length": 232.0, "episode/score": 0.26266982092056423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26266982092056423}
{"step": 441080, "time": 22518.783692359924, "episode/length": 184.0, "episode/score": 0.20060900745193067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20060900745193067}
{"step": 441120, "time": 22522.097315073013, "episode/length": 272.0, "episode/score": 0.27327693222105154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27327693222105154}
{"step": 441168, "time": 22525.64743256569, "episode/length": 149.0, "episode/score": 0.16185745458824385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16185745458824385}
{"step": 441312, "time": 22532.494670152664, "episode/length": 172.0, "episode/score": 0.19182762824493693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19182762824493693}
{"step": 441512, "time": 22541.303315639496, "episode/length": 165.0, "episode/score": 0.16416291414952866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16416291414952866}
{"step": 441664, "time": 22548.845865249634, "episode/length": 157.0, "episode/score": 0.17804264314327156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17804264314327156}
{"step": 441776, "time": 22554.674597501755, "episode/length": 86.0, "episode/score": 0.09509570552199875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09509570552199875}
{"step": 442184, "time": 22572.07665681839, "episode/length": 217.0, "episode/score": 0.2212968751482549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2212968751482549}
{"step": 442456, "time": 22586.32456588745, "episode/length": 199.0, "episode/score": 0.2063683921514894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2063683921514894}
{"step": 442536, "time": 22590.82940173149, "episode/length": 176.0, "episode/score": 0.17752967545766296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17752967545766296}
{"step": 442720, "time": 22599.47001695633, "episode/length": 193.0, "episode/score": 0.19993212757344736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19993212757344736}
{"step": 442728, "time": 22601.073080301285, "episode/length": 151.0, "episode/score": 0.1799583297688514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1799583297688514}
{"step": 442784, "time": 22604.94607448578, "episode/length": 183.0, "episode/score": 0.1877763904931271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1877763904931271}
{"step": 442896, "time": 22610.628022432327, "episode/length": 44.0, "episode/score": 0.04549999954178929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04549999954178929}
{"step": 443304, "time": 22627.10479402542, "episode/length": 50.0, "episode/score": 0.061458332114852965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061458332114852965}
{"step": 443808, "time": 22647.861358880997, "episode/length": 168.0, "episode/score": 0.18842488556492754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18842488556492754}
{"step": 443816, "time": 22649.54636979103, "episode/length": 254.0, "episode/score": 0.2615241116782272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2615241116782272}
{"step": 443960, "time": 22656.47766137123, "episode/length": 153.0, "episode/score": 0.15603305542845192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15603305542845192}
{"step": 444032, "time": 22660.970804929733, "episode/length": 295.0, "episode/score": 0.3134855761873041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3134855761873041}
{"step": 444088, "time": 22664.436838150024, "episode/length": 170.0, "episode/score": 0.17360344301323494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17360344301323494}
{"step": 444144, "time": 22668.456973552704, "episode/length": 169.0, "episode/score": 0.17880999573844747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17880999573844747}
{"step": 444192, "time": 22671.80638384819, "episode/length": 250.0, "episode/score": 0.2688675693152618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2688675693152618}
{"step": 444528, "time": 22685.859900951385, "episode/length": 152.0, "episode/score": 0.1625559418116609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1625559418116609}
{"step": 444792, "time": 22697.190617084503, "episode/length": 122.0, "episode/score": 0.14749999716877937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14749999716877937}
{"step": 445272, "time": 22716.968364953995, "episode/length": 154.0, "episode/score": 0.17342111872130772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17342111872130772}
{"step": 445336, "time": 22721.02673149109, "episode/length": 155.0, "episode/score": 0.17896588314442852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17896588314442852}
{"step": 445632, "time": 22733.986487150192, "episode/length": 185.0, "episode/score": 0.18907729566126363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18907729566126363}
{"step": 445664, "time": 22736.744727373123, "episode/length": 230.0, "episode/score": 0.2579063772336667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2579063772336667}
{"step": 445736, "time": 22740.8053920269, "episode/length": 221.0, "episode/score": 0.21656534418070805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21656534418070805}
{"step": 445760, "time": 22743.470523118973, "episode/length": 153.0, "episode/score": 0.14639965740934713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14639965740934713}
{"step": 446080, "time": 22757.066074848175, "episode/length": 160.0, "episode/score": 0.1818049809844524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1818049809844524}
{"step": 446496, "time": 22774.184623003006, "episode/length": 152.0, "episode/score": 0.17999999673338607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17999999673338607}
{"step": 446680, "time": 22782.355094194412, "episode/length": 167.0, "episode/score": 0.19804166292306036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19804166292306036}
{"step": 446880, "time": 22791.745451450348, "episode/length": 151.0, "episode/score": 0.16554270099004498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16554270099004498}
{"step": 447008, "time": 22798.61372590065, "episode/length": 171.0, "episode/score": 0.17670732885744656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17670732885744656}
{"step": 447064, "time": 22802.407066345215, "episode/length": 162.0, "episode/score": 0.19612499617505819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19612499617505819}
{"step": 447080, "time": 22804.60640478134, "episode/length": 167.0, "episode/score": 0.17755169040174223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17755169040174223}
{"step": 447200, "time": 22810.84178829193, "episode/length": 375.0, "episode/score": 0.3837696864238751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3837696864238751}
{"step": 447384, "time": 22819.14995455742, "episode/length": 162.0, "episode/score": 0.17603079032414826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17603079032414826}
{"step": 447512, "time": 22825.515115261078, "episode/length": 126.0, "episode/score": 0.14591513963387115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14591513963387115}
{"step": 447760, "time": 22837.282864570618, "episode/length": 134.0, "episode/score": 0.1495890466721903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1495890466721903}
{"step": 448360, "time": 22862.104857444763, "episode/length": 159.0, "episode/score": 0.1690610151999863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1690610151999863}
{"step": 448456, "time": 22867.262103796005, "episode/length": 156.0, "episode/score": 0.17329854818672175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17329854818672175}
{"step": 448464, "time": 22869.390273809433, "episode/length": 174.0, "episode/score": 0.19001623470467166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19001623470467166}
{"step": 448504, "time": 22872.191764354706, "episode/length": 186.0, "episode/score": 0.19189714111053036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19189714111053036}
{"step": 448648, "time": 22879.140616178513, "episode/length": 220.0, "episode/score": 0.23011183172638994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23011183172638994}
{"step": 448656, "time": 22881.281921625137, "episode/length": 158.0, "episode/score": 0.15978910959529458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15978910959529458}
{"step": 448696, "time": 22884.183958292007, "episode/length": 147.0, "episode/score": 0.16447648748362553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16447648748362553}
{"step": 448912, "time": 22894.128959417343, "episode/length": 143.0, "episode/score": 0.1661726718684804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661726718684804}
{"step": 449248, "time": 22908.254130601883, "episode/length": 74.0, "episode/score": 0.08979166497010738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08979166497010738}
{"step": 449560, "time": 22921.105598688126, "episode/length": 149.0, "episode/score": 0.1706600786837953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706600786837953}
{"step": 449696, "time": 22927.886105060577, "episode/length": 154.0, "episode/score": 0.1806655132677406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1806655132677406}
{"step": 449960, "time": 22939.223973751068, "episode/length": 162.0, "episode/score": 0.19156593504158081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19156593504158081}
{"step": 450008, "time": 22960.668770313263, "eval_episode/length": 117.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9491525423728814}
{"step": 450008, "time": 22962.85308766365, "eval_episode/length": 130.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9694656488549618}
{"step": 450008, "time": 22965.16504907608, "eval_episode/length": 145.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 450008, "time": 22967.31095790863, "eval_episode/length": 156.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 450008, "time": 22968.907217502594, "eval_episode/length": 157.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 450008, "time": 22972.00716638565, "eval_episode/length": 192.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 450008, "time": 22976.155178785324, "eval_episode/length": 254.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.996078431372549}
{"step": 450008, "time": 22977.876521587372, "eval_episode/length": 139.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 450048, "time": 22979.599490880966, "episode/length": 192.0, "episode/score": 0.18017006981062877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18017006981062877}
{"step": 450080, "time": 22982.348022460938, "episode/length": 172.0, "episode/score": 0.18779311951584532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18779311951584532}
{"step": 450128, "time": 22985.81192946434, "episode/length": 207.0, "episode/score": 0.24960713789914735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24960713789914735}
{"step": 450816, "time": 23015.453735113144, "episode/length": 195.0, "episode/score": 0.21190029783247155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21190029783247155}
{"step": 451024, "time": 23024.921228408813, "episode/length": 165.0, "episode/score": 0.17529994571123098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17529994571123098}
{"step": 451200, "time": 23032.9704413414, "episode/length": 154.0, "episode/score": 0.17730861202471715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17730861202471715}
{"step": 451240, "time": 23035.739632844925, "episode/length": 148.0, "episode/score": 0.16296110539224173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16296110539224173}
{"step": 451376, "time": 23042.54743528366, "episode/length": 161.0, "episode/score": 0.1730879734532209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1730879734532209}
{"step": 451600, "time": 23052.358165740967, "episode/length": 97.0, "episode/score": 0.11265369521424873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11265369521424873}
{"step": 451856, "time": 23063.640698432922, "episode/length": 367.0, "episode/score": 0.3661011953809066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3661011953809066}
{"step": 451896, "time": 23066.45076084137, "episode/length": 220.0, "episode/score": 0.24439524951048952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24439524951048952}
{"step": 452248, "time": 23081.36841249466, "episode/length": 152.0, "episode/score": 0.1514032534287253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1514032534287253}
{"step": 452368, "time": 23088.358920812607, "episode/length": 58.0, "episode/score": 0.06738888765084994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06738888765084994}
{"step": 452440, "time": 23092.9480676651, "episode/length": 154.0, "episode/score": 0.1576326300009896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1576326300009896}
{"step": 452672, "time": 23103.82163643837, "episode/length": 133.0, "episode/score": 0.1610557084377433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1610557084377433}
{"step": 452744, "time": 23107.936566352844, "episode/length": 170.0, "episode/score": 0.19972389721806394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19972389721806394}
{"step": 452824, "time": 23112.43529677391, "episode/length": 407.0, "episode/score": 0.41795138277120714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41795138277120714}
{"step": 453168, "time": 23127.194284915924, "episode/length": 240.0, "episode/score": 0.2581606706316961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2581606706316961}
{"step": 453600, "time": 23144.93358707428, "episode/length": 168.0, "episode/score": 0.18838836598388298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18838836598388298}
{"step": 453624, "time": 23147.252170562744, "episode/length": 156.0, "episode/score": 0.1745236455808481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745236455808481}
{"step": 453880, "time": 23158.570108890533, "episode/length": 150.0, "episode/score": 0.17077380660339259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17077380660339259}
{"step": 454008, "time": 23165.46524810791, "episode/length": 157.0, "episode/score": 0.1807239966083216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1807239966083216}
{"step": 454056, "time": 23169.389341831207, "episode/length": 274.0, "episode/score": 0.3287637299636117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3287637299636117}
{"step": 454312, "time": 23180.973499059677, "episode/length": 185.0, "episode/score": 0.2141285547595544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2141285547595544}
{"step": 454440, "time": 23187.276739358902, "episode/length": 249.0, "episode/score": 0.2870575003871636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2870575003871636}
{"step": 454624, "time": 23195.970875501633, "episode/length": 181.0, "episode/score": 0.20182469193787256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20182469193787256}
{"step": 454928, "time": 23208.889971733093, "episode/length": 165.0, "episode/score": 0.16824896477828588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16824896477828588}
{"step": 455000, "time": 23212.90211391449, "episode/length": 171.0, "episode/score": 0.16832353859444993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16832353859444993}
{"step": 455312, "time": 23226.318707466125, "episode/length": 156.0, "episode/score": 0.14822942390219396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14822942390219396}
{"step": 455456, "time": 23233.23899459839, "episode/length": 180.0, "episode/score": 0.19028344054549962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19028344054549962}
{"step": 455488, "time": 23236.079938411713, "episode/length": 200.0, "episode/score": 0.2080841178603805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2080841178603805}
{"step": 455688, "time": 23245.003061532974, "episode/length": 155.0, "episode/score": 0.16067952946377773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16067952946377773}
{"step": 455904, "time": 23254.924880504608, "episode/length": 159.0, "episode/score": 0.1683165076892692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1683165076892692}
{"step": 456096, "time": 23263.538549661636, "episode/length": 97.0, "episode/score": 0.11592613411812636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11592613411812636}
{"step": 456112, "time": 23265.86206126213, "episode/length": 147.0, "episode/score": 0.18270832940470427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18270832940470427}
{"step": 456320, "time": 23275.244556188583, "episode/length": 164.0, "episode/score": 0.18237146383944491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18237146383944491}
{"step": 456840, "time": 23295.962263822556, "episode/length": 172.0, "episode/score": 0.19924336927579134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19924336927579134}
{"step": 457112, "time": 23308.44821381569, "episode/length": 150.0, "episode/score": 0.16080190250886517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16080190250886517}
{"step": 457144, "time": 23311.740094661713, "episode/length": 206.0, "episode/score": 0.22363231131475914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22363231131475914}
{"step": 457448, "time": 23325.644332885742, "episode/length": 219.0, "episode/score": 0.22272181922835443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22272181922835443}
{"step": 457480, "time": 23328.839049100876, "episode/length": 172.0, "episode/score": 0.1886946262748097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1886946262748097}
{"step": 457576, "time": 23334.610070228577, "episode/length": 407.0, "episode/score": 0.3949783386542549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3949783386542549}
{"step": 457808, "time": 23345.807241678238, "episode/length": 211.0, "episode/score": 0.23916312177152577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23916312177152577}
{"step": 458240, "time": 23364.015511989594, "episode/length": 140.0, "episode/score": 0.16809583721260424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16809583721260424}
{"step": 458336, "time": 23369.119686603546, "episode/length": 186.0, "episode/score": 0.20355658613425476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20355658613425476}
{"step": 458584, "time": 23379.70610642433, "episode/length": 179.0, "episode/score": 0.2191666621947661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2191666621947661}
{"step": 458688, "time": 23385.560978651047, "episode/length": 138.0, "episode/score": 0.1455689787353549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1455689787353549}
{"step": 458808, "time": 23392.790688991547, "episode/length": 169.0, "episode/score": 0.1790809927670125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1790809927670125}
{"step": 458984, "time": 23400.956902980804, "episode/length": 146.0, "episode/score": 0.16004085872509677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16004085872509677}
{"step": 459016, "time": 23403.77408528328, "episode/length": 191.0, "episode/score": 0.20046690951403434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20046690951403434}
{"step": 459120, "time": 23409.393706321716, "episode/length": 109.0, "episode/score": 0.12010897253639996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12010897253639996}
{"step": 459200, "time": 23413.94802093506, "episode/length": 76.0, "episode/score": 0.08921874828229193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08921874828229193}
{"step": 459232, "time": 23416.650319576263, "episode/length": 111.0, "episode/score": 0.11576382466591895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11576382466591895}
{"step": 459656, "time": 23433.82672405243, "episode/length": 416.0, "episode/score": 0.44323334150612936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44323334150612936}
{"step": 460048, "time": 23450.37044286728, "episode/length": 169.0, "episode/score": 0.18756948148075026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18756948148075026}
{"step": 460096, "time": 23473.259444475174, "eval_episode/length": 141.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 460096, "time": 23475.737195014954, "eval_episode/length": 149.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 460096, "time": 23478.751118183136, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 460096, "time": 23482.35506081581, "eval_episode/length": 169.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 460096, "time": 23485.6223487854, "eval_episode/length": 192.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 460096, "time": 23488.79834294319, "eval_episode/length": 213.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 460096, "time": 23491.348886966705, "eval_episode/length": 227.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 460096, "time": 23494.786398649216, "eval_episode/length": 270.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.996309963099631}
{"step": 460097, "time": 23495.412625551224, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.330629410282258, "train/action_min": 0.0, "train/action_std": 4.941076390204891, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008555128017530566, "train/actor_opt_grad_steps": 28035.0, "train/actor_opt_loss": -13.654800889337615, "train/adv_mag": 0.18764496480505313, "train/adv_max": 0.13159032724797726, "train/adv_mean": -0.00021511543930559599, "train/adv_min": -0.18611400334104414, "train/adv_std": 0.014547242794276005, "train/cont_avg": 0.9942351310483871, "train/cont_loss_mean": 0.00021951629386808604, "train/cont_loss_std": 0.006499667190225057, "train/cont_neg_acc": 0.9915578610474064, "train/cont_neg_loss": 0.018929523767852632, "train/cont_pos_acc": 0.9999682965778536, "train/cont_pos_loss": 9.241761565161806e-05, "train/cont_pred": 0.9942402671421727, "train/cont_rate": 0.9942351310483871, "train/dyn_loss_mean": 12.001069445763864, "train/dyn_loss_std": 8.25330493527074, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15177719012623833, "train/extr_critic_critic_opt_grad_steps": 28035.0, "train/extr_critic_critic_opt_loss": 12391.078581779233, "train/extr_critic_mag": 0.28432295495463955, "train/extr_critic_max": 0.28432295495463955, "train/extr_critic_mean": 0.2355441240774047, "train/extr_critic_min": 0.0024134161010865244, "train/extr_critic_std": 0.05940896005279595, "train/extr_return_normed_mag": 0.21047229464015654, "train/extr_return_normed_max": 0.21047229464015654, "train/extr_return_normed_mean": 0.16126619483674726, "train/extr_return_normed_min": -0.07305787467668133, "train/extr_return_normed_std": 0.06141757000718386, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2845351263400047, "train/extr_return_raw_max": 0.2845351263400047, "train/extr_return_raw_mean": 0.2353290288198379, "train/extr_return_raw_min": 0.0010049564223135671, "train/extr_return_raw_std": 0.06141756991705587, "train/extr_reward_mag": 0.0014353144553399856, "train/extr_reward_max": 0.0014353144553399856, "train/extr_reward_mean": 0.0010878477647389855, "train/extr_reward_min": 9.466563501665669e-06, "train/extr_reward_std": 0.0002395218282124974, "train/image_loss_mean": 5.865100562572479, "train/image_loss_std": 9.984114477711339, "train/model_loss_mean": 13.106048091765373, "train/model_loss_std": 13.470652810988888, "train/model_opt_grad_norm": 57.60432558674966, "train/model_opt_grad_steps": 28007.0, "train/model_opt_loss": 12928.566701581402, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 987.9032258064516, "train/policy_entropy_mag": 2.7638018861893685, "train/policy_entropy_max": 2.7638018861893685, "train/policy_entropy_mean": 2.190086830046869, "train/policy_entropy_min": 0.0806940818626073, "train/policy_entropy_std": 0.5474988779714031, "train/policy_logprob_mag": 7.43810841345018, "train/policy_logprob_max": -0.00964241340425947, "train/policy_logprob_mean": -2.1910262742350177, "train/policy_logprob_min": -7.43810841345018, "train/policy_logprob_std": 1.089744127085132, "train/policy_randomness_mag": 0.975500778805825, "train/policy_randomness_max": 0.975500778805825, "train/policy_randomness_mean": 0.7730045347444473, "train/policy_randomness_min": 0.028481469684911352, "train/policy_randomness_std": 0.19324307852695066, "train/post_ent_mag": 55.97545343829739, "train/post_ent_max": 55.97545343829739, "train/post_ent_mean": 38.88340630069856, "train/post_ent_min": 20.02025991870511, "train/post_ent_std": 6.567452830653036, "train/prior_ent_mag": 64.98428344726562, "train/prior_ent_max": 64.98428344726562, "train/prior_ent_mean": 50.94242646617274, "train/prior_ent_min": 29.456843976051577, "train/prior_ent_std": 5.544244427834788, "train/rep_loss_mean": 12.001069445763864, "train/rep_loss_std": 8.25330493527074, "train/reward_avg": 0.0010614744049587076, "train/reward_loss_mean": 0.040086417609164794, "train/reward_loss_std": 0.01122541168344117, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013100062647173481, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04008641793963409, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010598837266555957, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.5954954812789822, "train_stats/max_log_achievement_collect_drink": 1.2252252252252251, "train_stats/max_log_achievement_collect_sapling": 0.5675675675675675, "train_stats/max_log_achievement_collect_wood": 0.3963963963963964, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.018018018018018018, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.40540540540540543, "train_stats/max_log_achievement_place_table": 0.04504504504504504, "train_stats/max_log_achievement_wake_up": 0.2072072072072072, "train_stats/mean_log_entropy": 2.26894181805688, "eval_stats/sum_log_reward": 0.599999975413084, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.304249523556791e-05, "report/cont_loss_std": 0.001290598651394248, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007236795499920845, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.43156624846597e-07, "report/cont_pred": 0.9941816926002502, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.899833679199219, "report/dyn_loss_std": 7.851436138153076, "report/image_loss_mean": 6.084061622619629, "report/image_loss_std": 11.582599639892578, "report/model_loss_mean": 13.263740539550781, "report/model_loss_std": 15.010007858276367, "report/post_ent_mag": 53.928409576416016, "report/post_ent_max": 53.928409576416016, "report/post_ent_mean": 39.250343322753906, "report/post_ent_min": 18.99929428100586, "report/post_ent_std": 6.289991855621338, "report/prior_ent_mag": 64.99617767333984, "report/prior_ent_max": 64.99617767333984, "report/prior_ent_mean": 51.146873474121094, "report/prior_ent_min": 28.070804595947266, "report/prior_ent_std": 5.436007499694824, "report/rep_loss_mean": 11.899833679199219, "report/rep_loss_std": 7.851436138153076, "report/reward_avg": 0.0010537172202020884, "report/reward_loss_mean": 0.039735741913318634, "report/reward_loss_std": 0.012214471586048603, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012220144271850586, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039735741913318634, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010177934309467673, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.320313109928975e-06, "eval/cont_loss_std": 0.00010044713417300954, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0014080482069402933, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9574522980292386e-07, "eval/cont_pred": 0.9970743060112, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.977977752685547, "eval/dyn_loss_std": 10.55053424835205, "eval/image_loss_mean": 14.087392807006836, "eval/image_loss_std": 24.215167999267578, "eval/model_loss_mean": 25.16707992553711, "eval/model_loss_std": 27.835670471191406, "eval/post_ent_mag": 54.78861999511719, "eval/post_ent_max": 54.78861999511719, "eval/post_ent_mean": 37.049827575683594, "eval/post_ent_min": 20.05278205871582, "eval/post_ent_std": 6.4132232666015625, "eval/prior_ent_mag": 64.99617767333984, "eval/prior_ent_max": 64.99617767333984, "eval/prior_ent_mean": 51.22772979736328, "eval/prior_ent_min": 24.093536376953125, "eval/prior_ent_std": 5.136794567108154, "eval/rep_loss_mean": 17.977977752685547, "eval/rep_loss_std": 10.55053424835205, "eval/reward_avg": 0.0035156249068677425, "eval/reward_loss_mean": 0.2928966283798218, "eval/reward_loss_std": 2.3647749423980713, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012606382369995117, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1746223121881485, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.360103607177734, "eval/reward_pred": 0.0009859164711087942, "eval/reward_rate": 0.005859375, "replay/size": 459593.0, "replay/inserts": 19912.0, "replay/samples": 19904.0, "replay/insert_wait_avg": 1.4255065044373956e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.885356390974529e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90424.0, "eval_replay/inserts": 4232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2633029815154625e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1014.5777170658112, "timer/env.step_count": 2489.0, "timer/env.step_total": 251.1584882736206, "timer/env.step_frac": 0.2475497776552578, "timer/env.step_avg": 0.10090738781583793, "timer/env.step_min": 0.02295541763305664, "timer/env.step_max": 2.2402842044830322, "timer/replay._sample_count": 19904.0, "timer/replay._sample_total": 10.202116250991821, "timer/replay._sample_frac": 0.010055529585743952, "timer/replay._sample_avg": 0.0005125661299734637, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.02282094955444336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3018.0, "timer/agent.policy_total": 49.273059129714966, "timer/agent.policy_frac": 0.04856509097421745, "timer/agent.policy_avg": 0.0163263946751872, "timer/agent.policy_min": 0.009329080581665039, "timer/agent.policy_max": 0.12239933013916016, "timer/dataset_train_count": 1244.0, "timer/dataset_train_total": 0.14516758918762207, "timer/dataset_train_frac": 0.0001430817834314862, "timer/dataset_train_avg": 0.00011669420352702739, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0003676414489746094, "timer/agent.train_count": 1244.0, "timer/agent.train_total": 560.9479610919952, "timer/agent.train_frac": 0.5528881145884746, "timer/agent.train_avg": 0.4509227983054624, "timer/agent.train_min": 0.4371483325958252, "timer/agent.train_max": 1.126077651977539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4854848384857178, "timer/agent.report_frac": 0.00047850926579558076, "timer/agent.report_avg": 0.2427424192428589, "timer/agent.report_min": 0.23833894729614258, "timer/agent.report_max": 0.2471458911895752, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.501394490396491e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 19.625623851153364}
{"step": 460224, "time": 23500.44645357132, "episode/length": 154.0, "episode/score": 0.1658225459177629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1658225459177629}
{"step": 460264, "time": 23503.335608959198, "episode/length": 181.0, "episode/score": 0.1967169082563487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1967169082563487}
{"step": 460320, "time": 23507.767918348312, "episode/length": 162.0, "episode/score": 0.1631950172195502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1631950172195502}
{"step": 460456, "time": 23514.071855306625, "episode/length": 166.0, "episode/score": 0.17523900343076093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17523900343076093}
{"step": 460576, "time": 23520.277203321457, "episode/length": 167.0, "episode/score": 0.18653731046651956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18653731046651956}
{"step": 460776, "time": 23529.052414417267, "episode/length": 196.0, "episode/score": 0.2270801241211302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2270801241211302}
{"step": 461032, "time": 23540.21817970276, "episode/length": 171.0, "episode/score": 0.17618668570139562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17618668570139562}
{"step": 461280, "time": 23551.254045009613, "episode/length": 153.0, "episode/score": 0.14582066782895708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14582066782895708}
{"step": 461504, "time": 23561.175911664963, "episode/length": 154.0, "episode/score": 0.15559790829138365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15559790829138365}
{"step": 461744, "time": 23571.889177322388, "episode/length": 177.0, "episode/score": 0.1863283876555215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1863283876555215}
{"step": 461968, "time": 23581.887143611908, "episode/length": 188.0, "episode/score": 0.2077849783709098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2077849783709098}
{"step": 462176, "time": 23591.183613061905, "episode/length": 174.0, "episode/score": 0.17536432565066207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17536432565066207}
{"step": 462456, "time": 23603.299565315247, "episode/length": 234.0, "episode/score": 0.25823698480780877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25823698480780877}
{"step": 462712, "time": 23614.867837667465, "episode/length": 310.0, "episode/score": 0.35035740989405895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35035740989405895}
{"step": 462784, "time": 23619.418496847153, "episode/length": 218.0, "episode/score": 0.23804918437963352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23804918437963352}
{"step": 462992, "time": 23628.894379377365, "episode/length": 155.0, "episode/score": 0.17286027323279995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17286027323279995}
{"step": 463232, "time": 23639.994195222855, "episode/length": 157.0, "episode/score": 0.17608142563403817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17608142563403817}
{"step": 463312, "time": 23645.108952999115, "episode/length": 225.0, "episode/score": 0.23364020347798942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23364020347798942}
{"step": 463448, "time": 23652.146251916885, "episode/length": 158.0, "episode/score": 0.16798803702840814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16798803702840814}
{"step": 463624, "time": 23660.948633909225, "episode/length": 145.0, "episode/score": 0.15622095340950182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15622095340950182}
{"step": 463952, "time": 23675.646270751953, "episode/length": 154.0, "episode/score": 0.18312499672174454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18312499672174454}
{"step": 464024, "time": 23679.79926085472, "episode/length": 154.0, "episode/score": 0.16220866522053257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16220866522053257}
{"step": 464144, "time": 23686.13841152191, "episode/length": 103.0, "episode/score": 0.11624382244917797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11624382244917797}
{"step": 464168, "time": 23688.442158460617, "episode/length": 146.0, "episode/score": 0.15661514935345622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15661514935345622}
{"step": 464384, "time": 23698.087978839874, "episode/length": 387.0, "episode/score": 0.40074362629638927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40074362629638927}
{"step": 464736, "time": 23712.88023519516, "episode/length": 160.0, "episode/score": 0.17922977354101022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17922977354101022}
{"step": 464952, "time": 23723.160496473312, "episode/length": 214.0, "episode/score": 0.23352792137666256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23352792137666256}
{"step": 465096, "time": 23730.133788585663, "episode/length": 142.0, "episode/score": 0.17249999672640115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17249999672640115}
{"step": 465176, "time": 23734.655141353607, "episode/length": 193.0, "episode/score": 0.21861696381711226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21861696381711226}
{"step": 465480, "time": 23748.44601035118, "episode/length": 163.0, "episode/score": 0.1670330867273151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1670330867273151}
{"step": 465488, "time": 23750.948983430862, "episode/length": 167.0, "episode/score": 0.16376340598253591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16376340598253591}
{"step": 465600, "time": 23757.304508447647, "episode/length": 196.0, "episode/score": 0.23052777353404963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23052777353404963}
{"step": 466056, "time": 23776.270440340042, "episode/length": 137.0, "episode/score": 0.151142246722884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.151142246722884}
{"step": 466080, "time": 23779.037976026535, "episode/length": 211.0, "episode/score": 0.24083899152356025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24083899152356025}
{"step": 466496, "time": 23796.03345823288, "episode/length": 219.0, "episode/score": 0.23655358203177457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23655358203177457}
{"step": 466584, "time": 23800.654211759567, "episode/length": 175.0, "episode/score": 0.20480977880652063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20480977880652063}
{"step": 466608, "time": 23803.284409046173, "episode/length": 140.0, "episode/score": 0.1545309334705962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1545309334705962}
{"step": 466688, "time": 23808.093354463577, "episode/length": 198.0, "episode/score": 0.21708671878332098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21708671878332098}
{"step": 466912, "time": 23817.932551383972, "episode/length": 177.0, "episode/score": 0.18968721472083416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18968721472083416}
{"step": 467408, "time": 23839.50145506859, "episode/length": 165.0, "episode/score": 0.17438020426379808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17438020426379808}
{"step": 467432, "time": 23841.796251296997, "episode/length": 228.0, "episode/score": 0.26584098411876766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26584098411876766}
{"step": 467752, "time": 23855.61869263649, "episode/length": 142.0, "episode/score": 0.16602832748321816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16602832748321816}
{"step": 467800, "time": 23859.532365083694, "episode/length": 138.0, "episode/score": 0.14946863919158204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14946863919158204}
{"step": 467864, "time": 23864.10900235176, "episode/length": 225.0, "episode/score": 0.25872244849961135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25872244849961135}
{"step": 467960, "time": 23869.160974264145, "episode/length": 182.0, "episode/score": 0.19375631009734207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19375631009734207}
{"step": 467968, "time": 23871.157576084137, "episode/length": 131.0, "episode/score": 0.14019599181028752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14019599181028752}
{"step": 468664, "time": 23898.341205835342, "episode/length": 156.0, "episode/score": 0.1862628169319578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1862628169319578}
{"step": 469088, "time": 23915.854216575623, "episode/length": 312.0, "episode/score": 0.33747976599534013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33747976599534013}
{"step": 469144, "time": 23919.258583068848, "episode/length": 146.0, "episode/score": 0.1553140710329899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1553140710329899}
{"step": 469160, "time": 23921.459505796432, "episode/length": 175.0, "episode/score": 0.19607258947598893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19607258947598893}
{"step": 469248, "time": 23926.702840566635, "episode/length": 172.0, "episode/score": 0.1925354457625872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1925354457625872}
{"step": 469296, "time": 23930.041137695312, "episode/length": 166.0, "episode/score": 0.16283909174399014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16283909174399014}
{"step": 469296, "time": 23930.04863834381, "episode/length": 186.0, "episode/score": 0.2041756004891795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2041756004891795}
{"step": 469512, "time": 23941.159967422485, "episode/length": 259.0, "episode/score": 0.27914225941549375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27914225941549375}
{"step": 469896, "time": 23957.091866970062, "episode/length": 153.0, "episode/score": 0.18289880602969788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18289880602969788}
{"step": 470080, "time": 23984.8951151371, "eval_episode/length": 141.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 470080, "time": 23987.137403011322, "eval_episode/length": 154.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 470080, "time": 23989.094749212265, "eval_episode/length": 160.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 470080, "time": 23991.747641563416, "eval_episode/length": 185.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 470080, "time": 23994.384979963303, "eval_episode/length": 208.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 470080, "time": 23996.326716899872, "eval_episode/length": 216.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 470080, "time": 23998.120403528214, "eval_episode/length": 220.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.995475113122172}
{"step": 470080, "time": 23999.96367788315, "eval_episode/length": 226.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 470440, "time": 24013.066542863846, "episode/length": 161.0, "episode/score": 0.1725217421317211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1725217421317211}
{"step": 470504, "time": 24017.10359621048, "episode/length": 75.0, "episode/score": 0.09034722036449239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09034722036449239}
{"step": 470528, "time": 24019.92414712906, "episode/length": 153.0, "episode/score": 0.158333981051328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.158333981051328}
{"step": 470584, "time": 24023.369389295578, "episode/length": 160.0, "episode/score": 0.1666870616709275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1666870616709275}
{"step": 470864, "time": 24035.61732697487, "episode/length": 201.0, "episode/score": 0.18962462160106952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18962462160106952}
{"step": 470928, "time": 24040.11414027214, "episode/length": 229.0, "episode/score": 0.25560168132778927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25560168132778927}
{"step": 471024, "time": 24045.85208582878, "episode/length": 232.0, "episode/score": 0.25598975034608884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25598975034608884}
{"step": 471040, "time": 24048.01222538948, "episode/length": 190.0, "episode/score": 0.20843656389024545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20843656389024545}
{"step": 471840, "time": 24079.61036491394, "episode/length": 174.0, "episode/score": 0.19691166751636047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19691166751636047}
{"step": 471856, "time": 24081.755775928497, "episode/length": 158.0, "episode/score": 0.16999965802551742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16999965802551742}
{"step": 471864, "time": 24083.403702020645, "episode/length": 169.0, "episode/score": 0.17853124291377753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17853124291377753}
{"step": 472152, "time": 24095.945375204086, "episode/length": 152.0, "episode/score": 0.16128473210937955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16128473210937955}
{"step": 472160, "time": 24098.56838107109, "episode/length": 203.0, "episode/score": 0.22900899426167598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22900899426167598}
{"step": 472160, "time": 24098.575650930405, "episode/length": 139.0, "episode/score": 0.1494759125980636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1494759125980636}
{"step": 472264, "time": 24106.638524532318, "episode/length": 154.0, "episode/score": 0.17305005303478538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17305005303478538}
{"step": 472688, "time": 24124.749222517014, "episode/length": 65.0, "episode/score": 0.07607287113432903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07607287113432903}
{"step": 472712, "time": 24127.062155246735, "episode/length": 230.0, "episode/score": 0.25980811683075444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25980811683075444}
{"step": 473072, "time": 24142.546051979065, "episode/length": 153.0, "episode/score": 0.14318783874841756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14318783874841756}
{"step": 473080, "time": 24144.6051197052, "episode/length": 151.0, "episode/score": 0.14259544430024107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14259544430024107}
{"step": 473216, "time": 24152.0001142025, "episode/length": 131.0, "episode/score": 0.14604077063722798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14604077063722798}
{"step": 473672, "time": 24170.381293058395, "episode/length": 56.0, "episode/score": 0.0666071416635532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0666071416635532}
{"step": 473696, "time": 24173.044150352478, "episode/length": 229.0, "episode/score": 0.25305273834419495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25305273834419495}
{"step": 474032, "time": 24187.18812084198, "episode/length": 167.0, "episode/score": 0.1594877315346821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1594877315346821}
{"step": 474144, "time": 24192.934004068375, "episode/length": 248.0, "episode/score": 0.2569961030576451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2569961030576451}
{"step": 474464, "time": 24206.56791782379, "episode/length": 274.0, "episode/score": 0.30194957718003934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30194957718003934}
{"step": 474504, "time": 24209.29571080208, "episode/length": 177.0, "episode/score": 0.20771130567300133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20771130567300133}
{"step": 474912, "time": 24226.41514825821, "episode/length": 151.0, "episode/score": 0.1667208905323605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1667208905323605}
{"step": 475040, "time": 24232.882747650146, "episode/length": 170.0, "episode/score": 0.16527927556671784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16527927556671784}
{"step": 475224, "time": 24243.234030246735, "episode/length": 313.0, "episode/score": 0.3419459771239417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3419459771239417}
{"step": 475464, "time": 24254.41041946411, "episode/length": 164.0, "episode/score": 0.1920427452569129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1920427452569129}
{"step": 475896, "time": 24272.12597680092, "episode/length": 232.0, "episode/score": 0.27359080407541114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27359080407541114}
{"step": 475952, "time": 24276.023919582367, "episode/length": 60.0, "episode/score": 0.06448205782635341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06448205782635341}
{"step": 475968, "time": 24278.21380496025, "episode/length": 182.0, "episode/score": 0.20954342426102812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20954342426102812}
{"step": 476296, "time": 24291.882630109787, "episode/length": 228.0, "episode/score": 0.2532187834203796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2532187834203796}
{"step": 476384, "time": 24296.852442979813, "episode/length": 413.0, "episode/score": 0.4215343370510709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4215343370510709}
{"step": 476392, "time": 24298.48524904251, "episode/length": 168.0, "episode/score": 0.18750725316112948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18750725316112948}
{"step": 476544, "time": 24305.903967380524, "episode/length": 164.0, "episode/score": 0.15290833638982804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15290833638982804}
{"step": 476656, "time": 24311.62495279312, "episode/length": 217.0, "episode/score": 0.22672971330166547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22672971330166547}
{"step": 477120, "time": 24330.50592660904, "episode/length": 152.0, "episode/score": 0.17779739727393462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17779739727393462}
{"step": 477168, "time": 24333.892173051834, "episode/length": 151.0, "episode/score": 0.15004841800782742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15004841800782742}
{"step": 477696, "time": 24355.163296461105, "episode/length": 163.0, "episode/score": 0.17102342269436122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17102342269436122}
{"step": 477832, "time": 24361.63411617279, "episode/length": 179.0, "episode/score": 0.20298599416673824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20298599416673824}
{"step": 477920, "time": 24366.793545484543, "episode/length": 202.0, "episode/score": 0.2200277901984009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2200277901984009}
{"step": 478224, "time": 24379.747208356857, "episode/length": 195.0, "episode/score": 0.1809997965774528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809997965774528}
{"step": 478272, "time": 24382.992707967758, "episode/length": 137.0, "episode/score": 0.15713042581683112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15713042581683112}
{"step": 478416, "time": 24389.851954460144, "episode/length": 305.0, "episode/score": 0.3541128054521323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3541128054521323}
{"step": 478512, "time": 24395.032314777374, "episode/length": 84.0, "episode/score": 0.10416666453238577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10416666453238577}
{"step": 479128, "time": 24419.262843370438, "episode/length": 150.0, "episode/score": 0.16210402421393155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16210402421393155}
{"step": 479176, "time": 24422.53014588356, "episode/length": 184.0, "episode/score": 0.19404787548455715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19404787548455715}
{"step": 479184, "time": 24424.725081682205, "episode/length": 257.0, "episode/score": 0.25144570949169065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25144570949169065}
{"step": 479440, "time": 24435.905369520187, "episode/length": 361.0, "episode/score": 0.3845297700568153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3845297700568153}
{"step": 479568, "time": 24442.840218305588, "episode/length": 161.0, "episode/score": 0.16134628543613871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16134628543613871}
{"step": 479600, "time": 24445.569865703583, "episode/length": 58.0, "episode/score": 0.06379091207736565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06379091207736565}
{"step": 479640, "time": 24448.46673464775, "episode/length": 152.0, "episode/score": 0.14666850886078464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14666850886078464}
{"step": 479768, "time": 24454.821979761124, "episode/length": 156.0, "episode/score": 0.1711386054180366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1711386054180366}
{"step": 480064, "time": 24487.344094753265, "eval_episode/length": 157.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 480064, "time": 24489.488599538803, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 480064, "time": 24491.63429236412, "eval_episode/length": 160.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 480064, "time": 24494.075922489166, "eval_episode/length": 166.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 480064, "time": 24496.099940776825, "eval_episode/length": 168.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 480064, "time": 24500.337249040604, "eval_episode/length": 215.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 480064, "time": 24502.422008514404, "eval_episode/length": 219.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 480064, "time": 24502.429885149002, "eval_episode/length": 219.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 480065, "time": 24503.082166194916, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.31205859375, "train/action_min": 0.0, "train/action_std": 4.906728363037109, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00857351616024971, "train/actor_opt_grad_steps": 29280.0, "train/actor_opt_loss": -15.244576844632626, "train/adv_mag": 0.18750770974159242, "train/adv_max": 0.13169356787204742, "train/adv_mean": -0.00023378889590094332, "train/adv_min": -0.1865455293059349, "train/adv_std": 0.014746007651090623, "train/cont_avg": 0.9946328125, "train/cont_loss_mean": 0.00023275500600857413, "train/cont_loss_std": 0.007081555676199059, "train/cont_neg_acc": 0.9943238105773926, "train/cont_neg_loss": 0.030365944195466, "train/cont_pos_acc": 0.9999685254096985, "train/cont_pos_loss": 7.638522597301289e-05, "train/cont_pred": 0.9946508712768555, "train/cont_rate": 0.9946328125, "train/dyn_loss_mean": 11.969930274963378, "train/dyn_loss_std": 8.287946811676026, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15902978122234346, "train/extr_critic_critic_opt_grad_steps": 29280.0, "train/extr_critic_critic_opt_loss": 12258.3750390625, "train/extr_critic_mag": 0.2836354818344116, "train/extr_critic_max": 0.2836354818344116, "train/extr_critic_mean": 0.23163764441013338, "train/extr_critic_min": 0.002596170425415039, "train/extr_critic_std": 0.05759871436655521, "train/extr_return_normed_mag": 0.20622812628746032, "train/extr_return_normed_max": 0.20622812628746032, "train/extr_return_normed_mean": 0.15501052129268647, "train/extr_return_normed_min": -0.0753909250497818, "train/extr_return_normed_std": 0.05955278031527996, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28262146139144895, "train/extr_return_raw_max": 0.28262146139144895, "train/extr_return_raw_mean": 0.23140385806560515, "train/extr_return_raw_min": 0.0010024099349975587, "train/extr_return_raw_std": 0.059552780762314794, "train/extr_reward_mag": 0.0013650617599487306, "train/extr_reward_max": 0.0013650617599487306, "train/extr_reward_mean": 0.001089944171719253, "train/extr_reward_min": 1.0576248168945312e-05, "train/extr_reward_std": 0.00023878564883489162, "train/image_loss_mean": 6.029952816009521, "train/image_loss_std": 10.4349619140625, "train/model_loss_mean": 13.252192977905274, "train/model_loss_std": 13.917430725097656, "train/model_opt_grad_norm": 58.62040440368652, "train/model_opt_grad_steps": 29250.688, "train/model_opt_loss": 12632.98106640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 945.0, "train/policy_entropy_mag": 2.766092763900757, "train/policy_entropy_max": 2.766092763900757, "train/policy_entropy_mean": 2.198896013259888, "train/policy_entropy_min": 0.0800769819021225, "train/policy_entropy_std": 0.5660320920944214, "train/policy_logprob_mag": 7.438157119750977, "train/policy_logprob_max": -0.009552384681999683, "train/policy_logprob_mean": -2.1991406059265137, "train/policy_logprob_min": -7.438157119750977, "train/policy_logprob_std": 1.0861582984924316, "train/policy_randomness_mag": 0.976309359550476, "train/policy_randomness_max": 0.976309359550476, "train/policy_randomness_mean": 0.7761137971878052, "train/policy_randomness_min": 0.028263660535216333, "train/policy_randomness_std": 0.1997844889163971, "train/post_ent_mag": 56.062876159667965, "train/post_ent_max": 56.062876159667965, "train/post_ent_mean": 39.1224873046875, "train/post_ent_min": 19.95092338562012, "train/post_ent_std": 6.666327617645264, "train/prior_ent_mag": 65.23082836914062, "train/prior_ent_max": 65.23082836914062, "train/prior_ent_mean": 51.13728128051758, "train/prior_ent_min": 29.71798634338379, "train/prior_ent_std": 5.515446689605713, "train/rep_loss_mean": 11.969930274963378, "train/rep_loss_std": 8.287946811676026, "train/reward_avg": 0.0010606182883493602, "train/reward_loss_mean": 0.040049397945404054, "train/reward_loss_std": 0.011242184944450855, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013161382675170898, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040049397945404054, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001060163808055222, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.6181817996230993, "train_stats/max_log_achievement_collect_drink": 0.6909090909090909, "train_stats/max_log_achievement_collect_sapling": 0.43636363636363634, "train_stats/max_log_achievement_collect_wood": 0.35454545454545455, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00909090909090909, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.39090909090909093, "train_stats/max_log_achievement_place_table": 0.045454545454545456, "train_stats/max_log_achievement_wake_up": 0.3, "train_stats/mean_log_entropy": 2.2816655538298867, "eval_stats/sum_log_reward": 0.41249997867271304, "eval_stats/max_log_achievement_collect_drink": 0.3125, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_stone": 0.10526315789473684, "eval_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.3285712106589926e-06, "report/cont_loss_std": 3.417950210859999e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.139510075328872e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8964489047211828e-06, "report/cont_pred": 0.995114803314209, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.108357429504395, "report/dyn_loss_std": 7.814709663391113, "report/image_loss_mean": 4.768767356872559, "report/image_loss_std": 10.082178115844727, "report/model_loss_mean": 12.074722290039062, "report/model_loss_std": 13.497693061828613, "report/post_ent_mag": 53.49253845214844, "report/post_ent_max": 53.49253845214844, "report/post_ent_mean": 38.67979431152344, "report/post_ent_min": 20.3309326171875, "report/post_ent_std": 6.260164737701416, "report/prior_ent_mag": 64.88052368164062, "report/prior_ent_max": 64.88052368164062, "report/prior_ent_mean": 51.30073547363281, "report/prior_ent_min": 30.468488693237305, "report/prior_ent_std": 5.086005687713623, "report/rep_loss_mean": 12.108357429504395, "report/rep_loss_std": 7.814709663391113, "report/reward_avg": 0.0010848131496459246, "report/reward_loss_mean": 0.04093652963638306, "report/reward_loss_std": 0.009843321517109871, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04093652963638306, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010858846362680197, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.5889543394441716e-05, "eval/cont_loss_std": 0.00054065982112661, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0024455382954329252, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.6400721506215632e-05, "eval/cont_pred": 0.9960871338844299, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.392662048339844, "eval/dyn_loss_std": 10.343640327453613, "eval/image_loss_mean": 15.979536056518555, "eval/image_loss_std": 21.42441177368164, "eval/model_loss_mean": 27.229904174804688, "eval/model_loss_std": 25.978166580200195, "eval/post_ent_mag": 53.348419189453125, "eval/post_ent_max": 53.348419189453125, "eval/post_ent_mean": 37.802860260009766, "eval/post_ent_min": 21.110631942749023, "eval/post_ent_std": 6.206305980682373, "eval/prior_ent_mag": 64.88052368164062, "eval/prior_ent_max": 64.88052368164062, "eval/prior_ent_mean": 52.08317565917969, "eval/prior_ent_min": 29.554426193237305, "eval/prior_ent_std": 5.680155277252197, "eval/rep_loss_mean": 17.392662048339844, "eval/rep_loss_std": 10.343640327453613, "eval/reward_avg": 0.005664062686264515, "eval/reward_loss_mean": 0.8147470951080322, "eval/reward_loss_std": 3.8595333099365234, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012704133987426758, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5843477845191956, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.24509048461914, "eval/reward_pred": 0.0010355053236708045, "eval/reward_rate": 0.01171875, "replay/size": 479561.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.4010434731459006e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.747865183231158e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94000.0, "eval_replay/inserts": 3576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2435635730990895e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1007.6294150352478, "timer/env.step_count": 2496.0, "timer/env.step_total": 251.72223663330078, "timer/env.step_frac": 0.24981628451616342, "timer/env.step_avg": 0.10085025506141858, "timer/env.step_min": 0.023146867752075195, "timer/env.step_max": 4.214314222335815, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 10.14424991607666, "timer/replay._sample_frac": 0.0100674412286007, "timer/replay._sample_avg": 0.0005080253363419801, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.022807836532592773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2943.0, "timer/agent.policy_total": 47.99340200424194, "timer/agent.policy_frac": 0.04763001286793825, "timer/agent.policy_avg": 0.016307645940958865, "timer/agent.policy_min": 0.009737491607666016, "timer/agent.policy_max": 0.09578657150268555, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14640545845031738, "timer/dataset_train_frac": 0.00014529692788414278, "timer/dataset_train_avg": 0.00011731206606595944, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.000888824462890625, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 560.8165590763092, "timer/agent.train_frac": 0.5565702536152056, "timer/agent.train_avg": 0.44937224284960675, "timer/agent.train_min": 0.43708372116088867, "timer/agent.train_max": 1.1093635559082031, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48026037216186523, "timer/agent.report_frac": 0.00047662400977552374, "timer/agent.report_avg": 0.24013018608093262, "timer/agent.report_min": 0.23012590408325195, "timer/agent.report_max": 0.2501344680786133, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.572861699663321e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 19.816400663587878}
{"step": 480200, "time": 24508.17330956459, "episode/length": 126.0, "episode/score": 0.15136551344903637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15136551344903637}
{"step": 480472, "time": 24519.95140337944, "episode/length": 161.0, "episode/score": 0.17497865101859134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17497865101859134}
{"step": 480824, "time": 24534.659656763077, "episode/length": 172.0, "episode/score": 0.17823889015608074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17823889015608074}
{"step": 480928, "time": 24540.463403701782, "episode/length": 160.0, "episode/score": 0.19237499631708488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19237499631708488}
{"step": 481040, "time": 24546.2559530735, "episode/length": 158.0, "episode/score": 0.17166949910415497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17166949910415497}
{"step": 481328, "time": 24558.802179574966, "episode/length": 387.0, "episode/score": 0.41533788523156545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41533788523156545}
{"step": 481408, "time": 24563.447511672974, "episode/length": 150.0, "episode/score": 0.16119826712110807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16119826712110807}
{"step": 482016, "time": 24587.805033683777, "episode/length": 135.0, "episode/score": 0.13304774728976554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13304774728976554}
{"step": 482016, "time": 24587.811812639236, "episode/length": 148.0, "episode/score": 0.16289075163967937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16289075163967937}
{"step": 482056, "time": 24592.49433207512, "episode/length": 197.0, "episode/score": 0.21444535072259896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21444535072259896}
{"step": 482144, "time": 24597.529027223587, "episode/length": 317.0, "episode/score": 0.3648728790212772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3648728790212772}
{"step": 482208, "time": 24601.47964477539, "episode/length": 145.0, "episode/score": 0.16247733695354327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16247733695354327}
{"step": 482696, "time": 24621.1754488945, "episode/length": 170.0, "episode/score": 0.17558741545735757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17558741545735757}
{"step": 482720, "time": 24624.022608041763, "episode/length": 71.0, "episode/score": 0.07314190213810434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07314190213810434}
{"step": 482760, "time": 24626.81341099739, "episode/length": 168.0, "episode/score": 0.18292625327558198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18292625327558198}
{"step": 482792, "time": 24629.717063188553, "episode/length": 402.0, "episode/score": 0.43888983059923703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43888983059923703}
{"step": 483408, "time": 24656.17589187622, "episode/length": 149.0, "episode/score": 0.1508451179624899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1508451179624899}
{"step": 483528, "time": 24662.019249916077, "episode/length": 188.0, "episode/score": 0.20772281253903202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20772281253903202}
{"step": 483560, "time": 24664.80716085434, "episode/length": 187.0, "episode/score": 0.18340569994279576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18340569994279576}
{"step": 483848, "time": 24677.32958984375, "episode/length": 143.0, "episode/score": 0.15433746360531586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15433746360531586}
{"step": 483976, "time": 24683.7023768425, "episode/length": 156.0, "episode/score": 0.17259701149441753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17259701149441753}
{"step": 484496, "time": 24706.074526309967, "episode/length": 309.0, "episode/score": 0.32824196957426466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32824196957426466}
{"step": 484616, "time": 24711.880949020386, "episode/length": 227.0, "episode/score": 0.23424335868571688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23424335868571688}
{"step": 484656, "time": 24715.249669075012, "episode/length": 155.0, "episode/score": 0.15577742779964865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15577742779964865}
{"step": 485000, "time": 24730.059455633163, "episode/length": 279.0, "episode/score": 0.3188302230125828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3188302230125828}
{"step": 485096, "time": 24735.390595674515, "episode/length": 195.0, "episode/score": 0.1899221899548138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1899221899548138}
{"step": 485320, "time": 24745.556480884552, "episode/length": 183.0, "episode/score": 0.18671271053017335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18671271053017335}
{"step": 485632, "time": 24759.115474700928, "episode/length": 206.0, "episode/score": 0.21141840168388626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21141840168388626}
{"step": 485960, "time": 24772.862254858017, "episode/length": 162.0, "episode/score": 0.17016272043861136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17016272043861136}
{"step": 485968, "time": 24774.96385216713, "episode/length": 183.0, "episode/score": 0.18921173471585462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18921173471585462}
{"step": 485976, "time": 24776.623596668243, "episode/length": 301.0, "episode/score": 0.325249791650549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.325249791650549}
{"step": 486096, "time": 24783.611837148666, "episode/length": 184.0, "episode/score": 0.17394122336054352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17394122336054352}
{"step": 486440, "time": 24797.968707084656, "episode/length": 179.0, "episode/score": 0.1985354849371106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1985354849371106}
{"step": 486968, "time": 24819.593884706497, "episode/length": 166.0, "episode/score": 0.1569390610507071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1569390610507071}
{"step": 487040, "time": 24824.262169599533, "episode/length": 242.0, "episode/score": 0.2528047726109435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2528047726109435}
{"step": 487152, "time": 24829.905317544937, "episode/length": 146.0, "episode/score": 0.16375785984087088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16375785984087088}
{"step": 487152, "time": 24829.91276526451, "episode/length": 228.0, "episode/score": 0.2607251265476407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2607251265476407}
{"step": 487344, "time": 24840.386037826538, "episode/length": 171.0, "episode/score": 0.17024853274574525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17024853274574525}
{"step": 487464, "time": 24846.587202310562, "episode/length": 170.0, "episode/score": 0.16314976036824191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16314976036824191}
{"step": 487592, "time": 24852.895961284637, "episode/length": 203.0, "episode/score": 0.20795251202048348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20795251202048348}
{"step": 487768, "time": 24861.194076776505, "episode/length": 165.0, "episode/score": 0.1787834777912849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1787834777912849}
{"step": 488328, "time": 24883.78242611885, "episode/length": 169.0, "episode/score": 0.1859338522044709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1859338522044709}
{"step": 488376, "time": 24887.833220005035, "episode/length": 152.0, "episode/score": 0.15251297891882132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15251297891882132}
{"step": 488592, "time": 24897.913766860962, "episode/length": 155.0, "episode/score": 0.1595073829885223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1595073829885223}
{"step": 488784, "time": 24906.63734817505, "episode/length": 217.0, "episode/score": 0.23857883374148514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23857883374148514}
{"step": 488832, "time": 24910.017647743225, "episode/length": 62.0, "episode/score": 0.07624268840299919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07624268840299919}
{"step": 488856, "time": 24912.24906182289, "episode/length": 212.0, "episode/score": 0.22916530560178217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22916530560178217}
{"step": 489112, "time": 24923.471849918365, "episode/length": 189.0, "episode/score": 0.2077068207836419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2077068207836419}
{"step": 489136, "time": 24926.248224258423, "episode/length": 94.0, "episode/score": 0.09381430151552195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09381430151552195}
{"step": 489568, "time": 24944.21130847931, "episode/length": 224.0, "episode/score": 0.23648269736077054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23648269736077054}
{"step": 489800, "time": 24954.26188659668, "episode/length": 150.0, "episode/score": 0.17215209180722013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17215209180722013}
{"step": 489944, "time": 24961.388359069824, "episode/length": 309.0, "episode/score": 0.35101251625383156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35101251625383156}
{"step": 490016, "time": 24965.885786771774, "episode/length": 153.0, "episode/score": 0.1765277746890206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1765277746890206}
{"step": 490048, "time": 24983.381546735764, "eval_episode/length": 39.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.875}
{"step": 490048, "time": 24990.00391292572, "eval_episode/length": 158.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 490048, "time": 24991.651114940643, "eval_episode/length": 160.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 490048, "time": 24993.67613530159, "eval_episode/length": 171.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 490048, "time": 24995.493376255035, "eval_episode/length": 178.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.994413407821229}
{"step": 490048, "time": 24997.148531913757, "eval_episode/length": 180.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.994475138121547}
{"step": 490048, "time": 25000.211491584778, "eval_episode/length": 217.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 490048, "time": 25003.30129313469, "eval_episode/length": 212.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 490192, "time": 25008.84002685547, "episode/length": 166.0, "episode/score": 0.1588616803746845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1588616803746845}
{"step": 490576, "time": 25024.82961654663, "episode/length": 217.0, "episode/score": 0.2265218222164549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2265218222164549}
{"step": 490584, "time": 25026.453405857086, "episode/length": 180.0, "episode/score": 0.19353668560142978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19353668560142978}
{"step": 490752, "time": 25034.689185857773, "episode/length": 147.0, "episode/score": 0.16401045915699797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16401045915699797}
{"step": 490880, "time": 25041.043242931366, "episode/length": 220.0, "episode/score": 0.260124995111255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.260124995111255}
{"step": 491392, "time": 25061.77706861496, "episode/length": 149.0, "episode/score": 0.1423475931333087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1423475931333087}
{"step": 491488, "time": 25067.67407488823, "episode/length": 210.0, "episode/score": 0.23134630182903493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23134630182903493}
{"step": 491672, "time": 25077.463577270508, "episode/length": 215.0, "episode/score": 0.22837152831925778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22837152831925778}
{"step": 491864, "time": 25086.371453762054, "episode/length": 160.0, "episode/score": 0.17386333842296153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17386333842296153}
{"step": 491984, "time": 25093.242785692215, "episode/length": 174.0, "episode/score": 0.1785337993023859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785337993023859}
{"step": 492056, "time": 25098.0370285511, "episode/length": 162.0, "episode/score": 0.15422099292482017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15422099292482017}
{"step": 492304, "time": 25109.558824539185, "episode/length": 177.0, "episode/score": 0.19582593178347452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19582593178347452}
{"step": 492664, "time": 25124.465230703354, "episode/length": 146.0, "episode/score": 0.17100529862727853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17100529862727853}
{"step": 492912, "time": 25135.492460489273, "episode/length": 189.0, "episode/score": 0.1748123989400483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748123989400483}
{"step": 492952, "time": 25138.308990240097, "episode/length": 366.0, "episode/score": 0.3513613682389405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3513613682389405}
{"step": 493144, "time": 25146.977550268173, "episode/length": 135.0, "episode/score": 0.13530919225195248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13530919225195248}
{"step": 493176, "time": 25149.698717832565, "episode/length": 163.0, "episode/score": 0.17238139487926674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17238139487926674}
{"step": 493480, "time": 25164.45043540001, "episode/length": 186.0, "episode/score": 0.195486033011548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.195486033011548}
{"step": 493760, "time": 25176.7853038311, "episode/length": 181.0, "episode/score": 0.19138681143158465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19138681143158465}
{"step": 493880, "time": 25182.545382261276, "episode/length": 151.0, "episode/score": 0.15235417582516675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15235417582516675}
{"step": 493888, "time": 25184.6599047184, "episode/length": 276.0, "episode/score": 0.290372287898208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.290372287898208}
{"step": 494280, "time": 25200.53339266777, "episode/length": 170.0, "episode/score": 0.18872122722677886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18872122722677886}
{"step": 494352, "time": 25205.04737138748, "episode/length": 150.0, "episode/score": 0.1515206992335152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1515206992335152}
{"step": 494408, "time": 25208.404586315155, "episode/length": 181.0, "episode/score": 0.20302855152112897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20302855152112897}
{"step": 494728, "time": 25221.846246242523, "episode/length": 155.0, "episode/score": 0.17762562807911308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17762562807911308}
{"step": 495032, "time": 25234.93069911003, "episode/length": 158.0, "episode/score": 0.16362643345928518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16362643345928518}
{"step": 495176, "time": 25242.54629445076, "episode/length": 161.0, "episode/score": 0.17454523127889843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17454523127889843}
{"step": 495200, "time": 25245.84238100052, "episode/length": 252.0, "episode/score": 0.27887855759763625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27887855759763625}
{"step": 495312, "time": 25252.12166452408, "episode/length": 177.0, "episode/score": 0.17691355067290715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17691355067290715}
{"step": 495728, "time": 25269.21821832657, "episode/length": 164.0, "episode/score": 0.1536391035260749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1536391035260749}
{"step": 495800, "time": 25273.3008518219, "episode/length": 180.0, "episode/score": 0.1980394218080619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980394218080619}
{"step": 495904, "time": 25279.268363952637, "episode/length": 202.0, "episode/score": 0.23290017911494942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23290017911494942}
{"step": 495984, "time": 25284.391640901566, "episode/length": 156.0, "episode/score": 0.16298846414792934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16298846414792934}
{"step": 496208, "time": 25294.836622476578, "episode/length": 146.0, "episode/score": 0.1563857321452815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1563857321452815}
{"step": 496296, "time": 25299.457649946213, "episode/length": 136.0, "episode/score": 0.1637499969219789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637499969219789}
{"step": 496640, "time": 25314.22134065628, "episode/length": 182.0, "episode/score": 0.1888182387847337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1888182387847337}
{"step": 496824, "time": 25322.455893993378, "episode/length": 114.0, "episode/score": 0.11956399943665019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11956399943665019}
{"step": 496880, "time": 25326.36164522171, "episode/length": 195.0, "episode/score": 0.20649881255849323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20649881255849323}
{"step": 496880, "time": 25326.369216442108, "episode/length": 134.0, "episode/score": 0.15620833064895123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15620833064895123}
{"step": 497200, "time": 25341.576031684875, "episode/length": 183.0, "episode/score": 0.20700482367283257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20700482367283257}
{"step": 497584, "time": 25357.631254434586, "episode/length": 160.0, "episode/score": 0.1666584168215195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1666584168215195}
{"step": 498088, "time": 25378.52013540268, "episode/length": 157.0, "episode/score": 0.18805998815514613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18805998815514613}
{"step": 498152, "time": 25382.516633749008, "episode/length": 188.0, "episode/score": 0.2088307903140958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2088307903140958}
{"step": 498184, "time": 25385.261873722076, "episode/length": 274.0, "episode/score": 0.3272326012775011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3272326012775011}
{"step": 498328, "time": 25392.20164871216, "episode/length": 180.0, "episode/score": 0.18561653795586608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18561653795586608}
{"step": 498344, "time": 25394.472202777863, "episode/length": 182.0, "episode/score": 0.19667131431924645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19667131431924645}
{"step": 498528, "time": 25403.05223441124, "episode/length": 165.0, "episode/score": 0.18671627771254862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18671627771254862}
{"step": 499104, "time": 25426.132216215134, "episode/length": 189.0, "episode/score": 0.2153913201746036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2153913201746036}
{"step": 499216, "time": 25431.93167614937, "episode/length": 140.0, "episode/score": 0.15567531020133174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15567531020133174}
{"step": 499336, "time": 25437.709399461746, "episode/length": 143.0, "episode/score": 0.16772644614684395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16772644614684395}
{"step": 499520, "time": 25446.449243307114, "episode/length": 146.0, "episode/score": 0.16590795739466557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16590795739466557}
{"step": 499560, "time": 25449.296229362488, "episode/length": 128.0, "episode/score": 0.15230278738818015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15230278738818015}
{"step": 499656, "time": 25454.502334833145, "episode/length": 430.0, "episode/score": 0.4334165706495696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4334165706495696}
{"step": 499712, "time": 25458.66834115982, "episode/length": 172.0, "episode/score": 0.185286461675787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185286461675787}
{"step": 500032, "time": 25491.50305747986, "eval_episode/length": 125.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9603174603174603}
{"step": 500032, "time": 25493.82426571846, "eval_episode/length": 143.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 500032, "time": 25495.617190361023, "eval_episode/length": 147.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 500032, "time": 25497.38136601448, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 500032, "time": 25499.12087535858, "eval_episode/length": 156.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 500032, "time": 25500.8967564106, "eval_episode/length": 158.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 500032, "time": 25502.920974731445, "eval_episode/length": 166.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 500032, "time": 25506.052239894867, "eval_episode/length": 56.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9122807017543859}
{"step": 500033, "time": 25506.660663366318, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.36410400390625, "train/action_min": 0.0, "train/action_std": 4.826607246398925, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007659613385796547, "train/actor_opt_grad_steps": 30530.0, "train/actor_opt_loss": -12.194133068799973, "train/adv_mag": 0.1753297317624092, "train/adv_max": 0.12154637014865875, "train/adv_mean": -9.538789517046098e-05, "train/adv_min": -0.17423266333341597, "train/adv_std": 0.013275125436484814, "train/cont_avg": 0.9946015625, "train/cont_loss_mean": 0.00026725287302849666, "train/cont_loss_std": 0.007860125340117975, "train/cont_neg_acc": 0.9875904779434204, "train/cont_neg_loss": 0.04004511085091508, "train/cont_pos_acc": 0.9999685235023499, "train/cont_pos_loss": 0.00010427169603394759, "train/cont_pred": 0.9946157441139222, "train/cont_rate": 0.9946015625, "train/dyn_loss_mean": 11.877411529541016, "train/dyn_loss_std": 8.2051169090271, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13986283272504807, "train/extr_critic_critic_opt_grad_steps": 30530.0, "train/extr_critic_critic_opt_loss": 12206.675734375, "train/extr_critic_mag": 0.27961767292022705, "train/extr_critic_max": 0.27961767292022705, "train/extr_critic_mean": 0.2287145105600357, "train/extr_critic_min": 0.0025238380432128908, "train/extr_critic_std": 0.056491059586405754, "train/extr_return_normed_mag": 0.1999159642457962, "train/extr_return_normed_max": 0.1999159642457962, "train/extr_return_normed_mean": 0.14999992120265962, "train/extr_return_normed_min": -0.07762928795814514, "train/extr_return_normed_std": 0.05807153269648552, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2785352065563202, "train/extr_return_raw_max": 0.2785352065563202, "train/extr_return_raw_mean": 0.22861916756629944, "train/extr_return_raw_min": 0.0009899539947509765, "train/extr_return_raw_std": 0.05807153308391571, "train/extr_reward_mag": 0.0013628273010253906, "train/extr_reward_max": 0.0013628273010253906, "train/extr_reward_mean": 0.0010815142309293152, "train/extr_reward_min": 1.0038375854492187e-05, "train/extr_reward_std": 0.00024205997318495066, "train/image_loss_mean": 5.746018669128418, "train/image_loss_std": 10.096796016693116, "train/model_loss_mean": 12.912692451477051, "train/model_loss_std": 13.5340498046875, "train/model_opt_grad_norm": 60.66476893615722, "train/model_opt_grad_steps": 30500.0, "train/model_opt_loss": 14384.73869921875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1115.0, "train/policy_entropy_mag": 2.7658743686676024, "train/policy_entropy_max": 2.7658743686676024, "train/policy_entropy_mean": 2.1986008281707763, "train/policy_entropy_min": 0.08011602604389191, "train/policy_entropy_std": 0.572283138513565, "train/policy_logprob_mag": 7.438190971374512, "train/policy_logprob_max": -0.009561972625553607, "train/policy_logprob_mean": -2.198695108413696, "train/policy_logprob_min": -7.438190971374512, "train/policy_logprob_std": 1.0861239457130432, "train/policy_randomness_mag": 0.9762322726249695, "train/policy_randomness_max": 0.9762322726249695, "train/policy_randomness_mean": 0.7760096039772034, "train/policy_randomness_min": 0.028277441427111624, "train/policy_randomness_std": 0.20199083471298218, "train/post_ent_mag": 56.39319360351563, "train/post_ent_max": 56.39319360351563, "train/post_ent_mean": 39.182581298828126, "train/post_ent_min": 19.981805046081544, "train/post_ent_std": 6.569073539733886, "train/prior_ent_mag": 65.28904760742188, "train/prior_ent_max": 65.28904760742188, "train/prior_ent_mean": 51.10111709594727, "train/prior_ent_min": 29.753665451049805, "train/prior_ent_std": 5.478166252136231, "train/rep_loss_mean": 11.877411529541016, "train/rep_loss_std": 8.2051169090271, "train/reward_avg": 0.0010578868556767702, "train/reward_loss_mean": 0.03995959627628327, "train/reward_loss_std": 0.01135798942297697, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013155584335327148, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03995959624648094, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010577532034367323, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.5579439075750725, "train_stats/max_log_achievement_collect_drink": 0.9252336448598131, "train_stats/max_log_achievement_collect_sapling": 0.6542056074766355, "train_stats/max_log_achievement_collect_stone": 0.009345794392523364, "train_stats/max_log_achievement_collect_wood": 0.411214953271028, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_sword": 0.009345794392523364, "train_stats/max_log_achievement_place_plant": 0.45794392523364486, "train_stats/max_log_achievement_place_table": 0.056074766355140186, "train_stats/max_log_achievement_wake_up": 0.17757009345794392, "train_stats/mean_log_entropy": 2.2754455815965886, "train_stats/max_log_achievement_collect_coal": 0.014492753623188406, "eval_stats/sum_log_reward": 0.03749998938292265, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.4375, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00043448014184832573, "report/cont_loss_std": 0.013258903287351131, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0015786562580615282, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00043111821287311614, "report/cont_pred": 0.9967218637466431, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.385875701904297, "report/dyn_loss_std": 7.85521125793457, "report/image_loss_mean": 5.017448425292969, "report/image_loss_std": 8.323747634887695, "report/model_loss_mean": 11.287923812866211, "report/model_loss_std": 11.914920806884766, "report/post_ent_mag": 59.534427642822266, "report/post_ent_max": 59.534427642822266, "report/post_ent_mean": 40.58684539794922, "report/post_ent_min": 19.531343460083008, "report/post_ent_std": 6.919992923736572, "report/prior_ent_mag": 65.18853759765625, "report/prior_ent_max": 65.18853759765625, "report/prior_ent_mean": 51.37303924560547, "report/prior_ent_min": 26.729633331298828, "report/prior_ent_std": 6.085439205169678, "report/rep_loss_mean": 10.385875701904297, "report/rep_loss_std": 7.85521125793457, "report/reward_avg": 0.0010161269456148148, "report/reward_loss_mean": 0.038515716791152954, "report/reward_loss_std": 0.012609699741005898, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.038515716791152954, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001012936350889504, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00011772157449740916, "eval/cont_loss_std": 0.003081392962485552, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0018978051375597715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000107229920104146, "eval/cont_pred": 0.9940497279167175, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.955318450927734, "eval/dyn_loss_std": 10.669435501098633, "eval/image_loss_mean": 18.349546432495117, "eval/image_loss_std": 31.731224060058594, "eval/model_loss_mean": 29.847610473632812, "eval/model_loss_std": 36.297637939453125, "eval/post_ent_mag": 57.888484954833984, "eval/post_ent_max": 57.888484954833984, "eval/post_ent_mean": 37.85584259033203, "eval/post_ent_min": 20.920915603637695, "eval/post_ent_std": 6.8797607421875, "eval/prior_ent_mag": 65.18853759765625, "eval/prior_ent_max": 65.18853759765625, "eval/prior_ent_mean": 52.66499710083008, "eval/prior_ent_min": 30.139739990234375, "eval/prior_ent_std": 4.799821853637695, "eval/rep_loss_mean": 17.955318450927734, "eval/rep_loss_std": 10.669435501098633, "eval/reward_avg": -0.0010742188896983862, "eval/reward_loss_mean": 0.724754810333252, "eval/reward_loss_std": 3.6927857398986816, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6276785731315613, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.508886337280273, "eval/reward_pred": 0.0010111336596310139, "eval/reward_rate": 0.0048828125, "replay/size": 499529.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.4006375120236323e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.574257103296427e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97632.0, "eval_replay/inserts": 3632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2023333410859633e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1003.5884802341461, "timer/env.step_count": 2496.0, "timer/env.step_total": 242.78813314437866, "timer/env.step_frac": 0.2419200079775069, "timer/env.step_avg": 0.09727088667643376, "timer/env.step_min": 0.02322554588317871, "timer/env.step_max": 3.4173927307128906, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 10.0127592086792, "timer/replay._sample_frac": 0.009976957095345627, "timer/replay._sample_avg": 0.0005014402648577323, "timer/replay._sample_min": 0.0003993511199951172, "timer/replay._sample_max": 0.011148452758789062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2950.0, "timer/agent.policy_total": 47.55930685997009, "timer/agent.policy_frac": 0.047389251467767034, "timer/agent.policy_avg": 0.016121798935583083, "timer/agent.policy_min": 0.009560823440551758, "timer/agent.policy_max": 0.1040034294128418, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.1453242301940918, "timer/dataset_train_frac": 0.0001448046017429239, "timer/dataset_train_avg": 0.0001164456972709069, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.001081228256225586, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 566.4890594482422, "timer/agent.train_frac": 0.5644634933594248, "timer/agent.train_avg": 0.4539175155835274, "timer/agent.train_min": 0.4399571418762207, "timer/agent.train_max": 1.9212017059326172, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47930169105529785, "timer/agent.report_frac": 0.0004775878764007659, "timer/agent.report_avg": 0.23965084552764893, "timer/agent.report_min": 0.23405838012695312, "timer/agent.report_max": 0.24524331092834473, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2784118753873453e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 19.896346811837883}
{"step": 500432, "time": 25521.87545132637, "episode/length": 284.0, "episode/score": 0.30311792560314643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30311792560314643}
{"step": 500544, "time": 25527.642296552658, "episode/length": 165.0, "episode/score": 0.19460118679853622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19460118679853622}
{"step": 500736, "time": 25536.391030550003, "episode/length": 174.0, "episode/score": 0.19245237795985304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19245237795985304}
{"step": 500768, "time": 25539.197489976883, "episode/length": 207.0, "episode/score": 0.23382920860603917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23382920860603917}
{"step": 500816, "time": 25542.46269416809, "episode/length": 137.0, "episode/score": 0.1603055527084507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1603055527084507}
{"step": 500872, "time": 25545.987551927567, "episode/length": 151.0, "episode/score": 0.1705524999924819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1705524999924819}
{"step": 501456, "time": 25569.574422359467, "episode/length": 241.0, "episode/score": 0.26753656344953924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26753656344953924}
{"step": 501816, "time": 25584.662328720093, "episode/length": 281.0, "episode/score": 0.30125716422116966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30125716422116966}
{"step": 501872, "time": 25588.920744895935, "episode/length": 179.0, "episode/score": 0.20452003988975775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20452003988975775}
{"step": 502064, "time": 25597.707230329514, "episode/length": 189.0, "episode/score": 0.19928806370080565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19928806370080565}
{"step": 502112, "time": 25601.12573480606, "episode/length": 167.0, "episode/score": 0.1913084903571871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1913084903571871}
{"step": 502200, "time": 25605.950794696808, "episode/length": 182.0, "episode/score": 0.2156781873673026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2156781873673026}
{"step": 502224, "time": 25608.577736139297, "episode/length": 175.0, "episode/score": 0.1998547722105286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1998547722105286}
{"step": 502440, "time": 25617.904338359833, "episode/length": 195.0, "episode/score": 0.23106134507179377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23106134507179377}
{"step": 502896, "time": 25636.554001808167, "episode/length": 179.0, "episode/score": 0.18987256706532207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18987256706532207}
{"step": 503000, "time": 25641.686461687088, "episode/length": 140.0, "episode/score": 0.1468142970734334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1468142970734334}
{"step": 503240, "time": 25652.480680942535, "episode/length": 146.0, "episode/score": 0.16928471940627787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16928471940627787}
{"step": 503376, "time": 25659.751176595688, "episode/length": 194.0, "episode/score": 0.20976215749396943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20976215749396943}
{"step": 503496, "time": 25665.676460027695, "episode/length": 172.0, "episode/score": 0.18716565615977743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18716565615977743}
{"step": 503512, "time": 25667.9068338871, "episode/length": 163.0, "episode/score": 0.1733692901361792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733692901361792}
{"step": 503784, "time": 25679.6177213192, "episode/length": 194.0, "episode/score": 0.21728602277835307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21728602277835307}
{"step": 503856, "time": 25684.035710811615, "episode/length": 176.0, "episode/score": 0.18969860799734306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18969860799734306}
{"step": 504144, "time": 25696.356158018112, "episode/length": 155.0, "episode/score": 0.18502550676748797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18502550676748797}
{"step": 504752, "time": 25720.623624801636, "episode/length": 218.0, "episode/score": 0.22373955044349714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22373955044349714}
{"step": 504792, "time": 25723.410800457, "episode/length": 193.0, "episode/score": 0.21855151616910007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21855151616910007}
{"step": 505008, "time": 25733.308811187744, "episode/length": 188.0, "episode/score": 0.20867624327911471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20867624327911471}
{"step": 505088, "time": 25737.795689821243, "episode/length": 162.0, "episode/score": 0.18470714541217603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18470714541217603}
{"step": 505288, "time": 25746.479665756226, "episode/length": 178.0, "episode/score": 0.20006427994303522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20006427994303522}
{"step": 505312, "time": 25749.20578145981, "episode/length": 145.0, "episode/score": 0.15009421522699995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15009421522699995}
{"step": 505400, "time": 25753.750883817673, "episode/length": 235.0, "episode/score": 0.2506451520439441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2506451520439441}
{"step": 505888, "time": 25773.770735263824, "episode/length": 141.0, "episode/score": 0.1532514585142053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1532514585142053}
{"step": 506200, "time": 25786.80248761177, "episode/length": 148.0, "episode/score": 0.14399765524285613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14399765524285613}
{"step": 506272, "time": 25791.32247185707, "episode/length": 147.0, "episode/score": 0.15725671156360477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15725671156360477}
{"step": 506352, "time": 25795.893102645874, "episode/length": 194.0, "episode/score": 0.20593521143200633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20593521143200633}
{"step": 506376, "time": 25798.555635929108, "episode/length": 374.0, "episode/score": 0.39753591018416046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39753591018416046}
{"step": 506624, "time": 25810.220674037933, "episode/length": 152.0, "episode/score": 0.17190620086785202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17190620086785202}
{"step": 506720, "time": 25815.49780511856, "episode/length": 178.0, "episode/score": 0.1747587476766057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1747587476766057}
{"step": 506760, "time": 25818.31755232811, "episode/length": 47.0, "episode/score": 0.05146044051616627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05146044051616627}
{"step": 506968, "time": 25827.61987042427, "episode/length": 206.0, "episode/score": 0.22169449000648456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22169449000648456}
{"step": 507056, "time": 25832.751391887665, "episode/length": 145.0, "episode/score": 0.1564514989777308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1564514989777308}
{"step": 507104, "time": 25836.143252134323, "episode/length": 93.0, "episode/score": 0.10224685280991253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10224685280991253}
{"step": 507472, "time": 25851.51593875885, "episode/length": 149.0, "episode/score": 0.14813790136213356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14813790136213356}
{"step": 508080, "time": 25877.14156627655, "episode/length": 181.0, "episode/score": 0.18531384449215693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18531384449215693}
{"step": 508160, "time": 25881.783930063248, "episode/length": 174.0, "episode/score": 0.19407929540466284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19407929540466284}
{"step": 508400, "time": 25892.504428625107, "episode/length": 209.0, "episode/score": 0.21983719524178014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21983719524178014}
{"step": 508408, "time": 25894.264025211334, "episode/length": 162.0, "episode/score": 0.17304325582608726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17304325582608726}
{"step": 508432, "time": 25896.9246301651, "episode/length": 171.0, "episode/score": 0.1809801510453326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809801510453326}
{"step": 508472, "time": 25899.84584069252, "episode/length": 283.0, "episode/score": 0.31979717783178785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31979717783178785}
{"step": 508736, "time": 25911.524559020996, "episode/length": 220.0, "episode/score": 0.21567210012017313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21567210012017313}
{"step": 509016, "time": 25923.233573913574, "episode/length": 67.0, "episode/score": 0.07153950451174751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07153950451174751}
{"step": 509288, "time": 25934.990496873856, "episode/length": 226.0, "episode/score": 0.26046896732259484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26046896732259484}
{"step": 509296, "time": 25936.998220920563, "episode/length": 151.0, "episode/score": 0.1577410692407284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577410692407284}
{"step": 509368, "time": 25940.980105876923, "episode/length": 150.0, "episode/score": 0.14478745087399147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14478745087399147}
{"step": 509648, "time": 25953.140180826187, "episode/length": 154.0, "episode/score": 0.17008296609856188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17008296609856188}
{"step": 509680, "time": 25955.991240024567, "episode/length": 159.0, "episode/score": 0.17565631551406113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17565631551406113}
{"step": 509936, "time": 25967.641097545624, "episode/length": 149.0, "episode/score": 0.138683700501133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.138683700501133}
{"step": 510016, "time": 25989.427451610565, "eval_episode/length": 61.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 510016, "time": 25995.187618255615, "eval_episode/length": 164.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 510016, "time": 25997.00459766388, "eval_episode/length": 168.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 510016, "time": 25998.984244823456, "eval_episode/length": 178.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.994413407821229}
{"step": 510016, "time": 26001.149316072464, "eval_episode/length": 191.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 510016, "time": 26002.84335398674, "eval_episode/length": 193.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 510016, "time": 26004.802544116974, "eval_episode/length": 201.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.995049504950495}
{"step": 510016, "time": 26008.426831245422, "eval_episode/length": 189.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 510392, "time": 26022.153614521027, "episode/length": 171.0, "episode/score": 0.17713537485906272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17713537485906272}
{"step": 510504, "time": 26027.94477248192, "episode/length": 141.0, "episode/score": 0.1513420723749732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1513420723749732}
{"step": 510568, "time": 26031.845029115677, "episode/length": 159.0, "episode/score": 0.1626232685011928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1626232685011928}
{"step": 510800, "time": 26042.337220668793, "episode/length": 139.0, "episode/score": 0.13500583724271564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13500583724271564}
{"step": 510960, "time": 26050.573597431183, "episode/length": 207.0, "episode/score": 0.22023404414358083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22023404414358083}
{"step": 510976, "time": 26053.245481729507, "episode/length": 165.0, "episode/score": 0.1501409155789588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1501409155789588}
{"step": 511264, "time": 26066.20478463173, "episode/length": 353.0, "episode/score": 0.39764350974837726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39764350974837726}
{"step": 511304, "time": 26069.203612327576, "episode/length": 170.0, "episode/score": 0.194056829008332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.194056829008332}
{"step": 511704, "time": 26085.785821199417, "episode/length": 163.0, "episode/score": 0.19662499614059925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19662499614059925}
{"step": 511736, "time": 26088.50994348526, "episode/length": 153.0, "episode/score": 0.17106850576055876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17106850576055876}
{"step": 511952, "time": 26098.257389307022, "episode/length": 172.0, "episode/score": 0.18989352156313544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18989352156313544}
{"step": 511984, "time": 26101.127671718597, "episode/length": 147.0, "episode/score": 0.1617145241361868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1617145241361868}
{"step": 512272, "time": 26113.715909719467, "episode/length": 163.0, "episode/score": 0.1927757546909561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1927757546909561}
{"step": 512304, "time": 26117.130992889404, "episode/length": 165.0, "episode/score": 0.1775955149623769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1775955149623769}
{"step": 512560, "time": 26128.31759238243, "episode/length": 156.0, "episode/score": 0.17604245395159523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17604245395159523}
{"step": 512752, "time": 26137.046414852142, "episode/length": 185.0, "episode/score": 0.19791721811088792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19791721811088792}
{"step": 512856, "time": 26142.231507778168, "episode/length": 139.0, "episode/score": 0.15088352298880636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15088352298880636}
{"step": 512896, "time": 26145.63055372238, "episode/length": 148.0, "episode/score": 0.14854342420039757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14854342420039757}
{"step": 513184, "time": 26158.014728069305, "episode/length": 153.0, "episode/score": 0.1754676681393903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1754676681393903}
{"step": 513616, "time": 26175.824097394943, "episode/length": 94.0, "episode/score": 0.11566666429280303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11566666429280303}
{"step": 513736, "time": 26181.47424674034, "episode/length": 178.0, "episode/score": 0.20413768812250055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20413768812250055}
{"step": 513760, "time": 26184.17032456398, "episode/length": 185.0, "episode/score": 0.18780871426133672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18780871426133672}
{"step": 513776, "time": 26186.345806598663, "episode/length": 151.0, "episode/score": 0.1678842939563765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1678842939563765}
{"step": 513800, "time": 26188.553322315216, "episode/length": 226.0, "episode/score": 0.2485660654692765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2485660654692765}
{"step": 514056, "time": 26199.738340616226, "episode/length": 162.0, "episode/score": 0.1784697389257417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1784697389257417}
{"step": 514336, "time": 26212.646043777466, "episode/length": 179.0, "episode/score": 0.19246112278597138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19246112278597138}
{"step": 514400, "time": 26216.600117444992, "episode/length": 151.0, "episode/score": 0.157476678446983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.157476678446983}
{"step": 514824, "time": 26234.149230003357, "episode/length": 150.0, "episode/score": 0.1572512746661232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1572512746661232}
{"step": 515048, "time": 26243.976757526398, "episode/length": 163.0, "episode/score": 0.1828016326562647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1828016326562647}
{"step": 515384, "time": 26258.154381752014, "episode/length": 165.0, "episode/score": 0.1712152129784954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712152129784954}
{"step": 515384, "time": 26258.161370038986, "episode/length": 202.0, "episode/score": 0.22834063187474385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22834063187474385}
{"step": 515440, "time": 26263.63618016243, "episode/length": 204.0, "episode/score": 0.21655529899999237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21655529899999237}
{"step": 516056, "time": 26287.980739593506, "episode/length": 214.0, "episode/score": 0.24792829995203647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24792829995203647}
{"step": 516184, "time": 26295.857347249985, "episode/length": 169.0, "episode/score": 0.19013572325093264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19013572325093264}
{"step": 516248, "time": 26299.792741537094, "episode/length": 149.0, "episode/score": 0.1516144105908097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1516144105908097}
{"step": 516272, "time": 26302.554665327072, "episode/length": 311.0, "episode/score": 0.36435857611377287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36435857611377287}
{"step": 516368, "time": 26307.589212417603, "episode/length": 115.0, "episode/score": 0.1213433637867638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1213433637867638}
{"step": 516424, "time": 26311.008224487305, "episode/length": 252.0, "episode/score": 0.2753665821892355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2753665821892355}
{"step": 516976, "time": 26333.8199968338, "episode/length": 198.0, "episode/score": 0.20454703585528478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20454703585528478}
{"step": 517544, "time": 26357.159223794937, "episode/length": 185.0, "episode/score": 0.19874503673054278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19874503673054278}
{"step": 517576, "time": 26359.902309179306, "episode/length": 165.0, "episode/score": 0.14809419161974802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14809419161974802}
{"step": 517576, "time": 26359.909246444702, "episode/length": 143.0, "episode/score": 0.15954758486714127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15954758486714127}
{"step": 517712, "time": 26368.59035229683, "episode/length": 290.0, "episode/score": 0.31366707018696616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31366707018696616}
{"step": 518096, "time": 26384.66936635971, "episode/length": 47.0, "episode/score": 0.05674999888287857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05674999888287857}
{"step": 518104, "time": 26386.208095550537, "episode/length": 228.0, "episode/score": 0.23697673497099458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23697673497099458}
{"step": 518176, "time": 26390.615597248077, "episode/length": 149.0, "episode/score": 0.14385544023662078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14385544023662078}
{"step": 518248, "time": 26394.661264181137, "episode/length": 257.0, "episode/score": 0.2841471209712836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2841471209712836}
{"step": 518392, "time": 26401.609488010406, "episode/length": 252.0, "episode/score": 0.26043909042891755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26043909042891755}
{"step": 518736, "time": 26416.10495519638, "episode/length": 144.0, "episode/score": 0.1377064716134555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1377064716134555}
{"step": 518768, "time": 26418.786588430405, "episode/length": 148.0, "episode/score": 0.15963753403593728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15963753403593728}
{"step": 519248, "time": 26438.060356855392, "episode/length": 142.0, "episode/score": 0.13649302005296704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13649302005296704}
{"step": 519384, "time": 26444.689664125443, "episode/length": 150.0, "episode/score": 0.16176044385611021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16176044385611021}
{"step": 519496, "time": 26450.4426817894, "episode/length": 174.0, "episode/score": 0.18237497936297586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18237497936297586}
{"step": 519720, "time": 26460.428296089172, "episode/length": 183.0, "episode/score": 0.20195469923692144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20195469923692144}
{"step": 519760, "time": 26463.722939491272, "episode/length": 127.0, "episode/score": 0.1460061101061001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1460061101061001}
{"step": 519880, "time": 26469.533212184906, "episode/length": 138.0, "episode/score": 0.15984523539373185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15984523539373185}
{"step": 519880, "time": 26469.540426015854, "episode/length": 185.0, "episode/score": 0.19370813635714512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19370813635714512}
{"step": 519912, "time": 26474.17292046547, "episode/length": 295.0, "episode/score": 0.31937500226831617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31937500226831617}
{"step": 520000, "time": 26497.85050344467, "eval_episode/length": 139.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.95}
{"step": 520000, "time": 26500.102036237717, "eval_episode/length": 152.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 520000, "time": 26502.263959884644, "eval_episode/length": 164.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 520000, "time": 26504.282747745514, "eval_episode/length": 169.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 520000, "time": 26505.918924093246, "eval_episode/length": 170.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 520000, "time": 26507.83852148056, "eval_episode/length": 178.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.994413407821229}
{"step": 520000, "time": 26510.93863916397, "eval_episode/length": 215.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 520000, "time": 26512.534561634064, "eval_episode/length": 51.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 520001, "time": 26513.14248776436, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.29057763671875, "train/action_min": 0.0, "train/action_std": 4.817422080993652, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0079052201397717, "train/actor_opt_grad_steps": 31780.0, "train/actor_opt_loss": -8.590266073226928, "train/adv_mag": 0.1769458459019661, "train/adv_max": 0.12130403786897659, "train/adv_mean": 4.220316994542372e-05, "train/adv_min": -0.1756419283747673, "train/adv_std": 0.01344073310121894, "train/cont_avg": 0.9943125, "train/cont_loss_mean": 0.00021677864837738525, "train/cont_loss_std": 0.006072750099869154, "train/cont_neg_acc": 0.9878476204872131, "train/cont_neg_loss": 0.03249986944520788, "train/cont_pos_acc": 0.9999763765335083, "train/cont_pos_loss": 7.189539878169171e-05, "train/cont_pred": 0.9943359484672546, "train/cont_rate": 0.9943125, "train/dyn_loss_mean": 11.723979454040528, "train/dyn_loss_std": 8.257014347076415, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14428825932741166, "train/extr_critic_critic_opt_grad_steps": 31780.0, "train/extr_critic_critic_opt_loss": 12322.910234375, "train/extr_critic_mag": 0.27774962520599367, "train/extr_critic_max": 0.27774962520599367, "train/extr_critic_mean": 0.23023259973526, "train/extr_critic_min": 0.002592658996582031, "train/extr_critic_std": 0.05741249462962151, "train/extr_return_normed_mag": 0.2011766859292984, "train/extr_return_normed_max": 0.2011766859292984, "train/extr_return_normed_mean": 0.15446971333026885, "train/extr_return_normed_min": -0.07479455810785293, "train/extr_return_normed_std": 0.05915515372157097, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.276981794834137, "train/extr_return_raw_max": 0.276981794834137, "train/extr_return_raw_mean": 0.23027482640743255, "train/extr_return_raw_min": 0.0010105504989624022, "train/extr_return_raw_std": 0.059155154019594196, "train/extr_reward_mag": 0.0013710880279541016, "train/extr_reward_max": 0.0013710880279541016, "train/extr_reward_mean": 0.001090342649258673, "train/extr_reward_min": 1.0328292846679688e-05, "train/extr_reward_std": 0.00023998844728339463, "train/image_loss_mean": 5.571468351364135, "train/image_loss_std": 9.712883068084716, "train/model_loss_mean": 12.646164779663087, "train/model_loss_std": 13.170317245483398, "train/model_opt_grad_norm": 60.09429460956204, "train/model_opt_grad_steps": 31748.92, "train/model_opt_loss": 16801.474171875, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 1320.0, "train/policy_entropy_mag": 2.763576551437378, "train/policy_entropy_max": 2.763576551437378, "train/policy_entropy_mean": 2.178673815727234, "train/policy_entropy_min": 0.08017139399051666, "train/policy_entropy_std": 0.5785048706531525, "train/policy_logprob_mag": 7.438194961547851, "train/policy_logprob_max": -0.009565422736108303, "train/policy_logprob_mean": -2.1790061111450196, "train/policy_logprob_min": -7.438194961547851, "train/policy_logprob_std": 1.0958927936553955, "train/policy_randomness_mag": 0.9754212489128112, "train/policy_randomness_max": 0.9754212489128112, "train/policy_randomness_mean": 0.7689762434959412, "train/policy_randomness_min": 0.02829698383808136, "train/policy_randomness_std": 0.20418683421611786, "train/post_ent_mag": 56.555011199951174, "train/post_ent_max": 56.555011199951174, "train/post_ent_mean": 39.43928143310547, "train/post_ent_min": 20.161480010986327, "train/post_ent_std": 6.6898548088073735, "train/prior_ent_mag": 65.36793627929687, "train/prior_ent_max": 65.36793627929687, "train/prior_ent_mean": 51.24006610107422, "train/prior_ent_min": 30.016361450195312, "train/prior_ent_std": 5.4678337783813475, "train/rep_loss_mean": 11.723979454040528, "train/rep_loss_std": 8.257014347076415, "train/reward_avg": 0.001061656222678721, "train/reward_loss_mean": 0.040092069178819655, "train/reward_loss_std": 0.011187827862799168, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013206748962402344, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040092069178819655, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010615687994286417, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.6789473472980031, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 0.7894736842105263, "train_stats/max_log_achievement_collect_sapling": 0.5526315789473685, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5263157894736842, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.017543859649122806, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_place_table": 0.08771929824561403, "train_stats/max_log_achievement_wake_up": 0.20175438596491227, "train_stats/mean_log_entropy": 2.2508114388114526, "eval_stats/sum_log_reward": 0.6624999744817615, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.6875, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00011229096708120778, "report/cont_loss_std": 0.003060438670217991, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002583662047982216, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.528053487883881e-05, "report/cont_pred": 0.9930914044380188, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.453662872314453, "report/dyn_loss_std": 8.183123588562012, "report/image_loss_mean": 4.749368190765381, "report/image_loss_std": 7.735722541809082, "report/model_loss_mean": 12.262879371643066, "report/model_loss_std": 11.185888290405273, "report/post_ent_mag": 57.064353942871094, "report/post_ent_max": 57.064353942871094, "report/post_ent_mean": 39.215065002441406, "report/post_ent_min": 21.536026000976562, "report/post_ent_std": 6.7209601402282715, "report/prior_ent_mag": 65.60982513427734, "report/prior_ent_max": 65.60982513427734, "report/prior_ent_mean": 51.64109420776367, "report/prior_ent_min": 30.048233032226562, "report/prior_ent_std": 5.237802982330322, "report/rep_loss_mean": 12.453662872314453, "report/rep_loss_std": 8.183123588562012, "report/reward_avg": 0.0010942351073026657, "report/reward_loss_mean": 0.04120082035660744, "report/reward_loss_std": 0.010203445330262184, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013206005096435547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04120081663131714, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011060023680329323, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.005033391527831554, "eval/cont_loss_std": 0.16002239286899567, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.0307998657226562, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.910573388386183e-07, "eval/cont_pred": 0.9961174726486206, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.58676528930664, "eval/dyn_loss_std": 10.366918563842773, "eval/image_loss_mean": 12.24476432800293, "eval/image_loss_std": 22.01476287841797, "eval/model_loss_mean": 23.302289962768555, "eval/model_loss_std": 26.59148597717285, "eval/post_ent_mag": 52.50450134277344, "eval/post_ent_max": 52.50450134277344, "eval/post_ent_mean": 37.69927978515625, "eval/post_ent_min": 21.89238929748535, "eval/post_ent_std": 6.238193511962891, "eval/prior_ent_mag": 65.60982513427734, "eval/prior_ent_max": 65.60982513427734, "eval/prior_ent_mean": 52.15043640136719, "eval/prior_ent_min": 26.16494369506836, "eval/prior_ent_std": 5.036275386810303, "eval/rep_loss_mean": 17.58676528930664, "eval/rep_loss_std": 10.366918563842773, "eval/reward_avg": 0.0008789058774709702, "eval/reward_loss_mean": 0.5004304647445679, "eval/reward_loss_std": 3.0909621715545654, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.38152891397476196, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.674072265625, "eval/reward_pred": 0.0010114110773429275, "eval/reward_rate": 0.005859375, "replay/size": 519497.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3933421518558111e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.129371473422417e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2020058215045726e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1006.4700043201447, "timer/env.step_count": 2496.0, "timer/env.step_total": 250.59097480773926, "timer/env.step_frac": 0.24898007266198627, "timer/env.step_avg": 0.10039702516335708, "timer/env.step_min": 0.023281335830688477, "timer/env.step_max": 3.399913787841797, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.594073295593262, "timer/replay._sample_frac": 0.009532398635241905, "timer/replay._sample_avg": 0.0004804724206527074, "timer/replay._sample_min": 0.00039768218994140625, "timer/replay._sample_max": 0.012043952941894531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2965.0, "timer/agent.policy_total": 48.7746148109436, "timer/agent.policy_frac": 0.048461071469179176, "timer/agent.policy_avg": 0.01645012303910408, "timer/agent.policy_min": 0.009458065032958984, "timer/agent.policy_max": 0.11296606063842773, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14350605010986328, "timer/dataset_train_frac": 0.000142583534028716, "timer/dataset_train_avg": 0.00011498882220341609, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.00035452842712402344, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 561.3815484046936, "timer/agent.train_frac": 0.5577727562620194, "timer/agent.train_avg": 0.4498249586576071, "timer/agent.train_min": 0.43573427200317383, "timer/agent.train_max": 1.01777982711792, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792454242706299, "timer/agent.report_frac": 0.00047616463701206176, "timer/agent.report_avg": 0.23962271213531494, "timer/agent.report_min": 0.23291707038879395, "timer/agent.report_max": 0.24632835388183594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.363780151132344e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 19.8394127683349}
{"step": 520424, "time": 26528.888538599014, "episode/length": 115.0, "episode/score": 0.13221492721186223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13221492721186223}
{"step": 520512, "time": 26533.93411755562, "episode/length": 157.0, "episode/score": 0.17629185268697256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17629185268697256}
{"step": 520584, "time": 26537.982621192932, "episode/length": 149.0, "episode/score": 0.16617985671791757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16617985671791757}
{"step": 521088, "time": 26558.632174253464, "episode/length": 150.0, "episode/score": 0.16472174017826546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16472174017826546}
{"step": 521208, "time": 26564.46967291832, "episode/length": 165.0, "episode/score": 0.17756265111438552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17756265111438552}
{"step": 521320, "time": 26570.26057243347, "episode/length": 194.0, "episode/score": 0.1827542747651023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1827542747651023}
{"step": 521352, "time": 26573.160081624985, "episode/length": 203.0, "episode/score": 0.2294306754911304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2294306754911304}
{"step": 521480, "time": 26579.45083284378, "episode/length": 195.0, "episode/score": 0.2137082027534234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2137082027534234}
{"step": 521896, "time": 26596.437470197678, "episode/length": 183.0, "episode/score": 0.2014406906619115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2014406906619115}
{"step": 522144, "time": 26607.464450120926, "episode/length": 131.0, "episode/score": 0.15958333003800362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15958333003800362}
{"step": 522144, "time": 26607.47252702713, "episode/length": 203.0, "episode/score": 0.2142992216449784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2142992216449784}
{"step": 522592, "time": 26627.6426486969, "episode/length": 172.0, "episode/score": 0.19192200966654127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19192200966654127}
{"step": 522704, "time": 26633.422997236252, "episode/length": 100.0, "episode/score": 0.10995482112457466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10995482112457466}
{"step": 522712, "time": 26634.933688402176, "episode/length": 153.0, "episode/score": 0.13565314287961883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13565314287961883}
{"step": 522776, "time": 26638.798308372498, "episode/length": 273.0, "episode/score": 0.2908841481480522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2908841481480522}
{"step": 523008, "time": 26649.25617337227, "episode/length": 210.0, "episode/score": 0.21694675622029536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21694675622029536}
{"step": 523424, "time": 26666.328467607498, "episode/length": 258.0, "episode/score": 0.28340264397911596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28340264397911596}
{"step": 523552, "time": 26672.631672143936, "episode/length": 175.0, "episode/score": 0.17695521852056117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17695521852056117}
{"step": 523584, "time": 26675.388442993164, "episode/length": 179.0, "episode/score": 0.19315511292506926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19315511292506926}
{"step": 523848, "time": 26686.557244062424, "episode/length": 156.0, "episode/score": 0.172826551781327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.172826551781327}
{"step": 524016, "time": 26694.605884075165, "episode/length": 162.0, "episode/score": 0.19252641642378876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19252641642378876}
{"step": 524096, "time": 26699.17771410942, "episode/length": 173.0, "episode/score": 0.18489928443887038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18489928443887038}
{"step": 524376, "time": 26712.460952043533, "episode/length": 170.0, "episode/score": 0.18591464592827833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18591464592827833}
{"step": 524888, "time": 26733.12808561325, "episode/length": 263.0, "episode/score": 0.28445381372148404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28445381372148404}
{"step": 525008, "time": 26739.651493787766, "episode/length": 181.0, "episode/score": 0.1781944110734912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1781944110734912}
{"step": 525288, "time": 26752.204125642776, "episode/length": 179.0, "episode/score": 0.19843481759380666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19843481759380666}
{"step": 525296, "time": 26754.2540538311, "episode/length": 213.0, "episode/score": 0.25795976501103723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25795976501103723}
{"step": 525416, "time": 26760.025323152542, "episode/length": 50.0, "episode/score": 0.059223810261755716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059223810261755716}
{"step": 525440, "time": 26762.773430109024, "episode/length": 167.0, "episode/score": 0.1760193506597716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1760193506597716}
{"step": 525568, "time": 26769.11793422699, "episode/length": 193.0, "episode/score": 0.19829719355038833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19829719355038833}
{"step": 525680, "time": 26774.943940877914, "episode/length": 281.0, "episode/score": 0.3380762824235717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3380762824235717}
{"step": 526152, "time": 26793.98460125923, "episode/length": 221.0, "episode/score": 0.2556428609077557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2556428609077557}
{"step": 526200, "time": 26797.994028806686, "episode/length": 163.0, "episode/score": 0.15709468639579427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15709468639579427}
{"step": 526472, "time": 26810.27131986618, "episode/length": 147.0, "episode/score": 0.15578136310796253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15578136310796253}
{"step": 526672, "time": 26819.506390333176, "episode/length": 153.0, "episode/score": 0.17669938708604604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17669938708604604}
{"step": 526704, "time": 26822.2198073864, "episode/length": 160.0, "episode/score": 0.1856988260806247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1856988260806247}
{"step": 526888, "time": 26830.429367780685, "episode/length": 150.0, "episode/score": 0.16425518511641712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16425518511641712}
{"step": 526992, "time": 26836.248905181885, "episode/length": 177.0, "episode/score": 0.18711972191886161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18711972191886161}
{"step": 527568, "time": 26859.43351483345, "episode/length": 283.0, "episode/score": 0.3256275269759499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3256275269759499}
{"step": 527640, "time": 26863.48286008835, "episode/length": 93.0, "episode/score": 0.11112499790033326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11112499790033326}
{"step": 527696, "time": 26867.615547657013, "episode/length": 152.0, "episode/score": 0.16133164116399712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16133164116399712}
{"step": 527760, "time": 26871.55693745613, "episode/length": 200.0, "episode/score": 0.2185118871366285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2185118871366285}
{"step": 527776, "time": 26873.706045150757, "episode/length": 137.0, "episode/score": 0.144514632778737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.144514632778737}
{"step": 527784, "time": 26875.47484588623, "episode/length": 197.0, "episode/score": 0.21965261783407186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21965261783407186}
{"step": 528304, "time": 26896.922157764435, "episode/length": 199.0, "episode/score": 0.19749240409510094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19749240409510094}
{"step": 528544, "time": 26907.51419711113, "episode/length": 193.0, "episode/score": 0.19033510141889565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19033510141889565}
{"step": 528936, "time": 26923.355886936188, "episode/length": 170.0, "episode/score": 0.18834677927588928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18834677927588928}
{"step": 529032, "time": 26928.61533308029, "episode/length": 173.0, "episode/score": 0.1902769362559411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1902769362559411}
{"step": 529152, "time": 26934.849014759064, "episode/length": 181.0, "episode/score": 0.2023021350350973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2023021350350973}
{"step": 529216, "time": 26938.77645277977, "episode/length": 181.0, "episode/score": 0.20465763795527891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20465763795527891}
{"step": 529312, "time": 26944.034133911133, "episode/length": 190.0, "episode/score": 0.21439013203871582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21439013203871582}
{"step": 530016, "time": 26972.28196454048, "episode/length": 213.0, "episode/score": 0.20563714675154188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20563714675154188}
{"step": 530088, "time": 26993.29461669922, "eval_episode/length": 87.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9318181818181818}
{"step": 530088, "time": 26997.749567985535, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 530088, "time": 26999.998252391815, "eval_episode/length": 151.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.993421052631579}
{"step": 530088, "time": 27002.436148405075, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.99375}
{"step": 530088, "time": 27004.83126974106, "eval_episode/length": 162.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 530088, "time": 27007.413464546204, "eval_episode/length": 174.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 530088, "time": 27011.728646993637, "eval_episode/length": 221.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 530088, "time": 27014.217886686325, "eval_episode/length": 235.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9703389830508474}
{"step": 530104, "time": 27014.814967393875, "episode/length": 194.0, "episode/score": 0.2135944231058602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2135944231058602}
{"step": 530320, "time": 27024.58032989502, "episode/length": 317.0, "episode/score": 0.3757076438068907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3757076438068907}
{"step": 530376, "time": 27028.014288663864, "episode/length": 179.0, "episode/score": 0.18427229513235943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18427229513235943}
{"step": 530392, "time": 27030.159665107727, "episode/length": 146.0, "episode/score": 0.16837499718531035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16837499718531035}
{"step": 530552, "time": 27037.642347574234, "episode/length": 154.0, "episode/score": 0.1673701271356549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1673701271356549}
{"step": 531008, "time": 27056.45268034935, "episode/length": 231.0, "episode/score": 0.2531734915291963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2531734915291963}
{"step": 531008, "time": 27056.45915555954, "episode/length": 123.0, "episode/score": 0.12586736267166998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12586736267166998}
{"step": 531584, "time": 27081.133539676666, "episode/length": 318.0, "episode/score": 0.34949857765241177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34949857765241177}
{"step": 531648, "time": 27085.176646709442, "episode/length": 165.0, "episode/score": 0.17339197369892645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17339197369892645}
{"step": 531672, "time": 27087.343252420425, "episode/length": 159.0, "episode/score": 0.17768828001135262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17768828001135262}
{"step": 531696, "time": 27090.06449484825, "episode/length": 198.0, "episode/score": 0.21960233841400623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21960233841400623}
{"step": 531800, "time": 27095.192744255066, "episode/length": 177.0, "episode/score": 0.19364091138959338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19364091138959338}
{"step": 532112, "time": 27108.7485435009, "episode/length": 194.0, "episode/score": 0.22702057328933734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22702057328933734}
{"step": 532392, "time": 27120.404750347137, "episode/length": 172.0, "episode/score": 0.19299417297406762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19299417297406762}
{"step": 532448, "time": 27124.241569280624, "episode/length": 179.0, "episode/score": 0.19777084424185887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19777084424185887}
{"step": 532880, "time": 27143.574115276337, "episode/length": 150.0, "episode/score": 0.1586428548907861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1586428548907861}
{"step": 533016, "time": 27150.07919073105, "episode/length": 151.0, "episode/score": 0.17186458050855435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17186458050855435}
{"step": 533088, "time": 27154.527488946915, "episode/length": 173.0, "episode/score": 0.19145751388714416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19145751388714416}
{"step": 533232, "time": 27161.49320077896, "episode/length": 197.0, "episode/score": 0.21254481057985686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21254481057985686}
{"step": 533648, "time": 27179.162496089935, "episode/length": 191.0, "episode/score": 0.21758608181698946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21758608181698946}
{"step": 533760, "time": 27184.941605567932, "episode/length": 170.0, "episode/score": 0.19466285048110876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19466285048110876}
{"step": 533896, "time": 27191.323748350143, "episode/length": 180.0, "episode/score": 0.17221498258732026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17221498258732026}
{"step": 534000, "time": 27196.97767353058, "episode/length": 301.0, "episode/score": 0.3387420577055309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3387420577055309}
{"step": 534256, "time": 27208.03271126747, "episode/length": 154.0, "episode/score": 0.1608578778032097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1608578778032097}
{"step": 534360, "time": 27213.387516498566, "episode/length": 158.0, "episode/score": 0.17895886642145342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17895886642145342}
{"step": 534456, "time": 27218.470195531845, "episode/length": 152.0, "episode/score": 0.1738602300065395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1738602300065395}
{"step": 534752, "time": 27231.190017223358, "episode/length": 233.0, "episode/score": 0.2620570337494428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2620570337494428}
{"step": 535144, "time": 27247.28977036476, "episode/length": 172.0, "episode/score": 0.2030249303279561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2030249303279561}
{"step": 535320, "time": 27255.602091550827, "episode/length": 164.0, "episode/score": 0.1849355663289316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1849355663289316}
{"step": 535520, "time": 27264.9198949337, "episode/length": 157.0, "episode/score": 0.17851000824884977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17851000824884977}
{"step": 535608, "time": 27269.469832658768, "episode/length": 155.0, "episode/score": 0.1795416635577567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1795416635577567}
{"step": 535768, "time": 27276.93357038498, "episode/length": 264.0, "episode/score": 0.29476255194458645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29476255194458645}
{"step": 535848, "time": 27281.4365067482, "episode/length": 243.0, "episode/score": 0.2661877052451018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2661877052451018}
{"step": 536120, "time": 27293.086210489273, "episode/length": 207.0, "episode/score": 0.21908922256261576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21908922256261576}
{"step": 536200, "time": 27297.52234506607, "episode/length": 180.0, "episode/score": 0.2049678849434713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2049678849434713}
{"step": 536520, "time": 27311.013372182846, "episode/length": 171.0, "episode/score": 0.18151113457497559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18151113457497559}
{"step": 536808, "time": 27323.291402339935, "episode/length": 185.0, "episode/score": 0.19212771733327827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19212771733327827}
{"step": 536896, "time": 27328.34743618965, "episode/length": 140.0, "episode/score": 0.1637545258308819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637545258308819}
{"step": 537016, "time": 27334.11689734459, "episode/length": 145.0, "episode/score": 0.15169543135925778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15169543135925778}
{"step": 537032, "time": 27336.34285759926, "episode/length": 177.0, "episode/score": 0.2070875498939131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2070875498939131}
{"step": 537520, "time": 27356.644337177277, "episode/length": 164.0, "episode/score": 0.17539062442847353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17539062442847353}
{"step": 537624, "time": 27361.88618850708, "episode/length": 262.0, "episode/score": 0.2828334804853512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2828334804853512}
{"step": 537880, "time": 27373.08414387703, "episode/length": 169.0, "episode/score": 0.17233705484250095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17233705484250095}
{"step": 537904, "time": 27376.439244508743, "episode/length": 222.0, "episode/score": 0.23366921672823082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23366921672823082}
{"step": 538072, "time": 27384.6320810318, "episode/length": 146.0, "episode/score": 0.16210151812083495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16210151812083495}
{"step": 538296, "time": 27395.15230035782, "episode/length": 159.0, "episode/score": 0.17193506324110785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17193506324110785}
{"step": 538696, "time": 27412.189235925674, "episode/length": 207.0, "episode/score": 0.2232694590547908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2232694590547908}
{"step": 538776, "time": 27416.732469320297, "episode/length": 245.0, "episode/score": 0.2970238034904469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2970238034904469}
{"step": 538888, "time": 27422.55050969124, "episode/length": 170.0, "episode/score": 0.18836234241007332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18836234241007332}
{"step": 539112, "time": 27432.441956281662, "episode/length": 185.0, "episode/score": 0.20084155401036696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20084155401036696}
{"step": 539184, "time": 27437.04344034195, "episode/length": 162.0, "episode/score": 0.19141523166035768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19141523166035768}
{"step": 539456, "time": 27448.701531410217, "episode/length": 193.0, "episode/score": 0.2042960040807884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2042960040807884}
{"step": 539512, "time": 27452.16125535965, "episode/length": 179.0, "episode/score": 0.18577592009387445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18577592009387445}
{"step": 539880, "time": 27467.76355600357, "episode/length": 197.0, "episode/score": 0.20575593988814944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20575593988814944}
{"step": 540072, "time": 27495.19664144516, "eval_episode/length": 132.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 540072, "time": 27497.414926052094, "eval_episode/length": 148.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 540072, "time": 27499.422842264175, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.99375}
{"step": 540072, "time": 27501.180876493454, "eval_episode/length": 160.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 540072, "time": 27503.160163640976, "eval_episode/length": 169.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 540072, "time": 27505.81281709671, "eval_episode/length": 192.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 540072, "time": 27508.023361682892, "eval_episode/length": 206.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 540072, "time": 27511.97344326973, "eval_episode/length": 264.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 540089, "time": 27513.623538017273, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.18489990234375, "train/action_min": 0.0, "train/action_std": 4.864765323638916, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0076709724739193914, "train/actor_opt_grad_steps": 33030.0, "train/actor_opt_loss": -8.85251772993803, "train/adv_mag": 0.17808182692527771, "train/adv_max": 0.12456012618541717, "train/adv_mean": 6.369120515591931e-05, "train/adv_min": -0.17642510163784028, "train/adv_std": 0.013141048792749643, "train/cont_avg": 0.994703125, "train/cont_loss_mean": 0.00023515676699219058, "train/cont_loss_std": 0.006743245092411826, "train/cont_neg_acc": 0.9953904776573181, "train/cont_neg_loss": 0.01568632014286959, "train/cont_pos_acc": 0.9999685168266297, "train/cont_pos_loss": 0.00014370775890728283, "train/cont_pred": 0.9947003655433655, "train/cont_rate": 0.994703125, "train/dyn_loss_mean": 11.765431785583496, "train/dyn_loss_std": 8.30682061767578, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13138659259676932, "train/extr_critic_critic_opt_grad_steps": 33030.0, "train/extr_critic_critic_opt_loss": 12297.1261875, "train/extr_critic_mag": 0.2801507415771484, "train/extr_critic_max": 0.2801507415771484, "train/extr_critic_mean": 0.23144765698909758, "train/extr_critic_min": 0.0022714500427246094, "train/extr_critic_std": 0.058691914498806, "train/extr_return_normed_mag": 0.20609388852119445, "train/extr_return_normed_max": 0.20609388852119445, "train/extr_return_normed_mean": 0.15801905584335327, "train/extr_return_normed_min": -0.07248778223991394, "train/extr_return_normed_std": 0.06018741047382355, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2795862123966217, "train/extr_return_raw_max": 0.2795862123966217, "train/extr_return_raw_mean": 0.23151138508319855, "train/extr_return_raw_min": 0.0010045413970947265, "train/extr_return_raw_std": 0.06018741065263748, "train/extr_reward_mag": 0.0013654470443725587, "train/extr_reward_max": 0.0013654470443725587, "train/extr_reward_mean": 0.0010898896884173155, "train/extr_reward_min": 9.748458862304687e-06, "train/extr_reward_std": 0.00024270138761494308, "train/image_loss_mean": 5.641675283432007, "train/image_loss_std": 10.174596313476563, "train/model_loss_mean": 12.74126513671875, "train/model_loss_std": 13.621654762268067, "train/model_opt_grad_norm": 54.46585209655762, "train/model_opt_grad_steps": 32997.68, "train/model_opt_loss": 15926.5814140625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.7637842712402345, "train/policy_entropy_max": 2.7637842712402345, "train/policy_entropy_mean": 2.191220185279846, "train/policy_entropy_min": 0.0802020098567009, "train/policy_entropy_std": 0.5647198393344879, "train/policy_logprob_mag": 7.438122119903564, "train/policy_logprob_max": -0.009570696458220482, "train/policy_logprob_mean": -2.192167725563049, "train/policy_logprob_min": -7.438122119903564, "train/policy_logprob_std": 1.0844852004051209, "train/policy_randomness_mag": 0.9754945635795593, "train/policy_randomness_max": 0.9754945635795593, "train/policy_randomness_mean": 0.7734045658111572, "train/policy_randomness_min": 0.02830778995156288, "train/policy_randomness_std": 0.19932132303714753, "train/post_ent_mag": 56.57725360107422, "train/post_ent_max": 56.57725360107422, "train/post_ent_mean": 39.516975067138674, "train/post_ent_min": 19.96169856262207, "train/post_ent_std": 6.693763263702393, "train/prior_ent_mag": 65.4685033569336, "train/prior_ent_max": 65.4685033569336, "train/prior_ent_mean": 51.310458404541016, "train/prior_ent_min": 29.983238494873046, "train/prior_ent_std": 5.490411151885986, "train/rep_loss_mean": 11.765431785583496, "train/rep_loss_std": 8.30682061767578, "train/reward_avg": 0.0010620707338675857, "train/reward_loss_mean": 0.04009572601318359, "train/reward_loss_std": 0.011283745631575585, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013115882873535156, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04009572607278824, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010618374263867735, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.9867924307033701, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.320754716981132, "train_stats/max_log_achievement_collect_sapling": 0.7830188679245284, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.49056603773584906, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_sword": 0.009433962264150943, "train_stats/max_log_achievement_place_plant": 0.5, "train_stats/max_log_achievement_place_table": 0.03773584905660377, "train_stats/max_log_achievement_wake_up": 0.25471698113207547, "train_stats/mean_log_entropy": 2.2513902502239875, "eval_stats/sum_log_reward": 0.5375000145286322, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.625, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.417949351889547e-05, "report/cont_loss_std": 0.0004493048181757331, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0024018429685384035, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0682101958536805e-07, "report/cont_pred": 0.9941544532775879, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.135704040527344, "report/dyn_loss_std": 8.136547088623047, "report/image_loss_mean": 5.38517427444458, "report/image_loss_std": 8.428656578063965, "report/model_loss_mean": 12.105941772460938, "report/model_loss_std": 12.135580062866211, "report/post_ent_mag": 58.34083938598633, "report/post_ent_max": 58.34083938598633, "report/post_ent_mean": 39.234745025634766, "report/post_ent_min": 20.106555938720703, "report/post_ent_std": 6.464458465576172, "report/prior_ent_mag": 65.60842895507812, "report/prior_ent_max": 65.60842895507812, "report/prior_ent_mean": 50.98680877685547, "report/prior_ent_min": 26.15024185180664, "report/prior_ent_std": 5.460283279418945, "report/rep_loss_mean": 11.135704040527344, "report/rep_loss_std": 8.136547088623047, "report/reward_avg": 0.001039513386785984, "report/reward_loss_mean": 0.03932986408472061, "report/reward_loss_std": 0.011751368641853333, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012606382369995117, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03932986408472061, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010388832306489348, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.99211091412144e-07, "eval/cont_loss_std": 9.851235517999157e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.353644842718495e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.938208005318302e-07, "eval/cont_pred": 0.9980462789535522, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.394597053527832, "eval/dyn_loss_std": 9.909186363220215, "eval/image_loss_mean": 7.940242767333984, "eval/image_loss_std": 12.782326698303223, "eval/model_loss_mean": 17.69886016845703, "eval/model_loss_std": 17.032978057861328, "eval/post_ent_mag": 55.88818359375, "eval/post_ent_max": 55.88818359375, "eval/post_ent_mean": 38.566932678222656, "eval/post_ent_min": 20.669513702392578, "eval/post_ent_std": 6.4162750244140625, "eval/prior_ent_mag": 65.60842895507812, "eval/prior_ent_max": 65.60842895507812, "eval/prior_ent_mean": 51.67076110839844, "eval/prior_ent_min": 25.23960304260254, "eval/prior_ent_std": 5.088180065155029, "eval/rep_loss_mean": 15.394597053527832, "eval/rep_loss_std": 9.909186363220215, "eval/reward_avg": 0.007031249813735485, "eval/reward_loss_mean": 0.5218588709831238, "eval/reward_loss_std": 3.1336941719055176, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012655258178710938, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.323768675327301, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.60820960998535, "eval/reward_pred": 0.0010283930459991097, "eval/reward_rate": 0.009765625, "replay/size": 539585.0, "replay/inserts": 20088.0, "replay/samples": 20096.0, "replay/insert_wait_avg": 1.3832265473323626e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.055050471785722e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1671089126678285e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4901161193847656e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4708151817322, "timer/env.step_count": 2511.0, "timer/env.step_total": 237.61599588394165, "timer/env.step_frac": 0.23750417531247975, "timer/env.step_avg": 0.0946300262381289, "timer/env.step_min": 0.023172616958618164, "timer/env.step_max": 3.3392105102539062, "timer/replay._sample_count": 20096.0, "timer/replay._sample_total": 9.567119598388672, "timer/replay._sample_frac": 0.00956261737295239, "timer/replay._sample_avg": 0.00047607083988797133, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.018202543258666992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3012.0, "timer/agent.policy_total": 48.60209894180298, "timer/agent.policy_frac": 0.04857922710416552, "timer/agent.policy_avg": 0.016136155027159024, "timer/agent.policy_min": 0.00957036018371582, "timer/agent.policy_max": 0.1161508560180664, "timer/dataset_train_count": 1256.0, "timer/dataset_train_total": 0.1372840404510498, "timer/dataset_train_frac": 0.00013721943545760764, "timer/dataset_train_avg": 0.00010930257997695048, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00027298927307128906, "timer/agent.train_count": 1256.0, "timer/agent.train_total": 564.0312089920044, "timer/agent.train_frac": 0.5637657795040728, "timer/agent.train_avg": 0.44906943391083154, "timer/agent.train_min": 0.4340949058532715, "timer/agent.train_max": 1.05531907081604, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4824800491333008, "timer/agent.report_frac": 0.00048225299710082987, "timer/agent.report_avg": 0.2412400245666504, "timer/agent.report_min": 0.23486900329589844, "timer/agent.report_max": 0.24761104583740234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.57763671875e-05, "timer/dataset_eval_frac": 4.575482512119544e-08, "timer/dataset_eval_avg": 4.57763671875e-05, "timer/dataset_eval_min": 4.57763671875e-05, "timer/dataset_eval_max": 4.57763671875e-05, "fps": 20.078300198365486}
{"step": 540216, "time": 27518.21883916855, "episode/length": 165.0, "episode/score": 0.1683336312917163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1683336312917163}
{"step": 540216, "time": 27518.226872205734, "episode/length": 189.0, "episode/score": 0.2146216271657977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2146216271657977}
{"step": 540384, "time": 27528.1780295372, "episode/length": 149.0, "episode/score": 0.15390438421673025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15390438421673025}
{"step": 540384, "time": 27528.18574333191, "episode/length": 158.0, "episode/score": 0.16888033808209002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16888033808209002}
{"step": 540792, "time": 27547.744339466095, "episode/length": 251.0, "episode/score": 0.2662400689014248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2662400689014248}
{"step": 540872, "time": 27552.243039131165, "episode/length": 176.0, "episode/score": 0.19491792052394885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19491792052394885}
{"step": 541544, "time": 27578.9460875988, "episode/length": 207.0, "episode/score": 0.2294785294589019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2294785294589019}
{"step": 541568, "time": 27581.752584457397, "episode/length": 168.0, "episode/score": 0.19014972074910474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19014972074910474}
{"step": 541872, "time": 27594.765917539597, "episode/length": 185.0, "episode/score": 0.21890678296767874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21890678296767874}
{"step": 541984, "time": 27600.492834329605, "episode/length": 148.0, "episode/score": 0.1540207760199337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1540207760199337}
{"step": 542192, "time": 27609.728007793427, "episode/length": 225.0, "episode/score": 0.26638074906350084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26638074906350084}
{"step": 542200, "time": 27611.44654583931, "episode/length": 165.0, "episode/score": 0.17583649143216462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17583649143216462}
{"step": 542896, "time": 27638.877230644226, "episode/length": 168.0, "episode/score": 0.19184412436879938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19184412436879938}
{"step": 542944, "time": 27642.108936309814, "episode/length": 428.0, "episode/score": 0.41969616980986757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41969616980986757}
{"step": 543088, "time": 27649.194356441498, "episode/length": 189.0, "episode/score": 0.19505420139648777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19505420139648777}
{"step": 543144, "time": 27653.089106082916, "episode/length": 365.0, "episode/score": 0.39976180788153215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39976180788153215}
{"step": 543280, "time": 27660.670137882233, "episode/length": 175.0, "episode/score": 0.1835376551025547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1835376551025547}
{"step": 543584, "time": 27674.32022690773, "episode/length": 173.0, "episode/score": 0.1782813611880556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1782813611880556}
{"step": 543624, "time": 27677.57364630699, "episode/length": 177.0, "episode/score": 0.1831272582994643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1831272582994643}
{"step": 544384, "time": 27708.182275295258, "episode/length": 179.0, "episode/score": 0.19910414139167187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19910414139167187}
{"step": 544392, "time": 27709.766434431076, "episode/length": 162.0, "episode/score": 0.18262163259805675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18262163259805675}
{"step": 544544, "time": 27717.175503492355, "episode/length": 157.0, "episode/score": 0.16240288153130678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16240288153130678}
{"step": 544640, "time": 27722.38976240158, "episode/length": 217.0, "episode/score": 0.23992235324067224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23992235324067224}
{"step": 544784, "time": 27729.340770959854, "episode/length": 149.0, "episode/score": 0.16943057284333918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16943057284333918}
{"step": 545096, "time": 27742.50356411934, "episode/length": 183.0, "episode/score": 0.2041248826744777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2041248826744777}
{"step": 545232, "time": 27749.395176887512, "episode/length": 405.0, "episode/score": 0.42817840984162103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42817840984162103}
{"step": 545304, "time": 27753.402227640152, "episode/length": 94.0, "episode/score": 0.10562180015949707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10562180015949707}
{"step": 545544, "time": 27763.919727563858, "episode/length": 143.0, "episode/score": 0.15131776979342249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15131776979342249}
{"step": 545848, "time": 27776.945757627487, "episode/length": 182.0, "episode/score": 0.17967339053984688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17967339053984688}
{"step": 545928, "time": 27781.494550943375, "episode/length": 347.0, "episode/score": 0.3481056684458963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3481056684458963}
{"step": 546056, "time": 27787.896661758423, "episode/length": 176.0, "episode/score": 0.18631532603922096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18631532603922096}
{"step": 546496, "time": 27806.145379066467, "episode/length": 157.0, "episode/score": 0.1748497541548204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748497541548204}
{"step": 546504, "time": 27807.749111175537, "episode/length": 175.0, "episode/score": 0.19582237779650313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19582237779650313}
{"step": 546640, "time": 27814.57769870758, "episode/length": 166.0, "episode/score": 0.19055499934529507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19055499934529507}
{"step": 546728, "time": 27819.256443738937, "episode/length": 147.0, "episode/score": 0.16177555449166903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16177555449166903}
{"step": 546744, "time": 27821.357741117477, "episode/length": 244.0, "episode/score": 0.2761862900174492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2761862900174492}
{"step": 547472, "time": 27850.240389108658, "episode/length": 202.0, "episode/score": 0.21960343364526125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21960343364526125}
{"step": 547488, "time": 27852.498492002487, "episode/length": 178.0, "episode/score": 0.19777890660634512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19777890660634512}
{"step": 547600, "time": 27858.28376173973, "episode/length": 208.0, "episode/score": 0.2301561882218266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2301561882218266}
{"step": 547864, "time": 27869.354949712753, "episode/length": 169.0, "episode/score": 0.2018779723730404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2018779723730404}
{"step": 547952, "time": 27874.51060605049, "episode/length": 150.0, "episode/score": 0.16722983360477883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16722983360477883}
{"step": 547976, "time": 27876.71489715576, "episode/length": 184.0, "episode/score": 0.19365879291808596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19365879291808596}
{"step": 547992, "time": 27878.84393620491, "episode/length": 157.0, "episode/score": 0.17499882005540712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17499882005540712}
{"step": 548200, "time": 27888.139717817307, "episode/length": 194.0, "episode/score": 0.1963558019051561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1963558019051561}
{"step": 548656, "time": 27906.76746058464, "episode/length": 145.0, "episode/score": 0.15882848526962334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15882848526962334}
{"step": 548728, "time": 27910.763393878937, "episode/length": 156.0, "episode/score": 0.1623007536231853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1623007536231853}
{"step": 549280, "time": 27934.7719540596, "episode/length": 162.0, "episode/score": 0.1818779191835347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1818779191835347}
{"step": 549296, "time": 27936.86493062973, "episode/length": 167.0, "episode/score": 0.16213363065162412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16213363065162412}
{"step": 549520, "time": 27947.027951478958, "episode/length": 239.0, "episode/score": 0.2760072928867885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2760072928867885}
{"step": 549584, "time": 27950.937695980072, "episode/length": 172.0, "episode/score": 0.18250386841236832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18250386841236832}
{"step": 549688, "time": 27956.123586416245, "episode/length": 227.0, "episode/score": 0.25200464317003934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25200464317003934}
{"step": 549800, "time": 27961.85272192955, "episode/length": 225.0, "episode/score": 0.2517368700791849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2517368700791849}
{"step": 550024, "time": 27971.74928879738, "episode/length": 170.0, "episode/score": 0.19305407056435797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19305407056435797}
{"step": 550056, "time": 27992.97407579422, "eval_episode/length": 99.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.95}
{"step": 550056, "time": 27995.236025571823, "eval_episode/length": 114.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 550056, "time": 27997.761165857315, "eval_episode/length": 136.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 550056, "time": 27999.570253133774, "eval_episode/length": 142.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.965034965034965}
{"step": 550056, "time": 28002.46463394165, "eval_episode/length": 170.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 550056, "time": 28004.278856515884, "eval_episode/length": 175.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 550056, "time": 28006.438727140427, "eval_episode/length": 189.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 550056, "time": 28009.515879154205, "eval_episode/length": 226.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 550344, "time": 28020.179214000702, "episode/length": 201.0, "episode/score": 0.20370077956386012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20370077956386012}
{"step": 550640, "time": 28033.01543569565, "episode/length": 169.0, "episode/score": 0.16808821375843763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16808821375843763}
{"step": 550680, "time": 28035.96044397354, "episode/length": 172.0, "episode/score": 0.1890772806145833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1890772806145833}
{"step": 550896, "time": 28045.662945747375, "episode/length": 136.0, "episode/score": 0.158361919995059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.158361919995059}
{"step": 550904, "time": 28047.424300909042, "episode/length": 164.0, "episode/score": 0.1700249235850606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1700249235850606}
{"step": 551008, "time": 28053.148501873016, "episode/length": 185.0, "episode/score": 0.19156071959196197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19156071959196197}
{"step": 551072, "time": 28057.1228222847, "episode/length": 172.0, "episode/score": 0.191716201066356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191716201066356}
{"step": 551328, "time": 28068.309518814087, "episode/length": 162.0, "episode/score": 0.1883058408566285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1883058408566285}
{"step": 551552, "time": 28078.224432229996, "episode/length": 150.0, "episode/score": 0.14273639043176445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14273639043176445}
{"step": 551600, "time": 28081.639935970306, "episode/length": 73.0, "episode/score": 0.08770833146991208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08770833146991208}
{"step": 551680, "time": 28086.17849302292, "episode/length": 129.0, "episode/score": 0.12950303853085643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12950303853085643}
{"step": 552072, "time": 28102.125885009766, "episode/length": 173.0, "episode/score": 0.18058210330218571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18058210330218571}
{"step": 552368, "time": 28114.891944885254, "episode/length": 183.0, "episode/score": 0.20900016530549692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20900016530549692}
{"step": 552464, "time": 28119.975332260132, "episode/length": 173.0, "episode/score": 0.19452579815060744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19452579815060744}
{"step": 552576, "time": 28125.825914144516, "episode/length": 155.0, "episode/score": 0.16251028756505548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16251028756505548}
{"step": 552848, "time": 28137.481389522552, "episode/length": 242.0, "episode/score": 0.28018256655059304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28018256655059304}
{"step": 553016, "time": 28145.020647764206, "episode/length": 176.0, "episode/score": 0.1915290798674505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1915290798674505}
{"step": 553048, "time": 28147.843921661377, "episode/length": 186.0, "episode/score": 0.2106366591870028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2106366591870028}
{"step": 553136, "time": 28153.071446418762, "episode/length": 181.0, "episode/score": 0.20063247675352613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20063247675352613}
{"step": 553672, "time": 28174.67033314705, "episode/length": 150.0, "episode/score": 0.14898062224165187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14898062224165187}
{"step": 553680, "time": 28177.231790542603, "episode/length": 200.0, "episode/score": 0.22687137732600604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22687137732600604}
{"step": 553752, "time": 28181.761769533157, "episode/length": 172.0, "episode/score": 0.17819552421860863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17819552421860863}
{"step": 553960, "time": 28191.528726816177, "episode/length": 172.0, "episode/score": 0.18329910121974535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18329910121974535}
{"step": 554016, "time": 28195.454338550568, "episode/length": 120.0, "episode/score": 0.14416666387114674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14416666387114674}
{"step": 554392, "time": 28210.80268239975, "episode/length": 192.0, "episode/score": 0.210899950361636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.210899950361636}
{"step": 554568, "time": 28218.923079252243, "episode/length": 178.0, "episode/score": 0.20619852588424692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20619852588424692}
{"step": 555080, "time": 28239.53902196884, "episode/length": 174.0, "episode/score": 0.20153266620036447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20153266620036447}
{"step": 555176, "time": 28244.8675429821, "episode/length": 144.0, "episode/score": 0.17229166335891932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17229166335891932}
{"step": 555176, "time": 28244.874742507935, "episode/length": 151.0, "episode/score": 0.16207829976337962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16207829976337962}
{"step": 555248, "time": 28251.191746473312, "episode/length": 278.0, "episode/score": 0.3213891810228233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3213891810228233}
{"step": 555664, "time": 28268.16915988922, "episode/length": 248.0, "episode/score": 0.29396428015024867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29396428015024867}
{"step": 556040, "time": 28283.592366456985, "episode/length": 183.0, "episode/score": 0.20516760489772423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20516760489772423}
{"step": 556368, "time": 28297.54915046692, "episode/length": 160.0, "episode/score": 0.18316531936216052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18316531936216052}
{"step": 556456, "time": 28302.388800621033, "episode/length": 159.0, "episode/score": 0.16267810704448493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16267810704448493}
{"step": 556640, "time": 28311.171317338943, "episode/length": 280.0, "episode/score": 0.3127260267792735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3127260267792735}
{"step": 556784, "time": 28318.062722206116, "episode/length": 191.0, "episode/score": 0.19536590607640392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19536590607640392}
{"step": 556792, "time": 28319.77097249031, "episode/length": 201.0, "episode/score": 0.2242325444240123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2242325444240123}
{"step": 556976, "time": 28328.390592098236, "episode/length": 402.0, "episode/score": 0.4122282832468045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4122282832468045}
{"step": 557248, "time": 28341.7385802269, "episode/length": 197.0, "episode/score": 0.20017949072280317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20017949072280317}
{"step": 557456, "time": 28351.82578253746, "episode/length": 124.0, "episode/score": 0.14269254785904195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14269254785904195}
{"step": 557904, "time": 28371.099335193634, "episode/length": 232.0, "episode/score": 0.2583894296330982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2583894296330982}
{"step": 558008, "time": 28376.738879203796, "episode/length": 204.0, "episode/score": 0.19529342634268687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19529342634268687}
{"step": 558072, "time": 28380.788343906403, "episode/length": 178.0, "episode/score": 0.1868659936299082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1868659936299082}
{"step": 558112, "time": 28384.095331430435, "episode/length": 165.0, "episode/score": 0.1787980792360031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1787980792360031}
{"step": 558168, "time": 28387.454393148422, "episode/length": 171.0, "episode/score": 0.18088988101953873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18088988101953873}
{"step": 558472, "time": 28400.401765346527, "episode/length": 186.0, "episode/score": 0.2214999957359396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2214999957359396}
{"step": 558624, "time": 28407.882781028748, "episode/length": 171.0, "episode/score": 0.18119772193767858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18119772193767858}
{"step": 558840, "time": 28417.29994249344, "episode/length": 172.0, "episode/score": 0.1859029551869753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1859029551869753}
{"step": 558904, "time": 28421.351799726486, "episode/length": 111.0, "episode/score": 0.13067690038769797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13067690038769797}
{"step": 559480, "time": 28445.58158493042, "episode/length": 163.0, "episode/score": 0.18763717802903557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18763717802903557}
{"step": 559528, "time": 28448.857533454895, "episode/length": 176.0, "episode/score": 0.20478063803784607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20478063803784607}
{"step": 559592, "time": 28452.889323472977, "episode/length": 189.0, "episode/score": 0.21883290262849187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21883290262849187}
{"step": 559624, "time": 28455.702303409576, "episode/length": 214.0, "episode/score": 0.22548413868844364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22548413868844364}
{"step": 559928, "time": 28468.82275247574, "episode/length": 181.0, "episode/score": 0.18269954351308115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18269954351308115}
{"step": 560040, "time": 28494.164225816727, "eval_episode/length": 136.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 560040, "time": 28496.51028776169, "eval_episode/length": 144.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.993103448275862}
{"step": 560040, "time": 28499.441471338272, "eval_episode/length": 161.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 560040, "time": 28502.939346075058, "eval_episode/length": 190.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 560040, "time": 28505.155024290085, "eval_episode/length": 194.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 560040, "time": 28507.277412891388, "eval_episode/length": 196.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 560040, "time": 28510.74363207817, "eval_episode/length": 227.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 560040, "time": 28513.789979457855, "eval_episode/length": 249.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.968}
{"step": 560041, "time": 28514.946360826492, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.985455078125, "train/action_min": 0.0, "train/action_std": 4.781400211334229, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007883342932909727, "train/actor_opt_grad_steps": 34280.0, "train/actor_opt_loss": -12.242050688147545, "train/adv_mag": 0.175630326628685, "train/adv_max": 0.1244162939786911, "train/adv_mean": -0.00013381262528855588, "train/adv_min": -0.17449886643886567, "train/adv_std": 0.013401925921440124, "train/cont_avg": 0.9946953125, "train/cont_loss_mean": 0.00018995374166104283, "train/cont_loss_std": 0.005742542983540261, "train/cont_neg_acc": 0.9937015881538391, "train/cont_neg_loss": 0.019118474020975555, "train/cont_pos_acc": 0.999984257221222, "train/cont_pos_loss": 7.378342024190942e-05, "train/cont_pred": 0.9947092986106872, "train/cont_rate": 0.9946953125, "train/dyn_loss_mean": 11.729571266174316, "train/dyn_loss_std": 8.257010585784911, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13071583527326583, "train/extr_critic_critic_opt_grad_steps": 34280.0, "train/extr_critic_critic_opt_loss": 12178.755984375, "train/extr_critic_mag": 0.28073538208007814, "train/extr_critic_max": 0.28073538208007814, "train/extr_critic_mean": 0.22953862011432646, "train/extr_critic_min": 0.002366572380065918, "train/extr_critic_std": 0.05829653951525688, "train/extr_return_normed_mag": 0.20239117562770845, "train/extr_return_normed_max": 0.20239117562770845, "train/extr_return_normed_mean": 0.15173665964603425, "train/extr_return_normed_min": -0.07667048525810241, "train/extr_return_normed_std": 0.05998561438918114, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2800593149662018, "train/extr_return_raw_max": 0.2800593149662018, "train/extr_return_raw_mean": 0.22940480268001556, "train/extr_return_raw_min": 0.0009976539611816406, "train/extr_return_raw_std": 0.05998561438918114, "train/extr_reward_mag": 0.0013474740982055665, "train/extr_reward_max": 0.0013474740982055665, "train/extr_reward_mean": 0.0010966413728892804, "train/extr_reward_min": 1.096820831298828e-05, "train/extr_reward_std": 0.00023177273233886809, "train/image_loss_mean": 5.603405996322632, "train/image_loss_std": 9.937956562042237, "train/model_loss_mean": 12.681521987915039, "train/model_loss_std": 13.378073493957519, "train/model_opt_grad_norm": 55.96597599792481, "train/model_opt_grad_steps": 34246.496, "train/model_opt_loss": 16138.46484375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1270.0, "train/policy_entropy_mag": 2.7618612823486326, "train/policy_entropy_max": 2.7618612823486326, "train/policy_entropy_mean": 2.1849735527038576, "train/policy_entropy_min": 0.08010145682096481, "train/policy_entropy_std": 0.5641973741054535, "train/policy_logprob_mag": 7.438176490783691, "train/policy_logprob_max": -0.009555855348706245, "train/policy_logprob_mean": -2.184046998023987, "train/policy_logprob_min": -7.438176490783691, "train/policy_logprob_std": 1.084255774974823, "train/policy_randomness_mag": 0.9748158326148987, "train/policy_randomness_max": 0.9748158326148987, "train/policy_randomness_mean": 0.771199779510498, "train/policy_randomness_min": 0.0282722992002964, "train/policy_randomness_std": 0.19913691341876982, "train/post_ent_mag": 56.35633239746094, "train/post_ent_max": 56.35633239746094, "train/post_ent_mean": 39.616807373046875, "train/post_ent_min": 19.964784530639648, "train/post_ent_std": 6.726685085296631, "train/prior_ent_mag": 65.58645837402344, "train/prior_ent_max": 65.58645837402344, "train/prior_ent_mean": 51.39210876464844, "train/prior_ent_min": 30.1053274230957, "train/prior_ent_std": 5.482905372619629, "train/rep_loss_mean": 11.729571266174316, "train/rep_loss_std": 8.257010585784911, "train/reward_avg": 0.0010642989752814175, "train/reward_loss_mean": 0.040183341145515444, "train/reward_loss_std": 0.011063469372689724, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013006753921508789, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04018334093689919, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010644036494195461, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.9037383005162266, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.205607476635514, "train_stats/max_log_achievement_collect_sapling": 0.8504672897196262, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5327102803738317, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.4485981308411215, "train_stats/max_log_achievement_place_table": 0.04672897196261682, "train_stats/max_log_achievement_wake_up": 0.18691588785046728, "train_stats/mean_log_entropy": 2.217977328835247, "eval_stats/sum_log_reward": 0.16249996982514858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.1875, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00012304502888582647, "report/cont_loss_std": 0.003892455017194152, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00018985927454195917, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0001227830071002245, "report/cont_pred": 0.9959795475006104, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.354711532592773, "report/dyn_loss_std": 8.07241153717041, "report/image_loss_mean": 4.654392242431641, "report/image_loss_std": 7.881907939910889, "report/model_loss_mean": 10.905827522277832, "report/model_loss_std": 11.194122314453125, "report/post_ent_mag": 57.73737335205078, "report/post_ent_max": 57.73737335205078, "report/post_ent_mean": 39.685997009277344, "report/post_ent_min": 20.44404411315918, "report/post_ent_std": 6.448207855224609, "report/prior_ent_mag": 65.80399322509766, "report/prior_ent_max": 65.80399322509766, "report/prior_ent_mean": 50.36516189575195, "report/prior_ent_min": 29.642234802246094, "report/prior_ent_std": 6.2094621658325195, "report/rep_loss_mean": 10.354711532592773, "report/rep_loss_std": 8.07241153717041, "report/reward_avg": 0.0010141587117686868, "report/reward_loss_mean": 0.03848570957779884, "report/reward_loss_std": 0.012652609497308731, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001295328140258789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03848570957779884, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010420152684673667, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.1696336577624606e-07, "eval/cont_loss_std": 2.8886565814900678e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.410725862020627e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.116985768907398e-07, "eval/cont_pred": 0.9980468153953552, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.50679874420166, "eval/dyn_loss_std": 9.241266250610352, "eval/image_loss_mean": 7.199690818786621, "eval/image_loss_std": 10.303372383117676, "eval/model_loss_mean": 16.301998138427734, "eval/model_loss_std": 14.23796272277832, "eval/post_ent_mag": 54.71832275390625, "eval/post_ent_max": 54.71832275390625, "eval/post_ent_mean": 39.29743194580078, "eval/post_ent_min": 19.360193252563477, "eval/post_ent_std": 6.769007205963135, "eval/prior_ent_mag": 65.80399322509766, "eval/prior_ent_max": 65.80399322509766, "eval/prior_ent_mean": 51.729248046875, "eval/prior_ent_min": 28.605918884277344, "eval/prior_ent_std": 4.9063191413879395, "eval/rep_loss_mean": 14.50679874420166, "eval/rep_loss_std": 9.241266250610352, "eval/reward_avg": 0.0068359375, "eval/reward_loss_mean": 0.39822694659233093, "eval/reward_loss_std": 2.789947271347046, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012853145599365234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.21810388565063477, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.712106704711914, "eval/reward_pred": 0.0010129467118531466, "eval/reward_rate": 0.0087890625, "replay/size": 559537.0, "replay/inserts": 19952.0, "replay/samples": 19952.0, "replay/insert_wait_avg": 1.4059669797479772e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.013646126558232e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2153349582504177e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3008098602295, "timer/env.step_count": 2494.0, "timer/env.step_total": 240.0628697872162, "timer/env.step_frac": 0.23975099932329658, "timer/env.step_avg": 0.09625616270537939, "timer/env.step_min": 0.02310919761657715, "timer/env.step_max": 3.4504106044769287, "timer/replay._sample_count": 19952.0, "timer/replay._sample_total": 9.558609247207642, "timer/replay._sample_frac": 0.009546191467219444, "timer/replay._sample_avg": 0.0004790802549723156, "timer/replay._sample_min": 0.0003635883331298828, "timer/replay._sample_max": 0.0286102294921875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2971.0, "timer/agent.policy_total": 49.34543538093567, "timer/agent.policy_frac": 0.049281329741282985, "timer/agent.policy_avg": 0.01660903244057074, "timer/agent.policy_min": 0.009315252304077148, "timer/agent.policy_max": 0.17946457862854004, "timer/dataset_train_count": 1247.0, "timer/dataset_train_total": 0.13642430305480957, "timer/dataset_train_frac": 0.000136247071520748, "timer/dataset_train_avg": 0.00010940200726127472, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0002105236053466797, "timer/agent.train_count": 1247.0, "timer/agent.train_total": 561.3421394824982, "timer/agent.train_frac": 0.5606128887090936, "timer/agent.train_avg": 0.4501540813813137, "timer/agent.train_min": 0.43590307235717773, "timer/agent.train_max": 1.0361459255218506, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47330641746520996, "timer/agent.report_frac": 0.0004726915356547832, "timer/agent.report_avg": 0.23665320873260498, "timer/agent.report_min": 0.22987651824951172, "timer/agent.report_max": 0.24342989921569824, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.476389133619805e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 19.925799591436448}
{"step": 560328, "time": 28525.753586292267, "episode/length": 105.0, "episode/score": 0.1233665289619239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1233665289619239}
{"step": 560408, "time": 28530.281999111176, "episode/length": 187.0, "episode/score": 0.192746093968708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.192746093968708}
{"step": 560640, "time": 28540.707466363907, "episode/length": 251.0, "episode/score": 0.2823834505115883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2823834505115883}
{"step": 560840, "time": 28549.445466518402, "episode/length": 163.0, "episode/score": 0.18250255334442045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18250255334442045}
{"step": 560896, "time": 28553.380300283432, "episode/length": 256.0, "episode/score": 0.2911876425960145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2911876425960145}
{"step": 561104, "time": 28562.64963197708, "episode/length": 86.0, "episode/score": 0.0994772710109828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0994772710109828}
{"step": 561224, "time": 28568.462126493454, "episode/length": 203.0, "episode/score": 0.23723883819729963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23723883819729963}
{"step": 561456, "time": 28579.101872205734, "episode/length": 228.0, "episode/score": 0.22169262785519095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22169262785519095}
{"step": 561544, "time": 28584.39647769928, "episode/length": 201.0, "episode/score": 0.21605717144484515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21605717144484515}
{"step": 561600, "time": 28588.745003461838, "episode/length": 158.0, "episode/score": 0.1702392588067596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1702392588067596}
{"step": 561936, "time": 28603.108119010925, "episode/length": 161.0, "episode/score": 0.18244485122522747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18244485122522747}
{"step": 562224, "time": 28615.508710622787, "episode/length": 172.0, "episode/score": 0.20697726872458588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20697726872458588}
{"step": 562272, "time": 28618.81003832817, "episode/length": 171.0, "episode/score": 0.19370039354544133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19370039354544133}
{"step": 562320, "time": 28622.214810609818, "episode/length": 151.0, "episode/score": 0.1637152754701674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637152754701674}
{"step": 562704, "time": 28638.20306444168, "episode/length": 144.0, "episode/score": 0.15661130723310634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15661130723310634}
{"step": 562720, "time": 28640.85576081276, "episode/length": 49.0, "episode/score": 0.05716666567604989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05716666567604989}
{"step": 562888, "time": 28649.091632127762, "episode/length": 82.0, "episode/score": 0.09609550674576894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09609550674576894}
{"step": 562952, "time": 28653.424332141876, "episode/length": 186.0, "episode/score": 0.1987899154992192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1987899154992192}
{"step": 563352, "time": 28669.856590032578, "episode/length": 176.0, "episode/score": 0.19145489930087933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19145489930087933}
{"step": 563616, "time": 28681.336002111435, "episode/length": 167.0, "episode/score": 0.18741811788640916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18741811788640916}
{"step": 563672, "time": 28684.7576444149, "episode/length": 258.0, "episode/score": 0.285187008419598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.285187008419598}
{"step": 563952, "time": 28697.05588531494, "episode/length": 132.0, "episode/score": 0.15579310050816275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15579310050816275}
{"step": 564048, "time": 28702.176925182343, "episode/length": 165.0, "episode/score": 0.1918719962486648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1918719962486648}
{"step": 564184, "time": 28708.616411924362, "episode/length": 184.0, "episode/score": 0.21518860435389797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21518860435389797}
{"step": 564456, "time": 28720.34659934044, "episode/length": 187.0, "episode/score": 0.18917946650617523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18917946650617523}
{"step": 564568, "time": 28726.153000593185, "episode/length": 417.0, "episode/score": 0.4460845484663878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4460845484663878}
{"step": 564960, "time": 28742.73020219803, "episode/length": 167.0, "episode/score": 0.17027036223589676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17027036223589676}
{"step": 564976, "time": 28745.372153759003, "episode/length": 127.0, "episode/score": 0.13971860945275694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13971860945275694}
{"step": 565272, "time": 28759.72050690651, "episode/length": 199.0, "episode/score": 0.2168333462868759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2168333462868759}
{"step": 565416, "time": 28766.640620708466, "episode/length": 153.0, "episode/score": 0.1646201152325375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1646201152325375}
{"step": 565472, "time": 28770.466881990433, "episode/length": 112.0, "episode/score": 0.128976416104706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.128976416104706}
{"step": 565584, "time": 28776.156034708023, "episode/length": 140.0, "episode/score": 0.15597798722592415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15597798722592415}
{"step": 565592, "time": 28777.814611673355, "episode/length": 192.0, "episode/score": 0.22890500366702327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22890500366702327}
{"step": 565640, "time": 28781.104877471924, "episode/length": 285.0, "episode/score": 0.29196760659397114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29196760659397114}
{"step": 565984, "time": 28795.60865163803, "episode/length": 127.0, "episode/score": 0.14840119162545307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14840119162545307}
{"step": 566544, "time": 28818.115458726883, "episode/length": 195.0, "episode/score": 0.2142757276451448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2142757276451448}
{"step": 566664, "time": 28823.836412668228, "episode/length": 173.0, "episode/score": 0.19126610341481864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19126610341481864}
{"step": 566672, "time": 28825.903765916824, "episode/length": 156.0, "episode/score": 0.18173101531283464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18173101531283464}
{"step": 566856, "time": 28834.055334091187, "episode/length": 157.0, "episode/score": 0.16129838686902076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16129838686902076}
{"step": 567048, "time": 28842.71590089798, "episode/length": 182.0, "episode/score": 0.1998366197803989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1998366197803989}
{"step": 567368, "time": 28856.43483686447, "episode/length": 172.0, "episode/score": 0.17873354789117002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17873354789117002}
{"step": 567640, "time": 28868.188527584076, "episode/length": 249.0, "episode/score": 0.2834507832158124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2834507832158124}
{"step": 567744, "time": 28873.80208325386, "episode/length": 283.0, "episode/score": 0.3216278077161405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3216278077161405}
{"step": 568064, "time": 28887.51860976219, "episode/length": 174.0, "episode/score": 0.17551881770486943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17551881770486943}
{"step": 568368, "time": 28900.52863907814, "episode/length": 188.0, "episode/score": 0.20838111378907342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20838111378907342}
{"step": 568488, "time": 28906.42881989479, "episode/length": 179.0, "episode/score": 0.20684955780598102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20684955780598102}
{"step": 568520, "time": 28909.176754951477, "episode/length": 230.0, "episode/score": 0.26066366874147207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26066366874147207}
{"step": 568648, "time": 28915.440472841263, "episode/length": 159.0, "episode/score": 0.16987999250704888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16987999250704888}
{"step": 568872, "time": 28925.321660518646, "episode/length": 290.0, "episode/score": 0.32542523060328676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32542523060328676}
{"step": 569168, "time": 28938.364046812057, "episode/length": 177.0, "episode/score": 0.2040902743465267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2040902743465267}
{"step": 569328, "time": 28946.364550113678, "episode/length": 210.0, "episode/score": 0.2502094108349411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2502094108349411}
{"step": 569424, "time": 28951.524980545044, "episode/length": 96.0, "episode/score": 0.11399139988498064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11399139988498064}
{"step": 569736, "time": 28964.61933851242, "episode/length": 170.0, "episode/score": 0.1825458623789018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1825458623789018}
{"step": 569952, "time": 28974.398134708405, "episode/length": 178.0, "episode/score": 0.19712455048284028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19712455048284028}
{"step": 570024, "time": 28995.873227596283, "eval_episode/length": 100.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9504950495049505}
{"step": 570024, "time": 28999.48320698738, "eval_episode/length": 148.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 570024, "time": 29001.766924381256, "eval_episode/length": 164.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 570024, "time": 29003.563568115234, "eval_episode/length": 170.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 570024, "time": 29005.458645105362, "eval_episode/length": 178.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.994413407821229}
{"step": 570024, "time": 29006.945803642273, "eval_episode/length": 179.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 570024, "time": 29009.118961572647, "eval_episode/length": 196.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 570024, "time": 29011.081449985504, "eval_episode/length": 42.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8837209302325582}
{"step": 570064, "time": 29012.827104330063, "episode/length": 196.0, "episode/score": 0.21856039202248212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21856039202248212}
{"step": 570080, "time": 29014.979289770126, "episode/length": 251.0, "episode/score": 0.27654002148483414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27654002148483414}
{"step": 570376, "time": 29027.554495334625, "episode/length": 187.0, "episode/score": 0.19317083257919876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19317083257919876}
{"step": 570728, "time": 29042.31196284294, "episode/length": 174.0, "episode/score": 0.17434843484079465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17434843484079465}
{"step": 571008, "time": 29054.99046278, "episode/length": 158.0, "episode/score": 0.15544032159959897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15544032159959897}
{"step": 571040, "time": 29058.250307559967, "episode/length": 201.0, "episode/score": 0.23858072472648928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23858072472648928}
{"step": 571216, "time": 29067.097130060196, "episode/length": 141.0, "episode/score": 0.16330555257445667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16330555257445667}
{"step": 571648, "time": 29085.68958234787, "episode/length": 211.0, "episode/score": 0.2465343117073644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2465343117073644}
{"step": 571688, "time": 29088.452933073044, "episode/length": 202.0, "episode/score": 0.22372618706140202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22372618706140202}
{"step": 571848, "time": 29095.975348472595, "episode/length": 139.0, "episode/score": 0.14261456886015367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14261456886015367}
{"step": 572024, "time": 29104.098295927048, "episode/length": 205.0, "episode/score": 0.22770036016299855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22770036016299855}
{"step": 572288, "time": 29115.814464092255, "episode/length": 159.0, "episode/score": 0.1641027075565944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1641027075565944}
{"step": 572392, "time": 29121.092296123505, "episode/length": 402.0, "episode/score": 0.4137909103119455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4137909103119455}
{"step": 572560, "time": 29129.24445295334, "episode/length": 167.0, "episode/score": 0.16875904795961105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16875904795961105}
{"step": 572808, "time": 29139.85192465782, "episode/length": 144.0, "episode/score": 0.16332145402884635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16332145402884635}
{"step": 573120, "time": 29153.29822254181, "episode/length": 158.0, "episode/score": 0.17763095522059302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17763095522059302}
{"step": 573176, "time": 29156.719729185104, "episode/length": 266.0, "episode/score": 0.27525586740739527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27525586740739527}
{"step": 573200, "time": 29159.427506923676, "episode/length": 188.0, "episode/score": 0.19769460186944343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19769460186944343}
{"step": 573448, "time": 29170.68383359909, "episode/length": 177.0, "episode/score": 0.1854571879557625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1854571879557625}
{"step": 573768, "time": 29185.37717604637, "episode/length": 184.0, "episode/score": 0.2052108164771198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2052108164771198}
{"step": 573776, "time": 29187.589437246323, "episode/length": 172.0, "episode/score": 0.1965421701042942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1965421701042942}
{"step": 574040, "time": 29199.075722694397, "episode/length": 153.0, "episode/score": 0.17364331136559485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17364331136559485}
{"step": 574056, "time": 29201.679645061493, "episode/length": 186.0, "episode/score": 0.1957865989243146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1957865989243146}
{"step": 574424, "time": 29218.053698062897, "episode/length": 152.0, "episode/score": 0.1574692142839922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1574692142839922}
{"step": 574432, "time": 29220.55694103241, "episode/length": 46.0, "episode/score": 0.04988739843247458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04988739843247458}
{"step": 574440, "time": 29222.7693836689, "episode/length": 157.0, "episode/score": 0.17063445090025198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17063445090025198}
{"step": 574552, "time": 29229.011942625046, "episode/length": 178.0, "episode/score": 0.2024543545958295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2024543545958295}
{"step": 574904, "time": 29244.455940246582, "episode/length": 181.0, "episode/score": 0.1857896366109344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1857896366109344}
{"step": 575056, "time": 29251.838135242462, "episode/length": 160.0, "episode/score": 0.16779461431906384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16779461431906384}
{"step": 575104, "time": 29255.15516781807, "episode/length": 68.0, "episode/score": 0.08312499837484211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08312499837484211}
{"step": 575496, "time": 29271.079657316208, "episode/length": 181.0, "episode/score": 0.18746187454780738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18746187454780738}
{"step": 575784, "time": 29283.317930698395, "episode/length": 250.0, "episode/score": 0.29494628888460284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29494628888460284}
{"step": 575784, "time": 29283.32498383522, "episode/length": 167.0, "episode/score": 0.15677527234674926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15677527234674926}
{"step": 575864, "time": 29289.586354017258, "episode/length": 179.0, "episode/score": 0.18998834500416706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18998834500416706}
{"step": 576216, "time": 29304.21856021881, "episode/length": 222.0, "episode/score": 0.25688281043858296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25688281043858296}
{"step": 576304, "time": 29309.331019878387, "episode/length": 174.0, "episode/score": 0.18818520254626492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18818520254626492}
{"step": 576344, "time": 29312.14600777626, "episode/length": 160.0, "episode/score": 0.16701603051114944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16701603051114944}
{"step": 576640, "time": 29325.209366083145, "episode/length": 191.0, "episode/score": 0.21235964289098774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21235964289098774}
{"step": 576864, "time": 29335.057485818863, "episode/length": 170.0, "episode/score": 0.1768325493158045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768325493158045}
{"step": 577112, "time": 29345.665608406067, "episode/length": 155.0, "episode/score": 0.1846137899274254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846137899274254}
{"step": 577224, "time": 29351.29232788086, "episode/length": 179.0, "episode/score": 0.1809839291336175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809839291336175}
{"step": 577296, "time": 29355.848791837692, "episode/length": 134.0, "episode/score": 0.159339145577178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159339145577178}
{"step": 577552, "time": 29366.914017677307, "episode/length": 150.0, "episode/score": 0.1633451477791823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1633451477791823}
{"step": 577648, "time": 29372.067158460617, "episode/length": 232.0, "episode/score": 0.26400347657181555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26400347657181555}
{"step": 577960, "time": 29385.05672121048, "episode/length": 164.0, "episode/score": 0.17271050001545518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17271050001545518}
{"step": 578528, "time": 29407.989774942398, "episode/length": 176.0, "episode/score": 0.19566190551176987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19566190551176987}
{"step": 578632, "time": 29413.21151638031, "episode/length": 175.0, "episode/score": 0.21210259699182643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21210259699182643}
{"step": 578688, "time": 29417.266535043716, "episode/length": 297.0, "episode/score": 0.33864799446564575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33864799446564575}
{"step": 578872, "time": 29425.54311966896, "episode/length": 196.0, "episode/score": 0.21061669168011576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21061669168011576}
{"step": 578936, "time": 29429.427810668945, "episode/length": 172.0, "episode/score": 0.19492444730713032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19492444730713032}
{"step": 579088, "time": 29436.870399951935, "episode/length": 179.0, "episode/score": 0.19591044865956064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19591044865956064}
{"step": 579440, "time": 29451.692268133163, "episode/length": 184.0, "episode/score": 0.20277777123556007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20277777123556007}
{"step": 579904, "time": 29470.852437496185, "episode/length": 171.0, "episode/score": 0.18655332743946929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18655332743946929}
{"step": 579912, "time": 29472.46749806404, "episode/length": 152.0, "episode/score": 0.1646187270525843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1646187270525843}
{"step": 579976, "time": 29476.627002716064, "episode/length": 388.0, "episode/score": 0.3346816154744374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3346816154744374}
{"step": 580008, "time": 29499.1093916893, "eval_episode/length": 152.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 580008, "time": 29501.157211065292, "eval_episode/length": 162.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 580008, "time": 29502.9158911705, "eval_episode/length": 165.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 580008, "time": 29505.336588144302, "eval_episode/length": 183.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 580008, "time": 29507.40969800949, "eval_episode/length": 194.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 580008, "time": 29508.97261095047, "eval_episode/length": 197.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 580008, "time": 29511.43219590187, "eval_episode/length": 219.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 580008, "time": 29513.734843969345, "eval_episode/length": 234.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 580025, "time": 29515.379154920578, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.15880224609375, "train/action_min": 0.0, "train/action_std": 4.919393402099609, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007964356854557991, "train/actor_opt_grad_steps": 35530.0, "train/actor_opt_loss": -6.61812280011177, "train/adv_mag": 0.18070975077152251, "train/adv_max": 0.1251320514678955, "train/adv_mean": 0.000170759852619085, "train/adv_min": -0.179623443543911, "train/adv_std": 0.013457890089601278, "train/cont_avg": 0.9946015625, "train/cont_loss_mean": 0.00031895467680328695, "train/cont_loss_std": 0.009830045663409124, "train/cont_neg_acc": 0.9894489256605026, "train/cont_neg_loss": 0.05695058255608479, "train/cont_pos_acc": 0.99998424243927, "train/cont_pos_loss": 7.714570941902821e-05, "train/cont_pred": 0.9946382389068603, "train/cont_rate": 0.9946015625, "train/dyn_loss_mean": 11.679062210083007, "train/dyn_loss_std": 8.311302143096924, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14392510272562503, "train/extr_critic_critic_opt_grad_steps": 35530.0, "train/extr_critic_critic_opt_loss": 12310.396140625, "train/extr_critic_mag": 0.2794900302886963, "train/extr_critic_max": 0.2794900302886963, "train/extr_critic_mean": 0.23107601583003998, "train/extr_critic_min": 0.00278083610534668, "train/extr_critic_std": 0.05703841686248779, "train/extr_return_normed_mag": 0.2001498771905899, "train/extr_return_normed_max": 0.2001498771905899, "train/extr_return_normed_mean": 0.15304973411560058, "train/extr_return_normed_min": -0.07717506873607635, "train/extr_return_normed_std": 0.05865722350776195, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.278346928358078, "train/extr_return_raw_max": 0.278346928358078, "train/extr_return_raw_mean": 0.23124678874015808, "train/extr_return_raw_min": 0.001021982192993164, "train/extr_return_raw_std": 0.058657223775982856, "train/extr_reward_mag": 0.0013537807464599609, "train/extr_reward_max": 0.0013537807464599609, "train/extr_reward_mean": 0.001090194119140506, "train/extr_reward_min": 1.0594367980957031e-05, "train/extr_reward_std": 0.0002395949502242729, "train/image_loss_mean": 5.355713924407959, "train/image_loss_std": 9.85357808303833, "train/model_loss_mean": 12.40364247894287, "train/model_loss_std": 13.340760406494141, "train/model_opt_grad_norm": 53.7043885345459, "train/model_opt_grad_steps": 35495.296, "train/model_opt_loss": 15504.5531328125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.7610134353637696, "train/policy_entropy_max": 2.7610134353637696, "train/policy_entropy_mean": 2.194843363761902, "train/policy_entropy_min": 0.0798355183005333, "train/policy_entropy_std": 0.5594491040706635, "train/policy_logprob_mag": 7.438217376708985, "train/policy_logprob_max": -0.009519960038363933, "train/policy_logprob_mean": -2.1946428394317627, "train/policy_logprob_min": -7.438217376708985, "train/policy_logprob_std": 1.072439419746399, "train/policy_randomness_mag": 0.974516577720642, "train/policy_randomness_max": 0.974516577720642, "train/policy_randomness_mean": 0.7746833853721619, "train/policy_randomness_min": 0.02817843447625637, "train/policy_randomness_std": 0.197460981965065, "train/post_ent_mag": 56.41692266845703, "train/post_ent_max": 56.41692266845703, "train/post_ent_mean": 39.64967138671875, "train/post_ent_min": 19.88531153869629, "train/post_ent_std": 6.691519874572754, "train/prior_ent_mag": 65.64203228759766, "train/prior_ent_max": 65.64203228759766, "train/prior_ent_mean": 51.393835205078126, "train/prior_ent_min": 30.067307708740234, "train/prior_ent_std": 5.457425056457519, "train/rep_loss_mean": 11.679062210083007, "train/rep_loss_std": 8.311302143096924, "train/reward_avg": 0.0010642408579587936, "train/reward_loss_mean": 0.04017232632637024, "train/reward_loss_std": 0.011126384735107422, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013129796981811524, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04017232608795166, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010640272255986929, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.8431192436896333, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.724770642201835, "train_stats/max_log_achievement_collect_sapling": 0.6972477064220184, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5504587155963303, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3394495412844037, "train_stats/max_log_achievement_place_table": 0.05504587155963303, "train_stats/max_log_achievement_wake_up": 0.1834862385321101, "train_stats/mean_log_entropy": 2.2077685375826075, "eval_stats/sum_log_reward": 0.7874999800696969, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.3125, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.511956141570408e-07, "report/cont_loss_std": 1.1533789802342653e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.010935173137113e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.127355796550546e-07, "report/cont_pred": 0.9951173663139343, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.725844383239746, "report/dyn_loss_std": 8.471354484558105, "report/image_loss_mean": 3.9752626419067383, "report/image_loss_std": 7.43731689453125, "report/model_loss_mean": 10.451057434082031, "report/model_loss_std": 11.125850677490234, "report/post_ent_mag": 57.54883575439453, "report/post_ent_max": 57.54883575439453, "report/post_ent_mean": 40.560935974121094, "report/post_ent_min": 18.81463623046875, "report/post_ent_std": 7.01655912399292, "report/prior_ent_mag": 65.38262176513672, "report/prior_ent_max": 65.38262176513672, "report/prior_ent_mean": 51.43326187133789, "report/prior_ent_min": 31.41815185546875, "report/prior_ent_std": 5.908374309539795, "report/rep_loss_mean": 10.725844383239746, "report/rep_loss_std": 8.471354484558105, "report/reward_avg": 0.0010666872840374708, "report/reward_loss_mean": 0.040288493037223816, "report/reward_loss_std": 0.0105789415538311, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040288493037223816, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010759109864011407, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0011901997495442629, "eval/cont_loss_std": 0.03805266320705414, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.2436738759279251, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.8758440723540843e-07, "eval/cont_pred": 0.9958046674728394, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.908409118652344, "eval/dyn_loss_std": 10.567442893981934, "eval/image_loss_mean": 11.798311233520508, "eval/image_loss_std": 16.137231826782227, "eval/model_loss_mean": 23.20624542236328, "eval/model_loss_std": 21.20440101623535, "eval/post_ent_mag": 52.9844856262207, "eval/post_ent_max": 52.9844856262207, "eval/post_ent_mean": 37.898765563964844, "eval/post_ent_min": 21.12024688720703, "eval/post_ent_std": 6.687079429626465, "eval/prior_ent_mag": 65.38262176513672, "eval/prior_ent_max": 65.38262176513672, "eval/prior_ent_mean": 52.46363830566406, "eval/prior_ent_min": 31.1243896484375, "eval/prior_ent_std": 4.292142868041992, "eval/rep_loss_mean": 17.908409118652344, "eval/rep_loss_std": 10.567442893981934, "eval/reward_avg": 0.0008789058774709702, "eval/reward_loss_mean": 0.6617019176483154, "eval/reward_loss_std": 3.564408540725708, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012753009796142578, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.54371178150177, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.680694580078125, "eval/reward_pred": 0.001046269666403532, "eval/reward_rate": 0.005859375, "replay/size": 579521.0, "replay/inserts": 19984.0, "replay/samples": 19984.0, "replay/insert_wait_avg": 1.3988241374349479e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.135986289947485e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.18408730552105e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4220824241638, "timer/env.step_count": 2498.0, "timer/env.step_total": 246.37467336654663, "timer/env.step_frac": 0.24627072682116938, "timer/env.step_avg": 0.09862877236451026, "timer/env.step_min": 0.02318596839904785, "timer/env.step_max": 3.300403118133545, "timer/replay._sample_count": 19984.0, "timer/replay._sample_total": 9.60389232635498, "timer/replay._sample_frac": 0.00959984040244633, "timer/replay._sample_avg": 0.0004805790795814142, "timer/replay._sample_min": 0.00039124488830566406, "timer/replay._sample_max": 0.026132583618164062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2941.0, "timer/agent.policy_total": 47.86862635612488, "timer/agent.policy_frac": 0.047848430374639914, "timer/agent.policy_avg": 0.016276309539654837, "timer/agent.policy_min": 0.009636402130126953, "timer/agent.policy_max": 0.10619711875915527, "timer/dataset_train_count": 1249.0, "timer/dataset_train_total": 0.14148378372192383, "timer/dataset_train_frac": 0.00014142409109871773, "timer/dataset_train_avg": 0.00011327764909681652, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.00036716461181640625, "timer/agent.train_count": 1249.0, "timer/agent.train_total": 561.6041958332062, "timer/agent.train_frac": 0.5613672525823901, "timer/agent.train_avg": 0.4496430711234637, "timer/agent.train_min": 0.43675875663757324, "timer/agent.train_max": 0.9819889068603516, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47447800636291504, "timer/agent.report_frac": 0.00047427782203006544, "timer/agent.report_avg": 0.23723900318145752, "timer/agent.report_min": 0.22993206977844238, "timer/agent.report_max": 0.24454593658447266, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.081031799316406e-05, "timer/dataset_eval_frac": 7.078044281227846e-08, "timer/dataset_eval_avg": 7.081031799316406e-05, "timer/dataset_eval_min": 7.081031799316406e-05, "timer/dataset_eval_max": 7.081031799316406e-05, "fps": 19.975317681657316}
{"step": 580264, "time": 29524.15998983383, "episode/length": 173.0, "episode/score": 0.18802170435446897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18802170435446897}
{"step": 580688, "time": 29542.037767887115, "episode/length": 199.0, "episode/score": 0.22868005549389636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22868005549389636}
{"step": 580688, "time": 29542.048389196396, "episode/length": 218.0, "episode/score": 0.2251000549258606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2251000549258606}
{"step": 581224, "time": 29566.162396669388, "episode/length": 163.0, "episode/score": 0.18951378484780435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18951378484780435}
{"step": 581336, "time": 29571.935165166855, "episode/length": 178.0, "episode/score": 0.1991474429196387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1991474429196387}
{"step": 581464, "time": 29579.010796308517, "episode/length": 185.0, "episode/score": 0.18195987316721585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18195987316721585}
{"step": 581776, "time": 29594.267515420914, "episode/length": 188.0, "episode/score": 0.20145008858526126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20145008858526126}
{"step": 581856, "time": 29598.90391612053, "episode/length": 301.0, "episode/score": 0.31705701793180197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31705701793180197}
{"step": 581856, "time": 29598.914238214493, "episode/length": 402.0, "episode/score": 0.4401814582015504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4401814582015504}
{"step": 582032, "time": 29609.02600646019, "episode/length": 167.0, "episode/score": 0.19981719383213203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19981719383213203}
{"step": 582048, "time": 29611.23300766945, "episode/length": 169.0, "episode/score": 0.1874649093078915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1874649093078915}
{"step": 582792, "time": 29640.87601542473, "episode/length": 195.0, "episode/score": 0.21680477173504187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21680477173504187}
{"step": 582944, "time": 29648.266216039658, "episode/length": 145.0, "episode/score": 0.15011938603856834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15011938603856834}
{"step": 582984, "time": 29651.06974363327, "episode/length": 140.0, "episode/score": 0.14728518731863005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14728518731863005}
{"step": 583056, "time": 29655.57875084877, "episode/length": 149.0, "episode/score": 0.164161642172985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.164161642172985}
{"step": 583152, "time": 29660.79324531555, "episode/length": 210.0, "episode/score": 0.22920678782247705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22920678782247705}
{"step": 583224, "time": 29664.88358092308, "episode/length": 235.0, "episode/score": 0.24927090021083131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24927090021083131}
{"step": 583376, "time": 29672.43367266655, "episode/length": 167.0, "episode/score": 0.1993749962421134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1993749962421134}
{"step": 583496, "time": 29678.802206277847, "episode/length": 54.0, "episode/score": 0.058198717179038795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058198717179038795}
{"step": 583976, "time": 29699.252332687378, "episode/length": 147.0, "episode/score": 0.16652537466507056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16652537466507056}
{"step": 584128, "time": 29706.80136871338, "episode/length": 259.0, "episode/score": 0.2936168539163191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2936168539163191}
{"step": 584248, "time": 29713.210500001907, "episode/length": 157.0, "episode/score": 0.16222929560171906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16222929560171906}
{"step": 584344, "time": 29718.980855226517, "episode/length": 174.0, "episode/score": 0.18609445520633017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18609445520633017}
{"step": 584440, "time": 29724.67333292961, "episode/length": 160.0, "episode/score": 0.16201963201456238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16201963201456238}
{"step": 584472, "time": 29727.461756944656, "episode/length": 155.0, "episode/score": 0.15423712351184804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15423712351184804}
{"step": 584504, "time": 29730.15700006485, "episode/length": 125.0, "episode/score": 0.1429172906355234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1429172906355234}
{"step": 584504, "time": 29730.162719488144, "episode/length": 65.0, "episode/score": 0.07529166544554755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07529166544554755}
{"step": 584864, "time": 29747.160733938217, "episode/length": 185.0, "episode/score": 0.18246660935983527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18246660935983527}
{"step": 585536, "time": 29774.032211780548, "episode/length": 128.0, "episode/score": 0.14820833067642525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14820833067642525}
{"step": 585696, "time": 29781.64120078087, "episode/length": 156.0, "episode/score": 0.16748005095723784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16748005095723784}
{"step": 585720, "time": 29783.920996665955, "episode/length": 183.0, "episode/score": 0.20020476831268752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20020476831268752}
{"step": 585808, "time": 29788.918446063995, "episode/length": 162.0, "episode/score": 0.16804983285692288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16804983285692288}
{"step": 585944, "time": 29795.338314771652, "episode/length": 183.0, "episode/score": 0.19952815788929001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19952815788929001}
{"step": 585984, "time": 29798.70499944687, "episode/length": 204.0, "episode/score": 0.21529067554001813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21529067554001813}
{"step": 586128, "time": 29805.743408203125, "episode/length": 157.0, "episode/score": 0.16185322632372845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16185322632372845}
{"step": 586232, "time": 29811.009474992752, "episode/length": 262.0, "episode/score": 0.2991795766283758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2991795766283758}
{"step": 586896, "time": 29837.66357445717, "episode/length": 146.0, "episode/score": 0.16037225777836284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16037225777836284}
{"step": 586968, "time": 29841.632666110992, "episode/length": 178.0, "episode/score": 0.19247330960206455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19247330960206455}
{"step": 587232, "time": 29853.398461341858, "episode/length": 160.0, "episode/score": 0.1596458540934691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1596458540934691}
{"step": 587312, "time": 29858.588671922684, "episode/length": 165.0, "episode/score": 0.18338210066212923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18338210066212923}
{"step": 587560, "time": 29869.96514773369, "episode/length": 165.0, "episode/score": 0.1897142822854221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1897142822854221}
{"step": 587600, "time": 29873.259014844894, "episode/length": 237.0, "episode/score": 0.2591312838048907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2591312838048907}
{"step": 587632, "time": 29876.00379705429, "episode/length": 187.0, "episode/score": 0.1957701365936373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1957701365936373}
{"step": 587856, "time": 29885.78321480751, "episode/length": 255.0, "episode/score": 0.29129499722148466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29129499722148466}
{"step": 588160, "time": 29898.717709302902, "episode/length": 157.0, "episode/score": 0.18243475382041652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18243475382041652}
{"step": 588632, "time": 29917.632865667343, "episode/length": 174.0, "episode/score": 0.18235883968009148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18235883968009148}
{"step": 588928, "time": 29930.44482946396, "episode/length": 161.0, "episode/score": 0.19207473163987743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19207473163987743}
{"step": 588984, "time": 29933.87917613983, "episode/length": 177.0, "episode/score": 0.19701090609305538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19701090609305538}
{"step": 589240, "time": 29945.009058475494, "episode/length": 240.0, "episode/score": 0.26468941739585716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26468941739585716}
{"step": 589376, "time": 29951.85312461853, "episode/length": 189.0, "episode/score": 0.20032719783193897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20032719783193897}
{"step": 589416, "time": 29954.736570835114, "episode/length": 226.0, "episode/score": 0.2572092005284503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2572092005284503}
{"step": 589704, "time": 29967.048258066177, "episode/length": 192.0, "episode/score": 0.20489616681152256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20489616681152256}
{"step": 590096, "time": 29984.99578523636, "episode/length": 182.0, "episode/score": 0.21500835308688693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21500835308688693}
{"step": 590096, "time": 30008.495317697525, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 590096, "time": 30010.449426174164, "eval_episode/length": 160.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 590096, "time": 30011.996259212494, "eval_episode/length": 161.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 590096, "time": 30013.861127614975, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 590096, "time": 30015.924885749817, "eval_episode/length": 175.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 590096, "time": 30018.35137271881, "eval_episode/length": 182.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.994535519125683}
{"step": 590096, "time": 30023.979956626892, "eval_episode/length": 252.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 590096, "time": 30026.555837869644, "eval_episode/length": 277.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9856115107913669}
{"step": 590192, "time": 30031.73245739937, "episode/length": 402.0, "episode/score": 0.3938082934510021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3938082934510021}
{"step": 590360, "time": 30039.33690905571, "episode/length": 171.0, "episode/score": 0.1939068549145304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939068549145304}
{"step": 590392, "time": 30042.01481628418, "episode/length": 182.0, "episode/score": 0.2002638155790919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2002638155790919}
{"step": 590440, "time": 30045.330531835556, "episode/length": 127.0, "episode/score": 0.1498749972670339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1498749972670339}
{"step": 590440, "time": 30045.33689236641, "episode/length": 91.0, "episode/score": 0.110363451512967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.110363451512967}
{"step": 590720, "time": 30059.5730509758, "episode/length": 167.0, "episode/score": 0.17340669933037134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17340669933037134}
{"step": 591104, "time": 30076.38521361351, "episode/length": 232.0, "episode/score": 0.24188508751103655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24188508751103655}
{"step": 591272, "time": 30084.660752296448, "episode/length": 134.0, "episode/score": 0.13988820260237844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13988820260237844}
{"step": 591600, "time": 30099.390768289566, "episode/length": 154.0, "episode/score": 0.18212499667424709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18212499667424709}
{"step": 591792, "time": 30108.239287137985, "episode/length": 211.0, "episode/score": 0.2543749950127676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2543749950127676}
{"step": 591840, "time": 30111.539960861206, "episode/length": 174.0, "episode/score": 0.18929065392148914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18929065392148914}
{"step": 591856, "time": 30113.650926589966, "episode/length": 176.0, "episode/score": 0.19750446104444563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19750446104444563}
{"step": 591896, "time": 30116.470410585403, "episode/length": 187.0, "episode/score": 0.20581100863637403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20581100863637403}
{"step": 592144, "time": 30127.510324001312, "episode/length": 177.0, "episode/score": 0.19003877519571688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19003877519571688}
{"step": 592360, "time": 30137.38440489769, "episode/length": 135.0, "episode/score": 0.13291421009489568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13291421009489568}
{"step": 592392, "time": 30140.1372051239, "episode/length": 160.0, "episode/score": 0.1787754475371912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1787754475371912}
{"step": 593272, "time": 30174.44401717186, "episode/length": 171.0, "episode/score": 0.19979463904746808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19979463904746808}
{"step": 593352, "time": 30178.96002817154, "episode/length": 188.0, "episode/score": 0.1932689280329214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1932689280329214}
{"step": 593360, "time": 30181.062168836594, "episode/length": 187.0, "episode/score": 0.21422150386933936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21422150386933936}
{"step": 593368, "time": 30182.615063667297, "episode/length": 220.0, "episode/score": 0.23403267965841223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23403267965841223}
{"step": 593424, "time": 30186.52356362343, "episode/length": 159.0, "episode/score": 0.15804254748945823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15804254748945823}
{"step": 593568, "time": 30193.482244729996, "episode/length": 221.0, "episode/score": 0.24695105045975652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24695105045975652}
{"step": 593584, "time": 30195.77887916565, "episode/length": 148.0, "episode/score": 0.1442866554389184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1442866554389184}
{"step": 593976, "time": 30211.72952079773, "episode/length": 201.0, "episode/score": 0.22384820966180996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22384820966180996}
{"step": 594712, "time": 30240.63445043564, "episode/length": 179.0, "episode/score": 0.20525392128911335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20525392128911335}
{"step": 594976, "time": 30252.29022359848, "episode/length": 193.0, "episode/score": 0.192372509283814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.192372509283814}
{"step": 595024, "time": 30255.891392230988, "episode/length": 181.0, "episode/score": 0.16909987625513168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16909987625513168}
{"step": 595112, "time": 30260.514223098755, "episode/length": 219.0, "episode/score": 0.2441310635076661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2441310635076661}
{"step": 595208, "time": 30265.719197034836, "episode/length": 202.0, "episode/score": 0.2325971527134243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2325971527134243}
{"step": 595280, "time": 30270.124741077423, "episode/length": 238.0, "episode/score": 0.26539818839410145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26539818839410145}
{"step": 595576, "time": 30282.581260204315, "episode/length": 199.0, "episode/score": 0.20806252049260365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20806252049260365}
{"step": 596016, "time": 30301.21707367897, "episode/length": 162.0, "episode/score": 0.1848928564977541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1848928564977541}
{"step": 596200, "time": 30310.003063440323, "episode/length": 114.0, "episode/score": 0.13466666411841288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13466666411841288}
{"step": 596312, "time": 30316.503204107285, "episode/length": 166.0, "episode/score": 0.18502380658173934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18502380658173934}
{"step": 596424, "time": 30322.850349664688, "episode/length": 163.0, "episode/score": 0.15918591980152996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15918591980152996}
{"step": 596552, "time": 30329.414935827255, "episode/length": 190.0, "episode/score": 0.21874810232839081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21874810232839081}
{"step": 596624, "time": 30333.88690018654, "episode/length": 407.0, "episode/score": 0.42342213935262407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42342213935262407}
{"step": 596728, "time": 30339.071196317673, "episode/length": 37.0, "episode/score": 0.04445833252975717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04445833252975717}
{"step": 597112, "time": 30354.93428659439, "episode/length": 191.0, "episode/score": 0.2249416973645566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2249416973645566}
{"step": 597280, "time": 30362.939091205597, "episode/length": 258.0, "episode/score": 0.30315212336427066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30315212336427066}
{"step": 597544, "time": 30374.167392015457, "episode/length": 153.0, "episode/score": 0.17812076666814392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17812076666814392}
{"step": 597712, "time": 30382.228484869003, "episode/length": 188.0, "episode/score": 0.1902548913130886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1902548913130886}
{"step": 597760, "time": 30386.082926273346, "episode/length": 150.0, "episode/score": 0.16327137218104326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16327137218104326}
{"step": 598152, "time": 30404.76317715645, "episode/length": 177.0, "episode/score": 0.1875816115643829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1875816115643829}
{"step": 598160, "time": 30407.29734134674, "episode/length": 191.0, "episode/score": 0.21020114516068134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21020114516068134}
{"step": 598264, "time": 30413.0928337574, "episode/length": 280.0, "episode/score": 0.31036875319841783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31036875319841783}
{"step": 598608, "time": 30428.112763166428, "episode/length": 165.0, "episode/score": 0.16822717673130683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16822717673130683}
{"step": 599168, "time": 30450.44197010994, "episode/length": 256.0, "episode/score": 0.2889300680399174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2889300680399174}
{"step": 599248, "time": 30455.05443739891, "episode/length": 185.0, "episode/score": 0.21439869184905547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21439869184905547}
{"step": 599440, "time": 30465.501127004623, "episode/length": 160.0, "episode/score": 0.15947002337270533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15947002337270533}
{"step": 599552, "time": 30471.235714912415, "episode/length": 250.0, "episode/score": 0.28622816954157315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28622816954157315}
{"step": 599712, "time": 30478.674674510956, "episode/length": 249.0, "episode/score": 0.2729701421703794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2729701421703794}
{"step": 599752, "time": 30481.47961449623, "episode/length": 185.0, "episode/score": 0.1846260681795684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846260681795684}
{"step": 599880, "time": 30487.778272390366, "episode/length": 214.0, "episode/score": 0.2172285242486396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2172285242486396}
{"step": 600080, "time": 30515.76826095581, "eval_episode/length": 138.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9640287769784173}
{"step": 600080, "time": 30517.984647989273, "eval_episode/length": 154.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 600080, "time": 30519.523312568665, "eval_episode/length": 155.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.967948717948718}
{"step": 600080, "time": 30521.521727085114, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 600080, "time": 30523.48955845833, "eval_episode/length": 173.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 600080, "time": 30525.465574026108, "eval_episode/length": 179.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 600080, "time": 30527.730067253113, "eval_episode/length": 194.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 600080, "time": 30530.264053106308, "eval_episode/length": 219.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 600081, "time": 30530.869660377502, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.34086181640625, "train/action_min": 0.0, "train/action_std": 5.006336738586426, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00871329738944769, "train/actor_opt_grad_steps": 36780.0, "train/actor_opt_loss": -6.7640083963871005, "train/adv_mag": 0.18917152643203736, "train/adv_max": 0.1375109480023384, "train/adv_mean": 0.00013932201686839106, "train/adv_min": -0.18840065574645995, "train/adv_std": 0.014784920915961265, "train/cont_avg": 0.994296875, "train/cont_loss_mean": 0.00024578955668704336, "train/cont_loss_std": 0.007568580826258767, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.005440092015054688, "train/cont_pos_acc": 0.9999292936325074, "train/cont_pos_loss": 0.0002132862169333123, "train/cont_pred": 0.9942555232048035, "train/cont_rate": 0.994296875, "train/dyn_loss_mean": 11.73744361114502, "train/dyn_loss_std": 8.381040843963623, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1492057791352272, "train/extr_critic_critic_opt_grad_steps": 36780.0, "train/extr_critic_critic_opt_loss": 12386.2423359375, "train/extr_critic_mag": 0.28180293369293213, "train/extr_critic_max": 0.28180293369293213, "train/extr_critic_mean": 0.23518941485881806, "train/extr_critic_min": 0.001970846176147461, "train/extr_critic_std": 0.060310963481664655, "train/extr_return_normed_mag": 0.203516756772995, "train/extr_return_normed_max": 0.203516756772995, "train/extr_return_normed_mean": 0.15773302209377288, "train/extr_return_normed_min": -0.07656617993116378, "train/extr_return_normed_std": 0.062316848933696746, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2811124951839447, "train/extr_return_raw_max": 0.2811124951839447, "train/extr_return_raw_mean": 0.23532876336574554, "train/extr_return_raw_min": 0.0010295581817626953, "train/extr_return_raw_std": 0.06231684935092926, "train/extr_reward_mag": 0.0013474416732788086, "train/extr_reward_max": 0.0013474416732788086, "train/extr_reward_mean": 0.0010906497798860073, "train/extr_reward_min": 1.1075973510742188e-05, "train/extr_reward_std": 0.00024054110213182867, "train/image_loss_mean": 5.663689594268799, "train/image_loss_std": 10.278273487091065, "train/model_loss_mean": 12.746652893066406, "train/model_loss_std": 13.797315048217774, "train/model_opt_grad_norm": 55.41100874328613, "train/model_opt_grad_steps": 36744.104, "train/model_opt_loss": 17596.657515625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1380.0, "train/policy_entropy_mag": 2.7582899570465087, "train/policy_entropy_max": 2.7582899570465087, "train/policy_entropy_mean": 2.1733884239196777, "train/policy_entropy_min": 0.07999043214321136, "train/policy_entropy_std": 0.5676750433444977, "train/policy_logprob_mag": 7.438214046478271, "train/policy_logprob_max": -0.00954099091142416, "train/policy_logprob_mean": -2.172886080741882, "train/policy_logprob_min": -7.438214046478271, "train/policy_logprob_std": 1.0882687854766846, "train/policy_randomness_mag": 0.9735553097724915, "train/policy_randomness_max": 0.9735553097724915, "train/policy_randomness_mean": 0.7671107368469239, "train/policy_randomness_min": 0.028233112201094628, "train/policy_randomness_std": 0.20036437904834747, "train/post_ent_mag": 56.35261654663086, "train/post_ent_max": 56.35261654663086, "train/post_ent_mean": 39.719224365234375, "train/post_ent_min": 19.85732918548584, "train/post_ent_std": 6.6439596443176265, "train/prior_ent_mag": 65.67360827636719, "train/prior_ent_max": 65.67360827636719, "train/prior_ent_mean": 51.46997259521484, "train/prior_ent_min": 30.08974758911133, "train/prior_ent_std": 5.483586757659912, "train/rep_loss_mean": 11.73744361114502, "train/rep_loss_std": 8.381040843963623, "train/reward_avg": 0.0010664634918794037, "train/reward_loss_mean": 0.04025131157040596, "train/reward_loss_std": 0.011052830949425697, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013078336715698243, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040251311153173444, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010680798469111324, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.9785046507125703, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.392523364485981, "train_stats/max_log_achievement_collect_sapling": 0.7570093457943925, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5514018691588785, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.037383177570093455, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.32710280373831774, "train_stats/max_log_achievement_place_table": 0.06542056074766354, "train_stats/max_log_achievement_wake_up": 0.22429906542056074, "train_stats/mean_log_entropy": 2.250109255870926, "eval_stats/sum_log_reward": 0.9749999670311809, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.5625, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.352803130634129e-05, "report/cont_loss_std": 0.0003056404530070722, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0023607334587723017, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.436251841369085e-05, "report/cont_pred": 0.9960887432098389, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.967817306518555, "report/dyn_loss_std": 7.577834606170654, "report/image_loss_mean": 4.665349006652832, "report/image_loss_std": 7.925147533416748, "report/model_loss_mean": 11.285372734069824, "report/model_loss_std": 11.190342903137207, "report/post_ent_mag": 56.58988952636719, "report/post_ent_max": 56.58988952636719, "report/post_ent_mean": 40.0570068359375, "report/post_ent_min": 20.964113235473633, "report/post_ent_std": 6.56524658203125, "report/prior_ent_mag": 65.78868103027344, "report/prior_ent_max": 65.78868103027344, "report/prior_ent_mean": 51.5079345703125, "report/prior_ent_min": 27.12383270263672, "report/prior_ent_std": 5.812928676605225, "report/rep_loss_mean": 10.967817306518555, "report/rep_loss_std": 7.577834606170654, "report/reward_avg": 0.0010391250252723694, "report/reward_loss_mean": 0.039310067892074585, "report/reward_loss_std": 0.012057885527610779, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013257265090942383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039310067892074585, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001036834786646068, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.003878204617649317, "eval/cont_loss_std": 0.10545290261507034, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.9924351572990417, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.510185484221438e-06, "eval/cont_pred": 0.9975427389144897, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.672977447509766, "eval/dyn_loss_std": 10.093174934387207, "eval/image_loss_mean": 11.289331436157227, "eval/image_loss_std": 17.040124893188477, "eval/model_loss_mean": 21.889049530029297, "eval/model_loss_std": 21.636581420898438, "eval/post_ent_mag": 54.50177764892578, "eval/post_ent_max": 54.50177764892578, "eval/post_ent_mean": 38.84614562988281, "eval/post_ent_min": 19.58206558227539, "eval/post_ent_std": 6.677367210388184, "eval/prior_ent_mag": 65.78868103027344, "eval/prior_ent_max": 65.78868103027344, "eval/prior_ent_mean": 52.72344970703125, "eval/prior_ent_min": 26.26750946044922, "eval/prior_ent_std": 5.0340166091918945, "eval/rep_loss_mean": 16.672977447509766, "eval/rep_loss_std": 10.093174934387207, "eval/reward_avg": 0.0039062495343387127, "eval/reward_loss_mean": 0.59205561876297, "eval/reward_loss_std": 3.32635235786438, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012655258178710938, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4334803819656372, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.731115341186523, "eval/reward_pred": 0.001036456087604165, "eval/reward_rate": 0.0078125, "replay/size": 599577.0, "replay/inserts": 20056.0, "replay/samples": 20048.0, "replay/insert_wait_avg": 1.4333169584879134e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.162696744000921e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1619315089949643e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1015.4790017604828, "timer/env.step_count": 2507.0, "timer/env.step_total": 245.88514494895935, "timer/env.step_frac": 0.2421371042854467, "timer/env.step_avg": 0.0980794355600157, "timer/env.step_min": 0.02324986457824707, "timer/env.step_max": 4.141756534576416, "timer/replay._sample_count": 20048.0, "timer/replay._sample_total": 9.727967262268066, "timer/replay._sample_frac": 0.009579683327181752, "timer/replay._sample_avg": 0.0004852338019886306, "timer/replay._sample_min": 0.0003635883331298828, "timer/replay._sample_max": 0.02473926544189453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3005.0, "timer/agent.policy_total": 49.77844858169556, "timer/agent.policy_frac": 0.04901967297738039, "timer/agent.policy_avg": 0.01656520751470734, "timer/agent.policy_min": 0.009751558303833008, "timer/agent.policy_max": 0.12036395072937012, "timer/dataset_train_count": 1253.0, "timer/dataset_train_total": 0.14345622062683105, "timer/dataset_train_frac": 0.00014126950963843518, "timer/dataset_train_avg": 0.00011449020002141345, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0005431175231933594, "timer/agent.train_count": 1253.0, "timer/agent.train_total": 567.1594231128693, "timer/agent.train_frac": 0.5585141811200572, "timer/agent.train_avg": 0.45264119961122845, "timer/agent.train_min": 0.43573641777038574, "timer/agent.train_max": 2.0922889709472656, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4701838493347168, "timer/agent.report_frac": 0.00046301681129750955, "timer/agent.report_avg": 0.2350919246673584, "timer/agent.report_min": 0.22805237770080566, "timer/agent.report_max": 0.24213147163391113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.404373099768007e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 19.750010918905456}
{"step": 600328, "time": 30540.03935289383, "episode/length": 214.0, "episode/score": 0.240136231202996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.240136231202996}
{"step": 600368, "time": 30543.251555919647, "episode/length": 139.0, "episode/score": 0.13636572100949707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13636572100949707}
{"step": 600600, "time": 30553.20185995102, "episode/length": 178.0, "episode/score": 0.19575884503865382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19575884503865382}
{"step": 601032, "time": 30570.933814525604, "episode/length": 164.0, "episode/score": 0.16440829924431455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16440829924431455}
{"step": 601056, "time": 30573.62310051918, "episode/length": 187.0, "episode/score": 0.2087619997382717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2087619997382717}
{"step": 601208, "time": 30580.556698799133, "episode/length": 181.0, "episode/score": 0.19283170436756336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19283170436756336}
{"step": 601384, "time": 30588.631425380707, "episode/length": 187.0, "episode/score": 0.2081315645173163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2081315645173163}
{"step": 601616, "time": 30599.080364704132, "episode/length": 126.0, "episode/score": 0.14712851224976475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14712851224976475}
{"step": 601736, "time": 30604.828870534897, "episode/length": 175.0, "episode/score": 0.16602795376820723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16602795376820723}
{"step": 601848, "time": 30610.469340324402, "episode/length": 184.0, "episode/score": 0.19877595122852654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19877595122852654}
{"step": 601920, "time": 30614.962333202362, "episode/length": 309.0, "episode/score": 0.344444470378221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.344444470378221}
{"step": 602360, "time": 30632.664268016815, "episode/length": 165.0, "episode/score": 0.17491999773392308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17491999773392308}
{"step": 602432, "time": 30637.041955709457, "episode/length": 152.0, "episode/score": 0.17161058026886167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17161058026886167}
{"step": 602592, "time": 30644.655057907104, "episode/length": 191.0, "episode/score": 0.20502806512376992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20502806512376992}
{"step": 602704, "time": 30650.33237719536, "episode/length": 164.0, "episode/score": 0.16810491194064525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16810491194064525}
{"step": 603104, "time": 30666.66241836548, "episode/length": 156.0, "episode/score": 0.16673684969828173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16673684969828173}
{"step": 603176, "time": 30670.744623422623, "episode/length": 156.0, "episode/score": 0.1501736602285746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1501736602285746}
{"step": 603464, "time": 30683.03897047043, "episode/length": 230.0, "episode/score": 0.27165138151576684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27165138151576684}
{"step": 603544, "time": 30687.63044810295, "episode/length": 225.0, "episode/score": 0.25166683497354825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25166683497354825}
{"step": 603720, "time": 30695.741569519043, "episode/length": 160.0, "episode/score": 0.16846714990515466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16846714990515466}
{"step": 603856, "time": 30702.678014039993, "episode/length": 143.0, "episode/score": 0.16681107526073902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16681107526073902}
{"step": 604024, "time": 30710.383225917816, "episode/length": 178.0, "episode/score": 0.1787113234104254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1787113234104254}
{"step": 604064, "time": 30713.60165309906, "episode/length": 212.0, "episode/score": 0.2375185472483281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2375185472483281}
{"step": 604736, "time": 30740.348875522614, "episode/length": 158.0, "episode/score": 0.16651989942602086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16651989942602086}
{"step": 604872, "time": 30747.43478012085, "episode/length": 143.0, "episode/score": 0.14072715072234132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14072715072234132}
{"step": 605016, "time": 30754.858778715134, "episode/length": 229.0, "episode/score": 0.25220462333527394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25220462333527394}
{"step": 605088, "time": 30759.323944807053, "episode/length": 247.0, "episode/score": 0.2838539498961836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2838539498961836}
{"step": 605216, "time": 30765.848876714706, "episode/length": 208.0, "episode/score": 0.23317896921435022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23317896921435022}
{"step": 605240, "time": 30768.1699283123, "episode/length": 172.0, "episode/score": 0.18738396089247544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18738396089247544}
{"step": 605472, "time": 30778.731097459793, "episode/length": 175.0, "episode/score": 0.19170524417495471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19170524417495471}
{"step": 605864, "time": 30794.717533111572, "episode/length": 229.0, "episode/score": 0.26832738757548213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26832738757548213}
{"step": 606176, "time": 30808.320085525513, "episode/length": 179.0, "episode/score": 0.20409896009277873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20409896009277873}
{"step": 606352, "time": 30817.921036958694, "episode/length": 184.0, "episode/score": 0.21571783516174037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21571783516174037}
{"step": 606360, "time": 30819.473823308945, "episode/length": 158.0, "episode/score": 0.1731018503296582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731018503296582}
{"step": 606368, "time": 30821.516409158707, "episode/length": 168.0, "episode/score": 0.18992202713889128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18992202713889128}
{"step": 606504, "time": 30827.963084459305, "episode/length": 157.0, "episode/score": 0.15227870910985075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15227870910985075}
{"step": 606760, "time": 30839.358018636703, "episode/length": 160.0, "episode/score": 0.18527780138902017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18527780138902017}
{"step": 606912, "time": 30847.208461999893, "episode/length": 211.0, "episode/score": 0.22191357155952574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22191357155952574}
{"step": 607120, "time": 30857.244916439056, "episode/length": 76.0, "episode/score": 0.08987499837530777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08987499837530777}
{"step": 607256, "time": 30863.611024856567, "episode/length": 173.0, "episode/score": 0.19545833015581593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19545833015581593}
{"step": 607504, "time": 30874.6445646286, "episode/length": 165.0, "episode/score": 0.1768351421051193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768351421051193}
{"step": 607648, "time": 30881.58899474144, "episode/length": 159.0, "episode/score": 0.18416666353004985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18416666353004985}
{"step": 607888, "time": 30892.204164266586, "episode/length": 191.0, "episode/score": 0.20509875243442366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20509875243442366}
{"step": 608104, "time": 30901.557775497437, "episode/length": 167.0, "episode/score": 0.1741757651689113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1741757651689113}
{"step": 608136, "time": 30904.350410223007, "episode/length": 221.0, "episode/score": 0.23644990401953692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23644990401953692}
{"step": 608744, "time": 30928.74588370323, "episode/length": 136.0, "episode/score": 0.1566048934837454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1566048934837454}
{"step": 608768, "time": 30931.605169057846, "episode/length": 188.0, "episode/score": 0.19593110915957368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19593110915957368}
{"step": 608792, "time": 30934.31667327881, "episode/length": 160.0, "episode/score": 0.1843185499383253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843185499383253}
{"step": 608816, "time": 30937.565318107605, "episode/length": 237.0, "episode/score": 0.2602291714792955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2602291714792955}
{"step": 609384, "time": 30960.465746164322, "episode/length": 282.0, "episode/score": 0.32341335825185524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32341335825185524}
{"step": 609536, "time": 30967.951963424683, "episode/length": 178.0, "episode/score": 0.1983542486850638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1983542486850638}
{"step": 609952, "time": 30985.059566259384, "episode/length": 226.0, "episode/score": 0.25396693022412364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25396693022412364}
{"step": 610016, "time": 30988.963063955307, "episode/length": 155.0, "episode/score": 0.14399489896277373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14399489896277373}
{"step": 610064, "time": 31011.408107995987, "eval_episode/length": 147.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 610064, "time": 31013.354778289795, "eval_episode/length": 155.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 610064, "time": 31015.422231435776, "eval_episode/length": 167.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 610064, "time": 31017.29136300087, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 610064, "time": 31019.187142133713, "eval_episode/length": 177.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9606741573033708}
{"step": 610064, "time": 31021.742817401886, "eval_episode/length": 201.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.995049504950495}
{"step": 610064, "time": 31023.420257806778, "eval_episode/length": 204.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 610064, "time": 31028.95817708969, "eval_episode/length": 153.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 610248, "time": 31035.629168510437, "episode/length": 187.0, "episode/score": 0.1980968267616845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980968267616845}
{"step": 610280, "time": 31038.514979839325, "episode/length": 182.0, "episode/score": 0.18625172678184754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18625172678184754}
{"step": 610328, "time": 31041.999261140823, "episode/length": 304.0, "episode/score": 0.31377734164561843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31377734164561843}
{"step": 610688, "time": 31057.130822896957, "episode/length": 50.0, "episode/score": 0.062083332100883126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062083332100883126}
{"step": 610712, "time": 31059.44522047043, "episode/length": 146.0, "episode/score": 0.1687083303113468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1687083303113468}
{"step": 610728, "time": 31061.49275946617, "episode/length": 167.0, "episode/score": 0.1872133087272232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1872133087272232}
{"step": 610736, "time": 31063.535521507263, "episode/length": 242.0, "episode/score": 0.2635884676965361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2635884676965361}
{"step": 610800, "time": 31067.624544382095, "episode/length": 97.0, "episode/score": 0.10963180199178169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10963180199178169}
{"step": 611096, "time": 31079.92923951149, "episode/length": 36.0, "episode/score": 0.0390189388563158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0390189388563158}
{"step": 611248, "time": 31087.320563077927, "episode/length": 161.0, "episode/score": 0.181759646797218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.181759646797218}
{"step": 611680, "time": 31105.09303879738, "episode/length": 178.0, "episode/score": 0.19257163901420427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19257163901420427}
{"step": 611896, "time": 31114.564311265945, "episode/length": 144.0, "episode/score": 0.16193258370549302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16193258370549302}
{"step": 611912, "time": 31116.754935503006, "episode/length": 152.0, "episode/score": 0.17679875065005035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17679875065005035}
{"step": 612080, "time": 31124.948890686035, "episode/length": 168.0, "episode/score": 0.18790676904973225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18790676904973225}
{"step": 612224, "time": 31131.92286014557, "episode/length": 140.0, "episode/score": 0.16337487032433273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16337487032433273}
{"step": 612384, "time": 31139.459517002106, "episode/length": 208.0, "episode/score": 0.23032425450219307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23032425450219307}
{"step": 612432, "time": 31142.86081814766, "episode/length": 262.0, "episode/score": 0.28267878764927445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28267878764927445}
{"step": 612448, "time": 31144.923714637756, "episode/length": 149.0, "episode/score": 0.16046223670127802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16046223670127802}
{"step": 612696, "time": 31155.798285484314, "episode/length": 99.0, "episode/score": 0.11462592735188082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11462592735188082}
{"step": 612832, "time": 31162.6566927433, "episode/length": 143.0, "episode/score": 0.15113415396263008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15113415396263008}
{"step": 613488, "time": 31188.807801008224, "episode/length": 175.0, "episode/score": 0.2045135608423152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2045135608423152}
{"step": 613616, "time": 31195.022572040558, "episode/length": 153.0, "episode/score": 0.17425032753817504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17425032753817504}
{"step": 613848, "time": 31205.010361909866, "episode/length": 143.0, "episode/score": 0.16593065987399314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16593065987399314}
{"step": 613872, "time": 31207.666239500046, "episode/length": 177.0, "episode/score": 0.20091282528301235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20091282528301235}
{"step": 613880, "time": 31209.17262506485, "episode/length": 206.0, "episode/score": 0.22440025887772208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22440025887772208}
{"step": 613984, "time": 31214.92606163025, "episode/length": 258.0, "episode/score": 0.2888295914963237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2888295914963237}
{"step": 614008, "time": 31217.101057767868, "episode/length": 146.0, "episode/score": 0.1360426220417139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1360426220417139}
{"step": 614208, "time": 31226.34291124344, "episode/length": 221.0, "episode/score": 0.24038039823790314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24038039823790314}
{"step": 614520, "time": 31240.804775953293, "episode/length": 38.0, "episode/score": 0.04583333246409893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04583333246409893}
{"step": 614800, "time": 31253.281254529953, "episode/length": 163.0, "episode/score": 0.18853124670567922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18853124670567922}
{"step": 614888, "time": 31257.887201547623, "episode/length": 125.0, "episode/score": 0.1209820417316223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1209820417316223}
{"step": 615096, "time": 31267.267188072205, "episode/length": 184.0, "episode/score": 0.18945145538600627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18945145538600627}
{"step": 615440, "time": 31281.825882434845, "episode/length": 195.0, "episode/score": 0.2172189955963404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2172189955963404}
{"step": 615672, "time": 31291.958037137985, "episode/length": 207.0, "episode/score": 0.2319833769943216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2319833769943216}
{"step": 615744, "time": 31296.46093225479, "episode/length": 236.0, "episode/score": 0.27489239438364166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27489239438364166}
{"step": 615832, "time": 31301.016077518463, "episode/length": 230.0, "episode/score": 0.2683409025958099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2683409025958099}
{"step": 615992, "time": 31308.594385385513, "episode/length": 183.0, "episode/score": 0.2068962254379585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2068962254379585}
{"step": 616336, "time": 31323.357508182526, "episode/length": 191.0, "episode/score": 0.20738837953285838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20738837953285838}
{"step": 616440, "time": 31328.65462756157, "episode/length": 167.0, "episode/score": 0.19024883602651244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19024883602651244}
{"step": 616504, "time": 31332.606575250626, "episode/length": 201.0, "episode/score": 0.2045039883141726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2045039883141726}
{"step": 616840, "time": 31347.104127168655, "episode/length": 174.0, "episode/score": 0.20091005081303592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20091005081303592}
{"step": 616936, "time": 31352.21884918213, "episode/length": 148.0, "episode/score": 0.16656987628994102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16656987628994102}
{"step": 617120, "time": 31360.859627008438, "episode/length": 160.0, "episode/score": 0.18467033999149862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18467033999149862}
{"step": 617264, "time": 31367.9165892601, "episode/length": 158.0, "episode/score": 0.16776622936049534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16776622936049534}
{"step": 617488, "time": 31377.75567317009, "episode/length": 226.0, "episode/score": 0.26018224614381324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26018224614381324}
{"step": 617576, "time": 31382.42348265648, "episode/length": 133.0, "episode/score": 0.156252384018444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.156252384018444}
{"step": 617672, "time": 31387.534049272537, "episode/length": 153.0, "episode/score": 0.17479484098839748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17479484098839748}
{"step": 617792, "time": 31393.740488290787, "episode/length": 181.0, "episode/score": 0.21549999580020085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21549999580020085}
{"step": 618232, "time": 31411.45170378685, "episode/length": 161.0, "episode/score": 0.16086881334376812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16086881334376812}
{"step": 618416, "time": 31420.238320827484, "episode/length": 161.0, "episode/score": 0.17622263616249256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17622263616249256}
{"step": 618728, "time": 31434.021634578705, "episode/length": 182.0, "episode/score": 0.2090964093895309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2090964093895309}
{"step": 618848, "time": 31440.790243148804, "episode/length": 158.0, "episode/score": 0.1935416627675295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1935416627675295}
{"step": 618912, "time": 31445.098086357117, "episode/length": 177.0, "episode/score": 0.22020832856651396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22020832856651396}
{"step": 619184, "time": 31457.705111026764, "episode/length": 188.0, "episode/score": 0.20432081143917458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20432081143917458}
{"step": 619200, "time": 31460.257917881012, "episode/length": 175.0, "episode/score": 0.1980685988401092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980685988401092}
{"step": 619712, "time": 31480.766990423203, "episode/length": 184.0, "episode/score": 0.1831514832447283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1831514832447283}
{"step": 619768, "time": 31484.230835199356, "episode/length": 365.0, "episode/score": 0.39770712142490083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39770712142490083}
{"step": 620048, "time": 31516.139413833618, "eval_episode/length": 151.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 620048, "time": 31518.731096744537, "eval_episode/length": 174.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 620048, "time": 31520.48741889, "eval_episode/length": 178.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.994413407821229}
{"step": 620048, "time": 31522.2051320076, "eval_episode/length": 180.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.994475138121547}
{"step": 620048, "time": 31524.373211860657, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 620048, "time": 31526.230386972427, "eval_episode/length": 201.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.995049504950495}
{"step": 620048, "time": 31528.884071588516, "eval_episode/length": 225.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 620048, "time": 31532.25741481781, "eval_episode/length": 268.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 620049, "time": 31532.865802764893, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.379498046875, "train/action_min": 0.0, "train/action_std": 5.009002906799316, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008358785400167108, "train/actor_opt_grad_steps": 38030.0, "train/actor_opt_loss": -11.758282763600349, "train/adv_mag": 0.1871323010325432, "train/adv_max": 0.1334068843126297, "train/adv_mean": -0.00010164437371895474, "train/adv_min": -0.18616137498617172, "train/adv_std": 0.014296020671725274, "train/cont_avg": 0.9946953125, "train/cont_loss_mean": 0.0002556091185765581, "train/cont_loss_std": 0.007867925119298888, "train/cont_neg_acc": 0.9950571436882019, "train/cont_neg_loss": 0.021507424488620017, "train/cont_pos_acc": 0.9999764294624328, "train/cont_pos_loss": 9.701635292140054e-05, "train/cont_pred": 0.9946984882354737, "train/cont_rate": 0.9946953125, "train/dyn_loss_mean": 11.624841644287109, "train/dyn_loss_std": 8.291900379180909, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1431875021159649, "train/extr_critic_critic_opt_grad_steps": 38030.0, "train/extr_critic_critic_opt_loss": 12382.584328125, "train/extr_critic_mag": 0.28541050720214844, "train/extr_critic_max": 0.28541050720214844, "train/extr_critic_mean": 0.23640239882469177, "train/extr_critic_min": 0.002378798484802246, "train/extr_critic_std": 0.05882313805818558, "train/extr_return_normed_mag": 0.20593079769611358, "train/extr_return_normed_max": 0.20593079769611358, "train/extr_return_normed_mean": 0.15748887038230897, "train/extr_return_normed_min": -0.07778605985641479, "train/extr_return_normed_std": 0.06062011206150055, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28474267172813417, "train/extr_return_raw_max": 0.28474267172813417, "train/extr_return_raw_mean": 0.23630074954032898, "train/extr_return_raw_min": 0.0010258140563964844, "train/extr_return_raw_std": 0.06062011206150055, "train/extr_reward_mag": 0.0013477468490600585, "train/extr_reward_max": 0.0013477468490600585, "train/extr_reward_mean": 0.001093869118951261, "train/extr_reward_min": 1.0897636413574218e-05, "train/extr_reward_std": 0.00023569714627228678, "train/image_loss_mean": 5.351053079605102, "train/image_loss_std": 9.629563388824463, "train/model_loss_mean": 12.366570487976075, "train/model_loss_std": 13.087272438049316, "train/model_opt_grad_norm": 53.925342208862304, "train/model_opt_grad_steps": 37992.904, "train/model_opt_loss": 16913.5561796875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1370.0, "train/policy_entropy_mag": 2.764199546813965, "train/policy_entropy_max": 2.764199546813965, "train/policy_entropy_mean": 2.18908842086792, "train/policy_entropy_min": 0.08018243646621705, "train/policy_entropy_std": 0.554393232345581, "train/policy_logprob_mag": 7.438240993499756, "train/policy_logprob_max": -0.009567990273237228, "train/policy_logprob_mean": -2.1894180812835695, "train/policy_logprob_min": -7.438240993499756, "train/policy_logprob_std": 1.0779495401382446, "train/policy_randomness_mag": 0.9756411361694336, "train/policy_randomness_max": 0.9756411361694336, "train/policy_randomness_mean": 0.7726521458625794, "train/policy_randomness_min": 0.028300881430506707, "train/policy_randomness_std": 0.1956764817237854, "train/post_ent_mag": 56.64999215698242, "train/post_ent_max": 56.64999215698242, "train/post_ent_mean": 39.9446689453125, "train/post_ent_min": 19.891884704589845, "train/post_ent_std": 6.791662155151367, "train/prior_ent_mag": 65.77024908447265, "train/prior_ent_max": 65.77024908447265, "train/prior_ent_mean": 51.58761996459961, "train/prior_ent_min": 30.713126403808594, "train/prior_ent_std": 5.455014225006104, "train/rep_loss_mean": 11.624841644287109, "train/rep_loss_std": 8.291900379180909, "train/reward_avg": 0.001069484991952777, "train/reward_loss_mean": 0.040356962859630585, "train/reward_loss_std": 0.010894389234483243, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013023481369018556, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04035696277022362, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010686957146972419, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.8909090621904894, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.3909090909090909, "train_stats/max_log_achievement_collect_sapling": 0.8, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.42727272727272725, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.4090909090909091, "train_stats/max_log_achievement_place_table": 0.02727272727272727, "train_stats/max_log_achievement_wake_up": 0.21818181818181817, "train_stats/mean_log_entropy": 2.22124971259724, "eval_stats/sum_log_reward": 0.6625000014901161, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.4375, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.3257844361523894e-07, "report/cont_loss_std": 2.3933557713462505e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.366224650060758e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2801940840745374e-07, "report/cont_pred": 0.998046875, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 11.365047454833984, "report/dyn_loss_std": 7.673473358154297, "report/image_loss_mean": 4.28450345993042, "report/image_loss_std": 9.890617370605469, "report/model_loss_mean": 11.143924713134766, "report/model_loss_std": 12.90857219696045, "report/post_ent_mag": 55.421356201171875, "report/post_ent_max": 55.421356201171875, "report/post_ent_mean": 40.01979064941406, "report/post_ent_min": 19.574115753173828, "report/post_ent_std": 6.560824394226074, "report/prior_ent_mag": 65.39867401123047, "report/prior_ent_max": 65.39867401123047, "report/prior_ent_mean": 51.61266326904297, "report/prior_ent_min": 31.159141540527344, "report/prior_ent_std": 4.142373561859131, "report/rep_loss_mean": 11.365047454833984, "report/rep_loss_std": 7.673473358154297, "report/reward_avg": 0.00107296253554523, "report/reward_loss_mean": 0.04039251059293747, "report/reward_loss_std": 0.011348418891429901, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013003349304199219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04039251059293747, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001063382951542735, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.186421443184372e-05, "eval/cont_loss_std": 0.0006799441180191934, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.95268570072949e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.175137160520535e-05, "eval/cont_pred": 0.9980255961418152, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 13.898269653320312, "eval/dyn_loss_std": 10.005504608154297, "eval/image_loss_mean": 7.866027355194092, "eval/image_loss_std": 13.096821784973145, "eval/model_loss_mean": 16.647018432617188, "eval/model_loss_std": 17.34726905822754, "eval/post_ent_mag": 59.62395095825195, "eval/post_ent_max": 59.62395095825195, "eval/post_ent_mean": 39.22411346435547, "eval/post_ent_min": 21.357290267944336, "eval/post_ent_std": 6.881612300872803, "eval/prior_ent_mag": 65.39867401123047, "eval/prior_ent_max": 65.39867401123047, "eval/prior_ent_mean": 50.51872253417969, "eval/prior_ent_min": 27.844989776611328, "eval/prior_ent_std": 6.534019470214844, "eval/rep_loss_mean": 13.898269653320312, "eval/rep_loss_std": 10.005504608154297, "eval/reward_avg": 0.007226563058793545, "eval/reward_loss_mean": 0.44200876355171204, "eval/reward_loss_std": 2.8741350173950195, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012753009796142578, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.24154576659202576, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.768959045410156, "eval/reward_pred": 0.00104141712654382, "eval/reward_rate": 0.009765625, "replay/size": 619545.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.4277055668525206e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.249488205481798e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1880218251991605e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.9823892116547, "timer/env.step_count": 2496.0, "timer/env.step_total": 243.98101091384888, "timer/env.step_frac": 0.24349830250590496, "timer/env.step_avg": 0.09774880244945869, "timer/env.step_min": 0.023320436477661133, "timer/env.step_max": 2.135284662246704, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.729746580123901, "timer/replay._sample_frac": 0.009710496596431327, "timer/replay._sample_avg": 0.0004872669561360127, "timer/replay._sample_min": 0.00038433074951171875, "timer/replay._sample_max": 0.010780572891235352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3067.0, "timer/agent.policy_total": 49.37582588195801, "timer/agent.policy_frac": 0.04927813743393853, "timer/agent.policy_avg": 0.016099062889454844, "timer/agent.policy_min": 0.009546279907226562, "timer/agent.policy_max": 0.08568596839904785, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14052796363830566, "timer/dataset_train_frac": 0.0001402499336828375, "timer/dataset_train_avg": 0.00011260253496659108, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.00035691261291503906, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 560.3033609390259, "timer/agent.train_frac": 0.5591948191623053, "timer/agent.train_avg": 0.4489610263934502, "timer/agent.train_min": 0.4346175193786621, "timer/agent.train_max": 1.0793399810791016, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745171070098877, "timer/agent.report_frac": 0.00047357829051589514, "timer/agent.report_avg": 0.23725855350494385, "timer/agent.report_min": 0.23336577415466309, "timer/agent.report_max": 0.2411513328552246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.093309385166848e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 19.928234190435607}
{"step": 620168, "time": 31537.364009141922, "episode/length": 156.0, "episode/score": 0.1704489854791973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704489854791973}
{"step": 620192, "time": 31540.19025373459, "episode/length": 167.0, "episode/score": 0.16998567468544934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16998567468544934}
{"step": 620376, "time": 31548.547868013382, "episode/length": 205.0, "episode/score": 0.2262802461946194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2262802461946194}
{"step": 620520, "time": 31555.39151239395, "episode/length": 164.0, "episode/score": 0.1902358784709577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1902358784709577}
{"step": 620552, "time": 31558.100679636, "episode/length": 266.0, "episode/score": 0.3055306662899966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3055306662899966}
{"step": 620776, "time": 31568.10120511055, "episode/length": 198.0, "episode/score": 0.21404297927256266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21404297927256266}
{"step": 621152, "time": 31583.98911499977, "episode/length": 179.0, "episode/score": 0.20043578247168625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20043578247168625}
{"step": 621240, "time": 31588.624718666077, "episode/length": 183.0, "episode/score": 0.2057505690791004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2057505690791004}
{"step": 621472, "time": 31599.09304523468, "episode/length": 159.0, "episode/score": 0.1667657958505515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1667657958505515}
{"step": 621584, "time": 31604.780665397644, "episode/length": 176.0, "episode/score": 0.19378662520375656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19378662520375656}
{"step": 621840, "time": 31615.843548297882, "episode/length": 182.0, "episode/score": 0.20750200593920454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20750200593920454}
{"step": 622032, "time": 31624.467443943024, "episode/length": 188.0, "episode/score": 0.2119254842718874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2119254842718874}
{"step": 622056, "time": 31626.644504070282, "episode/length": 159.0, "episode/score": 0.1576198154616577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1576198154616577}
{"step": 622360, "time": 31639.594146728516, "episode/length": 150.0, "episode/score": 0.15668978823396174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15668978823396174}
{"step": 622592, "time": 31650.60572910309, "episode/length": 168.0, "episode/score": 0.18034125858048355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18034125858048355}
{"step": 622936, "time": 31667.072996854782, "episode/length": 168.0, "episode/score": 0.17338694481622952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17338694481622952}
{"step": 623136, "time": 31676.25805068016, "episode/length": 322.0, "episode/score": 0.3701921345318624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3701921345318624}
{"step": 623384, "time": 31686.792538166046, "episode/length": 30.0, "episode/score": 0.035590277111623436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035590277111623436}
{"step": 623496, "time": 31692.546493530273, "episode/length": 182.0, "episode/score": 0.18816778051132133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18816778051132133}
{"step": 623816, "time": 31706.226675271988, "episode/length": 292.0, "episode/score": 0.3324143234749499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3324143234749499}
{"step": 623848, "time": 31708.976205825806, "episode/length": 185.0, "episode/score": 0.2043537169593037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2043537169593037}
{"step": 623856, "time": 31711.158359766006, "episode/length": 224.0, "episode/score": 0.24543269911646348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24543269911646348}
{"step": 623984, "time": 31717.498304605484, "episode/length": 173.0, "episode/score": 0.18398130169316573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18398130169316573}
{"step": 624032, "time": 31720.758544445038, "episode/length": 273.0, "episode/score": 0.3065749144207075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3065749144207075}
{"step": 624312, "time": 31732.605384349823, "episode/length": 171.0, "episode/score": 0.1779115370427462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1779115370427462}
{"step": 624776, "time": 31751.568263053894, "episode/length": 173.0, "episode/score": 0.17272459209198132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17272459209198132}
{"step": 625016, "time": 31762.84364080429, "episode/length": 144.0, "episode/score": 0.15728522489553143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15728522489553143}
{"step": 625232, "time": 31773.23755979538, "episode/length": 176.0, "episode/score": 0.19536093352508033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19536093352508033}
{"step": 625232, "time": 31773.257894277573, "episode/length": 172.0, "episode/score": 0.20105801149020408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20105801149020408}
{"step": 625280, "time": 31778.54824590683, "episode/length": 222.0, "episode/score": 0.2545515894107666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2545515894107666}
{"step": 625496, "time": 31788.0541036129, "episode/length": 147.0, "episode/score": 0.15888878626537917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15888878626537917}
{"step": 625600, "time": 31793.75690984726, "episode/length": 102.0, "episode/score": 0.12354166421573609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12354166421573609}
{"step": 625632, "time": 31796.62718272209, "episode/length": 205.0, "episode/score": 0.2317824214396751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2317824214396751}
{"step": 625872, "time": 31807.125081777573, "episode/length": 229.0, "episode/score": 0.24612686781347293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24612686781347293}
{"step": 626304, "time": 31824.805423259735, "episode/length": 160.0, "episode/score": 0.19377380565856583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19377380565856583}
{"step": 626464, "time": 31832.303375959396, "episode/length": 153.0, "episode/score": 0.1573808943117001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1573808943117001}
{"step": 626752, "time": 31844.67812514305, "episode/length": 156.0, "episode/score": 0.16883487258473906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16883487258473906}
{"step": 626936, "time": 31853.449699401855, "episode/length": 162.0, "episode/score": 0.1795098292259354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1795098292259354}
{"step": 626992, "time": 31857.875708818436, "episode/length": 173.0, "episode/score": 0.1842493467111126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1842493467111126}
{"step": 627032, "time": 31861.170556545258, "episode/length": 144.0, "episode/score": 0.162498926659282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.162498926659282}
{"step": 627032, "time": 31861.17896604538, "episode/length": 224.0, "episode/score": 0.22923130974822925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22923130974822925}
{"step": 627712, "time": 31891.22279548645, "episode/length": 303.0, "episode/score": 0.3303119793890801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3303119793890801}
{"step": 627728, "time": 31893.3043050766, "episode/length": 157.0, "episode/score": 0.1567141790765163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1567141790765163}
{"step": 627752, "time": 31895.466906785965, "episode/length": 180.0, "episode/score": 0.19224518438159066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19224518438159066}
{"step": 628080, "time": 31909.522310256958, "episode/length": 165.0, "episode/score": 0.18600941644581326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18600941644581326}
{"step": 628160, "time": 31914.05461001396, "episode/length": 152.0, "episode/score": 0.15871331916423514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15871331916423514}
{"step": 628272, "time": 31919.712024211884, "episode/length": 154.0, "episode/score": 0.1799930522684008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1799930522684008}
{"step": 628336, "time": 31923.67710709572, "episode/length": 162.0, "episode/score": 0.19883332919562235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19883332919562235}
{"step": 628512, "time": 31932.282898664474, "episode/length": 189.0, "episode/score": 0.22266666288487613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22266666288487613}
{"step": 629064, "time": 31954.197004795074, "episode/length": 163.0, "episode/score": 0.17411771181650693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17411771181650693}
{"step": 629072, "time": 31956.282873868942, "episode/length": 169.0, "episode/score": 0.1800360436027404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1800360436027404}
{"step": 629480, "time": 31972.841984033585, "episode/length": 164.0, "episode/score": 0.18403270341514144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18403270341514144}
{"step": 629528, "time": 31976.148386240005, "episode/length": 180.0, "episode/score": 0.18361556337185903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18361556337185903}
{"step": 629704, "time": 31984.280367851257, "episode/length": 178.0, "episode/score": 0.1750424265883339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1750424265883339}
{"step": 629720, "time": 31986.432318925858, "episode/length": 248.0, "episode/score": 0.2709722527797567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2709722527797567}
{"step": 629744, "time": 31989.044314146042, "episode/length": 175.0, "episode/score": 0.1912506074659177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1912506074659177}
{"step": 629784, "time": 31991.867815732956, "episode/length": 158.0, "episode/score": 0.1742543317086529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742543317086529}
{"step": 630032, "time": 32023.72040295601, "eval_episode/length": 148.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 630032, "time": 32025.763055324554, "eval_episode/length": 153.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 630032, "time": 32027.572383880615, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 630032, "time": 32029.38431453705, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 630032, "time": 32031.44837975502, "eval_episode/length": 174.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 630032, "time": 32033.789192676544, "eval_episode/length": 193.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 630032, "time": 32036.75572371483, "eval_episode/length": 225.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9690265486725663}
{"step": 630032, "time": 32039.372714996338, "eval_episode/length": 248.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9799196787148594}
{"step": 630408, "time": 32053.029881954193, "episode/length": 166.0, "episode/score": 0.1779807273487677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1779807273487677}
{"step": 630512, "time": 32058.823925733566, "episode/length": 180.0, "episode/score": 0.19487006085546454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19487006085546454}
{"step": 630640, "time": 32065.186557769775, "episode/length": 144.0, "episode/score": 0.16442447536246618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16442447536246618}
{"step": 630816, "time": 32074.71996831894, "episode/length": 160.0, "episode/score": 0.17837358628457878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17837358628457878}
{"step": 631072, "time": 32085.83918762207, "episode/length": 168.0, "episode/score": 0.1797548569702485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1797548569702485}
{"step": 631264, "time": 32094.552310466766, "episode/length": 184.0, "episode/score": 0.19003716711813468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19003716711813468}
{"step": 631712, "time": 32113.04589033127, "episode/length": 162.0, "episode/score": 0.17060006724750565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17060006724750565}
{"step": 631712, "time": 32113.055750608444, "episode/length": 245.0, "episode/score": 0.29223424079827964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29223424079827964}
{"step": 631944, "time": 32125.406056165695, "episode/length": 162.0, "episode/score": 0.1653181743604364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1653181743604364}
{"step": 631952, "time": 32127.495985269547, "episode/length": 29.0, "episode/score": 0.03407196909392951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03407196909392951}
{"step": 632032, "time": 32132.109172821045, "episode/length": 189.0, "episode/score": 0.21196848445833893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21196848445833893}
{"step": 632192, "time": 32139.58912062645, "episode/length": 171.0, "episode/score": 0.1855065931649733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1855065931649733}
{"step": 632528, "time": 32153.645352363586, "episode/length": 181.0, "episode/score": 0.2011280674705631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2011280674705631}
{"step": 632632, "time": 32158.72702240944, "episode/length": 170.0, "episode/score": 0.1882552340739494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1882552340739494}
{"step": 633008, "time": 32174.62505054474, "episode/length": 412.0, "episode/score": 0.48040144800506823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.48040144800506823}
{"step": 633080, "time": 32178.76805114746, "episode/length": 170.0, "episode/score": 0.1884166521485895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1884166521485895}
{"step": 633200, "time": 32184.974746227264, "episode/length": 156.0, "episode/score": 0.163654401398162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.163654401398162}
{"step": 633440, "time": 32195.428460121155, "episode/length": 185.0, "episode/score": 0.1794295491763478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1794295491763478}
{"step": 633552, "time": 32201.39164662361, "episode/length": 169.0, "episode/score": 0.18922187929092615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18922187929092615}
{"step": 633904, "time": 32216.899320840836, "episode/length": 171.0, "episode/score": 0.18830984609667212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18830984609667212}
{"step": 634304, "time": 32233.6903758049, "episode/length": 152.0, "episode/score": 0.16342517613702512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16342517613702512}
{"step": 634336, "time": 32236.530184030533, "episode/length": 165.0, "episode/score": 0.17883687295034179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17883687295034179}
{"step": 634376, "time": 32239.412123680115, "episode/length": 146.0, "episode/score": 0.1494995979110172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1494995979110172}
{"step": 634464, "time": 32244.43098974228, "episode/length": 303.0, "episode/score": 0.3554073010418506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3554073010418506}
{"step": 634624, "time": 32251.898252248764, "episode/length": 248.0, "episode/score": 0.2597011392708737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2597011392708737}
{"step": 634704, "time": 32256.422725200653, "episode/length": 143.0, "episode/score": 0.15126154143490567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15126154143490567}
{"step": 634712, "time": 32258.085364818573, "episode/length": 158.0, "episode/score": 0.17035785221924016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17035785221924016}
{"step": 635648, "time": 32294.877880096436, "episode/length": 158.0, "episode/score": 0.16732443672481168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16732443672481168}
{"step": 635696, "time": 32298.274926662445, "episode/length": 173.0, "episode/score": 0.18807453655335848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18807453655335848}
{"step": 635744, "time": 32301.55146574974, "episode/length": 229.0, "episode/score": 0.26482388080057717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26482388080057717}
{"step": 636048, "time": 32314.37542796135, "episode/length": 213.0, "episode/score": 0.23842242192586127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23842242192586127}
{"step": 636064, "time": 32316.608050107956, "episode/length": 179.0, "episode/score": 0.1922366698681799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1922366698681799}
{"step": 636328, "time": 32327.743921995163, "episode/length": 201.0, "episode/score": 0.21774899488082156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21774899488082156}
{"step": 636472, "time": 32334.64936351776, "episode/length": 220.0, "episode/score": 0.2617723167568329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2617723167568329}
{"step": 636488, "time": 32336.8973197937, "episode/length": 252.0, "episode/score": 0.27733499959413166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27733499959413166}
{"step": 637200, "time": 32365.047904729843, "episode/length": 143.0, "episode/score": 0.16685688160850987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16685688160850987}
{"step": 637352, "time": 32372.00848674774, "episode/length": 212.0, "episode/score": 0.23634761614539457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23634761614539457}
{"step": 637384, "time": 32374.732488155365, "episode/length": 164.0, "episode/score": 0.20077082913485356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20077082913485356}
{"step": 637384, "time": 32374.73976445198, "episode/length": 210.0, "episode/score": 0.2436920161890157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2436920161890157}
{"step": 637440, "time": 32380.384390830994, "episode/length": 211.0, "episode/score": 0.21430693201182294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21430693201182294}
{"step": 637640, "time": 32389.93342399597, "episode/length": 163.0, "episode/score": 0.15629216452634864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15629216452634864}
{"step": 637720, "time": 32394.564133644104, "episode/length": 155.0, "episode/score": 0.170270874858943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.170270874858943}
{"step": 637928, "time": 32403.79194378853, "episode/length": 179.0, "episode/score": 0.18403296569431404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18403296569431404}
{"step": 638368, "time": 32421.7895591259, "episode/length": 145.0, "episode/score": 0.13673138807735086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13673138807735086}
{"step": 638392, "time": 32424.01320552826, "episode/length": 129.0, "episode/score": 0.14726278183388786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14726278183388786}
{"step": 638832, "time": 32442.137585878372, "episode/length": 57.0, "episode/score": 0.056494478127206094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056494478127206094}
{"step": 638896, "time": 32446.126082897186, "episode/length": 188.0, "episode/score": 0.20706211419110332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20706211419110332}
{"step": 639104, "time": 32456.74354505539, "episode/length": 146.0, "episode/score": 0.1560480450916657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1560480450916657}
{"step": 639128, "time": 32459.020546913147, "episode/length": 175.0, "episode/score": 0.1977744921532576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1977744921532576}
{"step": 639600, "time": 32478.72577214241, "episode/length": 269.0, "episode/score": 0.29690024427509343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29690024427509343}
{"step": 639720, "time": 32485.076384067535, "episode/length": 259.0, "episode/score": 0.29891467715788167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29891467715788167}
{"step": 639800, "time": 32489.59360766411, "episode/length": 301.0, "episode/score": 0.3344864245627832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3344864245627832}
{"step": 639904, "time": 32495.378811597824, "episode/length": 188.0, "episode/score": 0.21509315391176642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21509315391176642}
{"step": 640016, "time": 32520.897704839706, "eval_episode/length": 158.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 640016, "time": 32522.836503744125, "eval_episode/length": 163.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 640016, "time": 32522.843299150467, "eval_episode/length": 163.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 640016, "time": 32526.338703870773, "eval_episode/length": 166.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 640016, "time": 32528.249212026596, "eval_episode/length": 174.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 640016, "time": 32530.186160564423, "eval_episode/length": 180.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.994475138121547}
{"step": 640016, "time": 32531.910222053528, "eval_episode/length": 187.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 640016, "time": 32534.302577257156, "eval_episode/length": 201.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 640017, "time": 32534.91131258011, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.340181640625, "train/action_min": 0.0, "train/action_std": 4.980271999359131, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00826003471761942, "train/actor_opt_grad_steps": 39280.0, "train/actor_opt_loss": -12.661945367336273, "train/adv_mag": 0.17986469906568528, "train/adv_max": 0.12989201521873475, "train/adv_mean": -0.00012728830324340378, "train/adv_min": -0.1784304109811783, "train/adv_std": 0.01392856153100729, "train/cont_avg": 0.994515625, "train/cont_loss_mean": 0.00031961669279075976, "train/cont_loss_std": 0.009653324309732852, "train/cont_neg_acc": 0.987044445514679, "train/cont_neg_loss": 0.0420561997165205, "train/cont_pos_acc": 0.9999764409065247, "train/cont_pos_loss": 0.00010611635698109013, "train/cont_pred": 0.9945426435470581, "train/cont_rate": 0.994515625, "train/dyn_loss_mean": 11.555437866210937, "train/dyn_loss_std": 8.252012798309327, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13310416823625565, "train/extr_critic_critic_opt_grad_steps": 39280.0, "train/extr_critic_critic_opt_loss": 12296.784328125, "train/extr_critic_mag": 0.28345613193511965, "train/extr_critic_max": 0.28345613193511965, "train/extr_critic_mean": 0.233019566655159, "train/extr_critic_min": 0.0024603500366210938, "train/extr_critic_std": 0.05796015371382236, "train/extr_return_normed_mag": 0.20164984428882599, "train/extr_return_normed_max": 0.20164984428882599, "train/extr_return_normed_mean": 0.15175998693704604, "train/extr_return_normed_min": -0.07972561478614808, "train/extr_return_normed_std": 0.05964930182695389, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2827820732593536, "train/extr_return_raw_max": 0.2827820732593536, "train/extr_return_raw_mean": 0.2328922162055969, "train/extr_return_raw_min": 0.001406613826751709, "train/extr_return_raw_std": 0.05964930157363415, "train/extr_reward_mag": 0.0013479862213134765, "train/extr_reward_max": 0.0013479862213134765, "train/extr_reward_mean": 0.0010896016797050834, "train/extr_reward_min": 1.104259490966797e-05, "train/extr_reward_std": 0.0002373814800521359, "train/image_loss_mean": 5.189182907104493, "train/image_loss_std": 9.681206104278564, "train/model_loss_mean": 12.162972137451172, "train/model_loss_std": 13.144833488464355, "train/model_opt_grad_norm": 57.50527577209473, "train/model_opt_grad_steps": 39241.712, "train/model_opt_loss": 15432.4231640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1270.0, "train/policy_entropy_mag": 2.762864284515381, "train/policy_entropy_max": 2.762864284515381, "train/policy_entropy_mean": 2.1901451358795168, "train/policy_entropy_min": 0.08001290273666382, "train/policy_entropy_std": 0.5606284809112548, "train/policy_logprob_mag": 7.438215381622315, "train/policy_logprob_max": -0.009544286139309407, "train/policy_logprob_mean": -2.19029718208313, "train/policy_logprob_min": -7.438215381622315, "train/policy_logprob_std": 1.0762865648269653, "train/policy_randomness_mag": 0.975169846534729, "train/policy_randomness_max": 0.975169846534729, "train/policy_randomness_mean": 0.7730251140594483, "train/policy_randomness_min": 0.02824104343354702, "train/policy_randomness_std": 0.19787725222110747, "train/post_ent_mag": 56.39034036254883, "train/post_ent_max": 56.39034036254883, "train/post_ent_mean": 39.930421905517576, "train/post_ent_min": 19.739462356567383, "train/post_ent_std": 6.709151752471924, "train/prior_ent_mag": 65.86759307861328, "train/prior_ent_max": 65.86759307861328, "train/prior_ent_mean": 51.5787790222168, "train/prior_ent_min": 29.95775325012207, "train/prior_ent_std": 5.416726539611816, "train/rep_loss_mean": 11.555437866210937, "train/rep_loss_std": 8.252012798309327, "train/reward_avg": 0.0010651322836056352, "train/reward_loss_mean": 0.04020696541666985, "train/reward_loss_std": 0.011076009243726731, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013060131072998046, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04020696538686752, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010652604857459664, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.7818181645463813, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.8545454545454545, "train_stats/max_log_achievement_collect_sapling": 0.6545454545454545, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.39090909090909093, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.35454545454545455, "train_stats/max_log_achievement_place_table": 0.045454545454545456, "train_stats/max_log_achievement_wake_up": 0.18181818181818182, "train_stats/mean_log_entropy": 2.2101062872193076, "eval_stats/sum_log_reward": 0.6624999763444066, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.6875, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.8847265891963616e-05, "report/cont_loss_std": 0.00010946451220661402, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000554545724298805, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5160057046159636e-05, "report/cont_pred": 0.9931527972221375, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.246052742004395, "report/dyn_loss_std": 8.111814498901367, "report/image_loss_mean": 4.109949111938477, "report/image_loss_std": 8.306507110595703, "report/model_loss_mean": 10.89703369140625, "report/model_loss_std": 11.921112060546875, "report/post_ent_mag": 53.888832092285156, "report/post_ent_max": 53.888832092285156, "report/post_ent_mean": 39.065773010253906, "report/post_ent_min": 19.077159881591797, "report/post_ent_std": 6.093464374542236, "report/prior_ent_mag": 65.99703979492188, "report/prior_ent_max": 65.99703979492188, "report/prior_ent_mean": 50.71870040893555, "report/prior_ent_min": 31.907075881958008, "report/prior_ent_std": 5.255913734436035, "report/rep_loss_mean": 11.246052742004395, "report/rep_loss_std": 8.111814498901367, "report/reward_avg": 0.0010444953804835677, "report/reward_loss_mean": 0.03943502530455589, "report/reward_loss_std": 0.012370959855616093, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013053417205810547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03943502530455589, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010388785740360618, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 1.897496076708194e-05, "eval/cont_loss_std": 0.00010648631723597646, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016394491831306368, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.7977132301894017e-05, "eval/cont_pred": 0.9931473135948181, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 15.870128631591797, "eval/dyn_loss_std": 10.759271621704102, "eval/image_loss_mean": 11.7968111038208, "eval/image_loss_std": 19.05573272705078, "eval/model_loss_mean": 22.091609954833984, "eval/model_loss_std": 23.541488647460938, "eval/post_ent_mag": 58.45455551147461, "eval/post_ent_max": 58.45455551147461, "eval/post_ent_mean": 39.01010513305664, "eval/post_ent_min": 18.89606475830078, "eval/post_ent_std": 6.825977325439453, "eval/prior_ent_mag": 65.99703979492188, "eval/prior_ent_max": 65.99703979492188, "eval/prior_ent_mean": 52.36129379272461, "eval/prior_ent_min": 27.08667755126953, "eval/prior_ent_std": 6.215571403503418, "eval/rep_loss_mean": 15.870128631591797, "eval/rep_loss_std": 10.759271621704102, "eval/reward_avg": 0.0017578122206032276, "eval/reward_loss_mean": 0.7727010250091553, "eval/reward_loss_std": 3.821333408355713, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6150121092796326, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.799190521240234, "eval/reward_pred": 0.0010391933610662818, "eval/reward_rate": 0.0078125, "replay/size": 639513.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.405712026051986e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.286979909126575e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2072914191201626e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.0339074134827, "timer/env.step_count": 2496.0, "timer/env.step_total": 247.63951134681702, "timer/env.step_frac": 0.24713685785947181, "timer/env.step_avg": 0.09921454781523117, "timer/env.step_min": 0.022740840911865234, "timer/env.step_max": 4.053786993026733, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.687506675720215, "timer/replay._sample_frac": 0.009667843177808482, "timer/replay._sample_avg": 0.0004851515763081037, "timer/replay._sample_min": 0.00036835670471191406, "timer/replay._sample_max": 0.006856679916381836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2947.0, "timer/agent.policy_total": 48.96831178665161, "timer/agent.policy_frac": 0.04886891693421025, "timer/agent.policy_avg": 0.01661632568260998, "timer/agent.policy_min": 0.009615421295166016, "timer/agent.policy_max": 0.13033151626586914, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.14309191703796387, "timer/dataset_train_frac": 0.00014280147206527407, "timer/dataset_train_avg": 0.00011465698480606079, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0007390975952148438, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 559.2066867351532, "timer/agent.train_frac": 0.5580716207284993, "timer/agent.train_avg": 0.448082281037783, "timer/agent.train_min": 0.43388938903808594, "timer/agent.train_max": 1.0180554389953613, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47245311737060547, "timer/agent.report_frac": 0.00047149414193990025, "timer/agent.report_avg": 0.23622655868530273, "timer/agent.report_min": 0.2288808822631836, "timer/agent.report_max": 0.24357223510742188, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.220008850097656e-05, "timer/dataset_eval_frac": 4.211443164623667e-08, "timer/dataset_eval_avg": 4.220008850097656e-05, "timer/dataset_eval_min": 4.220008850097656e-05, "timer/dataset_eval_max": 4.220008850097656e-05, "fps": 19.92721202475182}
{"step": 640232, "time": 32543.006437540054, "episode/length": 166.0, "episode/score": 0.1712931843030674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712931843030674}
{"step": 640368, "time": 32549.992468595505, "episode/length": 57.0, "episode/score": 0.06105303139747775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06105303139747775}
{"step": 640472, "time": 32555.335380792618, "episode/length": 167.0, "episode/score": 0.16539004205242236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16539004205242236}
{"step": 640872, "time": 32571.856290102005, "episode/length": 254.0, "episode/score": 0.2738048429691844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2738048429691844}
{"step": 640936, "time": 32575.80698657036, "episode/length": 166.0, "episode/score": 0.150753567139418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.150753567139418}
{"step": 640976, "time": 32579.081478834152, "episode/length": 156.0, "episode/score": 0.17666929469987736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17666929469987736}
{"step": 641272, "time": 32591.34032225609, "episode/length": 183.0, "episode/score": 0.20805093840863265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20805093840863265}
{"step": 641736, "time": 32610.12805891037, "episode/length": 187.0, "episode/score": 0.18880831563501488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18880831563501488}
{"step": 641824, "time": 32615.12222981453, "episode/length": 181.0, "episode/score": 0.1960906503759361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1960906503759361}
{"step": 642040, "time": 32624.45538854599, "episode/length": 366.0, "episode/score": 0.406563196436764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.406563196436764}
{"step": 642112, "time": 32628.881098747253, "episode/length": 146.0, "episode/score": 0.16981177435854988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16981177435854988}
{"step": 642184, "time": 32632.749969244003, "episode/length": 163.0, "episode/score": 0.19616248544025439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19616248544025439}
{"step": 642456, "time": 32644.3541367054, "episode/length": 147.0, "episode/score": 0.1703050684768641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1703050684768641}
{"step": 642800, "time": 32659.03253674507, "episode/length": 290.0, "episode/score": 0.31360978463317224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31360978463317224}
{"step": 642920, "time": 32664.796813964844, "episode/length": 242.0, "episode/score": 0.26712744550377465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26712744550377465}
{"step": 643352, "time": 32682.409930944443, "episode/length": 163.0, "episode/score": 0.18889480247753454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18889480247753454}
{"step": 643360, "time": 32684.65995311737, "episode/length": 155.0, "episode/score": 0.16587020933320673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16587020933320673}
{"step": 643464, "time": 32689.798503398895, "episode/length": 215.0, "episode/score": 0.24171020926860365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24171020926860365}
{"step": 643640, "time": 32697.810969114304, "episode/length": 181.0, "episode/score": 0.19706657643109793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19706657643109793}
{"step": 643768, "time": 32704.004878282547, "episode/length": 242.0, "episode/score": 0.26632214917844976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26632214917844976}
{"step": 643840, "time": 32708.462805747986, "episode/length": 172.0, "episode/score": 0.1798526222937653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1798526222937653}
{"step": 644072, "time": 32718.412910938263, "episode/length": 158.0, "episode/score": 0.16022676002421576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16022676002421576}
{"step": 644288, "time": 32728.18392944336, "episode/length": 170.0, "episode/score": 0.18609443021932748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18609443021932748}
{"step": 644704, "time": 32745.244787454605, "episode/length": 168.0, "episode/score": 0.168837044009706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.168837044009706}
{"step": 644704, "time": 32745.252536296844, "episode/length": 167.0, "episode/score": 0.19166082536730755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19166082536730755}
{"step": 644768, "time": 32750.75698709488, "episode/length": 162.0, "episode/score": 0.17923813530478583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17923813530478583}
{"step": 645096, "time": 32764.334027528763, "episode/length": 181.0, "episode/score": 0.18188379859202541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18188379859202541}
{"step": 645344, "time": 32775.52348828316, "episode/length": 196.0, "episode/score": 0.2043450822457089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2043450822457089}
{"step": 645776, "time": 32793.358567237854, "episode/length": 241.0, "episode/score": 0.2706050779306679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2706050779306679}
{"step": 645832, "time": 32796.763825416565, "episode/length": 192.0, "episode/score": 0.21467703943926608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21467703943926608}
{"step": 646040, "time": 32806.213977098465, "episode/length": 166.0, "episode/score": 0.17096189736184897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17096189736184897}
{"step": 646056, "time": 32808.415544748306, "episode/length": 168.0, "episode/score": 0.19209115901321638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19209115901321638}
{"step": 646400, "time": 32822.93094611168, "episode/length": 162.0, "episode/score": 0.17738274680596078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17738274680596078}
{"step": 646400, "time": 32822.93965339661, "episode/length": 203.0, "episode/score": 0.22657302574589266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22657302574589266}
{"step": 646528, "time": 32831.06534075737, "episode/length": 306.0, "episode/score": 0.3434961066232063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3434961066232063}
{"step": 646568, "time": 32833.90937876701, "episode/length": 98.0, "episode/score": 0.10458994948930922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10458994948930922}
{"step": 646616, "time": 32837.44392442703, "episode/length": 158.0, "episode/score": 0.1784902080107713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1784902080107713}
{"step": 647008, "time": 32853.85409092903, "episode/length": 146.0, "episode/score": 0.16096596833813237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16096596833813237}
{"step": 647304, "time": 32867.716087818146, "episode/length": 155.0, "episode/score": 0.16673625248949975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16673625248949975}
{"step": 647528, "time": 32877.57149839401, "episode/length": 185.0, "episode/score": 0.21228868667094503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21228868667094503}
{"step": 647744, "time": 32887.29497742653, "episode/length": 146.0, "episode/score": 0.15811811785533791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15811811785533791}
{"step": 647768, "time": 32889.4308886528, "episode/length": 170.0, "episode/score": 0.18556415064813336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18556415064813336}
{"step": 647904, "time": 32896.41626930237, "episode/length": 187.0, "episode/score": 0.2052529732172843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2052529732172843}
{"step": 648080, "time": 32904.53271603584, "episode/length": 193.0, "episode/score": 0.2245052989310352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2245052989310352}
{"step": 648248, "time": 32912.183351278305, "episode/length": 203.0, "episode/score": 0.2290722183897742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2290722183897742}
{"step": 648408, "time": 32919.742777347565, "episode/length": 174.0, "episode/score": 0.18600860267179087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18600860267179087}
{"step": 648832, "time": 32937.46608233452, "episode/length": 162.0, "episode/score": 0.17359082324401243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17359082324401243}
{"step": 648976, "time": 32944.31523966789, "episode/length": 133.0, "episode/score": 0.14819395291851833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14819395291851833}
{"step": 648984, "time": 32945.93060851097, "episode/length": 154.0, "episode/score": 0.171456078223855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.171456078223855}
{"step": 649264, "time": 32958.24548649788, "episode/length": 147.0, "episode/score": 0.1390205322568363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1390205322568363}
{"step": 649536, "time": 32969.920469760895, "episode/length": 278.0, "episode/score": 0.3331547553243581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3331547553243581}
{"step": 649592, "time": 32973.25376915932, "episode/length": 227.0, "episode/score": 0.2460753486120666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2460753486120666}
{"step": 649976, "time": 32989.42316675186, "episode/length": 142.0, "episode/score": 0.1527462207886856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1527462207886856}
{"step": 649984, "time": 32991.5534389019, "episode/length": 216.0, "episode/score": 0.22929909429876716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22929909429876716}
{"step": 650000, "time": 33013.023037433624, "eval_episode/length": 149.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 650000, "time": 33014.93632268906, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 650000, "time": 33016.88351845741, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 650000, "time": 33019.642313718796, "eval_episode/length": 187.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 650000, "time": 33021.75341296196, "eval_episode/length": 199.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.995}
{"step": 650000, "time": 33024.3391187191, "eval_episode/length": 224.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 650000, "time": 33027.445108652115, "eval_episode/length": 260.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9808429118773946}
{"step": 650000, "time": 33029.55956888199, "eval_episode/length": 271.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9963235294117647}
{"step": 650048, "time": 33031.3790872097, "episode/length": 204.0, "episode/score": 0.2262176074036688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2262176074036688}
{"step": 650296, "time": 33041.97400188446, "episode/length": 163.0, "episode/score": 0.17378831167297903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17378831167297903}
{"step": 650736, "time": 33060.14341020584, "episode/length": 149.0, "episode/score": 0.13642080436693504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13642080436693504}
{"step": 650824, "time": 33064.801805734634, "episode/length": 153.0, "episode/score": 0.16325304002020857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16325304002020857}
{"step": 650840, "time": 33066.937962055206, "episode/length": 196.0, "episode/score": 0.22639884756972606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22639884756972606}
{"step": 651416, "time": 33089.911613702774, "episode/length": 304.0, "episode/score": 0.3303879813029198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3303879813029198}
{"step": 651472, "time": 33093.89566063881, "episode/length": 185.0, "episode/score": 0.19221739272143168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19221739272143168}
{"step": 651512, "time": 33096.65341758728, "episode/length": 182.0, "episode/score": 0.1782899706868193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1782899706868193}
{"step": 651888, "time": 33112.45465922356, "episode/length": 238.0, "episode/score": 0.25184149012602575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25184149012602575}
{"step": 651904, "time": 33114.625920534134, "episode/length": 145.0, "episode/score": 0.16800097639134037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16800097639134037}
{"step": 652008, "time": 33119.891946315765, "episode/length": 145.0, "episode/score": 0.16235751992280711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16235751992280711}
{"step": 652464, "time": 33138.83590221405, "episode/length": 204.0, "episode/score": 0.23223179718115716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23223179718115716}
{"step": 652552, "time": 33143.61205768585, "episode/length": 141.0, "episode/score": 0.15452572064168635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15452572064168635}
{"step": 652752, "time": 33152.92926812172, "episode/length": 159.0, "episode/score": 0.15568114530287858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15568114530287858}
{"step": 652880, "time": 33159.19504857063, "episode/length": 51.0, "episode/score": 0.056214437649032334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056214437649032334}
{"step": 653144, "time": 33170.34234690666, "episode/length": 203.0, "episode/score": 0.2330607182739186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2330607182739186}
{"step": 653152, "time": 33172.41307759285, "episode/length": 155.0, "episode/score": 0.17290872713783756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17290872713783756}
{"step": 653256, "time": 33177.597006082535, "episode/length": 170.0, "episode/score": 0.16464024414744927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16464024414744927}
{"step": 653376, "time": 33183.8062748909, "episode/length": 384.0, "episode/score": 0.38208696249603236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38208696249603236}
{"step": 653768, "time": 33199.80706834793, "episode/length": 219.0, "episode/score": 0.23579308208354632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23579308208354632}
{"step": 654352, "time": 33223.43030166626, "episode/length": 183.0, "episode/score": 0.2032677119213986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2032677119213986}
{"step": 654384, "time": 33226.3762049675, "episode/length": 203.0, "episode/score": 0.21352981633935997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21352981633935997}
{"step": 654472, "time": 33230.987627744675, "episode/length": 164.0, "episode/score": 0.182285667026008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.182285667026008}
{"step": 654584, "time": 33236.78408360481, "episode/length": 179.0, "episode/score": 0.18091775463562954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18091775463562954}
{"step": 654584, "time": 33236.790630340576, "episode/length": 165.0, "episode/score": 0.16491550330738391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16491550330738391}
{"step": 654664, "time": 33243.20285820961, "episode/length": 263.0, "episode/score": 0.2756375072804076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2756375072804076}
{"step": 655168, "time": 33264.04496431351, "episode/length": 223.0, "episode/score": 0.2473289517020021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2473289517020021}
{"step": 655224, "time": 33267.40967750549, "episode/length": 181.0, "episode/score": 0.19722393699248641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19722393699248641}
{"step": 655552, "time": 33282.911573171616, "episode/length": 47.0, "episode/score": 0.04751006411424896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04751006411424896}
{"step": 655608, "time": 33286.509117126465, "episode/length": 152.0, "episode/score": 0.15993598563909472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15993598563909472}
{"step": 655752, "time": 33293.47257208824, "episode/length": 174.0, "episode/score": 0.186816460425689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.186816460425689}
{"step": 655832, "time": 33297.94339346886, "episode/length": 155.0, "episode/score": 0.18012247696879058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18012247696879058}
{"step": 655872, "time": 33301.12191224098, "episode/length": 174.0, "episode/score": 0.18251130773751356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18251130773751356}
{"step": 656424, "time": 33323.060626506805, "episode/length": 229.0, "episode/score": 0.2521972416989229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2521972416989229}
{"step": 656880, "time": 33342.152349472046, "episode/length": 165.0, "episode/score": 0.18005522843668587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18005522843668587}
{"step": 656920, "time": 33345.16312646866, "episode/length": 145.0, "episode/score": 0.1601902699958373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1601902699958373}
{"step": 657200, "time": 33357.35953426361, "episode/length": 165.0, "episode/score": 0.16435237677978876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16435237677978876}
{"step": 657536, "time": 33371.3318195343, "episode/length": 240.0, "episode/score": 0.2743578704912579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2743578704912579}
{"step": 657536, "time": 33371.34020733833, "episode/length": 212.0, "episode/score": 0.22286943859489838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22286943859489838}
{"step": 657704, "time": 33380.710139513016, "episode/length": 379.0, "episode/score": 0.418709981043321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.418709981043321}
{"step": 657920, "time": 33390.50810337067, "episode/length": 186.0, "episode/score": 0.21781788648331712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21781788648331712}
{"step": 658024, "time": 33395.63125562668, "episode/length": 349.0, "episode/score": 0.3911894146731356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3911894146731356}
{"step": 658232, "time": 33405.06776165962, "episode/length": 168.0, "episode/score": 0.17031668105119024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17031668105119024}
{"step": 659064, "time": 33437.7278881073, "episode/length": 190.0, "episode/score": 0.198438145509499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.198438145509499}
{"step": 659144, "time": 33442.35963535309, "episode/length": 152.0, "episode/score": 0.1701848182606227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1701848182606227}
{"step": 659160, "time": 33445.00082087517, "episode/length": 141.0, "episode/score": 0.16820201699874815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16820201699874815}
{"step": 659232, "time": 33450.07712483406, "episode/length": 288.0, "episode/score": 0.3403002809109239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3403002809109239}
{"step": 659328, "time": 33455.8226211071, "episode/length": 202.0, "episode/score": 0.2210811399686463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2210811399686463}
{"step": 659744, "time": 33473.36227321625, "episode/length": 275.0, "episode/score": 0.321916660934221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.321916660934221}
{"step": 659888, "time": 33480.2985291481, "episode/length": 206.0, "episode/score": 0.2380159275353435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2380159275353435}
{"step": 660088, "time": 33504.52110004425, "eval_episode/length": 56.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9298245614035088}
{"step": 660088, "time": 33508.217041015625, "eval_episode/length": 48.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 660088, "time": 33511.83419299126, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 660088, "time": 33513.64411664009, "eval_episode/length": 156.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 660088, "time": 33515.33175778389, "eval_episode/length": 157.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 660088, "time": 33517.2829246521, "eval_episode/length": 164.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 660088, "time": 33519.6734392643, "eval_episode/length": 181.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 660088, "time": 33519.68222928047, "eval_episode/length": 181.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.978021978021978}
{"step": 660216, "time": 33524.55471301079, "episode/length": 131.0, "episode/score": 0.1383178227906683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1383178227906683}
{"step": 660232, "time": 33526.82247662544, "episode/length": 145.0, "episode/score": 0.16342541304993574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16342541304993574}
{"step": 660385, "time": 33534.9441344738, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.318783737543061, "train/action_min": 0.0, "train/action_std": 4.9674151300445315, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007946365060079404, "train/actor_opt_grad_steps": 40540.0, "train/actor_opt_loss": -11.317179500235348, "train/adv_mag": 0.17904010749473345, "train/adv_max": 0.1297898078997304, "train/adv_mean": -7.711883463845135e-05, "train/adv_min": -0.17781721090707253, "train/adv_std": 0.013476677367273043, "train/cont_avg": 0.9945174089566929, "train/cont_loss_mean": 0.00016109910835572603, "train/cont_loss_std": 0.0044844659071062295, "train/cont_neg_acc": 0.9938320217170115, "train/cont_neg_loss": 0.017564593121629356, "train/cont_pos_acc": 0.9999689915048795, "train/cont_pos_loss": 7.247399996659145e-05, "train/cont_pred": 0.9945166547467389, "train/cont_rate": 0.9945174089566929, "train/dyn_loss_mean": 11.483252420200138, "train/dyn_loss_std": 8.282231946629802, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14176457592352168, "train/extr_critic_critic_opt_grad_steps": 40540.0, "train/extr_critic_critic_opt_loss": 12204.041823019194, "train/extr_critic_mag": 0.2807203812862006, "train/extr_critic_max": 0.2807203812862006, "train/extr_critic_mean": 0.23060573907349052, "train/extr_critic_min": 0.002219421657051627, "train/extr_critic_std": 0.05857511622992557, "train/extr_return_normed_mag": 0.19972534677175086, "train/extr_return_normed_max": 0.19972534677175086, "train/extr_return_normed_mean": 0.1503214843160524, "train/extr_return_normed_min": -0.07917140224787193, "train/extr_return_normed_std": 0.06025440424798042, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2799325012785243, "train/extr_return_raw_max": 0.2799325012785243, "train/extr_return_raw_mean": 0.23052864363343697, "train/extr_return_raw_min": 0.0010357531975573441, "train/extr_return_raw_std": 0.060254404057315955, "train/extr_reward_mag": 0.0013450787762018638, "train/extr_reward_max": 0.0013450787762018638, "train/extr_reward_mean": 0.0010923047845185858, "train/extr_reward_min": 1.1248851385642225e-05, "train/extr_reward_std": 0.00023686297340538558, "train/image_loss_mean": 5.111292974216732, "train/image_loss_std": 9.784359500164122, "train/model_loss_mean": 12.041712220259539, "train/model_loss_std": 13.222712877228505, "train/model_opt_grad_norm": 54.38184418265275, "train/model_opt_grad_steps": 40500.51181102362, "train/model_opt_loss": 15170.148583599901, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.8425196850394, "train/policy_entropy_mag": 2.7666150735119195, "train/policy_entropy_max": 2.7666150735119195, "train/policy_entropy_mean": 2.1893150900292584, "train/policy_entropy_min": 0.07972466933914996, "train/policy_entropy_std": 0.5635932967888089, "train/policy_logprob_mag": 7.438177916008656, "train/policy_logprob_max": -0.00950396701136208, "train/policy_logprob_mean": -2.1905703150381255, "train/policy_logprob_min": -7.438177916008656, "train/policy_logprob_std": 1.0841093105594004, "train/policy_randomness_mag": 0.9764937143626176, "train/policy_randomness_max": 0.9764937143626176, "train/policy_randomness_mean": 0.7727321522442374, "train/policy_randomness_min": 0.02813930975229252, "train/policy_randomness_std": 0.1989237027844106, "train/post_ent_mag": 56.38983280452218, "train/post_ent_max": 56.38983280452218, "train/post_ent_mean": 40.012567445049136, "train/post_ent_min": 19.90246353750154, "train/post_ent_std": 6.638753121293436, "train/prior_ent_mag": 65.93382569560855, "train/prior_ent_max": 65.93382569560855, "train/prior_ent_mean": 51.52022909930372, "train/prior_ent_min": 30.296750812079964, "train/prior_ent_std": 5.431734561920166, "train/rep_loss_mean": 11.483252420200138, "train/rep_loss_std": 8.282231946629802, "train/reward_avg": 0.0010682068605665264, "train/reward_loss_mean": 0.04030664139023916, "train/reward_loss_std": 0.010997296692290175, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013023915253286287, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04030664127290718, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010683904447790792, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.7792452603297414, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.2264150943396226, "train_stats/max_log_achievement_collect_sapling": 0.5188679245283019, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.4339622641509434, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.009433962264150943, "train_stats/max_log_achievement_eat_cow": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.24528301886792453, "train_stats/max_log_achievement_place_table": 0.0660377358490566, "train_stats/max_log_achievement_wake_up": 0.20754716981132076, "train_stats/mean_log_entropy": 2.2200104020676523, "eval_stats/sum_log_reward": 0.3499999875202775, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 9.781797416508198e-07, "report/cont_loss_std": 1.7187607227242552e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00019908171088900417, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.013030382386205e-07, "report/cont_pred": 0.9960943460464478, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.289677619934082, "report/dyn_loss_std": 8.832708358764648, "report/image_loss_mean": 5.201387405395508, "report/image_loss_std": 10.246724128723145, "report/model_loss_mean": 12.616134643554688, "report/model_loss_std": 13.809680938720703, "report/post_ent_mag": 55.67046356201172, "report/post_ent_max": 55.67046356201172, "report/post_ent_mean": 39.369422912597656, "report/post_ent_min": 19.63338851928711, "report/post_ent_std": 6.536487102508545, "report/prior_ent_mag": 66.11146545410156, "report/prior_ent_max": 66.11146545410156, "report/prior_ent_mean": 51.38393020629883, "report/prior_ent_min": 32.92301940917969, "report/prior_ent_std": 5.928421974182129, "report/rep_loss_mean": 12.289677619934082, "report/rep_loss_std": 8.832708358764648, "report/reward_avg": 0.0010854823049157858, "report/reward_loss_mean": 0.04093943163752556, "report/reward_loss_std": 0.010052909143269062, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012508630752563477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04093942791223526, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010721201542764902, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.162532473448664e-05, "eval/cont_loss_std": 0.0004463069490157068, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0014210294466465712, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3377365576161537e-05, "eval/cont_pred": 0.9941357374191284, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 15.817476272583008, "eval/dyn_loss_std": 10.660642623901367, "eval/image_loss_mean": 6.925717353820801, "eval/image_loss_std": 11.30802059173584, "eval/model_loss_mean": 17.0822696685791, "eval/model_loss_std": 16.75330352783203, "eval/post_ent_mag": 53.02552032470703, "eval/post_ent_max": 53.02552032470703, "eval/post_ent_mean": 38.43032455444336, "eval/post_ent_min": 19.531620025634766, "eval/post_ent_std": 6.530898571014404, "eval/prior_ent_mag": 66.11146545410156, "eval/prior_ent_max": 66.11146545410156, "eval/prior_ent_mean": 51.32594680786133, "eval/prior_ent_min": 26.64291000366211, "eval/prior_ent_std": 5.457985877990723, "eval/rep_loss_mean": 15.817476272583008, "eval/rep_loss_std": 10.660642623901367, "eval/reward_avg": 0.004003905691206455, "eval/reward_loss_mean": 0.6660441160202026, "eval/reward_loss_std": 3.5482981204986572, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013104677200317383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.487377405166626, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.81568145751953, "eval/reward_pred": 0.0010437285527586937, "eval/reward_rate": 0.0087890625, "replay/size": 659881.0, "replay/inserts": 20368.0, "replay/samples": 20368.0, "replay/insert_wait_avg": 1.3868614902481354e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.36408147639584e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.175747568911918e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0175330638885, "timer/env.step_count": 2546.0, "timer/env.step_total": 234.38661575317383, "timer/env.step_frac": 0.23438250630971635, "timer/env.step_avg": 0.09206072888969907, "timer/env.step_min": 0.023134946823120117, "timer/env.step_max": 3.4607038497924805, "timer/replay._sample_count": 20368.0, "timer/replay._sample_total": 9.927910566329956, "timer/replay._sample_frac": 0.009927736502691586, "timer/replay._sample_avg": 0.0004874268738378808, "timer/replay._sample_min": 0.0004012584686279297, "timer/replay._sample_max": 0.010375738143920898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3000.0, "timer/agent.policy_total": 48.204418420791626, "timer/agent.policy_frac": 0.048203573264461924, "timer/agent.policy_avg": 0.01606813947359721, "timer/agent.policy_min": 0.00974273681640625, "timer/agent.policy_max": 0.09255456924438477, "timer/dataset_train_count": 1273.0, "timer/dataset_train_total": 0.14389610290527344, "timer/dataset_train_frac": 0.00014389358000994198, "timer/dataset_train_avg": 0.00011303700149667984, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0010693073272705078, "timer/agent.train_count": 1273.0, "timer/agent.train_total": 571.7285420894623, "timer/agent.train_frac": 0.5717185181121579, "timer/agent.train_avg": 0.4491190432753042, "timer/agent.train_min": 0.4355621337890625, "timer/agent.train_max": 1.0791609287261963, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717538356781006, "timer/agent.report_frac": 0.0004717455645329785, "timer/agent.report_avg": 0.2358769178390503, "timer/agent.report_min": 0.22838854789733887, "timer/agent.report_max": 0.24336528778076172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9086556673934163e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 20.367361402758753}
{"step": 660464, "time": 33538.15691804886, "episode/length": 407.0, "episode/score": 0.373235418144759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.373235418144759}
{"step": 660528, "time": 33542.02273988724, "episode/length": 161.0, "episode/score": 0.1912569408100353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1912569408100353}
{"step": 660560, "time": 33544.71958041191, "episode/length": 153.0, "episode/score": 0.16454233603553803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16454233603553803}
{"step": 660624, "time": 33549.234659433365, "episode/length": 184.0, "episode/score": 0.20460582967825758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20460582967825758}
{"step": 661160, "time": 33571.38050198555, "episode/length": 158.0, "episode/score": 0.1683061678818376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1683061678818376}
{"step": 661168, "time": 33573.50340270996, "episode/length": 67.0, "episode/score": 0.07240597285090189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07240597285090189}
{"step": 661376, "time": 33582.749648571014, "episode/length": 144.0, "episode/score": 0.14868878505785688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14868878505785688}
{"step": 661632, "time": 33593.976634025574, "episode/length": 235.0, "episode/score": 0.25420650631986064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25420650631986064}
{"step": 661696, "time": 33597.86258864403, "episode/length": 153.0, "episode/score": 0.15028144415828137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15028144415828137}
{"step": 661904, "time": 33607.178793907166, "episode/length": 167.0, "episode/score": 0.18312780341875623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18312780341875623}
{"step": 661928, "time": 33609.42431807518, "episode/length": 211.0, "episode/score": 0.23182686877225933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23182686877225933}
{"step": 662096, "time": 33617.65663790703, "episode/length": 195.0, "episode/score": 0.22210165600563414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22210165600563414}
{"step": 662456, "time": 33632.40469264984, "episode/length": 160.0, "episode/score": 0.16417659482567615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16417659482567615}
{"step": 662896, "time": 33650.68319916725, "episode/length": 189.0, "episode/score": 0.195508721123133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.195508721123133}
{"step": 662960, "time": 33654.69033551216, "episode/length": 157.0, "episode/score": 0.1668718686560169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1668718686560169}
{"step": 663024, "time": 33658.76219749451, "episode/length": 139.0, "episode/score": 0.1506130167399533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1506130167399533}
{"step": 663152, "time": 33665.13376188278, "episode/length": 86.0, "episode/score": 0.09655367696541362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09655367696541362}
{"step": 663360, "time": 33674.60038590431, "episode/length": 157.0, "episode/score": 0.15918945340672508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15918945340672508}
{"step": 663480, "time": 33680.48580503464, "episode/length": 289.0, "episode/score": 0.34731961487841545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34731961487841545}
{"step": 663632, "time": 33689.37231683731, "episode/length": 212.0, "episode/score": 0.2311640497209737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2311640497209737}
{"step": 664128, "time": 33709.57733845711, "episode/length": 311.0, "episode/score": 0.352246755224769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.352246755224769}
{"step": 664232, "time": 33714.708523750305, "episode/length": 158.0, "episode/score": 0.18593508381673018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18593508381673018}
{"step": 664728, "time": 33734.77629685402, "episode/length": 196.0, "episode/score": 0.20588426267568138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20588426267568138}
{"step": 664808, "time": 33739.322536706924, "episode/length": 180.0, "episode/score": 0.18044093991920818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18044093991920818}
{"step": 664920, "time": 33745.5699198246, "episode/length": 160.0, "episode/score": 0.19424999604234472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19424999604234472}
{"step": 664976, "time": 33749.40966296196, "episode/length": 243.0, "episode/score": 0.2687068316845398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2687068316845398}
{"step": 665208, "time": 33759.40535187721, "episode/length": 288.0, "episode/score": 0.322770148904965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.322770148904965}
{"step": 665288, "time": 33764.145096063614, "episode/length": 225.0, "episode/score": 0.2534283712520846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2534283712520846}
{"step": 665368, "time": 33768.658077955246, "episode/length": 141.0, "episode/score": 0.14767719474912155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14767719474912155}
{"step": 665648, "time": 33780.823528289795, "episode/length": 189.0, "episode/score": 0.1928468559308385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1928468559308385}
{"step": 666000, "time": 33795.43879151344, "episode/length": 158.0, "episode/score": 0.17219211094743514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17219211094743514}
{"step": 666168, "time": 33803.0878777504, "episode/length": 155.0, "episode/score": 0.17314850818183913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17314850818183913}
{"step": 666168, "time": 33803.09585595131, "episode/length": 169.0, "episode/score": 0.1761773007146985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1761773007146985}
{"step": 666200, "time": 33807.64857530594, "episode/length": 123.0, "episode/score": 0.14719297962801647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14719297962801647}
{"step": 666280, "time": 33812.30102753639, "episode/length": 162.0, "episode/score": 0.18283064827119233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18283064827119233}
{"step": 666920, "time": 33837.84381771088, "episode/length": 203.0, "episode/score": 0.21461583042764687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21461583042764687}
{"step": 666976, "time": 33841.59916186333, "episode/length": 200.0, "episode/score": 0.22358597438687866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22358597438687866}
{"step": 667344, "time": 33857.03038907051, "episode/length": 142.0, "episode/score": 0.1667889787513559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1667889787513559}
{"step": 667368, "time": 33859.716248989105, "episode/length": 170.0, "episode/score": 0.19750034955904994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19750034955904994}
{"step": 667464, "time": 33865.434690237045, "episode/length": 226.0, "episode/score": 0.22452944940596353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22452944940596353}
{"step": 667520, "time": 33869.494599342346, "episode/length": 168.0, "episode/score": 0.1829280594974989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1829280594974989}
{"step": 667904, "time": 33885.3473982811, "episode/length": 216.0, "episode/score": 0.2509959425551642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2509959425551642}
{"step": 668160, "time": 33896.50092244148, "episode/length": 154.0, "episode/score": 0.16027722191574867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16027722191574867}
{"step": 668424, "time": 33907.68619227409, "episode/length": 267.0, "episode/score": 0.30155350370660017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30155350370660017}
{"step": 668560, "time": 33914.66489005089, "episode/length": 151.0, "episode/score": 0.15861059157032287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15861059157032287}
{"step": 668712, "time": 33921.753296136856, "episode/length": 155.0, "episode/score": 0.15387211338838824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15387211338838824}
{"step": 668960, "time": 33932.851043224335, "episode/length": 131.0, "episode/score": 0.15450210595463432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15450210595463432}
{"step": 669176, "time": 33942.24682426453, "episode/length": 206.0, "episode/score": 0.22503775019413297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22503775019413297}
{"step": 669792, "time": 33966.969053030014, "episode/length": 170.0, "episode/score": 0.1967203591211728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1967203591211728}
{"step": 669896, "time": 33972.25257110596, "episode/length": 147.0, "episode/score": 0.16400642818916822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16400642818916822}
{"step": 670000, "time": 33977.95267343521, "episode/length": 179.0, "episode/score": 0.1868830759485718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1868830759485718}
{"step": 670072, "time": 34000.241226911545, "eval_episode/length": 118.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.957983193277311}
{"step": 670072, "time": 34002.8336391449, "eval_episode/length": 145.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 670072, "time": 34005.201476335526, "eval_episode/length": 160.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 670072, "time": 34006.95949077606, "eval_episode/length": 164.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 670072, "time": 34008.79366016388, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 670072, "time": 34011.02140879631, "eval_episode/length": 181.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 670072, "time": 34013.07405638695, "eval_episode/length": 191.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 670072, "time": 34016.61650300026, "eval_episode/length": 43.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8863636363636364}
{"step": 670216, "time": 34021.939135074615, "episode/length": 156.0, "episode/score": 0.17191813574481785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17191813574481785}
{"step": 670240, "time": 34024.64094901085, "episode/length": 407.0, "episode/score": 0.45541983392558905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45541983392558905}
{"step": 670496, "time": 34035.882687568665, "episode/length": 164.0, "episode/score": 0.17050660122367844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17050660122367844}
{"step": 670592, "time": 34041.20286273956, "episode/length": 402.0, "episode/score": 0.3844415155836032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3844415155836032}
{"step": 671096, "time": 34061.144512176514, "episode/length": 162.0, "episode/score": 0.17565426566216047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17565426566216047}
{"step": 671376, "time": 34073.34851717949, "episode/length": 171.0, "episode/score": 0.19357056156059116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19357056156059116}
{"step": 671384, "time": 34075.02495908737, "episode/length": 402.0, "episode/score": 0.37964028320311627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.37964028320311627}
{"step": 671424, "time": 34078.26060795784, "episode/length": 147.0, "episode/score": 0.16479818849256844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16479818849256844}
{"step": 671432, "time": 34079.90569591522, "episode/length": 191.0, "episode/score": 0.22375320743230986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22375320743230986}
{"step": 671752, "time": 34093.923134088516, "episode/length": 191.0, "episode/score": 0.21132760050113575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21132760050113575}
{"step": 672512, "time": 34125.2381272316, "episode/length": 141.0, "episode/score": 0.1531359197351776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1531359197351776}
{"step": 672600, "time": 34129.90555667877, "episode/length": 262.0, "episode/score": 0.29720662565614475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29720662565614475}
{"step": 672696, "time": 34135.03463625908, "episode/length": 262.0, "episode/score": 0.2880053368080553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2880053368080553}
{"step": 672776, "time": 34139.63446855545, "episode/length": 168.0, "episode/score": 0.17699919450751622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17699919450751622}
{"step": 672952, "time": 34147.80916261673, "episode/length": 195.0, "episode/score": 0.21551613308020023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21551613308020023}
{"step": 673096, "time": 34154.80877542496, "episode/length": 167.0, "episode/score": 0.17137148329857155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17137148329857155}
{"step": 673376, "time": 34166.97622156143, "episode/length": 242.0, "episode/score": 0.2575632429598045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2575632429598045}
{"step": 673584, "time": 34176.26339864731, "episode/length": 60.0, "episode/score": 0.06873203908617143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06873203908617143}
{"step": 673952, "time": 34191.552595853806, "episode/length": 168.0, "episode/score": 0.1910482423263602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1910482423263602}
{"step": 674064, "time": 34197.289273262024, "episode/length": 170.0, "episode/score": 0.19800808998115826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19800808998115826}
{"step": 674248, "time": 34205.47366642952, "episode/length": 161.0, "episode/score": 0.1710953905567294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1710953905567294}
{"step": 674552, "time": 34218.54504799843, "episode/length": 431.0, "episode/score": 0.46011018495664757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.46011018495664757}
{"step": 675000, "time": 34236.959423303604, "episode/length": 176.0, "episode/score": 0.17427992772718426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17427992772718426}
{"step": 675080, "time": 34241.4256567955, "episode/length": 140.0, "episode/score": 0.14411668472894235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14411668472894235}
{"step": 675288, "time": 34250.75981044769, "episode/length": 238.0, "episode/score": 0.26348871179288835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26348871179288835}
{"step": 675384, "time": 34255.885756492615, "episode/length": 358.0, "episode/score": 0.3377524414263462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3377524414263462}
{"step": 675712, "time": 34269.88313341141, "episode/length": 205.0, "episode/score": 0.2185112434781331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2185112434781331}
{"step": 675840, "time": 34276.23638629913, "episode/length": 198.0, "episode/score": 0.1635012285951234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1635012285951234}
{"step": 676096, "time": 34287.30347585678, "episode/length": 414.0, "episode/score": 0.4372925953794038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4372925953794038}
{"step": 676168, "time": 34291.40925073624, "episode/length": 201.0, "episode/score": 0.22175793733367755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22175793733367755}
{"step": 676544, "time": 34307.35349202156, "episode/length": 182.0, "episode/score": 0.19623228474665666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19623228474665666}
{"step": 676664, "time": 34313.103299856186, "episode/length": 207.0, "episode/score": 0.22578919266197772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22578919266197772}
{"step": 676872, "time": 34322.42778015137, "episode/length": 185.0, "episode/score": 0.20558801232073165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20558801232073165}
{"step": 677120, "time": 34333.590386390686, "episode/length": 228.0, "episode/score": 0.25321268144216447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25321268144216447}
{"step": 677160, "time": 34337.1334335804, "episode/length": 180.0, "episode/score": 0.20113333589870308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20113333589870308}
{"step": 677384, "time": 34347.54314804077, "episode/length": 151.0, "episode/score": 0.16455196293645713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16455196293645713}
{"step": 677904, "time": 34369.39181351662, "episode/length": 225.0, "episode/score": 0.2306209392463643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2306209392463643}
{"step": 678040, "time": 34375.78147959709, "episode/length": 145.0, "episode/score": 0.13287657905584638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13287657905584638}
{"step": 678136, "time": 34380.903198480606, "episode/length": 286.0, "episode/score": 0.3240977346431464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3240977346431464}
{"step": 678352, "time": 34390.68215751648, "episode/length": 225.0, "episode/score": 0.24938197923620464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24938197923620464}
{"step": 678456, "time": 34396.01097726822, "episode/length": 161.0, "episode/score": 0.16215219612058718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16215219612058718}
{"step": 678456, "time": 34396.019611120224, "episode/length": 223.0, "episode/score": 0.22865519035804027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22865519035804027}
{"step": 678536, "time": 34402.30942797661, "episode/length": 49.0, "episode/score": 0.056749999115709215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056749999115709215}
{"step": 678648, "time": 34408.124589920044, "episode/length": 190.0, "episode/score": 0.20198058231380855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20198058231380855}
{"step": 679376, "time": 34437.68191623688, "episode/length": 166.0, "episode/score": 0.1716483909285671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1716483909285671}
{"step": 679496, "time": 34443.655378341675, "episode/length": 198.0, "episode/score": 0.21743739459452627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21743739459452627}
{"step": 679680, "time": 34452.394115448, "episode/length": 165.0, "episode/score": 0.1815050083296228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1815050083296228}
{"step": 679712, "time": 34455.21808552742, "episode/length": 156.0, "episode/score": 0.16795540041039203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16795540041039203}
{"step": 679880, "time": 34462.96246314049, "episode/length": 177.0, "episode/score": 0.18711789479129948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18711789479129948}
{"step": 679936, "time": 34466.97983455658, "episode/length": 174.0, "episode/score": 0.1913661065436827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1913661065436827}
{"step": 679960, "time": 34470.96946501732, "episode/length": 163.0, "episode/score": 0.18237456814767938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18237456814767938}
{"step": 680056, "time": 34497.15086054802, "eval_episode/length": 159.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.99375}
{"step": 680056, "time": 34499.13352918625, "eval_episode/length": 170.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 680056, "time": 34500.78915667534, "eval_episode/length": 171.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9593023255813954}
{"step": 680056, "time": 34502.752838134766, "eval_episode/length": 180.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.994475138121547}
{"step": 680056, "time": 34504.585641384125, "eval_episode/length": 186.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 680056, "time": 34507.59468579292, "eval_episode/length": 215.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 680056, "time": 34509.32369017601, "eval_episode/length": 216.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 680056, "time": 34510.96995592117, "eval_episode/length": 217.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 680096, "time": 34512.65648674965, "episode/length": 338.0, "episode/score": 0.38544946032106964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38544946032106964}
{"step": 680641, "time": 34535.00093269348, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.34153687484621, "train/action_min": 0.0, "train/action_std": 4.913482147877611, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008067103634463755, "train/actor_opt_grad_steps": 41810.0, "train/actor_opt_loss": -6.568897816462545, "train/adv_mag": 0.18137381143691972, "train/adv_max": 0.13011347027275505, "train/adv_mean": 0.00021172365261123546, "train/adv_min": -0.18101221950739388, "train/adv_std": 0.013702583073924376, "train/cont_avg": 0.9944251353346457, "train/cont_loss_mean": 0.00010522759115722811, "train/cont_loss_std": 0.0031444306207204387, "train/cont_neg_acc": 0.9965785535301749, "train/cont_neg_loss": 0.011028616112235889, "train/cont_pos_acc": 0.999992247172228, "train/cont_pos_loss": 4.1054540261318305e-05, "train/cont_pred": 0.9944417955368523, "train/cont_rate": 0.9944251353346457, "train/dyn_loss_mean": 11.474358896570882, "train/dyn_loss_std": 8.363593030163623, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1282979900853371, "train/extr_critic_critic_opt_grad_steps": 41810.0, "train/extr_critic_critic_opt_loss": 12322.695658526083, "train/extr_critic_mag": 0.28083453966876654, "train/extr_critic_max": 0.28083453966876654, "train/extr_critic_mean": 0.2331863665205287, "train/extr_critic_min": 0.0019457265148012657, "train/extr_critic_std": 0.057990904457456485, "train/extr_return_normed_mag": 0.19691144094223112, "train/extr_return_normed_max": 0.19691144094223112, "train/extr_return_normed_mean": 0.1500839399775182, "train/extr_return_normed_min": -0.08231244406362218, "train/extr_return_normed_std": 0.05967468325430014, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28022557027696626, "train/extr_return_raw_max": 0.28022557027696626, "train/extr_return_raw_mean": 0.23339807306687663, "train/extr_return_raw_min": 0.0010016856231088713, "train/extr_return_raw_std": 0.05967468325430014, "train/extr_reward_mag": 0.0013438829286830632, "train/extr_reward_max": 0.0013438829286830632, "train/extr_reward_mean": 0.0010902465222124744, "train/extr_reward_min": 1.1910603741022546e-05, "train/extr_reward_std": 0.00023835657866154688, "train/image_loss_mean": 5.137339494359775, "train/image_loss_std": 9.632271627741536, "train/model_loss_mean": 12.062224883732833, "train/model_loss_std": 13.146780366972676, "train/model_opt_grad_norm": 56.67697965066264, "train/model_opt_grad_steps": 41769.330708661415, "train/model_opt_loss": 15545.203286478838, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1289.3700787401574, "train/policy_entropy_mag": 2.7659829019561526, "train/policy_entropy_max": 2.7659829019561526, "train/policy_entropy_mean": 2.1465835777793343, "train/policy_entropy_min": 0.07964796490791276, "train/policy_entropy_std": 0.594590706618752, "train/policy_logprob_mag": 7.438259676685483, "train/policy_logprob_max": -0.009493469392631466, "train/policy_logprob_mean": -2.1453985154159425, "train/policy_logprob_min": -7.438259676685483, "train/policy_logprob_std": 1.1186083536448441, "train/policy_randomness_mag": 0.9762705817935974, "train/policy_randomness_max": 0.9762705817935974, "train/policy_randomness_mean": 0.7576497999701913, "train/policy_randomness_min": 0.028112236366379918, "train/policy_randomness_std": 0.20986442526025095, "train/post_ent_mag": 56.7379680543434, "train/post_ent_max": 56.7379680543434, "train/post_ent_mean": 40.2188414926604, "train/post_ent_min": 19.8383881426233, "train/post_ent_std": 6.822208122944269, "train/prior_ent_mag": 65.90238141638088, "train/prior_ent_max": 65.90238141638088, "train/prior_ent_mean": 51.72660896721787, "train/prior_ent_min": 30.33993707491657, "train/prior_ent_std": 5.403463412457564, "train/rep_loss_mean": 11.474358896570882, "train/rep_loss_std": 8.363593030163623, "train/reward_avg": 0.0010638310524495685, "train/reward_loss_mean": 0.04016490154496328, "train/reward_loss_std": 0.011078490333000976, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013072941246933824, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040164901720961245, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00106423077408195, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.847572791127904, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.436893203883495, "train_stats/max_log_achievement_collect_sapling": 0.5533980582524272, "train_stats/max_log_achievement_collect_stone": 0.009708737864077669, "train_stats/max_log_achievement_collect_wood": 0.4563106796116505, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009708737864077669, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009708737864077669, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.24271844660194175, "train_stats/max_log_achievement_place_table": 0.04854368932038835, "train_stats/max_log_achievement_wake_up": 0.20388349514563106, "train_stats/mean_log_entropy": 2.2132668448883352, "train_stats/max_log_achievement_place_stone": 0.012048192771084338, "eval_stats/sum_log_reward": 0.7249999968335032, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00295156124047935, "report/cont_loss_std": 0.09359800815582275, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.7491881251335144, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.5144054234260693e-05, "report/cont_pred": 0.9969968795776367, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.458839416503906, "report/dyn_loss_std": 8.355925559997559, "report/image_loss_mean": 6.194410800933838, "report/image_loss_std": 9.78844928741455, "report/model_loss_mean": 13.713727951049805, "report/model_loss_std": 12.984172821044922, "report/post_ent_mag": 57.95258331298828, "report/post_ent_max": 57.95258331298828, "report/post_ent_mean": 39.334571838378906, "report/post_ent_min": 19.92268180847168, "report/post_ent_std": 7.0239033699035645, "report/prior_ent_mag": 66.03089904785156, "report/prior_ent_max": 66.03089904785156, "report/prior_ent_mean": 51.84309768676758, "report/prior_ent_min": 26.107046127319336, "report/prior_ent_std": 5.739941596984863, "report/rep_loss_mean": 12.458839416503906, "report/rep_loss_std": 8.355925559997559, "report/reward_avg": 0.0010901610367000103, "report/reward_loss_mean": 0.041061922907829285, "report/reward_loss_std": 0.010300694964826107, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013360977172851562, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.041061922907829285, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010915396269410849, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.7464155462221242e-05, "eval/cont_loss_std": 0.0005432767211459577, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.830137524753809e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7344162188237533e-05, "eval/cont_pred": 0.9970533847808838, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.543598175048828, "eval/dyn_loss_std": 9.741765022277832, "eval/image_loss_mean": 8.495447158813477, "eval/image_loss_std": 12.819531440734863, "eval/model_loss_mean": 19.597183227539062, "eval/model_loss_std": 17.311857223510742, "eval/post_ent_mag": 52.48546600341797, "eval/post_ent_max": 52.48546600341797, "eval/post_ent_mean": 37.908485412597656, "eval/post_ent_min": 20.16484832763672, "eval/post_ent_std": 6.297847270965576, "eval/prior_ent_mag": 66.03089904785156, "eval/prior_ent_max": 66.03089904785156, "eval/prior_ent_mean": 52.12324905395508, "eval/prior_ent_min": 33.63762283325195, "eval/prior_ent_std": 4.7715229988098145, "eval/rep_loss_mean": 17.543598175048828, "eval/rep_loss_std": 9.741765022277832, "eval/reward_avg": 0.01015624962747097, "eval/reward_loss_mean": 0.5755585432052612, "eval/reward_loss_std": 3.3216428756713867, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.3149030804634094, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.84653091430664, "eval/reward_pred": 0.0010692669311538339, "eval/reward_rate": 0.0126953125, "replay/size": 680137.0, "replay/inserts": 20256.0, "replay/samples": 20256.0, "replay/insert_wait_avg": 1.395765639029408e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.361599456642476e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1909113056334105e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0469243526459, "timer/env.step_count": 2532.0, "timer/env.step_total": 235.41038179397583, "timer/env.step_frac": 0.23539933583252862, "timer/env.step_avg": 0.0929740844367993, "timer/env.step_min": 0.023154735565185547, "timer/env.step_max": 3.359041929244995, "timer/replay._sample_count": 20256.0, "timer/replay._sample_total": 9.901427268981934, "timer/replay._sample_frac": 0.009900962672717945, "timer/replay._sample_avg": 0.000488814537370751, "timer/replay._sample_min": 0.00036907196044921875, "timer/replay._sample_max": 0.008733510971069336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2986.0, "timer/agent.policy_total": 49.506845235824585, "timer/agent.policy_frac": 0.04950452226816411, "timer/agent.policy_avg": 0.016579653461428194, "timer/agent.policy_min": 0.009701013565063477, "timer/agent.policy_max": 0.12483024597167969, "timer/dataset_train_count": 1266.0, "timer/dataset_train_total": 0.14473319053649902, "timer/dataset_train_frac": 0.00014472639934389904, "timer/dataset_train_avg": 0.0001143232152736959, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0009400844573974609, "timer/agent.train_count": 1266.0, "timer/agent.train_total": 568.203428030014, "timer/agent.train_frac": 0.5681767667030481, "timer/agent.train_avg": 0.4488178736414013, "timer/agent.train_min": 0.43326234817504883, "timer/agent.train_max": 1.075166940689087, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787330627441406, "timer/agent.report_frac": 0.0004787105995591516, "timer/agent.report_avg": 0.2393665313720703, "timer/agent.report_min": 0.2306373119354248, "timer/agent.report_max": 0.24809575080871582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051614617459551e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 20.254776630622533}
{"step": 680768, "time": 34540.02268457413, "episode/length": 158.0, "episode/score": 0.17253183991851984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17253183991851984}
{"step": 680848, "time": 34544.68839287758, "episode/length": 145.0, "episode/score": 0.13958916410047095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13958916410047095}
{"step": 680888, "time": 34547.501260995865, "episode/length": 188.0, "episode/score": 0.18994477002888743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18994477002888743}
{"step": 681096, "time": 34556.94368934631, "episode/length": 151.0, "episode/score": 0.17824127203220996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17824127203220996}
{"step": 681256, "time": 34564.39754343033, "episode/length": 161.0, "episode/score": 0.17394005128608114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17394005128608114}
{"step": 681280, "time": 34567.07441973686, "episode/length": 147.0, "episode/score": 0.16944270518797566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16944270518797566}
{"step": 681808, "time": 34588.360965013504, "episode/length": 233.0, "episode/score": 0.24416830904647213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24416830904647213}
{"step": 682024, "time": 34597.68394994736, "episode/length": 141.0, "episode/score": 0.16610475704146666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16610475704146666}
{"step": 682168, "time": 34604.74980401993, "episode/length": 174.0, "episode/score": 0.19639174732219544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19639174732219544}
{"step": 682200, "time": 34607.46843314171, "episode/length": 310.0, "episode/score": 0.35293737477786635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35293737477786635}
{"step": 682456, "time": 34618.61135339737, "episode/length": 200.0, "episode/score": 0.19903136841003288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19903136841003288}
{"step": 682496, "time": 34621.96347618103, "episode/length": 154.0, "episode/score": 0.1510060041809993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1510060041809993}
{"step": 682568, "time": 34626.02860403061, "episode/length": 160.0, "episode/score": 0.17161636416039983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17161636416039983}
{"step": 682576, "time": 34628.19615793228, "episode/length": 184.0, "episode/score": 0.19582272475599893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19582272475599893}
{"step": 683288, "time": 34656.017050266266, "episode/length": 139.0, "episode/score": 0.15923543649751082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15923543649751082}
{"step": 683288, "time": 34656.025376319885, "episode/length": 184.0, "episode/score": 0.18896722476529249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18896722476529249}
{"step": 683544, "time": 34669.16116976738, "episode/length": 189.0, "episode/score": 0.21234109375382104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21234109375382104}
{"step": 683568, "time": 34671.934807777405, "episode/length": 170.0, "episode/score": 0.18267974321406655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18267974321406655}
{"step": 683584, "time": 34674.05333709717, "episode/length": 135.0, "episode/score": 0.12872790425763014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12872790425763014}
{"step": 683800, "time": 34683.32299518585, "episode/length": 152.0, "episode/score": 0.1447445567628165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1447445567628165}
{"step": 683992, "time": 34691.966146707535, "episode/length": 191.0, "episode/score": 0.19496016144057648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19496016144057648}
{"step": 684424, "time": 34709.722628593445, "episode/length": 104.0, "episode/score": 0.12155390447878744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12155390447878744}
{"step": 684488, "time": 34713.79511022568, "episode/length": 149.0, "episode/score": 0.17006707724112857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17006707724112857}
{"step": 684880, "time": 34730.31846380234, "episode/length": 198.0, "episode/score": 0.21741456997460773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21741456997460773}
{"step": 684960, "time": 34734.99527025223, "episode/length": 173.0, "episode/score": 0.20588109347136196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20588109347136196}
{"step": 685064, "time": 34740.31190156937, "episode/length": 189.0, "episode/score": 0.17915168493072997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17915168493072997}
{"step": 685240, "time": 34748.65165781975, "episode/length": 155.0, "episode/score": 0.1697324127471802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1697324127471802}
{"step": 685288, "time": 34751.99320268631, "episode/length": 185.0, "episode/score": 0.20844392607523332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20844392607523332}
{"step": 685864, "time": 34775.16092848778, "episode/length": 171.0, "episode/score": 0.16780726412025615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16780726412025615}
{"step": 685904, "time": 34778.54676795006, "episode/length": 416.0, "episode/score": 0.4261399145229916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4261399145229916}
{"step": 686024, "time": 34784.376661777496, "episode/length": 199.0, "episode/score": 0.21884520682579023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21884520682579023}
{"step": 686240, "time": 34794.21912574768, "episode/length": 159.0, "episode/score": 0.18443743871193874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18443743871193874}
{"step": 686632, "time": 34810.49514079094, "episode/length": 218.0, "episode/score": 0.22108406629831734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22108406629831734}
{"step": 686656, "time": 34813.537167310715, "episode/length": 170.0, "episode/score": 0.17664493897427747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17664493897427747}
{"step": 686680, "time": 34816.422520160675, "episode/length": 201.0, "episode/score": 0.21577540089310787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21577540089310787}
{"step": 687008, "time": 34831.11589407921, "episode/length": 142.0, "episode/score": 0.17483332959818654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17483332959818654}
{"step": 687176, "time": 34838.83422803879, "episode/length": 241.0, "episode/score": 0.24370880269088957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24370880269088957}
{"step": 687296, "time": 34845.24356675148, "episode/length": 158.0, "episode/score": 0.16354041583008438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16354041583008438}
{"step": 687488, "time": 34853.99075961113, "episode/length": 197.0, "episode/score": 0.22429991836861518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22429991836861518}
{"step": 687896, "time": 34870.506517887115, "episode/length": 206.0, "episode/score": 0.21072728159242615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21072728159242615}
{"step": 688208, "time": 34885.37304139137, "episode/length": 193.0, "episode/score": 0.20172318091090347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20172318091090347}
{"step": 688376, "time": 34893.07045865059, "episode/length": 217.0, "episode/score": 0.2308510967636721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2308510967636721}
{"step": 688720, "time": 34907.90287780762, "episode/length": 192.0, "episode/score": 0.1878830205232589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1878830205232589}
{"step": 688800, "time": 34912.411762714386, "episode/length": 223.0, "episode/score": 0.2680238042084966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2680238042084966}
{"step": 688952, "time": 34919.46375012398, "episode/length": 206.0, "episode/score": 0.22693669363798108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22693669363798108}
{"step": 689184, "time": 34930.01202893257, "episode/length": 312.0, "episode/score": 0.3509620327386074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3509620327386074}
{"step": 689584, "time": 34947.087317466736, "episode/length": 171.0, "episode/score": 0.17785639975772938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17785639975772938}
{"step": 689600, "time": 34949.27600765228, "episode/length": 212.0, "episode/score": 0.23069335364880317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23069335364880317}
{"step": 689816, "time": 34958.67177557945, "episode/length": 179.0, "episode/score": 0.1872109868068037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1872109868068037}
{"step": 689912, "time": 34963.77725625038, "episode/length": 148.0, "episode/score": 0.1564236843346407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1564236843346407}
{"step": 690040, "time": 34989.80810070038, "eval_episode/length": 156.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 690040, "time": 34991.823556661606, "eval_episode/length": 166.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 690040, "time": 34991.82961559296, "eval_episode/length": 166.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 690040, "time": 34995.42471218109, "eval_episode/length": 172.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 690040, "time": 34997.14130592346, "eval_episode/length": 175.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 690040, "time": 34999.103149175644, "eval_episode/length": 184.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 690040, "time": 35002.33066177368, "eval_episode/length": 223.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 690040, "time": 35008.28008270264, "eval_episode/length": 154.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 690296, "time": 35018.158994436264, "episode/length": 186.0, "episode/score": 0.19921328547798112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19921328547798112}
{"step": 690456, "time": 35026.25599575043, "episode/length": 187.0, "episode/score": 0.17839499516594515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17839499516594515}
{"step": 690912, "time": 35045.316175460815, "episode/length": 136.0, "episode/score": 0.16063803325050685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16063803325050685}
{"step": 691056, "time": 35052.20018339157, "episode/length": 445.0, "episode/score": 0.4006262814236834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4006262814236834}
{"step": 691224, "time": 35060.05402636528, "episode/length": 163.0, "episode/score": 0.17372898192661523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17372898192661523}
{"step": 691448, "time": 35069.929624795914, "episode/length": 232.0, "episode/score": 0.2572708025245447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2572708025245447}
{"step": 691712, "time": 35081.639129161835, "episode/length": 156.0, "episode/score": 0.17221209493618517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17221209493618517}
{"step": 691728, "time": 35083.82946562767, "episode/length": 317.0, "episode/score": 0.3426860508589016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3426860508589016}
{"step": 691856, "time": 35090.31289386749, "episode/length": 194.0, "episode/score": 0.22012492017756813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22012492017756813}
{"step": 692072, "time": 35099.70374441147, "episode/length": 144.0, "episode/score": 0.1531513752779574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1531513752779574}
{"step": 692272, "time": 35109.042112112045, "episode/length": 333.0, "episode/score": 0.3643254933354001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3643254933354001}
{"step": 692768, "time": 35129.37599182129, "episode/length": 192.0, "episode/score": 0.19225415133951174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19225415133951174}
{"step": 692880, "time": 35135.19089102745, "episode/length": 145.0, "episode/score": 0.17297468201968513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17297468201968513}
{"step": 692960, "time": 35139.80358529091, "episode/length": 153.0, "episode/score": 0.17427777498960495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17427777498960495}
{"step": 692992, "time": 35142.56485915184, "episode/length": 141.0, "episode/score": 0.17320832976838574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17320832976838574}
{"step": 693336, "time": 35157.48425769806, "episode/length": 157.0, "episode/score": 0.18650694086682051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18650694086682051}
{"step": 693400, "time": 35161.502141952515, "episode/length": 292.0, "episode/score": 0.3342268147334835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3342268147334835}
{"step": 693560, "time": 35169.27563548088, "episode/length": 263.0, "episode/score": 0.2890494148077778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2890494148077778}
{"step": 693728, "time": 35178.136053323746, "episode/length": 181.0, "episode/score": 0.20822726919141132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20822726919141132}
{"step": 693736, "time": 35180.27818226814, "episode/length": 41.0, "episode/score": 0.05031249899184331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05031249899184331}
{"step": 694064, "time": 35195.187089681625, "episode/length": 161.0, "episode/score": 0.17750495752261486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17750495752261486}
{"step": 694336, "time": 35207.761029958725, "episode/length": 167.0, "episode/score": 0.17680091407964937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17680091407964937}
{"step": 694400, "time": 35212.07927298546, "episode/length": 189.0, "episode/score": 0.21391844882600708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21391844882600708}
{"step": 694928, "time": 35233.38787651062, "episode/length": 148.0, "episode/score": 0.16750531796060386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16750531796060386}
{"step": 695072, "time": 35240.488921165466, "episode/length": 263.0, "episode/score": 0.29303259588050423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29303259588050423}
{"step": 695208, "time": 35246.886248111725, "episode/length": 205.0, "episode/score": 0.22081118005735334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22081118005735334}
{"step": 695464, "time": 35258.02476167679, "episode/length": 174.0, "episode/score": 0.1825088537989359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1825088537989359}
{"step": 695600, "time": 35265.00490236282, "episode/length": 282.0, "episode/score": 0.30286534308834234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30286534308834234}
{"step": 695640, "time": 35267.806784152985, "episode/length": 162.0, "episode/score": 0.18120358072701492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18120358072701492}
{"step": 695888, "time": 35278.91599488258, "episode/length": 185.0, "episode/score": 0.20114479092444526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20114479092444526}
{"step": 695896, "time": 35280.88402080536, "episode/length": 270.0, "episode/score": 0.33208332653157413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33208332653157413}
{"step": 696248, "time": 35296.13421916962, "episode/length": 164.0, "episode/score": 0.18045560934479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18045560934479}
{"step": 696408, "time": 35305.20821714401, "episode/length": 166.0, "episode/score": 0.18274049200772424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18274049200772424}
{"step": 696712, "time": 35318.165019989014, "episode/length": 155.0, "episode/score": 0.15864737008450902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15864737008450902}
{"step": 696776, "time": 35322.20140218735, "episode/length": 195.0, "episode/score": 0.2057136514413287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2057136514413287}
{"step": 697152, "time": 35338.191242456436, "episode/length": 193.0, "episode/score": 0.2198614195567643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2198614195567643}
{"step": 697160, "time": 35339.820400476456, "episode/length": 189.0, "episode/score": 0.2084304928430356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2084304928430356}
{"step": 697248, "time": 35344.844233989716, "episode/length": 168.0, "episode/score": 0.16353630003686703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16353630003686703}
{"step": 697496, "time": 35355.33718442917, "episode/length": 155.0, "episode/score": 0.17203075130237266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17203075130237266}
{"step": 697616, "time": 35361.6865978241, "episode/length": 215.0, "episode/score": 0.24759901192192046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24759901192192046}
{"step": 697768, "time": 35368.760351896286, "episode/length": 169.0, "episode/score": 0.17310420485955547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17310420485955547}
{"step": 698128, "time": 35384.21705651283, "episode/length": 176.0, "episode/score": 0.21049999597016722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21049999597016722}
{"step": 698688, "time": 35407.24232530594, "episode/length": 191.0, "episode/score": 0.2043138885164808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2043138885164808}
{"step": 698848, "time": 35414.75625371933, "episode/length": 153.0, "episode/score": 0.14873259834530472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14873259834530472}
{"step": 698912, "time": 35418.75943279266, "episode/length": 266.0, "episode/score": 0.29005654014144966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29005654014144966}
{"step": 698912, "time": 35418.76680636406, "episode/length": 176.0, "episode/score": 0.19793088239566714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19793088239566714}
{"step": 699072, "time": 35428.10447692871, "episode/length": 238.0, "episode/score": 0.26958322825157666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26958322825157666}
{"step": 699112, "time": 35431.042677402496, "episode/length": 167.0, "episode/score": 0.19766641152091324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19766641152091324}
{"step": 699176, "time": 35434.92057347298, "episode/length": 240.0, "episode/score": 0.2751856696395407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2751856696395407}
{"step": 699440, "time": 35446.71901464462, "episode/length": 163.0, "episode/score": 0.18397460324922577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18397460324922577}
{"step": 699976, "time": 35467.82321000099, "episode/length": 160.0, "episode/score": 0.1745658153686236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745658153686236}
{"step": 700024, "time": 35487.61385560036, "eval_episode/length": 81.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9390243902439024}
{"step": 700024, "time": 35492.999806165695, "eval_episode/length": 170.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 700024, "time": 35494.79441070557, "eval_episode/length": 176.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 700024, "time": 35496.83000779152, "eval_episode/length": 187.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 700024, "time": 35498.68885970116, "eval_episode/length": 195.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 700024, "time": 35501.9517621994, "eval_episode/length": 236.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 700024, "time": 35504.42605423927, "eval_episode/length": 173.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 700024, "time": 35508.032843112946, "eval_episode/length": 305.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9836601307189542}
{"step": 700136, "time": 35512.19657111168, "episode/length": 152.0, "episode/score": 0.16992728797504242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16992728797504242}
{"step": 700216, "time": 35516.7679400444, "episode/length": 170.0, "episode/score": 0.18179928742392804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18179928742392804}
{"step": 700328, "time": 35522.54900622368, "episode/length": 151.0, "episode/score": 0.18150272994898842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18150272994898842}
{"step": 700408, "time": 35527.07638454437, "episode/length": 166.0, "episode/score": 0.18644809845864074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18644809845864074}
{"step": 700553, "time": 35535.182205200195, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.146426293157762, "train/action_min": 0.0, "train/action_std": 4.862986591554457, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008444183996142518, "train/actor_opt_grad_steps": 43065.0, "train/actor_opt_loss": -9.068102149473082, "train/adv_mag": 0.18952592618523106, "train/adv_max": 0.13524219081286462, "train/adv_mean": 3.794826123691652e-05, "train/adv_min": -0.18780254734860313, "train/adv_std": 0.014456206110245999, "train/cont_avg": 0.9947076612903226, "train/cont_loss_mean": 0.00013668671370065647, "train/cont_loss_std": 0.0038906966552043477, "train/cont_neg_acc": 0.9979838709677419, "train/cont_neg_loss": 0.008213596713322923, "train/cont_pos_acc": 0.9999604258806475, "train/cont_pos_loss": 9.972557766155154e-05, "train/cont_pred": 0.9946703886793505, "train/cont_rate": 0.9947076612903226, "train/dyn_loss_mean": 11.50275206565857, "train/dyn_loss_std": 8.317522883415222, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1365413401396044, "train/extr_critic_critic_opt_grad_steps": 43065.0, "train/extr_critic_critic_opt_loss": 12445.959630166331, "train/extr_critic_mag": 0.2853876313855571, "train/extr_critic_max": 0.2853876313855571, "train/extr_critic_mean": 0.23836620488474447, "train/extr_critic_min": 0.0019612994886213735, "train/extr_critic_std": 0.057884629019686294, "train/extr_return_normed_mag": 0.20168873451409802, "train/extr_return_normed_max": 0.20168873451409802, "train/extr_return_normed_mean": 0.15461297387317305, "train/extr_return_normed_min": -0.08282263576984406, "train/extr_return_normed_std": 0.0598604058426234, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28547986789095786, "train/extr_return_raw_max": 0.28547986789095786, "train/extr_return_raw_mean": 0.23840411007404327, "train/extr_return_raw_min": 0.0009684976070157943, "train/extr_return_raw_std": 0.059860405797559406, "train/extr_reward_mag": 0.0013438165187835693, "train/extr_reward_max": 0.0013438165187835693, "train/extr_reward_mean": 0.0010961315438767234, "train/extr_reward_min": 1.1792106013144217e-05, "train/extr_reward_std": 0.00022979016836372114, "train/image_loss_mean": 5.027165739767013, "train/image_loss_std": 9.996622047116679, "train/model_loss_mean": 11.969262822981804, "train/model_loss_std": 13.452566992851995, "train/model_opt_grad_norm": 51.060138533192294, "train/model_opt_grad_steps": 43023.31451612903, "train/model_opt_loss": 17944.764506678428, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1491.9354838709678, "train/policy_entropy_mag": 2.765245089607854, "train/policy_entropy_max": 2.765245089607854, "train/policy_entropy_mean": 2.087952212941262, "train/policy_entropy_min": 0.0795307602252691, "train/policy_entropy_std": 0.6321281410994068, "train/policy_logprob_mag": 7.438264462255662, "train/policy_logprob_max": -0.009478407754232325, "train/policy_logprob_mean": -2.0866756554572814, "train/policy_logprob_min": -7.438264462255662, "train/policy_logprob_std": 1.1561378495347114, "train/policy_randomness_mag": 0.9760101673103148, "train/policy_randomness_max": 0.9760101673103148, "train/policy_randomness_mean": 0.7369555047442836, "train/policy_randomness_min": 0.028070868293364203, "train/policy_randomness_std": 0.22311349573635286, "train/post_ent_mag": 56.756761612430694, "train/post_ent_max": 56.756761612430694, "train/post_ent_mean": 40.194470743979174, "train/post_ent_min": 19.876413468391664, "train/post_ent_std": 6.770895261918345, "train/prior_ent_mag": 65.99483250033471, "train/prior_ent_max": 65.99483250033471, "train/prior_ent_mean": 51.727059795010476, "train/prior_ent_min": 30.396422463078654, "train/prior_ent_std": 5.4077461381112375, "train/rep_loss_mean": 11.50275206565857, "train/rep_loss_std": 8.317522883415222, "train/reward_avg": 0.0010680435582124178, "train/reward_loss_mean": 0.04030925588261697, "train/reward_loss_std": 0.010912656171938344, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013095823026472522, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04030925567231832, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010662458699962666, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.1095237919262477, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.123809523809523, "train_stats/max_log_achievement_collect_sapling": 0.8, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.3904761904761905, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.02857142857142857, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.37142857142857144, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.0380952380952381, "train_stats/max_log_achievement_wake_up": 0.2, "train_stats/mean_log_entropy": 2.133681174686977, "eval_stats/sum_log_reward": 1.0374999912455678, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.1875, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.660027919569984e-05, "report/cont_loss_std": 0.0002972706570290029, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00027758782380260527, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5062042621138971e-05, "report/cont_pred": 0.9941273331642151, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.682191848754883, "report/dyn_loss_std": 7.6449713706970215, "report/image_loss_mean": 4.229803562164307, "report/image_loss_std": 6.307257175445557, "report/model_loss_mean": 10.680036544799805, "report/model_loss_std": 9.465518951416016, "report/post_ent_mag": 56.0595703125, "report/post_ent_max": 56.0595703125, "report/post_ent_mean": 41.14067077636719, "report/post_ent_min": 20.444629669189453, "report/post_ent_std": 6.790511131286621, "report/prior_ent_mag": 66.34963989257812, "report/prior_ent_max": 66.34963989257812, "report/prior_ent_mean": 52.30252456665039, "report/prior_ent_min": 29.0511474609375, "report/prior_ent_std": 5.777923583984375, "report/rep_loss_mean": 10.682191848754883, "report/rep_loss_std": 7.6449713706970215, "report/reward_avg": 0.0010865333024412394, "report/reward_loss_mean": 0.04090147465467453, "report/reward_loss_std": 0.010728579945862293, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013003349304199219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04090147465467453, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010589533485472202, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0004976575146429241, "eval/cont_loss_std": 0.01569465361535549, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1256847083568573, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.727938853146043e-06, "eval/cont_pred": 0.9964730739593506, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.761283874511719, "eval/dyn_loss_std": 10.608202934265137, "eval/image_loss_mean": 6.316400527954102, "eval/image_loss_std": 12.91965389251709, "eval/model_loss_mean": 16.12314224243164, "eval/model_loss_std": 17.764326095581055, "eval/post_ent_mag": 54.33021545410156, "eval/post_ent_max": 54.33021545410156, "eval/post_ent_mean": 39.52449417114258, "eval/post_ent_min": 18.061832427978516, "eval/post_ent_std": 6.458932399749756, "eval/prior_ent_mag": 66.34963989257812, "eval/prior_ent_max": 66.34963989257812, "eval/prior_ent_mean": 52.41739273071289, "eval/prior_ent_min": 37.79083251953125, "eval/prior_ent_std": 3.9102447032928467, "eval/rep_loss_mean": 15.761283874511719, "eval/rep_loss_std": 10.608202934265137, "eval/reward_avg": 0.0023437500931322575, "eval/reward_loss_mean": 0.3494735062122345, "eval/reward_loss_std": 2.6115827560424805, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012220144271850586, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2483067512512207, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.967260360717773, "eval/reward_pred": 0.000982459750957787, "eval/reward_rate": 0.0048828125, "replay/size": 700049.0, "replay/inserts": 19912.0, "replay/samples": 19920.0, "replay/insert_wait_avg": 1.4257340030815764e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.287559072655367e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5024.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1554094636516207e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1657724380493, "timer/env.step_count": 2489.0, "timer/env.step_total": 238.63863515853882, "timer/env.step_frac": 0.2385990820069982, "timer/env.step_avg": 0.09587731424609836, "timer/env.step_min": 0.023005008697509766, "timer/env.step_max": 3.6071369647979736, "timer/replay._sample_count": 19920.0, "timer/replay._sample_total": 9.831587314605713, "timer/replay._sample_frac": 0.009829957778538843, "timer/replay._sample_avg": 0.0004935535800504876, "timer/replay._sample_min": 0.0004024505615234375, "timer/replay._sample_max": 0.028554201126098633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3117.0, "timer/agent.policy_total": 50.640950202941895, "timer/agent.policy_frac": 0.050632556720569655, "timer/agent.policy_avg": 0.016246695605691978, "timer/agent.policy_min": 0.009857892990112305, "timer/agent.policy_max": 0.10841822624206543, "timer/dataset_train_count": 1245.0, "timer/dataset_train_total": 0.14346790313720703, "timer/dataset_train_frac": 0.00014344412405503857, "timer/dataset_train_avg": 0.00011523526356402171, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0011615753173828125, "timer/agent.train_count": 1245.0, "timer/agent.train_total": 560.7655375003815, "timer/agent.train_frac": 0.5606725934376199, "timer/agent.train_avg": 0.4504140863456879, "timer/agent.train_min": 0.43496012687683105, "timer/agent.train_max": 1.0906944274902344, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748566150665283, "timer/agent.report_frac": 0.00047477790997485985, "timer/agent.report_avg": 0.23742830753326416, "timer/agent.report_min": 0.2311558723449707, "timer/agent.report_max": 0.24370074272155762, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.884386655320777e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 19.90843173159232}
{"step": 700728, "time": 35541.506844997406, "episode/length": 193.0, "episode/score": 0.22700127398275072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22700127398275072}
{"step": 700744, "time": 35543.83080935478, "episode/length": 228.0, "episode/score": 0.2516597206240476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2516597206240476}
{"step": 700760, "time": 35546.13589692116, "episode/length": 164.0, "episode/score": 0.17560920957930648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17560920957930648}
{"step": 701408, "time": 35571.987004995346, "episode/length": 158.0, "episode/score": 0.16853454716328997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16853454716328997}
{"step": 701648, "time": 35582.37666344643, "episode/length": 164.0, "episode/score": 0.16960058472614037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16960058472614037}
{"step": 701648, "time": 35582.38354802132, "episode/length": 154.0, "episode/score": 0.17173188432934694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17173188432934694}
{"step": 701728, "time": 35588.63503623009, "episode/length": 188.0, "episode/score": 0.20936134103976656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20936134103976656}
{"step": 701904, "time": 35596.738497018814, "episode/length": 144.0, "episode/score": 0.1309113792522112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1309113792522112}
{"step": 702312, "time": 35613.275851011276, "episode/length": 193.0, "episode/score": 0.22334783395126578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22334783395126578}
{"step": 702376, "time": 35617.29772114754, "episode/length": 299.0, "episode/score": 0.3499999937484972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3499999937484972}
{"step": 702568, "time": 35626.02395272255, "episode/length": 229.0, "episode/score": 0.2569748221358168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2569748221358168}
{"step": 702832, "time": 35637.74220728874, "episode/length": 147.0, "episode/score": 0.1565196944429772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1565196944429772}
{"step": 702840, "time": 35639.34776306152, "episode/length": 148.0, "episode/score": 0.16078684966487344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16078684966487344}
{"step": 702912, "time": 35643.797716379166, "episode/length": 187.0, "episode/score": 0.19254698008444393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19254698008444393}
{"step": 703008, "time": 35648.85880160332, "episode/length": 159.0, "episode/score": 0.16727209930104436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16727209930104436}
{"step": 703416, "time": 35665.44111633301, "episode/length": 188.0, "episode/score": 0.1957105461260653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1957105461260653}
{"step": 703520, "time": 35671.04281616211, "episode/length": 142.0, "episode/score": 0.15068329951100168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15068329951100168}
{"step": 703560, "time": 35673.821970939636, "episode/length": 155.0, "episode/score": 0.16764346655145346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16764346655145346}
{"step": 704048, "time": 35693.697263002396, "episode/length": 184.0, "episode/score": 0.20071433210796386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20071433210796386}
{"step": 704224, "time": 35701.96666288376, "episode/length": 163.0, "episode/score": 0.17017410053085769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17017410053085769}
{"step": 704392, "time": 35709.55946969986, "episode/length": 172.0, "episode/score": 0.20385382146923803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20385382146923803}
{"step": 704512, "time": 35716.08236479759, "episode/length": 208.0, "episode/score": 0.22062693335101358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22062693335101358}
{"step": 704800, "time": 35729.87202358246, "episode/length": 93.0, "episode/score": 0.1108528624936298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1108528624936298}
{"step": 704832, "time": 35732.688164711, "episode/length": 158.0, "episode/score": 0.18370833015069366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18370833015069366}
{"step": 705056, "time": 35742.57419753075, "episode/length": 191.0, "episode/score": 0.20958032455928333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20958032455928333}
{"step": 705296, "time": 35753.9088807106, "episode/length": 307.0, "episode/score": 0.352174078418102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.352174078418102}
{"step": 705408, "time": 35760.23065018654, "episode/length": 147.0, "episode/score": 0.16939147926677833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16939147926677833}
{"step": 705408, "time": 35760.238887786865, "episode/length": 248.0, "episode/score": 0.2907499946304597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2907499946304597}
{"step": 705520, "time": 35768.728262901306, "episode/length": 140.0, "episode/score": 0.1648749970481731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1648749970481731}
{"step": 705984, "time": 35788.295391082764, "episode/length": 147.0, "episode/score": 0.1714905808603362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714905808603362}
{"step": 706056, "time": 35792.82756066322, "episode/length": 152.0, "episode/score": 0.16606264052825281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16606264052825281}
{"step": 706080, "time": 35795.543922662735, "episode/length": 195.0, "episode/score": 0.20443219277331082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20443219277331082}
{"step": 706480, "time": 35812.45619678497, "episode/length": 147.0, "episode/score": 0.15663865213173267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15663865213173267}
{"step": 706568, "time": 35817.6072678566, "episode/length": 188.0, "episode/score": 0.21829069757950492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21829069757950492}
{"step": 706616, "time": 35821.47715973854, "episode/length": 150.0, "episode/score": 0.16542993121220206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16542993121220206}
{"step": 706832, "time": 35831.98524475098, "episode/length": 163.0, "episode/score": 0.19629545173756924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19629545173756924}
{"step": 706944, "time": 35838.40604543686, "episode/length": 191.0, "episode/score": 0.21978584222779318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21978584222779318}
{"step": 707328, "time": 35855.300932884216, "episode/length": 158.0, "episode/score": 0.17598908449872397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17598908449872397}
{"step": 707768, "time": 35873.57663202286, "episode/length": 149.0, "episode/score": 0.16264962674176786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16264962674176786}
{"step": 707960, "time": 35882.279767513275, "episode/length": 184.0, "episode/score": 0.2148333296063356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2148333296063356}
{"step": 707968, "time": 35884.28489995003, "episode/length": 168.0, "episode/score": 0.20115212521341164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20115212521341164}
{"step": 708176, "time": 35893.81061959267, "episode/length": 167.0, "episode/score": 0.17333934988710098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17333934988710098}
{"step": 708344, "time": 35902.03986287117, "episode/length": 294.0, "episode/score": 0.3122977043822175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3122977043822175}
{"step": 708368, "time": 35905.186356306076, "episode/length": 177.0, "episode/score": 0.1884902090750984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1884902090750984}
{"step": 708584, "time": 35914.96799945831, "episode/length": 156.0, "episode/score": 0.16777252571773715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16777252571773715}
{"step": 709144, "time": 35937.261820077896, "episode/length": 382.0, "episode/score": 0.40063292188096966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40063292188096966}
{"step": 709176, "time": 35940.01443529129, "episode/length": 151.0, "episode/score": 0.16228284304816043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16228284304816043}
{"step": 709456, "time": 35952.36623668671, "episode/length": 159.0, "episode/score": 0.18079430243960815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18079430243960815}
{"step": 709512, "time": 35955.90358066559, "episode/length": 192.0, "episode/score": 0.21287538811884588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21287538811884588}
{"step": 709536, "time": 35959.14437150955, "episode/length": 220.0, "episode/score": 0.25192833207256626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25192833207256626}
{"step": 709712, "time": 35967.84857058525, "episode/length": 170.0, "episode/score": 0.17828534124055295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17828534124055295}
{"step": 709856, "time": 35975.256043195724, "episode/length": 158.0, "episode/score": 0.1607176641227852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1607176641227852}
{"step": 709888, "time": 35978.46446657181, "episode/length": 189.0, "episode/score": 0.20588094927370548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20588094927370548}
{"step": 710008, "time": 36003.009545087814, "eval_episode/length": 38.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 710008, "time": 36008.997395038605, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 710008, "time": 36010.75553536415, "eval_episode/length": 147.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 710008, "time": 36012.37110185623, "eval_episode/length": 148.0, "eval_episode/score": 0.10000002384185791, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 710008, "time": 36014.578329086304, "eval_episode/length": 158.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 710008, "time": 36016.63332891464, "eval_episode/length": 168.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 710008, "time": 36018.43874025345, "eval_episode/length": 174.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 710008, "time": 36020.10159659386, "eval_episode/length": 175.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 710416, "time": 36035.54675292969, "episode/length": 154.0, "episode/score": 0.15924932314555917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15924932314555917}
{"step": 710624, "time": 36045.006721019745, "episode/length": 184.0, "episode/score": 0.18577239327896677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18577239327896677}
{"step": 710848, "time": 36054.866386413574, "episode/length": 173.0, "episode/score": 0.18715589673956856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18715589673956856}
{"step": 710856, "time": 36056.505816698074, "episode/length": 164.0, "episode/score": 0.17397235543830902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17397235543830902}
{"step": 710896, "time": 36059.76070904732, "episode/length": 172.0, "episode/score": 0.207191172417879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.207191172417879}
{"step": 711080, "time": 36067.797014951706, "episode/length": 170.0, "episode/score": 0.1726428733945795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1726428733945795}
{"step": 711208, "time": 36074.19468212128, "episode/length": 164.0, "episode/score": 0.1846698297849798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846698297849798}
{"step": 711528, "time": 36087.916388988495, "episode/length": 138.0, "episode/score": 0.16289532221526315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16289532221526315}
{"step": 712200, "time": 36115.28449487686, "episode/length": 196.0, "episode/score": 0.21859742781271052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21859742781271052}
{"step": 712360, "time": 36122.69984078407, "episode/length": 188.0, "episode/score": 0.1976929796837794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1976929796837794}
{"step": 712368, "time": 36124.67647409439, "episode/length": 160.0, "episode/score": 0.17570191019331105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17570191019331105}
{"step": 712496, "time": 36130.96513748169, "episode/length": 160.0, "episode/score": 0.17817114567333192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17817114567333192}
{"step": 712520, "time": 36133.185651779175, "episode/length": 207.0, "episode/score": 0.24236919362920162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24236919362920162}
{"step": 712936, "time": 36151.748363256454, "episode/length": 254.0, "episode/score": 0.2709304360378155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2709304360378155}
{"step": 713128, "time": 36160.28648161888, "episode/length": 408.0, "episode/score": 0.47564683528253227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47564683528253227}
{"step": 713608, "time": 36179.777311086655, "episode/length": 175.0, "episode/score": 0.18494851928699063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18494851928699063}
{"step": 713720, "time": 36185.46202373505, "episode/length": 169.0, "episode/score": 0.17547510039639747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17547510039639747}
{"step": 713744, "time": 36188.28904891014, "episode/length": 155.0, "episode/score": 0.16855822728484782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16855822728484782}
{"step": 713776, "time": 36191.154109716415, "episode/length": 175.0, "episode/score": 0.17322608555605257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17322608555605257}
{"step": 713864, "time": 36195.880178928375, "episode/length": 291.0, "episode/score": 0.33236388968543906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33236388968543906}
{"step": 714392, "time": 36217.10173654556, "episode/length": 233.0, "episode/score": 0.25087783003618824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25087783003618824}
{"step": 714448, "time": 36220.973717689514, "episode/length": 164.0, "episode/score": 0.1691102973127272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1691102973127272}
{"step": 714456, "time": 36222.62375950813, "episode/length": 189.0, "episode/score": 0.2196249962435104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2196249962435104}
{"step": 714752, "time": 36235.45244073868, "episode/length": 110.0, "episode/score": 0.1325531222319114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1325531222319114}
{"step": 715104, "time": 36250.12442994118, "episode/length": 172.0, "episode/score": 0.1891657268279232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1891657268279232}
{"step": 715104, "time": 36250.131891965866, "episode/length": 186.0, "episode/score": 0.20204152970109135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20204152970109135}
{"step": 715200, "time": 36257.018585920334, "episode/length": 181.0, "episode/score": 0.21013712905551074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21013712905551074}
{"step": 715536, "time": 36271.08437490463, "episode/length": 219.0, "episode/score": 0.2462185377298738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2462185377298738}
{"step": 715616, "time": 36275.61645126343, "episode/length": 152.0, "episode/score": 0.16679294819914503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16679294819914503}
{"step": 715752, "time": 36282.0517706871, "episode/length": 161.0, "episode/score": 0.1878402743022889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1878402743022889}
{"step": 716296, "time": 36303.73950743675, "episode/length": 192.0, "episode/score": 0.20206234452780336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20206234452780336}
{"step": 716344, "time": 36307.11016845703, "episode/length": 154.0, "episode/score": 0.1721642485281336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1721642485281336}
{"step": 716376, "time": 36309.786130189896, "episode/length": 158.0, "episode/score": 0.17809407950699097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17809407950699097}
{"step": 716520, "time": 36316.791576862335, "episode/length": 258.0, "episode/score": 0.2864292844606098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2864292844606098}
{"step": 716600, "time": 36321.337688207626, "episode/length": 174.0, "episode/score": 0.18032497307285666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18032497307285666}
{"step": 716680, "time": 36325.85958862305, "episode/length": 37.0, "episode/score": 0.0454166658455506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0454166658455506}
{"step": 716848, "time": 36333.88316822052, "episode/length": 163.0, "episode/score": 0.1916696393309394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1916696393309394}
{"step": 717192, "time": 36348.23561859131, "episode/length": 179.0, "episode/score": 0.2110326657202677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2110326657202677}
{"step": 717304, "time": 36353.87840342522, "episode/length": 210.0, "episode/score": 0.22102605421969201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22102605421969201}
{"step": 717560, "time": 36364.890023231506, "episode/length": 157.0, "episode/score": 0.17284475447013392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17284475447013392}
{"step": 717800, "time": 36376.25598907471, "episode/length": 149.0, "episode/score": 0.1657785978713946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1657785978713946}
{"step": 717864, "time": 36380.244702100754, "episode/length": 189.0, "episode/score": 0.2084875558357453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2084875558357453}
{"step": 718048, "time": 36388.86225986481, "episode/length": 190.0, "episode/score": 0.18947524822942796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18947524822942796}
{"step": 718584, "time": 36412.239531993866, "episode/length": 159.0, "episode/score": 0.17740483973466326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17740483973466326}
{"step": 718608, "time": 36415.007763147354, "episode/length": 240.0, "episode/score": 0.2621237437306263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2621237437306263}
{"step": 718744, "time": 36421.32593011856, "episode/length": 193.0, "episode/score": 0.20716815162450075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20716815162450075}
{"step": 718792, "time": 36424.59287548065, "episode/length": 242.0, "episode/score": 0.27702380475238897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27702380475238897}
{"step": 718832, "time": 36427.8840572834, "episode/length": 158.0, "episode/score": 0.17218055319972336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17218055319972336}
{"step": 719192, "time": 36442.67986035347, "episode/length": 72.0, "episode/score": 0.08294361129082972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08294361129082972}
{"step": 719224, "time": 36445.44222378731, "episode/length": 169.0, "episode/score": 0.18254973278089892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18254973278089892}
{"step": 719408, "time": 36454.05598950386, "episode/length": 169.0, "episode/score": 0.15955490981286857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15955490981286857}
{"step": 719448, "time": 36456.947362184525, "episode/length": 205.0, "episode/score": 0.24542324081994593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24542324081994593}
{"step": 719800, "time": 36471.67339515686, "episode/length": 151.0, "episode/score": 0.17207577464432688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17207577464432688}
{"step": 720048, "time": 36482.573481082916, "episode/length": 156.0, "episode/score": 0.17571652534752502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17571652534752502}
{"step": 720064, "time": 36484.702337026596, "episode/length": 164.0, "episode/score": 0.17806334365013754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17806334365013754}
{"step": 720096, "time": 36508.92213797569, "eval_episode/length": 160.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 720096, "time": 36508.92812824249, "eval_episode/length": 160.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 720096, "time": 36512.506653785706, "eval_episode/length": 164.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 720096, "time": 36514.99047732353, "eval_episode/length": 185.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 720096, "time": 36517.33868718147, "eval_episode/length": 204.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 720096, "time": 36517.346140146255, "eval_episode/length": 204.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 720096, "time": 36520.94664502144, "eval_episode/length": 210.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.995260663507109}
{"step": 720096, "time": 36526.65089726448, "eval_episode/length": 307.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9967532467532467}
{"step": 720313, "time": 36535.4976849556, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.1539902225617436, "train/action_min": 0.0, "train/action_std": 4.844337774861243, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008602150546897563, "train/actor_opt_grad_steps": 44305.0, "train/actor_opt_loss": -10.306916484729417, "train/adv_mag": 0.18568405136466026, "train/adv_max": 0.12885190005744657, "train/adv_mean": -5.6873995724286475e-06, "train/adv_min": -0.185052786262766, "train/adv_std": 0.014236180359617837, "train/cont_avg": 0.9945580267137096, "train/cont_loss_mean": 0.00014356296383900532, "train/cont_loss_std": 0.0042861391348966915, "train/cont_neg_acc": 0.9897625455933232, "train/cont_neg_loss": 0.01594151063134984, "train/cont_pos_acc": 0.9999603609884938, "train/cont_pos_loss": 5.929523063927155e-05, "train/cont_pred": 0.9945619120713203, "train/cont_rate": 0.9945580267137096, "train/dyn_loss_mean": 11.438809979346491, "train/dyn_loss_std": 8.289202613215293, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14288737318448483, "train/extr_critic_critic_opt_grad_steps": 44305.0, "train/extr_critic_critic_opt_loss": 12284.876764112903, "train/extr_critic_mag": 0.2905137961910617, "train/extr_critic_max": 0.2905137961910617, "train/extr_critic_mean": 0.23797129455112642, "train/extr_critic_min": 0.0020492922875189013, "train/extr_critic_std": 0.06077231139305138, "train/extr_return_normed_mag": 0.207118027392895, "train/extr_return_normed_max": 0.207118027392895, "train/extr_return_normed_mean": 0.15464747865353862, "train/extr_return_normed_min": -0.0823021661490202, "train/extr_return_normed_std": 0.06260741294752206, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2904362039219949, "train/extr_return_raw_max": 0.2904362039219949, "train/extr_return_raw_mean": 0.23796565878775813, "train/extr_return_raw_min": 0.0010160101998236872, "train/extr_return_raw_std": 0.06260741288743672, "train/extr_reward_mag": 0.0013437655664259387, "train/extr_reward_max": 0.0013437655664259387, "train/extr_reward_mean": 0.001096192144623567, "train/extr_reward_min": 1.2347775120888987e-05, "train/extr_reward_std": 0.00023139609120628466, "train/image_loss_mean": 4.9620277747031185, "train/image_loss_std": 9.712209801520071, "train/model_loss_mean": 11.865710658411826, "train/model_loss_std": 13.133770012086437, "train/model_opt_grad_norm": 52.35121562404017, "train/model_opt_grad_steps": 44262.145161290326, "train/model_opt_loss": 15954.210905997983, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1340.725806451613, "train/policy_entropy_mag": 2.762494085296508, "train/policy_entropy_max": 2.762494085296508, "train/policy_entropy_mean": 2.057033925287185, "train/policy_entropy_min": 0.07956818797655645, "train/policy_entropy_std": 0.6401262478001656, "train/policy_logprob_mag": 7.435405627373727, "train/policy_logprob_max": -0.009483112623133966, "train/policy_logprob_mean": -2.0572509794465956, "train/policy_logprob_min": -7.435405627373727, "train/policy_logprob_std": 1.1752196031232034, "train/policy_randomness_mag": 0.9750391816900622, "train/policy_randomness_max": 0.9750391816900622, "train/policy_randomness_mean": 0.7260427076009012, "train/policy_randomness_min": 0.02808407859335984, "train/policy_randomness_std": 0.2259364755403611, "train/post_ent_mag": 56.70335760424214, "train/post_ent_max": 56.70335760424214, "train/post_ent_mean": 40.31037441376717, "train/post_ent_min": 19.908773160749867, "train/post_ent_std": 6.801702537844258, "train/prior_ent_mag": 66.07590404633552, "train/prior_ent_max": 66.07590404633552, "train/prior_ent_mean": 51.788387298583984, "train/prior_ent_min": 30.8055068139107, "train/prior_ent_std": 5.444189133182649, "train/rep_loss_mean": 11.438809979346491, "train/rep_loss_std": 8.289202613215293, "train/reward_avg": 0.001066659680931949, "train/reward_loss_mean": 0.04025339863954052, "train/reward_loss_std": 0.01104375655432382, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013002685962184783, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040253398549412525, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010662370712511361, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.053703685739526, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.018518518518518, "train_stats/max_log_achievement_collect_sapling": 0.8518518518518519, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.42592592592592593, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.018518518518518517, "train_stats/max_log_achievement_eat_cow": 0.027777777777777776, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.037037037037037035, "train_stats/max_log_achievement_wake_up": 0.17592592592592593, "train_stats/mean_log_entropy": 2.1283541001655437, "eval_stats/sum_log_reward": 0.9124999782070518, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.9375, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.218601250409847e-06, "report/cont_loss_std": 5.2146147936582565e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015099806478247046, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3476027308788616e-06, "report/cont_pred": 0.9941392540931702, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.847138404846191, "report/dyn_loss_std": 8.175630569458008, "report/image_loss_mean": 5.107011795043945, "report/image_loss_std": 8.719808578491211, "report/model_loss_mean": 12.255278587341309, "report/model_loss_std": 12.005382537841797, "report/post_ent_mag": 57.28507995605469, "report/post_ent_max": 57.28507995605469, "report/post_ent_mean": 38.91022872924805, "report/post_ent_min": 20.908132553100586, "report/post_ent_std": 6.718986511230469, "report/prior_ent_mag": 66.00990295410156, "report/prior_ent_max": 66.00990295410156, "report/prior_ent_mean": 50.96056365966797, "report/prior_ent_min": 28.594982147216797, "report/prior_ent_std": 5.801374912261963, "report/rep_loss_mean": 11.847138404846191, "report/rep_loss_std": 8.175630569458008, "report/reward_avg": 0.00105937453918159, "report/reward_loss_mean": 0.03997982293367386, "report/reward_loss_std": 0.011734984815120697, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03997982665896416, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010911114513874054, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.718130629858933e-06, "eval/cont_loss_std": 0.0001301247684750706, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00022478513710666448, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.657939022465143e-06, "eval/cont_pred": 0.9951107501983643, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.122556686401367, "eval/dyn_loss_std": 9.705936431884766, "eval/image_loss_mean": 8.706132888793945, "eval/image_loss_std": 12.747076988220215, "eval/model_loss_mean": 18.789199829101562, "eval/model_loss_std": 17.01664924621582, "eval/post_ent_mag": 53.1536865234375, "eval/post_ent_max": 53.1536865234375, "eval/post_ent_mean": 39.03110122680664, "eval/post_ent_min": 21.488521575927734, "eval/post_ent_std": 6.734237194061279, "eval/prior_ent_mag": 66.00990295410156, "eval/prior_ent_max": 66.00990295410156, "eval/prior_ent_mean": 52.42475128173828, "eval/prior_ent_min": 29.754789352416992, "eval/prior_ent_std": 4.428086757659912, "eval/rep_loss_mean": 16.122556686401367, "eval/rep_loss_std": 9.705936431884766, "eval/reward_avg": 0.0018554687267169356, "eval/reward_loss_mean": 0.4095257520675659, "eval/reward_loss_std": 2.778715133666992, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2898055911064148, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.722043991088867, "eval/reward_pred": 0.0010829046368598938, "eval/reward_rate": 0.005859375, "replay/size": 719809.0, "replay/inserts": 19760.0, "replay/samples": 19760.0, "replay/insert_wait_avg": 1.3807041924974696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.189726455008936e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2127205360034282e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3000667095184, "timer/env.step_count": 2470.0, "timer/env.step_total": 246.74064350128174, "timer/env.step_frac": 0.2466666270581524, "timer/env.step_avg": 0.09989499736893998, "timer/env.step_min": 0.022975921630859375, "timer/env.step_max": 4.265858888626099, "timer/replay._sample_count": 19760.0, "timer/replay._sample_total": 9.69418454170227, "timer/replay._sample_frac": 0.009691276512248206, "timer/replay._sample_avg": 0.0004905963836893862, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.009767532348632812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2954.0, "timer/agent.policy_total": 49.36944842338562, "timer/agent.policy_frac": 0.04935463873933964, "timer/agent.policy_avg": 0.01671274489620366, "timer/agent.policy_min": 0.009867429733276367, "timer/agent.policy_max": 0.14407873153686523, "timer/dataset_train_count": 1235.0, "timer/dataset_train_total": 0.14036202430725098, "timer/dataset_train_frac": 0.0001403199189708855, "timer/dataset_train_avg": 0.00011365346097753115, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.00034546852111816406, "timer/agent.train_count": 1235.0, "timer/agent.train_total": 555.1067476272583, "timer/agent.train_frac": 0.5549402285389012, "timer/agent.train_avg": 0.44947914787632254, "timer/agent.train_min": 0.43529582023620605, "timer/agent.train_max": 2.364893674850464, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474170446395874, "timer/agent.report_frac": 0.00047402820631178713, "timer/agent.report_avg": 0.237085223197937, "timer/agent.report_min": 0.23032474517822266, "timer/agent.report_max": 0.24384570121765137, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.076957702636719e-05, "timer/dataset_eval_frac": 4.075734710333319e-08, "timer/dataset_eval_avg": 4.076957702636719e-05, "timer/dataset_eval_min": 4.076957702636719e-05, "timer/dataset_eval_max": 4.076957702636719e-05, "fps": 19.75383102993471}
{"step": 720504, "time": 36542.43992257118, "episode/length": 159.0, "episode/score": 0.1722953896096442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1722953896096442}
{"step": 720552, "time": 36545.7442381382, "episode/length": 214.0, "episode/score": 0.23361188374474295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23361188374474295}
{"step": 720616, "time": 36549.77234864235, "episode/length": 150.0, "episode/score": 0.16686956270132214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16686956270132214}
{"step": 720736, "time": 36556.051726579666, "episode/length": 160.0, "episode/score": 0.18548653799734893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18548653799734893}
{"step": 721000, "time": 36568.64211058617, "episode/length": 225.0, "episode/score": 0.25843533099396154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25843533099396154}
{"step": 721312, "time": 36582.007174015045, "episode/length": 155.0, "episode/score": 0.1569609778780432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1569609778780432}
{"step": 721344, "time": 36584.923901319504, "episode/length": 192.0, "episode/score": 0.2125020477360522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2125020477360522}
{"step": 721664, "time": 36598.340342760086, "episode/length": 201.0, "episode/score": 0.20764515463270072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20764515463270072}
{"step": 721808, "time": 36605.30274629593, "episode/length": 162.0, "episode/score": 0.17978824648162117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17978824648162117}
{"step": 722024, "time": 36614.753160476685, "episode/length": 175.0, "episode/score": 0.17566615237410588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17566615237410588}
{"step": 722032, "time": 36616.94225406647, "episode/length": 161.0, "episode/score": 0.177814522976405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.177814522976405}
{"step": 722232, "time": 36625.88141989708, "episode/length": 209.0, "episode/score": 0.23582032551166776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23582032551166776}
{"step": 722264, "time": 36628.70332670212, "episode/length": 157.0, "episode/score": 0.17432583058871387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17432583058871387}
{"step": 722640, "time": 36644.55277442932, "episode/length": 165.0, "episode/score": 0.19090195606622729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19090195606622729}
{"step": 722816, "time": 36652.661432266235, "episode/length": 183.0, "episode/score": 0.1992165033952915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1992165033952915}
{"step": 723192, "time": 36667.82345700264, "episode/length": 172.0, "episode/score": 0.18742412673236686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18742412673236686}
{"step": 723216, "time": 36670.50448727608, "episode/length": 147.0, "episode/score": 0.13925228931839229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13925228931839229}
{"step": 723408, "time": 36679.2661755085, "episode/length": 217.0, "episode/score": 0.19561980315666005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19561980315666005}
{"step": 723488, "time": 36683.88655805588, "episode/length": 152.0, "episode/score": 0.17332069959593355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17332069959593355}
{"step": 723552, "time": 36687.98515534401, "episode/length": 190.0, "episode/score": 0.20195955143208266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20195955143208266}
{"step": 723904, "time": 36702.57960510254, "episode/length": 157.0, "episode/score": 0.16680690782050078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16680690782050078}
{"step": 724264, "time": 36717.33697652817, "episode/length": 253.0, "episode/score": 0.2808762542226759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2808762542226759}
{"step": 724432, "time": 36725.28734898567, "episode/length": 201.0, "episode/score": 0.2085431475070436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2085431475070436}
{"step": 724544, "time": 36730.99465250969, "episode/length": 123.0, "episode/score": 0.13189337738549511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13189337738549511}
{"step": 724632, "time": 36735.65544342995, "episode/length": 179.0, "episode/score": 0.2048446274466187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2048446274466187}
{"step": 724680, "time": 36739.06605601311, "episode/length": 158.0, "episode/score": 0.179722781322198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179722781322198}
{"step": 724808, "time": 36745.37277364731, "episode/length": 164.0, "episode/score": 0.1465773960662773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1465773960662773}
{"step": 725144, "time": 36759.46468448639, "episode/length": 154.0, "episode/score": 0.1703040612019322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1703040612019322}
{"step": 725728, "time": 36783.0329246521, "episode/length": 313.0, "episode/score": 0.3464688171779926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3464688171779926}
{"step": 725736, "time": 36784.63769316673, "episode/length": 183.0, "episode/score": 0.2005661567709467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2005661567709467}
{"step": 726024, "time": 36797.11624789238, "episode/length": 109.0, "episode/score": 0.12043080375769932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12043080375769932}
{"step": 726032, "time": 36799.29331922531, "episode/length": 168.0, "episode/score": 0.17905139516187774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17905139516187774}
{"step": 726056, "time": 36801.541249513626, "episode/length": 188.0, "episode/score": 0.1970914044577512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1970914044577512}
{"step": 726144, "time": 36806.59148430824, "episode/length": 166.0, "episode/score": 0.19213630884223676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19213630884223676}
{"step": 726336, "time": 36815.35348820686, "episode/length": 237.0, "episode/score": 0.2658208324428415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2658208324428415}
{"step": 726664, "time": 36828.9216439724, "episode/length": 253.0, "episode/score": 0.27690479027205583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27690479027205583}
{"step": 727032, "time": 36844.004715919495, "episode/length": 110.0, "episode/score": 0.1297311480539065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1297311480539065}
{"step": 727056, "time": 36846.713651418686, "episode/length": 164.0, "episode/score": 0.16397774982760893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16397774982760893}
{"step": 727232, "time": 36854.95810317993, "episode/length": 149.0, "episode/score": 0.16133413075021963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16133413075021963}
{"step": 727392, "time": 36862.47392940521, "episode/length": 166.0, "episode/score": 0.17493123261192522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17493123261192522}
{"step": 727616, "time": 36872.39932703972, "episode/length": 235.0, "episode/score": 0.27881547081051394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27881547081051394}
{"step": 727808, "time": 36881.1680765152, "episode/length": 222.0, "episode/score": 0.24095177462822903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24095177462822903}
{"step": 727952, "time": 36888.43986535072, "episode/length": 201.0, "episode/score": 0.2197058196461512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2197058196461512}
{"step": 728192, "time": 36898.91977882385, "episode/length": 144.0, "episode/score": 0.16373036813911312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16373036813911312}
{"step": 728216, "time": 36901.15061593056, "episode/length": 50.0, "episode/score": 0.05181236567659653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05181236567659653}
{"step": 728392, "time": 36909.269704818726, "episode/length": 54.0, "episode/score": 0.06060143424838316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06060143424838316}
{"step": 728528, "time": 36916.34358716011, "episode/length": 141.0, "episode/score": 0.15074085054857278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15074085054857278}
{"step": 728600, "time": 36920.385061979294, "episode/length": 241.0, "episode/score": 0.2659865558262027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2659865558262027}
{"step": 728688, "time": 36925.48320865631, "episode/length": 181.0, "episode/score": 0.18244733680330683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18244733680330683}
{"step": 729040, "time": 36940.23610544205, "episode/length": 247.0, "episode/score": 0.26932037395272346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26932037395272346}
{"step": 729520, "time": 36961.13815712929, "episode/length": 162.0, "episode/score": 0.17529893216487835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17529893216487835}
{"step": 729680, "time": 36968.582043886185, "episode/length": 185.0, "episode/score": 0.18903096857229684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18903096857229684}
{"step": 729832, "time": 36975.818217754364, "episode/length": 142.0, "episode/score": 0.15451708372529538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15451708372529538}
{"step": 730016, "time": 36984.99696755409, "episode/length": 185.0, "episode/score": 0.19194961952325684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19194961952325684}
{"step": 730080, "time": 37007.39542889595, "eval_episode/length": 140.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 730080, "time": 37009.7166929245, "eval_episode/length": 158.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 730080, "time": 37011.453078985214, "eval_episode/length": 160.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.968944099378882}
{"step": 730080, "time": 37013.137581825256, "eval_episode/length": 164.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 730080, "time": 37013.144114494324, "eval_episode/length": 164.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 730080, "time": 37016.43967604637, "eval_episode/length": 165.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 730080, "time": 37019.78807210922, "eval_episode/length": 203.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 730080, "time": 37025.614871263504, "eval_episode/length": 149.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 730256, "time": 37032.15474867821, "episode/length": 232.0, "episode/score": 0.2395937405690347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2395937405690347}
{"step": 730272, "time": 37034.432987213135, "episode/length": 153.0, "episode/score": 0.1706900622921239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706900622921239}
{"step": 730720, "time": 37052.66862201691, "episode/length": 149.0, "episode/score": 0.16858333046548069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16858333046548069}
{"step": 730776, "time": 37056.28320527077, "episode/length": 271.0, "episode/score": 0.3073974259023089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3073974259023089}
{"step": 730840, "time": 37060.252633571625, "episode/length": 402.0, "episode/score": 0.38545656430687814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38545656430687814}
{"step": 731288, "time": 37078.80149769783, "episode/length": 181.0, "episode/score": 0.1916721029629116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1916721029629116}
{"step": 731648, "time": 37094.730192661285, "episode/length": 171.0, "episode/score": 0.171707777561096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.171707777561096}
{"step": 731968, "time": 37108.3595225811, "episode/length": 155.0, "episode/score": 0.17597287581520504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17597287581520504}
{"step": 731992, "time": 37110.575400829315, "episode/length": 151.0, "episode/score": 0.1535060346686805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1535060346686805}
{"step": 732256, "time": 37122.24248099327, "episode/length": 249.0, "episode/score": 0.28029348753989325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28029348753989325}
{"step": 732328, "time": 37126.4134683609, "episode/length": 330.0, "episode/score": 0.3580421947808645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3580421947808645}
{"step": 732904, "time": 37149.29660487175, "episode/length": 156.0, "episode/score": 0.16037334500651923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16037334500651923}
{"step": 733136, "time": 37159.86103057861, "episode/length": 145.0, "episode/score": 0.16954166372306645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16954166372306645}
{"step": 733368, "time": 37169.79589056969, "episode/length": 418.0, "episode/score": 0.42648280531648197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42648280531648197}
{"step": 733424, "time": 37173.52276778221, "episode/length": 178.0, "episode/score": 0.19994820614192577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19994820614192577}
{"step": 733872, "time": 37191.802250385284, "episode/length": 201.0, "episode/score": 0.22715649027304607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22715649027304607}
{"step": 733968, "time": 37196.84463763237, "episode/length": 204.0, "episode/score": 0.2301180398753786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2301180398753786}
{"step": 734200, "time": 37206.67960238457, "episode/length": 419.0, "episode/score": 0.44481022589388886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44481022589388886}
{"step": 734376, "time": 37214.752391815186, "episode/length": 154.0, "episode/score": 0.16172067814477487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16172067814477487}
{"step": 734608, "time": 37225.08005452156, "episode/length": 154.0, "episode/score": 0.17731626343629614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17731626343629614}
{"step": 734784, "time": 37233.11370444298, "episode/length": 436.0, "episode/score": 0.4159309547076191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4159309547076191}
{"step": 735064, "time": 37245.01486444473, "episode/length": 56.0, "episode/score": 0.07041666517034173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07041666517034173}
{"step": 735152, "time": 37249.98053526878, "episode/length": 159.0, "episode/score": 0.1704450225479377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704450225479377}
{"step": 735224, "time": 37253.92235207558, "episode/length": 156.0, "episode/score": 0.15993304051335144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15993304051335144}
{"step": 735344, "time": 37260.1989839077, "episode/length": 239.0, "episode/score": 0.25192111841352016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25192111841352016}
{"step": 735480, "time": 37266.53547978401, "episode/length": 159.0, "episode/score": 0.16379797123136086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16379797123136086}
{"step": 735808, "time": 37280.64971327782, "episode/length": 178.0, "episode/score": 0.19264931999714463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19264931999714463}
{"step": 735992, "time": 37288.871796131134, "episode/length": 150.0, "episode/score": 0.15102957966973918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15102957966973918}
{"step": 736104, "time": 37294.637372493744, "episode/length": 399.0, "episode/score": 0.4557929839211283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4557929839211283}
{"step": 736360, "time": 37305.903913497925, "episode/length": 161.0, "episode/score": 0.17974192094789032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17974192094789032}
{"step": 736632, "time": 37317.47345995903, "episode/length": 184.0, "episode/score": 0.19093427183088352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19093427183088352}
{"step": 736696, "time": 37321.43175792694, "episode/length": 183.0, "episode/score": 0.19159108399799152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19159108399799152}
{"step": 736856, "time": 37328.943314790726, "episode/length": 188.0, "episode/score": 0.20469678515928535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20469678515928535}
{"step": 737184, "time": 37343.05703473091, "episode/length": 148.0, "episode/score": 0.1701034945444917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1701034945444917}
{"step": 737360, "time": 37352.64519262314, "episode/length": 90.0, "episode/score": 0.10841666453052312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10841666453052312}
{"step": 737368, "time": 37354.2525100708, "episode/length": 235.0, "episode/score": 0.2634095294170038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2634095294170038}
{"step": 737456, "time": 37359.34638738632, "episode/length": 168.0, "episode/score": 0.13694478860452364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13694478860452364}
{"step": 737632, "time": 37367.70236158371, "episode/length": 227.0, "episode/score": 0.2529980788667672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2529980788667672}
{"step": 737704, "time": 37371.746938467026, "episode/length": 167.0, "episode/score": 0.18046551680799894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18046551680799894}
{"step": 738360, "time": 37397.75823020935, "episode/length": 207.0, "episode/score": 0.22860975169987796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22860975169987796}
{"step": 738536, "time": 37405.86656689644, "episode/length": 168.0, "episode/score": 0.17822132738365326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17822132738365326}
{"step": 738680, "time": 37412.938331365585, "episode/length": 152.0, "episode/score": 0.15672585125867045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15672585125867045}
{"step": 738936, "time": 37424.152151584625, "episode/length": 153.0, "episode/score": 0.18213790070149116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18213790070149116}
{"step": 739104, "time": 37432.20111131668, "episode/length": 183.0, "episode/score": 0.19510608368364046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19510608368364046}
{"step": 739272, "time": 37439.75558710098, "episode/length": 238.0, "episode/score": 0.25849184324579255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25849184324579255}
{"step": 739624, "time": 37454.503734111786, "episode/length": 345.0, "episode/score": 0.3814865054064285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3814865054064285}
{"step": 739648, "time": 37457.07421588898, "episode/length": 160.0, "episode/score": 0.18021555686664215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18021555686664215}
{"step": 739744, "time": 37462.168154239655, "episode/length": 296.0, "episode/score": 0.34001137313316576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34001137313316576}
{"step": 740016, "time": 37473.887711286545, "episode/length": 184.0, "episode/score": 0.20044877900727442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20044877900727442}
{"step": 740064, "time": 37496.1842045784, "eval_episode/length": 146.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9727891156462585}
{"step": 740064, "time": 37498.07424092293, "eval_episode/length": 154.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 740064, "time": 37500.50308346748, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 740064, "time": 37502.25860667229, "eval_episode/length": 177.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 740064, "time": 37504.17846131325, "eval_episode/length": 184.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9567567567567568}
{"step": 740064, "time": 37506.117888212204, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 740064, "time": 37506.125156879425, "eval_episode/length": 192.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 740064, "time": 37509.853353500366, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 740088, "time": 37510.53177189827, "episode/length": 175.0, "episode/score": 0.20266071056539658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20266071056539658}
{"step": 740384, "time": 37523.503333091736, "episode/length": 138.0, "episode/score": 0.16167856844549533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16167856844549533}
{"step": 740600, "time": 37532.93718791008, "episode/length": 186.0, "episode/score": 0.2083079698641086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2083079698641086}
{"step": 740601, "time": 37535.530980587006, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.0134743517778055, "train/action_min": 0.0, "train/action_std": 4.778187920728068, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008507444952269943, "train/actor_opt_grad_steps": 45560.0, "train/actor_opt_loss": -9.841445516765587, "train/adv_mag": 0.1891543713845606, "train/adv_max": 0.13430713105389452, "train/adv_mean": 2.945875307278319e-05, "train/adv_min": -0.1874630210671838, "train/adv_std": 0.014181839720177369, "train/cont_avg": 0.9944482037401575, "train/cont_loss_mean": 0.0003245852395985691, "train/cont_loss_std": 0.010061650380902657, "train/cont_neg_acc": 0.9888795163687758, "train/cont_neg_loss": 0.04182455760895918, "train/cont_pos_acc": 0.9999767602898004, "train/cont_pos_loss": 0.00010470689190563105, "train/cont_pred": 0.9944691883297417, "train/cont_rate": 0.9944482037401575, "train/dyn_loss_mean": 11.272472742035633, "train/dyn_loss_std": 8.370188213708833, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14210792950640513, "train/extr_critic_critic_opt_grad_steps": 45560.0, "train/extr_critic_critic_opt_loss": 12211.80263441191, "train/extr_critic_mag": 0.2942213880734181, "train/extr_critic_max": 0.2942213880734181, "train/extr_critic_mean": 0.23897701982907424, "train/extr_critic_min": 0.001758027264452356, "train/extr_critic_std": 0.06161737301218228, "train/extr_return_normed_mag": 0.2116460833023852, "train/extr_return_normed_max": 0.2116460833023852, "train/extr_return_normed_mean": 0.156615610784433, "train/extr_return_normed_min": -0.08138279235503805, "train/extr_return_normed_std": 0.0634835528165806, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2940369246043558, "train/extr_return_raw_max": 0.2940369246043558, "train/extr_return_raw_mean": 0.2390064564276868, "train/extr_return_raw_min": 0.001008048770934578, "train/extr_return_raw_std": 0.06348355293391257, "train/extr_reward_mag": 0.0013491666223120501, "train/extr_reward_max": 0.0013491666223120501, "train/extr_reward_mean": 0.001101048406594851, "train/extr_reward_min": 1.2017610504871278e-05, "train/extr_reward_std": 0.00022950859953040683, "train/image_loss_mean": 4.956921684460377, "train/image_loss_std": 9.656177899968906, "train/model_loss_mean": 11.76110936713031, "train/model_loss_std": 13.161060738751269, "train/model_opt_grad_norm": 51.629052379938564, "train/model_opt_grad_steps": 45515.86614173228, "train/model_opt_loss": 15369.202079232284, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1309.0551181102362, "train/policy_entropy_mag": 2.7635718462035412, "train/policy_entropy_max": 2.7635718462035412, "train/policy_entropy_mean": 2.0617363246407097, "train/policy_entropy_min": 0.07955374210838258, "train/policy_entropy_std": 0.6434945013579421, "train/policy_logprob_mag": 7.438273779050571, "train/policy_logprob_max": -0.009480829467982288, "train/policy_logprob_mean": -2.0613899822310198, "train/policy_logprob_min": -7.438273779050571, "train/policy_logprob_std": 1.178174317352415, "train/policy_randomness_mag": 0.975419585629711, "train/policy_randomness_max": 0.975419585629711, "train/policy_randomness_mean": 0.7277024482178875, "train/policy_randomness_min": 0.02807897979056272, "train/policy_randomness_std": 0.2271253185009393, "train/post_ent_mag": 56.82078360009381, "train/post_ent_max": 56.82078360009381, "train/post_ent_mean": 40.423298392708844, "train/post_ent_min": 19.83219508674201, "train/post_ent_std": 6.869145389616959, "train/prior_ent_mag": 66.21159597081463, "train/prior_ent_max": 66.21159597081463, "train/prior_ent_mean": 51.77670270063746, "train/prior_ent_min": 30.531164830125224, "train/prior_ent_std": 5.59636459200401, "train/rep_loss_mean": 11.272472742035633, "train/rep_loss_std": 8.370188213708833, "train/reward_avg": 0.0010701146684440337, "train/reward_loss_mean": 0.04037943954660198, "train/reward_loss_std": 0.010820785522695602, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013009807256263073, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04037943948793599, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010702106304188062, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.1283018626272678, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.19811320754717, "train_stats/max_log_achievement_collect_sapling": 0.8207547169811321, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5566037735849056, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.33962264150943394, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.05660377358490566, "train_stats/max_log_achievement_wake_up": 0.20754716981132076, "train_stats/mean_log_entropy": 2.123838542767291, "eval_stats/sum_log_reward": 0.7874999800696969, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.331613258225843e-05, "report/cont_loss_std": 0.0019838232547044754, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.01273987628519535, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.115158511311165e-06, "report/cont_pred": 0.9951764345169067, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.399136543273926, "report/dyn_loss_std": 8.187825202941895, "report/image_loss_mean": 3.830379009246826, "report/image_loss_std": 8.085831642150879, "report/model_loss_mean": 10.710310935974121, "report/model_loss_std": 11.789545059204102, "report/post_ent_mag": 55.00494384765625, "report/post_ent_max": 55.00494384765625, "report/post_ent_mean": 40.512596130371094, "report/post_ent_min": 17.090700149536133, "report/post_ent_std": 6.653975486755371, "report/prior_ent_mag": 66.26925659179688, "report/prior_ent_max": 66.26925659179688, "report/prior_ent_mean": 51.97179412841797, "report/prior_ent_min": 35.45270538330078, "report/prior_ent_std": 4.435839653015137, "report/rep_loss_mean": 11.399136543273926, "report/rep_loss_std": 8.187825202941895, "report/reward_avg": 0.0010724798776209354, "report/reward_loss_mean": 0.04038653522729874, "report/reward_loss_std": 0.01164435874670744, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013309717178344727, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04038653522729874, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010458434699103236, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.7752847270458005e-05, "eval/cont_loss_std": 0.0004442185745574534, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0046083759516477585, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.2642400330805685e-06, "eval/cont_pred": 0.9970794916152954, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.438505172729492, "eval/dyn_loss_std": 10.405184745788574, "eval/image_loss_mean": 11.962179183959961, "eval/image_loss_std": 17.017070770263672, "eval/model_loss_mean": 22.964309692382812, "eval/model_loss_std": 20.991943359375, "eval/post_ent_mag": 54.461891174316406, "eval/post_ent_max": 54.461891174316406, "eval/post_ent_mean": 38.820899963378906, "eval/post_ent_min": 18.50075912475586, "eval/post_ent_std": 6.8860764503479, "eval/prior_ent_mag": 66.26925659179688, "eval/prior_ent_max": 66.26925659179688, "eval/prior_ent_mean": 52.9793701171875, "eval/prior_ent_min": 29.394378662109375, "eval/prior_ent_std": 4.963079452514648, "eval/rep_loss_mean": 17.438505172729492, "eval/rep_loss_std": 10.405184745788574, "eval/reward_avg": 0.0029296875, "eval/reward_loss_mean": 0.5390104055404663, "eval/reward_loss_std": 3.2400050163269043, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012363195419311523, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.3994080424308777, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.821237564086914, "eval/reward_pred": 0.00104048871435225, "eval/reward_rate": 0.0068359375, "replay/size": 740097.0, "replay/inserts": 20288.0, "replay/samples": 20288.0, "replay/insert_wait_avg": 1.385784487619009e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.177188480690075e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.197994924059101e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0219411849976, "timer/env.step_count": 2536.0, "timer/env.step_total": 233.5810534954071, "timer/env.step_frac": 0.23357592856274753, "timer/env.step_avg": 0.09210609364960848, "timer/env.step_min": 0.023120880126953125, "timer/env.step_max": 2.0492241382598877, "timer/replay._sample_count": 20288.0, "timer/replay._sample_total": 9.741176128387451, "timer/replay._sample_frac": 0.009740962400129376, "timer/replay._sample_avg": 0.0004801447224165739, "timer/replay._sample_min": 0.000377655029296875, "timer/replay._sample_max": 0.009509563446044922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3046.0, "timer/agent.policy_total": 49.12834858894348, "timer/agent.policy_frac": 0.0491272706784091, "timer/agent.policy_avg": 0.016128807809896086, "timer/agent.policy_min": 0.00969839096069336, "timer/agent.policy_max": 0.10318636894226074, "timer/dataset_train_count": 1268.0, "timer/dataset_train_total": 0.14271211624145508, "timer/dataset_train_frac": 0.00014270898503721357, "timer/dataset_train_avg": 0.00011254898757212546, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0009224414825439453, "timer/agent.train_count": 1268.0, "timer/agent.train_total": 569.4595704078674, "timer/agent.train_frac": 0.5694470760642252, "timer/agent.train_avg": 0.4491006075771825, "timer/agent.train_min": 0.43461036682128906, "timer/agent.train_max": 1.038696050643921, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776902198791504, "timer/agent.report_frac": 0.00047767973901962697, "timer/agent.report_avg": 0.2388451099395752, "timer/agent.report_min": 0.2312450408935547, "timer/agent.report_max": 0.2464451789855957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9801668503773435e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.287295805189853}
{"step": 740936, "time": 37547.977716207504, "episode/length": 249.0, "episode/score": 0.2824126936029643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2824126936029643}
{"step": 741008, "time": 37552.37824225426, "episode/length": 157.0, "episode/score": 0.1710252949706046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1710252949706046}
{"step": 741200, "time": 37560.980774879456, "episode/length": 196.0, "episode/score": 0.23154824128141627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23154824128141627}
{"step": 741448, "time": 37571.578379154205, "episode/length": 224.0, "episode/score": 0.25528594346542377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25528594346542377}
{"step": 741488, "time": 37574.91102385521, "episode/length": 183.0, "episode/score": 0.19406403040193254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19406403040193254}
{"step": 741696, "time": 37584.20741343498, "episode/length": 200.0, "episode/score": 0.23935869104025187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23935869104025187}
{"step": 741784, "time": 37588.81078219414, "episode/length": 174.0, "episode/score": 0.2100804088404402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2100804088404402}
{"step": 741928, "time": 37595.65805840492, "episode/length": 165.0, "episode/score": 0.1543840040685609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1543840040685609}
{"step": 742512, "time": 37619.29491662979, "episode/length": 163.0, "episode/score": 0.1768472694857337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768472694857337}
{"step": 742656, "time": 37626.21506714821, "episode/length": 214.0, "episode/score": 0.24100191182515118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24100191182515118}
{"step": 742712, "time": 37629.68417072296, "episode/length": 212.0, "episode/score": 0.22019116779847536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22019116779847536}
{"step": 742864, "time": 37637.22668552399, "episode/length": 43.0, "episode/score": 0.05187499907333404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05187499907333404}
{"step": 742976, "time": 37643.01435947418, "episode/length": 190.0, "episode/score": 0.20473814680735813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20473814680735813}
{"step": 743064, "time": 37647.79588985443, "episode/length": 196.0, "episode/score": 0.21759725039737532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21759725039737532}
{"step": 743304, "time": 37659.033393621445, "episode/length": 189.0, "episode/score": 0.19523246936660144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19523246936660144}
{"step": 743408, "time": 37665.23434662819, "episode/length": 213.0, "episode/score": 0.21365913913177792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21365913913177792}
{"step": 743680, "time": 37676.936040878296, "episode/length": 218.0, "episode/score": 0.2192109322968463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2192109322968463}
{"step": 744256, "time": 37700.0180709362, "episode/length": 173.0, "episode/score": 0.19995912561716978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19995912561716978}
{"step": 744280, "time": 37702.18640589714, "episode/length": 162.0, "episode/score": 0.1663634365067992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1663634365067992}
{"step": 744416, "time": 37709.04759001732, "episode/length": 219.0, "episode/score": 0.24865678099740762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24865678099740762}
{"step": 744416, "time": 37709.05586910248, "episode/length": 168.0, "episode/score": 0.19238270817368175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19238270817368175}
{"step": 744576, "time": 37718.48350691795, "episode/length": 145.0, "episode/score": 0.17960883967862173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17960883967862173}
{"step": 744912, "time": 37733.21182489395, "episode/length": 200.0, "episode/score": 0.1784027468002023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1784027468002023}
{"step": 745160, "time": 37743.82757019997, "episode/length": 184.0, "episode/score": 0.1901850723043026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1901850723043026}
{"step": 745648, "time": 37765.73007416725, "episode/length": 170.0, "episode/score": 0.1898296671879507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898296671879507}
{"step": 745752, "time": 37770.90140223503, "episode/length": 186.0, "episode/score": 0.21081004301231587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21081004301231587}
{"step": 745880, "time": 37777.254133462906, "episode/length": 395.0, "episode/score": 0.4218077591176552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4218077591176552}
{"step": 746232, "time": 37792.412296533585, "episode/length": 226.0, "episode/score": 0.23192129313974874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23192129313974874}
{"step": 746328, "time": 37797.61401247978, "episode/length": 238.0, "episode/score": 0.26838923002833326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26838923002833326}
{"step": 746360, "time": 37800.41920495033, "episode/length": 180.0, "episode/score": 0.1863926082969556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1863926082969556}
{"step": 746528, "time": 37808.47494697571, "episode/length": 170.0, "episode/score": 0.17420045148992358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17420045148992358}
{"step": 746784, "time": 37819.518131017685, "episode/length": 141.0, "episode/score": 0.15649279567605845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15649279567605845}
{"step": 746800, "time": 37821.67122960091, "episode/length": 58.0, "episode/score": 0.06572184580090834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06572184580090834}
{"step": 747672, "time": 37855.35314631462, "episode/length": 179.0, "episode/score": 0.19837741802894016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19837741802894016}
{"step": 747704, "time": 37858.07913303375, "episode/length": 167.0, "episode/score": 0.19417778288971022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19417778288971022}
{"step": 747800, "time": 37863.18235182762, "episode/length": 402.0, "episode/score": 0.41484484048214654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41484484048214654}
{"step": 747880, "time": 37867.72800731659, "episode/length": 168.0, "episode/score": 0.17228667477229465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17228667477229465}
{"step": 748048, "time": 37875.91310739517, "episode/length": 155.0, "episode/score": 0.17244917492189415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17244917492189415}
{"step": 748120, "time": 37879.923065423965, "episode/length": 295.0, "episode/score": 0.3332080169866458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3332080169866458}
{"step": 748240, "time": 37886.16197824478, "episode/length": 294.0, "episode/score": 0.3306154290194172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3306154290194172}
{"step": 748640, "time": 37903.15104961395, "episode/length": 231.0, "episode/score": 0.25104199654288095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25104199654288095}
{"step": 748936, "time": 37915.57067036629, "episode/length": 141.0, "episode/score": 0.15588615838260012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15588615838260012}
{"step": 749024, "time": 37920.737889528275, "episode/length": 168.0, "episode/score": 0.1850627414378323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1850627414378323}
{"step": 749192, "time": 37929.02174496651, "episode/length": 163.0, "episode/score": 0.172819041387811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.172819041387811}
{"step": 749400, "time": 37939.24773526192, "episode/length": 211.0, "episode/score": 0.2319563909813951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2319563909813951}
{"step": 749440, "time": 37943.09742665291, "episode/length": 149.0, "episode/score": 0.14397714868209732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14397714868209732}
{"step": 749440, "time": 37943.10543465614, "episode/length": 164.0, "episode/score": 0.19048998034304532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19048998034304532}
{"step": 749952, "time": 37965.41936421394, "episode/length": 237.0, "episode/score": 0.2841249944176525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2841249944176525}
{"step": 750048, "time": 37989.72547507286, "eval_episode/length": 152.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 750048, "time": 37991.28027129173, "eval_episode/length": 154.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 750048, "time": 37993.12364053726, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 750048, "time": 37995.24420881271, "eval_episode/length": 173.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 750048, "time": 37996.895141363144, "eval_episode/length": 175.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 750048, "time": 37998.69869399071, "eval_episode/length": 180.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.994475138121547}
{"step": 750048, "time": 38000.4033844471, "eval_episode/length": 184.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 750048, "time": 38003.36111998558, "eval_episode/length": 218.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 750104, "time": 38005.24563908577, "episode/length": 145.0, "episode/score": 0.16301919437501056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16301919437501056}
{"step": 750392, "time": 38017.47847676277, "episode/length": 218.0, "episode/score": 0.25033520697252243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25033520697252243}
{"step": 750440, "time": 38020.838248968124, "episode/length": 176.0, "episode/score": 0.2004330799982199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2004330799982199}
{"step": 750472, "time": 38023.67643761635, "episode/length": 159.0, "episode/score": 0.17100201023094996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17100201023094996}
{"step": 750592, "time": 38030.10450553894, "episode/length": 148.0, "episode/score": 0.16864659690691042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16864659690691042}
{"step": 750720, "time": 38036.5319314003, "episode/length": 159.0, "episode/score": 0.17758094764212728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17758094764212728}
{"step": 750920, "time": 38045.21337771416, "episode/length": 184.0, "episode/score": 0.1980082985082845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980082985082845}
{"step": 751232, "time": 38058.815969944, "episode/length": 94.0, "episode/score": 0.10263604520878289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10263604520878289}
{"step": 751376, "time": 38065.720834732056, "episode/length": 158.0, "episode/score": 0.17788066953107773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17788066953107773}
{"step": 751584, "time": 38075.286655426025, "episode/length": 203.0, "episode/score": 0.22429529126475245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22429529126475245}
{"step": 751824, "time": 38086.422976732254, "episode/length": 153.0, "episode/score": 0.15638274736738822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15638274736738822}
{"step": 751848, "time": 38088.599695682526, "episode/length": 181.0, "episode/score": 0.20755917627229792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20755917627229792}
{"step": 751928, "time": 38093.077547073364, "episode/length": 185.0, "episode/score": 0.20575261845260684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20575261845260684}
{"step": 752144, "time": 38102.79700875282, "episode/length": 177.0, "episode/score": 0.1948273656780657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1948273656780657}
{"step": 752536, "time": 38118.84647631645, "episode/length": 144.0, "episode/score": 0.16204060567179113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16204060567179113}
{"step": 752568, "time": 38121.66059708595, "episode/length": 205.0, "episode/score": 0.21496221227516799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21496221227516799}
{"step": 752744, "time": 38129.75186872482, "episode/length": 188.0, "episode/score": 0.2154818988919942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2154818988919942}
{"step": 753136, "time": 38146.21233820915, "episode/length": 193.0, "episode/score": 0.21265574613335048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21265574613335048}
{"step": 753232, "time": 38151.41930150986, "episode/length": 172.0, "episode/score": 0.18153555935714394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18153555935714394}
{"step": 753344, "time": 38157.17824792862, "episode/length": 176.0, "episode/score": 0.20411566195252817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20411566195252817}
{"step": 753488, "time": 38164.18115544319, "episode/length": 207.0, "episode/score": 0.20875757959402108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20875757959402108}
{"step": 753680, "time": 38174.55635261536, "episode/length": 142.0, "episode/score": 0.16790035914891632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16790035914891632}
{"step": 753896, "time": 38184.075765132904, "episode/length": 165.0, "episode/score": 0.16096334278336144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16096334278336144}
{"step": 754008, "time": 38189.879779815674, "episode/length": 40.0, "episode/score": 0.047708332538604736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047708332538604736}
{"step": 754056, "time": 38193.30917644501, "episode/length": 238.0, "episode/score": 0.26667304311558837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26667304311558837}
{"step": 754376, "time": 38207.06842136383, "episode/length": 154.0, "episode/score": 0.17675687150403974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17675687150403974}
{"step": 754680, "time": 38219.965686798096, "episode/length": 148.0, "episode/score": 0.16628668226621812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16628668226621812}
{"step": 754784, "time": 38225.641568899155, "episode/length": 254.0, "episode/score": 0.2928768202182255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2928768202182255}
{"step": 755000, "time": 38235.103680849075, "episode/length": 206.0, "episode/score": 0.22365820526101743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22365820526101743}
{"step": 755416, "time": 38252.22937178612, "episode/length": 169.0, "episode/score": 0.181624965127412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.181624965127412}
{"step": 755680, "time": 38263.98836493492, "episode/length": 208.0, "episode/score": 0.24299854153650813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24299854153650813}
{"step": 755880, "time": 38273.55304002762, "episode/length": 247.0, "episode/score": 0.27758207475199015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27758207475199015}
{"step": 755944, "time": 38277.58497786522, "episode/length": 195.0, "episode/score": 0.20937055800823146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20937055800823146}
{"step": 756264, "time": 38291.084565639496, "episode/length": 72.0, "episode/score": 0.08031618626591808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08031618626591808}
{"step": 756280, "time": 38293.23509645462, "episode/length": 186.0, "episode/score": 0.172379813842781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.172379813842781}
{"step": 756408, "time": 38299.66311788559, "episode/length": 215.0, "episode/score": 0.22559289732089383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22559289732089383}
{"step": 756584, "time": 38307.84156560898, "episode/length": 418.0, "episode/score": 0.4455303273807658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4455303273807658}
{"step": 756616, "time": 38310.65135407448, "episode/length": 201.0, "episode/score": 0.21810398900561268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21810398900561268}
{"step": 757136, "time": 38331.81617426872, "episode/length": 148.0, "episode/score": 0.1630109297366289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1630109297366289}
{"step": 757304, "time": 38339.42019033432, "episode/length": 177.0, "episode/score": 0.21277375032332202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21277375032332202}
{"step": 757520, "time": 38349.21424365044, "episode/length": 154.0, "episode/score": 0.1752691472775041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1752691472775041}
{"step": 757552, "time": 38351.8999004364, "episode/length": 160.0, "episode/score": 0.1823741527805396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1823741527805396}
{"step": 757632, "time": 38356.64347028732, "episode/length": 152.0, "episode/score": 0.1500032537678635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1500032537678635}
{"step": 757640, "time": 38358.33988213539, "episode/length": 277.0, "episode/score": 0.31648336273792665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31648336273792665}
{"step": 757968, "time": 38372.2318944931, "episode/length": 172.0, "episode/score": 0.18742800805739535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18742800805739535}
{"step": 758328, "time": 38387.262010097504, "episode/length": 100.0, "episode/score": 0.1169756923118257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1169756923118257}
{"step": 758360, "time": 38390.45702934265, "episode/length": 217.0, "episode/score": 0.24362622274020396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24362622274020396}
{"step": 758496, "time": 38397.955682992935, "episode/length": 169.0, "episode/score": 0.18252417290204903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18252417290204903}
{"step": 758672, "time": 38406.632731199265, "episode/length": 170.0, "episode/score": 0.19816522360270028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19816522360270028}
{"step": 758800, "time": 38412.908063173294, "episode/length": 145.0, "episode/score": 0.15779278579793754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15779278579793754}
{"step": 759232, "time": 38430.57782435417, "episode/length": 198.0, "episode/score": 0.2288246822263318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2288246822263318}
{"step": 759344, "time": 38436.256699323654, "episode/length": 223.0, "episode/score": 0.2488798128997587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2488798128997587}
{"step": 759816, "time": 38455.31312561035, "episode/length": 230.0, "episode/score": 0.2619589453752269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2619589453752269}
{"step": 759848, "time": 38458.028332948685, "episode/length": 189.0, "episode/score": 0.21322435544607288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21322435544607288}
{"step": 759864, "time": 38460.171424388885, "episode/length": 148.0, "episode/score": 0.15376966685289517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15376966685289517}
{"step": 759912, "time": 38463.543956041336, "episode/length": 176.0, "episode/score": 0.19404925505841675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19404925505841675}
{"step": 760032, "time": 38488.17008471489, "eval_episode/length": 88.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9438202247191011}
{"step": 760032, "time": 38492.2681388855, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 760032, "time": 38494.05326485634, "eval_episode/length": 152.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 760032, "time": 38496.071257829666, "eval_episode/length": 163.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 760032, "time": 38498.357360839844, "eval_episode/length": 178.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 760032, "time": 38500.43952059746, "eval_episode/length": 191.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 760032, "time": 38502.1006231308, "eval_episode/length": 192.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 760032, "time": 38505.22185301781, "eval_episode/length": 59.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9333333333333333}
{"step": 760040, "time": 38505.30181193352, "episode/length": 154.0, "episode/score": 0.17998187683406286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17998187683406286}
{"step": 760192, "time": 38512.75197887421, "episode/length": 228.0, "episode/score": 0.24456904335784202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24456904335784202}
{"step": 760488, "time": 38525.1775124073, "episode/length": 156.0, "episode/score": 0.17656224127858877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17656224127858877}
{"step": 760648, "time": 38532.734015226364, "episode/length": 162.0, "episode/score": 0.18766658692038618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18766658692038618}
{"step": 760649, "time": 38535.5479824543, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.9174853515625, "train/action_min": 0.0, "train/action_std": 4.772548824310303, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008319798186421394, "train/actor_opt_grad_steps": 46820.0, "train/actor_opt_loss": -10.522551131248473, "train/adv_mag": 0.17900709480047225, "train/adv_max": 0.1308627322912216, "train/adv_mean": 4.303894353142823e-05, "train/adv_min": -0.17745950824022294, "train/adv_std": 0.013712051134556532, "train/cont_avg": 0.994546875, "train/cont_loss_mean": 0.00018906507795486504, "train/cont_loss_std": 0.005161494748160294, "train/cont_neg_acc": 0.993577778339386, "train/cont_neg_loss": 0.016734818129902122, "train/cont_pos_acc": 0.9999685111045837, "train/cont_pos_loss": 9.834061554613527e-05, "train/cont_pred": 0.9945320162773132, "train/cont_rate": 0.994546875, "train/dyn_loss_mean": 11.223409103393555, "train/dyn_loss_std": 8.305284652709961, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12615470027923584, "train/extr_critic_critic_opt_grad_steps": 46820.0, "train/extr_critic_critic_opt_loss": 12261.6595, "train/extr_critic_mag": 0.2949991579055786, "train/extr_critic_max": 0.2949991579055786, "train/extr_critic_mean": 0.24014625346660615, "train/extr_critic_min": 0.0018724679946899414, "train/extr_critic_std": 0.0622268807888031, "train/extr_return_normed_mag": 0.21602763640880585, "train/extr_return_normed_max": 0.21602763640880585, "train/extr_return_normed_mean": 0.16140229058265687, "train/extr_return_normed_min": -0.07780551385879517, "train/extr_return_normed_std": 0.06376229810714722, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.29481457471847533, "train/extr_return_raw_max": 0.29481457471847533, "train/extr_return_raw_mean": 0.24018923473358153, "train/extr_return_raw_min": 0.000981424331665039, "train/extr_return_raw_std": 0.06376229786872864, "train/extr_reward_mag": 0.001340041160583496, "train/extr_reward_max": 0.001340041160583496, "train/extr_reward_mean": 0.0011040713544934989, "train/extr_reward_min": 1.1214256286621094e-05, "train/extr_reward_std": 0.00022775542468298225, "train/image_loss_mean": 4.787166807174683, "train/image_loss_std": 9.503978092193604, "train/model_loss_mean": 11.561614494323731, "train/model_loss_std": 12.985515930175781, "train/model_opt_grad_norm": 50.050409576416016, "train/model_opt_grad_steps": 46774.648, "train/model_opt_loss": 14563.7134921875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1270.0, "train/policy_entropy_mag": 2.760369691848755, "train/policy_entropy_max": 2.760369691848755, "train/policy_entropy_mean": 2.022599123954773, "train/policy_entropy_min": 0.07962528276443481, "train/policy_entropy_std": 0.6461291146278382, "train/policy_logprob_mag": 7.438282775878906, "train/policy_logprob_max": -0.009490602381527423, "train/policy_logprob_mean": -2.0216720333099367, "train/policy_logprob_min": -7.438282775878906, "train/policy_logprob_std": 1.195536135673523, "train/policy_randomness_mag": 0.9742893657684326, "train/policy_randomness_max": 0.9742893657684326, "train/policy_randomness_mean": 0.7138887348175049, "train/policy_randomness_min": 0.028104230612516403, "train/policy_randomness_std": 0.2280552223920822, "train/post_ent_mag": 57.09387072753906, "train/post_ent_max": 57.09387072753906, "train/post_ent_mean": 40.57528494262695, "train/post_ent_min": 19.726665802001953, "train/post_ent_std": 6.933798076629639, "train/prior_ent_mag": 66.22719342041016, "train/prior_ent_max": 66.22719342041016, "train/prior_ent_mean": 51.86111624145508, "train/prior_ent_min": 30.75278498840332, "train/prior_ent_std": 5.358598394393921, "train/rep_loss_mean": 11.223409103393555, "train/rep_loss_std": 8.305284652709961, "train/reward_avg": 0.001065359347499907, "train/reward_loss_mean": 0.04021327513456344, "train/reward_loss_std": 0.011028137192130088, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001300262451171875, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04021327483654022, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010655003236606717, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.1370370247297816, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.7592592592592595, "train_stats/max_log_achievement_collect_sapling": 0.7407407407407407, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.46296296296296297, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.2962962962962963, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.037037037037037035, "train_stats/max_log_achievement_wake_up": 0.16666666666666666, "train_stats/mean_log_entropy": 2.0504059780527046, "eval_stats/sum_log_reward": 0.4749999772757292, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.7041129467543215e-05, "report/cont_loss_std": 0.0005227562505751848, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004327707923948765, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3655385089350602e-07, "report/cont_pred": 0.9961104393005371, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.027482986450195, "report/dyn_loss_std": 8.148174285888672, "report/image_loss_mean": 4.086508750915527, "report/image_loss_std": 7.728198528289795, "report/model_loss_mean": 10.744359970092773, "report/model_loss_std": 11.269139289855957, "report/post_ent_mag": 54.93328857421875, "report/post_ent_max": 54.93328857421875, "report/post_ent_mean": 40.34062957763672, "report/post_ent_min": 18.171083450317383, "report/post_ent_std": 6.890370845794678, "report/prior_ent_mag": 66.08688354492188, "report/prior_ent_max": 66.08688354492188, "report/prior_ent_mean": 50.937374114990234, "report/prior_ent_min": 27.26145362854004, "report/prior_ent_std": 5.4591064453125, "report/rep_loss_mean": 11.027482986450195, "report/rep_loss_std": 8.148174285888672, "report/reward_avg": 0.0011002134997397661, "report/reward_loss_mean": 0.04134538769721985, "report/reward_loss_std": 0.010395785793662071, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04134539142251015, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010630980832502246, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.005121031776070595, "eval/cont_loss_std": 0.16378173232078552, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.048763394355774, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1920604237047883e-07, "eval/cont_pred": 0.9960887432098389, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.557159423828125, "eval/dyn_loss_std": 9.783020973205566, "eval/image_loss_mean": 11.504264831542969, "eval/image_loss_std": 20.302141189575195, "eval/model_loss_mean": 22.526721954345703, "eval/model_loss_std": 24.190641403198242, "eval/post_ent_mag": 57.55181121826172, "eval/post_ent_max": 57.55181121826172, "eval/post_ent_mean": 38.57636260986328, "eval/post_ent_min": 21.71514892578125, "eval/post_ent_std": 6.654205322265625, "eval/prior_ent_mag": 66.08688354492188, "eval/prior_ent_max": 66.08688354492188, "eval/prior_ent_mean": 52.77954864501953, "eval/prior_ent_min": 29.032527923583984, "eval/prior_ent_std": 4.31028413772583, "eval/rep_loss_mean": 17.557159423828125, "eval/rep_loss_std": 9.783020973205566, "eval/reward_avg": 0.00527343712747097, "eval/reward_loss_mean": 0.48304057121276855, "eval/reward_loss_std": 3.0343823432922363, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012269020080566406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.30151331424713135, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.955278396606445, "eval/reward_pred": 0.001025750651024282, "eval/reward_rate": 0.0087890625, "replay/size": 760145.0, "replay/inserts": 20048.0, "replay/samples": 20048.0, "replay/insert_wait_avg": 1.3795169181854175e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.239045869990149e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1852982350988796e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0030045509338, "timer/env.step_count": 2506.0, "timer/env.step_total": 242.15695476531982, "timer/env.step_frac": 0.24215622719460128, "timer/env.step_avg": 0.09663086782335188, "timer/env.step_min": 0.022934675216674805, "timer/env.step_max": 3.302185535430908, "timer/replay._sample_count": 20048.0, "timer/replay._sample_total": 9.582382440567017, "timer/replay._sample_frac": 0.00958235364989741, "timer/replay._sample_avg": 0.0004779719892541409, "timer/replay._sample_min": 0.00039649009704589844, "timer/replay._sample_max": 0.009443044662475586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2949.0, "timer/agent.policy_total": 48.81851387023926, "timer/agent.policy_frac": 0.04881836719296852, "timer/agent.policy_avg": 0.01655426038326187, "timer/agent.policy_min": 0.009648323059082031, "timer/agent.policy_max": 0.12421059608459473, "timer/dataset_train_count": 1253.0, "timer/dataset_train_total": 0.1445014476776123, "timer/dataset_train_frac": 0.0001445010135169572, "timer/dataset_train_avg": 0.00011532437963097551, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0004303455352783203, "timer/agent.train_count": 1253.0, "timer/agent.train_total": 564.1502773761749, "timer/agent.train_frac": 0.564148582363025, "timer/agent.train_avg": 0.45023964674874295, "timer/agent.train_min": 0.4357328414916992, "timer/agent.train_max": 1.108572244644165, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780247211456299, "timer/agent.report_frac": 0.00047802328490032284, "timer/agent.report_avg": 0.23901236057281494, "timer/agent.report_min": 0.23269009590148926, "timer/agent.report_max": 0.24533462524414062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8371725668791085e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 20.0476812726187}
{"step": 761048, "time": 38550.12505197525, "episode/length": 153.0, "episode/score": 0.1710439928865526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1710439928865526}
{"step": 761192, "time": 38556.944685935974, "episode/length": 165.0, "episode/score": 0.17515183154318947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17515183154318947}
{"step": 761232, "time": 38560.22345995903, "episode/length": 172.0, "episode/score": 0.19498341966391308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19498341966391308}
{"step": 761328, "time": 38565.472297906876, "episode/length": 176.0, "episode/score": 0.20355219423800008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20355219423800008}
{"step": 761640, "time": 38578.921986579895, "episode/length": 199.0, "episode/score": 0.22158493225288112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22158493225288112}
{"step": 761720, "time": 38583.44534230232, "episode/length": 190.0, "episode/score": 0.18633859498004313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18633859498004313}
{"step": 762016, "time": 38597.65162539482, "episode/length": 190.0, "episode/score": 0.2047347503284982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2047347503284982}
{"step": 762232, "time": 38606.94091081619, "episode/length": 147.0, "episode/score": 0.16189541454150458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16189541454150458}
{"step": 762336, "time": 38612.6208627224, "episode/length": 210.0, "episode/score": 0.22021270960976835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22021270960976835}
{"step": 762616, "time": 38624.483365535736, "episode/length": 177.0, "episode/score": 0.16448137828047038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16448137828047038}
{"step": 762736, "time": 38630.67658853531, "episode/length": 175.0, "episode/score": 0.16784076101976098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16784076101976098}
{"step": 762976, "time": 38641.21614098549, "episode/length": 156.0, "episode/score": 0.1635922298719379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1635922298719379}
{"step": 763328, "time": 38656.05160737038, "episode/length": 210.0, "episode/score": 0.24376209858382936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24376209858382936}
{"step": 763600, "time": 38667.834461927414, "episode/length": 170.0, "episode/score": 0.17430314491321042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17430314491321042}
{"step": 763616, "time": 38670.01350784302, "episode/length": 199.0, "episode/score": 0.21708520835454692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21708520835454692}
{"step": 763736, "time": 38675.725551366806, "episode/length": 174.0, "episode/score": 0.18272384293777577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18272384293777577}
{"step": 764168, "time": 38693.46421074867, "episode/length": 193.0, "episode/score": 0.1957811921438406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1957811921438406}
{"step": 764224, "time": 38697.2924580574, "episode/length": 185.0, "episode/score": 0.19395097119922866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19395097119922866}
{"step": 764512, "time": 38709.65038895607, "episode/length": 191.0, "episode/score": 0.2035939278157457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2035939278157457}
{"step": 764560, "time": 38713.08027219772, "episode/length": 415.0, "episode/score": 0.39933321405442257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39933321405442257}
{"step": 764920, "time": 38727.95181560516, "episode/length": 164.0, "episode/score": 0.18669026150564605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18669026150564605}
{"step": 765032, "time": 38733.64217185974, "episode/length": 161.0, "episode/score": 0.17589772251994873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17589772251994873}
{"step": 765352, "time": 38747.37672352791, "episode/length": 216.0, "episode/score": 0.22311248996993527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22311248996993527}
{"step": 765432, "time": 38751.977095365524, "episode/length": 262.0, "episode/score": 0.3168749938486144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3168749938486144}
{"step": 765472, "time": 38755.17642235756, "episode/length": 162.0, "episode/score": 0.18125948037777562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18125948037777562}
{"step": 765592, "time": 38760.95199561119, "episode/length": 170.0, "episode/score": 0.16665106849086442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16665106849086442}
{"step": 765744, "time": 38768.27975153923, "episode/length": 153.0, "episode/score": 0.17063499557025352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17063499557025352}
{"step": 765824, "time": 38772.882190942764, "episode/length": 157.0, "episode/score": 0.1696364219624229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1696364219624229}
{"step": 766328, "time": 38793.1598277092, "episode/length": 161.0, "episode/score": 0.171107251317153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.171107251317153}
{"step": 766392, "time": 38797.20296692848, "episode/length": 183.0, "episode/score": 0.21180468368220318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21180468368220318}
{"step": 766616, "time": 38807.16285634041, "episode/length": 157.0, "episode/score": 0.16776101565938006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16776101565938006}
{"step": 766632, "time": 38809.369592905045, "episode/length": 144.0, "episode/score": 0.17004893256853393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17004893256853393}
{"step": 766848, "time": 38819.180097818375, "episode/length": 176.0, "episode/score": 0.19363571120811685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19363571120811685}
{"step": 766960, "time": 38824.85369038582, "episode/length": 170.0, "episode/score": 0.1718059369122784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1718059369122784}
{"step": 767240, "time": 38836.82759308815, "episode/length": 176.0, "episode/score": 0.1990484692287282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1990484692287282}
{"step": 767288, "time": 38840.53248214722, "episode/length": 192.0, "episode/score": 0.20011409579365136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20011409579365136}
{"step": 767760, "time": 38860.44443511963, "episode/length": 178.0, "episode/score": 0.18650923492805305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18650923492805305}
{"step": 767912, "time": 38867.60571718216, "episode/length": 159.0, "episode/score": 0.1576813500805656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1576813500805656}
{"step": 768064, "time": 38875.15627193451, "episode/length": 208.0, "episode/score": 0.24412941110404063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24412941110404063}
{"step": 768232, "time": 38882.668645620346, "episode/length": 201.0, "episode/score": 0.22586525233873544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22586525233873544}
{"step": 768400, "time": 38890.81282162666, "episode/length": 193.0, "episode/score": 0.20087485586918774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20087485586918774}
{"step": 769008, "time": 38915.07972884178, "episode/length": 220.0, "episode/score": 0.23968461118147388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23968461118147388}
{"step": 769096, "time": 38919.76478052139, "episode/length": 166.0, "episode/score": 0.1733255522985928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733255522985928}
{"step": 769200, "time": 38925.59310936928, "episode/length": 120.0, "episode/score": 0.14718333031487418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14718333031487418}
{"step": 769288, "time": 38930.19906759262, "episode/length": 290.0, "episode/score": 0.31141707644019334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31141707644019334}
{"step": 769512, "time": 38940.22939491272, "episode/length": 180.0, "episode/score": 0.19812487336912454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19812487336912454}
{"step": 769720, "time": 38949.481586933136, "episode/length": 303.0, "episode/score": 0.3442819053716448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3442819053716448}
{"step": 769800, "time": 38954.08199548721, "episode/length": 174.0, "episode/score": 0.1970084556405709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1970084556405709}
{"step": 770016, "time": 38982.75423455238, "eval_episode/length": 147.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 770016, "time": 38984.86225748062, "eval_episode/length": 157.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 770016, "time": 38986.774883270264, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 770016, "time": 38988.75165081024, "eval_episode/length": 169.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 770016, "time": 38990.87246465683, "eval_episode/length": 183.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 770016, "time": 38992.829263448715, "eval_episode/length": 193.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 770016, "time": 38995.59535360336, "eval_episode/length": 222.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 770016, "time": 38997.658916950226, "eval_episode/length": 233.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 770120, "time": 39002.72354340553, "episode/length": 275.0, "episode/score": 0.2876191693912915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2876191693912915}
{"step": 770360, "time": 39013.22447037697, "episode/length": 157.0, "episode/score": 0.17269045823104534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17269045823104534}
{"step": 770512, "time": 39020.731612443924, "episode/length": 152.0, "episode/score": 0.15350711850351217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15350711850351217}
{"step": 770776, "time": 39031.9611287117, "episode/length": 196.0, "episode/score": 0.2225256230813102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2225256230813102}
{"step": 771096, "time": 39045.56935548782, "episode/length": 161.0, "episode/score": 0.18472451193156303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18472451193156303}
{"step": 771096, "time": 39045.57793331146, "episode/length": 260.0, "episode/score": 0.2946926135873582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2946926135873582}
{"step": 771200, "time": 39053.132927417755, "episode/length": 210.0, "episode/score": 0.2464330826423975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2464330826423975}
{"step": 771336, "time": 39059.51849961281, "episode/length": 201.0, "episode/score": 0.2297407187143108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2297407187143108}
{"step": 771656, "time": 39073.014090299606, "episode/length": 161.0, "episode/score": 0.195023655453042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.195023655453042}
{"step": 771680, "time": 39075.83987212181, "episode/length": 194.0, "episode/score": 0.20701403812108765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20701403812108765}
{"step": 772152, "time": 39094.756356954575, "episode/length": 171.0, "episode/score": 0.1942994757400811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942994757400811}
{"step": 772664, "time": 39115.45283937454, "episode/length": 195.0, "episode/score": 0.21687941538084488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21687941538084488}
{"step": 772824, "time": 39123.05409741402, "episode/length": 202.0, "episode/score": 0.22990034475742505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22990034475742505}
{"step": 772848, "time": 39125.881998062134, "episode/length": 145.0, "episode/score": 0.14593178875293233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14593178875293233}
{"step": 773128, "time": 39138.42974638939, "episode/length": 183.0, "episode/score": 0.21744773951377283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21744773951377283}
{"step": 773224, "time": 39143.61344194412, "episode/length": 235.0, "episode/score": 0.2731620690442469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2731620690442469}
{"step": 773512, "time": 39155.99475455284, "episode/length": 47.0, "episode/score": 0.05380862098536454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05380862098536454}
{"step": 773544, "time": 39158.78188562393, "episode/length": 173.0, "episode/score": 0.20563934326173694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20563934326173694}
{"step": 773576, "time": 39161.52205657959, "episode/length": 382.0, "episode/score": 0.42047973678972994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42047973678972994}
{"step": 773576, "time": 39161.531061172485, "episode/length": 309.0, "episode/score": 0.3159090680137524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3159090680137524}
{"step": 774360, "time": 39194.17113375664, "episode/length": 211.0, "episode/score": 0.2335673041525297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2335673041525297}
{"step": 774400, "time": 39197.566905498505, "episode/length": 146.0, "episode/score": 0.159017097740616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159017097740616}
{"step": 774480, "time": 39202.117988586426, "episode/length": 206.0, "episode/score": 0.23069146430634646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23069146430634646}
{"step": 774912, "time": 39219.89024972916, "episode/length": 174.0, "episode/score": 0.18952666572249655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18952666572249655}
{"step": 775080, "time": 39227.792316675186, "episode/length": 278.0, "episode/score": 0.3100974197022879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3100974197022879}
{"step": 775512, "time": 39245.51435875893, "episode/length": 241.0, "episode/score": 0.279397639450508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.279397639450508}
{"step": 775608, "time": 39250.62390255928, "episode/length": 257.0, "episode/score": 0.2847832800607648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2847832800607648}
{"step": 775840, "time": 39261.21646118164, "episode/length": 169.0, "episode/score": 0.19082969127066463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19082969127066463}
{"step": 775864, "time": 39264.05201625824, "episode/length": 187.0, "episode/score": 0.19834618837421658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19834618837421658}
{"step": 776168, "time": 39277.06736731529, "episode/length": 220.0, "episode/score": 0.23093555689865752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23093555689865752}
{"step": 776168, "time": 39277.07483482361, "episode/length": 156.0, "episode/score": 0.18020315450530688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18020315450530688}
{"step": 776456, "time": 39291.26819348335, "episode/length": 171.0, "episode/score": 0.19567422916770738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19567422916770738}
{"step": 776800, "time": 39305.74858403206, "episode/length": 160.0, "episode/score": 0.17651796837481015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17651796837481015}
{"step": 776880, "time": 39310.20355772972, "episode/length": 88.0, "episode/score": 0.10193828022329399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10193828022329399}
{"step": 776888, "time": 39311.987064123154, "episode/length": 413.0, "episode/score": 0.4497197994674025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4497197994674025}
{"step": 777072, "time": 39320.674362421036, "episode/length": 182.0, "episode/score": 0.19096421255107998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19096421255107998}
{"step": 777152, "time": 39325.23029088974, "episode/length": 163.0, "episode/score": 0.18518414922209558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18518414922209558}
{"step": 777320, "time": 39332.80910038948, "episode/length": 181.0, "episode/score": 0.1825348102101998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1825348102101998}
{"step": 777368, "time": 39336.14255309105, "episode/length": 149.0, "episode/score": 0.15230991895305124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15230991895305124}
{"step": 777664, "time": 39349.059930086136, "episode/length": 150.0, "episode/score": 0.15295493685061956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15295493685061956}
{"step": 778152, "time": 39368.50517868996, "episode/length": 168.0, "episode/score": 0.17164339536248008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17164339536248008}
{"step": 778184, "time": 39371.226855516434, "episode/length": 101.0, "episode/score": 0.11151619386146194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11151619386146194}
{"step": 778448, "time": 39384.4870531559, "episode/length": 194.0, "episode/score": 0.1979746302276908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1979746302276908}
{"step": 778496, "time": 39387.826597213745, "episode/length": 167.0, "episode/score": 0.19459857405172443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19459857405172443}
{"step": 778528, "time": 39390.64079332352, "episode/length": 205.0, "episode/score": 0.23428437687789483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23428437687789483}
{"step": 778536, "time": 39392.30778455734, "episode/length": 182.0, "episode/score": 0.20245152426241475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20245152426241475}
{"step": 779432, "time": 39427.1499671936, "episode/length": 155.0, "episode/score": 0.15539670825228313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15539670825228313}
{"step": 779456, "time": 39429.85916638374, "episode/length": 223.0, "episode/score": 0.2481394037527025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2481394037527025}
{"step": 779560, "time": 39435.29338359833, "episode/length": 279.0, "episode/score": 0.3101632233310738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3101632233310738}
{"step": 779640, "time": 39439.9488530159, "episode/length": 185.0, "episode/score": 0.21114318392346831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21114318392346831}
{"step": 779760, "time": 39446.27776169777, "episode/length": 153.0, "episode/score": 0.17901742129470222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17901742129470222}
{"step": 779896, "time": 39453.40581011772, "episode/length": 169.0, "episode/score": 0.17218824732390203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17218824732390203}
{"step": 779992, "time": 39459.18591976166, "episode/length": 192.0, "episode/score": 0.1974832459454774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974832459454774}
{"step": 780000, "time": 39486.160501241684, "eval_episode/length": 154.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 780000, "time": 39486.167521476746, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 780000, "time": 39491.69203996658, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 780000, "time": 39493.780443906784, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 780000, "time": 39493.78792977333, "eval_episode/length": 177.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 780000, "time": 39498.80366587639, "eval_episode/length": 188.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 780000, "time": 39501.470056295395, "eval_episode/length": 201.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995049504950495}
{"step": 780000, "time": 39504.52478957176, "eval_episode/length": 224.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 780056, "time": 39506.458082675934, "episode/length": 194.0, "episode/score": 0.21743850526945607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21743850526945607}
{"step": 780712, "time": 39532.94834399223, "episode/length": 156.0, "episode/score": 0.18904621652063724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18904621652063724}
{"step": 780721, "time": 39535.60245299339, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.15594482421875, "train/action_min": 0.0, "train/action_std": 4.879262161254883, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00823100147023797, "train/actor_opt_grad_steps": 48070.0, "train/actor_opt_loss": -15.789363961219788, "train/adv_mag": 0.1819321595430374, "train/adv_max": 0.12107938879728317, "train/adv_mean": -0.0003129887046015938, "train/adv_min": -0.18094134134054185, "train/adv_std": 0.013576336048543454, "train/cont_avg": 0.994546875, "train/cont_loss_mean": 0.00014056210162425486, "train/cont_loss_std": 0.004414848658325809, "train/cont_neg_acc": 0.9968000001907349, "train/cont_neg_loss": 0.011753815648036835, "train/cont_pos_acc": 0.999976448059082, "train/cont_pos_loss": 8.105880982230929e-05, "train/cont_pred": 0.9945484428405762, "train/cont_rate": 0.994546875, "train/dyn_loss_mean": 11.174847885131836, "train/dyn_loss_std": 8.367031963348389, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12742595919966698, "train/extr_critic_critic_opt_grad_steps": 48070.0, "train/extr_critic_critic_opt_loss": 12151.1151796875, "train/extr_critic_mag": 0.29305442810058596, "train/extr_critic_max": 0.29305442810058596, "train/extr_critic_mean": 0.23624704897403717, "train/extr_critic_min": 0.001684539794921875, "train/extr_critic_std": 0.0624740569293499, "train/extr_return_normed_mag": 0.2166251837015152, "train/extr_return_normed_max": 0.2166251837015152, "train/extr_return_normed_mean": 0.15999375653266906, "train/extr_return_normed_min": -0.07495370241999626, "train/extr_return_normed_std": 0.06416938069462776, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2925655362606049, "train/extr_return_raw_max": 0.2925655362606049, "train/extr_return_raw_mean": 0.23593411314487459, "train/extr_return_raw_min": 0.000986649513244629, "train/extr_return_raw_std": 0.06416938087344169, "train/extr_reward_mag": 0.0013441896438598632, "train/extr_reward_max": 0.0013441896438598632, "train/extr_reward_mean": 0.0011003366094082595, "train/extr_reward_min": 1.1707305908203125e-05, "train/extr_reward_std": 0.000229420232353732, "train/image_loss_mean": 4.876786367416382, "train/image_loss_std": 9.419825614929199, "train/model_loss_mean": 11.622142204284668, "train/model_loss_std": 12.915535423278808, "train/model_opt_grad_norm": 57.439827285766604, "train/model_opt_grad_steps": 48023.28, "train/model_opt_loss": 9313.35083203125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 800.0, "train/policy_entropy_mag": 2.7610995750427247, "train/policy_entropy_max": 2.7610995750427247, "train/policy_entropy_mean": 2.063861515045166, "train/policy_entropy_min": 0.07953519433736801, "train/policy_entropy_std": 0.6358972434997558, "train/policy_logprob_mag": 7.438285633087158, "train/policy_logprob_max": -0.009478234320878982, "train/policy_logprob_mean": -2.063997812271118, "train/policy_logprob_min": -7.438285633087158, "train/policy_logprob_std": 1.1689179883003236, "train/policy_randomness_mag": 0.9745469813346863, "train/policy_randomness_max": 0.9745469813346863, "train/policy_randomness_mean": 0.7284525470733643, "train/policy_randomness_min": 0.02807243326306343, "train/policy_randomness_std": 0.2244438202381134, "train/post_ent_mag": 57.27635443115234, "train/post_ent_max": 57.27635443115234, "train/post_ent_mean": 40.622168823242184, "train/post_ent_min": 19.65748945617676, "train/post_ent_std": 6.950913024902344, "train/prior_ent_mag": 66.4147869873047, "train/prior_ent_max": 66.4147869873047, "train/prior_ent_mean": 51.85143173217774, "train/prior_ent_min": 30.156828125, "train/prior_ent_std": 5.543195615768433, "train/rep_loss_mean": 11.174847885131836, "train/rep_loss_std": 8.367031963348389, "train/reward_avg": 0.0010680675422772765, "train/reward_loss_mean": 0.04030668926239014, "train/reward_loss_std": 0.010948508396744728, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013054876327514649, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040306689351797105, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010682114288210868, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.1679611318175076, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.941747572815534, "train_stats/max_log_achievement_collect_sapling": 0.8058252427184466, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.6407766990291263, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.009708737864077669, "train_stats/max_log_achievement_place_plant": 0.33980582524271846, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.10679611650485436, "train_stats/max_log_achievement_wake_up": 0.13592233009708737, "train_stats/mean_log_entropy": 2.075589103606141, "eval_stats/sum_log_reward": 0.7249999791383743, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 0.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.2255764128640294e-05, "report/cont_loss_std": 0.0011067689629271626, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019007878145202994, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.4967401006724685e-05, "report/cont_pred": 0.9960669279098511, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.045965194702148, "report/dyn_loss_std": 8.730096817016602, "report/image_loss_mean": 4.335107326507568, "report/image_loss_std": 8.793100357055664, "report/model_loss_mean": 11.00411605834961, "report/model_loss_std": 12.379037857055664, "report/post_ent_mag": 58.86738586425781, "report/post_ent_max": 58.86738586425781, "report/post_ent_mean": 39.9471435546875, "report/post_ent_min": 20.224462509155273, "report/post_ent_std": 6.746297836303711, "report/prior_ent_mag": 66.24647521972656, "report/prior_ent_max": 66.24647521972656, "report/prior_ent_mean": 50.964927673339844, "report/prior_ent_min": 30.232221603393555, "report/prior_ent_std": 6.24036979675293, "report/rep_loss_mean": 11.045965194702148, "report/rep_loss_std": 8.730096817016602, "report/reward_avg": 0.0011002093087881804, "report/reward_loss_mean": 0.04138666391372681, "report/reward_loss_std": 0.009985052980482578, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012606382369995117, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04138666391372681, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010815003188326955, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.2172343960846774e-05, "eval/cont_loss_std": 0.0006397193064913154, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00033043904113583267, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.096345451718662e-05, "eval/cont_pred": 0.9960744380950928, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.604248046875, "eval/dyn_loss_std": 10.070846557617188, "eval/image_loss_mean": 9.138116836547852, "eval/image_loss_std": 14.091964721679688, "eval/model_loss_mean": 19.216787338256836, "eval/model_loss_std": 18.642244338989258, "eval/post_ent_mag": 54.22373962402344, "eval/post_ent_max": 54.22373962402344, "eval/post_ent_mean": 39.529701232910156, "eval/post_ent_min": 20.208724975585938, "eval/post_ent_std": 6.66375207901001, "eval/prior_ent_mag": 66.24647521972656, "eval/prior_ent_max": 66.24647521972656, "eval/prior_ent_mean": 52.512908935546875, "eval/prior_ent_min": 32.481353759765625, "eval/prior_ent_std": 5.614616394042969, "eval/rep_loss_mean": 15.604248046875, "eval/rep_loss_std": 10.070846557617188, "eval/reward_avg": 0.0032226559706032276, "eval/reward_loss_mean": 0.7160993814468384, "eval/reward_loss_std": 3.671588182449341, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5379250049591064, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.81022071838379, "eval/reward_pred": 0.0010677926475182176, "eval/reward_rate": 0.0087890625, "replay/size": 780217.0, "replay/inserts": 20072.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.3722253064322444e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.058628777377724e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2306606068330653e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0463647842407, "timer/env.step_count": 2509.0, "timer/env.step_total": 232.49084162712097, "timer/env.step_frac": 0.2324800627391718, "timer/env.step_avg": 0.09266275074815503, "timer/env.step_min": 0.023134231567382812, "timer/env.step_max": 3.485203266143799, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 9.620020627975464, "timer/replay._sample_frac": 0.00961957461847379, "timer/replay._sample_avg": 0.0004794667378376926, "timer/replay._sample_min": 0.00038909912109375, "timer/replay._sample_max": 0.010365486145019531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2968.0, "timer/agent.policy_total": 48.198657512664795, "timer/agent.policy_frac": 0.04819642289591605, "timer/agent.policy_avg": 0.01623943986275768, "timer/agent.policy_min": 0.009598970413208008, "timer/agent.policy_max": 0.09520316123962402, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.14182138442993164, "timer/dataset_train_frac": 0.00014181480921690015, "timer/dataset_train_avg": 0.00011309520289468232, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0004391670227050781, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 564.8709533214569, "timer/agent.train_frac": 0.5648447644158253, "timer/agent.train_avg": 0.4504553056789927, "timer/agent.train_min": 0.4383888244628906, "timer/agent.train_max": 1.0647571086883545, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47354769706726074, "timer/agent.report_frac": 0.0004735257421483936, "timer/agent.report_avg": 0.23677384853363037, "timer/agent.report_min": 0.23000836372375488, "timer/agent.report_max": 0.24353933334350586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.813208799579421e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 20.070818615984937}
{"step": 780928, "time": 39543.844138622284, "episode/length": 186.0, "episode/score": 0.19176834786958352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19176834786958352}
{"step": 780992, "time": 39548.341878414154, "episode/length": 178.0, "episode/score": 0.2052263486202719, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2052263486202719}
{"step": 781024, "time": 39551.61068367958, "episode/length": 157.0, "episode/score": 0.16230528584856074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16230528584856074}
{"step": 781280, "time": 39563.42951440811, "episode/length": 204.0, "episode/score": 0.22854334810335786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22854334810335786}
{"step": 781312, "time": 39566.73351144791, "episode/length": 176.0, "episode/score": 0.175285688470467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.175285688470467}
{"step": 781544, "time": 39577.45848441124, "episode/length": 193.0, "episode/score": 0.21836340083200412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21836340083200412}
{"step": 781624, "time": 39582.56809306145, "episode/length": 195.0, "episode/score": 0.2086634392421729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2086634392421729}
{"step": 782200, "time": 39606.272631406784, "episode/length": 185.0, "episode/score": 0.20182052375457715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20182052375457715}
{"step": 782208, "time": 39608.45095205307, "episode/length": 82.0, "episode/score": 0.0991666647605598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0991666647605598}
{"step": 782232, "time": 39610.80197548866, "episode/length": 150.0, "episode/score": 0.17141405002621468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17141405002621468}
{"step": 782384, "time": 39618.285875320435, "episode/length": 173.0, "episode/score": 0.19426988335180795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19426988335180795}
{"step": 782424, "time": 39621.154336214066, "episode/length": 186.0, "episode/score": 0.1936322842957452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1936322842957452}
{"step": 782504, "time": 39625.78639745712, "episode/length": 152.0, "episode/score": 0.17924198375840206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17924198375840206}
{"step": 782928, "time": 39643.5801692009, "episode/length": 162.0, "episode/score": 0.19268187452689745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19268187452689745}
{"step": 783328, "time": 39661.039377212524, "episode/length": 251.0, "episode/score": 0.3042628143739421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3042628143739421}
{"step": 783600, "time": 39672.741391420364, "episode/length": 170.0, "episode/score": 0.16626410704338923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16626410704338923}
{"step": 783616, "time": 39675.05056095123, "episode/length": 176.0, "episode/score": 0.18443690606000018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18443690606000018}
{"step": 783728, "time": 39680.79505825043, "episode/length": 189.0, "episode/score": 0.22266266722726868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22266266722726868}
{"step": 783776, "time": 39684.068440914154, "episode/length": 158.0, "episode/score": 0.1651742295580334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1651742295580334}
{"step": 783920, "time": 39691.015748262405, "episode/length": 186.0, "episode/score": 0.2180255867751839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2180255867751839}
{"step": 783984, "time": 39695.043994903564, "episode/length": 199.0, "episode/score": 0.21238238316800562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21238238316800562}
{"step": 784312, "time": 39708.69725680351, "episode/length": 172.0, "episode/score": 0.19129463998251595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19129463998251595}
{"step": 784600, "time": 39721.78640460968, "episode/length": 158.0, "episode/score": 0.17940866459684912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17940866459684912}
{"step": 784776, "time": 39730.57015180588, "episode/length": 146.0, "episode/score": 0.1594071397848893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1594071397848893}
{"step": 785032, "time": 39741.79120159149, "episode/length": 162.0, "episode/score": 0.17085305880755186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17085305880755186}
{"step": 785200, "time": 39749.9562022686, "episode/length": 197.0, "episode/score": 0.22224106773501262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22224106773501262}
{"step": 785312, "time": 39755.800740003586, "episode/length": 173.0, "episode/score": 0.19087213766761124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19087213766761124}
{"step": 785336, "time": 39758.05834150314, "episode/length": 168.0, "episode/score": 0.17939758121065097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17939758121065097}
{"step": 785616, "time": 39770.44396686554, "episode/length": 37.0, "episode/score": 0.043624999234452844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043624999234452844}
{"step": 785808, "time": 39779.114936590195, "episode/length": 186.0, "episode/score": 0.1996220286418975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1996220286418975}
{"step": 786072, "time": 39790.23592495918, "episode/length": 286.0, "episode/score": 0.33355168045818573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33355168045818573}
{"step": 786304, "time": 39800.75033426285, "episode/length": 190.0, "episode/score": 0.21750297277685604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21750297277685604}
{"step": 786392, "time": 39805.39477133751, "episode/length": 169.0, "episode/score": 0.1762790632492397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1762790632492397}
{"step": 786560, "time": 39814.83183026314, "episode/length": 169.0, "episode/score": 0.18702985771597014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18702985771597014}
{"step": 786800, "time": 39825.38690304756, "episode/length": 182.0, "episode/score": 0.2143330203361984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2143330203361984}
{"step": 786872, "time": 39829.3285112381, "episode/length": 156.0, "episode/score": 0.16785183691899874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16785183691899874}
{"step": 787288, "time": 39846.3768863678, "episode/length": 151.0, "episode/score": 0.16646775234039524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16646775234039524}
{"step": 787304, "time": 39848.484047174454, "episode/length": 186.0, "episode/score": 0.21277798431401607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21277798431401607}
{"step": 787608, "time": 39861.22034287453, "episode/length": 162.0, "episode/score": 0.18018361378926784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18018361378926784}
{"step": 787904, "time": 39874.10746908188, "episode/length": 167.0, "episode/score": 0.18461303845469956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18461303845469956}
{"step": 788056, "time": 39881.06999254227, "episode/length": 431.0, "episode/score": 0.4550817095241655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4550817095241655}
{"step": 788224, "time": 39889.08129262924, "episode/length": 168.0, "episode/score": 0.1839911401966674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1839911401966674}
{"step": 788520, "time": 39901.37756252289, "episode/length": 151.0, "episode/score": 0.16723209947667783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16723209947667783}
{"step": 788576, "time": 39905.19286799431, "episode/length": 221.0, "episode/score": 0.23712685227837937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23712685227837937}
{"step": 788584, "time": 39907.31184267998, "episode/length": 273.0, "episode/score": 0.3120578927882889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3120578927882889}
{"step": 788616, "time": 39910.47695636749, "episode/length": 165.0, "episode/score": 0.17885605790434056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17885605790434056}
{"step": 789152, "time": 39933.343353033066, "episode/length": 192.0, "episode/score": 0.21121311093156692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21121311093156692}
{"step": 789744, "time": 39957.36722326279, "episode/length": 189.0, "episode/score": 0.18858989835644024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18858989835644024}
{"step": 789888, "time": 39964.258472681046, "episode/length": 163.0, "episode/score": 0.19604457651439589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19604457651439589}
{"step": 790000, "time": 39970.00149178505, "episode/length": 172.0, "episode/score": 0.18861755676334724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18861755676334724}
{"step": 790072, "time": 39974.10063314438, "episode/length": 185.0, "episode/score": 0.21768551181594376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21768551181594376}
{"step": 790080, "time": 39976.21929526329, "episode/length": 194.0, "episode/score": 0.22028817225873354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22028817225873354}
{"step": 790088, "time": 39997.85020542145, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 790088, "time": 39999.802468299866, "eval_episode/length": 173.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 790088, "time": 40001.56151032448, "eval_episode/length": 175.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 790088, "time": 40003.55059361458, "eval_episode/length": 183.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 790088, "time": 40005.85433077812, "eval_episode/length": 197.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 790088, "time": 40007.62718248367, "eval_episode/length": 199.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.995}
{"step": 790088, "time": 40009.380046606064, "eval_episode/length": 203.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 790088, "time": 40013.64456295967, "eval_episode/length": 264.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 790192, "time": 40017.682742357254, "episode/length": 285.0, "episode/score": 0.31997004902586923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31997004902586923}
{"step": 790320, "time": 40023.90987920761, "episode/length": 282.0, "episode/score": 0.33167526380566414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33167526380566414}
{"step": 790832, "time": 40044.62552857399, "episode/length": 209.0, "episode/score": 0.22808425264520338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22808425264520338}
{"step": 791064, "time": 40054.58067893982, "episode/length": 164.0, "episode/score": 0.17875286803246127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17875286803246127}
{"step": 791416, "time": 40069.21996188164, "episode/length": 176.0, "episode/score": 0.2062807125839754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2062807125839754}
{"step": 791648, "time": 40079.64686512947, "episode/length": 196.0, "episode/score": 0.21968380774342222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21968380774342222}
{"step": 791664, "time": 40081.827070236206, "episode/length": 183.0, "episode/score": 0.19434659214675776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19434659214675776}
{"step": 791888, "time": 40091.748160123825, "episode/length": 195.0, "episode/score": 0.21413260248300503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21413260248300503}
{"step": 792344, "time": 40110.16911482811, "episode/length": 188.0, "episode/score": 0.21122812788235024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21122812788235024}
{"step": 792640, "time": 40122.82196307182, "episode/length": 196.0, "episode/score": 0.2199234514919226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2199234514919226}
{"step": 792864, "time": 40132.81564903259, "episode/length": 180.0, "episode/score": 0.21022122609429061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21022122609429061}
{"step": 793016, "time": 40139.837718486786, "episode/length": 168.0, "episode/score": 0.16081772390134574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16081772390134574}
{"step": 793064, "time": 40143.089782714844, "episode/length": 372.0, "episode/score": 0.34799324007144605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34799324007144605}
{"step": 793272, "time": 40152.307945013046, "episode/length": 172.0, "episode/score": 0.20370564112818101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20370564112818101}
{"step": 793336, "time": 40156.47566866875, "episode/length": 430.0, "episode/score": 0.4572558161926281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4572558161926281}
{"step": 793688, "time": 40171.0764772892, "episode/length": 254.0, "episode/score": 0.29249692487792345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29249692487792345}
{"step": 794080, "time": 40187.654933452606, "episode/length": 151.0, "episode/score": 0.15684352095922804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15684352095922804}
{"step": 794080, "time": 40187.66386628151, "episode/length": 179.0, "episode/score": 0.19896597885963274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19896597885963274}
{"step": 794280, "time": 40198.18827533722, "episode/length": 157.0, "episode/score": 0.17100552392548707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17100552392548707}
{"step": 794504, "time": 40208.02672481537, "episode/length": 179.0, "episode/score": 0.2015794698654645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2015794698654645}
{"step": 794552, "time": 40211.40211892128, "episode/length": 275.0, "episode/score": 0.31943736214816454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31943736214816454}
{"step": 794576, "time": 40214.03608703613, "episode/length": 154.0, "episode/score": 0.17312078427130473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17312078427130473}
{"step": 795072, "time": 40235.47865104675, "episode/length": 224.0, "episode/score": 0.24945412052511529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24945412052511529}
{"step": 795232, "time": 40243.14339923859, "episode/length": 192.0, "episode/score": 0.2259628225237975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2259628225237975}
{"step": 795552, "time": 40257.46218752861, "episode/length": 183.0, "episode/score": 0.19809562813679804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19809562813679804}
{"step": 795560, "time": 40259.54860711098, "episode/length": 159.0, "episode/score": 0.18324914657023328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18324914657023328}
{"step": 795576, "time": 40261.71101927757, "episode/length": 186.0, "episode/score": 0.21509524151770165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21509524151770165}
{"step": 795728, "time": 40269.11289167404, "episode/length": 152.0, "episode/score": 0.14730172151030274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14730172151030274}
{"step": 795784, "time": 40272.567880153656, "episode/length": 153.0, "episode/score": 0.17021175571426284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17021175571426284}
{"step": 796096, "time": 40286.09733366966, "episode/length": 189.0, "episode/score": 0.2009710337042634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2009710337042634}
{"step": 796392, "time": 40298.38303375244, "episode/length": 164.0, "episode/score": 0.1829147752332574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1829147752332574}
{"step": 796744, "time": 40313.01641488075, "episode/length": 188.0, "episode/score": 0.20073281560325995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20073281560325995}
{"step": 796840, "time": 40318.2691450119, "episode/length": 157.0, "episode/score": 0.1643731623134954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1643731623134954}
{"step": 796856, "time": 40320.410949230194, "episode/length": 133.0, "episode/score": 0.14505472443306644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14505472443306644}
{"step": 797024, "time": 40328.54068660736, "episode/length": 182.0, "episode/score": 0.20617722334645805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20617722334645805}
{"step": 797144, "time": 40334.387758016586, "episode/length": 176.0, "episode/score": 0.20131391976792656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20131391976792656}
{"step": 797688, "time": 40356.28529548645, "episode/length": 266.0, "episode/score": 0.3018518312692322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3018518312692322}
{"step": 798064, "time": 40372.11752295494, "episode/length": 164.0, "episode/score": 0.1785051958540862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785051958540862}
{"step": 798128, "time": 40376.0418279171, "episode/length": 216.0, "episode/score": 0.22711424503449962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22711424503449962}
{"step": 798272, "time": 40382.965248823166, "episode/length": 176.0, "episode/score": 0.18381134044739156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18381134044739156}
{"step": 798360, "time": 40387.60137248039, "episode/length": 189.0, "episode/score": 0.2214336396264116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2214336396264116}
{"step": 798440, "time": 40392.10614991188, "episode/length": 292.0, "episode/score": 0.33197760306939017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33197760306939017}
{"step": 798520, "time": 40396.76228737831, "episode/length": 186.0, "episode/score": 0.2031596890574292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2031596890574292}
{"step": 798992, "time": 40416.09384679794, "episode/length": 230.0, "episode/score": 0.24313273435291194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24313273435291194}
{"step": 799072, "time": 40420.59873056412, "episode/length": 172.0, "episode/score": 0.1712771826178141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712771826178141}
{"step": 799456, "time": 40436.4049384594, "episode/length": 165.0, "episode/score": 0.16971021069184644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16971021069184644}
{"step": 799608, "time": 40443.373304605484, "episode/length": 166.0, "episode/score": 0.17174035756397643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17174035756397643}
{"step": 799640, "time": 40446.522567510605, "episode/length": 196.0, "episode/score": 0.23419034289509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23419034289509}
{"step": 799720, "time": 40451.57370042801, "episode/length": 169.0, "episode/score": 0.19966666301479563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19966666301479563}
{"step": 800072, "time": 40486.72447371483, "eval_episode/length": 146.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 800072, "time": 40489.280406951904, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 800072, "time": 40490.89983296394, "eval_episode/length": 173.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 800072, "time": 40492.97477245331, "eval_episode/length": 186.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 800072, "time": 40494.652617931366, "eval_episode/length": 187.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 800072, "time": 40496.41193938255, "eval_episode/length": 191.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 800072, "time": 40502.66770815849, "eval_episode/length": 302.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 800072, "time": 40505.5350754261, "eval_episode/length": 147.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 800160, "time": 40509.033306121826, "episode/length": 214.0, "episode/score": 0.22802100670469372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22802100670469372}
{"step": 800216, "time": 40512.46936392784, "episode/length": 211.0, "episode/score": 0.22467918577422097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22467918577422097}
{"step": 800512, "time": 40525.446338653564, "episode/length": 189.0, "episode/score": 0.20203619882977364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20203619882977364}
{"step": 800616, "time": 40530.65951251984, "episode/length": 192.0, "episode/score": 0.22014382855104486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22014382855104486}
{"step": 800681, "time": 40535.662898778915, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.15501220703125, "train/action_min": 0.0, "train/action_std": 4.9648129272460935, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008136822322383523, "train/actor_opt_grad_steps": 49320.0, "train/actor_opt_loss": -14.473099875509739, "train/adv_mag": 0.1780664581656456, "train/adv_max": 0.12398307585716248, "train/adv_mean": -0.0001941464604678913, "train/adv_min": -0.17691978400945663, "train/adv_std": 0.013267822280526162, "train/cont_avg": 0.9943359375, "train/cont_loss_mean": 0.00013804965280939997, "train/cont_loss_std": 0.004253558603987585, "train/cont_neg_acc": 0.9925904774665832, "train/cont_neg_loss": 0.01950154124902474, "train/cont_pos_acc": 0.9999999861717224, "train/cont_pos_loss": 1.7856373446988983e-05, "train/cont_pred": 0.9943729252815247, "train/cont_rate": 0.9943359375, "train/dyn_loss_mean": 11.252088729858398, "train/dyn_loss_std": 8.375091361999512, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13052794256806374, "train/extr_critic_critic_opt_grad_steps": 49320.0, "train/extr_critic_critic_opt_loss": 12119.0131328125, "train/extr_critic_mag": 0.2899018964767456, "train/extr_critic_max": 0.2899018964767456, "train/extr_critic_mean": 0.23140059804916382, "train/extr_critic_min": 0.0016094369888305664, "train/extr_critic_std": 0.06427343466877937, "train/extr_return_normed_mag": 0.22470454812049867, "train/extr_return_normed_max": 0.22470454812049867, "train/extr_return_normed_mean": 0.16680248510837556, "train/extr_return_normed_min": -0.0634197653234005, "train/extr_return_normed_std": 0.06570203971862792, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28910846829414366, "train/extr_return_raw_max": 0.28910846829414366, "train/extr_return_raw_mean": 0.23120640897750855, "train/extr_return_raw_min": 0.0009841547012329102, "train/extr_return_raw_std": 0.06570203948020935, "train/extr_reward_mag": 0.0013431510925292968, "train/extr_reward_max": 0.0013431510925292968, "train/extr_reward_mean": 0.0011035280879586936, "train/extr_reward_min": 1.1435508728027343e-05, "train/extr_reward_std": 0.00023044128203764558, "train/image_loss_mean": 4.653860092163086, "train/image_loss_std": 9.52035615158081, "train/model_loss_mean": 11.445685081481933, "train/model_loss_std": 13.012144111633301, "train/model_opt_grad_norm": 47.53695181274414, "train/model_opt_grad_steps": 49273.0, "train/model_opt_loss": 15496.16469921875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1350.0, "train/policy_entropy_mag": 2.760334342956543, "train/policy_entropy_max": 2.760334342956543, "train/policy_entropy_mean": 2.063037173271179, "train/policy_entropy_min": 0.0794910619854927, "train/policy_entropy_std": 0.6304340183734893, "train/policy_logprob_mag": 7.438214336395264, "train/policy_logprob_max": -0.009472133614122868, "train/policy_logprob_mean": -2.0641681861877443, "train/policy_logprob_min": -7.438214336395264, "train/policy_logprob_std": 1.168694712638855, "train/policy_randomness_mag": 0.9742768917083741, "train/policy_randomness_max": 0.9742768917083741, "train/policy_randomness_mean": 0.7281615862846375, "train/policy_randomness_min": 0.02805685645341873, "train/policy_randomness_std": 0.22251554203033447, "train/post_ent_mag": 57.011957122802734, "train/post_ent_max": 57.011957122802734, "train/post_ent_mean": 40.48585934448242, "train/post_ent_min": 19.615491348266602, "train/post_ent_std": 6.882280715942382, "train/prior_ent_mag": 66.37512231445312, "train/prior_ent_max": 66.37512231445312, "train/prior_ent_mean": 51.78917333984375, "train/prior_ent_min": 30.590095611572266, "train/prior_ent_std": 5.384550193786621, "train/rep_loss_mean": 11.252088729858398, "train/rep_loss_std": 8.375091361999512, "train/reward_avg": 0.0010720252431929112, "train/reward_loss_mean": 0.04043375089764595, "train/reward_loss_std": 0.010876888364553451, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013067684173583985, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040433750927448275, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010721978386864066, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.9857142559829213, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.961904761904762, "train_stats/max_log_achievement_collect_sapling": 0.580952380952381, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5333333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.009523809523809525, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.009523809523809525, "train_stats/max_log_achievement_place_plant": 0.17142857142857143, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.08571428571428572, "train_stats/max_log_achievement_wake_up": 0.19047619047619047, "train_stats/mean_log_entropy": 2.0645398117247082, "eval_stats/sum_log_reward": 1.0999999698251486, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.0625, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.137320891255513e-05, "report/cont_loss_std": 0.0005127393524162471, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.3470702217309736e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.1427600333699957e-05, "report/cont_pred": 0.9931331276893616, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 10.543783187866211, "report/dyn_loss_std": 8.037924766540527, "report/image_loss_mean": 4.024764060974121, "report/image_loss_std": 9.681894302368164, "report/model_loss_mean": 10.391112327575684, "report/model_loss_std": 12.688907623291016, "report/post_ent_mag": 54.55624771118164, "report/post_ent_max": 54.55624771118164, "report/post_ent_mean": 40.910797119140625, "report/post_ent_min": 19.481475830078125, "report/post_ent_std": 6.98579216003418, "report/prior_ent_mag": 66.19723510742188, "report/prior_ent_max": 66.19723510742188, "report/prior_ent_mean": 51.74696350097656, "report/prior_ent_min": 24.168354034423828, "report/prior_ent_std": 5.380975723266602, "report/rep_loss_mean": 10.543783187866211, "report/rep_loss_std": 8.037924766540527, "report/reward_avg": 0.0010615187929943204, "report/reward_loss_mean": 0.04004660248756409, "report/reward_loss_std": 0.011510076001286507, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04004660248756409, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010581972310319543, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.290205187222455e-06, "eval/cont_loss_std": 3.019594805664383e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.869021747959778e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.20088098407723e-06, "eval/cont_pred": 0.9970622062683105, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.317584991455078, "eval/dyn_loss_std": 10.56618595123291, "eval/image_loss_mean": 10.565084457397461, "eval/image_loss_std": 14.233988761901855, "eval/model_loss_mean": 20.362245559692383, "eval/model_loss_std": 19.009305953979492, "eval/post_ent_mag": 57.71829605102539, "eval/post_ent_max": 57.71829605102539, "eval/post_ent_mean": 38.736549377441406, "eval/post_ent_min": 20.28321075439453, "eval/post_ent_std": 6.48726224899292, "eval/prior_ent_mag": 66.19723510742188, "eval/prior_ent_max": 66.19723510742188, "eval/prior_ent_mean": 51.423213958740234, "eval/prior_ent_min": 22.369258880615234, "eval/prior_ent_std": 6.854891777038574, "eval/rep_loss_mean": 15.317584991455078, "eval/rep_loss_std": 10.56618595123291, "eval/reward_avg": 9.765633149072528e-05, "eval/reward_loss_mean": 0.606602132320404, "eval/reward_loss_std": 3.413639545440674, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012655258178710938, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5069601535797119, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.913631439208984, "eval/reward_pred": 0.0010616795625537634, "eval/reward_rate": 0.0048828125, "replay/size": 800177.0, "replay/inserts": 19960.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.4287078070019433e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.20674288731355e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1968612670898436e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0462274551392, "timer/env.step_count": 2495.0, "timer/env.step_total": 240.04339575767517, "timer/env.step_frac": 0.24003229967530998, "timer/env.step_avg": 0.09620977785878765, "timer/env.step_min": 0.02309274673461914, "timer/env.step_max": 3.291409730911255, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.601237297058105, "timer/replay._sample_frac": 0.009600793476808357, "timer/replay._sample_avg": 0.00048083119476452854, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.010414361953735352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3095.0, "timer/agent.policy_total": 51.13573479652405, "timer/agent.policy_frac": 0.051133371030908606, "timer/agent.policy_avg": 0.01652204678401423, "timer/agent.policy_min": 0.009515762329101562, "timer/agent.policy_max": 0.1891779899597168, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.1402144432067871, "timer/dataset_train_frac": 0.00014020796174952517, "timer/dataset_train_avg": 0.00011235131667210505, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0004296302795410156, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 559.5007045269012, "timer/agent.train_frac": 0.5594748414287676, "timer/agent.train_avg": 0.4483178722170683, "timer/agent.train_min": 0.43527746200561523, "timer/agent.train_max": 1.0743279457092285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47464847564697266, "timer/agent.report_frac": 0.00047462653487012407, "timer/agent.report_avg": 0.23732423782348633, "timer/agent.report_min": 0.23127365112304688, "timer/agent.report_max": 0.24337482452392578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956253720773118e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 19.95879844274502}
{"step": 800808, "time": 40540.27802944183, "episode/length": 168.0, "episode/score": 0.15707132051375083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15707132051375083}
{"step": 800824, "time": 40542.39811396599, "episode/length": 147.0, "episode/score": 0.1486149225229383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1486149225229383}
{"step": 800920, "time": 40547.75379705429, "episode/length": 163.0, "episode/score": 0.1734437949489802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1734437949489802}
{"step": 801272, "time": 40563.24338746071, "episode/length": 193.0, "episode/score": 0.19924137491307192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19924137491307192}
{"step": 801560, "time": 40576.308592796326, "episode/length": 167.0, "episode/score": 0.16999846614817216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16999846614817216}
{"step": 801608, "time": 40580.03700327873, "episode/length": 180.0, "episode/score": 0.19290479323080945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19290479323080945}
{"step": 802024, "time": 40597.18443465233, "episode/length": 188.0, "episode/score": 0.18592193156200665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18592193156200665}
{"step": 802112, "time": 40602.234995126724, "episode/length": 162.0, "episode/score": 0.17919426532853322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17919426532853322}
{"step": 802120, "time": 40603.870725393295, "episode/length": 187.0, "episode/score": 0.20097232233456452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20097232233456452}
{"step": 802488, "time": 40619.16081094742, "episode/length": 195.0, "episode/score": 0.19844487516047593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19844487516047593}
{"step": 802688, "time": 40628.426916360855, "episode/length": 134.0, "episode/score": 0.14086570792051134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14086570792051134}
{"step": 802824, "time": 40635.49153780937, "episode/length": 157.0, "episode/score": 0.17432688659755513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17432688659755513}
{"step": 802928, "time": 40642.16961193085, "episode/length": 206.0, "episode/score": 0.23890277364989743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23890277364989743}
{"step": 803032, "time": 40647.37093830109, "episode/length": 114.0, "episode/score": 0.1333670199946937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1333670199946937}
{"step": 803104, "time": 40651.77797174454, "episode/length": 134.0, "episode/score": 0.1546249974053353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1546249974053353}
{"step": 803768, "time": 40677.87635755539, "episode/length": 205.0, "episode/score": 0.23237354539924127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23237354539924127}
{"step": 803968, "time": 40687.17550301552, "episode/length": 184.0, "episode/score": 0.18218824702853453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18218824702853453}
{"step": 804112, "time": 40694.16656279564, "episode/length": 410.0, "episode/score": 0.44722471695013155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44722471695013155}
{"step": 804392, "time": 40705.966888189316, "episode/length": 212.0, "episode/score": 0.22320892896595979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22320892896595979}
{"step": 804416, "time": 40708.65954995155, "episode/length": 163.0, "episode/score": 0.16502882521035644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16502882521035644}
{"step": 804536, "time": 40714.53253221512, "episode/length": 187.0, "episode/score": 0.20532067791555164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20532067791555164}
{"step": 804624, "time": 40719.573823451996, "episode/length": 211.0, "episode/score": 0.23486027282297073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23486027282297073}
{"step": 805192, "time": 40742.02355694771, "episode/length": 177.0, "episode/score": 0.19529105494211763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19529105494211763}
{"step": 805248, "time": 40745.94999265671, "episode/length": 302.0, "episode/score": 0.34594065806550134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34594065806550134}
{"step": 805536, "time": 40758.308248996735, "episode/length": 177.0, "episode/score": 0.17392446321309762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17392446321309762}
{"step": 805688, "time": 40765.44039440155, "episode/length": 161.0, "episode/score": 0.166467074324828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166467074324828}
{"step": 805736, "time": 40768.81842970848, "episode/length": 149.0, "episode/score": 0.17329860807512887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17329860807512887}
{"step": 806000, "time": 40780.5222966671, "episode/length": 197.0, "episode/score": 0.19960959825220925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19960959825220925}
{"step": 806216, "time": 40790.14002895355, "episode/length": 198.0, "episode/score": 0.21792420845758897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21792420845758897}
{"step": 806296, "time": 40794.70940160751, "episode/length": 137.0, "episode/score": 0.16279777601721435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16279777601721435}
{"step": 806744, "time": 40812.75058245659, "episode/length": 186.0, "episode/score": 0.21320127509807207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21320127509807207}
{"step": 806768, "time": 40815.55535078049, "episode/length": 68.0, "episode/score": 0.08146425589666251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08146425589666251}
{"step": 806864, "time": 40820.80341696739, "episode/length": 165.0, "episode/score": 0.18327995321715207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18327995321715207}
{"step": 806976, "time": 40826.57982802391, "episode/length": 154.0, "episode/score": 0.17353427704301794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17353427704301794}
{"step": 807000, "time": 40828.84823131561, "episode/length": 163.0, "episode/score": 0.17915782161708194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17915782161708194}
{"step": 807320, "time": 40842.30465006828, "episode/length": 164.0, "episode/score": 0.18178972229952706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18178972229952706}
{"step": 807416, "time": 40847.49658989906, "episode/length": 430.0, "episode/score": 0.445387214153925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.445387214153925}
{"step": 808000, "time": 40871.36604475975, "episode/length": 153.0, "episode/score": 0.1737019153529218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1737019153529218}
{"step": 808128, "time": 40878.32271528244, "episode/length": 172.0, "episode/score": 0.19688665672538264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19688665672538264}
{"step": 808128, "time": 40878.331107616425, "episode/length": 228.0, "episode/score": 0.269584923378261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.269584923378261}
{"step": 808264, "time": 40886.74449849129, "episode/length": 160.0, "episode/score": 0.17777842401665112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17777842401665112}
{"step": 808320, "time": 40890.618735075, "episode/length": 164.0, "episode/score": 0.156457115192552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.156457115192552}
{"step": 808376, "time": 40894.003200769424, "episode/length": 188.0, "episode/score": 0.2050137601008828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2050137601008828}
{"step": 808624, "time": 40905.27963137627, "episode/length": 162.0, "episode/score": 0.17438247334530388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17438247334530388}
{"step": 808904, "time": 40917.01327109337, "episode/length": 185.0, "episode/score": 0.22197992821020307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22197992821020307}
{"step": 809320, "time": 40934.02861380577, "episode/length": 164.0, "episode/score": 0.19280341517878696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19280341517878696}
{"step": 809416, "time": 40939.18508839607, "episode/length": 160.0, "episode/score": 0.16627523259376176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16627523259376176}
{"step": 809544, "time": 40945.470041275024, "episode/length": 145.0, "episode/score": 0.16739694093848811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16739694093848811}
{"step": 809808, "time": 40957.1123521328, "episode/length": 192.0, "episode/score": 0.2150726925683557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2150726925683557}
{"step": 809960, "time": 40964.15808916092, "episode/length": 204.0, "episode/score": 0.24601675740268547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24601675740268547}
{"step": 810056, "time": 40988.85876727104, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 810056, "time": 40990.91434264183, "eval_episode/length": 169.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 810056, "time": 40992.66153240204, "eval_episode/length": 172.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 810056, "time": 40994.54894089699, "eval_episode/length": 177.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 810056, "time": 40996.90572309494, "eval_episode/length": 194.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 810056, "time": 40998.65506863594, "eval_episode/length": 195.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 810056, "time": 40998.66148376465, "eval_episode/length": 195.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 810056, "time": 41004.767958164215, "eval_episode/length": 261.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 810464, "time": 41020.13253259659, "episode/length": 291.0, "episode/score": 0.30621322582737776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30621322582737776}
{"step": 810752, "time": 41032.40859532356, "episode/length": 166.0, "episode/score": 0.19045022294812952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19045022294812952}
{"step": 810968, "time": 41041.70980787277, "episode/length": 205.0, "episode/score": 0.2293864948915143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2293864948915143}
{"step": 811032, "time": 41047.130883932114, "episode/length": 300.0, "episode/score": 0.323248693079222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.323248693079222}
{"step": 811080, "time": 41050.435188770294, "episode/length": 191.0, "episode/score": 0.21815700866136467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21815700866136467}
{"step": 811136, "time": 41054.36473917961, "episode/length": 278.0, "episode/score": 0.312567427270551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.312567427270551}
{"step": 811280, "time": 41061.345621585846, "episode/length": 164.0, "episode/score": 0.1882551158523711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1882551158523711}
{"step": 811664, "time": 41077.26342463493, "episode/length": 149.0, "episode/score": 0.14597220602809102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14597220602809102}
{"step": 811800, "time": 41083.63831591606, "episode/length": 248.0, "episode/score": 0.2949627406815125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2949627406815125}
{"step": 812240, "time": 41101.74500966072, "episode/length": 54.0, "episode/score": 0.05480846779391868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05480846779391868}
{"step": 812288, "time": 41105.02288031578, "episode/length": 191.0, "episode/score": 0.22056058489033603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22056058489033603}
{"step": 812624, "time": 41119.66472482681, "episode/length": 198.0, "episode/score": 0.20871397205883113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20871397205883113}
{"step": 812648, "time": 41122.469118118286, "episode/length": 170.0, "episode/score": 0.18114133679227962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18114133679227962}
{"step": 812672, "time": 41125.6958861351, "episode/length": 198.0, "episode/score": 0.21186854440747993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21186854440747993}
{"step": 812848, "time": 41134.514984846115, "episode/length": 213.0, "episode/score": 0.23248105649145145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23248105649145145}
{"step": 813184, "time": 41149.297183036804, "episode/length": 189.0, "episode/score": 0.2073328015558218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2073328015558218}
{"step": 813224, "time": 41152.05969834328, "episode/length": 281.0, "episode/score": 0.31634904420025123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31634904420025123}
{"step": 813424, "time": 41161.36854457855, "episode/length": 147.0, "episode/score": 0.15946995487865934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15946995487865934}
{"step": 813800, "time": 41176.75421619415, "episode/length": 146.0, "episode/score": 0.14392185241013067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14392185241013067}
{"step": 813840, "time": 41180.03551054001, "episode/length": 193.0, "episode/score": 0.21469661138144147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21469661138144147}
{"step": 814024, "time": 41188.29718255997, "episode/length": 171.0, "episode/score": 0.17917561424656014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17917561424656014}
{"step": 814048, "time": 41191.64172935486, "episode/length": 171.0, "episode/score": 0.2058537969714962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2058537969714962}
{"step": 814248, "time": 41201.15106511116, "episode/length": 174.0, "episode/score": 0.20068344850369613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20068344850369613}
{"step": 814648, "time": 41217.672676324844, "episode/length": 177.0, "episode/score": 0.21645832899957895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21645832899957895}
{"step": 814712, "time": 41221.637268066406, "episode/length": 190.0, "episode/score": 0.21022183210152434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21022183210152434}
{"step": 814992, "time": 41234.47304439545, "episode/length": 195.0, "episode/score": 0.2057046353820624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2057046353820624}
{"step": 815200, "time": 41243.65952825546, "episode/length": 174.0, "episode/score": 0.16722414488504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16722414488504}
{"step": 815352, "time": 41250.834657907486, "episode/length": 188.0, "episode/score": 0.20996899628698884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20996899628698884}
{"step": 815592, "time": 41261.90494585037, "episode/length": 195.0, "episode/score": 0.20206028008760768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20206028008760768}
{"step": 815824, "time": 41272.47617173195, "episode/length": 196.0, "episode/score": 0.22211753083865915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22211753083865915}
{"step": 816016, "time": 41281.127501010895, "episode/length": 162.0, "episode/score": 0.18137909630513604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18137909630513604}
{"step": 816216, "time": 41290.262553453445, "episode/length": 195.0, "episode/score": 0.20335725913810165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20335725913810165}
{"step": 816264, "time": 41293.720831632614, "episode/length": 276.0, "episode/score": 0.3133825638524286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3133825638524286}
{"step": 816504, "time": 41304.39916777611, "episode/length": 162.0, "episode/score": 0.1964583294466138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1964583294466138}
{"step": 816688, "time": 41313.113503456116, "episode/length": 166.0, "episode/score": 0.20072221815917146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20072221815917146}
{"step": 816872, "time": 41321.854874134064, "episode/length": 159.0, "episode/score": 0.1651047557243146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1651047557243146}
{"step": 817296, "time": 41339.49718642235, "episode/length": 159.0, "episode/score": 0.187829934331603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187829934331603}
{"step": 817352, "time": 41343.03785562515, "episode/length": 190.0, "episode/score": 0.1949069209931622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1949069209931622}
{"step": 817424, "time": 41347.63151693344, "episode/length": 303.0, "episode/score": 0.3497236427883763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3497236427883763}
{"step": 817800, "time": 41363.37285733223, "episode/length": 161.0, "episode/score": 0.1760409474836706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1760409474836706}
{"step": 817816, "time": 41366.090542554855, "episode/length": 193.0, "episode/score": 0.21350765961597062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21350765961597062}
{"step": 817864, "time": 41369.4066092968, "episode/length": 205.0, "episode/score": 0.23081207794257352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23081207794257352}
{"step": 818568, "time": 41397.17748451233, "episode/length": 211.0, "episode/score": 0.21662733646098786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21662733646098786}
{"step": 818752, "time": 41405.80407166481, "episode/length": 257.0, "episode/score": 0.27574938778161595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27574938778161595}
{"step": 818816, "time": 41409.833799123764, "episode/length": 189.0, "episode/score": 0.2140176778057139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2140176778057139}
{"step": 819248, "time": 41429.341824769974, "episode/length": 227.0, "episode/score": 0.2620351972100252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2620351972100252}
{"step": 819272, "time": 41431.558578014374, "episode/length": 181.0, "episode/score": 0.17587157149137056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17587157149137056}
{"step": 819336, "time": 41435.41525506973, "episode/length": 183.0, "episode/score": 0.20217041607156716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20217041607156716}
{"step": 819408, "time": 41440.02235126495, "episode/length": 200.0, "episode/score": 0.23109378955268767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23109378955268767}
{"step": 820032, "time": 41465.26758313179, "episode/length": 159.0, "episode/score": 0.1758048841438722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1758048841438722}
{"step": 820040, "time": 41485.941101551056, "eval_episode/length": 135.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 820040, "time": 41488.43880391121, "eval_episode/length": 154.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 820040, "time": 41490.118475914, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 820040, "time": 41492.2596514225, "eval_episode/length": 168.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 820040, "time": 41494.16848373413, "eval_episode/length": 178.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.994413407821229}
{"step": 820040, "time": 41496.711751937866, "eval_episode/length": 201.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995049504950495}
{"step": 820040, "time": 41498.58285021782, "eval_episode/length": 209.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 820040, "time": 41498.59027457237, "eval_episode/length": 209.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 820088, "time": 41500.378902196884, "episode/length": 158.0, "episode/score": 0.15315698148333468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15315698148333468}
{"step": 820184, "time": 41505.63129854202, "episode/length": 201.0, "episode/score": 0.2281816636423173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2281816636423173}
{"step": 820328, "time": 41512.592188835144, "episode/length": 371.0, "episode/score": 0.4002017934426476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4002017934426476}
{"step": 820560, "time": 41523.04639792442, "episode/length": 160.0, "episode/score": 0.166358172580658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166358172580658}
{"step": 820600, "time": 41525.829980134964, "episode/length": 157.0, "episode/score": 0.17000656479649479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17000656479649479}
{"step": 820760, "time": 41533.465688467026, "episode/length": 188.0, "episode/score": 0.2158264748286456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2158264748286456}
{"step": 820761, "time": 41536.22897148132, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.016464960007441, "train/action_min": 0.0, "train/action_std": 4.905325586833651, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007668462253013064, "train/actor_opt_grad_steps": 50575.0, "train/actor_opt_loss": -10.095654467741648, "train/adv_mag": 0.16828681244736626, "train/adv_max": 0.1196205880315531, "train/adv_mean": 3.376129211213242e-05, "train/adv_min": -0.16733178502273938, "train/adv_std": 0.012516187603718467, "train/cont_avg": 0.9951249379960317, "train/cont_loss_mean": 0.00019116740766513712, "train/cont_loss_std": 0.005562714320599334, "train/cont_neg_acc": 0.9925075594394926, "train/cont_neg_loss": 0.01657796317363497, "train/cont_pos_acc": 0.9999766307217735, "train/cont_pos_loss": 8.861246732982589e-05, "train/cont_pred": 0.9951191927705493, "train/cont_rate": 0.9951249379960317, "train/dyn_loss_mean": 11.181903733147514, "train/dyn_loss_std": 8.314186815231565, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11901957467789688, "train/extr_critic_critic_opt_grad_steps": 50575.0, "train/extr_critic_critic_opt_loss": 12080.501542348711, "train/extr_critic_mag": 0.2850687030761961, "train/extr_critic_max": 0.2850687030761961, "train/extr_critic_mean": 0.22950724559643912, "train/extr_critic_min": 0.001901097713954865, "train/extr_critic_std": 0.05903008589077564, "train/extr_return_normed_mag": 0.21245880011055204, "train/extr_return_normed_max": 0.21245880011055204, "train/extr_return_normed_mean": 0.15741032042673656, "train/extr_return_normed_min": -0.07108512869666493, "train/extr_return_normed_std": 0.06025950637246881, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2845894777112537, "train/extr_return_raw_max": 0.2845894777112537, "train/extr_return_raw_mean": 0.22954100417712378, "train/extr_return_raw_min": 0.0010455496727474153, "train/extr_return_raw_std": 0.06025950622463983, "train/extr_reward_mag": 0.0013634032673305934, "train/extr_reward_max": 0.0013634032673305934, "train/extr_reward_mean": 0.0011004038711285426, "train/extr_reward_min": 1.1645612262544178e-05, "train/extr_reward_std": 0.0002299900604864686, "train/image_loss_mean": 4.698349578039987, "train/image_loss_std": 9.525537532473367, "train/model_loss_mean": 11.448035751070295, "train/model_loss_std": 12.984553692832826, "train/model_opt_grad_norm": 52.388048156859384, "train/model_opt_grad_steps": 50527.00793650794, "train/model_opt_loss": 15762.5216781374, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1388.888888888889, "train/policy_entropy_mag": 2.7617264210231722, "train/policy_entropy_max": 2.7617264210231722, "train/policy_entropy_mean": 2.075799335562994, "train/policy_entropy_min": 0.07947139761277608, "train/policy_entropy_std": 0.6340127289295197, "train/policy_logprob_mag": 7.438241644511147, "train/policy_logprob_max": -0.009469436865950387, "train/policy_logprob_mean": -2.074476945967901, "train/policy_logprob_min": -7.438241644511147, "train/policy_logprob_std": 1.1588249173429277, "train/policy_randomness_mag": 0.9747682332046448, "train/policy_randomness_max": 0.9747682332046448, "train/policy_randomness_mean": 0.7326660709721702, "train/policy_randomness_min": 0.02804991588114746, "train/policy_randomness_std": 0.2237786715702405, "train/post_ent_mag": 57.068638483683266, "train/post_ent_max": 57.068638483683266, "train/post_ent_mean": 40.62527157011486, "train/post_ent_min": 19.685237203325546, "train/post_ent_std": 6.882798085137019, "train/prior_ent_mag": 66.4032488626147, "train/prior_ent_max": 66.4032488626147, "train/prior_ent_mean": 51.88495390755789, "train/prior_ent_min": 30.011104341537234, "train/prior_ent_std": 5.430906488781884, "train/rep_loss_mean": 11.181903733147514, "train/rep_loss_std": 8.314186815231565, "train/reward_avg": 0.0010694128633033308, "train/reward_loss_mean": 0.040352848018445665, "train/reward_loss_std": 0.010870558424069294, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013124725175282313, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04035284772278771, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010702874056906218, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.8641509290011424, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.9811320754716981, "train_stats/max_log_achievement_collect_sapling": 0.7358490566037735, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.44339622641509435, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.018867924528301886, "train_stats/max_log_achievement_place_plant": 0.330188679245283, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.03773584905660377, "train_stats/max_log_achievement_wake_up": 0.1509433962264151, "train_stats/mean_log_entropy": 2.0843456061381214, "eval_stats/sum_log_reward": 1.0374999637715518, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.3125, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.85540283282171e-06, "report/cont_loss_std": 0.00011851567251142114, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00038865391979925334, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.977097549068276e-06, "report/cont_pred": 0.9951152801513672, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.728325843811035, "report/dyn_loss_std": 8.207976341247559, "report/image_loss_mean": 4.313726425170898, "report/image_loss_std": 6.979178428649902, "report/model_loss_mean": 10.790674209594727, "report/model_loss_std": 10.48317813873291, "report/post_ent_mag": 56.256439208984375, "report/post_ent_max": 56.256439208984375, "report/post_ent_mean": 41.2350959777832, "report/post_ent_min": 20.73807144165039, "report/post_ent_std": 7.182132244110107, "report/prior_ent_mag": 66.5770263671875, "report/prior_ent_max": 66.5770263671875, "report/prior_ent_mean": 52.25532913208008, "report/prior_ent_min": 33.20722198486328, "report/prior_ent_std": 5.605140209197998, "report/rep_loss_mean": 10.728325843811035, "report/rep_loss_std": 8.207976341247559, "report/reward_avg": 0.0010586294811218977, "report/reward_loss_mean": 0.03994704782962799, "report/reward_loss_std": 0.011334489099681377, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013889074325561523, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03994704782962799, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010715450625866652, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 4.573528713081032e-05, "eval/cont_loss_std": 0.001359019079245627, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00021438887051772326, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.4574444473255426e-05, "eval/cont_pred": 0.9931222796440125, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.56757354736328, "eval/dyn_loss_std": 10.025733947753906, "eval/image_loss_mean": 9.021000862121582, "eval/image_loss_std": 11.366873741149902, "eval/model_loss_mean": 19.72394371032715, "eval/model_loss_std": 15.783183097839355, "eval/post_ent_mag": 55.949851989746094, "eval/post_ent_max": 55.949851989746094, "eval/post_ent_mean": 38.98891830444336, "eval/post_ent_min": 19.74623680114746, "eval/post_ent_std": 6.907540798187256, "eval/prior_ent_mag": 66.5770263671875, "eval/prior_ent_max": 66.5770263671875, "eval/prior_ent_mean": 53.11042404174805, "eval/prior_ent_min": 29.20931625366211, "eval/prior_ent_std": 5.025888919830322, "eval/rep_loss_mean": 16.56757354736328, "eval/rep_loss_std": 10.025733947753906, "eval/reward_avg": 0.0032226562034338713, "eval/reward_loss_mean": 0.7623528242111206, "eval/reward_loss_std": 3.7972350120544434, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012853145599365234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5629161596298218, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.9852237701416, "eval/reward_pred": 0.001099568558856845, "eval/reward_rate": 0.009765625, "replay/size": 820257.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.4103978753564843e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.249425318136633e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1714459475824387e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5518009662628, "timer/env.step_count": 2510.0, "timer/env.step_total": 242.16496634483337, "timer/env.step_frac": 0.24203141317717625, "timer/env.step_avg": 0.09648006627284199, "timer/env.step_min": 0.023384809494018555, "timer/env.step_max": 3.5488274097442627, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 9.688769817352295, "timer/replay._sample_frac": 0.009683426493256582, "timer/replay._sample_avg": 0.00048250845703945694, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.010052680969238281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2982.0, "timer/agent.policy_total": 48.13898992538452, "timer/agent.policy_frac": 0.048112441433712134, "timer/agent.policy_avg": 0.016143189109786894, "timer/agent.policy_min": 0.009765625, "timer/agent.policy_max": 0.11865472793579102, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.14216375350952148, "timer/dataset_train_frac": 0.00014208535067572684, "timer/dataset_train_avg": 0.0001132778912426466, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0007770061492919922, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 565.2696058750153, "timer/agent.train_frac": 0.5649578615810971, "timer/agent.train_avg": 0.45041402858566953, "timer/agent.train_min": 0.43543028831481934, "timer/agent.train_max": 1.0841426849365234, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4702141284942627, "timer/agent.report_frac": 0.0004699548069776726, "timer/agent.report_avg": 0.23510706424713135, "timer/agent.report_min": 0.2283308506011963, "timer/agent.report_max": 0.2418832778930664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.121560905906341e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 20.068665671696884}
{"step": 820856, "time": 41539.57464694977, "episode/length": 95.0, "episode/score": 0.11358624474087264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11358624474087264}
{"step": 821576, "time": 41567.96630716324, "episode/length": 192.0, "episode/score": 0.22929166213725694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22929166213725694}
{"step": 821600, "time": 41570.6519112587, "episode/length": 158.0, "episode/score": 0.17150519104325213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17150519104325213}
{"step": 821696, "time": 41575.72459292412, "episode/length": 285.0, "episode/score": 0.31751535337389214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31751535337389214}
{"step": 821864, "time": 41583.29516816139, "episode/length": 157.0, "episode/score": 0.17036914423078997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17036914423078997}
{"step": 821912, "time": 41586.65052604675, "episode/length": 215.0, "episode/score": 0.24142742267576978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24142742267576978}
{"step": 822016, "time": 41592.24554729462, "episode/length": 156.0, "episode/score": 0.172551967218169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.172551967218169}
{"step": 822024, "time": 41593.839800834656, "episode/length": 182.0, "episode/score": 0.20499160922918236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20499160922918236}
{"step": 822824, "time": 41626.226028203964, "episode/length": 245.0, "episode/score": 0.29453074805496726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29453074805496726}
{"step": 823040, "time": 41636.0000371933, "episode/length": 167.0, "episode/score": 0.17929702911351342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17929702911351342}
{"step": 823128, "time": 41640.508987903595, "episode/length": 151.0, "episode/score": 0.1799270798728685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1799270798728685}
{"step": 823336, "time": 41650.00860238075, "episode/length": 163.0, "episode/score": 0.18025462668083492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18025462668083492}
{"step": 823560, "time": 41660.02662014961, "episode/length": 247.0, "episode/score": 0.2873412122571608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2873412122571608}
{"step": 823560, "time": 41660.03230857849, "episode/length": 64.0, "episode/score": 0.0738333321060054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0738333321060054}
{"step": 823656, "time": 41666.980543375015, "episode/length": 204.0, "episode/score": 0.209577075602283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.209577075602283}
{"step": 823672, "time": 41669.25694799423, "episode/length": 258.0, "episode/score": 0.29960711656895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29960711656895}
{"step": 823672, "time": 41669.26535439491, "episode/length": 225.0, "episode/score": 0.24784827659095754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24784827659095754}
{"step": 824256, "time": 41694.397216796875, "episode/length": 178.0, "episode/score": 0.19870420930965338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19870420930965338}
{"step": 824560, "time": 41707.1933529377, "episode/length": 152.0, "episode/score": 0.16023368065361865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16023368065361865}
{"step": 824832, "time": 41718.85024309158, "episode/length": 158.0, "episode/score": 0.15619421939118183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15619421939118183}
{"step": 824840, "time": 41720.48418593407, "episode/length": 159.0, "episode/score": 0.17320501342328498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17320501342328498}
{"step": 825048, "time": 41729.889833688736, "episode/length": 171.0, "episode/score": 0.17769503946692566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17769503946692566}
{"step": 825056, "time": 41732.02926325798, "episode/length": 172.0, "episode/score": 0.1899382660194533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1899382660194533}
{"step": 825072, "time": 41734.214844703674, "episode/length": 242.0, "episode/score": 0.2650964618915168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2650964618915168}
{"step": 825088, "time": 41736.30869984627, "episode/length": 178.0, "episode/score": 0.19873201087102643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19873201087102643}
{"step": 825544, "time": 41754.52695822716, "episode/length": 160.0, "episode/score": 0.17504860865301453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17504860865301453}
{"step": 825832, "time": 41766.72402405739, "episode/length": 158.0, "episode/score": 0.1739189570871531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1739189570871531}
{"step": 826032, "time": 41776.10022568703, "episode/length": 148.0, "episode/score": 0.17682364261418115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17682364261418115}
{"step": 826200, "time": 41783.73920536041, "episode/length": 138.0, "episode/score": 0.14657638693461195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14657638693461195}
{"step": 826200, "time": 41783.747076272964, "episode/length": 170.0, "episode/score": 0.1831717146706069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1831717146706069}
{"step": 826352, "time": 41792.98387169838, "episode/length": 159.0, "episode/score": 0.16647254361305386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16647254361305386}
{"step": 826496, "time": 41799.949932575226, "episode/length": 179.0, "episode/score": 0.20945062639657408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20945062639657408}
{"step": 826568, "time": 41803.967542648315, "episode/length": 127.0, "episode/score": 0.15487499692244455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15487499692244455}
{"step": 826784, "time": 41813.77232789993, "episode/length": 216.0, "episode/score": 0.2427764161111554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2427764161111554}
{"step": 827336, "time": 41835.654963970184, "episode/length": 162.0, "episode/score": 0.16875652695307508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16875652695307508}
{"step": 827432, "time": 41842.22912192345, "episode/length": 153.0, "episode/score": 0.17672640777891502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17672640777891502}
{"step": 827544, "time": 41847.869859457016, "episode/length": 167.0, "episode/score": 0.17154855769331334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17154855769331334}
{"step": 827744, "time": 41857.10965871811, "episode/length": 173.0, "episode/score": 0.1937769679352641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1937769679352641}
{"step": 828016, "time": 41868.954810619354, "episode/length": 189.0, "episode/score": 0.2089161145631806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2089161145631806}
{"step": 828232, "time": 41878.888649225235, "episode/length": 180.0, "episode/score": 0.1876706581970211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1876706581970211}
{"step": 828400, "time": 41886.90890002251, "episode/length": 228.0, "episode/score": 0.2565663206260069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2565663206260069}
{"step": 828640, "time": 41897.42436528206, "episode/length": 150.0, "episode/score": 0.1498352946655359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1498352946655359}
{"step": 828800, "time": 41904.97075223923, "episode/length": 182.0, "episode/score": 0.1993276801513275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1993276801513275}
{"step": 828880, "time": 41909.50466680527, "episode/length": 166.0, "episode/score": 0.19299952067012782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19299952067012782}
{"step": 828968, "time": 41914.201635837555, "episode/length": 391.0, "episode/score": 0.4121175426116679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4121175426116679}
{"step": 829248, "time": 41927.10853433609, "episode/length": 187.0, "episode/score": 0.20399001380428672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20399001380428672}
{"step": 829544, "time": 41939.58967399597, "episode/length": 190.0, "episode/score": 0.2044645509959082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2044645509959082}
{"step": 829672, "time": 41945.982060194016, "episode/length": 158.0, "episode/score": 0.17949862352543278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17949862352543278}
{"step": 829760, "time": 41951.586431503296, "episode/length": 139.0, "episode/score": 0.16024999727960676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16024999727960676}
{"step": 830024, "time": 41983.332355737686, "eval_episode/length": 161.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 830024, "time": 41985.13333940506, "eval_episode/length": 162.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 830024, "time": 41986.863928318024, "eval_episode/length": 164.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 830024, "time": 41988.89856672287, "eval_episode/length": 174.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 830024, "time": 41990.81252121925, "eval_episode/length": 182.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 830024, "time": 41992.6696062088, "eval_episode/length": 187.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 830024, "time": 41994.73442864418, "eval_episode/length": 195.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 830024, "time": 41996.38893008232, "eval_episode/length": 198.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 830104, "time": 41999.355798244476, "episode/length": 233.0, "episode/score": 0.27267279939405853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27267279939405853}
{"step": 830200, "time": 42004.55988717079, "episode/length": 174.0, "episode/score": 0.18666052117623622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18666052117623622}
{"step": 830296, "time": 42009.74505376816, "episode/length": 77.0, "episode/score": 0.08766463798747282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08766463798747282}
{"step": 830344, "time": 42013.05159330368, "episode/length": 182.0, "episode/score": 0.2089187509373005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2089187509373005}
{"step": 830544, "time": 42022.425934791565, "episode/length": 196.0, "episode/score": 0.20461238415009575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20461238415009575}
{"step": 831200, "time": 42048.93933749199, "episode/length": 206.0, "episode/score": 0.22935859915378387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22935859915378387}
{"step": 831264, "time": 42053.59847307205, "episode/length": 144.0, "episode/score": 0.16360988440465007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16360988440465007}
{"step": 831408, "time": 42061.13542342186, "episode/length": 150.0, "episode/score": 0.1587058963286836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1587058963286836}
{"step": 831536, "time": 42067.455231666565, "episode/length": 221.0, "episode/score": 0.2149954847045592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2149954847045592}
{"step": 831584, "time": 42070.80615210533, "episode/length": 154.0, "episode/score": 0.16493825971156184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16493825971156184}
{"step": 831656, "time": 42075.01861190796, "episode/length": 169.0, "episode/score": 0.17738999172979675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17738999172979675}
{"step": 831744, "time": 42080.03203082085, "episode/length": 311.0, "episode/score": 0.3695021858475229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3695021858475229}
{"step": 832728, "time": 42118.125344753265, "episode/length": 272.0, "episode/score": 0.28115670018451056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28115670018451056}
{"step": 832768, "time": 42122.04346728325, "episode/length": 153.0, "episode/score": 0.16221577485703165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16221577485703165}
{"step": 832792, "time": 42124.667392492294, "episode/length": 172.0, "episode/score": 0.1756051715783542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1756051715783542}
{"step": 832856, "time": 42129.088675022125, "episode/length": 206.0, "episode/score": 0.2381666624569334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2381666624569334}
{"step": 832928, "time": 42134.3599421978, "episode/length": 147.0, "episode/score": 0.1704763193920371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704763193920371}
{"step": 833000, "time": 42138.87001466751, "episode/length": 167.0, "episode/score": 0.18984705578441208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18984705578441208}
{"step": 833176, "time": 42147.55507540703, "episode/length": 198.0, "episode/score": 0.22061360830230115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22061360830230115}
{"step": 833912, "time": 42176.613401174545, "episode/length": 139.0, "episode/score": 0.15868167300504865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15868167300504865}
{"step": 834192, "time": 42188.841960430145, "episode/length": 148.0, "episode/score": 0.1705610388698915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1705610388698915}
{"step": 834224, "time": 42191.559993982315, "episode/length": 161.0, "episode/score": 0.16335967498889659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16335967498889659}
{"step": 834304, "time": 42196.21204543114, "episode/length": 196.0, "episode/score": 0.21248803422895435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21248803422895435}
{"step": 834336, "time": 42199.01032495499, "episode/length": 144.0, "episode/score": 0.14845956988301623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14845956988301623}
{"step": 834336, "time": 42199.01921749115, "episode/length": 184.0, "episode/score": 0.21521473169286764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21521473169286764}
{"step": 834544, "time": 42210.37125492096, "episode/length": 221.0, "episode/score": 0.24765144870798395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24765144870798395}
{"step": 834712, "time": 42218.64913201332, "episode/length": 430.0, "episode/score": 0.42326439213229605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42326439213229605}
{"step": 835440, "time": 42247.90143060684, "episode/length": 141.0, "episode/score": 0.1466716805480246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1466716805480246}
{"step": 835480, "time": 42250.66290092468, "episode/length": 195.0, "episode/score": 0.20055139728538052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20055139728538052}
{"step": 835624, "time": 42259.08338880539, "episode/length": 174.0, "episode/score": 0.19357512324040727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19357512324040727}
{"step": 835680, "time": 42262.9623670578, "episode/length": 167.0, "episode/score": 0.18208729893012787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18208729893012787}
{"step": 835712, "time": 42265.71710062027, "episode/length": 171.0, "episode/score": 0.18639992365660873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18639992365660873}
{"step": 836016, "time": 42278.72305083275, "episode/length": 162.0, "episode/score": 0.17421440131874988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17421440131874988}
{"step": 836088, "time": 42283.30490851402, "episode/length": 50.0, "episode/score": 0.05962797501706518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05962797501706518}
{"step": 836704, "time": 42308.01189136505, "episode/length": 313.0, "episode/score": 0.3475621583465909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3475621583465909}
{"step": 836744, "time": 42310.83822178841, "episode/length": 157.0, "episode/score": 0.1647624400084169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1647624400084169}
{"step": 836864, "time": 42317.16311144829, "episode/length": 289.0, "episode/score": 0.32212931134381506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32212931134381506}
{"step": 836936, "time": 42321.03788495064, "episode/length": 186.0, "episode/score": 0.2076743265015466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2076743265015466}
{"step": 837104, "time": 42329.16659760475, "episode/length": 173.0, "episode/score": 0.198542745449231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.198542745449231}
{"step": 837264, "time": 42336.73359274864, "episode/length": 204.0, "episode/score": 0.23812499566702172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23812499566702172}
{"step": 837728, "time": 42355.64750146866, "episode/length": 213.0, "episode/score": 0.2531249952153303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2531249952153303}
{"step": 837944, "time": 42364.907680273056, "episode/length": 154.0, "episode/score": 0.1728222854580963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1728222854580963}
{"step": 838120, "time": 42372.97178387642, "episode/length": 156.0, "episode/score": 0.16872772113856627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16872772113856627}
{"step": 838160, "time": 42376.3837223053, "episode/length": 176.0, "episode/score": 0.20036755630280823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20036755630280823}
{"step": 838168, "time": 42378.06089735031, "episode/length": 259.0, "episode/score": 0.29966254050668795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29966254050668795}
{"step": 838272, "time": 42383.716304540634, "episode/length": 40.0, "episode/score": 0.0495833323802799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0495833323802799}
{"step": 838632, "time": 42398.734261751175, "episode/length": 211.0, "episode/score": 0.2330744742139359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2330744742139359}
{"step": 838680, "time": 42402.53870868683, "episode/length": 196.0, "episode/score": 0.21732628250174457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21732628250174457}
{"step": 838944, "time": 42414.20435881615, "episode/length": 151.0, "episode/score": 0.16390853143821005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16390853143821005}
{"step": 839224, "time": 42425.88025403023, "episode/length": 137.0, "episode/score": 0.16311507610589615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16311507610589615}
{"step": 839568, "time": 42440.654999256134, "episode/length": 174.0, "episode/score": 0.19541098194531514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19541098194531514}
{"step": 839856, "time": 42453.026894807816, "episode/length": 197.0, "episode/score": 0.21745646784620476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21745646784620476}
{"step": 840008, "time": 42475.23855638504, "eval_episode/length": 45.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9130434782608695}
{"step": 840008, "time": 42482.60784864426, "eval_episode/length": 153.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 840008, "time": 42484.63247489929, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 840008, "time": 42487.11791777611, "eval_episode/length": 172.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 840008, "time": 42489.119854450226, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 840008, "time": 42491.863337278366, "eval_episode/length": 188.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 840008, "time": 42494.48061776161, "eval_episode/length": 161.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 840008, "time": 42497.03056001663, "eval_episode/length": 227.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 840024, "time": 42497.63130402565, "episode/length": 167.0, "episode/score": 0.18857620117705665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18857620117705665}
{"step": 840288, "time": 42509.32382631302, "episode/length": 206.0, "episode/score": 0.2185071095955209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2185071095955209}
{"step": 840320, "time": 42512.09492468834, "episode/length": 381.0, "episode/score": 0.43801001225801883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43801001225801883}
{"step": 840552, "time": 42522.036964416504, "episode/length": 298.0, "episode/score": 0.33566028001951054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33566028001951054}
{"step": 840704, "time": 42529.50839519501, "episode/length": 141.0, "episode/score": 0.17253204777443898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17253204777443898}
{"step": 840776, "time": 42533.59600996971, "episode/length": 193.0, "episode/score": 0.18965759829006856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18965759829006856}
{"step": 840777, "time": 42536.240152835846, "train_stats/sum_log_reward": 0.6887850232213457, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.205607476635514, "train_stats/max_log_achievement_collect_sapling": 0.6074766355140186, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.308411214953271, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.29906542056074764, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.018691588785046728, "train_stats/max_log_achievement_wake_up": 0.17757009345794392, "train_stats/mean_log_entropy": 2.1438683873025055, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.1622392578125, "train/action_min": 0.0, "train/action_std": 4.893919723510742, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007880548227578402, "train/actor_opt_grad_steps": 51830.0, "train/actor_opt_loss": -9.727512087345124, "train/adv_mag": 0.17547086274623871, "train/adv_max": 0.1251879466176033, "train/adv_mean": 5.823052289633779e-05, "train/adv_min": -0.17507369375228882, "train/adv_std": 0.012873856127262115, "train/cont_avg": 0.9949375, "train/cont_loss_mean": 0.00016539155538043815, "train/cont_loss_std": 0.00469629296655512, "train/cont_neg_acc": 0.9972571434974671, "train/cont_neg_loss": 0.010515548872281216, "train/cont_pos_acc": 0.9999528675079346, "train/cont_pos_loss": 0.00010697798498426891, "train/cont_pred": 0.9949152154922485, "train/cont_rate": 0.9949375, "train/dyn_loss_mean": 10.958656616210938, "train/dyn_loss_std": 8.320600273132325, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12034696182608605, "train/extr_critic_critic_opt_grad_steps": 51830.0, "train/extr_critic_critic_opt_loss": 12165.4611484375, "train/extr_critic_mag": 0.2808136987686157, "train/extr_critic_max": 0.2808136987686157, "train/extr_critic_mean": 0.2309382998943329, "train/extr_critic_min": 0.002096782684326172, "train/extr_critic_std": 0.055239083021879194, "train/extr_return_normed_mag": 0.1920300931930542, "train/extr_return_normed_max": 0.1920300931930542, "train/extr_return_normed_mean": 0.1423964129090309, "train/extr_return_normed_min": -0.08759163331985474, "train/extr_return_normed_std": 0.05666813312470913, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2806303470134735, "train/extr_return_raw_max": 0.2806303470134735, "train/extr_return_raw_mean": 0.23099667179584504, "train/extr_return_raw_min": 0.0010086212158203125, "train/extr_return_raw_std": 0.05666813285648823, "train/extr_reward_mag": 0.0013463993072509765, "train/extr_reward_max": 0.0013463993072509765, "train/extr_reward_mean": 0.0010956598687916993, "train/extr_reward_min": 1.2032508850097657e-05, "train/extr_reward_std": 0.00023388078215066344, "train/image_loss_mean": 4.517756813049316, "train/image_loss_std": 9.033876674652099, "train/model_loss_mean": 11.133514930725097, "train/model_loss_std": 12.491565628051758, "train/model_opt_grad_norm": 49.49871043236025, "train/model_opt_grad_steps": 51780.744, "train/model_opt_loss": 14639.2964609375, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 1300.0, "train/policy_entropy_mag": 2.766717945098877, "train/policy_entropy_max": 2.766717945098877, "train/policy_entropy_mean": 2.1283878202438355, "train/policy_entropy_min": 0.07946533763408661, "train/policy_entropy_std": 0.6230676255226135, "train/policy_logprob_mag": 7.438051345825195, "train/policy_logprob_max": -0.009468561954796314, "train/policy_logprob_mean": -2.128846304893494, "train/policy_logprob_min": -7.438051345825195, "train/policy_logprob_std": 1.1278763179779052, "train/policy_randomness_mag": 0.9765300207138061, "train/policy_randomness_max": 0.9765300207138061, "train/policy_randomness_mean": 0.7512274894714356, "train/policy_randomness_min": 0.028047776982188223, "train/policy_randomness_std": 0.21991553020477295, "train/post_ent_mag": 57.38348532104492, "train/post_ent_max": 57.38348532104492, "train/post_ent_mean": 40.91952676391602, "train/post_ent_min": 19.47738638305664, "train/post_ent_std": 7.0064495735168455, "train/prior_ent_mag": 66.53219226074219, "train/prior_ent_max": 66.53219226074219, "train/prior_ent_mean": 51.97057113647461, "train/prior_ent_min": 30.634713348388672, "train/prior_ent_std": 5.402472078323364, "train/rep_loss_mean": 10.958656616210938, "train/rep_loss_std": 8.320600273132325, "train/reward_avg": 0.0010709096621721982, "train/reward_loss_mean": 0.04039877459406853, "train/reward_loss_std": 0.010886434346437454, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013065853118896485, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040398774355649945, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010714651681482791, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.34999997820705175, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 0.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.065704267006367e-05, "report/cont_loss_std": 0.0015303962863981724, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.009043828584253788, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.6627749321050942e-05, "report/cont_pred": 0.9951342344284058, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.77517318725586, "report/dyn_loss_std": 8.202493667602539, "report/image_loss_mean": 5.572713851928711, "report/image_loss_std": 12.107443809509277, "report/model_loss_mean": 12.67950439453125, "report/model_loss_std": 15.352875709533691, "report/post_ent_mag": 58.32347106933594, "report/post_ent_max": 58.32347106933594, "report/post_ent_mean": 41.084129333496094, "report/post_ent_min": 20.158008575439453, "report/post_ent_std": 6.99599027633667, "report/prior_ent_mag": 66.6853256225586, "report/prior_ent_max": 66.6853256225586, "report/prior_ent_mean": 53.09698486328125, "report/prior_ent_min": 36.370086669921875, "report/prior_ent_std": 5.197610855102539, "report/rep_loss_mean": 11.77517318725586, "report/rep_loss_std": 8.202493667602539, "report/reward_avg": 0.0011065219296142459, "report/reward_loss_mean": 0.04161592945456505, "report/reward_loss_std": 0.0092985350638628, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012508630752563477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04161592945456505, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010796078713610768, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.4351690879266243e-05, "eval/cont_loss_std": 0.00039228922105394304, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00017147944890893996, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4044200725038536e-05, "eval/cont_pred": 0.9980332851409912, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.123291015625, "eval/dyn_loss_std": 10.03286075592041, "eval/image_loss_mean": 10.220199584960938, "eval/image_loss_std": 14.30632495880127, "eval/model_loss_mean": 20.290435791015625, "eval/model_loss_std": 18.226665496826172, "eval/post_ent_mag": 61.375885009765625, "eval/post_ent_max": 61.375885009765625, "eval/post_ent_mean": 39.457618713378906, "eval/post_ent_min": 19.696950912475586, "eval/post_ent_std": 7.17525053024292, "eval/prior_ent_mag": 66.6853256225586, "eval/prior_ent_max": 66.6853256225586, "eval/prior_ent_mean": 52.77671813964844, "eval/prior_ent_min": 35.608131408691406, "eval/prior_ent_std": 5.554913520812988, "eval/rep_loss_mean": 16.123291015625, "eval/rep_loss_std": 10.03286075592041, "eval/reward_avg": 0.0087890625, "eval/reward_loss_mean": 0.39624708890914917, "eval/reward_loss_std": 2.7371976375579834, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1931610405445099, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.989177703857422, "eval/reward_pred": 0.0010438223835080862, "eval/reward_rate": 0.009765625, "replay/size": 840273.0, "replay/inserts": 20016.0, "replay/samples": 20016.0, "replay/insert_wait_avg": 1.405890611149996e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.238043240029558e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2166606179445075e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.996691942215, "timer/env.step_count": 2502.0, "timer/env.step_total": 242.68874979019165, "timer/env.step_frac": 0.24268955262125555, "timer/env.step_avg": 0.09699790159480082, "timer/env.step_min": 0.02325439453125, "timer/env.step_max": 3.5232346057891846, "timer/replay._sample_count": 20016.0, "timer/replay._sample_total": 9.714606523513794, "timer/replay._sample_frac": 0.009714638660099842, "timer/replay._sample_avg": 0.0004853420525336628, "timer/replay._sample_min": 0.000362396240234375, "timer/replay._sample_max": 0.010472536087036133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2929.0, "timer/agent.policy_total": 48.80591940879822, "timer/agent.policy_frac": 0.04880608086213397, "timer/agent.policy_avg": 0.016662997408261597, "timer/agent.policy_min": 0.009737253189086914, "timer/agent.policy_max": 0.11868739128112793, "timer/dataset_train_count": 1251.0, "timer/dataset_train_total": 0.14255356788635254, "timer/dataset_train_frac": 0.00014255403946335257, "timer/dataset_train_avg": 0.00011395169295471826, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0010700225830078125, "timer/agent.train_count": 1251.0, "timer/agent.train_total": 562.0856642723083, "timer/agent.train_frac": 0.562087523690317, "timer/agent.train_avg": 0.4493090841505263, "timer/agent.train_min": 0.43621325492858887, "timer/agent.train_max": 1.0053136348724365, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47648119926452637, "timer/agent.report_frac": 0.0004764827754970813, "timer/agent.report_avg": 0.23824059963226318, "timer/agent.report_min": 0.2320849895477295, "timer/agent.report_max": 0.24439620971679688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9802420975826033e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.015806265428793}
{"step": 840800, "time": 42537.06513476372, "episode/length": 231.0, "episode/score": 0.25737508553720545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25737508553720545}
{"step": 840872, "time": 42541.269570827484, "episode/length": 72.0, "episode/score": 0.08081883927115996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08081883927115996}
{"step": 841224, "time": 42555.99479985237, "episode/length": 43.0, "episode/score": 0.0512499992037192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0512499992037192}
{"step": 841224, "time": 42556.00231003761, "episode/length": 149.0, "episode/score": 0.16202880290984467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16202880290984467}
{"step": 841528, "time": 42570.64390587807, "episode/length": 208.0, "episode/score": 0.2141267760489427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2141267760489427}
{"step": 841904, "time": 42586.57063007355, "episode/length": 197.0, "episode/score": 0.2153708687364997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2153708687364997}
{"step": 841936, "time": 42589.409039735794, "episode/length": 153.0, "episode/score": 0.16374565547266684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16374565547266684}
{"step": 842152, "time": 42598.893104076385, "episode/length": 171.0, "episode/score": 0.18709320885682246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18709320885682246}
{"step": 842264, "time": 42604.59887909889, "episode/length": 213.0, "episode/score": 0.21562472931327648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21562472931327648}
{"step": 842696, "time": 42622.23426961899, "episode/length": 183.0, "episode/score": 0.1934655118802766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1934655118802766}
{"step": 842736, "time": 42625.468420267105, "episode/length": 241.0, "episode/score": 0.25466117732321436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25466117732321436}
{"step": 842840, "time": 42630.5755007267, "episode/length": 112.0, "episode/score": 0.12022822099243058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12022822099243058}
{"step": 842912, "time": 42634.93779373169, "episode/length": 210.0, "episode/score": 0.2442915961273684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2442915961273684}
{"step": 843032, "time": 42640.78555440903, "episode/length": 140.0, "episode/score": 0.16895250590823707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16895250590823707}
{"step": 843424, "time": 42657.17674612999, "episode/length": 158.0, "episode/score": 0.17696570586304006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17696570586304006}
{"step": 843888, "time": 42677.65502524376, "episode/length": 202.0, "episode/score": 0.2226609430672397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2226609430672397}
{"step": 844072, "time": 42685.93128705025, "episode/length": 317.0, "episode/score": 0.3531373642344988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3531373642344988}
{"step": 844248, "time": 42694.07060956955, "episode/length": 166.0, "episode/score": 0.18121277810860192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18121277810860192}
{"step": 844344, "time": 42699.24146437645, "episode/length": 200.0, "episode/score": 0.20468463055294706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20468463055294706}
{"step": 844496, "time": 42706.918576955795, "episode/length": 133.0, "episode/score": 0.13645039501716383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13645039501716383}
{"step": 844560, "time": 42710.862228393555, "episode/length": 190.0, "episode/score": 0.22337801237154054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22337801237154054}
{"step": 844576, "time": 42712.97807908058, "episode/length": 234.0, "episode/score": 0.2417712007445516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2417712007445516}
{"step": 845352, "time": 42743.71782517433, "episode/length": 159.0, "episode/score": 0.1846872409223579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846872409223579}
{"step": 845480, "time": 42749.989100933075, "episode/length": 198.0, "episode/score": 0.22088125001755543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22088125001755543}
{"step": 845856, "time": 42766.12019991875, "episode/length": 376.0, "episode/score": 0.4522235360054765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4522235360054765}
{"step": 845896, "time": 42769.47039794922, "episode/length": 193.0, "episode/score": 0.21371288695809199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21371288695809199}
{"step": 845920, "time": 42772.61820483208, "episode/length": 208.0, "episode/score": 0.23228841184754856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23228841184754856}
{"step": 846040, "time": 42778.43409729004, "episode/length": 192.0, "episode/score": 0.22876796936179744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22876796936179744}
{"step": 846136, "time": 42783.48298954964, "episode/length": 196.0, "episode/score": 0.1996614270246937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1996614270246937}
{"step": 846624, "time": 42803.55011367798, "episode/length": 142.0, "episode/score": 0.159953920476255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159953920476255}
{"step": 846864, "time": 42814.1542327404, "episode/length": 188.0, "episode/score": 0.21071725836372934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21071725836372934}
{"step": 847056, "time": 42822.793268442154, "episode/length": 149.0, "episode/score": 0.1650442343961913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1650442343961913}
{"step": 847104, "time": 42826.42068529129, "episode/length": 150.0, "episode/score": 0.1762499969190685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1762499969190685}
{"step": 847256, "time": 42833.46726632118, "episode/length": 151.0, "episode/score": 0.1750624968262855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1750624968262855}
{"step": 847624, "time": 42849.48866343498, "episode/length": 212.0, "episode/score": 0.23642926356114913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23642926356114913}
{"step": 847848, "time": 42859.52426600456, "episode/length": 213.0, "episode/score": 0.25569614874984836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25569614874984836}
{"step": 848000, "time": 42867.280879974365, "episode/length": 427.0, "episode/score": 0.431614042907313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.431614042907313}
{"step": 848408, "time": 42884.48382759094, "episode/length": 222.0, "episode/score": 0.25620855671877507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25620855671877507}
{"step": 848408, "time": 42884.49164772034, "episode/length": 192.0, "episode/score": 0.21084385200083489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21084385200083489}
{"step": 848480, "time": 42890.64939785004, "episode/length": 177.0, "episode/score": 0.19231111271801637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19231111271801637}
{"step": 848632, "time": 42897.64526510239, "episode/length": 190.0, "episode/score": 0.20874283680677763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20874283680677763}
{"step": 848752, "time": 42903.872269153595, "episode/length": 140.0, "episode/score": 0.16057295550854178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16057295550854178}
{"step": 848808, "time": 42907.95385503769, "episode/length": 193.0, "episode/score": 0.2019965859799413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2019965859799413}
{"step": 849208, "time": 42924.91520833969, "episode/length": 150.0, "episode/score": 0.158527452222188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.158527452222188}
{"step": 849488, "time": 42937.20395207405, "episode/length": 204.0, "episode/score": 0.2240819966827985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2240819966827985}
{"step": 849648, "time": 42944.75771069527, "episode/length": 154.0, "episode/score": 0.17587430847925134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17587430847925134}
{"step": 849752, "time": 42949.98908853531, "episode/length": 117.0, "episode/score": 0.13636147612851346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13636147612851346}
{"step": 850096, "time": 42984.11574292183, "eval_episode/length": 149.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 850096, "time": 42986.580510139465, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 850096, "time": 42988.96653199196, "eval_episode/length": 189.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 850096, "time": 42990.76208090782, "eval_episode/length": 192.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 850096, "time": 42992.49080514908, "eval_episode/length": 196.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 850096, "time": 42994.34118413925, "eval_episode/length": 200.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 850096, "time": 42996.58787512779, "eval_episode/length": 216.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 850096, "time": 43001.6516418457, "eval_episode/length": 152.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 850104, "time": 43001.73160982132, "episode/length": 168.0, "episode/score": 0.17901880181671004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17901880181671004}
{"step": 850192, "time": 43006.95138812065, "episode/length": 194.0, "episode/score": 0.22058605819256627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22058605819256627}
{"step": 850256, "time": 43010.959384679794, "episode/length": 230.0, "episode/score": 0.2695896771547268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2695896771547268}
{"step": 850560, "time": 43026.02463412285, "episode/length": 168.0, "episode/score": 0.1809452876514115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809452876514115}
{"step": 850776, "time": 43035.41332769394, "episode/length": 160.0, "episode/score": 0.16399863375772838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16399863375772838}
{"step": 850960, "time": 43043.96642041206, "episode/length": 150.0, "episode/score": 0.17645614497996576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17645614497996576}
{"step": 851184, "time": 43054.22481369972, "episode/length": 191.0, "episode/score": 0.2127745329926256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2127745329926256}
{"step": 851496, "time": 43067.72892475128, "episode/length": 173.0, "episode/score": 0.18001046470999427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18001046470999427}
{"step": 851504, "time": 43069.78056192398, "episode/length": 163.0, "episode/score": 0.17295828663736756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17295828663736756}
{"step": 851792, "time": 43082.04681253433, "episode/length": 413.0, "episode/score": 0.45706371137748647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45706371137748647}
{"step": 851912, "time": 43087.79736018181, "episode/length": 168.0, "episode/score": 0.17895560065881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17895560065881}
{"step": 852224, "time": 43103.30003499985, "episode/length": 157.0, "episode/score": 0.1777338030133251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1777338030133251}
{"step": 852432, "time": 43112.764152765274, "episode/length": 155.0, "episode/score": 0.16860434501359123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16860434501359123}
{"step": 852848, "time": 43129.959263563156, "episode/length": 168.0, "episode/score": 0.18446929175297555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18446929175297555}
{"step": 853152, "time": 43142.992851257324, "episode/length": 154.0, "episode/score": 0.16769924415166315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16769924415166315}
{"step": 853192, "time": 43145.78352975845, "episode/length": 366.0, "episode/score": 0.4026839941761864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4026839941761864}
{"step": 853192, "time": 43145.791759967804, "episode/length": 174.0, "episode/score": 0.16526619579781254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16526619579781254}
{"step": 853208, "time": 43149.67474889755, "episode/length": 303.0, "episode/score": 0.3277251017316303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3277251017316303}
{"step": 853656, "time": 43168.22015833855, "episode/length": 152.0, "episode/score": 0.1665679603447643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1665679603447643}
{"step": 853856, "time": 43177.567942619324, "episode/length": 203.0, "episode/score": 0.221948263440936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.221948263440936}
{"step": 854512, "time": 43204.202646017075, "episode/length": 375.0, "episode/score": 0.41534551011864096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41534551011864096}
{"step": 854600, "time": 43209.4368891716, "episode/length": 180.0, "episode/score": 0.2021451365071698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2021451365071698}
{"step": 854608, "time": 43211.96965956688, "episode/length": 176.0, "episode/score": 0.19042993105813366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19042993105813366}
{"step": 854792, "time": 43220.8165037632, "episode/length": 197.0, "episode/score": 0.23001699260112218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23001699260112218}
{"step": 855136, "time": 43235.55999350548, "episode/length": 184.0, "episode/score": 0.21309698892491724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21309698892491724}
{"step": 855368, "time": 43245.86685824394, "episode/length": 188.0, "episode/score": 0.20959867326382664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20959867326382664}
{"step": 855568, "time": 43255.212847709656, "episode/length": 339.0, "episode/score": 0.37306759518651234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.37306759518651234}
{"step": 855800, "time": 43265.39332461357, "episode/length": 149.0, "episode/score": 0.15766009038270568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15766009038270568}
{"step": 856080, "time": 43277.799068927765, "episode/length": 160.0, "episode/score": 0.1750369857854821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1750369857854821}
{"step": 856448, "time": 43293.24361419678, "episode/length": 241.0, "episode/score": 0.2709616832962638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2709616832962638}
{"step": 856456, "time": 43294.86700320244, "episode/length": 230.0, "episode/score": 0.25363676131928514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25363676131928514}
{"step": 856504, "time": 43298.32471227646, "episode/length": 413.0, "episode/score": 0.4343949449603315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4343949449603315}
{"step": 856544, "time": 43301.64657187462, "episode/length": 175.0, "episode/score": 0.18897619032304647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18897619032304647}
{"step": 857344, "time": 43333.50907087326, "episode/length": 192.0, "episode/score": 0.2089796065047267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2089796065047267}
{"step": 857416, "time": 43337.67537689209, "episode/length": 166.0, "episode/score": 0.18716714883248642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18716714883248642}
{"step": 857464, "time": 43341.03192639351, "episode/length": 236.0, "episode/score": 0.2538384647050407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2538384647050407}
{"step": 857752, "time": 43353.58860683441, "episode/length": 162.0, "episode/score": 0.17985440724169166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17985440724169166}
{"step": 857760, "time": 43355.7309217453, "episode/length": 162.0, "episode/score": 0.1801895466987844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1801895466987844}
{"step": 857992, "time": 43366.01933217049, "episode/length": 180.0, "episode/score": 0.1942819128926203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942819128926203}
{"step": 858416, "time": 43384.206652879715, "episode/length": 238.0, "episode/score": 0.2755385326454416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2755385326454416}
{"step": 858432, "time": 43386.43831348419, "episode/length": 382.0, "episode/score": 0.4348481492979772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4348481492979772}
{"step": 858584, "time": 43393.5990459919, "episode/length": 154.0, "episode/score": 0.17528082297303627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17528082297303627}
{"step": 858744, "time": 43401.36812567711, "episode/length": 165.0, "episode/score": 0.1752054694106846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1752054694106846}
{"step": 858928, "time": 43410.10221147537, "episode/length": 182.0, "episode/score": 0.18319181397964712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18319181397964712}
{"step": 859240, "time": 43423.29081559181, "episode/length": 185.0, "episode/score": 0.20302677261406643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20302677261406643}
{"step": 859352, "time": 43429.317150592804, "episode/length": 169.0, "episode/score": 0.17321919419191545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17321919419191545}
{"step": 859656, "time": 43442.46947264671, "episode/length": 152.0, "episode/score": 0.17066170007001347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17066170007001347}
{"step": 859992, "time": 43456.73977804184, "episode/length": 155.0, "episode/score": 0.14799950391716266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14799950391716266}
{"step": 860080, "time": 43481.39889240265, "eval_episode/length": 155.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 860080, "time": 43484.12614989281, "eval_episode/length": 176.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 860080, "time": 43486.11230278015, "eval_episode/length": 183.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 860080, "time": 43488.1904168129, "eval_episode/length": 195.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 860080, "time": 43490.218948841095, "eval_episode/length": 208.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 860080, "time": 43491.95380783081, "eval_episode/length": 210.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995260663507109}
{"step": 860080, "time": 43495.07087278366, "eval_episode/length": 247.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9758064516129032}
{"step": 860080, "time": 43497.2962334156, "eval_episode/length": 263.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9810606060606061}
{"step": 860264, "time": 43505.6007475853, "episode/length": 166.0, "episode/score": 0.16787292311164492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16787292311164492}
{"step": 860624, "time": 43521.03970456123, "episode/length": 158.0, "episode/score": 0.17642442771921196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17642442771921196}
{"step": 860664, "time": 43523.915884017944, "episode/length": 259.0, "episode/score": 0.2925805533259336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2925805533259336}
{"step": 860816, "time": 43531.35693073273, "episode/length": 196.0, "episode/score": 0.1926019538377659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1926019538377659}
{"step": 860889, "time": 43536.51868033409, "train_stats/sum_log_reward": 1.0393939096518237, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.474747474747475, "train_stats/max_log_achievement_collect_sapling": 0.6666666666666666, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.4444444444444444, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.010101010101010102, "train_stats/max_log_achievement_make_wood_pickaxe": 0.010101010101010102, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.32323232323232326, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.050505050505050504, "train_stats/max_log_achievement_wake_up": 0.20202020202020202, "train_stats/mean_log_entropy": 2.155757369417133, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.35310986328125, "train/action_min": 0.0, "train/action_std": 4.990071235656738, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00780014374665916, "train/actor_opt_grad_steps": 53080.0, "train/actor_opt_loss": -13.363053798675537, "train/adv_mag": 0.17352206915616988, "train/adv_max": 0.11923788225650787, "train/adv_mean": -0.00014516630556317978, "train/adv_min": -0.17255577832460403, "train/adv_std": 0.01301927499473095, "train/cont_avg": 0.994640625, "train/cont_loss_mean": 0.00023466864710167102, "train/cont_loss_std": 0.007333365710072939, "train/cont_neg_acc": 0.9905817979766477, "train/cont_neg_loss": 0.03523351991352977, "train/cont_pos_acc": 0.9999842820167542, "train/cont_pos_loss": 5.8756610091563746e-05, "train/cont_pred": 0.9946718015670777, "train/cont_rate": 0.994640625, "train/dyn_loss_mean": 10.858782485961914, "train/dyn_loss_std": 8.360619621276856, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12319305825233459, "train/extr_critic_critic_opt_grad_steps": 53080.0, "train/extr_critic_critic_opt_loss": 11967.0174375, "train/extr_critic_mag": 0.2810159950256348, "train/extr_critic_max": 0.2810159950256348, "train/extr_critic_mean": 0.2269036467075348, "train/extr_critic_min": 0.0018265047073364258, "train/extr_critic_std": 0.05894252437353134, "train/extr_return_normed_mag": 0.20177972662448884, "train/extr_return_normed_max": 0.20177972662448884, "train/extr_return_normed_mean": 0.14770618802309035, "train/extr_return_normed_min": -0.07805500113964081, "train/extr_return_normed_std": 0.060480538815259936, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2808319392204285, "train/extr_return_raw_max": 0.2808319392204285, "train/extr_return_raw_mean": 0.22675840604305267, "train/extr_return_raw_min": 0.0009972114562988282, "train/extr_return_raw_std": 0.060480538934469225, "train/extr_reward_mag": 0.0013514127731323242, "train/extr_reward_max": 0.0013514127731323242, "train/extr_reward_mean": 0.0010963166933506726, "train/extr_reward_min": 1.1930465698242187e-05, "train/extr_reward_std": 0.00023423875297885389, "train/image_loss_mean": 4.627936071395874, "train/image_loss_std": 9.502075805664063, "train/model_loss_mean": 11.183774589538574, "train/model_loss_std": 13.001382423400878, "train/model_opt_grad_norm": 48.58134509277344, "train/model_opt_grad_steps": 53029.576, "train/model_opt_loss": 14309.376125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1280.0, "train/policy_entropy_mag": 2.7649355850219726, "train/policy_entropy_max": 2.7649355850219726, "train/policy_entropy_mean": 2.139135585784912, "train/policy_entropy_min": 0.07949512755870819, "train/policy_entropy_std": 0.6121261048316956, "train/policy_logprob_mag": 7.438106880187989, "train/policy_logprob_max": -0.009472692750394345, "train/policy_logprob_mean": -2.139266428947449, "train/policy_logprob_min": -7.438106880187989, "train/policy_logprob_std": 1.1212110137939453, "train/policy_randomness_mag": 0.9759009265899659, "train/policy_randomness_max": 0.9759009265899659, "train/policy_randomness_mean": 0.7550209946632386, "train/policy_randomness_min": 0.028058291494846344, "train/policy_randomness_std": 0.21605365192890166, "train/post_ent_mag": 57.060849365234375, "train/post_ent_max": 57.060849365234375, "train/post_ent_mean": 40.919485076904294, "train/post_ent_min": 19.924516372680664, "train/post_ent_std": 6.981891479492187, "train/prior_ent_mag": 66.53172033691406, "train/prior_ent_max": 66.53172033691406, "train/prior_ent_mean": 51.85546887207031, "train/prior_ent_min": 30.35308512878418, "train/prior_ent_std": 5.512586814880371, "train/rep_loss_mean": 10.858782485961914, "train/rep_loss_std": 8.360619621276856, "train/reward_avg": 0.0010690771881490945, "train/reward_loss_mean": 0.04033444094657898, "train/reward_loss_std": 0.010933724865317344, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001303767204284668, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0403344409763813, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001070280366577208, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.4124999810010195, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.4375, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.691293386509642e-05, "report/cont_loss_std": 0.0005756259197369218, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.489660442341119e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.6571182135958225e-05, "report/cont_pred": 0.9941049814224243, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.072826385498047, "report/dyn_loss_std": 9.14536190032959, "report/image_loss_mean": 6.4360880851745605, "report/image_loss_std": 13.348382949829102, "report/model_loss_mean": 13.120594024658203, "report/model_loss_std": 17.323612213134766, "report/post_ent_mag": 61.29803466796875, "report/post_ent_max": 61.29803466796875, "report/post_ent_mean": 41.66429901123047, "report/post_ent_min": 17.58388900756836, "report/post_ent_std": 7.599928379058838, "report/prior_ent_mag": 66.12982940673828, "report/prior_ent_max": 66.12982940673828, "report/prior_ent_mean": 52.62726974487305, "report/prior_ent_min": 30.570249557495117, "report/prior_ent_std": 5.401114463806152, "report/rep_loss_mean": 11.072826385498047, "report/rep_loss_std": 9.14536190032959, "report/reward_avg": 0.0010818231385201216, "report/reward_loss_mean": 0.04077373445034027, "report/reward_loss_std": 0.010515756905078888, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013728141784667969, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04077373445034027, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010933929588645697, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0022707018069922924, "eval/cont_loss_std": 0.07230625301599503, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.38643133640289307, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.493559340015054e-06, "eval/cont_pred": 0.9950178861618042, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.545440673828125, "eval/dyn_loss_std": 10.141266822814941, "eval/image_loss_mean": 11.089743614196777, "eval/image_loss_std": 15.898478507995605, "eval/model_loss_mean": 22.120389938354492, "eval/model_loss_std": 19.973731994628906, "eval/post_ent_mag": 55.77043151855469, "eval/post_ent_max": 55.77043151855469, "eval/post_ent_mean": 38.66539764404297, "eval/post_ent_min": 19.74405288696289, "eval/post_ent_std": 6.837419509887695, "eval/prior_ent_mag": 66.12982940673828, "eval/prior_ent_max": 66.12982940673828, "eval/prior_ent_mean": 53.313018798828125, "eval/prior_ent_min": 31.698970794677734, "eval/prior_ent_std": 5.008635997772217, "eval/rep_loss_mean": 17.545440673828125, "eval/rep_loss_std": 10.141266822814941, "eval/reward_avg": -0.0003906250058207661, "eval/reward_loss_mean": 0.5011112689971924, "eval/reward_loss_std": 3.096285581588745, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4010883569717407, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.88577651977539, "eval/reward_pred": 0.0010758449789136648, "eval/reward_rate": 0.0048828125, "replay/size": 860385.0, "replay/inserts": 20112.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.4175781676384222e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.177738295913975e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.170595276713161e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2662250995636, "timer/env.step_count": 2514.0, "timer/env.step_total": 228.0228385925293, "timer/env.step_frac": 0.22796214934662276, "timer/env.step_avg": 0.0907012086684683, "timer/env.step_min": 0.023363828659057617, "timer/env.step_max": 3.3219244480133057, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 9.86330246925354, "timer/replay._sample_frac": 0.009860677309455066, "timer/replay._sample_avg": 0.0004904187783041737, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.025254011154174805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3081.0, "timer/agent.policy_total": 50.5548357963562, "timer/agent.policy_frac": 0.050541380412323846, "timer/agent.policy_avg": 0.016408580264964688, "timer/agent.policy_min": 0.009677886962890625, "timer/agent.policy_max": 0.11438512802124023, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.14358949661254883, "timer/dataset_train_frac": 0.00014355127965882917, "timer/dataset_train_avg": 0.00011423189865755675, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.00024127960205078125, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 568.8783662319183, "timer/agent.train_frac": 0.5687269568412088, "timer/agent.train_avg": 0.4525683104470313, "timer/agent.train_min": 0.437666654586792, "timer/agent.train_max": 2.6389927864074707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725492000579834, "timer/agent.report_frac": 0.00047242342908353945, "timer/agent.report_avg": 0.2362746000289917, "timer/agent.report_min": 0.22916746139526367, "timer/agent.report_max": 0.24338173866271973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1939586480018713e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 20.106374942212508}
{"step": 861224, "time": 43549.1364467144, "episode/length": 195.0, "episode/score": 0.2153460023455409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2153460023455409}
{"step": 861272, "time": 43552.881794929504, "episode/length": 438.0, "episode/score": 0.4524513572300748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4524513572300748}
{"step": 861368, "time": 43558.19085216522, "episode/length": 368.0, "episode/score": 0.4073453957403217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4073453957403217}
{"step": 861392, "time": 43560.88606309891, "episode/length": 174.0, "episode/score": 0.1820058842808976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1820058842808976}
{"step": 862040, "time": 43586.867688417435, "episode/length": 221.0, "episode/score": 0.2517308835517724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2517308835517724}
{"step": 862120, "time": 43591.51714515686, "episode/length": 186.0, "episode/score": 0.21292672036224758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21292672036224758}
{"step": 862280, "time": 43599.08807206154, "episode/length": 182.0, "episode/score": 0.2098800792655311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2098800792655311}
{"step": 862304, "time": 43601.83212184906, "episode/length": 204.0, "episode/score": 0.20788385991909308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20788385991909308}
{"step": 862608, "time": 43614.969989061356, "episode/length": 172.0, "episode/score": 0.20108250333214528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20108250333214528}
{"step": 862712, "time": 43620.381188869476, "episode/length": 179.0, "episode/score": 0.19620164720890898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19620164720890898}
{"step": 862720, "time": 43622.93765449524, "episode/length": 168.0, "episode/score": 0.17497376902110773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17497376902110773}
{"step": 863032, "time": 43636.72809267044, "episode/length": 204.0, "episode/score": 0.22808058157534106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22808058157534106}
{"step": 863552, "time": 43658.412606954575, "episode/length": 158.0, "episode/score": 0.16550047530517986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16550047530517986}
{"step": 863664, "time": 43664.36768198013, "episode/length": 192.0, "episode/score": 0.21681082868599333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21681082868599333}
{"step": 863936, "time": 43676.4928715229, "episode/length": 236.0, "episode/score": 0.25739885685561603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25739885685561603}
{"step": 864056, "time": 43682.962212085724, "episode/length": 48.0, "episode/score": 0.058977271532057784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058977271532057784}
{"step": 864096, "time": 43686.86281251907, "episode/length": 223.0, "episode/score": 0.2401514017037698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2401514017037698}
{"step": 864120, "time": 43689.51839828491, "episode/length": 175.0, "episode/score": 0.20006824414122093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20006824414122093}
{"step": 864224, "time": 43695.93327331543, "episode/length": 187.0, "episode/score": 0.20695167339499676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20695167339499676}
{"step": 864424, "time": 43704.951486349106, "episode/length": 226.0, "episode/score": 0.2660029710677918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2660029710677918}
{"step": 864704, "time": 43717.422728061676, "episode/length": 143.0, "episode/score": 0.1564080943908266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1564080943908266}
{"step": 865456, "time": 43747.513637304306, "episode/length": 169.0, "episode/score": 0.17370516576693262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17370516576693262}
{"step": 865568, "time": 43753.355531454086, "episode/length": 188.0, "episode/score": 0.2075606897765283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2075606897765283}
{"step": 865576, "time": 43755.18369102478, "episode/length": 204.0, "episode/score": 0.23816051599942512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23816051599942512}
{"step": 865624, "time": 43758.473216056824, "episode/length": 187.0, "episode/score": 0.20655996840969237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20655996840969237}
{"step": 866016, "time": 43775.04430985451, "episode/length": 198.0, "episode/score": 0.1972335629166082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1972335629166082}
{"step": 866336, "time": 43788.67458176613, "episode/length": 412.0, "episode/score": 0.4251600477309694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4251600477309694}
{"step": 866560, "time": 43798.58824753761, "episode/length": 231.0, "episode/score": 0.25469170656697315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25469170656697315}
{"step": 866696, "time": 43805.10760593414, "episode/length": 154.0, "episode/score": 0.15596380854958625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15596380854958625}
{"step": 866984, "time": 43817.452674388885, "episode/length": 176.0, "episode/score": 0.18105317505387575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18105317505387575}
{"step": 867112, "time": 43824.01697802544, "episode/length": 185.0, "episode/score": 0.19813640098891483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19813640098891483}
{"step": 867496, "time": 43840.05633974075, "episode/length": 408.0, "episode/score": 0.4201364202181139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4201364202181139}
{"step": 867600, "time": 43845.814573049545, "episode/length": 197.0, "episode/score": 0.21164011495466184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21164011495466184}
{"step": 867976, "time": 43861.301573991776, "episode/length": 176.0, "episode/score": 0.20057243173641837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20057243173641837}
{"step": 868088, "time": 43867.09189724922, "episode/length": 218.0, "episode/score": 0.2270928840621309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2270928840621309}
{"step": 868224, "time": 43874.03957438469, "episode/length": 190.0, "episode/score": 0.19982857459626757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19982857459626757}
{"step": 868496, "time": 43887.369042634964, "episode/length": 172.0, "episode/score": 0.1692502278961001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1692502278961001}
{"step": 868616, "time": 43893.35531616211, "episode/length": 203.0, "episode/score": 0.20216614355695128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20216614355695128}
{"step": 868896, "time": 43905.87275195122, "episode/length": 414.0, "episode/score": 0.4311883535897323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4311883535897323}
{"step": 869320, "time": 43923.243621110916, "episode/length": 214.0, "episode/score": 0.25006107203807915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25006107203807915}
{"step": 869432, "time": 43929.02438521385, "episode/length": 150.0, "episode/score": 0.15517689304670057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15517689304670057}
{"step": 869560, "time": 43935.48436045647, "episode/length": 197.0, "episode/score": 0.2160900188919186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2160900188919186}
{"step": 869648, "time": 43940.67070746422, "episode/length": 194.0, "episode/score": 0.21213745658451444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21213745658451444}
{"step": 869944, "time": 43953.101034879684, "episode/length": 180.0, "episode/score": 0.20662011533067925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20662011533067925}
{"step": 870064, "time": 43978.81574559212, "eval_episode/length": 140.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 870064, "time": 43980.65195775032, "eval_episode/length": 148.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 870064, "time": 43982.1706328392, "eval_episode/length": 149.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 870064, "time": 43984.346193790436, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 870064, "time": 43986.45781469345, "eval_episode/length": 174.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 870064, "time": 43989.18534326553, "eval_episode/length": 197.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 870064, "time": 43991.467183828354, "eval_episode/length": 210.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.995260663507109}
{"step": 870064, "time": 43993.45432162285, "eval_episode/length": 221.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 870248, "time": 44000.22737264633, "episode/length": 168.0, "episode/score": 0.18623414394824067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18623414394824067}
{"step": 870424, "time": 44008.410992860794, "episode/length": 225.0, "episode/score": 0.23494957206776235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23494957206776235}
{"step": 870768, "time": 44022.9983727932, "episode/length": 408.0, "episode/score": 0.4050041268856148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4050041268856148}
{"step": 870808, "time": 44026.017870903015, "episode/length": 171.0, "episode/score": 0.19236346562684048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19236346562684048}
{"step": 870832, "time": 44028.74379491806, "episode/length": 188.0, "episode/score": 0.19511683280461511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19511683280461511}
{"step": 870952, "time": 44034.63830804825, "episode/length": 173.0, "episode/score": 0.19646098786552102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19646098786552102}
{"step": 871160, "time": 44043.97494101524, "episode/length": 151.0, "episode/score": 0.16701227529210882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16701227529210882}
{"step": 871208, "time": 44047.292593717575, "episode/length": 194.0, "episode/score": 0.22938325344830446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22938325344830446}
{"step": 871328, "time": 44053.65886235237, "episode/length": 134.0, "episode/score": 0.13938166843036015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13938166843036015}
{"step": 871744, "time": 44071.106684446335, "episode/length": 164.0, "episode/score": 0.187053511913291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187053511913291}
{"step": 872240, "time": 44091.36628460884, "episode/length": 175.0, "episode/score": 0.20989393534546252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20989393534546252}
{"step": 872288, "time": 44094.78037428856, "episode/length": 184.0, "episode/score": 0.21527380551560782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21527380551560782}
{"step": 872312, "time": 44096.98916244507, "episode/length": 169.0, "episode/score": 0.17656829733459745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17656829733459745}
{"step": 872584, "time": 44108.856399059296, "episode/length": 177.0, "episode/score": 0.1977638858370483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1977638858370483}
{"step": 872680, "time": 44114.10718154907, "episode/length": 168.0, "episode/score": 0.19088663886941504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19088663886941504}
{"step": 872680, "time": 44114.12075471878, "episode/length": 238.0, "episode/score": 0.24755467771319672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24755467771319672}
{"step": 873032, "time": 44130.54492545128, "episode/length": 227.0, "episode/score": 0.2635416619013995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2635416619013995}
{"step": 873120, "time": 44135.58925127983, "episode/length": 171.0, "episode/score": 0.19255385339056375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19255385339056375}
{"step": 873664, "time": 44157.70664548874, "episode/length": 171.0, "episode/score": 0.18702678254339844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18702678254339844}
{"step": 873680, "time": 44159.91994524002, "episode/length": 179.0, "episode/score": 0.19498942502832506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19498942502832506}
{"step": 873784, "time": 44165.24645805359, "episode/length": 183.0, "episode/score": 0.19962070450856118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19962070450856118}
{"step": 873800, "time": 44167.42677664757, "episode/length": 151.0, "episode/score": 0.17539179940649774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17539179940649774}
{"step": 874064, "time": 44179.25486969948, "episode/length": 172.0, "episode/score": 0.19271238845249172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19271238845249172}
{"step": 874400, "time": 44193.95762968063, "episode/length": 91.0, "episode/score": 0.09554620486596832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09554620486596832}
{"step": 874592, "time": 44203.30171775818, "episode/length": 238.0, "episode/score": 0.2755828323715832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2755828323715832}
{"step": 874768, "time": 44211.641157865524, "episode/length": 205.0, "episode/score": 0.224343538073299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.224343538073299}
{"step": 875032, "time": 44222.78749918938, "episode/length": 168.0, "episode/score": 0.1881006780968164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1881006780968164}
{"step": 875128, "time": 44227.884222984314, "episode/length": 167.0, "episode/score": 0.18608946062158793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18608946062158793}
{"step": 875392, "time": 44239.806653261185, "episode/length": 198.0, "episode/score": 0.2197880917301518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2197880917301518}
{"step": 875464, "time": 44244.41031336784, "episode/length": 174.0, "episode/score": 0.19533338506516884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19533338506516884}
{"step": 876000, "time": 44267.039472818375, "episode/length": 370.0, "episode/score": 0.4255661644638167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4255661644638167}
{"step": 876176, "time": 44275.318064928055, "episode/length": 221.0, "episode/score": 0.23785493959803716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23785493959803716}
{"step": 876312, "time": 44281.77189350128, "episode/length": 159.0, "episode/score": 0.17566462742979638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17566462742979638}
{"step": 876376, "time": 44285.775806427, "episode/length": 155.0, "episode/score": 0.17328457656913088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17328457656913088}
{"step": 876600, "time": 44297.53865289688, "episode/length": 150.0, "episode/score": 0.17454166372772306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17454166372772306}
{"step": 876968, "time": 44312.86869478226, "episode/length": 187.0, "episode/score": 0.20917279473360395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20917279473360395}
{"step": 877176, "time": 44322.10185146332, "episode/length": 300.0, "episode/score": 0.3171911496719986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3171911496719986}
{"step": 877296, "time": 44328.526082754135, "episode/length": 337.0, "episode/score": 0.38209608281977125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38209608281977125}
{"step": 877704, "time": 44345.11106920242, "episode/length": 165.0, "episode/score": 0.17105552906286903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17105552906286903}
{"step": 877872, "time": 44353.28159737587, "episode/length": 211.0, "episode/score": 0.2239999785706459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2239999785706459}
{"step": 877984, "time": 44359.039761304855, "episode/length": 208.0, "episode/score": 0.2274133274495398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2274133274495398}
{"step": 877992, "time": 44360.70980167389, "episode/length": 248.0, "episode/score": 0.2599295072031964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2599295072031964}
{"step": 878120, "time": 44367.06577897072, "episode/length": 189.0, "episode/score": 0.20803426378188306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20803426378188306}
{"step": 878536, "time": 44384.275257110596, "episode/length": 169.0, "episode/score": 0.19702324187892373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19702324187892373}
{"step": 878840, "time": 44397.11115193367, "episode/length": 192.0, "episode/score": 0.19819875399298326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19819875399298326}
{"step": 879256, "time": 44414.2473552227, "episode/length": 193.0, "episode/score": 0.19873697172806715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19873697172806715}
{"step": 879288, "time": 44417.01924276352, "episode/length": 176.0, "episode/score": 0.19405681746320624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19405681746320624}
{"step": 879400, "time": 44422.75093913078, "episode/length": 175.0, "episode/score": 0.1842666305892635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1842666305892635}
{"step": 879448, "time": 44426.115688085556, "episode/length": 165.0, "episode/score": 0.18140085105369508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18140085105369508}
{"step": 879952, "time": 44446.83363056183, "episode/length": 245.0, "episode/score": 0.2765060656638525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2765060656638525}
{"step": 880048, "time": 44477.887214660645, "eval_episode/length": 154.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 880048, "time": 44480.411846637726, "eval_episode/length": 163.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 880048, "time": 44483.19623160362, "eval_episode/length": 178.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.994413407821229}
{"step": 880048, "time": 44485.75741124153, "eval_episode/length": 190.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 880048, "time": 44487.935267448425, "eval_episode/length": 197.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 880048, "time": 44489.78929686546, "eval_episode/length": 202.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 880048, "time": 44491.92728948593, "eval_episode/length": 215.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 880048, "time": 44494.51614022255, "eval_episode/length": 239.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 880184, "time": 44499.38916301727, "episode/length": 205.0, "episode/score": 0.23395276430164813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23395276430164813}
{"step": 880416, "time": 44510.334438085556, "episode/length": 430.0, "episode/score": 0.4425929762537635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4425929762537635}
{"step": 880616, "time": 44519.24106860161, "episode/length": 221.0, "episode/score": 0.24252587643422885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24252587643422885}
{"step": 880808, "time": 44527.92517709732, "episode/length": 169.0, "episode/score": 0.1808019069403599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1808019069403599}
{"step": 880816, "time": 44530.0979578495, "episode/length": 176.0, "episode/score": 0.1958803899724444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1958803899724444}
{"step": 880929, "time": 44536.52904701233, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.024380154079861, "train/action_min": 0.0, "train/action_std": 4.795459664057171, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007641087689008268, "train/actor_opt_grad_steps": 54335.0, "train/actor_opt_loss": -8.947006850192944, "train/adv_mag": 0.1738838159020931, "train/adv_max": 0.1216609680226871, "train/adv_mean": 5.9294154941392024e-05, "train/adv_min": -0.1729956085956286, "train/adv_std": 0.012724896630508796, "train/cont_avg": 0.9946056547619048, "train/cont_loss_mean": 0.00011635820602083955, "train/cont_loss_std": 0.003447089590303048, "train/cont_neg_acc": 0.9992063494901808, "train/cont_neg_loss": 0.005537874022968662, "train/cont_pos_acc": 0.9999688281899407, "train/cont_pos_loss": 7.902114399818915e-05, "train/cont_pred": 0.9945888273299687, "train/cont_rate": 0.9946056547619048, "train/dyn_loss_mean": 10.934041469816178, "train/dyn_loss_std": 8.374236984858436, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1292086128322851, "train/extr_critic_critic_opt_grad_steps": 54335.0, "train/extr_critic_critic_opt_loss": 11975.288860987102, "train/extr_critic_mag": 0.28148185639154344, "train/extr_critic_max": 0.28148185639154344, "train/extr_critic_mean": 0.22729549202181043, "train/extr_critic_min": 0.0016667275201706659, "train/extr_critic_std": 0.05953981712578781, "train/extr_return_normed_mag": 0.20833052103481595, "train/extr_return_normed_max": 0.20833052103481595, "train/extr_return_normed_mean": 0.1544931378984262, "train/extr_return_normed_min": -0.07185206461756949, "train/extr_return_normed_std": 0.060952215115465815, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2811922135334166, "train/extr_return_raw_max": 0.2811922135334166, "train/extr_return_raw_mean": 0.22735483258489578, "train/extr_return_raw_min": 0.0010096279401627798, "train/extr_return_raw_std": 0.060952215115465815, "train/extr_reward_mag": 0.0013557114298381502, "train/extr_reward_max": 0.0013557114298381502, "train/extr_reward_mean": 0.0010985341994831012, "train/extr_reward_min": 1.12529784914047e-05, "train/extr_reward_std": 0.0002350563284828298, "train/image_loss_mean": 4.525623132312108, "train/image_loss_std": 9.423880849565778, "train/model_loss_mean": 11.126482509431385, "train/model_loss_std": 12.909495664021325, "train/model_opt_grad_norm": 49.96732415093316, "train/model_opt_grad_steps": 54283.56349206349, "train/model_opt_loss": 16598.84349423363, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1488.095238095238, "train/policy_entropy_mag": 2.7658510794715276, "train/policy_entropy_max": 2.7658510794715276, "train/policy_entropy_mean": 2.0878821923619224, "train/policy_entropy_min": 0.07943457707999245, "train/policy_entropy_std": 0.6390487369563844, "train/policy_logprob_mag": 7.438177188237508, "train/policy_logprob_max": -0.009464407191863136, "train/policy_logprob_mean": -2.08738084444924, "train/policy_logprob_min": -7.438177188237508, "train/policy_logprob_std": 1.1613822929442874, "train/policy_randomness_mag": 0.9762240553659106, "train/policy_randomness_max": 0.9762240553659106, "train/policy_randomness_mean": 0.7369307847250075, "train/policy_randomness_min": 0.02803691974767144, "train/policy_randomness_std": 0.22555616143203916, "train/post_ent_mag": 57.10442191835434, "train/post_ent_max": 57.10442191835434, "train/post_ent_mean": 40.77664002918062, "train/post_ent_min": 19.728471786256822, "train/post_ent_std": 6.935173874809628, "train/prior_ent_mag": 66.59797759283157, "train/prior_ent_max": 66.59797759283157, "train/prior_ent_mean": 51.800319278050985, "train/prior_ent_min": 30.482520814925905, "train/prior_ent_std": 5.463082235956949, "train/rep_loss_mean": 10.934041469816178, "train/rep_loss_std": 8.374236984858436, "train/reward_avg": 0.0010688674565966403, "train/reward_loss_mean": 0.040318126065863505, "train/reward_loss_std": 0.01104534278431582, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001309367399367075, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04031812630238987, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010685145823536293, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.0292929030126996, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.292929292929293, "train_stats/max_log_achievement_collect_sapling": 0.5656565656565656, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.3838383838383838, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.010101010101010102, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.010101010101010102, "train_stats/max_log_achievement_place_plant": 0.35353535353535354, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.04040404040404041, "train_stats/max_log_achievement_wake_up": 0.26262626262626265, "train_stats/mean_log_entropy": 2.1149844220190337, "eval_stats/sum_log_reward": 1.2874999679625034, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.654841738258256e-07, "report/cont_loss_std": 8.094995791907422e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.815569551894441e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.3280824734683847e-07, "report/cont_pred": 0.9931644797325134, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.662595748901367, "report/dyn_loss_std": 9.36722183227539, "report/image_loss_mean": 5.272871971130371, "report/image_loss_std": 13.843096733093262, "report/model_loss_mean": 12.31122875213623, "report/model_loss_std": 17.653564453125, "report/post_ent_mag": 61.60633087158203, "report/post_ent_max": 61.60633087158203, "report/post_ent_mean": 40.45363998413086, "report/post_ent_min": 19.99087905883789, "report/post_ent_std": 7.248941898345947, "report/prior_ent_mag": 66.57249450683594, "report/prior_ent_max": 66.57249450683594, "report/prior_ent_mean": 51.67768859863281, "report/prior_ent_min": 30.66054916381836, "report/prior_ent_std": 5.915832042694092, "report/rep_loss_mean": 11.662595748901367, "report/rep_loss_std": 9.36722183227539, "report/reward_avg": 0.0010809216182678938, "report/reward_loss_mean": 0.04079914093017578, "report/reward_loss_std": 0.010111615993082523, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04079914093017578, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010980700608342886, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.1635201594326645e-05, "eval/cont_loss_std": 0.0009863360319286585, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006365721579641104, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.552878974413034e-07, "eval/cont_pred": 0.9951472878456116, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.492714881896973, "eval/dyn_loss_std": 10.483196258544922, "eval/image_loss_mean": 6.827886581420898, "eval/image_loss_std": 11.215267181396484, "eval/model_loss_mean": 16.17637062072754, "eval/model_loss_std": 16.216772079467773, "eval/post_ent_mag": 53.83406066894531, "eval/post_ent_max": 53.83406066894531, "eval/post_ent_mean": 39.342559814453125, "eval/post_ent_min": 18.357315063476562, "eval/post_ent_std": 6.783425807952881, "eval/prior_ent_mag": 66.57249450683594, "eval/prior_ent_max": 66.57249450683594, "eval/prior_ent_mean": 51.13188552856445, "eval/prior_ent_min": 32.833587646484375, "eval/prior_ent_std": 5.488397598266602, "eval/rep_loss_mean": 14.492714881896973, "eval/rep_loss_std": 10.483196258544922, "eval/reward_avg": -0.0013671875931322575, "eval/reward_loss_mean": 0.6528233885765076, "eval/reward_loss_std": 3.547142267227173, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012853145599365234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5530602335929871, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.98456382751465, "eval/reward_pred": 0.00108249275945127, "eval/reward_rate": 0.0048828125, "replay/size": 880425.0, "replay/inserts": 20040.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.4179481003812688e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.324060005882678e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2231208545304995e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9988586902618, "timer/env.step_count": 2505.0, "timer/env.step_total": 227.27156925201416, "timer/env.step_frac": 0.22727182863956538, "timer/env.step_avg": 0.09072717335409747, "timer/env.step_min": 0.02339768409729004, "timer/env.step_max": 3.216541051864624, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 9.861474752426147, "timer/replay._sample_frac": 0.00986148600743616, "timer/replay._sample_avg": 0.0004922860798934778, "timer/replay._sample_min": 0.00035190582275390625, "timer/replay._sample_max": 0.011220455169677734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2967.0, "timer/agent.policy_total": 50.20817852020264, "timer/agent.policy_frac": 0.05020823582335112, "timer/agent.policy_avg": 0.016922203747961793, "timer/agent.policy_min": 0.009660959243774414, "timer/agent.policy_max": 0.1985464096069336, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.14449429512023926, "timer/dataset_train_frac": 0.0001444944600331736, "timer/dataset_train_avg": 0.00011541077885003135, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0004487037658691406, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 565.7209465503693, "timer/agent.train_frac": 0.5657215922139316, "timer/agent.train_avg": 0.4518537911744163, "timer/agent.train_min": 0.43764638900756836, "timer/agent.train_max": 1.0760877132415771, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47843456268310547, "timer/agent.report_frac": 0.00047843510872575413, "timer/agent.report_avg": 0.23921728134155273, "timer/agent.report_min": 0.2324519157409668, "timer/agent.report_max": 0.24598264694213867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.0531158447265625e-05, "timer/dataset_eval_frac": 4.053120470592425e-08, "timer/dataset_eval_avg": 4.0531158447265625e-05, "timer/dataset_eval_min": 4.0531158447265625e-05, "timer/dataset_eval_max": 4.0531158447265625e-05, "fps": 20.039764733778178}
{"step": 881216, "time": 44547.831293821335, "episode/length": 244.0, "episode/score": 0.26216690865567216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26216690865567216}
{"step": 881312, "time": 44553.070667505264, "episode/length": 62.0, "episode/score": 0.06892300447361777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06892300447361777}
{"step": 881400, "time": 44557.72764658928, "episode/length": 263.0, "episode/score": 0.28377157950217224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28377157950217224}
{"step": 881584, "time": 44566.48381972313, "episode/length": 203.0, "episode/score": 0.2279624839538883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2279624839538883}
{"step": 881608, "time": 44568.81242609024, "episode/length": 177.0, "episode/score": 0.18758697528755874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18758697528755874}
{"step": 881992, "time": 44584.68434000015, "episode/length": 171.0, "episode/score": 0.19051890268292482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19051890268292482}
{"step": 882552, "time": 44607.29603457451, "episode/length": 154.0, "episode/score": 0.17701793482410721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17701793482410721}
{"step": 882712, "time": 44614.80991792679, "episode/length": 186.0, "episode/score": 0.19604124572651926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19604124572651926}
{"step": 882752, "time": 44618.216089725494, "episode/length": 168.0, "episode/score": 0.19693055195966735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19693055195966735}
{"step": 882784, "time": 44621.04281568527, "episode/length": 295.0, "episode/score": 0.32504502250958467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32504502250958467}
{"step": 882984, "time": 44629.879422187805, "episode/length": 270.0, "episode/score": 0.31171337807609234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31171337807609234}
{"step": 883216, "time": 44640.32094359398, "episode/length": 200.0, "episode/score": 0.21896396373631433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21896396373631433}
{"step": 883400, "time": 44648.499717235565, "episode/length": 226.0, "episode/score": 0.2514997260805103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2514997260805103}
{"step": 883512, "time": 44654.80156373978, "episode/length": 189.0, "episode/score": 0.21731074631679803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21731074631679803}
{"step": 883984, "time": 44674.11011147499, "episode/length": 178.0, "episode/score": 0.19775854380714009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19775854380714009}
{"step": 884248, "time": 44685.38200569153, "episode/length": 182.0, "episode/score": 0.18149943879325292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18149943879325292}
{"step": 884304, "time": 44689.296510219574, "episode/length": 198.0, "episode/score": 0.20623074044124223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20623074044124223}
{"step": 884376, "time": 44693.34444451332, "episode/length": 202.0, "episode/score": 0.2188225855679775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2188225855679775}
{"step": 884536, "time": 44700.84407830238, "episode/length": 164.0, "episode/score": 0.1687484291869623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1687484291869623}
{"step": 884640, "time": 44706.56937336922, "episode/length": 140.0, "episode/score": 0.1592973871556751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1592973871556751}
{"step": 884896, "time": 44719.50975561142, "episode/length": 238.0, "episode/score": 0.2651086870137078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2651086870137078}
{"step": 885264, "time": 44735.62566304207, "episode/length": 232.0, "episode/score": 0.26477999670169083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26477999670169083}
{"step": 885272, "time": 44737.341982126236, "episode/length": 160.0, "episode/score": 0.16759325577004347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16759325577004347}
{"step": 885520, "time": 44748.46519756317, "episode/length": 158.0, "episode/score": 0.16124836203380255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16124836203380255}
{"step": 885600, "time": 44752.969460487366, "episode/length": 161.0, "episode/score": 0.1680127271793026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1680127271793026}
{"step": 885832, "time": 44762.89324426651, "episode/length": 148.0, "episode/score": 0.17251545002909552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17251545002909552}
{"step": 885936, "time": 44769.24767756462, "episode/length": 174.0, "episode/score": 0.20209166811400792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20209166811400792}
{"step": 886128, "time": 44778.820296525955, "episode/length": 218.0, "episode/score": 0.22659030643990263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22659030643990263}
{"step": 886328, "time": 44788.3547604084, "episode/length": 178.0, "episode/score": 0.19421163292281562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19421163292281562}
{"step": 886824, "time": 44809.598457336426, "episode/length": 193.0, "episode/score": 0.23158739045538823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23158739045538823}
{"step": 886960, "time": 44816.408628702164, "episode/length": 179.0, "episode/score": 0.20149171838056645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20149171838056645}
{"step": 887072, "time": 44822.31471967697, "episode/length": 183.0, "episode/score": 0.18711180112768488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18711180112768488}
{"step": 887136, "time": 44826.87094950676, "episode/length": 233.0, "episode/score": 0.26060001613041095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26060001613041095}
{"step": 887704, "time": 44850.3621840477, "episode/length": 233.0, "episode/score": 0.26833853024072596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26833853024072596}
{"step": 887712, "time": 44852.48237657547, "episode/length": 197.0, "episode/score": 0.1984683624414174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1984683624414174}
{"step": 887808, "time": 44857.6569955349, "episode/length": 233.0, "episode/score": 0.23352385837642942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23352385837642942}
{"step": 888264, "time": 44876.08025074005, "episode/length": 241.0, "episode/score": 0.28596373517939355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28596373517939355}
{"step": 888344, "time": 44880.63243889809, "episode/length": 150.0, "episode/score": 0.1662789947768033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1662789947768033}
{"step": 888520, "time": 44888.81511306763, "episode/length": 211.0, "episode/score": 0.2319673782940299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2319673782940299}
{"step": 889000, "time": 44908.433552503586, "episode/length": 148.0, "episode/score": 0.1682036032752876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1682036032752876}
{"step": 889136, "time": 44915.33895134926, "episode/length": 177.0, "episode/score": 0.20267666287327302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20267666287327302}
{"step": 889160, "time": 44917.57903838158, "episode/length": 181.0, "episode/score": 0.209241560854025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.209241560854025}
{"step": 889264, "time": 44923.23625802994, "episode/length": 273.0, "episode/score": 0.3146232985491224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3146232985491224}
{"step": 889328, "time": 44927.2453224659, "episode/length": 295.0, "episode/score": 0.32670863546536566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32670863546536566}
{"step": 889520, "time": 44935.908239126205, "episode/length": 44.0, "episode/score": 0.05062499921768904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05062499921768904}
{"step": 889552, "time": 44939.226912498474, "episode/length": 160.0, "episode/score": 0.18566503628062492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18566503628062492}
{"step": 889904, "time": 44954.748219013214, "episode/length": 194.0, "episode/score": 0.19626626045555895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19626626045555895}
{"step": 890032, "time": 44985.86178135872, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 890032, "time": 44988.190979242325, "eval_episode/length": 156.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 890032, "time": 44990.74677681923, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 890032, "time": 44992.72068834305, "eval_episode/length": 168.0, "eval_episode/score": 1.1000000312924385, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 890032, "time": 44996.15564918518, "eval_episode/length": 195.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 890032, "time": 44998.50888180733, "eval_episode/length": 202.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 890032, "time": 45000.75494670868, "eval_episode/length": 204.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 890032, "time": 45007.43653988838, "eval_episode/length": 312.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.987220447284345}
{"step": 890048, "time": 45008.04172348976, "episode/length": 190.0, "episode/score": 0.21224025399260427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21224025399260427}
{"step": 890464, "time": 45025.49610853195, "episode/length": 149.0, "episode/score": 0.1371063701226376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1371063701226376}
{"step": 890568, "time": 45030.84042787552, "episode/length": 195.0, "episode/score": 0.1688322447689643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1688322447689643}
{"step": 890616, "time": 45034.2487077713, "episode/length": 184.0, "episode/score": 0.1859276590967056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1859276590967056}
{"step": 890808, "time": 45042.99787688255, "episode/length": 160.0, "episode/score": 0.16451360875998944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16451360875998944}
{"step": 891224, "time": 45060.28307342529, "episode/length": 146.0, "episode/score": 0.1596325970858743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1596325970858743}
{"step": 891280, "time": 45064.074021577835, "episode/length": 215.0, "episode/score": 0.23510771932342323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23510771932342323}
{"step": 891528, "time": 45074.69690608978, "episode/length": 202.0, "episode/score": 0.20738641818024917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20738641818024917}
{"step": 892072, "time": 45096.515813827515, "episode/length": 200.0, "episode/score": 0.2286882153384795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2286882153384795}
{"step": 892240, "time": 45104.85543179512, "episode/length": 178.0, "episode/score": 0.20305899120558024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20305899120558024}
{"step": 892312, "time": 45109.405500650406, "episode/length": 211.0, "episode/score": 0.22664556582367368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22664556582367368}
{"step": 892584, "time": 45121.62912130356, "episode/length": 406.0, "episode/score": 0.429570487397541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.429570487397541}
{"step": 892616, "time": 45124.32872200012, "episode/length": 173.0, "episode/score": 0.1782648346343194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1782648346343194}
{"step": 892912, "time": 45137.16463112831, "episode/length": 203.0, "episode/score": 0.22209929964537878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22209929964537878}
{"step": 892936, "time": 45139.96278810501, "episode/length": 295.0, "episode/score": 0.3495291388453552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3495291388453552}
{"step": 893080, "time": 45148.17451930046, "episode/length": 193.0, "episode/score": 0.22842559105993132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22842559105993132}
{"step": 893832, "time": 45177.814994096756, "episode/length": 198.0, "episode/score": 0.21869080022588605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21869080022588605}
{"step": 893872, "time": 45181.205169677734, "episode/length": 156.0, "episode/score": 0.18862499632814433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18862499632814433}
{"step": 893944, "time": 45185.2333240509, "episode/length": 169.0, "episode/score": 0.20453897435072577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20453897435072577}
{"step": 894192, "time": 45196.475135564804, "episode/length": 264.0, "episode/score": 0.31507196352322353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31507196352322353}
{"step": 894248, "time": 45199.93411755562, "episode/length": 163.0, "episode/score": 0.18377509082347387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18377509082347387}
{"step": 894400, "time": 45207.3754491806, "episode/length": 260.0, "episode/score": 0.29340092111669946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29340092111669946}
{"step": 894544, "time": 45214.46988749504, "episode/length": 203.0, "episode/score": 0.2165544024319388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2165544024319388}
{"step": 894968, "time": 45231.6582159996, "episode/length": 235.0, "episode/score": 0.25853006323450245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25853006323450245}
{"step": 895184, "time": 45241.5441865921, "episode/length": 168.0, "episode/score": 0.14526968853533617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14526968853533617}
{"step": 895240, "time": 45245.14600992203, "episode/length": 161.0, "episode/score": 0.15851951636432204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15851951636432204}
{"step": 895288, "time": 45248.62092781067, "episode/length": 176.0, "episode/score": 0.19942250065287226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19942250065287226}
{"step": 895352, "time": 45253.17742419243, "episode/length": 144.0, "episode/score": 0.1625551379929675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1625551379929675}
{"step": 895720, "time": 45269.19165301323, "episode/length": 45.0, "episode/score": 0.05666666547767818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05666666547767818}
{"step": 895952, "time": 45279.751628637314, "episode/length": 193.0, "episode/score": 0.20721365960525873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20721365960525873}
{"step": 896072, "time": 45285.755997896194, "episode/length": 190.0, "episode/score": 0.20642867193600978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20642867193600978}
{"step": 896296, "time": 45295.724642038345, "episode/length": 165.0, "episode/score": 0.19275808241218328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19275808241218328}
{"step": 896344, "time": 45298.99531555176, "episode/length": 261.0, "episode/score": 0.2807750548763579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2807750548763579}
{"step": 896536, "time": 45307.63855433464, "episode/length": 155.0, "episode/score": 0.16108484432152181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16108484432152181}
{"step": 896696, "time": 45315.28736281395, "episode/length": 188.0, "episode/score": 0.21276081889300258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21276081889300258}
{"step": 897056, "time": 45330.50626540184, "episode/length": 166.0, "episode/score": 0.1797323937953479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1797323937953479}
{"step": 897080, "time": 45332.816559791565, "episode/length": 229.0, "episode/score": 0.25711523232530453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25711523232530453}
{"step": 897128, "time": 45336.147211551666, "episode/length": 146.0, "episode/score": 0.16924915568961296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16924915568961296}
{"step": 897592, "time": 45355.07954573631, "episode/length": 189.0, "episode/score": 0.19132469252144801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19132469252144801}
{"step": 897624, "time": 45357.84208607674, "episode/length": 70.0, "episode/score": 0.07809857594838832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07809857594838832}
{"step": 897672, "time": 45361.30170249939, "episode/length": 141.0, "episode/score": 0.1535820686349325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1535820686349325}
{"step": 897864, "time": 45369.95991230011, "episode/length": 195.0, "episode/score": 0.20776484866655665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20776484866655665}
{"step": 898088, "time": 45380.10714793205, "episode/length": 173.0, "episode/score": 0.17960693130953587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17960693130953587}
{"step": 898424, "time": 45394.282210588455, "episode/length": 161.0, "episode/score": 0.16915153045647457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16915153045647457}
{"step": 898776, "time": 45409.00606560707, "episode/length": 211.0, "episode/score": 0.2150302192512754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2150302192512754}
{"step": 898936, "time": 45416.60558485985, "episode/length": 157.0, "episode/score": 0.18398421366873663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18398421366873663}
{"step": 899040, "time": 45422.323085308075, "episode/length": 176.0, "episode/score": 0.19653755341914803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19653755341914803}
{"step": 899056, "time": 45424.5618622303, "episode/length": 182.0, "episode/score": 0.2109723072635461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2109723072635461}
{"step": 899288, "time": 45434.75195670128, "episode/length": 177.0, "episode/score": 0.19413695174171153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19413695174171153}
{"step": 899800, "time": 45455.22047281265, "episode/length": 431.0, "episode/score": 0.4509167538190013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4509167538190013}
{"step": 899872, "time": 45459.647864341736, "episode/length": 180.0, "episode/score": 0.20084625392792077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20084625392792077}
{"step": 900016, "time": 45482.21491241455, "eval_episode/length": 56.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 900016, "time": 45489.02502346039, "eval_episode/length": 170.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 900016, "time": 45491.22491812706, "eval_episode/length": 174.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 900016, "time": 45493.50635123253, "eval_episode/length": 180.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.994475138121547}
{"step": 900016, "time": 45495.979068279266, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 900016, "time": 45497.99579811096, "eval_episode/length": 186.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 900016, "time": 45500.50602555275, "eval_episode/length": 207.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 900016, "time": 45502.16655039787, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 900032, "time": 45502.767083883286, "episode/length": 242.0, "episode/score": 0.2823728024523007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2823728024523007}
{"step": 900096, "time": 45506.775832891464, "episode/length": 164.0, "episode/score": 0.1792214131237415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1792214131237415}
{"step": 900192, "time": 45511.87055706978, "episode/length": 141.0, "episode/score": 0.14958721999664704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14958721999664704}
{"step": 900480, "time": 45524.598512887955, "episode/length": 192.0, "episode/score": 0.21294435590425564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21294435590425564}
{"step": 900584, "time": 45529.877825737, "episode/length": 161.0, "episode/score": 0.18993835506353207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18993835506353207}
{"step": 900697, "time": 45536.79709935188, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.0278345123539125, "train/action_min": 0.0, "train/action_std": 4.813381229958883, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008377742219140859, "train/actor_opt_grad_steps": 55580.0, "train/actor_opt_loss": -8.78763668245174, "train/adv_mag": 0.17931808846268227, "train/adv_max": 0.12329037069547467, "train/adv_mean": 0.00013809725533804346, "train/adv_min": -0.17891713976860046, "train/adv_std": 0.013748820753752942, "train/cont_avg": 0.9946566946138211, "train/cont_loss_mean": 7.381247905753269e-05, "train/cont_loss_std": 0.0021498112864423817, "train/cont_neg_acc": 0.9983739838367556, "train/cont_neg_loss": 0.007056576391037899, "train/cont_pos_acc": 0.9999839862187704, "train/cont_pos_loss": 4.0514208398139835e-05, "train/cont_pred": 0.9946522649710741, "train/cont_rate": 0.9946566946138211, "train/dyn_loss_mean": 10.989762786927262, "train/dyn_loss_std": 8.415831969036319, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12928957849498687, "train/extr_critic_critic_opt_grad_steps": 55580.0, "train/extr_critic_critic_opt_loss": 11962.316120426829, "train/extr_critic_mag": 0.2831196067779045, "train/extr_critic_max": 0.2831196067779045, "train/extr_critic_mean": 0.22871684749436572, "train/extr_critic_min": 0.00225169678044513, "train/extr_critic_std": 0.05910379433534979, "train/extr_return_normed_mag": 0.20605144716375243, "train/extr_return_normed_max": 0.20605144716375243, "train/extr_return_normed_mean": 0.1518052850312334, "train/extr_return_normed_min": -0.07604654315041333, "train/extr_return_normed_std": 0.06068298426585469, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2831011177078495, "train/extr_return_raw_max": 0.2831011177078495, "train/extr_return_raw_mean": 0.2288549607846795, "train/extr_return_raw_min": 0.001003126787945507, "train/extr_return_raw_std": 0.06068298496245369, "train/extr_reward_mag": 0.001339893030926464, "train/extr_reward_max": 0.001339893030926464, "train/extr_reward_mean": 0.0010999415270469294, "train/extr_reward_min": 1.137431074933308e-05, "train/extr_reward_std": 0.00023042468334703395, "train/image_loss_mean": 4.580069450828118, "train/image_loss_std": 9.55589673964958, "train/model_loss_mean": 11.214455589046324, "train/model_loss_std": 13.043428234937714, "train/model_opt_grad_norm": 46.65913859421645, "train/model_opt_grad_steps": 55527.422764227646, "train/model_opt_loss": 14803.761996633639, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1321.138211382114, "train/policy_entropy_mag": 2.7643946864740636, "train/policy_entropy_max": 2.7643946864740636, "train/policy_entropy_mean": 2.0593310090584485, "train/policy_entropy_min": 0.07942714118133716, "train/policy_entropy_std": 0.6581887047949845, "train/policy_logprob_mag": 7.438206358653743, "train/policy_logprob_max": -0.009463360926848116, "train/policy_logprob_mean": -2.058940115982924, "train/policy_logprob_min": -7.438206358653743, "train/policy_logprob_std": 1.1805539247466297, "train/policy_randomness_mag": 0.9757100135330262, "train/policy_randomness_max": 0.9757100135330262, "train/policy_randomness_mean": 0.7268534714613504, "train/policy_randomness_min": 0.02803429520529945, "train/policy_randomness_std": 0.23231172949317994, "train/post_ent_mag": 57.62578561054013, "train/post_ent_max": 57.62578561054013, "train/post_ent_mean": 40.93153772121522, "train/post_ent_min": 19.764925173627653, "train/post_ent_std": 7.050476837933548, "train/prior_ent_mag": 66.69361281976467, "train/prior_ent_max": 66.69361281976467, "train/prior_ent_mean": 51.98092815740322, "train/prior_ent_min": 30.65019930087454, "train/prior_ent_std": 5.528202591872796, "train/rep_loss_mean": 10.989762786927262, "train/rep_loss_std": 8.415831969036319, "train/reward_avg": 0.0010724736763754997, "train/reward_loss_mean": 0.040454690897367834, "train/reward_loss_std": 0.010786299313592717, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013048794211410896, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04045469053392488, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010709854891538862, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.9932038700117648, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.495145631067961, "train_stats/max_log_achievement_collect_sapling": 0.5242718446601942, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.3592233009708738, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.009708737864077669, "train_stats/max_log_achievement_eat_cow": 0.009708737864077669, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.2912621359223301, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.009708737864077669, "train_stats/max_log_achievement_wake_up": 0.21359223300970873, "train_stats/mean_log_entropy": 2.0948826317648286, "eval_stats/sum_log_reward": 0.7249999707564712, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_sapling": 0.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.182591290671553e-06, "report/cont_loss_std": 1.4005401681060903e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.996169683290645e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.003962766953919e-07, "report/cont_pred": 0.994140625, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.051307678222656, "report/dyn_loss_std": 8.471576690673828, "report/image_loss_mean": 4.267073631286621, "report/image_loss_std": 10.229471206665039, "report/model_loss_mean": 10.337234497070312, "report/model_loss_std": 13.404644012451172, "report/post_ent_mag": 56.7565803527832, "report/post_ent_max": 56.7565803527832, "report/post_ent_mean": 41.62525177001953, "report/post_ent_min": 15.713658332824707, "report/post_ent_std": 7.053715229034424, "report/prior_ent_mag": 66.4111328125, "report/prior_ent_max": 66.4111328125, "report/prior_ent_mean": 51.53948974609375, "report/prior_ent_min": 28.93573760986328, "report/prior_ent_std": 6.222537994384766, "report/rep_loss_mean": 10.051307678222656, "report/rep_loss_std": 8.471576690673828, "report/reward_avg": 0.0010416866280138493, "report/reward_loss_mean": 0.03937464952468872, "report/reward_loss_std": 0.011997959576547146, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012460947036743164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03937464952468872, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001038690679706633, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0006164286751300097, "eval/cont_loss_std": 0.01971084251999855, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.3154221455333754e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006175701273605227, "eval/cont_pred": 0.9975898861885071, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.767406463623047, "eval/dyn_loss_std": 10.092151641845703, "eval/image_loss_mean": 10.524017333984375, "eval/image_loss_std": 21.29814910888672, "eval/model_loss_mean": 21.051984786987305, "eval/model_loss_std": 25.151500701904297, "eval/post_ent_mag": 55.50886535644531, "eval/post_ent_max": 55.50886535644531, "eval/post_ent_mean": 38.566871643066406, "eval/post_ent_min": 18.18756866455078, "eval/post_ent_std": 6.387294292449951, "eval/prior_ent_mag": 66.4111328125, "eval/prior_ent_max": 66.4111328125, "eval/prior_ent_mean": 52.39433288574219, "eval/prior_ent_min": 28.047603607177734, "eval/prior_ent_std": 4.087492942810059, "eval/rep_loss_mean": 16.767406463623047, "eval/rep_loss_std": 10.092151641845703, "eval/reward_avg": 0.0006835935055278242, "eval/reward_loss_mean": 0.46690911054611206, "eval/reward_loss_std": 2.9881675243377686, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012557506561279297, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.3864886164665222, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.974136352539062, "eval/reward_pred": 0.001050079707056284, "eval/reward_rate": 0.00390625, "replay/size": 900193.0, "replay/inserts": 19768.0, "replay/samples": 19776.0, "replay/insert_wait_avg": 1.40274743327531e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.332353193783065e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2096102911097403e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2496201992035, "timer/env.step_count": 2471.0, "timer/env.step_total": 237.4108293056488, "timer/env.step_frac": 0.2373515815565794, "timer/env.step_avg": 0.09607884633980121, "timer/env.step_min": 0.022765159606933594, "timer/env.step_max": 2.8648288249969482, "timer/replay._sample_count": 19776.0, "timer/replay._sample_total": 9.707438945770264, "timer/replay._sample_frac": 0.009705016377648801, "timer/replay._sample_avg": 0.0004908696877917811, "timer/replay._sample_min": 0.0003788471221923828, "timer/replay._sample_max": 0.010898828506469727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2995.0, "timer/agent.policy_total": 49.29783535003662, "timer/agent.policy_frac": 0.049285532685549804, "timer/agent.policy_avg": 0.01646004519199887, "timer/agent.policy_min": 0.00945281982421875, "timer/agent.policy_max": 0.10788679122924805, "timer/dataset_train_count": 1236.0, "timer/dataset_train_total": 0.14275813102722168, "timer/dataset_train_frac": 0.00014272250460719082, "timer/dataset_train_avg": 0.00011550010600907903, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0010752677917480469, "timer/agent.train_count": 1236.0, "timer/agent.train_total": 555.9370152950287, "timer/agent.train_frac": 0.5557982768184523, "timer/agent.train_avg": 0.44978722920309766, "timer/agent.train_min": 0.43625855445861816, "timer/agent.train_max": 1.250701904296875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47819995880126953, "timer/agent.report_frac": 0.0004780806202216145, "timer/agent.report_avg": 0.23909997940063477, "timer/agent.report_min": 0.23205184936523438, "timer/agent.report_max": 0.24614810943603516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194011670131581e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 19.76279166147204}
{"step": 900816, "time": 45541.33406043053, "episode/length": 221.0, "episode/score": 0.25540838099823304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25540838099823304}
{"step": 901440, "time": 45567.58753943443, "episode/length": 195.0, "episode/score": 0.21495125442288554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21495125442288554}
{"step": 901480, "time": 45570.85443377495, "episode/length": 180.0, "episode/score": 0.20827283450216783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20827283450216783}
{"step": 901648, "time": 45578.8763897419, "episode/length": 181.0, "episode/score": 0.19443016743662156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19443016743662156}
{"step": 901712, "time": 45582.78739929199, "episode/length": 238.0, "episode/score": 0.26197921516723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26197921516723}
{"step": 901784, "time": 45586.91078901291, "episode/length": 210.0, "episode/score": 0.22755108400451718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22755108400451718}
{"step": 901864, "time": 45591.48486614227, "episode/length": 172.0, "episode/score": 0.1896819124076501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1896819124076501}
{"step": 902160, "time": 45604.30673241615, "episode/length": 167.0, "episode/score": 0.16723848272795294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16723848272795294}
{"step": 902800, "time": 45630.55931711197, "episode/length": 164.0, "episode/score": 0.18209190505422157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18209190505422157}
{"step": 903184, "time": 45647.377655506134, "episode/length": 164.0, "episode/score": 0.16455418065743288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16455418065743288}
{"step": 903200, "time": 45649.6345539093, "episode/length": 193.0, "episode/score": 0.1969151463090384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1969151463090384}
{"step": 903216, "time": 45651.75262546539, "episode/length": 178.0, "episode/score": 0.19539476177305914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19539476177305914}
{"step": 903720, "time": 45671.993532180786, "episode/length": 66.0, "episode/score": 0.08124999841675162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08124999841675162}
{"step": 903760, "time": 45675.9202671051, "episode/length": 199.0, "episode/score": 0.23666666238568723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23666666238568723}
{"step": 903808, "time": 45679.95082497597, "episode/length": 261.0, "episode/score": 0.28895635562639654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28895635562639654}
{"step": 903848, "time": 45682.79103064537, "episode/length": 407.0, "episode/score": 0.4145652599263485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4145652599263485}
{"step": 903896, "time": 45686.04454421997, "episode/length": 136.0, "episode/score": 0.1556590215113829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1556590215113829}
{"step": 904112, "time": 45695.96925878525, "episode/length": 43.0, "episode/score": 0.047666666097939014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047666666097939014}
{"step": 904656, "time": 45717.83637595177, "episode/length": 179.0, "episode/score": 0.18907740877693868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18907740877693868}
{"step": 904680, "time": 45719.99575090408, "episode/length": 404.0, "episode/score": 0.4089824113925715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4089824113925715}
{"step": 905056, "time": 45735.86432361603, "episode/length": 166.0, "episode/score": 0.1944134211553319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1944134211553319}
{"step": 905064, "time": 45737.50381064415, "episode/length": 232.0, "episode/score": 0.25381495723559055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25381495723559055}
{"step": 905448, "time": 45753.551981687546, "episode/length": 204.0, "episode/score": 0.20328782159049297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20328782159049297}
{"step": 905464, "time": 45755.66204762459, "episode/length": 168.0, "episode/score": 0.17866243033131468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17866243033131468}
{"step": 905616, "time": 45763.07540369034, "episode/length": 220.0, "episode/score": 0.25227380517026177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25227380517026177}
{"step": 906056, "time": 45780.8749563694, "episode/length": 171.0, "episode/score": 0.19326419091157732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19326419091157732}
{"step": 906128, "time": 45785.33156847954, "episode/length": 278.0, "episode/score": 0.32298956999511574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32298956999511574}
{"step": 906128, "time": 45785.339445114136, "episode/length": 183.0, "episode/score": 0.17698287253369926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17698287253369926}
{"step": 906304, "time": 45795.25732898712, "episode/length": 154.0, "episode/score": 0.14882311030305573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14882311030305573}
{"step": 907120, "time": 45827.411787986755, "episode/length": 257.0, "episode/score": 0.2981292406038847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2981292406038847}
{"step": 907128, "time": 45829.426166296005, "episode/length": 124.0, "episode/score": 0.136359282905687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.136359282905687}
{"step": 907144, "time": 45832.03926372528, "episode/length": 209.0, "episode/score": 0.206461252661029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.206461252661029}
{"step": 907416, "time": 45844.42217206955, "episode/length": 245.0, "episode/score": 0.24997635938416352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24997635938416352}
{"step": 907472, "time": 45848.377524614334, "episode/length": 231.0, "episode/score": 0.2714306672060047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2714306672060047}
{"step": 907576, "time": 45853.62339711189, "episode/length": 189.0, "episode/score": 0.22939393470005598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22939393470005598}
{"step": 907632, "time": 45857.573620557785, "episode/length": 187.0, "episode/score": 0.19786964318700484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19786964318700484}
{"step": 907896, "time": 45868.650961875916, "episode/length": 198.0, "episode/score": 0.22431480211525923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22431480211525923}
{"step": 908328, "time": 45886.37192583084, "episode/length": 149.0, "episode/score": 0.16285751688701566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16285751688701566}
{"step": 908368, "time": 45889.50192666054, "episode/length": 152.0, "episode/score": 0.1598440591878898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1598440591878898}
{"step": 908696, "time": 45903.19015622139, "episode/length": 159.0, "episode/score": 0.1697688867443503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1697688867443503}
{"step": 908768, "time": 45907.76269221306, "episode/length": 205.0, "episode/score": 0.2081144544899871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2081144544899871}
{"step": 908856, "time": 45912.4170293808, "episode/length": 172.0, "episode/score": 0.19969913613931567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19969913613931567}
{"step": 909040, "time": 45921.42017650604, "episode/length": 175.0, "episode/score": 0.19164566613653733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19164566613653733}
{"step": 909216, "time": 45930.17755842209, "episode/length": 204.0, "episode/score": 0.18973240677678405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18973240677678405}
{"step": 909384, "time": 45939.41074490547, "episode/length": 185.0, "episode/score": 0.2081356297385355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2081356297385355}
{"step": 909856, "time": 45958.99152517319, "episode/length": 190.0, "episode/score": 0.21938468752978224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21938468752978224}
{"step": 910000, "time": 45987.36927175522, "eval_episode/length": 143.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 910000, "time": 45989.850551366806, "eval_episode/length": 152.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 910000, "time": 45989.857774972916, "eval_episode/length": 152.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 910000, "time": 45994.42107248306, "eval_episode/length": 161.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 910000, "time": 45997.47972226143, "eval_episode/length": 180.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 910000, "time": 45999.76272749901, "eval_episode/length": 44.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 910000, "time": 46003.059099674225, "eval_episode/length": 219.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 910000, "time": 46007.00396871567, "eval_episode/length": 267.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9738805970149254}
{"step": 910144, "time": 46012.43993186951, "episode/length": 171.0, "episode/score": 0.17692538626397436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17692538626397436}
{"step": 910576, "time": 46030.282208919525, "episode/length": 214.0, "episode/score": 0.24427629185265687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24427629185265687}
{"step": 910608, "time": 46033.066025972366, "episode/length": 173.0, "episode/score": 0.2069940434739692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2069940434739692}
{"step": 910768, "time": 46040.86810207367, "episode/length": 258.0, "episode/score": 0.2791478118633677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2791478118633677}
{"step": 910920, "time": 46047.902017354965, "episode/length": 191.0, "episode/score": 0.16901448863336554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16901448863336554}
{"step": 910960, "time": 46051.23422431946, "episode/length": 323.0, "episode/score": 0.3483355947446398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3483355947446398}
{"step": 911136, "time": 46059.409651994705, "episode/length": 261.0, "episode/score": 0.26830765940212586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26830765940212586}
{"step": 911152, "time": 46061.570303201675, "episode/length": 161.0, "episode/score": 0.17306537520380516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17306537520380516}
{"step": 911696, "time": 46084.04454779625, "episode/length": 193.0, "episode/score": 0.19736323762299435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19736323762299435}
{"step": 912096, "time": 46101.217257499695, "episode/length": 185.0, "episode/score": 0.2073120441782521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2073120441782521}
{"step": 912504, "time": 46117.96586084366, "episode/length": 192.0, "episode/score": 0.21081345700713428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21081345700713428}
{"step": 912512, "time": 46120.11923503876, "episode/length": 241.0, "episode/score": 0.28014915710718924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28014915710718924}
{"step": 912704, "time": 46128.99579310417, "episode/length": 195.0, "episode/score": 0.20289922774099978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20289922774099978}
{"step": 912808, "time": 46134.21231627464, "episode/length": 206.0, "episode/score": 0.2099066093669535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2099066093669535}
{"step": 912816, "time": 46136.42297291756, "episode/length": 139.0, "episode/score": 0.1614933648152146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1614933648152146}
{"step": 913184, "time": 46151.81680774689, "episode/length": 301.0, "episode/score": 0.34145545883802697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34145545883802697}
{"step": 913192, "time": 46153.52660489082, "episode/length": 136.0, "episode/score": 0.15078693256782572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15078693256782572}
{"step": 913864, "time": 46180.19620656967, "episode/length": 83.0, "episode/score": 0.09777957274854998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09777957274854998}
{"step": 913960, "time": 46185.50208544731, "episode/length": 181.0, "episode/score": 0.20163654098087136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20163654098087136}
{"step": 913968, "time": 46187.53931975365, "episode/length": 181.0, "episode/score": 0.21081880615474802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21081880615474802}
{"step": 914096, "time": 46194.01301383972, "episode/length": 159.0, "episode/score": 0.19216666283318773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19216666283318773}
{"step": 914128, "time": 46197.307612895966, "episode/length": 164.0, "episode/score": 0.18317825420945155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18317825420945155}
{"step": 914272, "time": 46204.84460616112, "episode/length": 418.0, "episode/score": 0.4584145871576766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4584145871576766}
{"step": 914528, "time": 46216.15921711922, "episode/length": 227.0, "episode/score": 0.24835438934496779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24835438934496779}
{"step": 914544, "time": 46218.36734867096, "episode/length": 169.0, "episode/score": 0.18704296899340989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18704296899340989}
{"step": 915272, "time": 46246.93330621719, "episode/length": 142.0, "episode/score": 0.16410499389075994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16410499389075994}
{"step": 915432, "time": 46254.53137135506, "episode/length": 183.0, "episode/score": 0.21048233906913083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21048233906913083}
{"step": 915496, "time": 46258.56965494156, "episode/length": 174.0, "episode/score": 0.19715725201240275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19715725201240275}
{"step": 915608, "time": 46264.405997276306, "episode/length": 166.0, "episode/score": 0.17394882908865839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17394882908865839}
{"step": 915624, "time": 46267.02706480026, "episode/length": 206.0, "episode/score": 0.24065892811995582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24065892811995582}
{"step": 915864, "time": 46278.49544215202, "episode/length": 166.0, "episode/score": 0.19226401347714273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19226401347714273}
{"step": 915880, "time": 46281.14845538139, "episode/length": 251.0, "episode/score": 0.29578780577503494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29578780577503494}
{"step": 916144, "time": 46293.25002741814, "episode/length": 199.0, "episode/score": 0.22363115229745745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22363115229745745}
{"step": 916632, "time": 46312.762284994125, "episode/length": 169.0, "episode/score": 0.19090616896119172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19090616896119172}
{"step": 916784, "time": 46320.16466498375, "episode/length": 160.0, "episode/score": 0.18517427126653274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18517427126653274}
{"step": 916944, "time": 46327.623235702515, "episode/length": 188.0, "episode/score": 0.17446184831578648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17446184831578648}
{"step": 917000, "time": 46331.035039424896, "episode/length": 173.0, "episode/score": 0.18936307925741858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18936307925741858}
{"step": 917320, "time": 46344.72209095955, "episode/length": 181.0, "episode/score": 0.19726487940670268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19726487940670268}
{"step": 917504, "time": 46353.652636528015, "episode/length": 169.0, "episode/score": 0.18936029089945805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18936029089945805}
{"step": 917936, "time": 46373.24459218979, "episode/length": 288.0, "episode/score": 0.3291354181415045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3291354181415045}
{"step": 918088, "time": 46380.23639464378, "episode/length": 275.0, "episode/score": 0.3080413464981575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3080413464981575}
{"step": 918232, "time": 46387.26594161987, "episode/length": 160.0, "episode/score": 0.19500675274730384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19500675274730384}
{"step": 918288, "time": 46391.61925172806, "episode/length": 160.0, "episode/score": 0.1660850014782227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1660850014782227}
{"step": 918304, "time": 46394.21012830734, "episode/length": 189.0, "episode/score": 0.19411858969488094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19411858969488094}
{"step": 918480, "time": 46402.84603571892, "episode/length": 230.0, "episode/score": 0.2733818440660798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2733818440660798}
{"step": 918720, "time": 46413.41013336182, "episode/length": 174.0, "episode/score": 0.21042992536285965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21042992536285965}
{"step": 918856, "time": 46419.8782222271, "episode/length": 46.0, "episode/score": 0.051810605233185925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051810605233185925}
{"step": 919448, "time": 46443.6442129612, "episode/length": 151.0, "episode/score": 0.1663275135274489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1663275135274489}
{"step": 919568, "time": 46449.889199733734, "episode/length": 203.0, "episode/score": 0.2301721631010878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2301721631010878}
{"step": 919624, "time": 46453.2124505043, "episode/length": 191.0, "episode/score": 0.2215544668702023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2215544668702023}
{"step": 919632, "time": 46455.339003801346, "episode/length": 165.0, "episode/score": 0.1464487694888703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1464487694888703}
{"step": 919936, "time": 46468.41458415985, "episode/length": 205.0, "episode/score": 0.1786611964776057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1786611964776057}
{"step": 919976, "time": 46471.780595541, "episode/length": 156.0, "episode/score": 0.15905900775032933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15905900775032933}
{"step": 920088, "time": 46499.51532435417, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 920088, "time": 46499.522540569305, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 920088, "time": 46504.09717321396, "eval_episode/length": 170.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 920088, "time": 46506.67389464378, "eval_episode/length": 184.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 920088, "time": 46509.394473552704, "eval_episode/length": 200.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 920088, "time": 46511.60098576546, "eval_episode/length": 203.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 920088, "time": 46513.67448711395, "eval_episode/length": 204.0, "eval_episode/score": 1.1000000312924385, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 920088, "time": 46520.843842983246, "eval_episode/length": 321.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9906832298136646}
{"step": 920456, "time": 46534.613938093185, "episode/length": 199.0, "episode/score": 0.21206353967681935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21206353967681935}
{"step": 920457, "time": 46537.195138931274, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.003585323210685, "train/action_min": 0.0, "train/action_std": 4.855567551428272, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0084227453353965, "train/actor_opt_grad_steps": 56815.0, "train/actor_opt_loss": -9.392583682119186, "train/adv_mag": 0.18372012638757307, "train/adv_max": 0.12854397206777526, "train/adv_mean": 7.06946080578247e-05, "train/adv_min": -0.18327739780708666, "train/adv_std": 0.013598939561615548, "train/cont_avg": 0.9944477696572581, "train/cont_loss_mean": 9.346570257329929e-05, "train/cont_loss_std": 0.002931716779371637, "train/cont_neg_acc": 0.998991935483871, "train/cont_neg_loss": 0.004333220149657879, "train/cont_pos_acc": 0.999968302346045, "train/cont_pos_loss": 6.796041674672984e-05, "train/cont_pred": 0.9944296445577375, "train/cont_rate": 0.9944477696572581, "train/dyn_loss_mean": 10.883071022648965, "train/dyn_loss_std": 8.358669157951109, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12979381019249558, "train/extr_critic_critic_opt_grad_steps": 56815.0, "train/extr_critic_critic_opt_loss": 12048.003181703629, "train/extr_critic_mag": 0.2869809577541967, "train/extr_critic_max": 0.2869809577541967, "train/extr_critic_mean": 0.2308599809485097, "train/extr_critic_min": 0.0015748902674644224, "train/extr_critic_std": 0.06335437730435402, "train/extr_return_normed_mag": 0.21320411502834288, "train/extr_return_normed_max": 0.21320411502834288, "train/extr_return_normed_mean": 0.15711290545521245, "train/extr_return_normed_min": -0.07275606956212752, "train/extr_return_normed_std": 0.06498474600694833, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2870218292359383, "train/extr_return_raw_max": 0.2870218292359383, "train/extr_return_raw_mean": 0.23093062458980468, "train/extr_return_raw_min": 0.0010616452463211553, "train/extr_return_raw_std": 0.06498474567647904, "train/extr_reward_mag": 0.0013363236381161597, "train/extr_reward_max": 0.0013363236381161597, "train/extr_reward_mean": 0.0011063837361777382, "train/extr_reward_min": 1.2219913544193392e-05, "train/extr_reward_std": 0.00022878809461197364, "train/image_loss_mean": 4.422414552780889, "train/image_loss_std": 9.305798303696417, "train/model_loss_mean": 10.992884674379903, "train/model_loss_std": 12.784283061181345, "train/model_opt_grad_norm": 46.22985093824325, "train/model_opt_grad_steps": 56761.23387096774, "train/model_opt_loss": 13741.105870400706, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.7655587830851154, "train/policy_entropy_max": 2.7655587830851154, "train/policy_entropy_mean": 2.031327058230677, "train/policy_entropy_min": 0.07941245281648251, "train/policy_entropy_std": 0.6695052193057153, "train/policy_logprob_mag": 7.438224323334232, "train/policy_logprob_max": -0.009461345639260064, "train/policy_logprob_mean": -2.032223282321807, "train/policy_logprob_min": -7.438224323334232, "train/policy_logprob_std": 1.1990698749019253, "train/policy_randomness_mag": 0.9761208901482243, "train/policy_randomness_max": 0.9761208901482243, "train/policy_randomness_mean": 0.7169693093146047, "train/policy_randomness_min": 0.028029110898534135, "train/policy_randomness_std": 0.23630596252699052, "train/post_ent_mag": 57.43727259482107, "train/post_ent_max": 57.43727259482107, "train/post_ent_mean": 40.9667173201038, "train/post_ent_min": 19.557264243402788, "train/post_ent_std": 7.044147541446071, "train/prior_ent_mag": 66.60461401170299, "train/prior_ent_max": 66.60461401170299, "train/prior_ent_mean": 51.95708204084827, "train/prior_ent_min": 30.508824302304177, "train/prior_ent_std": 5.5022845652795604, "train/rep_loss_mean": 10.883071022648965, "train/rep_loss_std": 8.358669157951109, "train/reward_avg": 0.001074842932153373, "train/reward_loss_mean": 0.040534066667239514, "train/reward_loss_std": 0.010721876263438214, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00130237014062943, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040534066547068856, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010749960154850756, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.0399999564141036, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.12, "train_stats/max_log_achievement_collect_sapling": 0.53, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.43, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.32, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.04, "train_stats/max_log_achievement_wake_up": 0.27, "train_stats/mean_log_entropy": 2.110567992925644, "eval_stats/sum_log_reward": 0.5999999749474227, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 0.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1543968867044896e-05, "report/cont_loss_std": 0.00023959112877491862, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010925602400675416, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.172557393962052e-06, "report/cont_pred": 0.9941419959068298, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.325336456298828, "report/dyn_loss_std": 8.181234359741211, "report/image_loss_mean": 4.635491847991943, "report/image_loss_std": 10.264400482177734, "report/model_loss_mean": 11.471392631530762, "report/model_loss_std": 13.681963920593262, "report/post_ent_mag": 56.72780227661133, "report/post_ent_max": 56.72780227661133, "report/post_ent_mean": 40.8026008605957, "report/post_ent_min": 20.337345123291016, "report/post_ent_std": 7.19460916519165, "report/prior_ent_mag": 66.65615844726562, "report/prior_ent_max": 66.65615844726562, "report/prior_ent_mean": 52.06481170654297, "report/prior_ent_min": 26.745141983032227, "report/prior_ent_std": 5.450965881347656, "report/rep_loss_mean": 11.325336456298828, "report/rep_loss_std": 8.181234359741211, "report/reward_avg": 0.001078989589586854, "report/reward_loss_mean": 0.04068863019347191, "report/reward_loss_std": 0.010564908385276794, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012902021408081055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04068863391876221, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011009934823960066, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.887105989037082e-06, "eval/cont_loss_std": 0.0002623698383104056, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002323077293112874, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.157725801538618e-07, "eval/cont_pred": 0.9961020946502686, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.20645523071289, "eval/dyn_loss_std": 10.388264656066895, "eval/image_loss_mean": 9.373917579650879, "eval/image_loss_std": 16.775362014770508, "eval/model_loss_mean": 19.704952239990234, "eval/model_loss_std": 21.294334411621094, "eval/post_ent_mag": 56.83190155029297, "eval/post_ent_max": 56.83190155029297, "eval/post_ent_mean": 39.50811767578125, "eval/post_ent_min": 19.86958122253418, "eval/post_ent_std": 7.071231842041016, "eval/prior_ent_mag": 66.65615844726562, "eval/prior_ent_max": 66.65615844726562, "eval/prior_ent_mean": 52.36051559448242, "eval/prior_ent_min": 28.695697784423828, "eval/prior_ent_std": 5.471456050872803, "eval/rep_loss_mean": 16.20645523071289, "eval/rep_loss_std": 10.388264656066895, "eval/reward_avg": -0.0008789062267169356, "eval/reward_loss_mean": 0.6071504354476929, "eval/reward_loss_std": 3.3980307579040527, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5067455768585205, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 21.06966209411621, "eval/reward_pred": 0.0010779681615531445, "eval/reward_rate": 0.0048828125, "replay/size": 919953.0, "replay/inserts": 19760.0, "replay/samples": 19760.0, "replay/insert_wait_avg": 1.39369897031591e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.328482207016424e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 2.294071650100967e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3855173587799, "timer/env.step_count": 2470.0, "timer/env.step_total": 233.98859024047852, "timer/env.step_frac": 0.23389841834001726, "timer/env.step_avg": 0.0947322227694245, "timer/env.step_min": 0.023103713989257812, "timer/env.step_max": 3.3471338748931885, "timer/replay._sample_count": 19760.0, "timer/replay._sample_total": 9.767199277877808, "timer/replay._sample_frac": 0.009763435304086758, "timer/replay._sample_avg": 0.0004942914614310632, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.03359365463256836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3060.0, "timer/agent.policy_total": 51.433409452438354, "timer/agent.policy_frac": 0.05141358862154758, "timer/agent.policy_avg": 0.016808303742626915, "timer/agent.policy_min": 0.009931802749633789, "timer/agent.policy_max": 0.11785387992858887, "timer/dataset_train_count": 1235.0, "timer/dataset_train_total": 0.14025354385375977, "timer/dataset_train_frac": 0.0001401994945149321, "timer/dataset_train_avg": 0.00011356562255365163, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.00020313262939453125, "timer/agent.train_count": 1235.0, "timer/agent.train_total": 556.9449274539948, "timer/agent.train_frac": 0.5567302982598569, "timer/agent.train_avg": 0.45096755259432775, "timer/agent.train_min": 0.43648266792297363, "timer/agent.train_max": 1.1205322742462158, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47678446769714355, "timer/agent.report_frac": 0.0004766007298425821, "timer/agent.report_avg": 0.23839223384857178, "timer/agent.report_min": 0.23238730430603027, "timer/agent.report_max": 0.24439716339111328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931418410266214e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 19.752125957629012}
{"step": 920784, "time": 46549.5111284256, "episode/length": 409.0, "episode/score": 0.38596358712811707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38596358712811707}
{"step": 920960, "time": 46557.63374495506, "episode/length": 173.0, "episode/score": 0.17705644517445762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17705644517445762}
{"step": 921120, "time": 46565.06828761101, "episode/length": 185.0, "episode/score": 0.19631658910338956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19631658910338956}
{"step": 921208, "time": 46569.59197831154, "episode/length": 197.0, "episode/score": 0.20881576933152246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20881576933152246}
{"step": 921256, "time": 46572.9619269371, "episode/length": 164.0, "episode/score": 0.19283341761774864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19283341761774864}
{"step": 921320, "time": 46577.00295495987, "episode/length": 167.0, "episode/score": 0.18427035195418284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18427035195418284}
{"step": 921784, "time": 46596.0435628891, "episode/length": 165.0, "episode/score": 0.17488059152265123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17488059152265123}
{"step": 922208, "time": 46613.995877981186, "episode/length": 155.0, "episode/score": 0.161641766055709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.161641766055709}
{"step": 922312, "time": 46619.20889377594, "episode/length": 148.0, "episode/score": 0.17020720235086628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17020720235086628}
{"step": 922416, "time": 46625.01829075813, "episode/length": 370.0, "episode/score": 0.3572905901614831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3572905901614831}
{"step": 922616, "time": 46633.78815865517, "episode/length": 161.0, "episode/score": 0.18121279812248758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18121279812248758}
{"step": 922816, "time": 46643.87618517876, "episode/length": 200.0, "episode/score": 0.21865638551253141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21865638551253141}
{"step": 923104, "time": 46657.04400372505, "episode/length": 289.0, "episode/score": 0.3371288789326172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3371288789326172}
{"step": 923312, "time": 46666.57584500313, "episode/length": 190.0, "episode/score": 0.2146788424256556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2146788424256556}
{"step": 923376, "time": 46670.5185239315, "episode/length": 264.0, "episode/score": 0.2983436605954921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2983436605954921}
{"step": 923832, "time": 46689.618122816086, "episode/length": 189.0, "episode/score": 0.2080779307443663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2080779307443663}
{"step": 924032, "time": 46698.898787260056, "episode/length": 201.0, "episode/score": 0.22021300364349372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22021300364349372}
{"step": 924128, "time": 46703.965822935104, "episode/length": 239.0, "episode/score": 0.2731271667285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2731271667285}
{"step": 924176, "time": 46707.273873090744, "episode/length": 194.0, "episode/score": 0.20485139177117162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20485139177117162}
{"step": 924448, "time": 46718.94796347618, "episode/length": 167.0, "episode/score": 0.15936423344828654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15936423344828654}
{"step": 924552, "time": 46724.17757701874, "episode/length": 146.0, "episode/score": 0.16772618753020652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16772618753020652}
{"step": 924592, "time": 46727.615250110626, "episode/length": 221.0, "episode/score": 0.23974391703450237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23974391703450237}
{"step": 925160, "time": 46750.16879463196, "episode/length": 165.0, "episode/score": 0.16509108234458836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16509108234458836}
{"step": 925648, "time": 46770.34982705116, "episode/length": 189.0, "episode/score": 0.19954915405833162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19954915405833162}
{"step": 925712, "time": 46775.90523171425, "episode/length": 299.0, "episode/score": 0.33774074291659417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33774074291659417}
{"step": 925920, "time": 46785.3933095932, "episode/length": 217.0, "episode/score": 0.25367200983237126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25367200983237126}
{"step": 925936, "time": 46787.50716090202, "episode/length": 167.0, "episode/score": 0.19350310142181115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19350310142181115}
{"step": 925952, "time": 46789.68819928169, "episode/length": 239.0, "episode/score": 0.23163335128629114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23163335128629114}
{"step": 926112, "time": 46797.36600136757, "episode/length": 207.0, "episode/score": 0.22770110446435865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22770110446435865}
{"step": 926336, "time": 46807.376316547394, "episode/length": 222.0, "episode/score": 0.2487276977590227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2487276977590227}
{"step": 926464, "time": 46814.46921658516, "episode/length": 162.0, "episode/score": 0.1932083297870122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1932083297870122}
{"step": 926848, "time": 46831.3450255394, "episode/length": 149.0, "episode/score": 0.18583332933485508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18583332933485508}
{"step": 926928, "time": 46835.86810851097, "episode/length": 151.0, "episode/score": 0.17729463955038227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17729463955038227}
{"step": 927352, "time": 46853.22738170624, "episode/length": 174.0, "episode/score": 0.19721219072380336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19721219072380336}
{"step": 927448, "time": 46858.97216582298, "episode/length": 190.0, "episode/score": 0.18860955818672664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18860955818672664}
{"step": 927536, "time": 46864.1959605217, "episode/length": 177.0, "episode/score": 0.21112499601440504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21112499601440504}
{"step": 927800, "time": 46875.55718636513, "episode/length": 232.0, "episode/score": 0.2686124219180783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2686124219180783}
{"step": 927808, "time": 46877.68036746979, "episode/length": 167.0, "episode/score": 0.18793928272498306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18793928272498306}
{"step": 928064, "time": 46888.79897880554, "episode/length": 215.0, "episode/score": 0.2289261465994059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2289261465994059}
{"step": 928600, "time": 46910.33791947365, "episode/length": 218.0, "episode/score": 0.25419230287661776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25419230287661776}
{"step": 928720, "time": 46916.65689730644, "episode/length": 170.0, "episode/score": 0.18830024520138977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18830024520138977}
{"step": 928848, "time": 46923.0670337677, "episode/length": 174.0, "episode/score": 0.18589032985255471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18589032985255471}
{"step": 928856, "time": 46924.70316052437, "episode/length": 164.0, "episode/score": 0.17992758018226596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17992758018226596}
{"step": 928896, "time": 46928.023725271225, "episode/length": 245.0, "episode/score": 0.2893333281390369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2893333281390369}
{"step": 929088, "time": 46936.941308021545, "episode/length": 159.0, "episode/score": 0.17381114331874414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17381114331874414}
{"step": 929424, "time": 46951.04306650162, "episode/length": 169.0, "episode/score": 0.19272520957747474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19272520957747474}
{"step": 929936, "time": 46971.900255441666, "episode/length": 266.0, "episode/score": 0.28610827026932384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28610827026932384}
{"step": 929944, "time": 46973.652059555054, "episode/length": 152.0, "episode/score": 0.1463392655896314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1463392655896314}
{"step": 930056, "time": 46979.55021691322, "episode/length": 150.0, "episode/score": 0.1570510544388526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1570510544388526}
{"step": 930072, "time": 47001.38508629799, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 930072, "time": 47003.85382270813, "eval_episode/length": 161.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 930072, "time": 47003.86067199707, "eval_episode/length": 161.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 930072, "time": 47009.03267645836, "eval_episode/length": 199.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.995}
{"step": 930072, "time": 47010.803194999695, "eval_episode/length": 202.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 930072, "time": 47013.32490897179, "eval_episode/length": 225.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.995575221238938}
{"step": 930072, "time": 47015.24193882942, "eval_episode/length": 232.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 930072, "time": 47018.9933488369, "eval_episode/length": 285.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.986013986013986}
{"step": 930248, "time": 47025.68461704254, "episode/length": 168.0, "episode/score": 0.18358818976048497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18358818976048497}
{"step": 930256, "time": 47027.80775666237, "episode/length": 174.0, "episode/score": 0.17926582049767603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17926582049767603}
{"step": 930464, "time": 47037.150114536285, "episode/length": 171.0, "episode/score": 0.19117299331264803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19117299331264803}
{"step": 930592, "time": 47044.06587052345, "episode/length": 145.0, "episode/score": 0.16234625182732998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16234625182732998}
{"step": 930856, "time": 47055.31320309639, "episode/length": 281.0, "episode/score": 0.2974177052274172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2974177052274172}
{"step": 931304, "time": 47073.60969924927, "episode/length": 170.0, "episode/score": 0.1962732168540242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1962732168540242}
{"step": 931464, "time": 47081.18760848045, "episode/length": 189.0, "episode/score": 0.22185713882208802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22185713882208802}
{"step": 931720, "time": 47092.701102018356, "episode/length": 182.0, "episode/score": 0.2045485266498872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2045485266498872}
{"step": 931808, "time": 47097.86267900467, "episode/length": 194.0, "episode/score": 0.21147672913139104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21147672913139104}
{"step": 931832, "time": 47100.147206783295, "episode/length": 221.0, "episode/score": 0.2550226186231157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2550226186231157}
{"step": 932032, "time": 47109.360989809036, "episode/length": 195.0, "episode/score": 0.21029360458669544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21029360458669544}
{"step": 932088, "time": 47112.795835733414, "episode/length": 186.0, "episode/score": 0.2032840460578882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2032840460578882}
{"step": 932576, "time": 47133.04129457474, "episode/length": 214.0, "episode/score": 0.21701641245635983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21701641245635983}
{"step": 932600, "time": 47135.3739130497, "episode/length": 161.0, "episode/score": 0.17581547374720685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17581547374720685}
{"step": 933016, "time": 47152.65017032623, "episode/length": 150.0, "episode/score": 0.1663779734808486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1663779734808486}
{"step": 933088, "time": 47157.053198337555, "episode/length": 156.0, "episode/score": 0.1646896804595599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1646896804595599}
{"step": 933112, "time": 47159.33392262459, "episode/length": 173.0, "episode/score": 0.17937441678805044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17937441678805044}
{"step": 933576, "time": 47178.30244350433, "episode/length": 263.0, "episode/score": 0.28111894895118894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28111894895118894}
{"step": 933736, "time": 47185.939309597015, "episode/length": 205.0, "episode/score": 0.2286917315213941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2286917315213941}
{"step": 933760, "time": 47188.614820957184, "episode/length": 215.0, "episode/score": 0.23939819663064554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23939819663064554}
{"step": 934152, "time": 47206.230749607086, "episode/length": 196.0, "episode/score": 0.23043055104426458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23043055104426458}
{"step": 934176, "time": 47209.00887298584, "episode/length": 196.0, "episode/score": 0.19935461249406217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19935461249406217}
{"step": 934320, "time": 47215.94350218773, "episode/length": 153.0, "episode/score": 0.14290519248243072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14290519248243072}
{"step": 934376, "time": 47219.35443902016, "episode/length": 157.0, "episode/score": 0.1591907456968329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1591907456968329}
{"step": 934416, "time": 47222.69835615158, "episode/length": 174.0, "episode/score": 0.19025484349185717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19025484349185717}
{"step": 934976, "time": 47245.34579253197, "episode/length": 174.0, "episode/score": 0.1918297183510731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1918297183510731}
{"step": 935008, "time": 47248.3379650116, "episode/length": 158.0, "episode/score": 0.16461344589697546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16461344589697546}
{"step": 935016, "time": 47249.911679029465, "episode/length": 156.0, "episode/score": 0.14868974044111383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14868974044111383}
{"step": 935616, "time": 47274.13275384903, "episode/length": 179.0, "episode/score": 0.20932577436906286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20932577436906286}
{"step": 935624, "time": 47275.69538426399, "episode/length": 183.0, "episode/score": 0.21115178184118122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21115178184118122}
{"step": 935672, "time": 47279.033692359924, "episode/length": 156.0, "episode/score": 0.16012979572951735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16012979572951735}
{"step": 935928, "time": 47290.15582203865, "episode/length": 200.0, "episode/score": 0.23691666225204244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23691666225204244}
{"step": 935968, "time": 47293.37900686264, "episode/length": 198.0, "episode/score": 0.22938142395651084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22938142395651084}
{"step": 936416, "time": 47311.72923374176, "episode/length": 175.0, "episode/score": 0.19688114383097854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19688114383097854}
{"step": 936432, "time": 47313.897959947586, "episode/length": 181.0, "episode/score": 0.20066895670242957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20066895670242957}
{"step": 936680, "time": 47324.77704882622, "episode/length": 207.0, "episode/score": 0.22184854975057533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22184854975057533}
{"step": 936856, "time": 47332.952047109604, "episode/length": 153.0, "episode/score": 0.17024923048484197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17024923048484197}
{"step": 936952, "time": 47338.14982700348, "episode/length": 159.0, "episode/score": 0.17901518872349698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17901518872349698}
{"step": 937272, "time": 47351.48938822746, "episode/length": 167.0, "episode/score": 0.1869335182072973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1869335182072973}
{"step": 937280, "time": 47353.53664588928, "episode/length": 163.0, "episode/score": 0.18832261474744882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18832261474744882}
{"step": 938056, "time": 47384.16251540184, "episode/length": 202.0, "episode/score": 0.22783512213754875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22783512213754875}
{"step": 938288, "time": 47395.10147380829, "episode/length": 200.0, "episode/score": 0.20839685756982362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20839685756982362}
{"step": 938376, "time": 47399.80994606018, "episode/length": 344.0, "episode/score": 0.38243756497104187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38243756497104187}
{"step": 938576, "time": 47409.184433460236, "episode/length": 202.0, "episode/score": 0.19857888034039206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19857888034039206}
{"step": 938672, "time": 47414.499153614044, "episode/length": 226.0, "episode/score": 0.2445958548814815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2445958548814815}
{"step": 938912, "time": 47425.028940200806, "episode/length": 203.0, "episode/score": 0.22758121201604808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22758121201604808}
{"step": 939400, "time": 47444.781891822815, "episode/length": 167.0, "episode/score": 0.19115537023117213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19115537023117213}
{"step": 939760, "time": 47460.116198301315, "episode/length": 417.0, "episode/score": 0.42791430502256844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42791430502256844}
{"step": 939944, "time": 47468.50923705101, "episode/length": 170.0, "episode/score": 0.18353136028508743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18353136028508743}
{"step": 939960, "time": 47470.65118575096, "episode/length": 197.0, "episode/score": 0.20382411675291223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20382411675291223}
{"step": 940040, "time": 47475.34390330315, "episode/length": 170.0, "episode/score": 0.18171139275182213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18171139275182213}
{"step": 940056, "time": 47497.165137052536, "eval_episode/length": 153.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 940056, "time": 47499.51823472977, "eval_episode/length": 170.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 940056, "time": 47501.54184341431, "eval_episode/length": 178.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.994413407821229}
{"step": 940056, "time": 47503.766927719116, "eval_episode/length": 193.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 940056, "time": 47505.61631035805, "eval_episode/length": 197.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 940056, "time": 47507.33018994331, "eval_episode/length": 200.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 940056, "time": 47509.1133992672, "eval_episode/length": 204.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 940056, "time": 47514.69804787636, "eval_episode/length": 300.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9867109634551495}
{"step": 940080, "time": 47515.85224866867, "episode/length": 223.0, "episode/score": 0.24513277115875098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24513277115875098}
{"step": 940264, "time": 47524.59974575043, "episode/length": 373.0, "episode/score": 0.371131955461351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.371131955461351}
{"step": 940521, "time": 47537.58966946602, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.11361865234375, "train/action_min": 0.0, "train/action_std": 4.904819480895996, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007669599471613765, "train/actor_opt_grad_steps": 58060.0, "train/actor_opt_loss": -13.198343400955201, "train/adv_mag": 0.1716423045396805, "train/adv_max": 0.11777792477607726, "train/adv_mean": -9.475749796365562e-05, "train/adv_min": -0.17066899514198303, "train/adv_std": 0.012690537180751561, "train/cont_avg": 0.994625, "train/cont_loss_mean": 0.0001420784097952037, "train/cont_loss_std": 0.004274713155838072, "train/cont_neg_acc": 0.999, "train/cont_neg_loss": 0.010574799136295042, "train/cont_pos_acc": 0.9999606533050537, "train/cont_pos_loss": 6.515792774223427e-05, "train/cont_pred": 0.994599552154541, "train/cont_rate": 0.994625, "train/dyn_loss_mean": 10.824917655944825, "train/dyn_loss_std": 8.307099353790283, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1226421444118023, "train/extr_critic_critic_opt_grad_steps": 58060.0, "train/extr_critic_critic_opt_loss": 12085.93209375, "train/extr_critic_mag": 0.2868099346160889, "train/extr_critic_max": 0.2868099346160889, "train/extr_critic_mean": 0.23157395195960997, "train/extr_critic_min": 0.001766852378845215, "train/extr_critic_std": 0.060364655643701554, "train/extr_return_normed_mag": 0.20731648230552674, "train/extr_return_normed_max": 0.20731648230552674, "train/extr_return_normed_mean": 0.1519537237882614, "train/extr_return_normed_min": -0.07847559714317322, "train/extr_return_normed_std": 0.061642589449882504, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28684200859069825, "train/extr_return_raw_max": 0.28684200859069825, "train/extr_return_raw_mean": 0.2314792516231537, "train/extr_return_raw_min": 0.0010499286651611329, "train/extr_return_raw_std": 0.06164258965849877, "train/extr_reward_mag": 0.0013391695022583008, "train/extr_reward_max": 0.0013391695022583008, "train/extr_reward_mean": 0.001102603679522872, "train/extr_reward_min": 1.2540817260742188e-05, "train/extr_reward_std": 0.00023252026026602835, "train/image_loss_mean": 4.295855457305908, "train/image_loss_std": 8.939147373199463, "train/model_loss_mean": 10.83145004272461, "train/model_loss_std": 12.39990406036377, "train/model_opt_grad_norm": 46.29742204284668, "train/model_opt_grad_steps": 58005.112, "train/model_opt_loss": 15714.097671875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1450.0, "train/policy_entropy_mag": 2.765927894592285, "train/policy_entropy_max": 2.765927894592285, "train/policy_entropy_mean": 2.061940453529358, "train/policy_entropy_min": 0.07941903030872345, "train/policy_entropy_std": 0.6417177822589875, "train/policy_logprob_mag": 7.438238056182861, "train/policy_logprob_max": -0.009462252415716648, "train/policy_logprob_mean": -2.0618667078018187, "train/policy_logprob_min": -7.438238056182861, "train/policy_logprob_std": 1.1777994861602783, "train/policy_randomness_mag": 0.9762511677742004, "train/policy_randomness_max": 0.9762511677742004, "train/policy_randomness_mean": 0.7277744846343994, "train/policy_randomness_min": 0.02803143249452114, "train/policy_randomness_std": 0.22649821507930756, "train/post_ent_mag": 57.57385510253906, "train/post_ent_max": 57.57385510253906, "train/post_ent_mean": 40.96806555175781, "train/post_ent_min": 19.69025727844238, "train/post_ent_std": 7.0098474540710445, "train/prior_ent_mag": 66.68800061035157, "train/prior_ent_max": 66.68800061035157, "train/prior_ent_mean": 51.915801879882814, "train/prior_ent_min": 30.778956909179687, "train/prior_ent_std": 5.426472404479981, "train/rep_loss_mean": 10.824917655944825, "train/rep_loss_std": 8.307099353790283, "train/reward_avg": 0.0010740501498803497, "train/reward_loss_mean": 0.040501966625452045, "train/reward_loss_std": 0.010784947887063027, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012957296371459961, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04050196638703346, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010730549097061157, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.0705882082236748, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.6666666666666665, "train_stats/max_log_achievement_collect_sapling": 0.46078431372549017, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5980392156862745, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.27450980392156865, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.0784313725490196, "train_stats/max_log_achievement_wake_up": 0.19607843137254902, "train_stats/mean_log_entropy": 2.1034394292270435, "eval_stats/sum_log_reward": 0.78749995585531, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.6500381409277907e-06, "report/cont_loss_std": 7.4376898737682495e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.7300556869013235e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.5141534933936782e-06, "report/cont_pred": 0.996091365814209, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.217670440673828, "report/dyn_loss_std": 7.787347316741943, "report/image_loss_mean": 3.9875338077545166, "report/image_loss_std": 7.136695861816406, "report/model_loss_mean": 10.759356498718262, "report/model_loss_std": 10.546382904052734, "report/post_ent_mag": 57.916595458984375, "report/post_ent_max": 57.916595458984375, "report/post_ent_mean": 39.957271575927734, "report/post_ent_min": 21.154348373413086, "report/post_ent_std": 6.76925802230835, "report/prior_ent_mag": 66.613525390625, "report/prior_ent_max": 66.613525390625, "report/prior_ent_mean": 51.80950164794922, "report/prior_ent_min": 31.171171188354492, "report/prior_ent_std": 5.175657749176025, "report/rep_loss_mean": 11.217670440673828, "report/rep_loss_std": 7.787347316741943, "report/reward_avg": 0.0010963983368128538, "report/reward_loss_mean": 0.041218094527721405, "report/reward_loss_std": 0.010496041737496853, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001295328140258789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.041218094527721405, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011164473835378885, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00010898518667090684, "eval/cont_loss_std": 0.003389687743037939, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.795095446752384e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00010922453657258302, "eval/cont_pred": 0.9959906935691833, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.72958755493164, "eval/dyn_loss_std": 9.952857971191406, "eval/image_loss_mean": 8.148563385009766, "eval/image_loss_std": 11.084981918334961, "eval/model_loss_mean": 18.893709182739258, "eval/model_loss_std": 15.807136535644531, "eval/post_ent_mag": 52.17085647583008, "eval/post_ent_max": 52.17085647583008, "eval/post_ent_mean": 38.430885314941406, "eval/post_ent_min": 20.800100326538086, "eval/post_ent_std": 6.171570301055908, "eval/prior_ent_mag": 66.613525390625, "eval/prior_ent_max": 66.613525390625, "eval/prior_ent_mean": 52.41963577270508, "eval/prior_ent_min": 32.30423355102539, "eval/prior_ent_std": 4.674227714538574, "eval/rep_loss_mean": 16.72958755493164, "eval/rep_loss_std": 9.952857971191406, "eval/reward_avg": 0.0054687499068677425, "eval/reward_loss_mean": 0.7072840929031372, "eval/reward_loss_std": 3.694044589996338, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013360977172851562, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4849727749824524, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 21.18013572692871, "eval/reward_pred": 0.001085209078155458, "eval/reward_rate": 0.0107421875, "replay/size": 940017.0, "replay/inserts": 20064.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.4049157001185074e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.306981463941851e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.169449222961114e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3814420700073, "timer/env.step_count": 2508.0, "timer/env.step_total": 232.61800479888916, "timer/env.step_frac": 0.23252930833817928, "timer/env.step_avg": 0.09275040063751562, "timer/env.step_min": 0.02315044403076172, "timer/env.step_max": 2.176668405532837, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 9.8594810962677, "timer/replay._sample_frac": 0.009855721709377459, "timer/replay._sample_avg": 0.0004914015697900569, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.011009931564331055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3095.0, "timer/agent.policy_total": 50.42403435707092, "timer/agent.policy_frac": 0.05040480784282903, "timer/agent.policy_avg": 0.016292095107292705, "timer/agent.policy_min": 0.009657859802246094, "timer/agent.policy_max": 0.10951972007751465, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.1440296173095703, "timer/dataset_train_frac": 0.0001439746993022398, "timer/dataset_train_avg": 0.00011485615415436229, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0010881423950195312, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 565.6671659946442, "timer/agent.train_frac": 0.5654514790120011, "timer/agent.train_avg": 0.45109024401486775, "timer/agent.train_min": 0.436126708984375, "timer/agent.train_max": 1.1514811515808105, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47353625297546387, "timer/agent.report_frac": 0.0004733556951992373, "timer/agent.report_avg": 0.23676812648773193, "timer/agent.report_min": 0.2307262420654297, "timer/agent.report_max": 0.24281001091003418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979095886267923e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.056070641615385}
{"step": 940880, "time": 47551.157906770706, "episode/length": 245.0, "episode/score": 0.28676170089875086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28676170089875086}
{"step": 940976, "time": 47556.27812886238, "episode/length": 196.0, "episode/score": 0.21878629345883382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21878629345883382}
{"step": 941248, "time": 47568.31310606003, "episode/length": 150.0, "episode/score": 0.17705448388005607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17705448388005607}
{"step": 941272, "time": 47570.59665799141, "episode/length": 163.0, "episode/score": 0.1615115418098867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1615115418098867}
{"step": 941352, "time": 47575.07581996918, "episode/length": 198.0, "episode/score": 0.2066081320954254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2066081320954254}
{"step": 941736, "time": 47591.12581992149, "episode/length": 223.0, "episode/score": 0.24032875752163818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24032875752163818}
{"step": 942176, "time": 47611.12448859215, "episode/length": 238.0, "episode/score": 0.2705541855902993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2705541855902993}
{"step": 942272, "time": 47616.2615840435, "episode/length": 161.0, "episode/score": 0.1618213477268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1618213477268}
{"step": 942568, "time": 47628.687769174576, "episode/length": 210.0, "episode/score": 0.22991171308240155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22991171308240155}
{"step": 942768, "time": 47637.887942790985, "episode/length": 186.0, "episode/score": 0.179740348681662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179740348681662}
{"step": 942808, "time": 47640.67051911354, "episode/length": 181.0, "episode/score": 0.1726612831444072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1726612831444072}
{"step": 943008, "time": 47649.90039539337, "episode/length": 219.0, "episode/score": 0.24957569165781024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24957569165781024}
{"step": 943128, "time": 47655.90035200119, "episode/length": 173.0, "episode/score": 0.190594430303463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.190594430303463}
{"step": 943528, "time": 47673.41370511055, "episode/length": 430.0, "episode/score": 0.43294830832019215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43294830832019215}
{"step": 943768, "time": 47684.11843132973, "episode/length": 198.0, "episode/score": 0.22079051830951357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22079051830951357}
{"step": 943872, "time": 47689.90546941757, "episode/length": 199.0, "episode/score": 0.22429508476852789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22429508476852789}
{"step": 943896, "time": 47692.20866775513, "episode/length": 165.0, "episode/score": 0.17911927638306224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17911927638306224}
{"step": 944352, "time": 47711.13046956062, "episode/length": 152.0, "episode/score": 0.1642799626733904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1642799626733904}
{"step": 944400, "time": 47714.655217170715, "episode/length": 198.0, "episode/score": 0.22681547221145593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22681547221145593}
{"step": 944632, "time": 47724.719089746475, "episode/length": 232.0, "episode/score": 0.2747916615335271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2747916615335271}
{"step": 944752, "time": 47731.13502788544, "episode/length": 152.0, "episode/score": 0.16723169408396643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16723169408396643}
{"step": 945128, "time": 47746.76716399193, "episode/length": 264.0, "episode/score": 0.27735625668719877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27735625668719877}
{"step": 945320, "time": 47755.508650779724, "episode/length": 193.0, "episode/score": 0.2144404728023801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2144404728023801}
{"step": 945608, "time": 47768.01253437996, "episode/length": 156.0, "episode/score": 0.1901666627964005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1901666627964005}
{"step": 945616, "time": 47770.139702796936, "episode/length": 214.0, "episode/score": 0.2367943541466957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2367943541466957}
{"step": 945664, "time": 47773.53805446625, "episode/length": 223.0, "episode/score": 0.2397458960331278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2397458960331278}
{"step": 945976, "time": 47786.827528715134, "episode/length": 196.0, "episode/score": 0.22523369179543806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22523369179543806}
{"step": 946096, "time": 47793.13041090965, "episode/length": 167.0, "episode/score": 0.1882428056705976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1882428056705976}
{"step": 946320, "time": 47803.12205219269, "episode/length": 210.0, "episode/score": 0.21298172194656217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21298172194656217}
{"step": 946472, "time": 47810.25872039795, "episode/length": 167.0, "episode/score": 0.1732325612247223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1732325612247223}
{"step": 946856, "time": 47826.20836853981, "episode/length": 191.0, "episode/score": 0.19712230881123105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19712230881123105}
{"step": 946952, "time": 47831.455110788345, "episode/length": 167.0, "episode/score": 0.1610315256366448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1610315256366448}
{"step": 947056, "time": 47837.35768556595, "episode/length": 179.0, "episode/score": 0.19234680229783407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19234680229783407}
{"step": 947080, "time": 47839.762843608856, "episode/length": 176.0, "episode/score": 0.20437608097927296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20437608097927296}
{"step": 947184, "time": 47845.379132032394, "episode/length": 88.0, "episode/score": 0.1070416645379737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1070416645379737}
{"step": 947648, "time": 47864.97481703758, "episode/length": 165.0, "episode/score": 0.18400973512871133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18400973512871133}
{"step": 947888, "time": 47876.168674468994, "episode/length": 238.0, "episode/score": 0.278153289018519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.278153289018519}
{"step": 948152, "time": 47887.513865470886, "episode/length": 161.0, "episode/score": 0.1748123661363934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748123661363934}
{"step": 948384, "time": 47898.252873420715, "episode/length": 165.0, "episode/score": 0.15940787065665063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15940787065665063}
{"step": 948504, "time": 47904.111006736755, "episode/length": 164.0, "episode/score": 0.1522606761791394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1522606761791394}
{"step": 948936, "time": 47921.876891851425, "episode/length": 354.0, "episode/score": 0.36244100311159855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36244100311159855}
{"step": 949168, "time": 47932.468687057495, "episode/length": 189.0, "episode/score": 0.21099069159754436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21099069159754436}
{"step": 949400, "time": 47942.47271180153, "episode/length": 155.0, "episode/score": 0.1815233750239713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1815233750239713}
{"step": 949728, "time": 47956.78298306465, "episode/length": 152.0, "episode/score": 0.16126096675361623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16126096675361623}
{"step": 949992, "time": 47968.16158223152, "episode/length": 200.0, "episode/score": 0.20419136361851997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20419136361851997}
{"step": 950040, "time": 47992.84897041321, "eval_episode/length": 154.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 950040, "time": 47992.855969429016, "eval_episode/length": 154.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 950040, "time": 47996.66362118721, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 950040, "time": 47998.3186647892, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 950040, "time": 48000.28060674667, "eval_episode/length": 169.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 950040, "time": 48002.027812719345, "eval_episode/length": 173.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 950040, "time": 48004.490240335464, "eval_episode/length": 193.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 950040, "time": 48006.51498699188, "eval_episode/length": 204.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 950200, "time": 48012.50603103638, "episode/length": 157.0, "episode/score": 0.16545913081426988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16545913081426988}
{"step": 950352, "time": 48021.70857191086, "episode/length": 408.0, "episode/score": 0.3928600284507411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3928600284507411}
{"step": 950512, "time": 48029.31250834465, "episode/length": 444.0, "episode/score": 0.4596419756735486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4596419756735486}
{"step": 950680, "time": 48036.89663553238, "episode/length": 188.0, "episode/score": 0.22832205736176547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22832205736176547}
{"step": 951176, "time": 48057.36912941933, "episode/length": 221.0, "episode/score": 0.2187418661023912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2187418661023912}
{"step": 951320, "time": 48064.85311079025, "episode/length": 139.0, "episode/score": 0.15661296931557445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15661296931557445}
{"step": 951344, "time": 48067.50415349007, "episode/length": 431.0, "episode/score": 0.4198380130228543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4198380130228543}
{"step": 951504, "time": 48075.14180994034, "episode/length": 188.0, "episode/score": 0.2089788701814541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2089788701814541}
{"step": 951560, "time": 48078.580001592636, "episode/length": 228.0, "episode/score": 0.26786464307951974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26786464307951974}
{"step": 951896, "time": 48092.67193341255, "episode/length": 192.0, "episode/score": 0.22187970808136015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22187970808136015}
{"step": 952232, "time": 48107.40840172768, "episode/length": 214.0, "episode/score": 0.23654887013526604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23654887013526604}
{"step": 952416, "time": 48115.9570145607, "episode/length": 216.0, "episode/score": 0.2314067789393448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2314067789393448}
{"step": 952496, "time": 48120.50783324242, "episode/length": 164.0, "episode/score": 0.1675066821017026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1675066821017026}
{"step": 952568, "time": 48124.604978084564, "episode/length": 152.0, "episode/score": 0.15258896279010514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15258896279010514}
{"step": 952600, "time": 48127.449656009674, "episode/length": 159.0, "episode/score": 0.13489710390240361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13489710390240361}
{"step": 952720, "time": 48133.73635816574, "episode/length": 144.0, "episode/score": 0.13529382781416643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13529382781416643}
{"step": 952920, "time": 48142.84460353851, "episode/length": 176.0, "episode/score": 0.1795937863535073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1795937863535073}
{"step": 953392, "time": 48162.32165122032, "episode/length": 186.0, "episode/score": 0.20327746956263582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20327746956263582}
{"step": 953776, "time": 48178.34555196762, "episode/length": 150.0, "episode/score": 0.16972565835658315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16972565835658315}
{"step": 953864, "time": 48182.92417836189, "episode/length": 203.0, "episode/score": 0.23025719941324496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23025719941324496}
{"step": 954072, "time": 48192.29866409302, "episode/length": 196.0, "episode/score": 0.2160873316333891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2160873316333891}
{"step": 954320, "time": 48203.788987874985, "episode/length": 199.0, "episode/score": 0.22783332946710289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22783332946710289}
{"step": 954336, "time": 48205.926540613174, "episode/length": 176.0, "episode/score": 0.18928831195717066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18928831195717066}
{"step": 954480, "time": 48213.00777387619, "episode/length": 135.0, "episode/score": 0.16050864743192506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16050864743192506}
{"step": 954632, "time": 48220.04597067833, "episode/length": 253.0, "episode/score": 0.2693592773130149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2693592773130149}
{"step": 955096, "time": 48238.97368001938, "episode/length": 334.0, "episode/score": 0.3882986041717231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3882986041717231}
{"step": 955264, "time": 48247.02777671814, "episode/length": 185.0, "episode/score": 0.203939173069557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.203939173069557}
{"step": 955264, "time": 48247.035141944885, "episode/length": 148.0, "episode/score": 0.16754412204318214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16754412204318214}
{"step": 955520, "time": 48260.09755778313, "episode/length": 147.0, "episode/score": 0.16834258971357485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16834258971357485}
{"step": 955600, "time": 48264.64293503761, "episode/length": 216.0, "episode/score": 0.18586260087613482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18586260087613482}
{"step": 956176, "time": 48288.08084797859, "episode/length": 211.0, "episode/score": 0.21912812773371115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21912812773371115}
{"step": 956248, "time": 48292.13679265976, "episode/length": 201.0, "episode/score": 0.2292139385608607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2292139385608607}
{"step": 956336, "time": 48297.33471298218, "episode/length": 251.0, "episode/score": 0.2926386849358096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2926386849358096}
{"step": 956744, "time": 48314.1563539505, "episode/length": 70.0, "episode/score": 0.08222115229000337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08222115229000337}
{"step": 956808, "time": 48318.07745432854, "episode/length": 213.0, "episode/score": 0.2240901990153361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2240901990153361}
{"step": 956904, "time": 48323.12415909767, "episode/length": 204.0, "episode/score": 0.23852777361753397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23852777361753397}
{"step": 957120, "time": 48333.05295443535, "episode/length": 231.0, "episode/score": 0.24998114691697992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24998114691697992}
{"step": 957184, "time": 48336.90759181976, "episode/length": 197.0, "episode/score": 0.2173396460566437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2173396460566437}
{"step": 957600, "time": 48354.41447710991, "episode/length": 168.0, "episode/score": 0.18942649538075784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18942649538075784}
{"step": 957744, "time": 48361.32423210144, "episode/length": 175.0, "episode/score": 0.2038009224124835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2038009224124835}
{"step": 958264, "time": 48382.139766931534, "episode/length": 189.0, "episode/score": 0.18633856313681463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18633856313681463}
{"step": 958280, "time": 48384.39809679985, "episode/length": 171.0, "episode/score": 0.19392026965579134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19392026965579134}
{"step": 958360, "time": 48388.925612449646, "episode/length": 193.0, "episode/score": 0.18055769486454665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18055769486454665}
{"step": 958376, "time": 48391.05332493782, "episode/length": 156.0, "episode/score": 0.16459127668349538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16459127668349538}
{"step": 958696, "time": 48406.198148489, "episode/length": 188.0, "episode/score": 0.19369263552653138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19369263552653138}
{"step": 958824, "time": 48412.44330239296, "episode/length": 412.0, "episode/score": 0.45020369905614643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45020369905614643}
{"step": 959080, "time": 48423.60589170456, "episode/length": 184.0, "episode/score": 0.20518575723326649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20518575723326649}
{"step": 959144, "time": 48427.6242377758, "episode/length": 174.0, "episode/score": 0.1742441965652688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742441965652688}
{"step": 959416, "time": 48439.464581251144, "episode/length": 129.0, "episode/score": 0.13782259847539535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13782259847539535}
{"step": 959536, "time": 48445.88523888588, "episode/length": 156.0, "episode/score": 0.1630259520807158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1630259520807158}
{"step": 959536, "time": 48445.89302968979, "episode/length": 158.0, "episode/score": 0.1880524688258447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1880524688258447}
{"step": 960024, "time": 48488.95851945877, "eval_episode/length": 138.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9640287769784173}
{"step": 960024, "time": 48491.46490693092, "eval_episode/length": 159.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.99375}
{"step": 960024, "time": 48494.022871255875, "eval_episode/length": 180.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.994475138121547}
{"step": 960024, "time": 48496.51962018013, "eval_episode/length": 200.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 960024, "time": 48498.1279861927, "eval_episode/length": 202.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 960024, "time": 48500.01604127884, "eval_episode/length": 208.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 960024, "time": 48501.94298315048, "eval_episode/length": 217.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 960024, "time": 48504.20281934738, "eval_episode/length": 235.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 960040, "time": 48504.81014037132, "episode/length": 167.0, "episode/score": 0.16632280613885086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16632280613885086}
{"step": 960424, "time": 48520.688321352005, "episode/length": 159.0, "episode/score": 0.17515412343163916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17515412343163916}
{"step": 960432, "time": 48522.83290076256, "episode/length": 200.0, "episode/score": 0.19428156886715442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19428156886715442}
{"step": 960440, "time": 48524.54581165314, "episode/length": 169.0, "episode/score": 0.16565593127234024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16565593127234024}
{"step": 960608, "time": 48532.56335616112, "episode/length": 280.0, "episode/score": 0.2924876930374012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2924876930374012}
{"step": 960675, "time": 48537.59043765068, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.029068719773066, "train/action_min": 0.0, "train/action_std": 4.843399869071113, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008158289897625171, "train/actor_opt_grad_steps": 59315.0, "train/actor_opt_loss": -11.039688984553019, "train/adv_mag": 0.17805857039869777, "train/adv_max": 0.12347156926989555, "train/adv_mean": -3.8003951349959865e-05, "train/adv_min": -0.1768309585750103, "train/adv_std": 0.013370884460441414, "train/cont_avg": 0.9945359002976191, "train/cont_loss_mean": 0.00015750263363885993, "train/cont_loss_std": 0.004779372366027611, "train/cont_neg_acc": 0.9966931220084901, "train/cont_neg_loss": 0.00959794865713544, "train/cont_pos_acc": 0.9999531914317419, "train/cont_pos_loss": 0.00011005179511485833, "train/cont_pred": 0.9945071297032493, "train/cont_rate": 0.9945359002976191, "train/dyn_loss_mean": 10.77860971481081, "train/dyn_loss_std": 8.397150225109524, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12023780217009877, "train/extr_critic_critic_opt_grad_steps": 59315.0, "train/extr_critic_critic_opt_loss": 11943.3152359251, "train/extr_critic_mag": 0.282738362985944, "train/extr_critic_max": 0.282738362985944, "train/extr_critic_mean": 0.22729927833591188, "train/extr_critic_min": 0.0015935178786989242, "train/extr_critic_std": 0.059469163713474125, "train/extr_return_normed_mag": 0.2051468820325912, "train/extr_return_normed_max": 0.2051468820325912, "train/extr_return_normed_mean": 0.15008760438788504, "train/extr_return_normed_min": -0.07618653460864037, "train/extr_return_normed_std": 0.060981551983526776, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2823206361324068, "train/extr_return_raw_max": 0.2823206361324068, "train/extr_return_raw_mean": 0.22726136280430687, "train/extr_return_raw_min": 0.0009872194320436508, "train/extr_return_raw_std": 0.06098155186526359, "train/extr_reward_mag": 0.0013589660326639812, "train/extr_reward_max": 0.0013589660326639812, "train/extr_reward_mean": 0.0010988737432478322, "train/extr_reward_min": 1.137218778095548e-05, "train/extr_reward_std": 0.00023410667164994048, "train/image_loss_mean": 4.338000233211215, "train/image_loss_std": 9.254352126802717, "train/model_loss_mean": 10.84576478080144, "train/model_loss_std": 12.794339338938395, "train/model_opt_grad_norm": 45.84780634017218, "train/model_opt_grad_steps": 59258.84920634921, "train/model_opt_loss": 14083.641686817957, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1299.6031746031747, "train/policy_entropy_mag": 2.76342915542542, "train/policy_entropy_max": 2.76342915542542, "train/policy_entropy_mean": 2.073620767820449, "train/policy_entropy_min": 0.07941088056753552, "train/policy_entropy_std": 0.6463867312385922, "train/policy_logprob_mag": 7.438247283299764, "train/policy_logprob_max": -0.00946115136944822, "train/policy_logprob_mean": -2.0733064507681225, "train/policy_logprob_min": -7.438247283299764, "train/policy_logprob_std": 1.1698825718864563, "train/policy_randomness_mag": 0.975369221634335, "train/policy_randomness_max": 0.975369221634335, "train/policy_randomness_mean": 0.7318971355756124, "train/policy_randomness_min": 0.02802855596833286, "train/policy_randomness_std": 0.22814615129951446, "train/post_ent_mag": 57.76820010230655, "train/post_ent_max": 57.76820010230655, "train/post_ent_mean": 41.06839534214565, "train/post_ent_min": 19.576372623443604, "train/post_ent_std": 7.0444426574404275, "train/prior_ent_mag": 66.76364063081287, "train/prior_ent_max": 66.76364063081287, "train/prior_ent_mean": 51.95571929689438, "train/prior_ent_min": 30.240849207318018, "train/prior_ent_std": 5.4906771826365635, "train/rep_loss_mean": 10.77860971481081, "train/rep_loss_std": 8.397150225109524, "train/reward_avg": 0.0010721510745555398, "train/reward_loss_mean": 0.040441266305389856, "train/reward_loss_std": 0.010807971765715924, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013061241498069159, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04044126615756088, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001072526567556437, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.020792051117019, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.910891089108911, "train_stats/max_log_achievement_collect_sapling": 0.6534653465346535, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.32673267326732675, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.019801980198019802, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.27722772277227725, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.039603960396039604, "train_stats/max_log_achievement_wake_up": 0.1782178217821782, "train_stats/mean_log_entropy": 2.11137597513671, "eval_stats/sum_log_reward": 0.8500000056810677, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.9375, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.5450684562383685e-06, "report/cont_loss_std": 0.0002330253628315404, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019142099190503359, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.795212925680971e-08, "report/cont_pred": 0.9961012005805969, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.793020248413086, "report/dyn_loss_std": 8.743847846984863, "report/image_loss_mean": 4.478793144226074, "report/image_loss_std": 10.350211143493652, "report/model_loss_mean": 11.594926834106445, "report/model_loss_std": 14.18266773223877, "report/post_ent_mag": 57.773475646972656, "report/post_ent_max": 57.773475646972656, "report/post_ent_mean": 40.23262023925781, "report/post_ent_min": 19.107425689697266, "report/post_ent_std": 7.2258830070495605, "report/prior_ent_mag": 66.620361328125, "report/prior_ent_max": 66.620361328125, "report/prior_ent_mean": 51.97700500488281, "report/prior_ent_min": 30.53264617919922, "report/prior_ent_std": 6.392820835113525, "report/rep_loss_mean": 11.793020248413086, "report/rep_loss_std": 8.743847846984863, "report/reward_avg": 0.0010660361731424928, "report/reward_loss_mean": 0.040314748883247375, "report/reward_loss_std": 0.010428662411868572, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040314748883247375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010380378225818276, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0036784247495234013, "eval/cont_loss_std": 0.11473540961742401, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.9414463043212891, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.04292448922206e-07, "eval/cont_pred": 0.997131884098053, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.754501342773438, "eval/dyn_loss_std": 9.890453338623047, "eval/image_loss_mean": 8.080516815185547, "eval/image_loss_std": 15.809469223022461, "eval/model_loss_mean": 18.74253273010254, "eval/model_loss_std": 19.858890533447266, "eval/post_ent_mag": 55.641239166259766, "eval/post_ent_max": 55.641239166259766, "eval/post_ent_mean": 39.26492691040039, "eval/post_ent_min": 17.69445037841797, "eval/post_ent_std": 6.826273441314697, "eval/prior_ent_mag": 66.620361328125, "eval/prior_ent_max": 66.620361328125, "eval/prior_ent_mean": 53.08515548706055, "eval/prior_ent_min": 32.52204513549805, "eval/prior_ent_std": 4.229736328125, "eval/rep_loss_mean": 16.754501342773438, "eval/rep_loss_std": 9.890453338623047, "eval/reward_avg": 0.007519530598074198, "eval/reward_loss_mean": 0.6056357622146606, "eval/reward_loss_std": 3.424013376235962, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013309717178344727, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.38380375504493713, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 21.034353256225586, "eval/reward_pred": 0.0010469115804880857, "eval/reward_rate": 0.0107421875, "replay/size": 960171.0, "replay/inserts": 20154.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.4057634510170127e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.276358211296148e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2040543718402889e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9915947914124, "timer/env.step_count": 2519.0, "timer/env.step_total": 229.6171727180481, "timer/env.step_frac": 0.22961910271450212, "timer/env.step_avg": 0.09115409794285355, "timer/env.step_min": 0.02307724952697754, "timer/env.step_max": 4.485577344894409, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 9.9581778049469, "timer/replay._sample_frac": 0.00995826150621203, "timer/replay._sample_avg": 0.0004943495733194449, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.02285289764404297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2960.0, "timer/agent.policy_total": 49.93918299674988, "timer/agent.policy_frac": 0.04993960274952777, "timer/agent.policy_avg": 0.016871345607010094, "timer/agent.policy_min": 0.009832143783569336, "timer/agent.policy_max": 0.11973953247070312, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.14484286308288574, "timer/dataset_train_frac": 0.00014484408052759526, "timer/dataset_train_avg": 0.00011504595955749463, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0004317760467529297, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 569.5418932437897, "timer/agent.train_frac": 0.5695466804024388, "timer/agent.train_avg": 0.4523764044827559, "timer/agent.train_min": 0.43757200241088867, "timer/agent.train_max": 1.1395854949951172, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4805769920349121, "timer/agent.report_frac": 0.00048058103141872445, "timer/agent.report_avg": 0.24028849601745605, "timer/agent.report_min": 0.23280906677246094, "timer/agent.report_max": 0.24776792526245117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051783463376574e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 20.15393504022412}
{"step": 960768, "time": 48541.547211647034, "episode/length": 153.0, "episode/score": 0.16497939027067332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16497939027067332}
{"step": 961104, "time": 48555.619226932526, "episode/length": 195.0, "episode/score": 0.19363415402949613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19363415402949613}
{"step": 961400, "time": 48567.873004198074, "episode/length": 169.0, "episode/score": 0.1942753947514575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942753947514575}
{"step": 961432, "time": 48570.57854986191, "episode/length": 251.0, "episode/score": 0.27134280497011787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27134280497011787}
{"step": 961848, "time": 48587.714623212814, "episode/length": 177.0, "episode/score": 0.20121308185298403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20121308185298403}
{"step": 961856, "time": 48589.78242516518, "episode/length": 176.0, "episode/score": 0.19011160071931954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19011160071931954}
{"step": 961936, "time": 48594.3755004406, "episode/length": 187.0, "episode/score": 0.19674817070790596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19674817070790596}
{"step": 962200, "time": 48605.45018053055, "episode/length": 198.0, "episode/score": 0.1987344429580844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1987344429580844}
{"step": 962248, "time": 48608.86186146736, "episode/length": 49.0, "episode/score": 0.056749999115709215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056749999115709215}
{"step": 962792, "time": 48630.87376308441, "episode/length": 173.0, "episode/score": 0.19654896045267378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19654896045267378}
{"step": 962840, "time": 48634.31837439537, "episode/length": 216.0, "episode/score": 0.24969172506007453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24969172506007453}
{"step": 962968, "time": 48640.67592859268, "episode/length": 191.0, "episode/score": 0.20229558397295477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20229558397295477}
{"step": 963024, "time": 48644.66298055649, "episode/length": 281.0, "episode/score": 0.30437983397314383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30437983397314383}
{"step": 963448, "time": 48661.71497583389, "episode/length": 188.0, "episode/score": 0.20019116806906823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20019116806906823}
{"step": 963480, "time": 48664.490550518036, "episode/length": 202.0, "episode/score": 0.20486318623534316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20486318623534316}
{"step": 963496, "time": 48666.69716858864, "episode/length": 161.0, "episode/score": 0.18623541017495882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18623541017495882}
{"step": 963976, "time": 48686.24367785454, "episode/length": 215.0, "episode/score": 0.2326861156079758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2326861156079758}
{"step": 964232, "time": 48698.078468322754, "episode/length": 173.0, "episode/score": 0.17952673276613496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17952673276613496}
{"step": 964464, "time": 48709.182655096054, "episode/length": 208.0, "episode/score": 0.20770170912328467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20770170912328467}
{"step": 964616, "time": 48716.134150505066, "episode/length": 198.0, "episode/score": 0.19436292321188375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19436292321188375}
{"step": 964784, "time": 48724.18997120857, "episode/length": 160.0, "episode/score": 0.16212508900753164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16212508900753164}
{"step": 964816, "time": 48727.03482031822, "episode/length": 166.0, "episode/score": 0.18394939498011809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18394939498011809}
{"step": 964864, "time": 48730.37562799454, "episode/length": 236.0, "episode/score": 0.24467885519879928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24467885519879928}
{"step": 965480, "time": 48754.59677553177, "episode/length": 155.0, "episode/score": 0.1637749078545312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637749078545312}
{"step": 965536, "time": 48758.462105989456, "episode/length": 260.0, "episode/score": 0.3021740846306784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3021740846306784}
{"step": 965616, "time": 48763.033898591995, "episode/length": 204.0, "episode/score": 0.2262972688249647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2262972688249647}
{"step": 965952, "time": 48777.74081611633, "episode/length": 145.0, "episode/score": 0.17413170551571966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17413170551571966}
{"step": 966088, "time": 48784.12615823746, "episode/length": 202.0, "episode/score": 0.20294781185111788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20294781185111788}
{"step": 966112, "time": 48786.78464627266, "episode/length": 161.0, "episode/score": 0.17575890309944953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17575890309944953}
{"step": 966200, "time": 48791.507123708725, "episode/length": 82.0, "episode/score": 0.09102348578562669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09102348578562669}
{"step": 966544, "time": 48806.18202185631, "episode/length": 209.0, "episode/score": 0.22753484668373858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22753484668373858}
{"step": 966576, "time": 48808.94179439545, "episode/length": 244.0, "episode/score": 0.2700381203649158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2700381203649158}
{"step": 967120, "time": 48832.44724345207, "episode/length": 204.0, "episode/score": 0.22348722672086296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22348722672086296}
{"step": 967408, "time": 48845.37911319733, "episode/length": 223.0, "episode/score": 0.2556054251581372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2556054251581372}
{"step": 967552, "time": 48852.298865795135, "episode/length": 199.0, "episode/score": 0.2058239983725798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2058239983725798}
{"step": 967600, "time": 48855.66583228111, "episode/length": 174.0, "episode/score": 0.1866035624052529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1866035624052529}
{"step": 967616, "time": 48857.83051085472, "episode/length": 190.0, "episode/score": 0.18348835604092528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18348835604092528}
{"step": 967672, "time": 48861.36159443855, "episode/length": 194.0, "episode/score": 0.21070591434909147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21070591434909147}
{"step": 968040, "time": 48876.83539009094, "episode/length": 54.0, "episode/score": 0.060818737823865376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060818737823865376}
{"step": 968096, "time": 48881.04388999939, "episode/length": 189.0, "episode/score": 0.212336888729169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.212336888729169}
{"step": 968368, "time": 48892.85982179642, "episode/length": 227.0, "episode/score": 0.2618062180936249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2618062180936249}
{"step": 968760, "time": 48908.62954688072, "episode/length": 168.0, "episode/score": 0.18212905568361748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18212905568361748}
{"step": 968784, "time": 48911.21276283264, "episode/length": 207.0, "episode/score": 0.22900751927681995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22900751927681995}
{"step": 969096, "time": 48924.24476003647, "episode/length": 177.0, "episode/score": 0.16760614979284583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16760614979284583}
{"step": 969192, "time": 48929.42481970787, "episode/length": 196.0, "episode/score": 0.2193384655911359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2193384655911359}
{"step": 969232, "time": 48932.70478248596, "episode/length": 209.0, "episode/score": 0.2250771527942561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2250771527942561}
{"step": 969608, "time": 48948.22722840309, "episode/length": 195.0, "episode/score": 0.221774617475603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.221774617475603}
{"step": 969656, "time": 48951.517238378525, "episode/length": 194.0, "episode/score": 0.18793454921978991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18793454921978991}
{"step": 970000, "time": 48966.02084541321, "episode/length": 203.0, "episode/score": 0.2160935258070822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2160935258070822}
{"step": 970008, "time": 48987.493374824524, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 970008, "time": 48989.836976766586, "eval_episode/length": 159.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.99375}
{"step": 970008, "time": 48992.087020397186, "eval_episode/length": 164.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 970008, "time": 48994.876848220825, "eval_episode/length": 177.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 970008, "time": 48997.19060301781, "eval_episode/length": 196.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 970008, "time": 48998.94157218933, "eval_episode/length": 199.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.995}
{"step": 970008, "time": 49004.25402164459, "eval_episode/length": 283.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9964788732394366}
{"step": 970008, "time": 49007.024337768555, "eval_episode/length": 135.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 970136, "time": 49011.80880308151, "episode/length": 171.0, "episode/score": 0.18795690692058997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18795690692058997}
{"step": 970224, "time": 49016.80722332001, "episode/length": 179.0, "episode/score": 0.1973223182867514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1973223182867514}
{"step": 970472, "time": 49027.301211833954, "episode/length": 171.0, "episode/score": 0.1779940455016913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1779940455016913}
{"step": 970560, "time": 49032.43601965904, "episode/length": 165.0, "episode/score": 0.18879315136291552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18879315136291552}
{"step": 970968, "time": 49049.22576022148, "episode/length": 221.0, "episode/score": 0.2454671956220409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2454671956220409}
{"step": 971040, "time": 49053.68819975853, "episode/length": 178.0, "episode/score": 0.2014459273632383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2014459273632383}
{"step": 971136, "time": 49058.78589320183, "episode/length": 141.0, "episode/score": 0.16081645296071656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16081645296071656}
{"step": 971336, "time": 49067.66538763046, "episode/length": 149.0, "episode/score": 0.1585840358202404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1585840358202404}
{"step": 971728, "time": 49083.95718407631, "episode/length": 187.0, "episode/score": 0.19057685360894538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19057685360894538}
{"step": 972072, "time": 49098.321434020996, "episode/length": 188.0, "episode/score": 0.19200060172443045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19200060172443045}
{"step": 972240, "time": 49106.33509016037, "episode/length": 158.0, "episode/score": 0.16525661205741926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16525661205741926}
{"step": 972560, "time": 49120.3539557457, "episode/length": 260.0, "episode/score": 0.30312996968859807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30312996968859807}
{"step": 972656, "time": 49126.17927265167, "episode/length": 189.0, "episode/score": 0.2056737931634416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2056737931634416}
{"step": 972960, "time": 49139.7305495739, "episode/length": 412.0, "episode/score": 0.4209717098128749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4209717098128749}
{"step": 973128, "time": 49148.01212191582, "episode/length": 174.0, "episode/score": 0.18873839452135144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18873839452135144}
{"step": 973224, "time": 49153.77395749092, "episode/length": 235.0, "episode/score": 0.26383624276786577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26383624276786577}
{"step": 973592, "time": 49170.009491205215, "episode/length": 318.0, "episode/score": 0.3539162110937468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3539162110937468}
{"step": 973776, "time": 49178.69759106636, "episode/length": 212.0, "episode/score": 0.231940130914154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.231940130914154}
{"step": 973848, "time": 49182.74900150299, "episode/length": 148.0, "episode/score": 0.16209518160030711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16209518160030711}
{"step": 973968, "time": 49189.36202335358, "episode/length": 215.0, "episode/score": 0.22288258144180872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22288258144180872}
{"step": 974376, "time": 49205.86656880379, "episode/length": 155.0, "episode/score": 0.1524824323169014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1524824323169014}
{"step": 974488, "time": 49211.64100241661, "episode/length": 190.0, "episode/score": 0.1906646962488594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1906646962488594}
{"step": 974632, "time": 49218.86070418358, "episode/length": 31.0, "episode/score": 0.03737499931594357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03737499931594357}
{"step": 974688, "time": 49222.74990963936, "episode/length": 265.0, "episode/score": 0.3021407583000837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3021407583000837}
{"step": 974832, "time": 49229.79467558861, "episode/length": 200.0, "episode/score": 0.2174705354627804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2174705354627804}
{"step": 975064, "time": 49241.35997247696, "episode/length": 160.0, "episode/score": 0.16578162318000977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16578162318000977}
{"step": 975096, "time": 49244.183317661285, "episode/length": 187.0, "episode/score": 0.2050567175319884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2050567175319884}
{"step": 975104, "time": 49246.335547208786, "episode/length": 156.0, "episode/score": 0.16301150959770894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16301150959770894}
{"step": 975496, "time": 49262.23809289932, "episode/length": 190.0, "episode/score": 0.20417115835880395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20417115835880395}
{"step": 975656, "time": 49269.71913313866, "episode/length": 145.0, "episode/score": 0.14091615726647433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14091615726647433}
{"step": 975960, "time": 49282.68112397194, "episode/length": 165.0, "episode/score": 0.1632666664172575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1632666664172575}
{"step": 976112, "time": 49290.12120985985, "episode/length": 159.0, "episode/score": 0.16972281543712597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16972281543712597}
{"step": 976312, "time": 49298.892709970474, "episode/length": 151.0, "episode/score": 0.16763556887599407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16763556887599407}
{"step": 976664, "time": 49313.58912277222, "episode/length": 194.0, "episode/score": 0.21553512679383857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21553512679383857}
{"step": 977152, "time": 49333.52943730354, "episode/length": 206.0, "episode/score": 0.20133528959559044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20133528959559044}
{"step": 977160, "time": 49335.25701189041, "episode/length": 187.0, "episode/score": 0.20883052863064222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20883052863064222}
{"step": 977208, "time": 49338.646094322205, "episode/length": 155.0, "episode/score": 0.1735047559996019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1735047559996019}
{"step": 977312, "time": 49344.46144199371, "episode/length": 327.0, "episode/score": 0.35467362129747926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35467362129747926}
{"step": 977488, "time": 49352.52250146866, "episode/length": 302.0, "episode/score": 0.35456551321112784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35456551321112784}
{"step": 977632, "time": 49359.347816705704, "episode/length": 164.0, "episode/score": 0.18614014848935767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18614014848935767}
{"step": 977640, "time": 49361.03247022629, "episode/length": 190.0, "episode/score": 0.2052504804560158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2052504804560158}
{"step": 978256, "time": 49385.890500068665, "episode/length": 198.0, "episode/score": 0.20687926242680987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20687926242680987}
{"step": 978304, "time": 49389.203454494476, "episode/length": 142.0, "episode/score": 0.15178146502876189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15178146502876189}
{"step": 978528, "time": 49399.27560353279, "episode/length": 164.0, "episode/score": 0.17787265617153025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17787265617153025}
{"step": 978592, "time": 49403.7155418396, "episode/length": 159.0, "episode/score": 0.17768239799988805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17768239799988805}
{"step": 978856, "time": 49415.865442276, "episode/length": 152.0, "episode/score": 0.16606070358102443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16606070358102443}
{"step": 979040, "time": 49425.1093006134, "episode/length": 235.0, "episode/score": 0.2766340345260687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2766340345260687}
{"step": 979096, "time": 49428.485003232956, "episode/length": 200.0, "episode/score": 0.21972833334803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21972833334803}
{"step": 979176, "time": 49432.96107339859, "episode/length": 191.0, "episode/score": 0.19366335724043893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19366335724043893}
{"step": 979624, "time": 49450.976455926895, "episode/length": 170.0, "episode/score": 0.18625468096252007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18625468096252007}
{"step": 979640, "time": 49453.161474227905, "episode/length": 57.0, "episode/score": 0.06456691813036741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06456691813036741}
{"step": 980096, "time": 49490.656037569046, "eval_episode/length": 138.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9640287769784173}
{"step": 980096, "time": 49492.665199279785, "eval_episode/length": 150.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 980096, "time": 49494.704859256744, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 980096, "time": 49496.77766776085, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 980096, "time": 49498.77765130997, "eval_episode/length": 186.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 980096, "time": 49500.9934220314, "eval_episode/length": 200.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 980096, "time": 49501.0613617897, "eval_episode/length": 200.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 980096, "time": 49504.36337900162, "eval_episode/length": 201.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.995049504950495}
{"step": 980112, "time": 49504.98600244522, "episode/length": 156.0, "episode/score": 0.16523180853801023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16523180853801023}
{"step": 980160, "time": 49508.43084859848, "episode/length": 195.0, "episode/score": 0.2166708808272233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2166708808272233}
{"step": 980232, "time": 49512.403962135315, "episode/length": 212.0, "episode/score": 0.24562995591804793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24562995591804793}
{"step": 980825, "time": 49537.7394361496, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.187784830729167, "train/action_min": 0.0, "train/action_std": 4.914357919541616, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007695593250294526, "train/actor_opt_grad_steps": 60575.0, "train/actor_opt_loss": -7.50825842333928, "train/adv_mag": 0.17456058939061467, "train/adv_max": 0.12277992353552863, "train/adv_mean": 0.0001723678533904055, "train/adv_min": -0.17233239616903048, "train/adv_std": 0.013054691199656753, "train/cont_avg": 0.9948381696428571, "train/cont_loss_mean": 0.0001977801193525976, "train/cont_loss_std": 0.005812853029716453, "train/cont_neg_acc": 0.9888038564295996, "train/cont_neg_loss": 0.021440404248056755, "train/cont_pos_acc": 0.99997659382366, "train/cont_pos_loss": 9.620853388724192e-05, "train/cont_pred": 0.9948407960316491, "train/cont_rate": 0.9948381696428571, "train/dyn_loss_mean": 10.783856437319802, "train/dyn_loss_std": 8.402818922012571, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13650369623468983, "train/extr_critic_critic_opt_grad_steps": 60575.0, "train/extr_critic_critic_opt_loss": 12082.870892237102, "train/extr_critic_mag": 0.2828233932691907, "train/extr_critic_max": 0.2828233932691907, "train/extr_critic_mean": 0.2296664496026342, "train/extr_critic_min": 0.001701158190530444, "train/extr_critic_std": 0.05866040771324483, "train/extr_return_normed_mag": 0.20263602773821543, "train/extr_return_normed_max": 0.20263602773821543, "train/extr_return_normed_mean": 0.14960641337056008, "train/extr_return_normed_min": -0.07918599933858901, "train/extr_return_normed_std": 0.06013097939273668, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2828684141711583, "train/extr_return_raw_max": 0.2828684141711583, "train/extr_return_raw_mean": 0.2298388031740037, "train/extr_return_raw_min": 0.0010463869760906886, "train/extr_return_raw_std": 0.060130979540565656, "train/extr_reward_mag": 0.0013635641052609398, "train/extr_reward_max": 0.0013635641052609398, "train/extr_reward_mean": 0.001100041585723086, "train/extr_reward_min": 1.1479097699362135e-05, "train/extr_reward_std": 0.00023482838716720126, "train/image_loss_mean": 4.383431275685628, "train/image_loss_std": 9.147976898011708, "train/model_loss_mean": 10.894568730914404, "train/model_loss_std": 12.672210829598564, "train/model_opt_grad_norm": 48.08376472715347, "train/model_opt_grad_steps": 60517.72222222222, "train/model_opt_loss": 14873.400677393352, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1369.047619047619, "train/policy_entropy_mag": 2.7667267265773954, "train/policy_entropy_max": 2.7667267265773954, "train/policy_entropy_mean": 2.082057675671956, "train/policy_entropy_min": 0.07944525340719828, "train/policy_entropy_std": 0.6398927011187114, "train/policy_logprob_mag": 7.438227956257169, "train/policy_logprob_max": -0.009465830614938149, "train/policy_logprob_mean": -2.0823115810515387, "train/policy_logprob_min": -7.438227956257169, "train/policy_logprob_std": 1.169460342043922, "train/policy_randomness_mag": 0.9765331201137059, "train/policy_randomness_max": 0.9765331201137059, "train/policy_randomness_mean": 0.7348749864669073, "train/policy_randomness_min": 0.028040688144900495, "train/policy_randomness_std": 0.2258540436862007, "train/post_ent_mag": 57.44786450219533, "train/post_ent_max": 57.44786450219533, "train/post_ent_mean": 41.080570917280895, "train/post_ent_min": 19.490545174432178, "train/post_ent_std": 7.031384664868551, "train/prior_ent_mag": 66.84624160282196, "train/prior_ent_max": 66.84624160282196, "train/prior_ent_mean": 51.931484858194985, "train/prior_ent_min": 30.611739234318808, "train/prior_ent_std": 5.496654824605064, "train/rep_loss_mean": 10.783856437319802, "train/rep_loss_std": 8.402818922012571, "train/reward_avg": 0.0010776241903104598, "train/reward_loss_mean": 0.04062589423524009, "train/reward_loss_std": 0.010637319535903987, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013129796300615584, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04062589444220066, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010773271584646805, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.7990291131642259, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.349514563106796, "train_stats/max_log_achievement_collect_sapling": 0.36893203883495146, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5145631067961165, "train_stats/max_log_achievement_defeat_skeleton": 0.009708737864077669, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009708737864077669, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.20388349514563106, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.08737864077669903, "train_stats/max_log_achievement_wake_up": 0.14563106796116504, "train_stats/mean_log_entropy": 2.1044158680925094, "eval_stats/sum_log_reward": 0.8499999884516001, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.4375, "eval_stats/max_log_achievement_collect_sapling": 0.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.342051786603406e-05, "report/cont_loss_std": 0.0009422482107765973, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.6444551369640976e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.3405674912501127e-05, "report/cont_pred": 0.9950846433639526, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 9.887320518493652, "report/dyn_loss_std": 8.60962200164795, "report/image_loss_mean": 4.048488616943359, "report/image_loss_std": 7.127490043640137, "report/model_loss_mean": 10.02092170715332, "report/model_loss_std": 10.9736909866333, "report/post_ent_mag": 58.327354431152344, "report/post_ent_max": 58.327354431152344, "report/post_ent_mean": 41.66442108154297, "report/post_ent_min": 18.253559112548828, "report/post_ent_std": 7.2626261711120605, "report/prior_ent_mag": 66.78907775878906, "report/prior_ent_max": 66.78907775878906, "report/prior_ent_mean": 52.26007843017578, "report/prior_ent_min": 33.41688537597656, "report/prior_ent_std": 5.249651908874512, "report/rep_loss_mean": 9.887320518493652, "report/rep_loss_std": 8.60962200164795, "report/reward_avg": 0.0010597397340461612, "report/reward_loss_mean": 0.04000798612833023, "report/reward_loss_std": 0.011455901898443699, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04000798612833023, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010708228219300508, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.120487458043499e-06, "eval/cont_loss_std": 0.0001309500657953322, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00024064622994046658, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.65957646156312e-06, "eval/cont_pred": 0.9980428218841553, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.01078224182129, "eval/dyn_loss_std": 10.210498809814453, "eval/image_loss_mean": 7.058368682861328, "eval/image_loss_std": 10.461681365966797, "eval/model_loss_mean": 17.158889770507812, "eval/model_loss_std": 15.364754676818848, "eval/post_ent_mag": 57.64192199707031, "eval/post_ent_max": 57.64192199707031, "eval/post_ent_mean": 39.72895050048828, "eval/post_ent_min": 19.498659133911133, "eval/post_ent_std": 7.530510902404785, "eval/prior_ent_mag": 66.78907775878906, "eval/prior_ent_max": 66.78907775878906, "eval/prior_ent_mean": 53.85137176513672, "eval/prior_ent_min": 32.60292053222656, "eval/prior_ent_std": 4.125978946685791, "eval/rep_loss_mean": 16.01078224182129, "eval/rep_loss_std": 10.210498809814453, "eval/reward_avg": 0.009765625, "eval/reward_loss_mean": 0.49404680728912354, "eval/reward_loss_std": 3.1066739559173584, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012753009796142578, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.250643789768219, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 21.021038055419922, "eval/reward_pred": 0.0010725472820922732, "eval/reward_rate": 0.01171875, "replay/size": 980321.0, "replay/inserts": 20150.0, "replay/samples": 20160.0, "replay/insert_wait_avg": 1.4141593914173968e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.239041245172895e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1775960293851157e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1380944252014, "timer/env.step_count": 2519.0, "timer/env.step_total": 235.9032576084137, "timer/env.step_frac": 0.23587068518172166, "timer/env.step_avg": 0.09364956633918765, "timer/env.step_min": 0.02328968048095703, "timer/env.step_max": 2.2637100219726562, "timer/replay._sample_count": 20160.0, "timer/replay._sample_total": 9.851569175720215, "timer/replay._sample_frac": 0.009850208916781738, "timer/replay._sample_avg": 0.0004886691059385027, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.008171796798706055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3035.0, "timer/agent.policy_total": 49.635515213012695, "timer/agent.policy_frac": 0.04962866177149185, "timer/agent.policy_avg": 0.01635437074563845, "timer/agent.policy_min": 0.009774208068847656, "timer/agent.policy_max": 0.10937094688415527, "timer/dataset_train_count": 1260.0, "timer/dataset_train_total": 0.14609527587890625, "timer/dataset_train_frac": 0.0001460751037214216, "timer/dataset_train_avg": 0.0001159486316499256, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0010197162628173828, "timer/agent.train_count": 1260.0, "timer/agent.train_total": 565.3316495418549, "timer/agent.train_frac": 0.565253591172089, "timer/agent.train_avg": 0.4486759123348054, "timer/agent.train_min": 0.4353671073913574, "timer/agent.train_max": 1.0946099758148193, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4777109622955322, "timer/agent.report_frac": 0.00047764500218350534, "timer/agent.report_avg": 0.2388554811477661, "timer/agent.report_min": 0.23301315307617188, "timer/agent.report_max": 0.24469780921936035, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.385076363067567e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 20.146971323671142}
{"step": 981152, "time": 49550.160064697266, "episode/length": 190.0, "episode/score": 0.19851684917375678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19851684917375678}
{"step": 981168, "time": 49552.34692978859, "episode/length": 190.0, "episode/score": 0.19418839074569405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19418839074569405}
{"step": 981296, "time": 49558.6322953701, "episode/length": 373.0, "episode/score": 0.4005124553987116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4005124553987116}
{"step": 981352, "time": 49562.08440947533, "episode/length": 288.0, "episode/score": 0.32224767927073117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32224767927073117}
{"step": 981488, "time": 49568.810175418854, "episode/length": 165.0, "episode/score": 0.1737382355495356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1737382355495356}
{"step": 981496, "time": 49570.40217256546, "episode/length": 157.0, "episode/score": 0.16453873580940126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16453873580940126}
{"step": 982056, "time": 49592.75460147858, "episode/length": 112.0, "episode/score": 0.10569777996533958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10569777996533958}
{"step": 982568, "time": 49613.38570308685, "episode/length": 174.0, "episode/score": 0.19575125234769075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19575125234769075}
{"step": 982664, "time": 49618.5053486824, "episode/length": 445.0, "episode/score": 0.4524307249175763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4524307249175763}
{"step": 982760, "time": 49624.18407821655, "episode/length": 175.0, "episode/score": 0.19469332685912377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19469332685912377}
{"step": 982776, "time": 49626.30494880676, "episode/length": 159.0, "episode/score": 0.15921378720395296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15921378720395296}
{"step": 983072, "time": 49640.76069307327, "episode/length": 221.0, "episode/score": 0.2531474876359425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2531474876359425}
{"step": 983512, "time": 49659.59843707085, "episode/length": 424.0, "episode/score": 0.4313148098417514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4313148098417514}
{"step": 983640, "time": 49666.62979722023, "episode/length": 197.0, "episode/score": 0.20964555554473918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20964555554473918}
{"step": 984296, "time": 49693.5013988018, "episode/length": 203.0, "episode/score": 0.21622562246739108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21622562246739108}
{"step": 984424, "time": 49700.13382983208, "episode/length": 207.0, "episode/score": 0.23081381361498643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23081381361498643}
{"step": 984488, "time": 49703.925305604935, "episode/length": 213.0, "episode/score": 0.19978767356406024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19978767356406024}
{"step": 984848, "time": 49719.36288571358, "episode/length": 221.0, "episode/score": 0.23847079900588142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23847079900588142}
{"step": 984872, "time": 49721.55232834816, "episode/length": 169.0, "episode/score": 0.17274485749658197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17274485749658197}
{"step": 985080, "time": 49730.80761909485, "episode/length": 448.0, "episode/score": 0.4361712418976822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4361712418976822}
{"step": 985112, "time": 49733.55097961426, "episode/length": 317.0, "episode/score": 0.32594953889838507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32594953889838507}
{"step": 985312, "time": 49742.78513908386, "episode/length": 208.0, "episode/score": 0.21782008197442337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21782008197442337}
{"step": 985496, "time": 49751.527923583984, "episode/length": 149.0, "episode/score": 0.14712688548388542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14712688548388542}
{"step": 985784, "time": 49764.20966362953, "episode/length": 161.0, "episode/score": 0.1618031922243972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1618031922243972}
{"step": 985944, "time": 49771.67873477936, "episode/length": 189.0, "episode/score": 0.20494490400596987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20494490400596987}
{"step": 986160, "time": 49781.44276094437, "episode/length": 163.0, "episode/score": 0.1690466383452076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1690466383452076}
{"step": 986440, "time": 49793.45434784889, "episode/length": 195.0, "episode/score": 0.2186222406971865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2186222406971865}
{"step": 986504, "time": 49797.409630060196, "episode/length": 148.0, "episode/score": 0.15519669318882734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15519669318882734}
{"step": 986584, "time": 49801.91806435585, "episode/length": 187.0, "episode/score": 0.20708273875061423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20708273875061423}
{"step": 986840, "time": 49813.08013677597, "episode/length": 215.0, "episode/score": 0.23009524076678645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23009524076678645}
{"step": 987024, "time": 49821.768689632416, "episode/length": 190.0, "episode/score": 0.18119084804720842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18119084804720842}
{"step": 987152, "time": 49828.21389102936, "episode/length": 170.0, "episode/score": 0.19352161087135755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19352161087135755}
{"step": 987288, "time": 49834.62252140045, "episode/length": 167.0, "episode/score": 0.18463936513535373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18463936513535373}
{"step": 987448, "time": 49842.14573550224, "episode/length": 160.0, "episode/score": 0.1770964258089407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1770964258089407}
{"step": 987800, "time": 49856.79511094093, "episode/length": 151.0, "episode/score": 0.18198908367776312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18198908367776312}
{"step": 988272, "time": 49876.15582203865, "episode/length": 220.0, "episode/score": 0.24638904066387113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24638904066387113}
{"step": 988528, "time": 49887.155334711075, "episode/length": 187.0, "episode/score": 0.20896076143708342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20896076143708342}
{"step": 988560, "time": 49890.071335315704, "episode/length": 264.0, "episode/score": 0.2929987304714814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2929987304714814}
{"step": 988600, "time": 49892.86405324936, "episode/length": 163.0, "episode/score": 0.15821300732022792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15821300732022792}
{"step": 988624, "time": 49895.96893119812, "episode/length": 183.0, "episode/score": 0.2067728736965364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2067728736965364}
{"step": 988936, "time": 49909.74151611328, "episode/length": 185.0, "episode/score": 0.20367889895760527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20367889895760527}
{"step": 989168, "time": 49920.111917972565, "episode/length": 170.0, "episode/score": 0.19009283386640163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19009283386640163}
{"step": 989856, "time": 49947.29202580452, "episode/length": 197.0, "episode/score": 0.20849710794391285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20849710794391285}
{"step": 989984, "time": 49953.66119885445, "episode/length": 169.0, "episode/score": 0.16916714881153894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16916714881153894}
{"step": 989984, "time": 49953.66961288452, "episode/length": 177.0, "episode/score": 0.17449429706221053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17449429706221053}
{"step": 990032, "time": 49958.63750529289, "episode/length": 187.0, "episode/score": 0.191632121859584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191632121859584}
{"step": 990080, "time": 49981.903175115585, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 990080, "time": 49981.914206027985, "eval_episode/length": 163.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 990080, "time": 49986.01884818077, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 990080, "time": 49988.20400428772, "eval_episode/length": 190.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 990080, "time": 49990.32899928093, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 990080, "time": 49990.336300611496, "eval_episode/length": 200.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 990080, "time": 49994.670214653015, "eval_episode/length": 223.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 990080, "time": 49996.579065561295, "eval_episode/length": 232.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9699570815450643}
{"step": 990184, "time": 50000.22231554985, "episode/length": 197.0, "episode/score": 0.2137876146630333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2137876146630333}
{"step": 990392, "time": 50009.464118003845, "episode/length": 443.0, "episode/score": 0.45679437019771285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45679437019771285}
{"step": 990504, "time": 50015.222338438034, "episode/length": 195.0, "episode/score": 0.21776586922896968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21776586922896968}
{"step": 991168, "time": 50041.85307121277, "episode/length": 249.0, "episode/score": 0.2524864619076652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2524864619076652}
{"step": 991232, "time": 50046.079100847244, "episode/length": 171.0, "episode/score": 0.18469851874033338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18469851874033338}
{"step": 991584, "time": 50062.43485927582, "episode/length": 193.0, "episode/score": 0.2162731398930191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2162731398930191}
{"step": 991632, "time": 50066.31052184105, "episode/length": 205.0, "episode/score": 0.21933055396948475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21933055396948475}
{"step": 991640, "time": 50068.43691325188, "episode/length": 181.0, "episode/score": 0.1861420355635346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1861420355635346}
{"step": 991856, "time": 50078.97257709503, "episode/length": 182.0, "episode/score": 0.21724999585421756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21724999585421756}
{"step": 991920, "time": 50083.01459479332, "episode/length": 241.0, "episode/score": 0.28294117814220954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28294117814220954}
{"step": 992016, "time": 50088.331244945526, "episode/length": 188.0, "episode/score": 0.200587879800878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.200587879800878}
{"step": 992520, "time": 50108.455307006836, "episode/length": 160.0, "episode/score": 0.15792268664699805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15792268664699805}
{"step": 993008, "time": 50129.17913746834, "episode/length": 170.0, "episode/score": 0.1719765101224766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1719765101224766}
{"step": 993024, "time": 50131.370898246765, "episode/length": 145.0, "episode/score": 0.14934591199016722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14934591199016722}
{"step": 993216, "time": 50140.12773728371, "episode/length": 161.0, "episode/score": 0.14410162266540283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14410162266540283}
{"step": 993376, "time": 50147.755965709686, "episode/length": 223.0, "episode/score": 0.25441421342475223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25441421342475223}
{"step": 993424, "time": 50151.186922073364, "episode/length": 223.0, "episode/score": 0.24423240547184832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24423240547184832}
{"step": 993672, "time": 50161.75823330879, "episode/length": 206.0, "episode/score": 0.21984040510142222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21984040510142222}
{"step": 993816, "time": 50168.66031289101, "episode/length": 330.0, "episode/score": 0.37544138554585516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.37544138554585516}
{"step": 993992, "time": 50176.83331465721, "episode/length": 183.0, "episode/score": 0.17990330692919088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17990330692919088}
{"step": 994432, "time": 50194.97568655014, "episode/length": 175.0, "episode/score": 0.19191140456132416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19191140456132416}
{"step": 994544, "time": 50200.7105653286, "episode/length": 191.0, "episode/score": 0.21739595097096753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21739595097096753}
{"step": 994936, "time": 50216.89461135864, "episode/length": 188.0, "episode/score": 0.2048112594311533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2048112594311533}
{"step": 995000, "time": 50221.448055267334, "episode/length": 202.0, "episode/score": 0.22912526547224843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22912526547224843}
{"step": 995264, "time": 50232.96799945831, "episode/length": 255.0, "episode/score": 0.27338362146838335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27338362146838335}
{"step": 995312, "time": 50236.4886777401, "episode/length": 204.0, "episode/score": 0.2311780477721186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2311780477721186}
{"step": 995512, "time": 50245.30740451813, "episode/length": 211.0, "episode/score": 0.23253457315877313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23253457315877313}
{"step": 995560, "time": 50249.35566830635, "episode/length": 195.0, "episode/score": 0.2051159923466912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2051159923466912}
{"step": 995832, "time": 50261.66071367264, "episode/length": 174.0, "episode/score": 0.2037479853406694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2037479853406694}
{"step": 996048, "time": 50271.64446425438, "episode/length": 187.0, "episode/score": 0.20955984801366867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20955984801366867}
{"step": 996656, "time": 50297.22306251526, "episode/length": 206.0, "episode/score": 0.22815295452892315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22815295452892315}
{"step": 996760, "time": 50303.201525211334, "episode/length": 155.0, "episode/score": 0.15863103510491783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15863103510491783}
{"step": 996992, "time": 50314.2954723835, "episode/length": 215.0, "episode/score": 0.236664272917551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.236664272917551}
{"step": 997008, "time": 50316.39393210411, "episode/length": 258.0, "episode/score": 0.30880769520990725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30880769520990725}
{"step": 997032, "time": 50321.10523366928, "episode/length": 214.0, "episode/score": 0.22334577602305217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22334577602305217}
{"step": 997336, "time": 50334.317377090454, "episode/length": 221.0, "episode/score": 0.25753480209823465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25753480209823465}
{"step": 997488, "time": 50341.71739935875, "episode/length": 206.0, "episode/score": 0.2312193548423238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2312193548423238}
{"step": 998112, "time": 50367.15819597244, "episode/length": 257.0, "episode/score": 0.2877432745954138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2877432745954138}
{"step": 998192, "time": 50372.208888053894, "episode/length": 191.0, "episode/score": 0.20522954440821195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20522954440821195}
{"step": 998360, "time": 50379.94681477547, "episode/length": 168.0, "episode/score": 0.18399362140189623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18399362140189623}
{"step": 998424, "time": 50384.094685554504, "episode/length": 178.0, "episode/score": 0.19608372266156948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19608372266156948}
{"step": 998504, "time": 50389.20951962471, "episode/length": 183.0, "episode/score": 0.20507863961029216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20507863961029216}
{"step": 998632, "time": 50395.47111082077, "episode/length": 233.0, "episode/score": 0.2546736071817577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2546736071817577}
{"step": 998888, "time": 50406.573210954666, "episode/length": 174.0, "episode/score": 0.19614089755850728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19614089755850728}
{"step": 999032, "time": 50413.59948635101, "episode/length": 211.0, "episode/score": 0.22257457523301127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22257457523301127}
{"step": 999592, "time": 50437.78005480766, "episode/length": 184.0, "episode/score": 0.19513392585213296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19513392585213296}
{"step": 999632, "time": 50441.18705368042, "episode/length": 179.0, "episode/score": 0.19446825116756372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19446825116756372}
{"step": 999720, "time": 50445.92262339592, "episode/length": 169.0, "episode/score": 0.18035834333568346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18035834333568346}
{"step": 1000064, "time": 50479.198415756226, "eval_episode/length": 98.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.98989898989899}
{"step": 1000064, "time": 50482.399930238724, "eval_episode/length": 134.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 1000064, "time": 50485.45993232727, "eval_episode/length": 167.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 1000064, "time": 50487.33916044235, "eval_episode/length": 171.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 1000064, "time": 50489.0507338047, "eval_episode/length": 173.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 1000064, "time": 50490.87001371384, "eval_episode/length": 176.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 1000064, "time": 50493.587171554565, "eval_episode/length": 204.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 1000064, "time": 50497.24960947037, "eval_episode/length": 259.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 1000112, "time": 50499.06909584999, "episode/length": 200.0, "episode/score": 0.22669971466530114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22669971466530114}
{"step": 1000304, "time": 50507.93482661247, "episode/length": 176.0, "episode/score": 0.199875074737065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.199875074737065}
{"step": 1000608, "time": 50520.830630779266, "episode/length": 246.0, "episode/score": 0.27012490655033616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27012490655033616}
{"step": 1000985, "time": 50538.05575108528, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.1437179323226685, "train/action_min": 0.0, "train/action_std": 4.890475799166967, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008285602539896018, "train/actor_opt_grad_steps": 61835.0, "train/actor_opt_loss": -11.050681617997942, "train/adv_mag": 0.1802541415487963, "train/adv_max": 0.12526093819548215, "train/adv_mean": -4.015037375220273e-05, "train/adv_min": -0.17859691836767727, "train/adv_std": 0.013538888478208156, "train/cont_avg": 0.9945824032738095, "train/cont_loss_mean": 6.924140750832016e-05, "train/cont_loss_std": 0.0020034351859345, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0018295562128391866, "train/cont_pos_acc": 0.9999688102139367, "train/cont_pos_loss": 6.0192519939417274e-05, "train/cont_pred": 0.9945519325279054, "train/cont_rate": 0.9945824032738095, "train/dyn_loss_mean": 10.704101373278906, "train/dyn_loss_std": 8.378239904131208, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12697603148482148, "train/extr_critic_critic_opt_grad_steps": 61835.0, "train/extr_critic_critic_opt_loss": 12033.39076450893, "train/extr_critic_mag": 0.2861713596752712, "train/extr_critic_max": 0.2861713596752712, "train/extr_critic_mean": 0.23033799928805185, "train/extr_critic_min": 0.001577272301628476, "train/extr_critic_std": 0.062288293215845315, "train/extr_return_normed_mag": 0.20847759407664102, "train/extr_return_normed_max": 0.20847759407664102, "train/extr_return_normed_mean": 0.15225966487612044, "train/extr_return_normed_min": -0.0770073670834776, "train/extr_return_normed_std": 0.06393397807897556, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2865157567319416, "train/extr_return_raw_max": 0.2865157567319416, "train/extr_return_raw_mean": 0.23029783036973742, "train/extr_return_raw_min": 0.0010307961040072972, "train/extr_return_raw_std": 0.0639339777389689, "train/extr_reward_mag": 0.0013860322180248442, "train/extr_reward_max": 0.0013860322180248442, "train/extr_reward_mean": 0.0010999874091736736, "train/extr_reward_min": 1.2221790495372953e-05, "train/extr_reward_std": 0.00023402777913447825, "train/image_loss_mean": 4.373251791984316, "train/image_loss_std": 8.973656499196613, "train/model_loss_mean": 10.836294711582244, "train/model_loss_std": 12.463895177084302, "train/model_opt_grad_norm": 46.665849731082005, "train/model_opt_grad_steps": 61776.51587301587, "train/model_opt_loss": 13545.368419828868, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.765413719510275, "train/policy_entropy_max": 2.765413719510275, "train/policy_entropy_mean": 2.0635380508407715, "train/policy_entropy_min": 0.07941550406671706, "train/policy_entropy_std": 0.6590487890773349, "train/policy_logprob_mag": 7.4382316460685125, "train/policy_logprob_max": -0.00946177461642831, "train/policy_logprob_mean": -2.0633191996150546, "train/policy_logprob_min": -7.4382316460685125, "train/policy_logprob_std": 1.1809769376875863, "train/policy_randomness_mag": 0.9760696869047861, "train/policy_randomness_max": 0.9760696869047861, "train/policy_randomness_mean": 0.7283383763971782, "train/policy_randomness_min": 0.02803018791157575, "train/policy_randomness_std": 0.23261530117856133, "train/post_ent_mag": 57.737236537630594, "train/post_ent_max": 57.737236537630594, "train/post_ent_mean": 41.12405428810725, "train/post_ent_min": 19.532884915669758, "train/post_ent_std": 7.011457246447367, "train/prior_ent_mag": 66.85872432163784, "train/prior_ent_max": 66.85872432163784, "train/prior_ent_mean": 51.918721123347204, "train/prior_ent_min": 30.685917036873953, "train/prior_ent_std": 5.506638595036098, "train/rep_loss_mean": 10.704101373278906, "train/rep_loss_std": 8.378239904131208, "train/reward_avg": 0.0010743000598195645, "train/reward_loss_mean": 0.04051285352380503, "train/reward_loss_std": 0.010770867031718057, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001312950300791907, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04051285358293662, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001074373044834901, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.0381442962079932, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.309278350515464, "train_stats/max_log_achievement_collect_sapling": 0.5567010309278351, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.3917525773195876, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.010309278350515464, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.32989690721649484, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.020618556701030927, "train_stats/max_log_achievement_wake_up": 0.17525773195876287, "train_stats/mean_log_entropy": 2.111020510958642, "eval_stats/sum_log_reward": 0.9749999856576324, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.403786245646188e-05, "report/cont_loss_std": 0.0003271090390626341, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.94122019619681e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3618950106319971e-05, "report/cont_pred": 0.995104193687439, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.808058738708496, "report/dyn_loss_std": 8.438179016113281, "report/image_loss_mean": 5.297285079956055, "report/image_loss_std": 10.04513168334961, "report/model_loss_mean": 13.023748397827148, "report/model_loss_std": 13.537699699401855, "report/post_ent_mag": 56.318687438964844, "report/post_ent_max": 56.318687438964844, "report/post_ent_mean": 39.550880432128906, "report/post_ent_min": 17.2880802154541, "report/post_ent_std": 6.645228385925293, "report/prior_ent_mag": 66.96401977539062, "report/prior_ent_max": 66.96401977539062, "report/prior_ent_mean": 52.42860412597656, "report/prior_ent_min": 33.22796630859375, "report/prior_ent_std": 4.880147933959961, "report/rep_loss_mean": 12.808058738708496, "report/rep_loss_std": 8.438179016113281, "report/reward_avg": 0.0011052852496504784, "report/reward_loss_mean": 0.041614286601543427, "report/reward_loss_std": 0.009267916902899742, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012412071228027344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04161429405212402, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010629408061504364, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.4410021524090553e-06, "eval/cont_loss_std": 5.290133412927389e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005073907668702304, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.6080657511993195e-07, "eval/cont_pred": 0.9960952997207642, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.50939655303955, "eval/dyn_loss_std": 9.845969200134277, "eval/image_loss_mean": 6.440545082092285, "eval/image_loss_std": 11.7150297164917, "eval/model_loss_mean": 16.253374099731445, "eval/model_loss_std": 15.90573501586914, "eval/post_ent_mag": 55.441490173339844, "eval/post_ent_max": 55.441490173339844, "eval/post_ent_mean": 39.66504669189453, "eval/post_ent_min": 20.746116638183594, "eval/post_ent_std": 7.246999263763428, "eval/prior_ent_mag": 66.96401977539062, "eval/prior_ent_max": 66.96401977539062, "eval/prior_ent_mean": 53.04802703857422, "eval/prior_ent_min": 25.822025299072266, "eval/prior_ent_std": 4.610800266265869, "eval/rep_loss_mean": 15.50939655303955, "eval/rep_loss_std": 9.845969200134277, "eval/reward_avg": 0.006542968563735485, "eval/reward_loss_mean": 0.5071883201599121, "eval/reward_loss_std": 3.136941909790039, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0012079477310180664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.30430054664611816, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 21.080007553100586, "eval/reward_pred": 0.0010046190582215786, "eval/reward_rate": 0.009765625, "replay/size": 1000000.0, "replay/inserts": 20160.0, "replay/samples": 20160.0, "replay/insert_wait_avg": 1.3921823766496446e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.343349373529828e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1630159846183979e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3027036190033, "timer/env.step_count": 2520.0, "timer/env.step_total": 231.82381129264832, "timer/env.step_frac": 0.23175365862146635, "timer/env.step_avg": 0.09199357590978108, "timer/env.step_min": 0.023095130920410156, "timer/env.step_max": 3.205907106399536, "timer/replay._sample_count": 20160.0, "timer/replay._sample_total": 9.8785240650177, "timer/replay._sample_frac": 0.009875534704922927, "timer/replay._sample_avg": 0.0004900061540187351, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.024712562561035156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3013.0, "timer/agent.policy_total": 50.35013794898987, "timer/agent.policy_frac": 0.05033490139217628, "timer/agent.policy_avg": 0.016710965134082267, "timer/agent.policy_min": 0.009468317031860352, "timer/agent.policy_max": 0.12546825408935547, "timer/dataset_train_count": 1260.0, "timer/dataset_train_total": 0.1448380947113037, "timer/dataset_train_frac": 0.0001447942649632884, "timer/dataset_train_avg": 0.00011495086881849501, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0006184577941894531, "timer/agent.train_count": 1260.0, "timer/agent.train_total": 570.1069207191467, "timer/agent.train_frac": 0.5699343995138194, "timer/agent.train_avg": 0.4524658100945609, "timer/agent.train_min": 0.43671631813049316, "timer/agent.train_max": 2.932781457901001, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47788047790527344, "timer/agent.report_frac": 0.0004777358655298499, "timer/agent.report_avg": 0.23894023895263672, "timer/agent.report_min": 0.231736421585083, "timer/agent.report_max": 0.24614405632019043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6933146677506136e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 20.15364149685489}
{"step": 1001000, "time": 50538.21375155449, "episode/length": 175.0, "episode/score": 0.20852903632476227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20852903632476227}
{"step": 1001024, "time": 50541.280396699905, "episode/length": 173.0, "episode/score": 0.19525634543242631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19525634543242631}
{"step": 1001072, "time": 50544.5949754715, "episode/length": 168.0, "episode/score": 0.20354166242759675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20354166242759675}
{"step": 1001232, "time": 50552.17134594917, "episode/length": 350.0, "episode/score": 0.41114562757866224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41114562757866224}
{"step": 1001640, "time": 50568.89000439644, "episode/length": 325.0, "episode/score": 0.3480570134415757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3480570134415757}
{"step": 1001736, "time": 50573.956981897354, "episode/length": 202.0, "episode/score": 0.22494059307791758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22494059307791758}
{"step": 1002032, "time": 50586.88807845116, "episode/length": 177.0, "episode/score": 0.19888392402936006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19888392402936006}
{"step": 1002128, "time": 50592.025461912155, "episode/length": 140.0, "episode/score": 0.1519999129268399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1519999129268399}
{"step": 1002680, "time": 50614.185989141464, "episode/length": 206.0, "episode/score": 0.23713596212110133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23713596212110133}
{"step": 1002840, "time": 50621.75423192978, "episode/length": 220.0, "episode/score": 0.25488459725966095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25488459725966095}
{"step": 1002984, "time": 50628.88336610794, "episode/length": 334.0, "episode/score": 0.3701336621743394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3701336621743394}
{"step": 1003008, "time": 50631.55880904198, "episode/length": 40.0, "episode/score": 0.04199208024510881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04199208024510881}
{"step": 1003072, "time": 50635.551137685776, "episode/length": 229.0, "episode/score": 0.27137499471427873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27137499471427873}
{"step": 1003408, "time": 50649.60637998581, "episode/length": 220.0, "episode/score": 0.22999128031733562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22999128031733562}
{"step": 1003760, "time": 50664.306416749954, "episode/length": 215.0, "episode/score": 0.24965407063427847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24965407063427847}
{"step": 1003776, "time": 50666.48547053337, "episode/length": 205.0, "episode/score": 0.2380552461854677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2380552461854677}
{"step": 1004216, "time": 50684.35855293274, "episode/length": 153.0, "episode/score": 0.1706401351329987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706401351329987}
{"step": 1004344, "time": 50690.67985415459, "episode/length": 158.0, "episode/score": 0.1676165532644518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1676165532644518}
{"step": 1004488, "time": 50697.59393906593, "episode/length": 205.0, "episode/score": 0.23531061614994542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23531061614994542}
{"step": 1004592, "time": 50703.255058050156, "episode/length": 147.0, "episode/score": 0.15385051594603283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15385051594603283}
{"step": 1004664, "time": 50707.25479006767, "episode/length": 365.0, "episode/score": 0.4090749757615413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4090749757615413}
{"step": 1005096, "time": 50724.91407704353, "episode/length": 166.0, "episode/score": 0.19679274363625154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19679274363625154}
{"step": 1005432, "time": 50738.975209236145, "episode/length": 206.0, "episode/score": 0.22424337804113748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22424337804113748}
{"step": 1005536, "time": 50744.69085431099, "episode/length": 315.0, "episode/score": 0.36096909988373227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36096909988373227}
{"step": 1005704, "time": 50752.31385016441, "episode/length": 169.0, "episode/score": 0.18986153108562576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18986153108562576}
{"step": 1006056, "time": 50767.0888440609, "episode/length": 173.0, "episode/score": 0.20070640064659528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20070640064659528}
{"step": 1006384, "time": 50781.30421876907, "episode/length": 160.0, "episode/score": 0.1748243461279344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748243461279344}
{"step": 1006416, "time": 50784.079347372055, "episode/length": 274.0, "episode/score": 0.3194789341523574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3194789341523574}
{"step": 1006512, "time": 50789.33394098282, "episode/length": 239.0, "episode/score": 0.25876654653075093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25876654653075093}
{"step": 1006640, "time": 50795.87700557709, "episode/length": 268.0, "episode/score": 0.3074934335982107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3074934335982107}
{"step": 1006896, "time": 50807.65988469124, "episode/length": 182.0, "episode/score": 0.1982405232702149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1982405232702149}
{"step": 1007120, "time": 50817.58702993393, "episode/length": 197.0, "episode/score": 0.18278649226795096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18278649226795096}
{"step": 1007552, "time": 50835.86432957649, "episode/length": 129.0, "episode/score": 0.14751290693493502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14751290693493502}
{"step": 1007576, "time": 50838.165030002594, "episode/length": 233.0, "episode/score": 0.2718697735681417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2718697735681417}
{"step": 1007696, "time": 50846.09640789032, "episode/length": 204.0, "episode/score": 0.22555727146118443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22555727146118443}
{"step": 1007768, "time": 50850.014382600784, "episode/length": 140.0, "episode/score": 0.15506299738717644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15506299738717644}
{"step": 1007896, "time": 50856.38992023468, "episode/length": 188.0, "episode/score": 0.20970078453592578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20970078453592578}
{"step": 1007944, "time": 50859.802904844284, "episode/length": 190.0, "episode/score": 0.2085957334475097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2085957334475097}
{"step": 1008360, "time": 50876.9693980217, "episode/length": 182.0, "episode/score": 0.21759648702027334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21759648702027334}
{"step": 1008752, "time": 50893.330313682556, "episode/length": 122.0, "episode/score": 0.1439582410184812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1439582410184812}
{"step": 1008944, "time": 50902.087297677994, "episode/length": 170.0, "episode/score": 0.18343505408665806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18343505408665806}
{"step": 1009016, "time": 50906.17536973953, "episode/length": 182.0, "episode/score": 0.19098130411293823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19098130411293823}
{"step": 1009048, "time": 50908.97484588623, "episode/length": 168.0, "episode/score": 0.19056915392866358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19056915392866358}
{"step": 1009512, "time": 50927.95505404472, "episode/length": 298.0, "episode/score": 0.33397207289362996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33397207289362996}
{"step": 1009568, "time": 50931.8503947258, "episode/length": 202.0, "episode/score": 0.21041925119334337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21041925119334337}
{"step": 1010048, "time": 50971.045988082886, "eval_episode/length": 157.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 1010048, "time": 50973.14788246155, "eval_episode/length": 168.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 1010048, "time": 50975.21929526329, "eval_episode/length": 179.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 1010048, "time": 50977.21037507057, "eval_episode/length": 188.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 1010048, "time": 50978.86971330643, "eval_episode/length": 190.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 1010048, "time": 50980.97165417671, "eval_episode/length": 204.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 1010048, "time": 50982.603875637054, "eval_episode/length": 206.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 1010048, "time": 50985.00649523735, "eval_episode/length": 223.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 1010072, "time": 50985.67755866051, "episode/length": 213.0, "episode/score": 0.22926589373037132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22926589373037132}
{"step": 1010184, "time": 50991.313256025314, "episode/length": 145.0, "episode/score": 0.1584273480466436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1584273480466436}
{"step": 1010240, "time": 50995.17161273956, "episode/length": 185.0, "episode/score": 0.20963867374848633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20963867374848633}
{"step": 1010264, "time": 50997.31182861328, "episode/length": 295.0, "episode/score": 0.34284021907569695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34284021907569695}
{"step": 1010688, "time": 51014.94990301132, "episode/length": 146.0, "episode/score": 0.1664075211974705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1664075211974705}
{"step": 1011048, "time": 51029.70200800896, "episode/length": 184.0, "episode/score": 0.19721707696226076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19721707696226076}
{"step": 1011464, "time": 51046.73995280266, "episode/length": 301.0, "episode/score": 0.33049095092792413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33049095092792413}
{"step": 1011528, "time": 51050.71215701103, "episode/length": 181.0, "episode/score": 0.19498411540553207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19498411540553207}
{"step": 1011656, "time": 51056.98782968521, "episode/length": 173.0, "episode/score": 0.18446725915418938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18446725915418938}
{"step": 1011752, "time": 51062.088550806046, "episode/length": 350.0, "episode/score": 0.3815183227579837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3815183227579837}
{"step": 1011824, "time": 51066.491086483, "episode/length": 204.0, "episode/score": 0.2321001943491865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2321001943491865}
{"step": 1012048, "time": 51076.46814870834, "episode/length": 169.0, "episode/score": 0.18565268787642708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18565268787642708}
{"step": 1012352, "time": 51089.37781333923, "episode/length": 263.0, "episode/score": 0.32004166013211943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32004166013211943}
{"step": 1012760, "time": 51106.564902067184, "episode/length": 161.0, "episode/score": 0.17698113551159622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17698113551159622}
{"step": 1012888, "time": 51112.84013414383, "episode/length": 153.0, "episode/score": 0.15372058050343185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15372058050343185}
{"step": 1012888, "time": 51112.84800338745, "episode/length": 229.0, "episode/score": 0.2563584057497792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2563584057497792}
{"step": 1013048, "time": 51122.14183330536, "episode/length": 189.0, "episode/score": 0.20642620712897042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20642620712897042}
{"step": 1013184, "time": 51128.95764708519, "episode/length": 141.0, "episode/score": 0.15698042739677476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15698042739677476}
{"step": 1013288, "time": 51134.179346084595, "episode/length": 191.0, "episode/score": 0.21079311579887872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21079311579887872}
{"step": 1013440, "time": 51141.75219082832, "episode/length": 201.0, "episode/score": 0.227677260802011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.227677260802011}
{"step": 1013752, "time": 51154.84777402878, "episode/length": 174.0, "episode/score": 0.19478393904864788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19478393904864788}
{"step": 1014104, "time": 51169.533522844315, "episode/length": 167.0, "episode/score": 0.17777543477495783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17777543477495783}
{"step": 1014176, "time": 51174.07976555824, "episode/length": 160.0, "episode/score": 0.18708152448380133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18708152448380133}
{"step": 1014312, "time": 51180.50813651085, "episode/length": 157.0, "episode/score": 0.15771058120662929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15771058120662929}
{"step": 1014424, "time": 51186.276601314545, "episode/length": 191.0, "episode/score": 0.21659949056629557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21659949056629557}
{"step": 1014768, "time": 51201.065252780914, "episode/length": 184.0, "episode/score": 0.20675695745921985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20675695745921985}
{"step": 1015184, "time": 51218.53274559975, "episode/length": 178.0, "episode/score": 0.1754093410236237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1754093410236237}
{"step": 1015240, "time": 51222.45028924942, "episode/length": 256.0, "episode/score": 0.2788396851046855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2788396851046855}
{"step": 1015400, "time": 51230.14857196808, "episode/length": 152.0, "episode/score": 0.16554348328099877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16554348328099877}
{"step": 1015640, "time": 51241.308933734894, "episode/length": 191.0, "episode/score": 0.19140223285467073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19140223285467073}
{"step": 1015680, "time": 51244.501742362976, "episode/length": 170.0, "episode/score": 0.19438819288370723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19438819288370723}
{"step": 1015688, "time": 51246.137618780136, "episode/length": 280.0, "episode/score": 0.30456435807172966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30456435807172966}
{"step": 1016280, "time": 51271.38544845581, "episode/length": 188.0, "episode/score": 0.20083395607434795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20083395607434795}
{"step": 1016584, "time": 51284.41665101051, "episode/length": 269.0, "episode/score": 0.28948965519339254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28948965519339254}
{"step": 1016632, "time": 51287.80133032799, "episode/length": 173.0, "episode/score": 0.17631901769709657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17631901769709657}
{"step": 1016952, "time": 51301.131536245346, "episode/length": 220.0, "episode/score": 0.24470775914232945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24470775914232945}
{"step": 1017064, "time": 51306.90878367424, "episode/length": 207.0, "episode/score": 0.2283188031242389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2283188031242389}
{"step": 1017080, "time": 51309.02992653847, "episode/length": 179.0, "episode/score": 0.1972388548510935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1972388548510935}
{"step": 1017120, "time": 51312.42527508736, "episode/length": 66.0, "episode/score": 0.07095138439763105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07095138439763105}
{"step": 1017584, "time": 51331.46090555191, "episode/length": 162.0, "episode/score": 0.16634262416846468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16634262416846468}
{"step": 1017632, "time": 51334.857149362564, "episode/length": 243.0, "episode/score": 0.28228074868093245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28228074868093245}
{"step": 1018368, "time": 51363.88336586952, "episode/length": 216.0, "episode/score": 0.25019474970031297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25019474970031297}
{"step": 1018432, "time": 51367.88420152664, "episode/length": 168.0, "episode/score": 0.18554761607083492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18554761607083492}
{"step": 1018600, "time": 51375.62427186966, "episode/length": 191.0, "episode/score": 0.2164336849891697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2164336849891697}
{"step": 1018792, "time": 51384.42999744415, "episode/length": 208.0, "episode/score": 0.2322037646881654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2322037646881654}
{"step": 1018808, "time": 51386.60050582886, "episode/length": 231.0, "episode/score": 0.2516443644199171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2516443644199171}
{"step": 1018888, "time": 51391.12957024574, "episode/length": 162.0, "episode/score": 0.1647214649929083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1647214649929083}
{"step": 1019104, "time": 51400.98693275452, "episode/length": 426.0, "episode/score": 0.42785509691475454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42785509691475454}
{"step": 1019512, "time": 51417.504230737686, "episode/length": 134.0, "episode/score": 0.15147762188280467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15147762188280467}
{"step": 1019688, "time": 51425.50819325447, "episode/length": 164.0, "episode/score": 0.1829153596499964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1829153596499964}
{"step": 1019856, "time": 51433.59604358673, "episode/length": 277.0, "episode/score": 0.30307568648277083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30307568648277083}
{"step": 1020032, "time": 51441.9421107769, "episode/length": 178.0, "episode/score": 0.2090687908748805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2090687908748805}
