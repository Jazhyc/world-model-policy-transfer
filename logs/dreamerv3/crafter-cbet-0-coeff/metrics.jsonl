{"step": 568, "time": 107.11772131919861, "episode/length": 70.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9436619718309859, "episode/intrinsic_return": 0.0}
{"step": 1152, "time": 112.1523745059967, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 1168, "time": 113.66606116294861, "episode/length": 145.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 1224, "time": 115.34692883491516, "episode/length": 152.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 1280, "time": 117.01384997367859, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1304, "time": 118.5639488697052, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 1472, "time": 120.96095323562622, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 122.86719417572021, "episode/length": 194.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 134.90025401115417, "eval_episode/length": 47.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 1560, "time": 138.29471731185913, "eval_episode/length": 145.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 1560, "time": 140.1674747467041, "eval_episode/length": 170.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1560, "time": 141.61230564117432, "eval_episode/length": 173.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 1560, "time": 143.4283766746521, "eval_episode/length": 191.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 1560, "time": 143.47325587272644, "eval_episode/length": 191.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 1560, "time": 146.20223450660706, "eval_episode/length": 194.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 1560, "time": 146.2425458431244, "train_stats/sum_log_reward": 0.9749999567866325, "train_stats/max_log_achievement_collect_sapling": 0.7142857142857143, "train_stats/max_log_achievement_wake_up": 1.8571428571428572, "train_stats/max_log_achievement_place_plant": 0.75, "train_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/sum_log_reward": 1.6714285016059875, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_wood": 0.14285714285714285, "eval_stats/max_log_achievement_place_plant": 0.8571428571428571, "eval_stats/max_log_achievement_wake_up": 1.8571428571428572}
{"step": 1560, "time": 181.38233017921448, "eval_episode/length": 61.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9354838709677419}
{"step": 1560, "time": 185.93797516822815, "eval_episode/length": 130.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9694656488549618}
{"step": 1560, "time": 188.1597900390625, "eval_episode/length": 147.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 189.7696018218994, "eval_episode/length": 148.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 1560, "time": 191.40657687187195, "eval_episode/length": 150.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 1560, "time": 193.5537314414978, "eval_episode/length": 161.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 1560, "time": 195.50553965568542, "eval_episode/length": 170.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 1560, "time": 198.8172047138214, "eval_episode/length": 214.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 1561, "time": 322.0630397796631, "eval_stats/sum_log_reward": 1.849999949336052, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/max_log_achievement_eat_cow": 0.14285714285714285, "eval_stats/max_log_achievement_collect_drink": 5.75, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.39013671875, "train/action_min": 0.0, "train/action_std": 4.845969200134277, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00030021212296560407, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.1186563968658447, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.675418496131897, "train/cont_loss_std": 0.2977985739707947, "train/cont_neg_acc": 0.6666666865348816, "train/cont_neg_loss": 0.6862739324569702, "train/cont_pos_acc": 0.5798236727714539, "train/cont_pos_loss": 0.6753865480422974, "train/cont_pred": 0.5302904844284058, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.881251335144043, "train/dyn_loss_std": 0.536005437374115, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 7.385529041290283, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 30360.4765625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3659.767578125, "train/image_loss_std": 156.12864685058594, "train/model_loss_mean": 3672.512939453125, "train/model_loss_std": 156.0323944091797, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36725128.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.770463705062866, "train/policy_entropy_max": 2.770463705062866, "train/policy_entropy_mean": 2.5739922523498535, "train/policy_entropy_min": 2.0218374729156494, "train/policy_entropy_std": 0.08116677403450012, "train/policy_logprob_mag": 5.7052717208862305, "train/policy_logprob_max": -0.7429425716400146, "train/policy_logprob_mean": -2.5648088455200195, "train/policy_logprob_min": -5.7052717208862305, "train/policy_logprob_std": 0.6766727566719055, "train/policy_randomness_mag": 0.9778521060943604, "train/policy_randomness_max": 0.9778521060943604, "train/policy_randomness_mean": 0.9085063934326172, "train/policy_randomness_min": 0.7136198878288269, "train/policy_randomness_std": 0.028648309409618378, "train/post_ent_mag": 106.15167236328125, "train/post_ent_max": 106.15167236328125, "train/post_ent_mean": 105.59133911132812, "train/post_ent_min": 105.0238265991211, "train/post_ent_std": 0.22583137452602386, "train/prior_ent_mag": 106.4232406616211, "train/prior_ent_max": 106.4232406616211, "train/prior_ent_mean": 105.58708190917969, "train/prior_ent_min": 104.32032012939453, "train/prior_ent_std": 0.3072589635848999, "train/rep_loss_mean": 10.881251335144043, "train/rep_loss_std": 0.536005437374115, "train/reward_avg": 0.0126953125, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.548376738166553e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0166015625, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.6831027269363403, "report/cont_loss_std": 0.2981688976287842, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.0294826030731201, "report/cont_pos_acc": 0.5749265551567078, "report/cont_pos_loss": 0.6820849776268005, "report/cont_pred": 0.5269947648048401, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.897764205932617, "report/dyn_loss_std": 0.4760935604572296, "report/image_loss_mean": 3658.3857421875, "report/image_loss_std": 156.57546997070312, "report/model_loss_mean": 3671.14892578125, "report/model_loss_std": 156.42044067382812, "report/post_ent_mag": 106.16242980957031, "report/post_ent_max": 106.16242980957031, "report/post_ent_mean": 105.60135650634766, "report/post_ent_min": 104.92227172851562, "report/post_ent_std": 0.24596518278121948, "report/prior_ent_mag": 106.39079284667969, "report/prior_ent_max": 106.39079284667969, "report/prior_ent_mean": 105.57090759277344, "report/prior_ent_min": 104.55812072753906, "report/prior_ent_std": 0.2750870883464813, "report/rep_loss_mean": 10.897764205932617, "report/rep_loss_std": 0.4760935604572296, "report/reward_avg": 0.0126953125, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.548376738166553e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.6982113122940063, "eval/cont_loss_std": 0.29529619216918945, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.6151570081710815, "eval/cont_pos_acc": 0.5480391979217529, "eval/cont_pos_loss": 0.6985369324684143, "eval/cont_pred": 0.5175971984863281, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 10.968276023864746, "eval/dyn_loss_std": 0.513988733291626, "eval/image_loss_mean": 3641.881591796875, "eval/image_loss_std": 158.99832153320312, "eval/model_loss_mean": 3654.7021484375, "eval/model_loss_std": 158.9163055419922, "eval/post_ent_mag": 106.15005493164062, "eval/post_ent_max": 106.15005493164062, "eval/post_ent_mean": 105.57803344726562, "eval/post_ent_min": 105.00608825683594, "eval/post_ent_std": 0.2335117906332016, "eval/prior_ent_mag": 106.40425872802734, "eval/prior_ent_max": 106.40425872802734, "eval/prior_ent_mean": 105.50945281982422, "eval/prior_ent_min": 104.67391204833984, "eval/prior_ent_std": 0.2718556523323059, "eval/rep_loss_mean": 10.968276023864746, "eval/rep_loss_std": 0.513988733291626, "eval/reward_avg": 0.005468749441206455, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.009765625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 2.1103540454817587e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.621386119297572e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2776.0, "eval_replay/inserts": 2776.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.2281648707321124e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.749616895403181e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 229.8335075378418, "timer/env.step_count": 196.0, "timer/env.step_total": 26.749579668045044, "timer/env.step_frac": 0.11638677038264648, "timer/env.step_avg": 0.1364774472859441, "timer/env.step_min": 0.022594213485717773, "timer/env.step_max": 11.159441471099854, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.09623503684997559, "timer/replay._sample_frac": 0.0004187163041669658, "timer/replay._sample_avg": 0.0008592414004462105, "timer/replay._sample_min": 0.00033783912658691406, "timer/replay._sample_max": 0.005543708801269531, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.693628549575806, "timer/agent.save_frac": 0.042176741996507026, "timer/agent.save_avg": 9.693628549575806, "timer/agent.save_min": 9.693628549575806, "timer/agent.save_max": 9.693628549575806, "timer/agent.policy_count": 216.0, "timer/agent.policy_total": 22.3356831073761, "timer/agent.policy_frac": 0.0971820138266765, "timer/agent.policy_avg": 0.10340594031192639, "timer/agent.policy_min": 0.00966191291809082, "timer/agent.policy_max": 16.75726008415222, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.409385681152344e-05, "timer/dataset_train_frac": 1.4834154156529994e-07, "timer/dataset_train_avg": 3.409385681152344e-05, "timer/dataset_train_min": 3.409385681152344e-05, "timer/dataset_train_max": 3.409385681152344e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 89.67983293533325, "timer/agent.train_frac": 0.3901947714067218, "timer/agent.train_avg": 89.67983293533325, "timer/agent.train_min": 89.67983293533325, "timer/agent.train_max": 89.67983293533325, "timer/agent.report_count": 2.0, "timer/agent.report_total": 29.904586791992188, "timer/agent.report_frac": 0.13011412962519592, "timer/agent.report_avg": 14.952293395996094, "timer/agent.report_min": 7.166787385940552, "timer/agent.report_max": 22.737799406051636, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 1.6493919656561323e-07, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05}
{"step": 1704, "time": 327.1133415699005, "episode/length": 141.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 2168, "time": 346.03124928474426, "episode/length": 110.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 2176, "time": 348.1924526691437, "episode/length": 125.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 2336, "time": 355.77773785591125, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 2736, "time": 372.33558201789856, "episode/length": 49.0, "episode/score": -0.9000000208616257, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 2848, "time": 377.9794807434082, "episode/length": 192.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 2936, "time": 382.57573223114014, "episode/length": 222.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 2936, "time": 382.6185562610626, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 3024, "time": 389.53002762794495, "episode/length": 193.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 3088, "time": 393.47310853004456, "episode/length": 190.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 3648, "time": 416.3181266784668, "episode/length": 184.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 3992, "time": 431.2746136188507, "episode/length": 142.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 4016, "time": 433.967472076416, "episode/length": 229.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 4256, "time": 444.73598527908325, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 4336, "time": 449.8270709514618, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 4368, "time": 453.0223877429962, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 4704, "time": 468.22559809684753, "episode/length": 220.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 5032, "time": 482.4351146221161, "episode/length": 242.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 5096, "time": 486.57029366493225, "episode/length": 90.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 5312, "time": 496.40006279945374, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 5320, "time": 498.0863530635834, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 5328, "time": 500.26384973526, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 5512, "time": 508.43562746047974, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 6184, "time": 535.4982974529266, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 6192, "time": 538.0377893447876, "episode/length": 185.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 6208, "time": 540.7739524841309, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 6368, "time": 549.0140435695648, "episode/length": 131.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 6568, "time": 558.6996877193451, "episode/length": 154.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 6696, "time": 565.7231714725494, "episode/length": 171.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 6768, "time": 570.1599102020264, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 578.0474133491516, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 7456, "time": 600.27161860466, "episode/length": 157.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 7520, "time": 604.7425994873047, "episode/length": 163.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 7656, "time": 611.403395652771, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 7808, "time": 618.7975742816925, "episode/length": 179.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 8008, "time": 627.6335639953613, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 8040, "time": 630.5054137706757, "episode/length": 72.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9452054794520548, "episode/intrinsic_return": 0.0}
{"step": 8144, "time": 636.2303583621979, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 8264, "time": 643.1172339916229, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 8288, "time": 645.7929821014404, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 9072, "time": 676.5145719051361, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 9224, "time": 683.4397668838501, "episode/length": 134.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 9232, "time": 685.4406890869141, "episode/length": 177.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 9272, "time": 688.2683472633362, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 9424, "time": 695.8741221427917, "episode/length": 237.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 9584, "time": 703.3667778968811, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 9840, "time": 714.4561169147491, "episode/length": 193.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 10016, "time": 722.5678420066833, "episode/length": 218.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 745.404495716095, "eval_episode/length": 132.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9624060150375939}
{"step": 10088, "time": 747.8099675178528, "eval_episode/length": 153.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 10088, "time": 750.6900248527527, "eval_episode/length": 182.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 10088, "time": 752.5064134597778, "eval_episode/length": 189.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 10088, "time": 754.382420539856, "eval_episode/length": 199.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 10088, "time": 756.3980541229248, "eval_episode/length": 207.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 10088, "time": 758.4497878551483, "eval_episode/length": 217.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 10088, "time": 760.7428045272827, "eval_episode/length": 236.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9831223628691983}
{"step": 10280, "time": 767.830287694931, "episode/length": 125.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 10696, "time": 784.7785415649414, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 10704, "time": 787.0191388130188, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 10888, "time": 795.1537055969238, "episode/length": 226.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 10904, "time": 797.3107876777649, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 11344, "time": 815.891351222992, "episode/length": 219.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 11368, "time": 818.6428713798523, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 11488, "time": 825.4831347465515, "episode/length": 150.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 11856, "time": 841.699872970581, "episode/length": 229.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9869565217391304, "episode/intrinsic_return": 0.0}
{"step": 12136, "time": 854.4680643081665, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 12336, "time": 864.445809841156, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 12528, "time": 873.8183569908142, "episode/length": 227.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 12568, "time": 877.2419857978821, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 12672, "time": 883.5724778175354, "episode/length": 222.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 12936, "time": 895.4202511310577, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 12952, "time": 897.9943659305573, "episode/length": 101.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 13136, "time": 907.374142408371, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 13432, "time": 920.5395693778992, "episode/length": 196.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 13776, "time": 936.0205950737, "episode/length": 155.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 941.074533700943, "episode/length": 191.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 14000, "time": 947.3957741260529, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 14256, "time": 958.4512367248535, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 14344, "time": 963.1328139305115, "episode/length": 58.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 14544, "time": 972.487300157547, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 14560, "time": 974.65540599823, "episode/length": 200.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 14808, "time": 985.2986748218536, "episode/length": 208.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 15104, "time": 998.2899193763733, "episode/length": 208.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 15320, "time": 1007.7828178405762, "episode/length": 121.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 15568, "time": 1018.763258934021, "episode/length": 127.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 15712, "time": 1025.7533769607544, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 15784, "time": 1029.8049585819244, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 15840, "time": 1033.5155653953552, "episode/length": 257.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 15968, "time": 1039.7261145114899, "episode/length": 245.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 16336, "time": 1054.8156640529633, "episode/length": 190.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 16672, "time": 1070.2839612960815, "episode/length": 168.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 17016, "time": 1084.4474699497223, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 17064, "time": 1088.047533750534, "episode/length": 244.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 17144, "time": 1092.5294859409332, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 17280, "time": 1099.477594614029, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 17432, "time": 1106.470806837082, "episode/length": 214.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 17568, "time": 1113.3826386928558, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 17728, "time": 1121.0347199440002, "episode/length": 55.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 17824, "time": 1126.0332744121552, "episode/length": 247.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 18072, "time": 1136.4355192184448, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 18304, "time": 1146.829907655716, "episode/length": 71.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.0}
{"step": 18336, "time": 1149.470721244812, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 18392, "time": 1152.938146352768, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 18600, "time": 1162.2146744728088, "episode/length": 128.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.0}
{"step": 18704, "time": 1167.8490204811096, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 18744, "time": 1170.5818965435028, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 19176, "time": 1188.0273268222809, "episode/length": 58.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 19376, "time": 1197.151349067688, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 19480, "time": 1202.3631701469421, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 19544, "time": 1206.4116027355194, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 19648, "time": 1212.0165333747864, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 19704, "time": 1215.462910413742, "episode/length": 119.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 19760, "time": 1219.3223729133606, "episode/length": 170.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 19912, "time": 1226.3898317813873, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1250.8477833271027, "eval_episode/length": 85.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9302325581395349}
{"step": 20072, "time": 1254.0872428417206, "eval_episode/length": 124.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.968}
{"step": 20072, "time": 1257.0607101917267, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.967948717948718}
{"step": 20072, "time": 1257.1012287139893, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 20072, "time": 1260.909351348877, "eval_episode/length": 165.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 20072, "time": 1262.794983625412, "eval_episode/length": 172.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 20072, "time": 1264.681421995163, "eval_episode/length": 179.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 20072, "time": 1266.9105973243713, "eval_episode/length": 192.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 20104, "time": 1268.0889003276825, "episode/length": 49.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 20568, "time": 1286.7851901054382, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 20665, "time": 1292.9525446891785, "train_stats/sum_log_reward": 1.035185166048231, "train_stats/max_log_achievement_collect_drink": 2.425925925925926, "train_stats/max_log_achievement_collect_sapling": 9.898148148148149, "train_stats/max_log_achievement_collect_wood": 0.24074074074074073, "train_stats/max_log_achievement_eat_cow": 0.10185185185185185, "train_stats/max_log_achievement_place_plant": 0.3888888888888889, "train_stats/max_log_achievement_wake_up": 0.6666666666666666, "train_stats/mean_log_entropy": 0.9885534477868566, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.87224008255646, "train/action_min": 0.0, "train/action_std": 2.0237094805020246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007072688816281568, "train/actor_opt_grad_steps": 600.0, "train/actor_opt_loss": 206.8624241552433, "train/adv_mag": 2.115557580998465, "train/adv_max": 2.115022548169148, "train/adv_mean": 0.03089190835250743, "train/adv_min": -0.3310448887576485, "train/adv_std": 0.15969880560349933, "train/cont_avg": 0.9944852941176471, "train/cont_loss_mean": 0.029443205021196555, "train/cont_loss_std": 0.267610219346375, "train/cont_neg_acc": 0.05349230728730434, "train/cont_neg_loss": 3.453286662823012, "train/cont_pos_acc": 0.9965970616380707, "train/cont_pos_loss": 0.010511416214040848, "train/cont_pred": 0.9908665118097257, "train/cont_rate": 0.9944852941176471, "train/dyn_loss_mean": 5.340798697551759, "train/dyn_loss_std": 8.036063036497902, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.682864496687881, "train/extr_critic_critic_opt_grad_steps": 600.0, "train/extr_critic_critic_opt_loss": 21434.339860162814, "train/extr_critic_mag": 0.26476096305526603, "train/extr_critic_max": 0.26476096105174857, "train/extr_critic_mean": 0.1011365569672167, "train/extr_critic_min": -0.005479068315329672, "train/extr_critic_std": 0.06752399870996358, "train/extr_return_normed_mag": 2.4023638625608714, "train/extr_return_normed_max": 2.4023638607072724, "train/extr_return_normed_mean": 0.18599669867219001, "train/extr_return_normed_min": -0.20587295989003246, "train/extr_return_normed_std": 0.1984095775149125, "train/extr_return_rate": 0.04015997236463957, "train/extr_return_raw_mag": 2.348575644189063, "train/extr_return_raw_max": 2.3485756421915625, "train/extr_return_raw_mean": 0.13202827329619707, "train/extr_return_raw_min": -0.2598591881857483, "train/extr_return_raw_std": 0.19842223916619026, "train/extr_reward_mag": 0.5280184355102667, "train/extr_reward_max": 0.5280184355102667, "train/extr_reward_mean": 0.008384131724214814, "train/extr_reward_min": -0.0542383795024968, "train/extr_reward_std": 0.03697604079293447, "train/image_loss_mean": 100.4393969463701, "train/image_loss_std": 53.15465311643456, "train/model_loss_mean": 104.0172551579836, "train/model_loss_std": 54.70128274965687, "train/model_opt_grad_norm": 308.3911552429199, "train/model_opt_grad_steps": 590.0, "train/model_opt_loss": 1365.1928501930558, "train/model_opt_model_opt_grad_overflow": 0.008403361344537815, "train/model_opt_model_opt_grad_scale": 11.242778361344538, "train/policy_entropy_mag": 1.2035280683962237, "train/policy_entropy_max": 1.2035280683962237, "train/policy_entropy_mean": 0.9154520391040489, "train/policy_entropy_min": 0.8113889779989459, "train/policy_entropy_std": 0.04538547045731244, "train/policy_logprob_mag": 6.725973009061413, "train/policy_logprob_max": -0.41128785306384336, "train/policy_logprob_mean": -0.9149038458571714, "train/policy_logprob_min": -6.725973009061413, "train/policy_logprob_std": 0.7265650013915631, "train/policy_randomness_mag": 0.4247925904493372, "train/policy_randomness_max": 0.4247925904493372, "train/policy_randomness_mean": 0.3231143921832828, "train/policy_randomness_min": 0.28638470388886306, "train/policy_randomness_std": 0.016019079533646258, "train/post_ent_mag": 51.082375406217174, "train/post_ent_max": 51.082375406217174, "train/post_ent_mean": 32.3560722896031, "train/post_ent_min": 16.641269046719334, "train/post_ent_std": 6.82729720192797, "train/prior_ent_mag": 57.64784904287643, "train/prior_ent_max": 57.64784904287643, "train/prior_ent_mean": 38.32710179561327, "train/prior_ent_min": 21.266060220093287, "train/prior_ent_std": 6.41666649776597, "train/rep_loss_mean": 5.340798697551759, "train/rep_loss_std": 8.036063036497902, "train/reward_avg": 0.008264672994308424, "train/reward_loss_mean": 0.34393761526135835, "train/reward_loss_std": 0.6761717861850812, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.6729556021570158, "train/reward_neg_acc": 0.9961577183058282, "train/reward_neg_loss": 0.3042872820143439, "train/reward_pos_acc": 0.4439024732393377, "train/reward_pos_loss": 3.1885070976089027, "train/reward_pred": 0.006100013564505121, "train/reward_rate": 0.013130252100840336, "train_stats/max_log_achievement_place_table": 0.06315789473684211, "train_stats/max_log_achievement_defeat_zombie": 0.32786885245901637, "eval_stats/sum_log_reward": 0.7874999893829226, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 16.4375, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.023603081703186035, "report/cont_loss_std": 0.20953358709812164, "report/cont_neg_acc": 0.1111111119389534, "report/cont_neg_loss": 1.997275471687317, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006102537736296654, "report/cont_pred": 0.9922682642936707, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 6.372929573059082, "report/dyn_loss_std": 5.847421169281006, "report/image_loss_mean": 22.1854190826416, "report/image_loss_std": 15.427716255187988, "report/model_loss_mean": 26.185232162475586, "report/model_loss_std": 17.125377655029297, "report/post_ent_mag": 45.05743408203125, "report/post_ent_max": 45.05743408203125, "report/post_ent_mean": 30.32816505432129, "report/post_ent_min": 14.904426574707031, "report/post_ent_std": 3.6021804809570312, "report/prior_ent_mag": 51.41652297973633, "report/prior_ent_max": 51.41652297973633, "report/prior_ent_mean": 37.5256462097168, "report/prior_ent_min": 20.033788681030273, "report/prior_ent_std": 4.013808250427246, "report/rep_loss_mean": 6.372929573059082, "report/rep_loss_std": 5.847421169281006, "report/reward_avg": 0.0064453124068677425, "report/reward_loss_mean": 0.15245042741298676, "report/reward_loss_std": 0.5968149900436401, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9716719388961792, "report/reward_neg_acc": 0.9960356950759888, "report/reward_neg_loss": 0.12234137952327728, "report/reward_pos_acc": 0.7333333492279053, "report/reward_pos_loss": 2.177785873413086, "report/reward_pred": 0.005933277774602175, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.035977788269519806, "eval/cont_loss_std": 0.6633975505828857, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.273443222045898, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0500483515206724e-05, "eval/cont_pred": 0.999979555606842, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 8.987151145935059, "eval/dyn_loss_std": 7.534479141235352, "eval/image_loss_mean": 71.52850341796875, "eval/image_loss_std": 53.37105941772461, "eval/model_loss_mean": 77.1447525024414, "eval/model_loss_std": 54.89447021484375, "eval/post_ent_mag": 46.189598083496094, "eval/post_ent_max": 46.189598083496094, "eval/post_ent_mean": 30.756160736083984, "eval/post_ent_min": 14.32677936553955, "eval/post_ent_std": 6.097385883331299, "eval/prior_ent_mag": 55.049034118652344, "eval/prior_ent_max": 55.049034118652344, "eval/prior_ent_mean": 37.67245864868164, "eval/prior_ent_min": 18.360151290893555, "eval/prior_ent_std": 6.109042167663574, "eval/rep_loss_mean": 8.987151145935059, "eval/rep_loss_std": 7.534479141235352, "eval/reward_avg": 0.01396484486758709, "eval/reward_loss_mean": 0.1879812777042389, "eval/reward_loss_std": 1.142019271850586, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9835852384567261, "eval/reward_neg_acc": 0.9970208406448364, "eval/reward_neg_loss": 0.14980529248714447, "eval/reward_pos_acc": 0.7058823704719543, "eval/reward_pos_loss": 2.4493465423583984, "eval/reward_pred": 0.010717583820223808, "eval/reward_rate": 0.0166015625, "replay/size": 20161.0, "replay/inserts": 19104.0, "replay/samples": 19104.0, "replay/insert_wait_avg": 1.5015228709184144e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.269046424022272e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6216.0, "eval_replay/inserts": 3440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1950038200200991e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 970.8793838024139, "timer/env.step_count": 2388.0, "timer/env.step_total": 247.51182103157043, "timer/env.step_frac": 0.2549357058774895, "timer/env.step_avg": 0.10364816626112665, "timer/env.step_min": 0.023471355438232422, "timer/env.step_max": 3.419332504272461, "timer/replay._sample_count": 19104.0, "timer/replay._sample_total": 10.094260215759277, "timer/replay._sample_frac": 0.010397028080074656, "timer/replay._sample_avg": 0.0005283846427847192, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.021971940994262695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2818.0, "timer/agent.policy_total": 48.642528772354126, "timer/agent.policy_frac": 0.050101515784429805, "timer/agent.policy_avg": 0.017261365781530917, "timer/agent.policy_min": 0.009602546691894531, "timer/agent.policy_max": 0.10817790031433105, "timer/dataset_train_count": 1194.0, "timer/dataset_train_total": 0.14277410507202148, "timer/dataset_train_frac": 0.00014705648039703127, "timer/dataset_train_avg": 0.00011957630240537813, "timer/dataset_train_min": 7.915496826171875e-05, "timer/dataset_train_max": 0.00043582916259765625, "timer/agent.train_count": 1194.0, "timer/agent.train_total": 535.1258075237274, "timer/agent.train_frac": 0.5511764040430301, "timer/agent.train_avg": 0.44817906827782866, "timer/agent.train_min": 0.43352317810058594, "timer/agent.train_max": 0.8673293590545654, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47342991828918457, "timer/agent.report_frac": 0.0004876300044965559, "timer/agent.report_avg": 0.23671495914459229, "timer/agent.report_min": 0.23095011711120605, "timer/agent.report_max": 0.24247980117797852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 3.045064536524382e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 19.676788177365214}
{"step": 20720, "time": 1295.0212585926056, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 20912, "time": 1303.7306451797485, "episode/length": 191.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 21232, "time": 1316.9225869178772, "episode/length": 63.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 21256, "time": 1319.1331586837769, "episode/length": 186.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 21328, "time": 1323.711529970169, "episode/length": 209.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 21448, "time": 1329.6335635185242, "episode/length": 191.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 21488, "time": 1332.8770773410797, "episode/length": 242.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 21728, "time": 1343.1494011878967, "episode/length": 202.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 22072, "time": 1357.2206990718842, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 22176, "time": 1362.8463912010193, "episode/length": 55.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 22552, "time": 1378.0772750377655, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 22592, "time": 1381.4556200504303, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 22600, "time": 1383.1292834281921, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 22616, "time": 1385.2202243804932, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 22616, "time": 1385.2568409442902, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 23160, "time": 1408.6799294948578, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 23368, "time": 1418.002988576889, "episode/length": 148.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 23384, "time": 1420.2030560970306, "episode/length": 241.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 23760, "time": 1435.794790506363, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 23792, "time": 1438.5765714645386, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 23944, "time": 1445.5751700401306, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 24176, "time": 1455.864180803299, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 24256, "time": 1460.3889136314392, "episode/length": 206.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 24416, "time": 1467.8011510372162, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 24544, "time": 1474.1039855480194, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 24680, "time": 1481.8759434223175, "episode/length": 163.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 24896, "time": 1491.6842007637024, "episode/length": 137.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 25040, "time": 1498.4911782741547, "episode/length": 159.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 25360, "time": 1511.7653548717499, "episode/length": 137.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 25376, "time": 1513.8199272155762, "episode/length": 149.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 25568, "time": 1522.688315629959, "episode/length": 143.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 25664, "time": 1527.8055663108826, "episode/length": 139.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 25808, "time": 1534.685097694397, "episode/length": 232.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 26120, "time": 1547.5738623142242, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 26488, "time": 1562.8081834316254, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 26656, "time": 1571.5797398090363, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 26672, "time": 1574.2126111984253, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 26792, "time": 1580.5590686798096, "episode/length": 236.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 26856, "time": 1584.95339179039, "episode/length": 186.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 26928, "time": 1589.3101377487183, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 27112, "time": 1597.44180727005, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 27552, "time": 1615.4336426258087, "episode/length": 86.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 27808, "time": 1626.5040550231934, "episode/length": 210.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 27808, "time": 1626.5436086654663, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 28120, "time": 1641.2090754508972, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 28200, "time": 1645.5464391708374, "episode/length": 175.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 28368, "time": 1653.4693732261658, "episode/length": 156.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 28424, "time": 1656.9104869365692, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 28952, "time": 1678.27898812294, "episode/length": 142.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 29088, "time": 1685.1201798915863, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 29200, "time": 1690.9411923885345, "episode/length": 134.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 29288, "time": 1695.4850704669952, "episode/length": 349.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 29552, "time": 1706.987426519394, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 29608, "time": 1710.3914182186127, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 29720, "time": 1716.0942723751068, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 29728, "time": 1718.1635105609894, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1746.0345113277435, "eval_episode/length": 38.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 30056, "time": 1751.937361240387, "eval_episode/length": 149.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 30056, "time": 1753.7749931812286, "eval_episode/length": 152.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 30056, "time": 1756.4446167945862, "eval_episode/length": 178.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 30056, "time": 1758.2430753707886, "eval_episode/length": 182.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 30056, "time": 1761.9084725379944, "eval_episode/length": 203.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 30056, "time": 1763.9243149757385, "eval_episode/length": 175.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 30056, "time": 1765.8373727798462, "eval_episode/length": 223.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 30488, "time": 1781.7871360778809, "episode/length": 149.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 30496, "time": 1783.9185750484467, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 30608, "time": 1789.7123143672943, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 30744, "time": 1796.133781671524, "episode/length": 148.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 30824, "time": 1800.661256313324, "episode/length": 151.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 31016, "time": 1809.5073812007904, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 31024, "time": 1812.0211691856384, "episode/length": 227.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 31120, "time": 1817.7561657428741, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 31520, "time": 1834.5951137542725, "episode/length": 61.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 31728, "time": 1843.907716035843, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 31816, "time": 1848.5430777072906, "episode/length": 99.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 31920, "time": 1854.107343196869, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 32080, "time": 1861.5655965805054, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 32232, "time": 1869.1128377914429, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 32248, "time": 1871.62792801857, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 32592, "time": 1886.7127740383148, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 32808, "time": 1897.0056474208832, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 32912, "time": 1902.6046562194824, "episode/length": 147.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 33352, "time": 1919.9539556503296, "episode/length": 158.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 33384, "time": 1922.712142944336, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 33416, "time": 1925.5973341464996, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 33568, "time": 1932.952493429184, "episode/length": 205.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 33728, "time": 1940.5496804714203, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 33768, "time": 1943.8434495925903, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 34056, "time": 1956.5242364406586, "episode/length": 142.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 34056, "time": 1956.5673258304596, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 34136, "time": 1962.9238605499268, "episode/length": 165.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 34384, "time": 1973.797192811966, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 34600, "time": 1982.985907793045, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 34712, "time": 1988.762625694275, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 35224, "time": 2009.036681652069, "episode/length": 145.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 35256, "time": 2011.94313621521, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 35288, "time": 2014.6491470336914, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 35592, "time": 2027.4085268974304, "episode/length": 252.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 35600, "time": 2029.5704627037048, "episode/length": 280.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 35664, "time": 2033.4619710445404, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 36568, "time": 2067.8997571468353, "episode/length": 245.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 36608, "time": 2071.1247251033783, "episode/length": 168.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 36616, "time": 2072.7452943325043, "episode/length": 237.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 36816, "time": 2081.932177066803, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 36856, "time": 2084.7611680030823, "episode/length": 35.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 36856, "time": 2084.801381111145, "episode/length": 148.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 37200, "time": 2100.9412088394165, "episode/length": 200.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 37344, "time": 2107.909262418747, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 37608, "time": 2118.8460721969604, "episode/length": 297.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 38072, "time": 2137.4479048252106, "episode/length": 151.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 38120, "time": 2140.7596428394318, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 38152, "time": 2143.529239654541, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 38536, "time": 2159.227837085724, "episode/length": 148.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 38672, "time": 2165.9748401641846, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 38672, "time": 2166.0100858211517, "episode/length": 256.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 39072, "time": 2183.848743200302, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 39448, "time": 2199.2924494743347, "episode/length": 96.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9587628865979382, "episode/intrinsic_return": 0.0}
{"step": 39512, "time": 2203.2086789608, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 39560, "time": 2206.61022400856, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 39672, "time": 2212.3191125392914, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 39728, "time": 2216.2150208950043, "episode/length": 196.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 39784, "time": 2219.578223466873, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 39984, "time": 2228.787163734436, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2247.0318920612335, "eval_episode/length": 52.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 40040, "time": 2252.081258535385, "eval_episode/length": 144.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993103448275862}
{"step": 40040, "time": 2253.867885828018, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 40040, "time": 2255.561230659485, "eval_episode/length": 151.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 40040, "time": 2257.5770773887634, "eval_episode/length": 161.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 40040, "time": 2259.5096378326416, "eval_episode/length": 172.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 40040, "time": 2261.6379561424255, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 40040, "time": 2264.51700091362, "eval_episode/length": 218.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 40584, "time": 2284.2612500190735, "episode/length": 99.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 40584, "time": 2284.3027908802032, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 40632, "time": 2289.4776680469513, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 40664, "time": 2292.2301399707794, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 40665, "time": 2294.877514362335, "train_stats/sum_log_reward": 2.1168066506125345, "train_stats/max_log_achievement_collect_drink": 2.0756302521008405, "train_stats/max_log_achievement_collect_sapling": 3.865546218487395, "train_stats/max_log_achievement_collect_wood": 0.10084033613445378, "train_stats/max_log_achievement_defeat_zombie": 0.10084033613445378, "train_stats/max_log_achievement_eat_cow": 0.15126050420168066, "train_stats/max_log_achievement_place_plant": 2.033613445378151, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.092436974789916, "train_stats/mean_log_entropy": 0.23230193242305466, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.5167216796875, "train/action_min": 0.0, "train/action_std": 2.3898518834114073, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0397140163006261, "train/actor_opt_grad_steps": 1820.0, "train/actor_opt_loss": 44.081798584222796, "train/adv_mag": 2.2697601981163027, "train/adv_max": 2.2697601981163027, "train/adv_mean": 0.026372050759382547, "train/adv_min": -0.6000895643234253, "train/adv_std": 0.17449289417266844, "train/cont_avg": 0.9943671875, "train/cont_loss_mean": 0.006419673204683931, "train/cont_loss_std": 0.08448193852556869, "train/cont_neg_acc": 0.6946254042387009, "train/cont_neg_loss": 0.8091213052971289, "train/cont_pos_acc": 0.9996383366584778, "train/cont_pos_loss": 0.00194686431674927, "train/cont_pred": 0.9945336213111877, "train/cont_rate": 0.9943671875, "train/dyn_loss_mean": 6.355014949798584, "train/dyn_loss_std": 5.96612712097168, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5288273887634278, "train/extr_critic_critic_opt_grad_steps": 1820.0, "train/extr_critic_critic_opt_loss": 18778.6480859375, "train/extr_critic_mag": 1.4791107749938965, "train/extr_critic_max": 1.4791107749938965, "train/extr_critic_mean": 0.3891472154073417, "train/extr_critic_min": -0.3790789165496826, "train/extr_critic_std": 0.5714808888435364, "train/extr_return_normed_mag": 3.025368638038635, "train/extr_return_normed_max": 3.025368638038635, "train/extr_return_normed_mean": 0.41621948540210724, "train/extr_return_normed_min": -0.3042593310177326, "train/extr_return_normed_std": 0.37493398225307467, "train/extr_return_rate": 0.3777713742852211, "train/extr_return_raw_mag": 5.319214876174927, "train/extr_return_raw_max": 5.319214876174927, "train/extr_return_raw_mean": 0.4397980069904588, "train/extr_return_raw_min": -0.9264728391170501, "train/extr_return_raw_std": 0.7189620516300201, "train/extr_reward_mag": 0.9932167558670044, "train/extr_reward_max": 0.9932167558670044, "train/extr_reward_mean": 0.01700719768262934, "train/extr_reward_min": -0.3499860134124756, "train/extr_reward_std": 0.09886299338936806, "train/image_loss_mean": 16.880836936950683, "train/image_loss_std": 15.079252578735352, "train/model_loss_mean": 20.782182525634767, "train/model_loss_std": 16.917876136779785, "train/model_opt_grad_norm": 127.26507601928711, "train/model_opt_grad_steps": 1810.0, "train/model_opt_loss": 531.0968913574219, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 26.25, "train/policy_entropy_mag": 1.6364764080047607, "train/policy_entropy_max": 1.6364764080047607, "train/policy_entropy_mean": 0.25558526438474655, "train/policy_entropy_min": 0.0799228298664093, "train/policy_entropy_std": 0.2556113368496299, "train/policy_logprob_mag": 7.4367783164978025, "train/policy_logprob_max": -0.009533272817730904, "train/policy_logprob_mean": -0.2551525416970253, "train/policy_logprob_min": -7.4367783164978025, "train/policy_logprob_std": 0.8917290906906128, "train/policy_randomness_mag": 0.5776043596863747, "train/policy_randomness_max": 0.5776043596863747, "train/policy_randomness_mean": 0.0902103822529316, "train/policy_randomness_min": 0.028209251686930656, "train/policy_randomness_std": 0.09021958519145847, "train/post_ent_mag": 41.50493240356445, "train/post_ent_max": 41.50493240356445, "train/post_ent_mean": 30.04561489868164, "train/post_ent_min": 13.39490119934082, "train/post_ent_std": 4.498007995605469, "train/prior_ent_mag": 53.085794830322264, "train/prior_ent_max": 53.085794830322264, "train/prior_ent_mean": 36.600176513671876, "train/prior_ent_min": 16.776978576660156, "train/prior_ent_std": 5.5680859088897705, "train/rep_loss_mean": 6.355014949798584, "train/rep_loss_std": 5.96612712097168, "train/reward_avg": 0.008296874979510904, "train/reward_loss_mean": 0.08191681721806526, "train/reward_loss_std": 0.395606419801712, "train/reward_max_data": 1.0016000003814698, "train/reward_max_pred": 0.9922734851837158, "train/reward_neg_acc": 0.9959173979759216, "train/reward_neg_loss": 0.06316152708232403, "train/reward_pos_acc": 0.8466565551757812, "train/reward_pos_loss": 1.4743119897842407, "train/reward_pred": 0.007581288634799421, "train/reward_rate": 0.013359375, "eval_stats/sum_log_reward": 2.412499912083149, "eval_stats/max_log_achievement_collect_drink": 8.625, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.005356457084417343, "report/cont_loss_std": 0.08591286092996597, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.10941249132156372, "report/cont_pos_acc": 0.998033344745636, "report/cont_pos_loss": 0.0046402402222156525, "report/cont_pred": 0.991040050983429, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.051724433898926, "report/dyn_loss_std": 6.649413108825684, "report/image_loss_mean": 14.916155815124512, "report/image_loss_std": 14.792168617248535, "report/model_loss_mean": 19.218814849853516, "report/model_loss_std": 17.30093002319336, "report/post_ent_mag": 42.75181198120117, "report/post_ent_max": 42.75181198120117, "report/post_ent_mean": 30.115070343017578, "report/post_ent_min": 11.721708297729492, "report/post_ent_std": 5.6991190910339355, "report/prior_ent_mag": 53.06511688232422, "report/prior_ent_max": 53.06511688232422, "report/prior_ent_mean": 36.02425003051758, "report/prior_ent_min": 15.405525207519531, "report/prior_ent_std": 7.065755844116211, "report/rep_loss_mean": 7.051724433898926, "report/rep_loss_std": 6.649413108825684, "report/reward_avg": 0.01357421837747097, "report/reward_loss_mean": 0.06626783311367035, "report/reward_loss_std": 0.3420674502849579, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9971822500228882, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.04409785941243172, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 1.3053234815597534, "report/reward_pred": 0.010230876505374908, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0001580831885803491, "eval/cont_loss_std": 0.0017563555156812072, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0035714793484658003, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0001514033501734957, "eval/cont_pred": 0.9979042410850525, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 11.174087524414062, "eval/dyn_loss_std": 7.433376312255859, "eval/image_loss_mean": 58.64605712890625, "eval/image_loss_std": 50.78626251220703, "eval/model_loss_mean": 65.42327117919922, "eval/model_loss_std": 52.396385192871094, "eval/post_ent_mag": 43.535133361816406, "eval/post_ent_max": 43.535133361816406, "eval/post_ent_mean": 30.062252044677734, "eval/post_ent_min": 15.728796005249023, "eval/post_ent_std": 6.106241703033447, "eval/prior_ent_mag": 58.009498596191406, "eval/prior_ent_max": 58.009498596191406, "eval/prior_ent_mean": 36.340980529785156, "eval/prior_ent_min": 18.40675926208496, "eval/prior_ent_std": 7.734614849090576, "eval/rep_loss_mean": 11.174087524414062, "eval/rep_loss_std": 7.433376312255859, "eval/reward_avg": 0.01972656324505806, "eval/reward_loss_mean": 0.07260077446699142, "eval/reward_loss_std": 0.5154532790184021, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9958393573760986, "eval/reward_neg_acc": 0.9980040192604065, "eval/reward_neg_loss": 0.016658473759889603, "eval/reward_pos_acc": 0.5909091234207153, "eval/reward_pos_loss": 2.620518684387207, "eval/reward_pred": 0.009352516382932663, "eval/reward_rate": 0.021484375, "replay/size": 40161.0, "replay/inserts": 20000.0, "replay/samples": 20000.0, "replay/insert_wait_avg": 1.4739751815795898e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.477376937866211e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9760.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.134977383753516e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.9127032756805, "timer/env.step_count": 2500.0, "timer/env.step_total": 260.9800326824188, "timer/env.step_frac": 0.26048180827447703, "timer/env.step_avg": 0.10439201307296753, "timer/env.step_min": 0.023641347885131836, "timer/env.step_max": 3.5031542778015137, "timer/replay._sample_count": 20000.0, "timer/replay._sample_total": 10.281265020370483, "timer/replay._sample_frac": 0.01026163755260976, "timer/replay._sample_avg": 0.0005140632510185242, "timer/replay._sample_min": 0.00036406517028808594, "timer/replay._sample_max": 0.022858858108520508, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2943.0, "timer/agent.policy_total": 50.33173370361328, "timer/agent.policy_frac": 0.05023564781548068, "timer/agent.policy_avg": 0.017102186103844133, "timer/agent.policy_min": 0.009327888488769531, "timer/agent.policy_max": 0.11897110939025879, "timer/dataset_train_count": 1250.0, "timer/dataset_train_total": 0.14716529846191406, "timer/dataset_train_frac": 0.00014688435228016157, "timer/dataset_train_avg": 0.00011773223876953125, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.0005614757537841797, "timer/agent.train_count": 1250.0, "timer/agent.train_total": 556.1328344345093, "timer/agent.train_frac": 0.5550711480314338, "timer/agent.train_avg": 0.4449062675476074, "timer/agent.train_min": 0.43343043327331543, "timer/agent.train_max": 0.8055083751678467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4728879928588867, "timer/agent.report_frac": 0.0004719852251726262, "timer/agent.report_avg": 0.23644399642944336, "timer/agent.report_min": 0.23022150993347168, "timer/agent.report_max": 0.24266648292541504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.736579395294429e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 19.961572755040677}
{"step": 40688, "time": 2295.6679050922394, "episode/length": 6.0, "episode/score": -0.8999999761581421, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 40872, "time": 2303.797417640686, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 40936, "time": 2307.740571975708, "episode/length": 30.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 41120, "time": 2317.5945014953613, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 41240, "time": 2323.3167264461517, "episode/length": 37.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 41512, "time": 2334.6639840602875, "episode/length": 229.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 41520, "time": 2336.7989869117737, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 42088, "time": 2358.9410815238953, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 42344, "time": 2369.78599357605, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 42416, "time": 2374.268659353256, "episode/length": 192.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 42592, "time": 2382.354817867279, "episode/length": 250.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 42616, "time": 2384.510160446167, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 42680, "time": 2388.411036014557, "episode/length": 251.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 42856, "time": 2396.4603011608124, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 43032, "time": 2404.440704345703, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 43072, "time": 2407.8964960575104, "episode/length": 228.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 43336, "time": 2418.819771051407, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 43872, "time": 2440.266684770584, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 44000, "time": 2446.537478685379, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 44072, "time": 2450.566196680069, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 44160, "time": 2455.6009027957916, "episode/length": 195.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 44168, "time": 2457.2340655326843, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 44584, "time": 2474.195821046829, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 44672, "time": 2479.2557561397552, "episode/length": 199.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 45040, "time": 2494.269266605377, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 45144, "time": 2499.4558148384094, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 45216, "time": 2503.9443385601044, "episode/length": 234.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659574468085106, "episode/intrinsic_return": 0.0}
{"step": 45296, "time": 2508.434965133667, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 45296, "time": 2508.4735019207, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 45896, "time": 2533.755413532257, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 45904, "time": 2535.861482858658, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 45936, "time": 2538.5319471359253, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 46264, "time": 2551.9683933258057, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 46584, "time": 2565.360725402832, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 46720, "time": 2572.1289880275726, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 46728, "time": 2573.8549251556396, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9553072625698324, "episode/intrinsic_return": 0.0}
{"step": 46968, "time": 2584.2358384132385, "episode/length": 30.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 47184, "time": 2594.206191778183, "episode/length": 245.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 47464, "time": 2605.812241792679, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 47536, "time": 2610.4135365486145, "episode/length": 203.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 47544, "time": 2612.1199235916138, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 47584, "time": 2615.476212978363, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 47808, "time": 2625.2717094421387, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 48152, "time": 2639.260438680649, "episode/length": 177.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 48432, "time": 2651.447245359421, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 48896, "time": 2670.2578027248383, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 48928, "time": 2672.9562928676605, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 48984, "time": 2676.5309648513794, "episode/length": 224.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 49008, "time": 2679.2562363147736, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 49096, "time": 2683.933179616928, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 49272, "time": 2693.9818387031555, "episode/length": 182.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 49336, "time": 2697.933869600296, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 49488, "time": 2705.2670464515686, "episode/length": 73.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 49704, "time": 2714.4908311367035, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 50000, "time": 2727.1404917240143, "episode/length": 133.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2745.691471338272, "eval_episode/length": 72.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9315068493150684}
{"step": 50024, "time": 2748.972383737564, "eval_episode/length": 101.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9509803921568627}
{"step": 50024, "time": 2754.271593809128, "eval_episode/length": 170.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 50024, "time": 2757.0375242233276, "eval_episode/length": 184.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 50024, "time": 2759.111786365509, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 50024, "time": 2761.676739215851, "eval_episode/length": 198.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 50024, "time": 2763.974666595459, "eval_episode/length": 205.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 50024, "time": 2767.053056716919, "eval_episode/length": 223.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 50096, "time": 2770.017889022827, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 50392, "time": 2782.8905522823334, "episode/length": 131.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 50408, "time": 2785.586913585663, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 50576, "time": 2794.2419176101685, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 50752, "time": 2803.0162377357483, "episode/length": 184.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 50824, "time": 2807.662984609604, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 50912, "time": 2812.7638700008392, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 51336, "time": 2829.8911945819855, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 51648, "time": 2843.3428144454956, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 51736, "time": 2847.939850330353, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 51928, "time": 2856.784430742264, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 52136, "time": 2865.9588792324066, "episode/length": 49.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 52336, "time": 2875.1027286052704, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 52368, "time": 2877.869292974472, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 52384, "time": 2880.0846490859985, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 52512, "time": 2886.733605861664, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 52816, "time": 2899.58101439476, "episode/length": 302.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 53200, "time": 2915.417501926422, "episode/length": 107.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 53416, "time": 2924.770958185196, "episode/length": 159.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 53560, "time": 2931.754734516144, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 53560, "time": 2931.789852619171, "episode/length": 238.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 53696, "time": 2940.3960106372833, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 54048, "time": 2955.0593876838684, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 54056, "time": 2956.7686908245087, "episode/length": 210.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 54152, "time": 2961.838223218918, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 54176, "time": 2964.5308849811554, "episode/length": 76.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 54344, "time": 2972.030577659607, "episode/length": 142.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 54600, "time": 2983.112694501877, "episode/length": 67.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 54672, "time": 2987.487321138382, "episode/length": 138.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 55056, "time": 3003.2803149223328, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 55112, "time": 3006.8744299411774, "episode/length": 211.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 55832, "time": 3035.611814022064, "episode/length": 209.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 55848, "time": 3038.2232451438904, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 55880, "time": 3041.434847354889, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 55920, "time": 3044.666779279709, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 56064, "time": 3051.538358926773, "episode/length": 235.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 56064, "time": 3051.583247423172, "episode/length": 182.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 56360, "time": 3065.8421533107758, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 56480, "time": 3072.043112039566, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 57120, "time": 3097.178431034088, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 57320, "time": 3106.113441467285, "episode/length": 156.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 57336, "time": 3108.2787330150604, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 57360, "time": 3112.2553231716156, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 57488, "time": 3118.5649843215942, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 57592, "time": 3123.7794239521027, "episode/length": 33.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 57744, "time": 3131.3734652996063, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 57744, "time": 3131.4115204811096, "episode/length": 232.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 57912, "time": 3140.8206708431244, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 58032, "time": 3147.1132538318634, "episode/length": 193.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 58304, "time": 3158.813681602478, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 58568, "time": 3169.9824364185333, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 59024, "time": 3188.831665277481, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 59312, "time": 3200.978664636612, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 59376, "time": 3204.828022480011, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 59416, "time": 3207.597585439682, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 59520, "time": 3213.1440880298615, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 59696, "time": 3221.315536737442, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3248.848539829254, "eval_episode/length": 37.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 60008, "time": 3252.3528265953064, "eval_episode/length": 49.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.92}
{"step": 60008, "time": 3255.779614210129, "eval_episode/length": 133.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 60008, "time": 3258.1740555763245, "eval_episode/length": 156.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 60008, "time": 3259.8822948932648, "eval_episode/length": 158.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 60008, "time": 3262.235356092453, "eval_episode/length": 178.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994413407821229}
{"step": 60008, "time": 3263.9944372177124, "eval_episode/length": 182.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 60008, "time": 3265.7516479492188, "eval_episode/length": 187.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 60056, "time": 3267.519560098648, "episode/length": 267.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 60160, "time": 3273.116673707962, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 60320, "time": 3280.6082830429077, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 60649, "time": 3295.1110758781433, "train_stats/sum_log_reward": 2.2913042792807454, "train_stats/max_log_achievement_collect_drink": 10.147826086956522, "train_stats/max_log_achievement_collect_sapling": 1.808695652173913, "train_stats/max_log_achievement_collect_wood": 0.3565217391304348, "train_stats/max_log_achievement_defeat_zombie": 0.12173913043478261, "train_stats/max_log_achievement_eat_cow": 0.06956521739130435, "train_stats/max_log_achievement_place_plant": 1.391304347826087, "train_stats/max_log_achievement_place_table": 0.034782608695652174, "train_stats/max_log_achievement_wake_up": 1.8347826086956522, "train_stats/mean_log_entropy": 0.5777316646083541, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.01703564453125, "train/action_min": 0.0, "train/action_std": 3.3529183673858642, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041352165028452875, "train/actor_opt_grad_steps": 3070.0, "train/actor_opt_loss": 9.322261644363403, "train/adv_mag": 1.4051548862457275, "train/adv_max": 1.4014069380760192, "train/adv_mean": 0.006397090115729952, "train/adv_min": -0.5946131999492645, "train/adv_std": 0.10709928026795387, "train/cont_avg": 0.994109375, "train/cont_loss_mean": 0.0006042647741778637, "train/cont_loss_std": 0.014869491651363205, "train/cont_neg_acc": 0.9799396862983704, "train/cont_neg_loss": 0.04778542376632686, "train/cont_pos_acc": 0.9998820433616639, "train/cont_pos_loss": 0.0002845575161991292, "train/cont_pred": 0.994094120979309, "train/cont_rate": 0.994109375, "train/dyn_loss_mean": 6.9215771713256835, "train/dyn_loss_std": 6.477033878326416, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.281358500957489, "train/extr_critic_critic_opt_grad_steps": 3070.0, "train/extr_critic_critic_opt_loss": 14814.2976328125, "train/extr_critic_mag": 1.9470302009582519, "train/extr_critic_max": 1.9470302009582519, "train/extr_critic_mean": 0.47967035782337186, "train/extr_critic_min": -0.2817890205383301, "train/extr_critic_std": 0.6252003471851348, "train/extr_return_normed_mag": 2.2410244073867798, "train/extr_return_normed_max": 2.2410244073867798, "train/extr_return_normed_mean": 0.36616456222534177, "train/extr_return_normed_min": -0.25754713505506516, "train/extr_return_normed_std": 0.3628948165178299, "train/extr_return_rate": 0.3320146001577377, "train/extr_return_raw_mag": 3.9508970012664797, "train/extr_return_raw_max": 3.9508970012664797, "train/extr_return_raw_mean": 0.49143949818611143, "train/extr_return_raw_min": -0.6590570087432861, "train/extr_return_raw_std": 0.6696148767471314, "train/extr_reward_mag": 0.9999136743545533, "train/extr_reward_max": 0.9999136743545533, "train/extr_reward_mean": 0.013438577059656382, "train/extr_reward_min": -0.4296854524612427, "train/extr_reward_std": 0.0989040210545063, "train/image_loss_mean": 16.588444999694826, "train/image_loss_std": 19.098714546203613, "train/model_loss_mean": 20.799727180480957, "train/model_loss_std": 21.166883949279786, "train/model_opt_grad_norm": 139.65573797607422, "train/model_opt_grad_steps": 3060.0, "train/model_opt_loss": 1247.0636640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 60.3125, "train/policy_entropy_mag": 2.3465908136367797, "train/policy_entropy_max": 2.3465908136367797, "train/policy_entropy_mean": 0.625660315990448, "train/policy_entropy_min": 0.07961084604263306, "train/policy_entropy_std": 0.47395103120803833, "train/policy_logprob_mag": 7.437514774322509, "train/policy_logprob_max": -0.00948834703117609, "train/policy_logprob_mean": -0.6261793086528779, "train/policy_logprob_min": -7.437514774322509, "train/policy_logprob_std": 1.1596399273872375, "train/policy_randomness_mag": 0.8282435789108277, "train/policy_randomness_max": 0.8282435789108277, "train/policy_randomness_mean": 0.22083063676953316, "train/policy_randomness_min": 0.02809913498163223, "train/policy_randomness_std": 0.16728391575813292, "train/post_ent_mag": 42.41138394165039, "train/post_ent_max": 42.41138394165039, "train/post_ent_mean": 30.760289321899414, "train/post_ent_min": 13.051878341674804, "train/post_ent_std": 5.240702104568482, "train/prior_ent_mag": 55.07527478027344, "train/prior_ent_max": 55.07527478027344, "train/prior_ent_mean": 37.779163604736326, "train/prior_ent_min": 14.640217849731446, "train/prior_ent_std": 6.759737617492676, "train/rep_loss_mean": 6.9215771713256835, "train/rep_loss_std": 6.477033878326416, "train/reward_avg": 0.01000859371945262, "train/reward_loss_mean": 0.05773160126805305, "train/reward_loss_std": 0.3121480107307434, "train/reward_max_data": 1.0024000005722047, "train/reward_max_pred": 0.998754813194275, "train/reward_neg_acc": 0.9944729943275452, "train/reward_neg_loss": 0.03897581049799919, "train/reward_pos_acc": 0.8787411708831787, "train/reward_pos_loss": 1.2843653430938722, "train/reward_pred": 0.009256932572461664, "train/reward_rate": 0.015328125, "eval_stats/sum_log_reward": 2.6624999260529876, "eval_stats/max_log_achievement_collect_drink": 2.6875, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02631578947368421, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 8.356035323231481e-06, "report/cont_loss_std": 9.900537406792864e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005326865357346833, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.747073944599833e-06, "report/cont_pred": 0.993162989616394, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.76469612121582, "report/dyn_loss_std": 6.7889580726623535, "report/image_loss_mean": 14.46352481842041, "report/image_loss_std": 18.420686721801758, "report/model_loss_mean": 18.564504623413086, "report/model_loss_std": 20.688169479370117, "report/post_ent_mag": 42.884315490722656, "report/post_ent_max": 42.884315490722656, "report/post_ent_mean": 31.6330509185791, "report/post_ent_min": 14.18585205078125, "report/post_ent_std": 5.1281256675720215, "report/prior_ent_mag": 57.5108528137207, "report/prior_ent_max": 57.5108528137207, "report/prior_ent_mean": 39.121665954589844, "report/prior_ent_min": 14.930850982666016, "report/prior_ent_std": 7.199937343597412, "report/rep_loss_mean": 6.76469612121582, "report/rep_loss_std": 6.7889580726623535, "report/reward_avg": 0.0074218749068677425, "report/reward_loss_mean": 0.04215328395366669, "report/reward_loss_std": 0.20965424180030823, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020942687988281, "report/reward_neg_acc": 0.9960435032844543, "report/reward_neg_loss": 0.02928684838116169, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 1.0427658557891846, "report/reward_pred": 0.005889446008950472, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.004319715313613415, "eval/cont_loss_std": 0.13692350685596466, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 1.1053540706634521, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9332251213199925e-06, "eval/cont_pred": 0.9970927238464355, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 11.599929809570312, "eval/dyn_loss_std": 7.9623260498046875, "eval/image_loss_mean": 32.20879364013672, "eval/image_loss_std": 37.165409088134766, "eval/model_loss_mean": 39.23107147216797, "eval/model_loss_std": 39.798011779785156, "eval/post_ent_mag": 43.8405647277832, "eval/post_ent_max": 43.8405647277832, "eval/post_ent_mean": 29.902626037597656, "eval/post_ent_min": 14.962181091308594, "eval/post_ent_std": 5.231288433074951, "eval/prior_ent_mag": 58.471107482910156, "eval/prior_ent_max": 58.471107482910156, "eval/prior_ent_mean": 39.28424072265625, "eval/prior_ent_min": 13.883035659790039, "eval/prior_ent_std": 8.632281303405762, "eval/rep_loss_mean": 11.599929809570312, "eval/rep_loss_std": 7.9623260498046875, "eval/reward_avg": 0.01601562649011612, "eval/reward_loss_mean": 0.05800271034240723, "eval/reward_loss_std": 0.4201435148715973, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018556118011475, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.018654029816389084, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.033306837081909, "eval/reward_pred": 0.007258957251906395, "eval/reward_rate": 0.01953125, "replay/size": 60145.0, "replay/inserts": 19984.0, "replay/samples": 19984.0, "replay/insert_wait_avg": 1.4760023694309451e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.337504259388957e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13056.0, "eval_replay/inserts": 3296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1834126074337265e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.220757484436, "timer/env.step_count": 2498.0, "timer/env.step_total": 253.58991861343384, "timer/env.step_frac": 0.25353394909661214, "timer/env.step_avg": 0.1015171811903258, "timer/env.step_min": 0.022906064987182617, "timer/env.step_max": 3.4999184608459473, "timer/replay._sample_count": 19984.0, "timer/replay._sample_total": 10.539675235748291, "timer/replay._sample_frac": 0.01053734903708224, "timer/replay._sample_avg": 0.0005274056863364837, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.011279821395874023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2910.0, "timer/agent.policy_total": 49.76517033576965, "timer/agent.policy_frac": 0.04975418672666771, "timer/agent.policy_avg": 0.017101433105075482, "timer/agent.policy_min": 0.00962519645690918, "timer/agent.policy_max": 0.11687445640563965, "timer/dataset_train_count": 1249.0, "timer/dataset_train_total": 0.15146827697753906, "timer/dataset_train_frac": 0.0001514348466017473, "timer/dataset_train_avg": 0.00012127163889314577, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0004448890686035156, "timer/agent.train_count": 1249.0, "timer/agent.train_total": 557.9206690788269, "timer/agent.train_frac": 0.5577975310990368, "timer/agent.train_avg": 0.44669389037536184, "timer/agent.train_min": 0.434828519821167, "timer/agent.train_max": 0.9764890670776367, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794158935546875, "timer/agent.report_frac": 0.00047931008226666146, "timer/agent.report_avg": 0.23970794677734375, "timer/agent.report_min": 0.23179173469543457, "timer/agent.report_max": 0.24762415885925293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812718304781047e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 19.979332196434832}
{"step": 60680, "time": 3296.042009830475, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 60712, "time": 3298.8606839179993, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 61056, "time": 3313.458993911743, "episode/length": 169.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 61072, "time": 3315.749490737915, "episode/length": 193.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 61192, "time": 3321.5521099567413, "episode/length": 226.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 61344, "time": 3328.9626545906067, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 61376, "time": 3331.7185866832733, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 61600, "time": 3341.7287781238556, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 62184, "time": 3364.5607690811157, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 62616, "time": 3382.28643655777, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 62696, "time": 3386.824244737625, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 62696, "time": 3386.866170167923, "episode/length": 136.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 62816, "time": 3394.6691846847534, "episode/length": 262.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 63072, "time": 3405.934890985489, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 63584, "time": 3426.3974101543427, "episode/length": 110.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 63776, "time": 3434.915905237198, "episode/length": 322.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 63816, "time": 3437.5801939964294, "episode/length": 149.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 63872, "time": 3441.485810279846, "episode/length": 146.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 63888, "time": 3443.541965007782, "episode/length": 37.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 64128, "time": 3453.8842539787292, "episode/length": 430.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 64408, "time": 3465.682779312134, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 64472, "time": 3469.5688729286194, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 64968, "time": 3489.5688741207123, "episode/length": 347.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.0}
{"step": 65000, "time": 3492.290615797043, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 65080, "time": 3496.7570340633392, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 65200, "time": 3503.0035598278046, "episode/length": 133.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 65608, "time": 3520.8832008838654, "episode/length": 79.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 65664, "time": 3524.8438062667847, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 65768, "time": 3530.0091121196747, "episode/length": 236.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 65944, "time": 3538.129438638687, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 66216, "time": 3549.968249320984, "episode/length": 225.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 66448, "time": 3560.2686433792114, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 66552, "time": 3565.413925409317, "episode/length": 117.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 66672, "time": 3571.6984300613403, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 66680, "time": 3573.1737644672394, "episode/length": 184.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 67064, "time": 3588.9986641407013, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 67080, "time": 3591.171277284622, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 67184, "time": 3596.85795211792, "episode/length": 154.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 67568, "time": 3612.6084866523743, "episode/length": 126.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.952755905511811, "episode/intrinsic_return": 0.0}
{"step": 68208, "time": 3637.6592257022858, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 68240, "time": 3640.486364841461, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 68408, "time": 3648.025523662567, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 68448, "time": 3651.2101249694824, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 68464, "time": 3653.3774847984314, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 68656, "time": 3661.930562734604, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 69056, "time": 3678.2547245025635, "episode/length": 354.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9971830985915493, "episode/intrinsic_return": 0.0}
{"step": 69648, "time": 3701.6270849704742, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 69672, "time": 3703.9311141967773, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 69760, "time": 3708.9421689510345, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 69800, "time": 3711.785761117935, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 69816, "time": 3713.9244191646576, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3741.5640864372253, "eval_episode/length": 66.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9253731343283582}
{"step": 70096, "time": 3743.267359495163, "eval_episode/length": 69.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9142857142857143}
{"step": 70096, "time": 3747.537188768387, "eval_episode/length": 137.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 70096, "time": 3750.2700595855713, "eval_episode/length": 165.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 70096, "time": 3751.904211997986, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 70096, "time": 3753.805707216263, "eval_episode/length": 175.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 70096, "time": 3756.472797870636, "eval_episode/length": 197.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 70096, "time": 3758.1107432842255, "eval_episode/length": 200.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 70512, "time": 3773.313575744629, "episode/length": 181.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 70648, "time": 3779.5741515159607, "episode/length": 445.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 70936, "time": 3791.8408374786377, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 70968, "time": 3794.525981903076, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 70984, "time": 3796.668172597885, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 71152, "time": 3804.6770482063293, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 71264, "time": 3810.302808046341, "episode/length": 325.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 71568, "time": 3823.169584274292, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 72424, "time": 3856.0207467079163, "episode/length": 181.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 72440, "time": 3858.383159637451, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 72480, "time": 3861.612327814102, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9650655021834061, "episode/intrinsic_return": 0.0}
{"step": 72584, "time": 3866.8256464004517, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 73352, "time": 3896.623183965683, "episode/length": 274.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 73512, "time": 3903.941925048828, "episode/length": 280.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 73648, "time": 3910.8135900497437, "episode/length": 391.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770408163265306, "episode/intrinsic_return": 0.0}
{"step": 73648, "time": 3910.8618879318237, "episode/length": 259.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 73976, "time": 3927.5956490039825, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 74072, "time": 3932.8517904281616, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 74400, "time": 3946.9525401592255, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 74680, "time": 3958.704492330551, "episode/length": 165.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 74744, "time": 3962.645780801773, "episode/length": 269.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 74928, "time": 3971.4067919254303, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 74936, "time": 3973.068468809128, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 75056, "time": 3979.254450082779, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 75160, "time": 3984.477777481079, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 75384, "time": 3994.269824743271, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 75832, "time": 4012.8379139900208, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 75992, "time": 4020.3292706012726, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 76248, "time": 4031.362021923065, "episode/length": 31.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 76328, "time": 4035.8945729732513, "episode/length": 281.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 76368, "time": 4039.193119287491, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 76544, "time": 4047.263487815857, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 76744, "time": 4055.9981338977814, "episode/length": 61.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 76832, "time": 4061.13351893425, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 77184, "time": 4075.5905985832214, "episode/length": 168.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 77400, "time": 4084.978765487671, "episode/length": 279.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 77736, "time": 4099.054337978363, "episode/length": 123.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9435483870967742, "episode/intrinsic_return": 0.0}
{"step": 77936, "time": 4108.2581696510315, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 77976, "time": 4111.122527837753, "episode/length": 178.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 78048, "time": 4115.664360523224, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 78088, "time": 4118.607535839081, "episode/length": 425.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 78336, "time": 4129.658848762512, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 78408, "time": 4134.189138412476, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 78648, "time": 4145.3326587677, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 79296, "time": 4171.560768842697, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 79528, "time": 4181.705632209778, "episode/length": 198.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 79608, "time": 4186.305267333984, "episode/length": 149.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 79696, "time": 4191.447612524033, "episode/length": 244.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 79952, "time": 4202.541635751724, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4223.177673101425, "eval_episode/length": 32.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 80080, "time": 4228.010110139847, "eval_episode/length": 111.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 80080, "time": 4231.553313732147, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 80080, "time": 4235.0826897621155, "eval_episode/length": 170.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 80080, "time": 4237.285029411316, "eval_episode/length": 148.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 80080, "time": 4240.2499351501465, "eval_episode/length": 213.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 80080, "time": 4241.91366314888, "eval_episode/length": 215.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 80080, "time": 4243.801480293274, "eval_episode/length": 221.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 80192, "time": 4247.9495623111725, "episode/length": 419.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 80600, "time": 4264.459494829178, "episode/length": 282.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 80776, "time": 4272.634028673172, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 80816, "time": 4275.902992725372, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 81200, "time": 4291.584854602814, "episode/length": 388.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 81241, "time": 4295.3223922252655, "train_stats/sum_log_reward": 3.328571361019498, "train_stats/max_log_achievement_collect_drink": 7.914285714285715, "train_stats/max_log_achievement_collect_sapling": 1.6285714285714286, "train_stats/max_log_achievement_collect_wood": 1.5333333333333334, "train_stats/max_log_achievement_defeat_zombie": 0.05714285714285714, "train_stats/max_log_achievement_eat_cow": 0.05714285714285714, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0380952380952381, "train_stats/max_log_achievement_place_plant": 1.4761904761904763, "train_stats/max_log_achievement_place_table": 0.42857142857142855, "train_stats/max_log_achievement_wake_up": 2.2666666666666666, "train_stats/mean_log_entropy": 0.9278502220199222, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.097245563832364, "train/action_min": 0.0, "train/action_std": 4.183352634888287, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04805288245800392, "train/actor_opt_grad_steps": 4340.0, "train/actor_opt_loss": 25.578433483145957, "train/adv_mag": 1.3047161495038706, "train/adv_max": 1.3047161495038706, "train/adv_mean": 0.008612994411031855, "train/adv_min": -0.5596654098625331, "train/adv_std": 0.10181479231100674, "train/cont_avg": 0.9945569888565892, "train/cont_loss_mean": 0.0003288109137138447, "train/cont_loss_std": 0.008843195960101488, "train/cont_neg_acc": 0.9914728689563367, "train/cont_neg_loss": 0.03897652385920139, "train/cont_pos_acc": 0.9999618738196617, "train/cont_pos_loss": 0.00012790845859533226, "train/cont_pred": 0.99456433963406, "train/cont_rate": 0.9945569888565892, "train/dyn_loss_mean": 8.503024345220522, "train/dyn_loss_std": 7.265469905941985, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.17349422948305, "train/extr_critic_critic_opt_grad_steps": 4340.0, "train/extr_critic_critic_opt_loss": 14377.982293180718, "train/extr_critic_mag": 2.166826887648235, "train/extr_critic_max": 2.166826887648235, "train/extr_critic_mean": 0.47653970307157945, "train/extr_critic_min": -0.22592992006346238, "train/extr_critic_std": 0.6164887434290361, "train/extr_return_normed_mag": 2.173250301863796, "train/extr_return_normed_max": 2.173250301863796, "train/extr_return_normed_mean": 0.340398714408394, "train/extr_return_normed_min": -0.24400276006307714, "train/extr_return_normed_std": 0.3494925690713779, "train/extr_return_rate": 0.3207743015400199, "train/extr_return_raw_mag": 3.944283453993095, "train/extr_return_raw_max": 3.944283453993095, "train/extr_return_raw_mean": 0.4928506578123847, "train/extr_return_raw_min": -0.6073999202759691, "train/extr_return_raw_std": 0.6580908504105354, "train/extr_reward_mag": 1.0026547428249388, "train/extr_reward_max": 1.0026547428249388, "train/extr_reward_mean": 0.0135305809802845, "train/extr_reward_min": -0.4034382003222325, "train/extr_reward_std": 0.09996763466633568, "train/image_loss_mean": 19.29595304089923, "train/image_loss_std": 22.367577397546103, "train/model_loss_mean": 24.450980016427447, "train/model_loss_std": 25.16225361639215, "train/model_opt_grad_norm": 118.32170589949733, "train/model_opt_grad_steps": 4330.0, "train/model_opt_loss": 3368.888865862706, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 136.8701550387597, "train/policy_entropy_mag": 2.453102087789728, "train/policy_entropy_max": 2.453102087789728, "train/policy_entropy_mean": 0.8505969038305357, "train/policy_entropy_min": 0.07943732216376667, "train/policy_entropy_std": 0.5616989073365234, "train/policy_logprob_mag": 7.437907522038896, "train/policy_logprob_max": -0.00946484624530918, "train/policy_logprob_mean": -0.850609495658283, "train/policy_logprob_min": -7.437907522038896, "train/policy_logprob_std": 1.2451644664586976, "train/policy_randomness_mag": 0.865837386412214, "train/policy_randomness_max": 0.865837386412214, "train/policy_randomness_mean": 0.3002233775549157, "train/policy_randomness_min": 0.02803788871266121, "train/policy_randomness_std": 0.19825506603070933, "train/post_ent_mag": 46.35005610857823, "train/post_ent_max": 46.35005610857823, "train/post_ent_mean": 32.627798080444336, "train/post_ent_min": 14.896639306415883, "train/post_ent_std": 5.52547240811725, "train/prior_ent_mag": 58.390371189561, "train/prior_ent_max": 58.390371189561, "train/prior_ent_mean": 41.271371235219085, "train/prior_ent_min": 16.7116529997005, "train/prior_ent_std": 7.714995118074639, "train/rep_loss_mean": 8.503024345220522, "train/rep_loss_std": 7.265469905941985, "train/reward_avg": 0.011237281889929038, "train/reward_loss_mean": 0.0528836691997541, "train/reward_loss_std": 0.28020765372487, "train/reward_max_data": 1.0031007759330808, "train/reward_max_pred": 1.0005503708077956, "train/reward_neg_acc": 0.9937912572261899, "train/reward_neg_loss": 0.03466730684677298, "train/reward_pos_acc": 0.9095502468042596, "train/reward_pos_loss": 1.1545643067175104, "train/reward_pred": 0.0103687674263781, "train/reward_rate": 0.016200339147286823, "train_stats/max_log_achievement_make_wood_sword": 0.04918032786885246, "eval_stats/sum_log_reward": 3.412499912083149, "eval_stats/max_log_achievement_collect_drink": 6.0625, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_wood": 1.5625, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.020833333333333332, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00024313766334671527, "report/cont_loss_std": 0.004911287687718868, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003515477292239666, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00022385080228559673, "report/cont_pred": 0.9939501285552979, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 9.556742668151855, "report/dyn_loss_std": 7.945148468017578, "report/image_loss_mean": 17.127826690673828, "report/image_loss_std": 19.975984573364258, "report/model_loss_mean": 22.956710815429688, "report/model_loss_std": 23.084068298339844, "report/post_ent_mag": 48.38996124267578, "report/post_ent_max": 48.38996124267578, "report/post_ent_mean": 33.0331916809082, "report/post_ent_min": 15.335289001464844, "report/post_ent_std": 6.293545246124268, "report/prior_ent_mag": 59.061668395996094, "report/prior_ent_max": 59.061668395996094, "report/prior_ent_mean": 42.97587203979492, "report/prior_ent_min": 16.57684326171875, "report/prior_ent_std": 8.886841773986816, "report/rep_loss_mean": 9.556742668151855, "report/rep_loss_std": 7.945148468017578, "report/reward_avg": 0.01416015625, "report/reward_loss_mean": 0.09459494799375534, "report/reward_loss_std": 0.5805491209030151, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.999148964881897, "report/reward_neg_acc": 0.9960199594497681, "report/reward_neg_loss": 0.056133974343538284, "report/reward_pos_acc": 0.8421052694320679, "report/reward_pos_loss": 2.1289782524108887, "report/reward_pred": 0.00783345103263855, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.486195444362238e-05, "eval/cont_loss_std": 0.00035644954186864197, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006429564207792282, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.04304432272329e-06, "eval/cont_pred": 0.9970830678939819, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 13.588225364685059, "eval/dyn_loss_std": 8.344962120056152, "eval/image_loss_mean": 28.512439727783203, "eval/image_loss_std": 30.442319869995117, "eval/model_loss_mean": 36.686492919921875, "eval/model_loss_std": 33.35943603515625, "eval/post_ent_mag": 47.40317153930664, "eval/post_ent_max": 47.40317153930664, "eval/post_ent_mean": 31.969247817993164, "eval/post_ent_min": 16.915306091308594, "eval/post_ent_std": 5.6489644050598145, "eval/prior_ent_mag": 58.908172607421875, "eval/prior_ent_max": 58.908172607421875, "eval/prior_ent_mean": 42.83768081665039, "eval/prior_ent_min": 17.40182113647461, "eval/prior_ent_std": 8.636335372924805, "eval/rep_loss_mean": 13.588225364685059, "eval/rep_loss_std": 8.344962120056152, "eval/reward_avg": 0.004199218936264515, "eval/reward_loss_mean": 0.021090999245643616, "eval/reward_loss_std": 0.17735259234905243, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9996087551116943, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.013269783928990364, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.1574015617370605, "eval/reward_pred": 0.0025747250765562057, "eval/reward_rate": 0.0068359375, "replay/size": 80737.0, "replay/inserts": 20592.0, "replay/samples": 20592.0, "replay/insert_wait_avg": 1.4646093143264546e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.84992351991406e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 16440.0, "eval_replay/inserts": 3384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.147424639257697e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1694602966309, "timer/env.step_count": 2574.0, "timer/env.step_total": 236.32600212097168, "timer/env.step_frac": 0.2362859610319255, "timer/env.step_avg": 0.09181274363674113, "timer/env.step_min": 0.023942947387695312, "timer/env.step_max": 3.4439315795898438, "timer/replay._sample_count": 20592.0, "timer/replay._sample_total": 10.343710660934448, "timer/replay._sample_frac": 0.010341958109645444, "timer/replay._sample_avg": 0.0005023169512885804, "timer/replay._sample_min": 0.0003883838653564453, "timer/replay._sample_max": 0.008000850677490234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2997.0, "timer/agent.policy_total": 50.84506869316101, "timer/agent.policy_frac": 0.05083645393259793, "timer/agent.policy_avg": 0.016965321552606275, "timer/agent.policy_min": 0.009770631790161133, "timer/agent.policy_max": 0.09325647354125977, "timer/dataset_train_count": 1287.0, "timer/dataset_train_total": 0.1471242904663086, "timer/dataset_train_frac": 0.0001470993629646264, "timer/dataset_train_avg": 0.00011431568800800978, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.00036644935607910156, "timer/agent.train_count": 1287.0, "timer/agent.train_total": 574.5990109443665, "timer/agent.train_frac": 0.5745016557233726, "timer/agent.train_avg": 0.4464638779676507, "timer/agent.train_min": 0.43439483642578125, "timer/agent.train_max": 1.1538548469543457, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48515796661376953, "timer/agent.report_frac": 0.0004850757655306543, "timer/agent.report_avg": 0.24257898330688477, "timer/agent.report_min": 0.22333645820617676, "timer/agent.report_max": 0.2618215084075928, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194267658416024e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 20.587928347509372}
{"step": 81344, "time": 4299.1427710056305, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 81528, "time": 4307.363603115082, "episode/length": 278.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 81552, "time": 4310.200339794159, "episode/length": 199.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 81608, "time": 4313.654180288315, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 81656, "time": 4316.959234952927, "episode/length": 38.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 81808, "time": 4324.38250875473, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 82056, "time": 4336.388514041901, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 82456, "time": 4352.6252772808075, "episode/length": 209.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 82720, "time": 4364.164726495743, "episode/length": 145.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 82728, "time": 4365.737366199493, "episode/length": 33.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 82824, "time": 4370.783315420151, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 82928, "time": 4376.3576691150665, "episode/length": 108.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 83016, "time": 4380.945394277573, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 83072, "time": 4384.728490352631, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 83176, "time": 4389.927036523819, "episode/length": 195.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 83480, "time": 4402.466467142105, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 83752, "time": 4413.8094136714935, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 84336, "time": 4437.080775260925, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 84424, "time": 4441.555382728577, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 84432, "time": 4443.631149530411, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 84496, "time": 4447.781047344208, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 85008, "time": 4468.2463574409485, "episode/length": 284.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 85176, "time": 4476.541496753693, "episode/length": 92.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 85184, "time": 4479.058018684387, "episode/length": 294.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 85424, "time": 4490.037478685379, "episode/length": 135.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 85424, "time": 4490.08513879776, "episode/length": 280.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 85568, "time": 4499.758293867111, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 85648, "time": 4504.713342428207, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 85856, "time": 4514.70553278923, "episode/length": 35.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 85880, "time": 4516.862783908844, "episode/length": 181.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 86480, "time": 4540.720363140106, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 86536, "time": 4544.2080018520355, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 86896, "time": 4559.174954414368, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 86904, "time": 4560.873880147934, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 87032, "time": 4567.248756170273, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 87120, "time": 4572.2088413238525, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 87232, "time": 4577.862595319748, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 87336, "time": 4583.039154052734, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 87976, "time": 4607.962099313736, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 88192, "time": 4617.656382083893, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 88256, "time": 4621.509393692017, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 88416, "time": 4629.032891750336, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 88520, "time": 4634.258292675018, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 88544, "time": 4636.978766918182, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 88960, "time": 4653.777317762375, "episode/length": 202.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 89376, "time": 4670.671361207962, "episode/length": 281.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 89512, "time": 4677.175639629364, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 89552, "time": 4680.427119016647, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4701.070152759552, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4714.958102941513, "eval_episode/length": 33.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8529411764705882}
{"step": 90064, "time": 4720.5901658535, "eval_episode/length": 136.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 90064, "time": 4722.448434591293, "eval_episode/length": 143.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 90064, "time": 4724.862848520279, "eval_episode/length": 162.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 90064, "time": 4726.931638717651, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 90064, "time": 4728.7112357616425, "eval_episode/length": 39.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.975}
{"step": 90064, "time": 4730.580455303192, "eval_episode/length": 187.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 90064, "time": 4732.667635917664, "eval_episode/length": 35.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 90248, "time": 4742.252992153168, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 90344, "time": 4747.3270790576935, "episode/length": 227.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 90456, "time": 4752.977973461151, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 90896, "time": 4770.854967594147, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 90984, "time": 4775.357196331024, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 91168, "time": 4783.896547317505, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 91200, "time": 4786.532188653946, "episode/length": 375.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 91376, "time": 4794.591075181961, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 91616, "time": 4804.893091201782, "episode/length": 257.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 91760, "time": 4811.938299894333, "episode/length": 162.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 91840, "time": 4816.472510814667, "episode/length": 106.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 91960, "time": 4822.174653053284, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 92112, "time": 4829.667154788971, "episode/length": 220.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 92240, "time": 4835.907196521759, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 92608, "time": 4851.046423912048, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 92632, "time": 4853.272711515427, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 93072, "time": 4871.25701546669, "episode/length": 181.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 93256, "time": 4879.402590036392, "episode/length": 256.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 93336, "time": 4883.928362369537, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 93488, "time": 4891.380601167679, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 93600, "time": 4897.148242950439, "episode/length": 32.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 93680, "time": 4901.697791814804, "episode/length": 229.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 93936, "time": 4912.753471374512, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 94112, "time": 4920.6726858615875, "episode/length": 233.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 94288, "time": 4928.777389764786, "episode/length": 209.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 94304, "time": 4930.924737215042, "episode/length": 45.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 94392, "time": 4935.411501169205, "episode/length": 164.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 94408, "time": 4937.612761735916, "episode/length": 114.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 94880, "time": 4956.726523637772, "episode/length": 159.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 95056, "time": 4964.843990325928, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 95320, "time": 4975.971107006073, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 95552, "time": 4986.2341866493225, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 95640, "time": 4990.90641951561, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 95688, "time": 4994.141464233398, "episode/length": 172.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 95872, "time": 5002.45880150795, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 96104, "time": 5012.269540309906, "episode/length": 213.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 96128, "time": 5015.0038895606995, "episode/length": 155.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 96216, "time": 5019.617418527603, "episode/length": 42.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 96632, "time": 5036.455976963043, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 96888, "time": 5047.421488285065, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 96920, "time": 5050.0599575042725, "episode/length": 35.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 96984, "time": 5053.961017370224, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 97112, "time": 5060.156171321869, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 97152, "time": 5063.396308422089, "episode/length": 261.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 97536, "time": 5079.012508392334, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 97544, "time": 5080.624319553375, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 98104, "time": 5102.628587007523, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 98128, "time": 5105.148312091827, "episode/length": 121.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 98192, "time": 5109.179807901382, "episode/length": 158.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 98208, "time": 5111.26145863533, "episode/length": 152.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 98352, "time": 5119.352934598923, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 98744, "time": 5134.9162809848785, "episode/length": 150.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 98984, "time": 5145.2393362522125, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 99008, "time": 5147.8880443573, "episode/length": 32.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 99320, "time": 5160.581842184067, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 99552, "time": 5170.799788475037, "episode/length": 416.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 99640, "time": 5175.358292102814, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 99704, "time": 5179.200617313385, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 99824, "time": 5185.3421812057495, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 99992, "time": 5192.789124011993, "episode/length": 125.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 100008, "time": 5194.843472957611, "episode/length": 224.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 5213.798592329025, "eval_episode/length": 66.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9253731343283582}
{"step": 100048, "time": 5215.682034730911, "eval_episode/length": 75.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9210526315789473}
{"step": 100048, "time": 5218.036285400391, "eval_episode/length": 92.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.946236559139785}
{"step": 100048, "time": 5220.172770500183, "eval_episode/length": 39.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.975}
{"step": 100048, "time": 5224.748086214066, "eval_episode/length": 182.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 100048, "time": 5226.515887260437, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 100048, "time": 5228.422955989838, "eval_episode/length": 99.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.95}
{"step": 100048, "time": 5230.196164131165, "eval_episode/length": 93.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9468085106382979}
{"step": 100216, "time": 5236.068503141403, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 100768, "time": 5258.179841518402, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 101040, "time": 5269.696837425232, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 101096, "time": 5273.051078557968, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 101208, "time": 5278.731565713882, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 101240, "time": 5281.560348033905, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 101304, "time": 5285.581895112991, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 101497, "time": 5295.2840213775635, "train_stats/sum_log_reward": 3.3478631760574813, "train_stats/max_log_achievement_collect_drink": 5.666666666666667, "train_stats/max_log_achievement_collect_sapling": 1.376068376068376, "train_stats/max_log_achievement_collect_wood": 1.623931623931624, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.017094017094017096, "train_stats/max_log_achievement_eat_cow": 0.042735042735042736, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017094017094017096, "train_stats/max_log_achievement_make_wood_sword": 0.017094017094017096, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 0.5384615384615384, "train_stats/max_log_achievement_wake_up": 2.0256410256410255, "train_stats/mean_log_entropy": 0.8080156397106301, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.819996182880704, "train/action_min": 0.0, "train/action_std": 4.083800164480058, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05029672682876625, "train/actor_opt_grad_steps": 5615.0, "train/actor_opt_loss": 19.828172339333427, "train/adv_mag": 1.0542940823804765, "train/adv_max": 1.0530767776663341, "train/adv_mean": 0.00809717940818888, "train/adv_min": -0.547595730376622, "train/adv_std": 0.09093788473142518, "train/cont_avg": 0.9944971478174603, "train/cont_loss_mean": 0.00040749423067019226, "train/cont_loss_std": 0.01036096834563761, "train/cont_neg_acc": 0.9897738747180455, "train/cont_neg_loss": 0.031089942537947637, "train/cont_pos_acc": 0.9999298562133123, "train/cont_pos_loss": 0.00022338039004834865, "train/cont_pred": 0.9944489290789952, "train/cont_rate": 0.9944971478174603, "train/dyn_loss_mean": 9.739564766959539, "train/dyn_loss_std": 7.8689104526761975, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1258109836351304, "train/extr_critic_critic_opt_grad_steps": 5615.0, "train/extr_critic_critic_opt_loss": 14832.329814608134, "train/extr_critic_mag": 2.692178376137264, "train/extr_critic_max": 2.692178376137264, "train/extr_critic_mean": 0.6229473553479664, "train/extr_critic_min": -0.24360264482952299, "train/extr_critic_std": 0.7685072410201269, "train/extr_return_normed_mag": 2.002192883264451, "train/extr_return_normed_max": 2.002192883264451, "train/extr_return_normed_mean": 0.3340476349232689, "train/extr_return_normed_min": -0.23293975019265736, "train/extr_return_normed_std": 0.35582650464678567, "train/extr_return_rate": 0.40662876339185805, "train/extr_return_raw_mag": 4.4662873480055065, "train/extr_return_raw_max": 4.4662873480055065, "train/extr_return_raw_mean": 0.6413991995274074, "train/extr_return_raw_min": -0.6578264870340862, "train/extr_return_raw_std": 0.8164225021998087, "train/extr_reward_mag": 1.0039406125507657, "train/extr_reward_max": 1.0039406125507657, "train/extr_reward_mean": 0.014090806133084235, "train/extr_reward_min": -0.46043695816918023, "train/extr_reward_std": 0.10466802353778529, "train/image_loss_mean": 16.205527933817063, "train/image_loss_std": 18.583435467311315, "train/model_loss_mean": 22.098759340861488, "train/model_loss_std": 21.890627550700355, "train/model_opt_grad_norm": 102.51129949660529, "train/model_opt_grad_steps": 5605.0, "train/model_opt_loss": 8084.396075536334, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 365.8234126984127, "train/policy_entropy_mag": 2.4921061803424167, "train/policy_entropy_max": 2.4921061803424167, "train/policy_entropy_mean": 0.8660034518393259, "train/policy_entropy_min": 0.07938943206081314, "train/policy_entropy_std": 0.6150444462185815, "train/policy_logprob_mag": 7.438166065821572, "train/policy_logprob_max": -0.00945828454421153, "train/policy_logprob_mean": -0.8666520657993498, "train/policy_logprob_min": -7.438166065821572, "train/policy_logprob_std": 1.2406281563970778, "train/policy_randomness_mag": 0.879604119630087, "train/policy_randomness_max": 0.879604119630087, "train/policy_randomness_mean": 0.30566121720605427, "train/policy_randomness_min": 0.028020985661044953, "train/policy_randomness_std": 0.21708369893687113, "train/post_ent_mag": 48.95406105404808, "train/post_ent_max": 48.95406105404808, "train/post_ent_mean": 34.04397613283188, "train/post_ent_min": 16.401448673672146, "train/post_ent_std": 5.747639920976427, "train/prior_ent_mag": 60.390789213634676, "train/prior_ent_max": 60.390789213634676, "train/prior_ent_mean": 44.007642594594806, "train/prior_ent_min": 18.5138658114842, "train/prior_ent_std": 8.071683630110725, "train/rep_loss_mean": 9.739564766959539, "train/rep_loss_std": 7.8689104526761975, "train/reward_avg": 0.012499999956205664, "train/reward_loss_mean": 0.04908501803283653, "train/reward_loss_std": 0.2683866913356478, "train/reward_max_data": 1.0055555568801031, "train/reward_max_pred": 1.0013261834780376, "train/reward_neg_acc": 0.9940809323674157, "train/reward_neg_loss": 0.030854994660272958, "train/reward_pos_acc": 0.9240861128246973, "train/reward_pos_loss": 1.0920676915418535, "train/reward_pred": 0.01178507812483798, "train/reward_rate": 0.01750062003968254, "eval_stats/sum_log_reward": 2.5374999763444066, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_wood": 0.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.8125, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00019920912745874375, "report/cont_loss_std": 0.0044487821869552135, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04493226110935211, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.37854037550278e-05, "report/cont_pred": 0.9962362051010132, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 9.664243698120117, "report/dyn_loss_std": 7.934612274169922, "report/image_loss_mean": 11.148862838745117, "report/image_loss_std": 15.698282241821289, "report/model_loss_mean": 16.9846248626709, "report/model_loss_std": 19.157920837402344, "report/post_ent_mag": 45.66848373413086, "report/post_ent_max": 45.66848373413086, "report/post_ent_mean": 33.26679229736328, "report/post_ent_min": 16.10184669494629, "report/post_ent_std": 4.94644021987915, "report/prior_ent_mag": 62.14204406738281, "report/prior_ent_max": 62.14204406738281, "report/prior_ent_mean": 43.54495620727539, "report/prior_ent_min": 19.418968200683594, "report/prior_ent_std": 7.763472080230713, "report/rep_loss_mean": 9.664243698120117, "report/rep_loss_std": 7.934612274169922, "report/reward_avg": 0.013574219308793545, "report/reward_loss_mean": 0.03701740503311157, "report/reward_loss_std": 0.16350990533828735, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005183219909668, "report/reward_neg_acc": 0.9980120062828064, "report/reward_neg_loss": 0.025187253952026367, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6981914639472961, "report/reward_pred": 0.014381629414856434, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.422855792858172e-06, "eval/cont_loss_std": 0.00013140248483978212, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0014097581151872873, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2965040241397219e-06, "eval/cont_pred": 0.9970731735229492, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.649164199829102, "eval/dyn_loss_std": 9.271180152893066, "eval/image_loss_mean": 27.630455017089844, "eval/image_loss_std": 28.078022003173828, "eval/model_loss_mean": 36.465606689453125, "eval/model_loss_std": 31.589012145996094, "eval/post_ent_mag": 49.024566650390625, "eval/post_ent_max": 49.024566650390625, "eval/post_ent_mean": 32.367225646972656, "eval/post_ent_min": 16.643184661865234, "eval/post_ent_std": 6.711754322052002, "eval/prior_ent_mag": 62.14204406738281, "eval/prior_ent_max": 62.14204406738281, "eval/prior_ent_mean": 43.96201705932617, "eval/prior_ent_min": 17.70438003540039, "eval/prior_ent_std": 10.67858600616455, "eval/rep_loss_mean": 14.649164199829102, "eval/rep_loss_std": 9.271180152893066, "eval/reward_avg": 0.01152343675494194, "eval/reward_loss_mean": 0.045650094747543335, "eval/reward_loss_std": 0.3584379255771637, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030131340026855, "eval/reward_neg_acc": 0.9990089535713196, "eval/reward_neg_loss": 0.0158233679831028, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 2.051994800567627, "eval/reward_pred": 0.005631399806588888, "eval/reward_rate": 0.0146484375, "replay/size": 100993.0, "replay/inserts": 20256.0, "replay/samples": 20256.0, "replay/insert_wait_avg": 1.3671403435922536e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.913858404656722e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19640.0, "eval_replay/inserts": 3200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0995566844940186e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9621932506561, "timer/env.step_count": 2532.0, "timer/env.step_total": 251.7257103919983, "timer/env.step_frac": 0.25173522768265233, "timer/env.step_avg": 0.0994177371216423, "timer/env.step_min": 0.02300572395324707, "timer/env.step_max": 4.254427671432495, "timer/replay._sample_count": 20256.0, "timer/replay._sample_total": 10.102420806884766, "timer/replay._sample_frac": 0.010102802761016423, "timer/replay._sample_avg": 0.000498737204131357, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.028296709060668945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2932.0, "timer/agent.policy_total": 48.06114721298218, "timer/agent.policy_frac": 0.04806296431742685, "timer/agent.policy_avg": 0.016391932883008928, "timer/agent.policy_min": 0.009497880935668945, "timer/agent.policy_max": 0.11699795722961426, "timer/dataset_train_count": 1266.0, "timer/dataset_train_total": 0.13454771041870117, "timer/dataset_train_frac": 0.00013455279742258683, "timer/dataset_train_avg": 0.00010627781233704674, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.00019860267639160156, "timer/agent.train_count": 1266.0, "timer/agent.train_total": 566.761570930481, "timer/agent.train_frac": 0.5667829991532624, "timer/agent.train_avg": 0.4476789659798428, "timer/agent.train_min": 0.4344191551208496, "timer/agent.train_max": 1.2102110385894775, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4696948528289795, "timer/agent.report_frac": 0.00046971261113593234, "timer/agent.report_avg": 0.23484742641448975, "timer/agent.report_min": 0.2278139591217041, "timer/agent.report_max": 0.2418808937072754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.980344915922726e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.256527631259022}
{"step": 101784, "time": 5305.614896535873, "episode/length": 195.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 102032, "time": 5316.584889411926, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 102320, "time": 5328.709951639175, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 102480, "time": 5336.277408361435, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 102488, "time": 5337.868047952652, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 102632, "time": 5344.666105747223, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 102736, "time": 5350.394876241684, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 102944, "time": 5359.541066169739, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 103056, "time": 5365.16688990593, "episode/length": 218.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 103632, "time": 5387.901078701019, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 103656, "time": 5390.004419803619, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 103664, "time": 5392.103364706039, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 103760, "time": 5397.206788063049, "episode/length": 215.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 103776, "time": 5399.373609542847, "episode/length": 142.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 103912, "time": 5405.8926475048065, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 104296, "time": 5421.542858839035, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 104728, "time": 5439.083735466003, "episode/length": 118.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 104752, "time": 5441.64747428894, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 104824, "time": 5445.64688873291, "episode/length": 145.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 104840, "time": 5447.795171737671, "episode/length": 134.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 104928, "time": 5452.794169425964, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 105048, "time": 5458.580230474472, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 105400, "time": 5473.117024421692, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 105752, "time": 5487.684484243393, "episode/length": 127.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 105752, "time": 5487.725986480713, "episode/length": 264.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.969811320754717, "episode/intrinsic_return": 0.0}
{"step": 105832, "time": 5494.840932607651, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 106032, "time": 5504.72078704834, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 106288, "time": 5516.466211795807, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 106328, "time": 5519.884503364563, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 106384, "time": 5524.255740880966, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 106960, "time": 5548.966508626938, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 107096, "time": 5555.366285800934, "episode/length": 167.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 107184, "time": 5560.349447011948, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 107200, "time": 5562.428050279617, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 107344, "time": 5569.131128311157, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 107488, "time": 5575.891320228577, "episode/length": 149.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 107576, "time": 5580.325112581253, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 107952, "time": 5596.063546657562, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 108336, "time": 5611.685535430908, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 108408, "time": 5615.81614613533, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 108608, "time": 5624.838919878006, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 108672, "time": 5628.734679222107, "episode/length": 32.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 108712, "time": 5631.438086271286, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 108728, "time": 5633.5304272174835, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 109032, "time": 5646.347522735596, "episode/length": 181.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 109168, "time": 5653.097795724869, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 109456, "time": 5665.141655921936, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 109536, "time": 5669.592598199844, "episode/length": 273.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 109824, "time": 5681.855865478516, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5709.223565340042, "eval_episode/length": 37.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 110032, "time": 5714.88326215744, "eval_episode/length": 144.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 110032, "time": 5716.879736185074, "eval_episode/length": 157.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 110032, "time": 5718.686322212219, "eval_episode/length": 164.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 110032, "time": 5720.3987872600555, "eval_episode/length": 167.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 110032, "time": 5722.420349597931, "eval_episode/length": 180.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 110032, "time": 5724.171802997589, "eval_episode/length": 36.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 110032, "time": 5725.75825548172, "eval_episode/length": 146.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 110464, "time": 5741.701691389084, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 110520, "time": 5745.0897789001465, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 110608, "time": 5750.051860332489, "episode/length": 133.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 110680, "time": 5754.009558916092, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 110688, "time": 5756.210597276688, "episode/length": 153.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 110728, "time": 5758.9868133068085, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 111144, "time": 5776.036532402039, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 111264, "time": 5782.874314546585, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 111576, "time": 5796.163342475891, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 111632, "time": 5800.046133041382, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 111912, "time": 5811.561863660812, "episode/length": 180.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 112000, "time": 5816.520799875259, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 112112, "time": 5822.283313751221, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 112288, "time": 5830.360383987427, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 112400, "time": 5836.095071554184, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 112616, "time": 5845.323791265488, "episode/length": 87.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 112728, "time": 5851.000644445419, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 112928, "time": 5860.205244779587, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 113096, "time": 5867.640159130096, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 113296, "time": 5876.741238832474, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 113432, "time": 5883.062517404556, "episode/length": 164.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 113632, "time": 5892.315207719803, "episode/length": 167.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 113968, "time": 5906.25913143158, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 113984, "time": 5908.325134754181, "episode/length": 170.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 114080, "time": 5913.443210363388, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 114296, "time": 5922.724184989929, "episode/length": 170.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 114536, "time": 5933.170805692673, "episode/length": 112.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 114704, "time": 5942.485133647919, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 114712, "time": 5944.177441596985, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 114800, "time": 5949.209812879562, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 115304, "time": 5968.999096632004, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 115312, "time": 5971.100954532623, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 115448, "time": 5977.418142080307, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 115704, "time": 5988.397971391678, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 115800, "time": 5993.446398019791, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 115896, "time": 5998.487484455109, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 116064, "time": 6006.440628051758, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 116344, "time": 6017.931203126907, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9461538461538461, "episode/intrinsic_return": 0.0}
{"step": 116568, "time": 6027.661062240601, "episode/length": 156.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 116896, "time": 6041.638355016708, "episode/length": 261.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 116912, "time": 6043.777006626129, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 117000, "time": 6048.389799356461, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 117160, "time": 6055.829679489136, "episode/length": 32.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 117248, "time": 6060.883458852768, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 117264, "time": 6063.036925792694, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 117776, "time": 6083.577718496323, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 117816, "time": 6086.42188334465, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 117944, "time": 6092.7601063251495, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 118256, "time": 6106.1013016700745, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 118264, "time": 6107.759383201599, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 118400, "time": 6114.677450180054, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 118584, "time": 6122.758116006851, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 118736, "time": 6130.300133943558, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 118864, "time": 6136.695385217667, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 119240, "time": 6151.884439229965, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 119392, "time": 6159.392958164215, "episode/length": 140.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 119440, "time": 6162.741807937622, "episode/length": 87.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 119552, "time": 6168.438757419586, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 119888, "time": 6182.367870569229, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 119928, "time": 6185.038561344147, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 6204.396141052246, "eval_episode/length": 37.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 120016, "time": 6206.029084444046, "eval_episode/length": 38.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 120016, "time": 6212.408529043198, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 120016, "time": 6214.191529035568, "eval_episode/length": 172.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 120016, "time": 6217.081114053726, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 120016, "time": 6218.8226482868195, "eval_episode/length": 168.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 120016, "time": 6220.482737541199, "eval_episode/length": 210.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 120016, "time": 6224.568630695343, "eval_episode/length": 272.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9816849816849816}
{"step": 120024, "time": 6224.649342775345, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 120176, "time": 6232.142728567123, "episode/length": 35.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 120328, "time": 6239.566679477692, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 120680, "time": 6254.862891197205, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 120800, "time": 6261.060191869736, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 120808, "time": 6262.675585985184, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 120880, "time": 6267.048584699631, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 121232, "time": 6281.481838226318, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 121432, "time": 6290.114160776138, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 121513, "time": 6295.529305934906, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.09897509765625, "train/action_min": 0.0, "train/action_std": 4.03808542060852, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048336714297533036, "train/actor_opt_grad_steps": 6870.0, "train/actor_opt_loss": -7.966191499829292, "train/adv_mag": 0.921586446762085, "train/adv_max": 0.9160168862342835, "train/adv_mean": 0.0035000106179650173, "train/adv_min": -0.5601708378791809, "train/adv_std": 0.08604588711261749, "train/cont_avg": 0.994109375, "train/cont_loss_mean": 0.0005448900447156575, "train/cont_loss_std": 0.014945943905739114, "train/cont_neg_acc": 0.9858152985572814, "train/cont_neg_loss": 0.050082386616759324, "train/cont_pos_acc": 0.9999291925430298, "train/cont_pos_loss": 0.00021715904519399487, "train/cont_pred": 0.9941096315383912, "train/cont_rate": 0.994109375, "train/dyn_loss_mean": 11.430789894104004, "train/dyn_loss_std": 8.44077638244629, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.107455624103546, "train/extr_critic_critic_opt_grad_steps": 6870.0, "train/extr_critic_critic_opt_loss": 15012.201359375, "train/extr_critic_mag": 3.1189975776672365, "train/extr_critic_max": 3.1189975776672365, "train/extr_critic_mean": 0.6664369356632233, "train/extr_critic_min": -0.30360516452789305, "train/extr_critic_std": 0.8403524098396301, "train/extr_return_normed_mag": 1.9368152379989625, "train/extr_return_normed_max": 1.9368152379989625, "train/extr_return_normed_mean": 0.33334724044799807, "train/extr_return_normed_min": -0.23337529212236405, "train/extr_return_normed_std": 0.35241937828063963, "train/extr_return_rate": 0.4093005425930023, "train/extr_return_raw_mag": 4.663837659835815, "train/extr_return_raw_max": 4.663837659835815, "train/extr_return_raw_mean": 0.6751522994041443, "train/extr_return_raw_min": -0.7348749310970306, "train/extr_return_raw_std": 0.8766598529815673, "train/extr_reward_mag": 1.0050708885192872, "train/extr_reward_max": 1.0050708885192872, "train/extr_reward_mean": 0.01567487218230963, "train/extr_reward_min": -0.4497921323776245, "train/extr_reward_std": 0.1100605705678463, "train/image_loss_mean": 15.271966453552245, "train/image_loss_std": 17.577440567016602, "train/model_loss_mean": 22.183470153808592, "train/model_loss_std": 21.20414852142334, "train/model_opt_grad_norm": 90.5242571105957, "train/model_opt_grad_steps": 6859.664, "train/model_opt_loss": 14492.3720234375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 655.0, "train/policy_entropy_mag": 2.557560981750488, "train/policy_entropy_max": 2.557560981750488, "train/policy_entropy_mean": 0.9034962735176086, "train/policy_entropy_min": 0.0793795844912529, "train/policy_entropy_std": 0.6703036313056946, "train/policy_logprob_mag": 7.438293312072754, "train/policy_logprob_max": -0.009456724151968956, "train/policy_logprob_mean": -0.9037828722000122, "train/policy_logprob_min": -7.438293312072754, "train/policy_logprob_std": 1.2507055320739746, "train/policy_randomness_mag": 0.9027067918777466, "train/policy_randomness_max": 0.9027067918777466, "train/policy_randomness_mean": 0.31889453542232515, "train/policy_randomness_min": 0.02801750983297825, "train/policy_randomness_std": 0.2365877674818039, "train/post_ent_mag": 50.584921203613284, "train/post_ent_max": 50.584921203613284, "train/post_ent_mean": 34.92127490234375, "train/post_ent_min": 17.62140200805664, "train/post_ent_std": 5.689780410766602, "train/prior_ent_mag": 61.77179898071289, "train/prior_ent_max": 61.77179898071289, "train/prior_ent_mean": 46.58089126586914, "train/prior_ent_min": 20.7988380279541, "train/prior_ent_std": 7.956392776489258, "train/rep_loss_mean": 11.430789894104004, "train/rep_loss_std": 8.44077638244629, "train/reward_avg": 0.014510937288403511, "train/reward_loss_mean": 0.052484940707683565, "train/reward_loss_std": 0.26795037543773653, "train/reward_max_data": 1.0024000005722047, "train/reward_max_pred": 1.0025690994262695, "train/reward_neg_acc": 0.9936381711959839, "train/reward_neg_loss": 0.03359525202214718, "train/reward_pos_acc": 0.9485238757133484, "train/reward_pos_loss": 0.9970396389961242, "train/reward_pred": 0.013870748195797205, "train/reward_rate": 0.0198046875, "train_stats/sum_log_reward": 3.8372880776049727, "train_stats/max_log_achievement_collect_drink": 4.211864406779661, "train_stats/max_log_achievement_collect_sapling": 2.26271186440678, "train_stats/max_log_achievement_collect_wood": 1.9067796610169492, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0423728813559322, "train_stats/max_log_achievement_eat_cow": 0.025423728813559324, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00847457627118644, "train_stats/max_log_achievement_make_wood_sword": 0.0423728813559322, "train_stats/max_log_achievement_place_plant": 2.2033898305084745, "train_stats/max_log_achievement_place_table": 0.6694915254237288, "train_stats/max_log_achievement_wake_up": 2.1610169491525424, "train_stats/mean_log_entropy": 0.783551266385337, "eval_stats/sum_log_reward": 2.84999992325902, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_wood": 1.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 2.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.000132618923089467, "report/cont_loss_std": 0.0025767411570996046, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.013475561514496803, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.7556390705285594e-05, "report/cont_pred": 0.9922622442245483, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.233166694641113, "report/dyn_loss_std": 8.493968963623047, "report/image_loss_mean": 13.56246566772461, "report/image_loss_std": 14.160244941711426, "report/model_loss_mean": 20.970930099487305, "report/model_loss_std": 17.63919448852539, "report/post_ent_mag": 53.06029510498047, "report/post_ent_max": 53.06029510498047, "report/post_ent_mean": 35.41339111328125, "report/post_ent_min": 15.445101737976074, "report/post_ent_std": 5.979218482971191, "report/prior_ent_mag": 62.118309020996094, "report/prior_ent_max": 62.118309020996094, "report/prior_ent_mean": 47.14789581298828, "report/prior_ent_min": 23.898563385009766, "report/prior_ent_std": 8.21455192565918, "report/rep_loss_mean": 12.233166694641113, "report/rep_loss_std": 8.493968963623047, "report/reward_avg": 0.010937499813735485, "report/reward_loss_mean": 0.06843224167823792, "report/reward_loss_std": 0.3098640739917755, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9999440908432007, "report/reward_neg_acc": 0.9900597333908081, "report/reward_neg_loss": 0.05490861088037491, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8242533206939697, "report/reward_pred": 0.01258083712309599, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.8517595890443772e-05, "eval/cont_loss_std": 9.667142148828134e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0009818918770179152, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.568691550346557e-05, "eval/cont_pred": 0.9970575571060181, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.460403442382812, "eval/dyn_loss_std": 9.047368049621582, "eval/image_loss_mean": 28.00434112548828, "eval/image_loss_std": 29.05362319946289, "eval/model_loss_mean": 37.98366928100586, "eval/model_loss_std": 32.38316345214844, "eval/post_ent_mag": 50.745399475097656, "eval/post_ent_max": 50.745399475097656, "eval/post_ent_mean": 34.24552917480469, "eval/post_ent_min": 18.321212768554688, "eval/post_ent_std": 5.687314033508301, "eval/prior_ent_mag": 62.118309020996094, "eval/prior_ent_max": 62.118309020996094, "eval/prior_ent_mean": 46.43463134765625, "eval/prior_ent_min": 19.879308700561523, "eval/prior_ent_std": 9.301984786987305, "eval/rep_loss_mean": 16.460403442382812, "eval/rep_loss_std": 9.047368049621582, "eval/reward_avg": 0.01845703087747097, "eval/reward_loss_mean": 0.10306916385889053, "eval/reward_loss_std": 0.6925798058509827, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001976490020752, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.02987266518175602, "eval/reward_pos_acc": 0.5652173757553101, "eval/reward_pos_loss": 3.288708209991455, "eval/reward_pred": 0.004440505988895893, "eval/reward_rate": 0.0224609375, "replay/size": 121009.0, "replay/inserts": 20016.0, "replay/samples": 20016.0, "replay/insert_wait_avg": 1.3659159533030314e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.968488261758757e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23304.0, "eval_replay/inserts": 3664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1197344184442378e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2340445518494, "timer/env.step_count": 2502.0, "timer/env.step_total": 252.6164848804474, "timer/env.step_frac": 0.2525573752027518, "timer/env.step_avg": 0.10096582129514284, "timer/env.step_min": 0.02307581901550293, "timer/env.step_max": 4.104059934616089, "timer/replay._sample_count": 20016.0, "timer/replay._sample_total": 10.195529460906982, "timer/replay._sample_frac": 0.01019314381113177, "timer/replay._sample_avg": 0.0005093689778630587, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.028967618942260742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2960.0, "timer/agent.policy_total": 49.02354121208191, "timer/agent.policy_frac": 0.04901207020407579, "timer/agent.policy_avg": 0.016562007166243887, "timer/agent.policy_min": 0.009490251541137695, "timer/agent.policy_max": 0.09415197372436523, "timer/dataset_train_count": 1251.0, "timer/dataset_train_total": 0.1414036750793457, "timer/dataset_train_frac": 0.00014137058806341771, "timer/dataset_train_avg": 0.00011303251405223478, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0003695487976074219, "timer/agent.train_count": 1251.0, "timer/agent.train_total": 561.9909017086029, "timer/agent.train_frac": 0.5618594015767585, "timer/agent.train_avg": 0.449233334699123, "timer/agent.train_min": 0.43910717964172363, "timer/agent.train_max": 1.0146276950836182, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475506067276001, "timer/agent.report_frac": 0.00047539480371221464, "timer/agent.report_avg": 0.2377530336380005, "timer/agent.report_min": 0.2304368019104004, "timer/agent.report_max": 0.24506926536560059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.621990707477103e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 20.011071731408418}
{"step": 121528, "time": 6295.669555902481, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 121912, "time": 6311.80939745903, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 121952, "time": 6315.047037124634, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 121952, "time": 6315.099322080612, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 122072, "time": 6322.603438138962, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 122248, "time": 6330.596415519714, "episode/length": 36.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 122472, "time": 6340.2704956531525, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 122544, "time": 6344.76308298111, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 122560, "time": 6346.774639368057, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 122744, "time": 6354.829683303833, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 122928, "time": 6365.330091238022, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 123064, "time": 6372.17275595665, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 123512, "time": 6390.64275097847, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 123520, "time": 6392.782269001007, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 123616, "time": 6397.909920454025, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 123624, "time": 6399.4776656627655, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 123792, "time": 6407.3727831840515, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 124584, "time": 6437.654549360275, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 124584, "time": 6437.689072370529, "episode/length": 189.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 124800, "time": 6449.103961467743, "episode/length": 146.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 124824, "time": 6451.344017982483, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 124928, "time": 6457.040452480316, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 125128, "time": 6465.728058815002, "episode/length": 274.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 125168, "time": 6468.8764889240265, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 125184, "time": 6471.073504447937, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 125528, "time": 6484.9004735946655, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 125864, "time": 6498.930003643036, "episode/length": 84.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 125936, "time": 6503.855380296707, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 126328, "time": 6521.214519739151, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 126456, "time": 6527.349697351456, "episode/length": 206.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 126600, "time": 6534.175906658173, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 126640, "time": 6537.3580503463745, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 126904, "time": 6548.472136259079, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 126992, "time": 6553.54368019104, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 127304, "time": 6566.278899669647, "episode/length": 170.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 127608, "time": 6579.3073699474335, "episode/length": 125.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 127808, "time": 6588.862423419952, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 127824, "time": 6590.879388809204, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 127848, "time": 6592.971973180771, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 128168, "time": 6606.362131595612, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 128408, "time": 6616.8445744514465, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 128568, "time": 6624.396687507629, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 128680, "time": 6630.05010175705, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 129016, "time": 6644.112100124359, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 129056, "time": 6647.29346871376, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 129392, "time": 6661.015994310379, "episode/length": 192.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 129464, "time": 6664.884908437729, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 129808, "time": 6679.432384490967, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 129840, "time": 6682.168092250824, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 129864, "time": 6684.420942783356, "episode/length": 161.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6711.479202032089, "eval_episode/length": 144.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 130000, "time": 6713.060795068741, "eval_episode/length": 145.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 130000, "time": 6714.818284034729, "eval_episode/length": 151.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993421052631579}
{"step": 130000, "time": 6718.086110591888, "eval_episode/length": 194.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 130000, "time": 6718.133632183075, "eval_episode/length": 194.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 130000, "time": 6721.550308704376, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 130000, "time": 6723.055554866791, "eval_episode/length": 197.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 130000, "time": 6728.491933584213, "eval_episode/length": 149.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 130208, "time": 6736.107673406601, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 130336, "time": 6742.3167552948, "episode/length": 206.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 130552, "time": 6752.0256135463715, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 130784, "time": 6763.063590526581, "episode/length": 173.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 130784, "time": 6763.11478972435, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 130984, "time": 6774.590161323547, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 131096, "time": 6782.224111557007, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 131440, "time": 6797.37678027153, "episode/length": 199.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 132000, "time": 6820.6345109939575, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 132008, "time": 6822.726266860962, "episode/length": 224.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 132016, "time": 6825.2362740039825, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 132096, "time": 6830.156725883484, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 132272, "time": 6838.107669353485, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 132304, "time": 6840.785856962204, "episode/length": 37.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 132440, "time": 6847.107718706131, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 132656, "time": 6856.780079603195, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 132672, "time": 6858.921443223953, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 133384, "time": 6886.578261375427, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 133520, "time": 6893.962917566299, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 133656, "time": 6900.884422302246, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 133864, "time": 6911.085420131683, "episode/length": 148.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 133896, "time": 6914.260504484177, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 134008, "time": 6920.420526981354, "episode/length": 216.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 134016, "time": 6922.883814096451, "episode/length": 239.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 134112, "time": 6928.488748788834, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 134648, "time": 6950.1408433914185, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 134864, "time": 6959.856235742569, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 135224, "time": 6974.558702468872, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 135280, "time": 6978.372850179672, "episode/length": 176.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 135384, "time": 6983.572097539902, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 135472, "time": 6988.497841119766, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 135592, "time": 6994.157743930817, "episode/length": 258.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 135984, "time": 7010.234157562256, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 136320, "time": 7023.9951775074005, "episode/length": 275.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 136632, "time": 7036.861343383789, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 136672, "time": 7040.128336191177, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 136680, "time": 7041.722608327866, "episode/length": 226.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 136800, "time": 7047.959697723389, "episode/length": 189.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 137096, "time": 7060.085446596146, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 137144, "time": 7063.372639417648, "episode/length": 144.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 137488, "time": 7077.773042917252, "episode/length": 354.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9971830985915493, "episode/intrinsic_return": 0.0}
{"step": 138096, "time": 7101.643428325653, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 138408, "time": 7114.341000795364, "episode/length": 366.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 138432, "time": 7117.124270200729, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9908675799086758, "episode/intrinsic_return": 0.0}
{"step": 138448, "time": 7119.230311870575, "episode/length": 221.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 138456, "time": 7120.770421028137, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 138520, "time": 7124.748162984848, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 138736, "time": 7134.297513246536, "episode/length": 241.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 139536, "time": 7166.528757572174, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 139880, "time": 7180.51144695282, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 139888, "time": 7182.543138027191, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 139896, "time": 7184.209491491318, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 140024, "time": 7190.30961728096, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 140048, "time": 7192.967684268951, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 7214.238446712494, "eval_episode/length": 147.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 140088, "time": 7216.105542898178, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 140088, "time": 7217.901472091675, "eval_episode/length": 163.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 140088, "time": 7219.829337120056, "eval_episode/length": 173.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 140088, "time": 7222.289682865143, "eval_episode/length": 192.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 140088, "time": 7224.716000556946, "eval_episode/length": 217.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 140088, "time": 7227.094001531601, "eval_episode/length": 235.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 140088, "time": 7231.027538061142, "eval_episode/length": 299.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.99}
{"step": 140232, "time": 7236.397437095642, "episode/length": 213.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 140504, "time": 7247.811131477356, "episode/length": 256.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 141032, "time": 7268.484689235687, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 141040, "time": 7270.493762016296, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 141472, "time": 7287.821059465408, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 141480, "time": 7289.455767869949, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 141512, "time": 7292.172506570816, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 141545, "time": 7296.102689266205, "train_stats/sum_log_reward": 4.136035972887331, "train_stats/max_log_achievement_collect_drink": 4.8108108108108105, "train_stats/max_log_achievement_collect_sapling": 2.6126126126126126, "train_stats/max_log_achievement_collect_wood": 2.099099099099099, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.10810810810810811, "train_stats/max_log_achievement_eat_cow": 0.06306306306306306, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05405405405405406, "train_stats/max_log_achievement_make_wood_sword": 0.08108108108108109, "train_stats/max_log_achievement_place_plant": 2.5405405405405403, "train_stats/max_log_achievement_place_table": 0.7567567567567568, "train_stats/max_log_achievement_wake_up": 2.369369369369369, "train_stats/mean_log_entropy": 0.8786907571930069, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.057317340184772, "train/action_min": 0.0, "train/action_std": 3.924128275068979, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049416566267609596, "train/actor_opt_grad_steps": 8125.0, "train/actor_opt_loss": -1.8952019174420645, "train/adv_mag": 0.9488847109060439, "train/adv_max": 0.9445552882694063, "train/adv_mean": 0.004682244278709522, "train/adv_min": -0.5478750434186723, "train/adv_std": 0.08807551529672411, "train/cont_avg": 0.9939701140873016, "train/cont_loss_mean": 0.0006200901730895541, "train/cont_loss_std": 0.018265048718517175, "train/cont_neg_acc": 0.9815980129771762, "train/cont_neg_loss": 0.058001058938922746, "train/cont_pos_acc": 0.99990637529464, "train/cont_pos_loss": 0.00025462616177104484, "train/cont_pred": 0.9939646271486131, "train/cont_rate": 0.9939701140873016, "train/dyn_loss_mean": 12.33144151596796, "train/dyn_loss_std": 8.673625669782124, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.064125576189586, "train/extr_critic_critic_opt_grad_steps": 8125.0, "train/extr_critic_critic_opt_loss": 15011.787473648314, "train/extr_critic_mag": 3.233515627800472, "train/extr_critic_max": 3.233515627800472, "train/extr_critic_mean": 0.6603410914540291, "train/extr_critic_min": -0.3107803340942141, "train/extr_critic_std": 0.8667315041262006, "train/extr_return_normed_mag": 1.98387768060442, "train/extr_return_normed_max": 1.98387768060442, "train/extr_return_normed_mean": 0.3238847078312011, "train/extr_return_normed_min": -0.24051584918347615, "train/extr_return_normed_std": 0.36285275705750025, "train/extr_return_rate": 0.3845072950399111, "train/extr_return_raw_mag": 4.831548299108233, "train/extr_return_raw_max": 4.831548299108233, "train/extr_return_raw_mean": 0.6721213624354393, "train/extr_return_raw_min": -0.7418598246479792, "train/extr_return_raw_std": 0.9092369401265704, "train/extr_reward_mag": 1.0050696323788355, "train/extr_reward_max": 1.0050696323788355, "train/extr_reward_mean": 0.01691751992921271, "train/extr_reward_min": -0.4970204092207409, "train/extr_reward_std": 0.11790723288579592, "train/image_loss_mean": 12.826106707255045, "train/image_loss_std": 14.740333246806312, "train/model_loss_mean": 20.275399957384383, "train/model_loss_std": 18.507396569327703, "train/model_opt_grad_norm": 85.07846944294279, "train/model_opt_grad_steps": 8113.619047619048, "train/model_opt_loss": 14688.885246155754, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 724.2063492063492, "train/policy_entropy_mag": 2.5440990224717157, "train/policy_entropy_max": 2.5440990224717157, "train/policy_entropy_mean": 0.9393436780997685, "train/policy_entropy_min": 0.0793788091885665, "train/policy_entropy_std": 0.7236102294354212, "train/policy_logprob_mag": 7.438353504453387, "train/policy_logprob_max": -0.009456589160161831, "train/policy_logprob_mean": -0.9398764977379451, "train/policy_logprob_min": -7.438353504453387, "train/policy_logprob_std": 1.2609173759581551, "train/policy_randomness_mag": 0.8979553126153492, "train/policy_randomness_max": 0.8979553126153492, "train/policy_randomness_mean": 0.3315470993282303, "train/policy_randomness_min": 0.028017236082445062, "train/policy_randomness_std": 0.2554026541728822, "train/post_ent_mag": 52.39886922684927, "train/post_ent_max": 52.39886922684927, "train/post_ent_mean": 35.59047178238157, "train/post_ent_min": 18.4538970977541, "train/post_ent_std": 5.727078574044364, "train/prior_ent_mag": 62.76974587213425, "train/prior_ent_max": 62.76974587213425, "train/prior_ent_mean": 48.11114084152948, "train/prior_ent_min": 22.54536154913524, "train/prior_ent_std": 7.664199836670407, "train/rep_loss_mean": 12.33144151596796, "train/rep_loss_std": 8.673625669782124, "train/reward_avg": 0.01575598324139026, "train/reward_loss_mean": 0.049808313744881795, "train/reward_loss_std": 0.2505394471070123, "train/reward_max_data": 1.007936509828719, "train/reward_max_pred": 1.0027467050249614, "train/reward_neg_acc": 0.9939862943830944, "train/reward_neg_loss": 0.030478512986548363, "train/reward_pos_acc": 0.9531399172449869, "train/reward_pos_loss": 0.9533377251927815, "train/reward_pred": 0.015069697721166507, "train/reward_rate": 0.021050347222222224, "train_stats/max_log_achievement_collect_stone": 0.05128205128205128, "eval_stats/sum_log_reward": 4.037499904632568, "eval_stats/max_log_achievement_collect_drink": 6.0625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_table": 0.8125, "eval_stats/max_log_achievement_wake_up": 2.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.6423376766615547e-05, "report/cont_loss_std": 0.000402009638492018, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010475898161530495, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.2418798835133202e-05, "report/cont_pred": 0.9960756301879883, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.953489303588867, "report/dyn_loss_std": 8.351468086242676, "report/image_loss_mean": 9.661154747009277, "report/image_loss_std": 11.293638229370117, "report/model_loss_mean": 16.26202392578125, "report/model_loss_std": 14.92030143737793, "report/post_ent_mag": 53.42181396484375, "report/post_ent_max": 53.42181396484375, "report/post_ent_mean": 34.95724105834961, "report/post_ent_min": 18.86669158935547, "report/post_ent_std": 5.3768157958984375, "report/prior_ent_mag": 63.70684814453125, "report/prior_ent_max": 63.70684814453125, "report/prior_ent_mean": 46.90776824951172, "report/prior_ent_min": 21.05623435974121, "report/prior_ent_std": 7.943883419036865, "report/rep_loss_mean": 10.953489303588867, "report/rep_loss_std": 8.351468086242676, "report/reward_avg": 0.01357421837747097, "report/reward_loss_mean": 0.028748750686645508, "report/reward_loss_std": 0.16935621201992035, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0054514408111572, "report/reward_neg_acc": 0.9980159401893616, "report/reward_neg_loss": 0.01847565919160843, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6759538054466248, "report/reward_pred": 0.013945414684712887, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0011288885725662112, "eval/cont_loss_std": 0.02732717990875244, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00028057245071977377, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.001134727499447763, "eval/cont_pred": 0.992330014705658, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 14.448968887329102, "eval/dyn_loss_std": 8.561202049255371, "eval/image_loss_mean": 13.383098602294922, "eval/image_loss_std": 16.847572326660156, "eval/model_loss_mean": 22.0965576171875, "eval/model_loss_std": 20.00879669189453, "eval/post_ent_mag": 48.67286682128906, "eval/post_ent_max": 48.67286682128906, "eval/post_ent_mean": 34.6434440612793, "eval/post_ent_min": 18.743452072143555, "eval/post_ent_std": 4.233297348022461, "eval/prior_ent_mag": 63.70684814453125, "eval/prior_ent_max": 63.70684814453125, "eval/prior_ent_mean": 47.154449462890625, "eval/prior_ent_min": 25.69493293762207, "eval/prior_ent_std": 5.820681095123291, "eval/rep_loss_mean": 14.448968887329102, "eval/rep_loss_std": 8.561202049255371, "eval/reward_avg": 0.008105468936264515, "eval/reward_loss_mean": 0.04294822737574577, "eval/reward_loss_std": 0.2891613841056824, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002046823501587, "eval/reward_neg_acc": 0.9990108609199524, "eval/reward_neg_loss": 0.03065996989607811, "eval/reward_pos_acc": 0.9230769872665405, "eval/reward_pos_loss": 0.9985965490341187, "eval/reward_pred": 0.006765924394130707, "eval/reward_rate": 0.0126953125, "replay/size": 141041.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.3731324825043115e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.13446296289706e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28064.0, "eval_replay/inserts": 4760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1119021087133584e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5614798069, "timer/env.step_count": 2504.0, "timer/env.step_total": 249.10304522514343, "timer/env.step_frac": 0.24896325738346256, "timer/env.step_avg": 0.09948204681515313, "timer/env.step_min": 0.023135900497436523, "timer/env.step_max": 4.1839988231658936, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 10.33540391921997, "timer/replay._sample_frac": 0.010329604055129742, "timer/replay._sample_avg": 0.0005159446844658532, "timer/replay._sample_min": 0.0003895759582519531, "timer/replay._sample_max": 0.028623104095458984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3099.0, "timer/agent.policy_total": 52.87730431556702, "timer/agent.policy_frac": 0.052847631437672266, "timer/agent.policy_avg": 0.01706269903696903, "timer/agent.policy_min": 0.00943136215209961, "timer/agent.policy_max": 0.11908793449401855, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.1397686004638672, "timer/dataset_train_frac": 0.0001396901672557306, "timer/dataset_train_avg": 0.00011163626235133162, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0005686283111572266, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 560.1692085266113, "timer/agent.train_frac": 0.5598548613271813, "timer/agent.train_avg": 0.4474194956282838, "timer/agent.train_min": 0.43326473236083984, "timer/agent.train_max": 1.1076221466064453, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47135066986083984, "timer/agent.report_frac": 0.0004710861644921675, "timer/agent.report_avg": 0.23567533493041992, "timer/agent.report_min": 0.2281169891357422, "timer/agent.report_max": 0.24323368072509766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6449611357595794e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 20.020522508828208}
{"step": 141592, "time": 7297.6544713974, "episode/length": 256.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 141616, "time": 7300.287544727325, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 141632, "time": 7302.498528003693, "episode/length": 140.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 142152, "time": 7322.8121082782745, "episode/length": 138.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 142792, "time": 7347.887025117874, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 142928, "time": 7354.752947092056, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 142960, "time": 7357.63693022728, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 143136, "time": 7365.6710793972015, "episode/length": 189.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 143152, "time": 7367.8135352134705, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 143232, "time": 7372.42058968544, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 143784, "time": 7394.076421260834, "episode/length": 203.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 143792, "time": 7396.197464704514, "episode/length": 344.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 144160, "time": 7411.068567991257, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 144160, "time": 7411.119477987289, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 144512, "time": 7427.42299413681, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 144536, "time": 7429.635831356049, "episode/length": 172.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 144608, "time": 7434.051137447357, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 144712, "time": 7439.213459014893, "episode/length": 239.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 145176, "time": 7457.917092323303, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 145472, "time": 7470.722118377686, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 145576, "time": 7476.332095384598, "episode/length": 107.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 145776, "time": 7485.893560171127, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 145848, "time": 7489.940109968185, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 145856, "time": 7492.001153707504, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 145912, "time": 7495.400203943253, "episode/length": 218.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 146280, "time": 7510.5928654670715, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 146368, "time": 7515.5085208415985, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 146824, "time": 7533.627997875214, "episode/length": 168.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 146888, "time": 7537.585270881653, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 147096, "time": 7546.674129247665, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 147096, "time": 7546.715059995651, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 147280, "time": 7556.978064537048, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 147560, "time": 7569.968487024307, "episode/length": 159.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 147664, "time": 7575.478880167007, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 147664, "time": 7575.543527603149, "episode/length": 161.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 147864, "time": 7586.001878023148, "episode/length": 95.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 148232, "time": 7601.186527729034, "episode/length": 175.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 148272, "time": 7604.321253538132, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 148808, "time": 7625.313166379929, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 148872, "time": 7629.281129837036, "episode/length": 198.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 148984, "time": 7634.907484054565, "episode/length": 88.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 149032, "time": 7638.192380189896, "episode/length": 267.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 149120, "time": 7643.231835126877, "episode/length": 156.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 149208, "time": 7647.762560129166, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 149744, "time": 7669.235537290573, "episode/length": 259.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7696.689702272415, "eval_episode/length": 37.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 150072, "time": 7702.391199588776, "eval_episode/length": 147.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 150072, "time": 7705.275208950043, "eval_episode/length": 179.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 150072, "time": 7706.804847955704, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 150072, "time": 7708.5061848163605, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 150072, "time": 7710.348976612091, "eval_episode/length": 156.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 150072, "time": 7711.937623500824, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 150072, "time": 7713.539514303207, "eval_episode/length": 199.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.995}
{"step": 150144, "time": 7716.440398216248, "episode/length": 138.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 150152, "time": 7718.084404706955, "episode/length": 145.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 150168, "time": 7720.273832321167, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 150368, "time": 7729.260774374008, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 150432, "time": 7733.1789927482605, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 150568, "time": 7739.475770950317, "episode/length": 219.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 150960, "time": 7755.643660068512, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 151104, "time": 7762.506302595139, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 151248, "time": 7769.35057425499, "episode/length": 136.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 151592, "time": 7783.54700255394, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 151728, "time": 7790.247447252274, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 151800, "time": 7794.134915828705, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 152456, "time": 7819.567599773407, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 152472, "time": 7821.662033081055, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 152696, "time": 7831.56884431839, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 152744, "time": 7835.432919025421, "episode/length": 143.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 152832, "time": 7840.900928497314, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 152952, "time": 7847.223160266876, "episode/length": 248.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 153120, "time": 7855.657281637192, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 153400, "time": 7867.132225513458, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 153952, "time": 7889.040675163269, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 154040, "time": 7893.571840047836, "episode/length": 150.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 154088, "time": 7896.898955106735, "episode/length": 203.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 154192, "time": 7902.4586770534515, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 154256, "time": 7906.289861679077, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 154256, "time": 7906.337644338608, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 154608, "time": 7922.457326173782, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 154776, "time": 7929.995262622833, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 155072, "time": 7942.548513174057, "episode/length": 139.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 155320, "time": 7952.931547880173, "episode/length": 132.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 155576, "time": 7964.167814016342, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 155712, "time": 7972.289854049683, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 155880, "time": 7979.775207519531, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 156000, "time": 7986.156620979309, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 156056, "time": 7989.608755111694, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 156344, "time": 8001.633745670319, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 156600, "time": 8012.422802209854, "episode/length": 292.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 156640, "time": 8015.646451711655, "episode/length": 115.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 156928, "time": 8027.768790960312, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 157376, "time": 8045.822132349014, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 157496, "time": 8051.573388338089, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 157584, "time": 8056.506122589111, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 157992, "time": 8072.688324689865, "episode/length": 301.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 158040, "time": 8075.968546152115, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 158064, "time": 8078.660487651825, "episode/length": 272.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 158168, "time": 8083.821697235107, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 158760, "time": 8107.060684919357, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 159056, "time": 8119.659499645233, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 159240, "time": 8127.842184782028, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 159272, "time": 8130.519952297211, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 159272, "time": 8130.571991682053, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 159376, "time": 8138.064592838287, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 159568, "time": 8146.596053361893, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 159800, "time": 8156.422649860382, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 159856, "time": 8160.29772233963, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 160016, "time": 8167.825576066971, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 8189.073823213577, "eval_episode/length": 147.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 160056, "time": 8191.388078451157, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 160056, "time": 8193.139115571976, "eval_episode/length": 171.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 160056, "time": 8193.187807559967, "eval_episode/length": 171.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 160056, "time": 8196.664902448654, "eval_episode/length": 173.0, "eval_episode/score": 4.1000000312924385, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 160056, "time": 8198.93176984787, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9633507853403142}
{"step": 160056, "time": 8200.718938589096, "eval_episode/length": 196.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 160056, "time": 8203.940416812897, "eval_episode/length": 240.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.979253112033195}
{"step": 160096, "time": 8205.62126326561, "episode/length": 102.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 160696, "time": 8228.82492017746, "episode/length": 104.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 160752, "time": 8232.519362449646, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 160800, "time": 8235.893940210342, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 161024, "time": 8245.612112283707, "episode/length": 282.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 161232, "time": 8254.741374015808, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 161248, "time": 8256.985412597656, "episode/length": 246.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 161480, "time": 8266.702433347702, "episode/length": 209.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 161608, "time": 8272.909520626068, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 161920, "time": 8286.141910791397, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 162040, "time": 8291.807435512543, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 162089, "time": 8296.167932748795, "train_stats/sum_log_reward": 4.1714285005416185, "train_stats/max_log_achievement_collect_drink": 5.821428571428571, "train_stats/max_log_achievement_collect_sapling": 2.7589285714285716, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.9375, "train_stats/max_log_achievement_defeat_skeleton": 0.008928571428571428, "train_stats/max_log_achievement_defeat_zombie": 0.09821428571428571, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.026785714285714284, "train_stats/max_log_achievement_make_wood_sword": 0.0625, "train_stats/max_log_achievement_place_plant": 2.4642857142857144, "train_stats/max_log_achievement_place_table": 0.625, "train_stats/max_log_achievement_wake_up": 2.6160714285714284, "train_stats/mean_log_entropy": 0.8944297762853759, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.594101905822754, "train/action_min": 0.0, "train/action_std": 4.089793276041746, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04779543093172833, "train/actor_opt_grad_steps": 9395.0, "train/actor_opt_loss": 9.574028617702425, "train/adv_mag": 0.8728107064962387, "train/adv_max": 0.8597433513496071, "train/adv_mean": 0.006027329458135, "train/adv_min": -0.5508378196973354, "train/adv_std": 0.08393976106890477, "train/cont_avg": 0.994354248046875, "train/cont_loss_mean": 0.00047105282694337447, "train/cont_loss_std": 0.013377794889045447, "train/cont_neg_acc": 0.9876922154799104, "train/cont_neg_loss": 0.03718733042941125, "train/cont_pos_acc": 0.9999232324771583, "train/cont_pos_loss": 0.00023179138128148757, "train/cont_pred": 0.9943542489781976, "train/cont_rate": 0.994354248046875, "train/dyn_loss_mean": 12.519400507211685, "train/dyn_loss_std": 8.885352715849876, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0334565252996981, "train/extr_critic_critic_opt_grad_steps": 9395.0, "train/extr_critic_critic_opt_loss": 15022.958099365234, "train/extr_critic_mag": 3.517725510522723, "train/extr_critic_max": 3.517725510522723, "train/extr_critic_mean": 0.6756674125790596, "train/extr_critic_min": -0.3058881154283881, "train/extr_critic_std": 0.9256934409495443, "train/extr_return_normed_mag": 1.8493637908250093, "train/extr_return_normed_max": 1.8493637908250093, "train/extr_return_normed_mean": 0.2933870900887996, "train/extr_return_normed_min": -0.2118523785029538, "train/extr_return_normed_std": 0.3518391518155113, "train/extr_return_rate": 0.36599326389841735, "train/extr_return_raw_mag": 4.975818309932947, "train/extr_return_raw_max": 4.975818309932947, "train/extr_return_raw_mean": 0.6922875205054879, "train/extr_return_raw_min": -0.6989615852944553, "train/extr_return_raw_std": 0.9690128481015563, "train/extr_reward_mag": 1.0054150242358446, "train/extr_reward_max": 1.0054150242358446, "train/extr_reward_mean": 0.01758678954502102, "train/extr_reward_min": -0.49335178174078465, "train/extr_reward_std": 0.1204509039525874, "train/image_loss_mean": 11.163491059094667, "train/image_loss_std": 13.9257120937109, "train/model_loss_mean": 18.725174613296986, "train/model_loss_std": 17.710950165987015, "train/model_opt_grad_norm": 80.25964206457138, "train/model_opt_grad_steps": 9382.7578125, "train/model_opt_loss": 15971.361347198486, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 844.7265625, "train/policy_entropy_mag": 2.5545488093048334, "train/policy_entropy_max": 2.5545488093048334, "train/policy_entropy_mean": 0.9758615992031991, "train/policy_entropy_min": 0.07937652722466737, "train/policy_entropy_std": 0.7861563349142671, "train/policy_logprob_mag": 7.438355691730976, "train/policy_logprob_max": -0.009456090250751004, "train/policy_logprob_mean": -0.9755287822335958, "train/policy_logprob_min": -7.438355691730976, "train/policy_logprob_std": 1.2808146914467216, "train/policy_randomness_mag": 0.9016436282545328, "train/policy_randomness_max": 0.9016436282545328, "train/policy_randomness_mean": 0.34443632210604846, "train/policy_randomness_min": 0.028016430718707852, "train/policy_randomness_std": 0.2774786854861304, "train/post_ent_mag": 53.32209771871567, "train/post_ent_max": 53.32209771871567, "train/post_ent_mean": 36.1518095433712, "train/post_ent_min": 19.039803877472878, "train/post_ent_std": 5.938751135021448, "train/prior_ent_mag": 63.54072427749634, "train/prior_ent_max": 63.54072427749634, "train/prior_ent_mean": 48.83801546692848, "train/prior_ent_min": 24.158172711730003, "train/prior_ent_std": 7.522893946617842, "train/rep_loss_mean": 12.519400507211685, "train/rep_loss_std": 8.885352715849876, "train/reward_avg": 0.015959930347889895, "train/reward_loss_mean": 0.049572255651582964, "train/reward_loss_std": 0.258610894321464, "train/reward_max_data": 1.0070312516763806, "train/reward_max_pred": 1.003111851401627, "train/reward_neg_acc": 0.994192065205425, "train/reward_neg_loss": 0.029936889430246083, "train/reward_pos_acc": 0.9467015150003135, "train/reward_pos_loss": 0.9726330954581499, "train/reward_pred": 0.015194889783742838, "train/reward_rate": 0.0210418701171875, "eval_stats/sum_log_reward": 4.2874999195337296, "eval_stats/max_log_achievement_collect_drink": 7.0, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_table": 0.75, "eval_stats/max_log_achievement_wake_up": 2.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.7027790565625764e-05, "report/cont_loss_std": 0.0004020996275357902, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013617112999781966, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6518470147275366e-05, "report/cont_pred": 0.9921818971633911, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.565251350402832, "report/dyn_loss_std": 9.654871940612793, "report/image_loss_mean": 11.125638961791992, "report/image_loss_std": 16.235424041748047, "report/model_loss_mean": 18.725419998168945, "report/model_loss_std": 20.314233779907227, "report/post_ent_mag": 55.940792083740234, "report/post_ent_max": 55.940792083740234, "report/post_ent_mean": 36.230384826660156, "report/post_ent_min": 20.490680694580078, "report/post_ent_std": 6.403181076049805, "report/prior_ent_mag": 64.62544250488281, "report/prior_ent_max": 64.62544250488281, "report/prior_ent_mean": 49.01390075683594, "report/prior_ent_min": 25.2862606048584, "report/prior_ent_std": 7.650173664093018, "report/rep_loss_mean": 12.565251350402832, "report/rep_loss_std": 9.654871940612793, "report/reward_avg": 0.02333984337747097, "report/reward_loss_mean": 0.060603007674217224, "report/reward_loss_std": 0.24219392240047455, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0203609466552734, "report/reward_neg_acc": 0.9979878664016724, "report/reward_neg_loss": 0.03993929550051689, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7452608346939087, "report/reward_pred": 0.022335726767778397, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 3.804383959504776e-05, "eval/cont_loss_std": 0.0010147280991077423, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005527574103325605, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.594623822460562e-07, "eval/cont_pred": 0.9932011365890503, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 13.169126510620117, "eval/dyn_loss_std": 9.54440975189209, "eval/image_loss_mean": 15.1331787109375, "eval/image_loss_std": 24.37353515625, "eval/model_loss_mean": 23.106849670410156, "eval/model_loss_std": 27.599693298339844, "eval/post_ent_mag": 52.13511657714844, "eval/post_ent_max": 52.13511657714844, "eval/post_ent_mean": 37.845191955566406, "eval/post_ent_min": 19.151430130004883, "eval/post_ent_std": 6.15944242477417, "eval/prior_ent_mag": 64.62544250488281, "eval/prior_ent_max": 64.62544250488281, "eval/prior_ent_mean": 49.23382568359375, "eval/prior_ent_min": 25.020437240600586, "eval/prior_ent_std": 7.125766754150391, "eval/rep_loss_mean": 13.169126510620117, "eval/rep_loss_std": 9.54440975189209, "eval/reward_avg": 0.010839843191206455, "eval/reward_loss_mean": 0.07215739786624908, "eval/reward_loss_std": 0.49249348044395447, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002103328704834, "eval/reward_neg_acc": 0.996023952960968, "eval/reward_neg_loss": 0.036494798958301544, "eval/reward_pos_acc": 0.7222222089767456, "eval/reward_pos_loss": 2.065300464630127, "eval/reward_pred": 0.0072520035319030285, "eval/reward_rate": 0.017578125, "replay/size": 161585.0, "replay/inserts": 20544.0, "replay/samples": 20544.0, "replay/insert_wait_avg": 1.3811078584082772e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.114285743867869e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31592.0, "eval_replay/inserts": 3528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1117415092969969e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0493326187134, "timer/env.step_count": 2568.0, "timer/env.step_total": 243.17728400230408, "timer/env.step_frac": 0.24316528802186577, "timer/env.step_avg": 0.09469520405074146, "timer/env.step_min": 0.02278757095336914, "timer/env.step_max": 3.393948793411255, "timer/replay._sample_count": 20544.0, "timer/replay._sample_total": 10.624985933303833, "timer/replay._sample_frac": 0.01062446180078078, "timer/replay._sample_avg": 0.0005171819476880759, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.011558771133422852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3009.0, "timer/agent.policy_total": 49.6888062953949, "timer/agent.policy_frac": 0.04968635513738165, "timer/agent.policy_avg": 0.01651339524606012, "timer/agent.policy_min": 0.00950312614440918, "timer/agent.policy_max": 0.08846163749694824, "timer/dataset_train_count": 1284.0, "timer/dataset_train_total": 0.1434030532836914, "timer/dataset_train_frac": 0.00014339597918452526, "timer/dataset_train_avg": 0.00011168462093745436, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0005908012390136719, "timer/agent.train_count": 1284.0, "timer/agent.train_total": 572.5217792987823, "timer/agent.train_frac": 0.5724935366934207, "timer/agent.train_avg": 0.44588923621400495, "timer/agent.train_min": 0.43570876121520996, "timer/agent.train_max": 1.0573475360870361, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47425246238708496, "timer/agent.report_frac": 0.00047422906742531886, "timer/agent.report_avg": 0.23712623119354248, "timer/agent.report_min": 0.2296302318572998, "timer/agent.report_max": 0.24462223052978516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9800852233614737e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.542719248901502}
{"step": 162240, "time": 8301.725082159042, "episode/length": 179.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 162408, "time": 8309.175081968307, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 162504, "time": 8314.250902414322, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 162568, "time": 8318.224524259567, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 162656, "time": 8323.11351275444, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 163104, "time": 8341.042853832245, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 163328, "time": 8350.847011566162, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 163360, "time": 8353.585041046143, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 163512, "time": 8360.472981452942, "episode/length": 158.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 163712, "time": 8369.60527396202, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 163880, "time": 8378.497345685959, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 163984, "time": 8384.089508533478, "episode/length": 81.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 164208, "time": 8393.875011444092, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 164240, "time": 8396.563816070557, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 164776, "time": 8417.577963113785, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 165064, "time": 8429.772941350937, "episode/length": 106.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 165352, "time": 8441.890656232834, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 165352, "time": 8441.942025184631, "episode/length": 280.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 165552, "time": 8453.048238515854, "episode/length": 208.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 165784, "time": 8462.84341263771, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 166016, "time": 8473.149990558624, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 166264, "time": 8483.660860300064, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 166560, "time": 8496.368087291718, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 166688, "time": 8502.64239192009, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 166848, "time": 8509.983254671097, "episode/length": 435.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 166912, "time": 8513.871711730957, "episode/length": 169.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 167008, "time": 8518.939782619476, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 167152, "time": 8525.89313697815, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 167192, "time": 8528.731251955032, "episode/length": 301.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 167904, "time": 8556.68531036377, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 168072, "time": 8564.19502043724, "episode/length": 225.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 168256, "time": 8572.591052293777, "episode/length": 195.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 168296, "time": 8575.487958192825, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 168336, "time": 8578.671226024628, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 168376, "time": 8581.413769721985, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 168520, "time": 8588.2898645401, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 168728, "time": 8597.379399299622, "episode/length": 270.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 169024, "time": 8610.015186309814, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 169384, "time": 8624.645858764648, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 169536, "time": 8631.876189231873, "episode/length": 126.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 169792, "time": 8642.850727796555, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 169880, "time": 8647.350307226181, "episode/length": 143.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 170016, "time": 8654.081823587418, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8676.3562104702, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 170040, "time": 8678.226741790771, "eval_episode/length": 155.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 170040, "time": 8680.095257520676, "eval_episode/length": 157.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 170040, "time": 8681.961288928986, "eval_episode/length": 167.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 170040, "time": 8683.954124450684, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 170040, "time": 8686.106179237366, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 170040, "time": 8687.879633903503, "eval_episode/length": 44.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9111111111111111}
{"step": 170040, "time": 8689.642129659653, "eval_episode/length": 203.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 170064, "time": 8690.740670681, "episode/length": 33.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 170240, "time": 8698.665534496307, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 170376, "time": 8705.035048007965, "episode/length": 249.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 170736, "time": 8719.997900724411, "episode/length": 309.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774193548387097, "episode/intrinsic_return": 0.0}
{"step": 170920, "time": 8728.05157327652, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 171120, "time": 8737.386886358261, "episode/length": 154.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 171456, "time": 8752.079825639725, "episode/length": 134.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 171536, "time": 8757.200236797333, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 171744, "time": 8767.099333763123, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 171816, "time": 8771.609490156174, "episode/length": 218.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 172392, "time": 8796.76316189766, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 172432, "time": 8800.212933540344, "episode/length": 211.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 172520, "time": 8804.725555181503, "episode/length": 391.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 172592, "time": 8809.162328481674, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 172848, "time": 8820.038921356201, "episode/length": 163.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 173064, "time": 8829.264111042023, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 173272, "time": 8838.296496391296, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 173288, "time": 8840.516544342041, "episode/length": 228.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 173568, "time": 8852.561476945877, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 173752, "time": 8860.600907564163, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 173816, "time": 8864.431048631668, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 173816, "time": 8864.477361917496, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 174192, "time": 8881.746308088303, "episode/length": 77.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 174240, "time": 8885.05141878128, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 174248, "time": 8886.717411279678, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 174776, "time": 8907.536231040955, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 174776, "time": 8907.586196184158, "episode/length": 240.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 175248, "time": 8928.492501020432, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 175296, "time": 8931.810922145844, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 175432, "time": 8938.06416964531, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 175616, "time": 8946.642399549484, "episode/length": 224.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 175704, "time": 8951.271748304367, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 175904, "time": 8960.215610265732, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 175960, "time": 8963.57930636406, "episode/length": 42.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 175992, "time": 8966.356065750122, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 176192, "time": 8975.489087343216, "episode/length": 176.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 176488, "time": 8987.575942516327, "episode/length": 148.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 176608, "time": 8993.668565750122, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 176928, "time": 9006.995657205582, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 176984, "time": 9010.252880573273, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 177120, "time": 9016.958373308182, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 177264, "time": 9023.73149728775, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 177328, "time": 9027.60369849205, "episode/length": 170.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 177520, "time": 9036.193556785583, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 177568, "time": 9039.571651935577, "episode/length": 207.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 177984, "time": 9056.569822311401, "episode/length": 89.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 178360, "time": 9072.597322702408, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 178424, "time": 9077.06635260582, "episode/length": 241.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 178696, "time": 9089.358748197556, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 178712, "time": 9091.8052983284, "episode/length": 172.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 178736, "time": 9095.027235269547, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 178752, "time": 9097.732113361359, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 179216, "time": 9117.230089902878, "episode/length": 64.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 179424, "time": 9127.10086941719, "episode/length": 132.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 179624, "time": 9136.439144849777, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 179952, "time": 9150.358610630035, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 179992, "time": 9153.035112380981, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 9170.338112831116, "eval_episode/length": 46.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 180024, "time": 9173.647163629532, "eval_episode/length": 96.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 180024, "time": 9177.557894945145, "eval_episode/length": 152.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 180024, "time": 9179.935891866684, "eval_episode/length": 162.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 180024, "time": 9182.501261472702, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 180024, "time": 9185.914150953293, "eval_episode/length": 205.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 180024, "time": 9190.251066923141, "eval_episode/length": 262.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 180024, "time": 9193.30168747902, "eval_episode/length": 38.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 180032, "time": 9193.83103132248, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9506172839506173, "episode/intrinsic_return": 0.0}
{"step": 180104, "time": 9197.849886417389, "episode/length": 264.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 180360, "time": 9210.117405653, "episode/length": 142.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 180408, "time": 9213.24527812004, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 181048, "time": 9238.093094110489, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 181328, "time": 9250.177274465561, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 181344, "time": 9252.411132574081, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 181424, "time": 9256.792697429657, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 181456, "time": 9259.65577507019, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 181624, "time": 9267.15296292305, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 181856, "time": 9277.405302762985, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 181992, "time": 9283.796317577362, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 182248, "time": 9294.630852937698, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 182249, "time": 9297.187313079834, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.047790042937748, "train/action_min": 0.0, "train/action_std": 3.6331344786144437, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050194071191880435, "train/actor_opt_grad_steps": 10665.0, "train/actor_opt_loss": -1.1498744630269588, "train/adv_mag": 0.8573359806859304, "train/adv_max": 0.8425070212946998, "train/adv_mean": 0.004782372474293215, "train/adv_min": -0.5494311324187687, "train/adv_std": 0.08486614799097417, "train/cont_avg": 0.9942723834325397, "train/cont_loss_mean": 0.00043884823406125674, "train/cont_loss_std": 0.0128349775270915, "train/cont_neg_acc": 0.9904667437076569, "train/cont_neg_loss": 0.03858274012940891, "train/cont_pos_acc": 0.999961046945481, "train/cont_pos_loss": 0.00021188347981156616, "train/cont_pred": 0.9942638339504363, "train/cont_rate": 0.9942723834325397, "train/dyn_loss_mean": 13.09225845336914, "train/dyn_loss_std": 8.986673680562822, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0633482015322124, "train/extr_critic_critic_opt_grad_steps": 10665.0, "train/extr_critic_critic_opt_loss": 14986.902762276786, "train/extr_critic_mag": 3.682810700128949, "train/extr_critic_max": 3.682810700128949, "train/extr_critic_mean": 0.7221869899640008, "train/extr_critic_min": -0.2938810974832565, "train/extr_critic_std": 0.91029825333565, "train/extr_return_normed_mag": 1.8777878520980713, "train/extr_return_normed_max": 1.8777878520980713, "train/extr_return_normed_mean": 0.30429977864500074, "train/extr_return_normed_min": -0.2182468818648467, "train/extr_return_normed_std": 0.34732496419123243, "train/extr_return_rate": 0.4000733920506069, "train/extr_return_raw_mag": 5.031494636384267, "train/extr_return_raw_max": 5.031494636384267, "train/extr_return_raw_mean": 0.7351548636243457, "train/extr_return_raw_min": -0.6919090324451053, "train/extr_return_raw_std": 0.9490738468510764, "train/extr_reward_mag": 1.005271345850021, "train/extr_reward_max": 1.005271345850021, "train/extr_reward_mean": 0.018176484224756085, "train/extr_reward_min": -0.48967711225388544, "train/extr_reward_std": 0.12336745473837095, "train/image_loss_mean": 10.456442666432213, "train/image_loss_std": 13.05662661128574, "train/model_loss_mean": 18.36142937342326, "train/model_loss_std": 16.891341179136244, "train/model_opt_grad_norm": 77.8460099507892, "train/model_opt_grad_steps": 10651.896825396825, "train/model_opt_loss": 15356.923618861607, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 843.2539682539683, "train/policy_entropy_mag": 2.563102413737585, "train/policy_entropy_max": 2.563102413737585, "train/policy_entropy_mean": 0.8839349259459783, "train/policy_entropy_min": 0.07937602515495013, "train/policy_entropy_std": 0.7701720264222887, "train/policy_logprob_mag": 7.438367832274664, "train/policy_logprob_max": -0.009455994037645203, "train/policy_logprob_mean": -0.8831754312628791, "train/policy_logprob_min": -7.438367832274664, "train/policy_logprob_std": 1.2623054631172665, "train/policy_randomness_mag": 0.9046626729624612, "train/policy_randomness_max": 0.9046626729624612, "train/policy_randomness_mean": 0.31199023801655995, "train/policy_randomness_min": 0.02801625362582623, "train/policy_randomness_std": 0.27183692677626536, "train/post_ent_mag": 54.177447969951324, "train/post_ent_max": 54.177447969951324, "train/post_ent_mean": 36.678785263545926, "train/post_ent_min": 19.790899087512305, "train/post_ent_std": 6.037857343280126, "train/prior_ent_mag": 64.05755306425549, "train/prior_ent_max": 64.05755306425549, "train/prior_ent_mean": 49.85556287614126, "train/prior_ent_min": 25.989288708520313, "train/prior_ent_std": 7.1162690737890815, "train/rep_loss_mean": 13.09225845336914, "train/rep_loss_std": 8.986673680562822, "train/reward_avg": 0.01737893708345909, "train/reward_loss_mean": 0.04919286489131905, "train/reward_loss_std": 0.25011639787800727, "train/reward_max_data": 1.0047619058972312, "train/reward_max_pred": 1.0032706128226385, "train/reward_neg_acc": 0.9940937237134055, "train/reward_neg_loss": 0.029168406523586737, "train/reward_pos_acc": 0.9551441499165126, "train/reward_pos_loss": 0.9186355457419441, "train/reward_pred": 0.016668683350352303, "train/reward_rate": 0.022553943452380952, "train_stats/sum_log_reward": 4.259291952558323, "train_stats/max_log_achievement_collect_drink": 5.274336283185841, "train_stats/max_log_achievement_collect_sapling": 2.566371681415929, "train_stats/max_log_achievement_collect_stone": 0.008849557522123894, "train_stats/max_log_achievement_collect_wood": 2.6991150442477876, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.21238938053097345, "train_stats/max_log_achievement_eat_cow": 0.061946902654867256, "train_stats/max_log_achievement_make_wood_pickaxe": 0.035398230088495575, "train_stats/max_log_achievement_make_wood_sword": 0.07964601769911504, "train_stats/max_log_achievement_place_plant": 2.088495575221239, "train_stats/max_log_achievement_place_table": 1.079646017699115, "train_stats/max_log_achievement_wake_up": 2.5486725663716814, "train_stats/mean_log_entropy": 0.7835255550072256, "eval_stats/sum_log_reward": 3.849999889731407, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_stone": 0.045454545454545456, "eval_stats/max_log_achievement_place_stone": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00011361365613993257, "report/cont_loss_std": 0.0033433956559747458, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.023212194442749023, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.741962532581965e-07, "report/cont_pred": 0.9952248930931091, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.45500659942627, "report/dyn_loss_std": 8.92366886138916, "report/image_loss_mean": 8.885387420654297, "report/image_loss_std": 11.676278114318848, "report/model_loss_mean": 17.59659194946289, "report/model_loss_std": 15.40491771697998, "report/post_ent_mag": 53.81716537475586, "report/post_ent_max": 53.81716537475586, "report/post_ent_mean": 36.733943939208984, "report/post_ent_min": 17.693592071533203, "report/post_ent_std": 6.0594353675842285, "report/prior_ent_mag": 63.67171096801758, "report/prior_ent_max": 63.67171096801758, "report/prior_ent_mean": 51.38910675048828, "report/prior_ent_min": 28.992481231689453, "report/prior_ent_std": 5.893402576446533, "report/rep_loss_mean": 14.45500659942627, "report/rep_loss_std": 8.92366886138916, "report/reward_avg": 0.01640624925494194, "report/reward_loss_mean": 0.03808749467134476, "report/reward_loss_std": 0.28265607357025146, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0001153945922852, "report/reward_neg_acc": 0.9960159659385681, "report/reward_neg_loss": 0.012657826766371727, "report/reward_pos_acc": 0.8500000238418579, "report/reward_pos_loss": 1.3146566152572632, "report/reward_pred": 0.01334889605641365, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.963858034694567e-05, "eval/cont_loss_std": 0.0010798405855894089, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0028627333231270313, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.411393481655978e-05, "eval/cont_pred": 0.9980189800262451, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.752029418945312, "eval/dyn_loss_std": 9.424549102783203, "eval/image_loss_mean": 19.03610610961914, "eval/image_loss_std": 26.672931671142578, "eval/model_loss_mean": 27.948776245117188, "eval/model_loss_std": 30.23589515686035, "eval/post_ent_mag": 53.46904373168945, "eval/post_ent_max": 53.46904373168945, "eval/post_ent_mean": 37.71998596191406, "eval/post_ent_min": 22.09966278076172, "eval/post_ent_std": 5.206207752227783, "eval/prior_ent_mag": 63.67171096801758, "eval/prior_ent_max": 63.67171096801758, "eval/prior_ent_mean": 49.647972106933594, "eval/prior_ent_min": 26.04342269897461, "eval/prior_ent_std": 6.767375469207764, "eval/rep_loss_mean": 14.752029418945312, "eval/rep_loss_std": 9.424549102783203, "eval/reward_avg": 0.01152343861758709, "eval/reward_loss_mean": 0.06141228973865509, "eval/reward_loss_std": 0.4718359708786011, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0070581436157227, "eval/reward_neg_acc": 0.9990079998970032, "eval/reward_neg_loss": 0.031313564628362656, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 1.957632303237915, "eval/reward_pred": 0.007499567698687315, "eval/reward_rate": 0.015625, "replay/size": 181745.0, "replay/inserts": 20160.0, "replay/samples": 20160.0, "replay/insert_wait_avg": 1.378830463167221e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.042487833234999e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35640.0, "eval_replay/inserts": 4048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1224167149057502e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.0091412067413, "timer/env.step_count": 2520.0, "timer/env.step_total": 248.16282391548157, "timer/env.step_frac": 0.24791264504968968, "timer/env.step_avg": 0.09847731107757204, "timer/env.step_min": 0.02272629737854004, "timer/env.step_max": 3.533170700073242, "timer/replay._sample_count": 20160.0, "timer/replay._sample_total": 10.51356291770935, "timer/replay._sample_frac": 0.010502963944000542, "timer/replay._sample_avg": 0.0005215060971085988, "timer/replay._sample_min": 0.0003859996795654297, "timer/replay._sample_max": 0.010958671569824219, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3026.0, "timer/agent.policy_total": 51.772093534469604, "timer/agent.policy_frac": 0.05171990085131197, "timer/agent.policy_avg": 0.017109085768165763, "timer/agent.policy_min": 0.009180068969726562, "timer/agent.policy_max": 0.10835146903991699, "timer/dataset_train_count": 1260.0, "timer/dataset_train_total": 0.14566302299499512, "timer/dataset_train_frac": 0.00014551617662491545, "timer/dataset_train_avg": 0.00011560557380555169, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.000354766845703125, "timer/agent.train_count": 1260.0, "timer/agent.train_total": 563.3736612796783, "timer/agent.train_frac": 0.5628057108454748, "timer/agent.train_avg": 0.4471219533965701, "timer/agent.train_min": 0.43152856826782227, "timer/agent.train_max": 1.1108572483062744, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47338438034057617, "timer/agent.report_frac": 0.000472907150248298, "timer/agent.report_avg": 0.23669219017028809, "timer/agent.report_min": 0.23001790046691895, "timer/agent.report_max": 0.24336647987365723, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4318695068359375e-05, "timer/dataset_eval_frac": 2.429417881143681e-08, "timer/dataset_eval_avg": 2.4318695068359375e-05, "timer/dataset_eval_min": 2.4318695068359375e-05, "timer/dataset_eval_max": 2.4318695068359375e-05, "fps": 20.13942087629641}
{"step": 182448, "time": 9304.45030450821, "episode/length": 73.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 182712, "time": 9315.53876876831, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 182800, "time": 9320.556497812271, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 182960, "time": 9327.925708770752, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 182992, "time": 9330.751518964767, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 183144, "time": 9337.664843559265, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 183176, "time": 9340.27339220047, "episode/length": 115.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.0}
{"step": 183336, "time": 9348.550877809525, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 183512, "time": 9356.54840373993, "episode/length": 41.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 183640, "time": 9362.842555761337, "episode/length": 115.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 183992, "time": 9377.309271335602, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 184312, "time": 9390.549697875977, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 184360, "time": 9393.783121824265, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 184448, "time": 9398.818317174911, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 184768, "time": 9412.006181955338, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 185176, "time": 9428.261703014374, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 185368, "time": 9436.756157159805, "episode/length": 320.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 185520, "time": 9444.209204912186, "episode/length": 144.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 185536, "time": 9446.415091276169, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 185696, "time": 9453.839212417603, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 185728, "time": 9456.613751649857, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 186296, "time": 9478.771991729736, "episode/length": 230.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 186368, "time": 9483.147677183151, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 186736, "time": 9498.149594783783, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 186768, "time": 9501.284895420074, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 186984, "time": 9511.105293750763, "episode/length": 160.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 187008, "time": 9513.75157880783, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 187136, "time": 9520.101436853409, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 187624, "time": 9539.341669082642, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 187624, "time": 9539.391349554062, "episode/length": 156.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 188096, "time": 9560.341109752655, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 188112, "time": 9562.365357160568, "episode/length": 167.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 188240, "time": 9568.620211362839, "episode/length": 337.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.0}
{"step": 188440, "time": 9578.71875, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 188768, "time": 9592.394056081772, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 188896, "time": 9598.599113702774, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 188904, "time": 9600.20102095604, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 189264, "time": 9615.327493667603, "episode/length": 145.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 189368, "time": 9620.346073627472, "episode/length": 294.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 189656, "time": 9632.406200885773, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 189696, "time": 9635.564860105515, "episode/length": 40.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 189704, "time": 9637.270349025726, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 189864, "time": 9644.687188863754, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9665.79938173294, "eval_episode/length": 37.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 190008, "time": 9667.34567975998, "eval_episode/length": 38.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 190008, "time": 9669.301278591156, "eval_episode/length": 48.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 190008, "time": 9673.073283672333, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 190008, "time": 9675.397824764252, "eval_episode/length": 90.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.989010989010989}
{"step": 190008, "time": 9679.857974767685, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 190008, "time": 9681.937348127365, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 190008, "time": 9683.647307872772, "eval_episode/length": 217.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 190232, "time": 9691.8134059906, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 190248, "time": 9693.956387996674, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 190256, "time": 9696.122625112534, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 190512, "time": 9707.05865764618, "episode/length": 101.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 190776, "time": 9717.93959069252, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 190976, "time": 9727.004412412643, "episode/length": 164.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 191296, "time": 9740.205033779144, "episode/length": 178.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 191304, "time": 9741.784967660904, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 191592, "time": 9753.805905103683, "episode/length": 235.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 191656, "time": 9757.869350194931, "episode/length": 174.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 191848, "time": 9766.3532269001, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 191984, "time": 9773.091359853745, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 192072, "time": 9777.467502117157, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 192400, "time": 9791.293858528137, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 192744, "time": 9805.113245248795, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 193056, "time": 9818.266928434372, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 193120, "time": 9822.113753080368, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 193488, "time": 9837.302054405212, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 193680, "time": 9846.649170160294, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 193712, "time": 9849.718172311783, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 193720, "time": 9851.656943321228, "episode/length": 257.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 193744, "time": 9854.7119576931, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 193760, "time": 9857.249334573746, "episode/length": 87.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 194272, "time": 9878.391391038895, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 194664, "time": 9894.802178382874, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 194680, "time": 9897.433387756348, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 194928, "time": 9908.912212133408, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 195080, "time": 9916.430870056152, "episode/length": 169.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 195240, "time": 9924.59060382843, "episode/length": 190.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 195424, "time": 9933.768095731735, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 195848, "time": 9951.580361127853, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 195936, "time": 9957.079779148102, "episode/length": 125.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 195952, "time": 9959.671487808228, "episode/length": 275.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 196528, "time": 9983.61370587349, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 196536, "time": 9985.788148403168, "episode/length": 233.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 196680, "time": 9994.64086318016, "episode/length": 156.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 196904, "time": 10005.1195602417, "episode/length": 277.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 196920, "time": 10007.624008893967, "episode/length": 209.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 196968, "time": 10011.447789669037, "episode/length": 35.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 197040, "time": 10016.49244594574, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 197304, "time": 10028.320322036743, "episode/length": 181.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 197408, "time": 10034.32646203041, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 197768, "time": 10049.584169626236, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 198288, "time": 10071.186935663223, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 198432, "time": 10078.084614276886, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 198640, "time": 10087.318408250809, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 198640, "time": 10087.364315986633, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 198664, "time": 10091.276762247086, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 198888, "time": 10101.019042730331, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 198944, "time": 10104.851873874664, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 199008, "time": 10108.803226470947, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 199520, "time": 10129.067316055298, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 199656, "time": 10135.375412225723, "episode/length": 88.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 200072, "time": 10152.132164239883, "episode/length": 178.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 200088, "time": 10154.197147130966, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 10170.36003446579, "eval_episode/length": 36.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.972972972972973}
{"step": 200096, "time": 10177.124138593674, "eval_episode/length": 164.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9878787878787879}
{"step": 200096, "time": 10179.639297485352, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 200096, "time": 10181.535034418106, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 200096, "time": 10183.706624746323, "eval_episode/length": 173.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 200096, "time": 10185.459924936295, "eval_episode/length": 218.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 200096, "time": 10188.458944559097, "eval_episode/length": 256.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.980544747081712}
{"step": 200096, "time": 10191.95010304451, "eval_episode/length": 120.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9669421487603306}
{"step": 200192, "time": 10195.466230392456, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 200200, "time": 10197.187803983688, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 201008, "time": 10228.3478307724, "episode/length": 295.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 201208, "time": 10237.052503585815, "episode/length": 274.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 201240, "time": 10239.746256351471, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 201296, "time": 10243.554074525833, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 201408, "time": 10249.158563613892, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 201416, "time": 10250.653786182404, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 201496, "time": 10255.067031860352, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 201768, "time": 10266.500930786133, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 202545, "time": 10297.224870443344, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.118557186577264, "train/action_min": 0.0, "train/action_std": 3.8750805366696337, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051231387709304105, "train/actor_opt_grad_steps": 11930.0, "train/actor_opt_loss": -0.8365624302954185, "train/adv_mag": 0.8330087136095903, "train/adv_max": 0.8192646705259489, "train/adv_mean": 0.005733746039404078, "train/adv_min": -0.5597926915630581, "train/adv_std": 0.08521282922212534, "train/cont_avg": 0.9942867249015748, "train/cont_loss_mean": 0.0003361932243860595, "train/cont_loss_std": 0.009826201744743688, "train/cont_neg_acc": 0.9876140506248775, "train/cont_neg_loss": 0.04135907764493178, "train/cont_pos_acc": 0.9999844722860441, "train/cont_pos_loss": 5.951850694214649e-05, "train/cont_pred": 0.9943640222699623, "train/cont_rate": 0.9942867249015748, "train/dyn_loss_mean": 13.005385841910295, "train/dyn_loss_std": 8.9663624801035, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9797112331615658, "train/extr_critic_critic_opt_grad_steps": 11930.0, "train/extr_critic_critic_opt_loss": 15219.469634288878, "train/extr_critic_mag": 3.9216276754544475, "train/extr_critic_max": 3.9216276754544475, "train/extr_critic_mean": 0.719974335488372, "train/extr_critic_min": -0.33181270088736464, "train/extr_critic_std": 0.9360995104932409, "train/extr_return_normed_mag": 1.9430485991981086, "train/extr_return_normed_max": 1.9430485991981086, "train/extr_return_normed_mean": 0.3063111451901789, "train/extr_return_normed_min": -0.22509187688743035, "train/extr_return_normed_std": 0.3516198992729187, "train/extr_return_rate": 0.401073471181036, "train/extr_return_raw_mag": 5.29923818806025, "train/extr_return_raw_max": 5.29923818806025, "train/extr_return_raw_mean": 0.7360115464278093, "train/extr_return_raw_min": -0.7442519723430393, "train/extr_return_raw_std": 0.9799500417521619, "train/extr_reward_mag": 1.0076666873271072, "train/extr_reward_max": 1.0076666873271072, "train/extr_reward_mean": 0.020137583198920478, "train/extr_reward_min": -0.5130831500676674, "train/extr_reward_std": 0.12962020569898952, "train/image_loss_mean": 9.647928076466238, "train/image_loss_std": 12.400158870877243, "train/model_loss_mean": 17.50104305687852, "train/model_loss_std": 16.232014198002854, "train/model_opt_grad_norm": 71.07611046438141, "train/model_opt_grad_steps": 11915.740157480315, "train/model_opt_loss": 11550.672501691683, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 659.4488188976378, "train/policy_entropy_mag": 2.535383907828744, "train/policy_entropy_max": 2.535383907828744, "train/policy_entropy_mean": 0.8320121671271137, "train/policy_entropy_min": 0.0793755962036726, "train/policy_entropy_std": 0.749265469904021, "train/policy_logprob_mag": 7.438375086296261, "train/policy_logprob_max": -0.009455879152877125, "train/policy_logprob_mean": -0.8327919460657075, "train/policy_logprob_min": -7.438375086296261, "train/policy_logprob_std": 1.2544478149864617, "train/policy_randomness_mag": 0.8948792571157921, "train/policy_randomness_max": 0.8948792571157921, "train/policy_randomness_mean": 0.2936637846269007, "train/policy_randomness_min": 0.028016102052931712, "train/policy_randomness_std": 0.2644578290032589, "train/post_ent_mag": 55.22979090532919, "train/post_ent_max": 55.22979090532919, "train/post_ent_mean": 37.33061671820212, "train/post_ent_min": 20.16701853744627, "train/post_ent_std": 6.214829981796385, "train/prior_ent_mag": 64.53973409697765, "train/prior_ent_max": 64.53973409697765, "train/prior_ent_mean": 50.50522655577171, "train/prior_ent_min": 27.753351752213607, "train/prior_ent_std": 6.679170871344138, "train/rep_loss_mean": 13.005385841910295, "train/rep_loss_std": 8.9663624801035, "train/reward_avg": 0.01763502697233023, "train/reward_loss_mean": 0.049547162596282994, "train/reward_loss_std": 0.25101514231032274, "train/reward_max_data": 1.0094488211504118, "train/reward_max_pred": 1.0040843590038029, "train/reward_neg_acc": 0.9938521220928102, "train/reward_neg_loss": 0.02907847656362404, "train/reward_pos_acc": 0.951931198281566, "train/reward_pos_loss": 0.9281502276893676, "train/reward_pred": 0.016848200550816192, "train/reward_rate": 0.022730068897637797, "train_stats/sum_log_reward": 4.590740670691486, "train_stats/max_log_achievement_collect_drink": 5.5, "train_stats/max_log_achievement_collect_sapling": 2.7962962962962963, "train_stats/max_log_achievement_collect_stone": 0.009259259259259259, "train_stats/max_log_achievement_collect_wood": 3.1018518518518516, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2222222222222222, "train_stats/max_log_achievement_eat_cow": 0.027777777777777776, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07407407407407407, "train_stats/max_log_achievement_make_wood_sword": 0.16666666666666666, "train_stats/max_log_achievement_place_plant": 2.5833333333333335, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.1944444444444444, "train_stats/max_log_achievement_wake_up": 2.4166666666666665, "train_stats/mean_log_entropy": 0.7559327712213552, "eval_stats/sum_log_reward": 3.8499999344348907, "eval_stats/max_log_achievement_collect_drink": 3.1875, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.0625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.125, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.511194674705621e-06, "report/cont_loss_std": 6.313704216154292e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000274954189080745, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.7165532376093324e-06, "report/cont_pred": 0.9970674514770508, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.601018905639648, "report/dyn_loss_std": 8.441980361938477, "report/image_loss_mean": 7.956371307373047, "report/image_loss_std": 12.253246307373047, "report/model_loss_mean": 15.556506156921387, "report/model_loss_std": 15.77817153930664, "report/post_ent_mag": 51.96562957763672, "report/post_ent_max": 51.96562957763672, "report/post_ent_mean": 37.31068420410156, "report/post_ent_min": 17.936452865600586, "report/post_ent_std": 5.405022621154785, "report/prior_ent_mag": 65.0955810546875, "report/prior_ent_max": 65.0955810546875, "report/prior_ent_mean": 50.24225997924805, "report/prior_ent_min": 25.723148345947266, "report/prior_ent_std": 6.3669657707214355, "report/rep_loss_mean": 12.601018905639648, "report/rep_loss_std": 8.441980361938477, "report/reward_avg": 0.0166015625, "report/reward_loss_mean": 0.03951919823884964, "report/reward_loss_std": 0.19794662296772003, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022823810577393, "report/reward_neg_acc": 0.9950149655342102, "report/reward_neg_loss": 0.023484375327825546, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.8053727149963379, "report/reward_pred": 0.01753086969256401, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.521215040156676e-06, "eval/cont_loss_std": 1.0087840564665385e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00019718887051567435, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3299464853844256e-06, "eval/cont_pred": 0.9990223050117493, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 15.16797924041748, "eval/dyn_loss_std": 10.83954906463623, "eval/image_loss_mean": 16.005146026611328, "eval/image_loss_std": 24.894346237182617, "eval/model_loss_mean": 25.165258407592773, "eval/model_loss_std": 29.09853744506836, "eval/post_ent_mag": 52.95793151855469, "eval/post_ent_max": 52.95793151855469, "eval/post_ent_mean": 36.81959533691406, "eval/post_ent_min": 20.610652923583984, "eval/post_ent_std": 5.561235427856445, "eval/prior_ent_mag": 65.0955810546875, "eval/prior_ent_max": 65.0955810546875, "eval/prior_ent_mean": 49.3768310546875, "eval/prior_ent_min": 24.868106842041016, "eval/prior_ent_std": 7.740315914154053, "eval/rep_loss_mean": 15.16797924041748, "eval/rep_loss_std": 10.83954906463623, "eval/reward_avg": 0.021484375, "eval/reward_loss_mean": 0.05932203680276871, "eval/reward_loss_std": 0.46893152594566345, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001415729522705, "eval/reward_neg_acc": 0.9920000433921814, "eval/reward_neg_loss": 0.02704280987381935, "eval/reward_pos_acc": 0.9166666865348816, "eval/reward_pos_loss": 1.4042900800704956, "eval/reward_pred": 0.02126629650592804, "eval/reward_rate": 0.0234375, "replay/size": 202041.0, "replay/inserts": 20296.0, "replay/samples": 20288.0, "replay/insert_wait_avg": 1.38399306835976e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.080354436338888e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 39856.0, "eval_replay/inserts": 4216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0986708147023616e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0238993167877, "timer/env.step_count": 2537.0, "timer/env.step_total": 247.63277196884155, "timer/env.step_frac": 0.2476268538562161, "timer/env.step_avg": 0.09760850294396592, "timer/env.step_min": 0.023344993591308594, "timer/env.step_max": 3.3677139282226562, "timer/replay._sample_count": 20288.0, "timer/replay._sample_total": 10.54386830329895, "timer/replay._sample_frac": 0.010543616318072477, "timer/replay._sample_avg": 0.0005197095969685997, "timer/replay._sample_min": 0.0003910064697265625, "timer/replay._sample_max": 0.02645564079284668, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3064.0, "timer/agent.policy_total": 50.731810331344604, "timer/agent.policy_frac": 0.05073059790471445, "timer/agent.policy_avg": 0.01655737935096103, "timer/agent.policy_min": 0.009490251541137695, "timer/agent.policy_max": 0.1055288314819336, "timer/dataset_train_count": 1268.0, "timer/dataset_train_total": 0.14819049835205078, "timer/dataset_train_frac": 0.00014818695678502677, "timer/dataset_train_avg": 0.00011686947819562365, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.0005011558532714844, "timer/agent.train_count": 1268.0, "timer/agent.train_total": 565.6272597312927, "timer/agent.train_frac": 0.5656137419492944, "timer/agent.train_avg": 0.44607828054518356, "timer/agent.train_min": 0.43360328674316406, "timer/agent.train_max": 1.2005863189697266, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47174525260925293, "timer/agent.report_frac": 0.0004717339784894615, "timer/agent.report_avg": 0.23587262630462646, "timer/agent.report_min": 0.22799468040466309, "timer/agent.report_max": 0.24375057220458984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218573896153945e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 20.295259383176344}
{"step": 202560, "time": 10297.919130563736, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 202632, "time": 10302.002064704895, "episode/length": 152.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 202640, "time": 10304.011234760284, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 202896, "time": 10314.817186117172, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 202904, "time": 10316.391946554184, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 203072, "time": 10324.31217455864, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 203104, "time": 10327.20101594925, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 203272, "time": 10334.609817504883, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 203928, "time": 10360.117893457413, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 204216, "time": 10372.152554750443, "episode/length": 117.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 204336, "time": 10378.412019968033, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 204432, "time": 10383.46991276741, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 204448, "time": 10385.717905759811, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 204632, "time": 10393.674558877945, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 204840, "time": 10404.340325593948, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 205144, "time": 10417.087947845459, "episode/length": 254.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9921568627450981, "episode/intrinsic_return": 0.0}
{"step": 205208, "time": 10420.892727851868, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 205488, "time": 10432.886382341385, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 205768, "time": 10444.408391475677, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 205832, "time": 10448.368595600128, "episode/length": 149.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 206536, "time": 10475.723071575165, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 206576, "time": 10479.06146979332, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 206584, "time": 10480.765040636063, "episode/length": 266.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 206776, "time": 10489.2620947361, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 207176, "time": 10505.379869937897, "episode/length": 175.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 207408, "time": 10515.59437417984, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 207624, "time": 10524.812646150589, "episode/length": 410.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9975669099756691, "episode/intrinsic_return": 0.0}
{"step": 207704, "time": 10529.2042760849, "episode/length": 115.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9396551724137931, "episode/intrinsic_return": 0.0}
{"step": 207976, "time": 10540.767008066177, "episode/length": 173.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 208128, "time": 10547.98846578598, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 208608, "time": 10567.64774441719, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 208664, "time": 10571.474838972092, "episode/length": 260.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 208680, "time": 10574.179523468018, "episode/length": 433.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 209064, "time": 10590.569460391998, "episode/length": 169.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 209248, "time": 10599.120629787445, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 209328, "time": 10603.511981964111, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 209368, "time": 10606.23901438713, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 209424, "time": 10610.029628515244, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10649.825146436691, "eval_episode/length": 39.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.975}
{"step": 210080, "time": 10651.632743358612, "eval_episode/length": 43.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8863636363636364}
{"step": 210080, "time": 10658.987880706787, "eval_episode/length": 146.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9727891156462585}
{"step": 210080, "time": 10660.614049911499, "eval_episode/length": 149.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 210080, "time": 10662.979454040527, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 210080, "time": 10664.64476108551, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 210080, "time": 10666.376530647278, "eval_episode/length": 176.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 210080, "time": 10669.133439302444, "eval_episode/length": 209.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 210080, "time": 10669.180750131607, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 210120, "time": 10670.423305988312, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 210144, "time": 10673.129549264908, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 210352, "time": 10682.337944030762, "episode/length": 208.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 210384, "time": 10685.035985469818, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 210392, "time": 10686.704176187515, "episode/length": 30.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 210544, "time": 10694.018281698227, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 210688, "time": 10700.834540843964, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 210720, "time": 10703.53513622284, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 210880, "time": 10710.895307779312, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 211432, "time": 10732.447008371353, "episode/length": 134.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 211552, "time": 10738.608486652374, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 211624, "time": 10742.419647216797, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 211640, "time": 10744.500401496887, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 212024, "time": 10760.132509469986, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 212048, "time": 10762.853147506714, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 212352, "time": 10775.535682201385, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 212400, "time": 10778.9684612751, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612068965517241, "episode/intrinsic_return": 0.0}
{"step": 212952, "time": 10800.43567109108, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 213032, "time": 10806.378791093826, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 213152, "time": 10812.50237607956, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.0}
{"step": 213176, "time": 10814.64591050148, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 213184, "time": 10816.685935497284, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 213304, "time": 10822.356926679611, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 213624, "time": 10835.658774614334, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 213688, "time": 10839.493578672409, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 214144, "time": 10857.86598110199, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 214296, "time": 10864.76946234703, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 214408, "time": 10870.499519824982, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 214416, "time": 10872.613845348358, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 214520, "time": 10877.71645975113, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 214760, "time": 10887.934778213501, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 214960, "time": 10897.16936993599, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 215080, "time": 10902.94274520874, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 215256, "time": 10910.934157133102, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 215512, "time": 10921.826415538788, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 215688, "time": 10929.936645269394, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 215752, "time": 10933.841006994247, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 216000, "time": 10944.665497541428, "episode/length": 154.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 216208, "time": 10953.79312825203, "episode/length": 25.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8846153846153846, "episode/intrinsic_return": 0.0}
{"step": 216352, "time": 10960.84004330635, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 216600, "time": 10971.682229757309, "episode/length": 105.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 216688, "time": 10976.640387535095, "episode/length": 298.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 216840, "time": 10983.498438835144, "episode/length": 302.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 216912, "time": 10988.063069105148, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 217072, "time": 10995.577268362045, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 217128, "time": 10998.953884601593, "episode/length": 201.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 217624, "time": 11018.86435675621, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 217928, "time": 11031.565868139267, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 218208, "time": 11043.52238893509, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 218224, "time": 11045.777642965317, "episode/length": 172.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 218432, "time": 11054.932534694672, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 218624, "time": 11063.534333229065, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 218664, "time": 11066.310344696045, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 218696, "time": 11068.927639484406, "episode/length": 250.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 219336, "time": 11093.839770555496, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 219480, "time": 11100.596885919571, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 219664, "time": 11109.20626950264, "episode/length": 413.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9975845410628019, "episode/intrinsic_return": 0.0}
{"step": 219904, "time": 11120.12503027916, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 220016, "time": 11126.277419567108, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 11148.425930023193, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 220064, "time": 11150.928973436356, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9611111111111111}
{"step": 220064, "time": 11152.876293182373, "eval_episode/length": 191.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 220064, "time": 11154.72988820076, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 220064, "time": 11156.818986415863, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 220064, "time": 11159.048073291779, "eval_episode/length": 230.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 220064, "time": 11161.935937643051, "eval_episode/length": 265.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.981203007518797}
{"step": 220064, "time": 11165.001994609833, "eval_episode/length": 304.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9901639344262295}
{"step": 220296, "time": 11173.351341962814, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 220376, "time": 11177.78508400917, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 220488, "time": 11183.411487817764, "episode/length": 143.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 220776, "time": 11195.5698056221, "episode/length": 161.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 221416, "time": 11221.840252399445, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 221472, "time": 11225.829736232758, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 221544, "time": 11229.815642595291, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 221576, "time": 11232.485029220581, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 221848, "time": 11243.964489936829, "episode/length": 426.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 222280, "time": 11261.257449388504, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 222624, "time": 11275.59851360321, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 222728, "time": 11280.891313791275, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 222864, "time": 11287.829973459244, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 222936, "time": 11291.801503896713, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 223008, "time": 11296.222086906433, "episode/length": 34.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 223009, "time": 11298.470870494843, "train_stats/sum_log_reward": 4.805357072103236, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.696428571428571, "train_stats/max_log_achievement_collect_sapling": 2.4642857142857144, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.116071428571429, "train_stats/max_log_achievement_defeat_skeleton": 0.017857142857142856, "train_stats/max_log_achievement_defeat_zombie": 0.23214285714285715, "train_stats/max_log_achievement_eat_cow": 0.11607142857142858, "train_stats/max_log_achievement_make_wood_pickaxe": 0.125, "train_stats/max_log_achievement_make_wood_sword": 0.10714285714285714, "train_stats/max_log_achievement_place_plant": 2.2410714285714284, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.7410714285714286, "train_stats/max_log_achievement_wake_up": 2.3482142857142856, "train_stats/mean_log_entropy": 0.785174127135958, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.20239782333374, "train/action_min": 0.0, "train/action_std": 3.9795034267008305, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048983839005813934, "train/actor_opt_grad_steps": 13205.0, "train/actor_opt_loss": -6.1211811089888215, "train/adv_mag": 0.7955355760641396, "train/adv_max": 0.7730222365353256, "train/adv_mean": 0.004307888963410278, "train/adv_min": -0.5374913292471319, "train/adv_std": 0.0821587716054637, "train/cont_avg": 0.9940719604492188, "train/cont_loss_mean": 0.00040349132491290796, "train/cont_loss_std": 0.011487081409081057, "train/cont_neg_acc": 0.9854597900994122, "train/cont_neg_loss": 0.038434031358518084, "train/cont_pos_acc": 0.9999308963306248, "train/cont_pos_loss": 0.00016498145227211714, "train/cont_pred": 0.9940783362835646, "train/cont_rate": 0.9940719604492188, "train/dyn_loss_mean": 13.318472534418106, "train/dyn_loss_std": 9.056325428187847, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9539566235616803, "train/extr_critic_critic_opt_grad_steps": 13205.0, "train/extr_critic_critic_opt_loss": 15400.29630279541, "train/extr_critic_mag": 4.261952619999647, "train/extr_critic_max": 4.261952619999647, "train/extr_critic_mean": 0.7597182686440647, "train/extr_critic_min": -0.3324238359928131, "train/extr_critic_std": 0.9861648832447827, "train/extr_return_normed_mag": 1.9310646252706647, "train/extr_return_normed_max": 1.9310646252706647, "train/extr_return_normed_mean": 0.3037685606395826, "train/extr_return_normed_min": -0.2041153169120662, "train/extr_return_normed_std": 0.34579425922129303, "train/extr_return_rate": 0.40568239509593695, "train/extr_return_raw_mag": 5.598740249872208, "train/extr_return_raw_max": 5.598740249872208, "train/extr_return_raw_mean": 0.7724923964124173, "train/extr_return_raw_min": -0.7339789911638945, "train/extr_return_raw_std": 1.0256391363218427, "train/extr_reward_mag": 1.01020104624331, "train/extr_reward_max": 1.01020104624331, "train/extr_reward_mean": 0.021788385674881283, "train/extr_reward_min": -0.48905549943447113, "train/extr_reward_std": 0.13529096072306857, "train/image_loss_mean": 9.545509994029999, "train/image_loss_std": 12.568638652563095, "train/model_loss_mean": 17.58734068274498, "train/model_loss_std": 16.426555633544922, "train/model_opt_grad_norm": 75.33491775393486, "train/model_opt_grad_steps": 13189.9921875, "train/model_opt_loss": 16146.668228149414, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 917.96875, "train/policy_entropy_mag": 2.506252059713006, "train/policy_entropy_max": 2.506252059713006, "train/policy_entropy_mean": 0.8498933785595, "train/policy_entropy_min": 0.07937540434068069, "train/policy_entropy_std": 0.7705224375240505, "train/policy_logprob_mag": 7.438379481434822, "train/policy_logprob_max": -0.009455777690163814, "train/policy_logprob_mean": -0.8506218236871064, "train/policy_logprob_min": -7.438379481434822, "train/policy_logprob_std": 1.2520081270486116, "train/policy_randomness_mag": 0.8845969932153821, "train/policy_randomness_max": 0.8845969932153821, "train/policy_randomness_mean": 0.2999750666785985, "train/policy_randomness_min": 0.02801603451371193, "train/policy_randomness_std": 0.271960606565699, "train/post_ent_mag": 55.5664898455143, "train/post_ent_max": 55.5664898455143, "train/post_ent_mean": 37.708033233881, "train/post_ent_min": 20.233225852251053, "train/post_ent_std": 6.429366879165173, "train/prior_ent_mag": 65.05982327461243, "train/prior_ent_max": 65.05982327461243, "train/prior_ent_mean": 51.147618651390076, "train/prior_ent_min": 28.884638503193855, "train/prior_ent_std": 6.4365727715194225, "train/rep_loss_mean": 13.318472534418106, "train/rep_loss_std": 9.056325428187847, "train/reward_avg": 0.019905853107047733, "train/reward_loss_mean": 0.050343838724074885, "train/reward_loss_std": 0.2530883402796462, "train/reward_max_data": 1.0093750022351742, "train/reward_max_pred": 1.0046267146244645, "train/reward_neg_acc": 0.9944963096641004, "train/reward_neg_loss": 0.028312848116911482, "train/reward_pos_acc": 0.9564740206114948, "train/reward_pos_loss": 0.9082769937813282, "train/reward_pred": 0.019137834229695727, "train/reward_rate": 0.02504730224609375, "eval_stats/sum_log_reward": 4.33529403630425, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.411764705882353, "eval_stats/max_log_achievement_collect_sapling": 2.0588235294117645, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.2941176470588234, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.058823529411764705, "eval_stats/max_log_achievement_eat_cow": 0.29411764705882354, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.11764705882352941, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.3529411764705883, "eval_stats/max_log_achievement_wake_up": 1.9411764705882353, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.69228507427033e-06, "report/cont_loss_std": 7.001401536399499e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015335882198996842, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.669014631668688e-06, "report/cont_pred": 0.9931615591049194, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.05310344696045, "report/dyn_loss_std": 8.699209213256836, "report/image_loss_mean": 7.223522186279297, "report/image_loss_std": 9.447742462158203, "report/model_loss_mean": 14.506362915039062, "report/model_loss_std": 13.042597770690918, "report/post_ent_mag": 57.71221160888672, "report/post_ent_max": 57.71221160888672, "report/post_ent_mean": 38.027835845947266, "report/post_ent_min": 19.92397689819336, "report/post_ent_std": 6.647322654724121, "report/prior_ent_mag": 65.88487243652344, "report/prior_ent_max": 65.88487243652344, "report/prior_ent_mean": 50.78820037841797, "report/prior_ent_min": 27.489200592041016, "report/prior_ent_std": 6.925774097442627, "report/rep_loss_mean": 12.05310344696045, "report/rep_loss_std": 8.699209213256836, "report/reward_avg": 0.01933593675494194, "report/reward_loss_mean": 0.05097412317991257, "report/reward_loss_std": 0.19789205491542816, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0051612854003906, "report/reward_neg_acc": 0.9989969730377197, "report/reward_neg_loss": 0.0325842909514904, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.730035662651062, "report/reward_pred": 0.018973333761096, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0025732705835253, "eval/cont_loss_std": 0.05378427356481552, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0037140105850994587, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0025687972083687782, "eval/cont_pred": 0.9945043325424194, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.16614532470703, "eval/dyn_loss_std": 9.64684772491455, "eval/image_loss_mean": 27.1956729888916, "eval/image_loss_std": 31.29316520690918, "eval/model_loss_mean": 38.77931594848633, "eval/model_loss_std": 34.74197769165039, "eval/post_ent_mag": 57.509613037109375, "eval/post_ent_max": 57.509613037109375, "eval/post_ent_mean": 37.13217544555664, "eval/post_ent_min": 18.72967529296875, "eval/post_ent_std": 5.455751419067383, "eval/prior_ent_mag": 65.88487243652344, "eval/prior_ent_max": 65.88487243652344, "eval/prior_ent_mean": 53.06207275390625, "eval/prior_ent_min": 32.50004196166992, "eval/prior_ent_std": 5.755356311798096, "eval/rep_loss_mean": 19.16614532470703, "eval/rep_loss_std": 9.64684772491455, "eval/reward_avg": 0.01826171949505806, "eval/reward_loss_mean": 0.08138157427310944, "eval/reward_loss_std": 0.5551810264587402, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0051615238189697, "eval/reward_neg_acc": 0.9990019798278809, "eval/reward_neg_loss": 0.037179045379161835, "eval/reward_pos_acc": 0.7727273106575012, "eval/reward_pos_loss": 2.0946056842803955, "eval/reward_pred": 0.010719113051891327, "eval/reward_rate": 0.021484375, "replay/size": 222505.0, "replay/inserts": 20464.0, "replay/samples": 20464.0, "replay/insert_wait_avg": 1.3736796807832696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.009811040477141e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 43976.0, "eval_replay/inserts": 4120.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1169216007862277e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.231508731842, "timer/env.step_count": 2558.0, "timer/env.step_total": 242.53784704208374, "timer/env.step_frac": 0.2422395269494482, "timer/env.step_avg": 0.09481542104850811, "timer/env.step_min": 0.023093461990356445, "timer/env.step_max": 2.1296496391296387, "timer/replay._sample_count": 20464.0, "timer/replay._sample_total": 10.51911997795105, "timer/replay._sample_frac": 0.010506181523666338, "timer/replay._sample_avg": 0.0005140304914948715, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.021422624588012695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3073.0, "timer/agent.policy_total": 52.04622435569763, "timer/agent.policy_frac": 0.05198220781287565, "timer/agent.policy_avg": 0.0169366171024073, "timer/agent.policy_min": 0.009195327758789062, "timer/agent.policy_max": 0.19685053825378418, "timer/dataset_train_count": 1279.0, "timer/dataset_train_total": 0.14934444427490234, "timer/dataset_train_frac": 0.0001491607515069734, "timer/dataset_train_avg": 0.00011676657097334037, "timer/dataset_train_min": 0.00010538101196289062, "timer/dataset_train_max": 0.00043511390686035156, "timer/agent.train_count": 1279.0, "timer/agent.train_total": 569.4345762729645, "timer/agent.train_frac": 0.5687341751701455, "timer/agent.train_avg": 0.44521858973648515, "timer/agent.train_min": 0.43294477462768555, "timer/agent.train_max": 1.1665706634521484, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4715120792388916, "timer/agent.report_frac": 0.0004709321222182749, "timer/agent.report_avg": 0.2357560396194458, "timer/agent.report_min": 0.22796869277954102, "timer/agent.report_max": 0.24354338645935059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9527540384780076e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 20.43855150590086}
{"step": 223056, "time": 11300.434945821762, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 223136, "time": 11304.857698917389, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 223640, "time": 11324.645267248154, "episode/length": 407.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 224112, "time": 11343.62353682518, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 224152, "time": 11346.446622371674, "episode/length": 136.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 224184, "time": 11349.233946323395, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 224688, "time": 11369.449258089066, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 224816, "time": 11375.619888305664, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 224840, "time": 11377.899256706238, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 225208, "time": 11392.935031414032, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 225312, "time": 11398.48138666153, "episode/length": 432.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 225448, "time": 11404.826380729675, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 225576, "time": 11411.082517385483, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 225688, "time": 11416.72982430458, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 225736, "time": 11420.050066947937, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.0}
{"step": 225992, "time": 11430.985916614532, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 226056, "time": 11434.942656517029, "episode/length": 151.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 226152, "time": 11440.052556276321, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 226752, "time": 11463.567493915558, "episode/length": 86.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 226824, "time": 11467.692826509476, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 226840, "time": 11469.937980413437, "episode/length": 173.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 226872, "time": 11472.542164325714, "episode/length": 141.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 227336, "time": 11490.960939884186, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 227416, "time": 11495.39188671112, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 227688, "time": 11506.90760588646, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 228128, "time": 11524.82255411148, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 228392, "time": 11535.929020166397, "episode/length": 299.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 228496, "time": 11541.601635217667, "episode/length": 100.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 228616, "time": 11547.256341934204, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 228656, "time": 11550.510340213776, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 228904, "time": 11560.855978488922, "episode/length": 268.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 228944, "time": 11564.16876411438, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 229344, "time": 11580.29971575737, "episode/length": 250.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 229632, "time": 11593.9384059906, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 229912, "time": 11605.4296708107, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 11629.896417856216, "eval_episode/length": 135.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 230048, "time": 11631.826984643936, "eval_episode/length": 146.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 230048, "time": 11633.492131471634, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 230048, "time": 11635.106123447418, "eval_episode/length": 153.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 230048, "time": 11636.779342651367, "eval_episode/length": 157.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 230048, "time": 11638.559515714645, "eval_episode/length": 161.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 230048, "time": 11641.738753080368, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 230048, "time": 11646.277161359787, "eval_episode/length": 126.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9448818897637795}
{"step": 230088, "time": 11647.51227259636, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 230192, "time": 11653.130334377289, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 230472, "time": 11664.645861148834, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 230664, "time": 11673.070060253143, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 230936, "time": 11684.585879087448, "episode/length": 253.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 231448, "time": 11704.846050024033, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 231504, "time": 11708.819274663925, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 231512, "time": 11710.571592092514, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 231808, "time": 11723.187238454819, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 232056, "time": 11734.455634117126, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 232264, "time": 11744.161388635635, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 232272, "time": 11746.313016414642, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 232680, "time": 11762.744549512863, "episode/length": 145.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 232784, "time": 11768.909492969513, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 233000, "time": 11778.666729927063, "episode/length": 148.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 233224, "time": 11789.08247089386, "episode/length": 54.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 233240, "time": 11791.792150259018, "episode/length": 216.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 233424, "time": 11801.069816112518, "episode/length": 628.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.985691573926868, "episode/intrinsic_return": 0.0}
{"step": 233528, "time": 11806.758918762207, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 233840, "time": 11820.689379930496, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 233976, "time": 11827.679723501205, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 234048, "time": 11832.652213096619, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 234464, "time": 11850.385419607162, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 234544, "time": 11855.52064704895, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 234552, "time": 11857.65487909317, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 235256, "time": 11886.174780845642, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 235312, "time": 11890.053050518036, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 235392, "time": 11894.495000839233, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 235584, "time": 11902.990404129028, "episode/length": 269.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 235760, "time": 11910.868207931519, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 235976, "time": 11920.157430887222, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 236072, "time": 11925.26226401329, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 236080, "time": 11927.306017160416, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 236096, "time": 11929.4879591465, "episode/length": 41.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 236560, "time": 11948.13211941719, "episode/length": 145.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 236648, "time": 11952.756785869598, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 237120, "time": 11971.898292064667, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 237280, "time": 11979.433142662048, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 237424, "time": 11986.26755785942, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 237520, "time": 11991.280989170074, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 237568, "time": 11994.879252433777, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 237840, "time": 12007.888082504272, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9871244635193133, "episode/intrinsic_return": 0.0}
{"step": 238072, "time": 12017.59841632843, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 238432, "time": 12032.619126558304, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 238920, "time": 12051.809390544891, "episode/length": 134.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 238928, "time": 12053.892336845398, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 239048, "time": 12059.638884067535, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 239080, "time": 12062.42815542221, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 239264, "time": 12071.030687570572, "episode/length": 217.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 239328, "time": 12074.899663209915, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 239672, "time": 12088.771988391876, "episode/length": 318.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 12117.81094622612, "eval_episode/length": 34.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 240032, "time": 12123.433444976807, "eval_episode/length": 140.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 240032, "time": 12125.469409704208, "eval_episode/length": 150.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 240032, "time": 12127.791468858719, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 240032, "time": 12130.794047355652, "eval_episode/length": 34.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 240032, "time": 12132.852073431015, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 240032, "time": 12137.824311971664, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 240032, "time": 12140.45361161232, "eval_episode/length": 259.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 240296, "time": 12150.193306684494, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 240312, "time": 12152.93282198906, "episode/length": 234.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 240504, "time": 12162.248708724976, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 240584, "time": 12167.228994846344, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 240960, "time": 12183.603723526001, "episode/length": 160.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 240984, "time": 12186.341347694397, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 241296, "time": 12200.27522969246, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 241512, "time": 12210.003175497055, "episode/length": 149.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 241792, "time": 12222.602755784988, "episode/length": 160.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 242080, "time": 12234.8345079422, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 242128, "time": 12238.661009550095, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 242128, "time": 12238.706638336182, "episode/length": 145.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 242248, "time": 12247.092413425446, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 242424, "time": 12255.640312433243, "episode/length": 417.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9976076555023924, "episode/intrinsic_return": 0.0}
{"step": 242632, "time": 12265.414503335953, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 242664, "time": 12268.499762296677, "episode/length": 51.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 243192, "time": 12290.362819433212, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 243337, "time": 12298.719873428345, "train_stats/sum_log_reward": 5.041747533001946, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.504854368932039, "train_stats/max_log_achievement_collect_sapling": 2.466019417475728, "train_stats/max_log_achievement_collect_stone": 0.009708737864077669, "train_stats/max_log_achievement_collect_wood": 4.893203883495145, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3106796116504854, "train_stats/max_log_achievement_eat_cow": 0.07766990291262135, "train_stats/max_log_achievement_make_wood_pickaxe": 0.10679611650485436, "train_stats/max_log_achievement_make_wood_sword": 0.1553398058252427, "train_stats/max_log_achievement_place_plant": 2.3398058252427183, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.087378640776699, "train_stats/max_log_achievement_wake_up": 3.0194174757281553, "train_stats/mean_log_entropy": 0.7385366472225745, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.045145350178395, "train/action_min": 0.0, "train/action_std": 3.888252498596672, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048620482422704774, "train/actor_opt_grad_steps": 14480.0, "train/actor_opt_loss": 0.49446219469853275, "train/adv_mag": 0.794495690995314, "train/adv_max": 0.7641418013047045, "train/adv_mean": 0.004554669336071165, "train/adv_min": -0.5650307808335372, "train/adv_std": 0.08069367601176886, "train/cont_avg": 0.9942867249015748, "train/cont_loss_mean": 0.00021542319749282636, "train/cont_loss_std": 0.006088539061231245, "train/cont_neg_acc": 0.990257468749219, "train/cont_neg_loss": 0.02104332205758009, "train/cont_pos_acc": 0.9999613104842779, "train/cont_pos_loss": 0.00011066568981139365, "train/cont_pred": 0.9942788354993806, "train/cont_rate": 0.9942867249015748, "train/dyn_loss_mean": 13.38022104398472, "train/dyn_loss_std": 9.017043308948907, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9164562234728355, "train/extr_critic_critic_opt_grad_steps": 14480.0, "train/extr_critic_critic_opt_loss": 15441.689314714567, "train/extr_critic_mag": 4.465656490776483, "train/extr_critic_max": 4.465656490776483, "train/extr_critic_mean": 0.7740090219523963, "train/extr_critic_min": -0.3359467570237287, "train/extr_critic_std": 0.9943822199904074, "train/extr_return_normed_mag": 1.9370399882474283, "train/extr_return_normed_max": 1.9370399882474283, "train/extr_return_normed_mean": 0.3020015850545853, "train/extr_return_normed_min": -0.21629488972697672, "train/extr_return_normed_std": 0.3443183566876284, "train/extr_return_rate": 0.4128158025619552, "train/extr_return_raw_mag": 5.6999057747247655, "train/extr_return_raw_max": 5.6999057747247655, "train/extr_return_raw_mean": 0.7876807509914158, "train/extr_return_raw_min": -0.7683953309622337, "train/extr_return_raw_std": 1.0342548057788938, "train/extr_reward_mag": 1.0125179816418746, "train/extr_reward_max": 1.0125179816418746, "train/extr_reward_mean": 0.02123451400108225, "train/extr_reward_min": -0.5035465880641787, "train/extr_reward_std": 0.13544508239885014, "train/image_loss_mean": 9.228191334431566, "train/image_loss_std": 12.624073614285686, "train/model_loss_mean": 17.308563960818795, "train/model_loss_std": 16.409471256526437, "train/model_opt_grad_norm": 70.36690271933247, "train/model_opt_grad_steps": 14463.92125984252, "train/model_opt_loss": 12299.335672213336, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 713.5826771653543, "train/policy_entropy_mag": 2.551385186788604, "train/policy_entropy_max": 2.551385186788604, "train/policy_entropy_mean": 0.829989514012975, "train/policy_entropy_min": 0.07937531871354486, "train/policy_entropy_std": 0.7766938237693366, "train/policy_logprob_mag": 7.438380883434626, "train/policy_logprob_max": -0.009455802850425243, "train/policy_logprob_mean": -0.8296479249563743, "train/policy_logprob_min": -7.438380883434626, "train/policy_logprob_std": 1.246963201545355, "train/policy_randomness_mag": 0.900527006059181, "train/policy_randomness_max": 0.900527006059181, "train/policy_randomness_mean": 0.2929498752740424, "train/policy_randomness_min": 0.02801600430072762, "train/policy_randomness_std": 0.27413883371146647, "train/post_ent_mag": 56.06235507154089, "train/post_ent_max": 56.06235507154089, "train/post_ent_mean": 38.216654980276516, "train/post_ent_min": 20.59423527004212, "train/post_ent_std": 6.64678371234203, "train/prior_ent_mag": 65.38444711279682, "train/prior_ent_max": 65.38444711279682, "train/prior_ent_mean": 51.698799583855575, "train/prior_ent_min": 30.087641633401706, "train/prior_ent_std": 6.08136324995146, "train/rep_loss_mean": 13.38022104398472, "train/rep_loss_std": 9.017043308948907, "train/reward_avg": 0.019272114656220272, "train/reward_loss_mean": 0.052024583031577386, "train/reward_loss_std": 0.25994088489004946, "train/reward_max_data": 1.0125984282005491, "train/reward_max_pred": 1.0067115731126681, "train/reward_neg_acc": 0.993721816483445, "train/reward_neg_loss": 0.030278109894024106, "train/reward_pos_acc": 0.950762418311412, "train/reward_pos_loss": 0.9204822131029264, "train/reward_pred": 0.018449699759160675, "train/reward_rate": 0.024452509842519687, "eval_stats/sum_log_reward": 4.287499964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.25, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00021869914780836552, "report/cont_loss_std": 0.0052343872375786304, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0016288228798657656, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00021316923084668815, "report/cont_pred": 0.9959007501602173, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.963384628295898, "report/dyn_loss_std": 8.546794891357422, "report/image_loss_mean": 7.438576698303223, "report/image_loss_std": 9.459096908569336, "report/model_loss_mean": 14.06180477142334, "report/model_loss_std": 12.661356925964355, "report/post_ent_mag": 59.236122131347656, "report/post_ent_max": 59.236122131347656, "report/post_ent_mean": 41.0301399230957, "report/post_ent_min": 19.07526969909668, "report/post_ent_std": 7.799081802368164, "report/prior_ent_mag": 65.85066223144531, "report/prior_ent_max": 65.85066223144531, "report/prior_ent_mean": 52.57252502441406, "report/prior_ent_min": 31.851402282714844, "report/prior_ent_std": 5.150849342346191, "report/rep_loss_mean": 10.963384628295898, "report/rep_loss_std": 8.546794891357422, "report/reward_avg": 0.02216796949505806, "report/reward_loss_mean": 0.04497870057821274, "report/reward_loss_std": 0.18900009989738464, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0027978420257568, "report/reward_neg_acc": 0.994979977607727, "report/reward_neg_loss": 0.025244710966944695, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7469450831413269, "report/reward_pred": 0.022613782435655594, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.6853936762781814e-05, "eval/cont_loss_std": 0.00025256964727304876, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00037783043808303773, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.585204831324518e-05, "eval/cont_pred": 0.9970356822013855, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.786653518676758, "eval/dyn_loss_std": 10.538617134094238, "eval/image_loss_mean": 21.586217880249023, "eval/image_loss_std": 29.11287498474121, "eval/model_loss_mean": 31.765071868896484, "eval/model_loss_std": 33.524044036865234, "eval/post_ent_mag": 57.166744232177734, "eval/post_ent_max": 57.166744232177734, "eval/post_ent_mean": 37.9217529296875, "eval/post_ent_min": 22.455472946166992, "eval/post_ent_std": 5.536993503570557, "eval/prior_ent_mag": 65.85066223144531, "eval/prior_ent_max": 65.85066223144531, "eval/prior_ent_mean": 52.119598388671875, "eval/prior_ent_min": 28.565322875976562, "eval/prior_ent_std": 5.776607513427734, "eval/rep_loss_mean": 16.786653518676758, "eval/rep_loss_std": 10.538617134094238, "eval/reward_avg": 0.02578124962747097, "eval/reward_loss_mean": 0.10682596266269684, "eval/reward_loss_std": 0.6180124878883362, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0027709007263184, "eval/reward_neg_acc": 0.9929577112197876, "eval/reward_neg_loss": 0.058551009744405746, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.7063357830047607, "eval/reward_pred": 0.02298424392938614, "eval/reward_rate": 0.029296875, "replay/size": 242833.0, "replay/inserts": 20328.0, "replay/samples": 20336.0, "replay/insert_wait_avg": 1.3788118929151755e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.184149169621741e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 48288.0, "eval_replay/inserts": 4312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1092103699806227e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2354311943054, "timer/env.step_count": 2541.0, "timer/env.step_total": 244.41913676261902, "timer/env.step_frac": 0.24436160641777768, "timer/env.step_avg": 0.09619013646698898, "timer/env.step_min": 0.023364543914794922, "timer/env.step_max": 4.002653121948242, "timer/replay._sample_count": 20336.0, "timer/replay._sample_total": 10.471796035766602, "timer/replay._sample_frac": 0.010469331228611871, "timer/replay._sample_avg": 0.0005149388294535111, "timer/replay._sample_min": 0.0003571510314941406, "timer/replay._sample_max": 0.011071920394897461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3080.0, "timer/agent.policy_total": 51.13691973686218, "timer/agent.policy_frac": 0.05112488334451766, "timer/agent.policy_avg": 0.01660289601846175, "timer/agent.policy_min": 0.009540081024169922, "timer/agent.policy_max": 0.09936261177062988, "timer/dataset_train_count": 1271.0, "timer/dataset_train_total": 0.15112781524658203, "timer/dataset_train_frac": 0.00015109224341926356, "timer/dataset_train_avg": 0.00011890465400989932, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.00107574462890625, "timer/agent.train_count": 1271.0, "timer/agent.train_total": 565.5876340866089, "timer/agent.train_frac": 0.5654545084563576, "timer/agent.train_avg": 0.44499420463147826, "timer/agent.train_min": 0.4329500198364258, "timer/agent.train_max": 1.2044436931610107, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4766371250152588, "timer/agent.report_frac": 0.0004765249361804175, "timer/agent.report_avg": 0.2383185625076294, "timer/agent.report_min": 0.23181557655334473, "timer/agent.report_max": 0.24482154846191406, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146384487083087e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 20.322939852998765}
{"step": 243376, "time": 12300.286458492279, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 243496, "time": 12306.63843369484, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 243616, "time": 12313.12914443016, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 243632, "time": 12315.351128578186, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 243920, "time": 12327.419773817062, "episode/length": 265.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 244120, "time": 12335.971523046494, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 244544, "time": 12353.155430316925, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 244696, "time": 12360.013529777527, "episode/length": 134.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 244856, "time": 12367.367787837982, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 245240, "time": 12382.957999944687, "episode/length": 232.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 245248, "time": 12385.08228468895, "episode/length": 165.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 245352, "time": 12390.119794845581, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 245448, "time": 12395.31392121315, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 245480, "time": 12398.158709287643, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 246032, "time": 12421.510433197021, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 246080, "time": 12424.792507886887, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 246136, "time": 12428.2338950634, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 246544, "time": 12444.85534620285, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 246552, "time": 12446.432781934738, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 246584, "time": 12449.210941314697, "episode/length": 167.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 246808, "time": 12460.000153541565, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 246968, "time": 12467.375947237015, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 247256, "time": 12479.357203960419, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 247264, "time": 12481.382911682129, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 247624, "time": 12495.95483660698, "episode/length": 134.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 247800, "time": 12503.942284584045, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 247984, "time": 12512.4637362957, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 248008, "time": 12514.608789682388, "episode/length": 233.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 248136, "time": 12520.972116708755, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 248456, "time": 12534.132441997528, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 248640, "time": 12542.689108371735, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 248984, "time": 12556.576950788498, "episode/length": 169.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 249208, "time": 12566.27223443985, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 249408, "time": 12575.524844646454, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 249496, "time": 12579.993211507797, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 249776, "time": 12591.918175935745, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 249888, "time": 12597.485956192017, "episode/length": 328.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 12618.389182567596, "eval_episode/length": 38.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 250016, "time": 12625.699758768082, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 250016, "time": 12627.815742015839, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 250016, "time": 12630.55565237999, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 250016, "time": 12632.31176686287, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 250016, "time": 12633.945373773575, "eval_episode/length": 200.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 250016, "time": 12636.429939031601, "eval_episode/length": 183.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 250016, "time": 12636.471621990204, "eval_episode/length": 222.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 250160, "time": 12641.727011680603, "episode/length": 146.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 250360, "time": 12650.213861465454, "episode/length": 319.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 250488, "time": 12656.393490076065, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 250528, "time": 12659.635606527328, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 251232, "time": 12686.859645843506, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 251472, "time": 12697.29068183899, "episode/length": 197.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 251632, "time": 12704.715720415115, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 251680, "time": 12708.071871042252, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 251688, "time": 12709.774891376495, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 251968, "time": 12721.641523838043, "episode/length": 308.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 252288, "time": 12735.276596546173, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 252552, "time": 12747.013844251633, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 252936, "time": 12763.706092357635, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 253000, "time": 12768.218416929245, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 253264, "time": 12780.362671136856, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 253416, "time": 12787.993161916733, "episode/length": 216.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 253416, "time": 12788.046350002289, "episode/length": 360.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 253528, "time": 12796.277540445328, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 253592, "time": 12800.763159036636, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 254040, "time": 12820.952916145325, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 254288, "time": 12832.444023609161, "episode/length": 160.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 254576, "time": 12845.234835386276, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 254784, "time": 12855.155997037888, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 254808, "time": 12857.787402629852, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 254928, "time": 12864.578966140747, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 254944, "time": 12867.120404958725, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 254952, "time": 12869.175921440125, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 255696, "time": 12899.278778791428, "episode/length": 93.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 255744, "time": 12902.53615951538, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 255840, "time": 12907.65023803711, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 256040, "time": 12916.258809804916, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 256088, "time": 12919.585062503815, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 256104, "time": 12921.646787643433, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 256336, "time": 12931.905105352402, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 256352, "time": 12934.045608997345, "episode/length": 81.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 256560, "time": 12943.267401218414, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 257064, "time": 12962.992122411728, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 257136, "time": 12967.55470609665, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 257312, "time": 12975.430647611618, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 257656, "time": 12989.300304889679, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 257768, "time": 12994.92267537117, "episode/length": 209.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 257800, "time": 12997.743018388748, "episode/length": 219.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 257944, "time": 13004.447601556778, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 258008, "time": 13008.423298358917, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 258512, "time": 13028.712738752365, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 258888, "time": 13043.75375366211, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 258912, "time": 13046.37209534645, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 258928, "time": 13048.501849651337, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 258936, "time": 13050.171151399612, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 259088, "time": 13057.61809706688, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 259176, "time": 13062.112163066864, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 259744, "time": 13084.63728094101, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 13109.969984292984, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 260000, "time": 13114.628628730774, "eval_episode/length": 118.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9915966386554622}
{"step": 260000, "time": 13117.866980075836, "eval_episode/length": 154.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 260000, "time": 13117.91861152649, "eval_episode/length": 154.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 260000, "time": 13121.283857107162, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9556962025316456}
{"step": 260000, "time": 13123.488565206528, "eval_episode/length": 174.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 260000, "time": 13123.537649869919, "eval_episode/length": 136.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 260000, "time": 13128.718720912933, "eval_episode/length": 223.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 260144, "time": 13134.007488489151, "episode/length": 156.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 260312, "time": 13141.495750904083, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 260376, "time": 13145.590067148209, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 260376, "time": 13145.63044834137, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 260576, "time": 13156.445404529572, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 260744, "time": 13163.994592189789, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9911894273127754, "episode/intrinsic_return": 0.0}
{"step": 260760, "time": 13166.098197460175, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 261240, "time": 13185.665229082108, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 261480, "time": 13196.594356536865, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 261624, "time": 13203.977723836899, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 261704, "time": 13209.132214307785, "episode/length": 117.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9491525423728814, "episode/intrinsic_return": 0.0}
{"step": 261936, "time": 13220.069326877594, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 262424, "time": 13241.882026195526, "episode/length": 230.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 262608, "time": 13251.095169067383, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 262776, "time": 13259.220759630203, "episode/length": 299.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 262832, "time": 13263.617064237595, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 262880, "time": 13267.565871238708, "episode/length": 204.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 263096, "time": 13277.426571130753, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 263336, "time": 13288.571647167206, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 263456, "time": 13294.952420711517, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 263497, "time": 13298.947535037994, "train_stats/sum_log_reward": 5.017431147601626, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.6880733944954125, "train_stats/max_log_achievement_collect_sapling": 2.293577981651376, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.220183486238532, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.23853211009174313, "train_stats/max_log_achievement_eat_cow": 0.06422018348623854, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06422018348623854, "train_stats/max_log_achievement_make_wood_sword": 0.28440366972477066, "train_stats/max_log_achievement_place_plant": 2.165137614678899, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.091743119266055, "train_stats/max_log_achievement_wake_up": 2.5688073394495414, "train_stats/mean_log_entropy": 0.7189474168720595, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.115270705450149, "train/action_min": 0.0, "train/action_std": 4.081075428024171, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04899206782676398, "train/actor_opt_grad_steps": 15745.0, "train/actor_opt_loss": 1.5196409119027001, "train/adv_mag": 0.7625575392019182, "train/adv_max": 0.7441479537695174, "train/adv_mean": 0.004678484080621216, "train/adv_min": -0.5366661461099745, "train/adv_std": 0.07896285323751351, "train/cont_avg": 0.994566902281746, "train/cont_loss_mean": 0.00032598594910912505, "train/cont_loss_std": 0.009396469363283567, "train/cont_neg_acc": 0.9902683307254125, "train/cont_neg_loss": 0.027515452867798256, "train/cont_pos_acc": 0.9999142416885921, "train/cont_pos_loss": 0.00020821979032019795, "train/cont_pred": 0.9945120981761387, "train/cont_rate": 0.994566902281746, "train/dyn_loss_mean": 13.274462662045918, "train/dyn_loss_std": 9.04632328427027, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9726129562135727, "train/extr_critic_critic_opt_grad_steps": 15745.0, "train/extr_critic_critic_opt_loss": 15646.686259920634, "train/extr_critic_mag": 4.57455953719124, "train/extr_critic_max": 4.57455953719124, "train/extr_critic_mean": 0.8150689566419238, "train/extr_critic_min": -0.34542788778032574, "train/extr_critic_std": 1.0034122448118905, "train/extr_return_normed_mag": 1.9134590086482821, "train/extr_return_normed_max": 1.9134590086482821, "train/extr_return_normed_mean": 0.2985767832114583, "train/extr_return_normed_min": -0.21824831148934742, "train/extr_return_normed_std": 0.3410168446245648, "train/extr_return_rate": 0.4275483865113485, "train/extr_return_raw_mag": 5.757602718141344, "train/extr_return_raw_max": 5.757602718141344, "train/extr_return_raw_mean": 0.8293415487758697, "train/extr_return_raw_min": -0.7479309233881178, "train/extr_return_raw_std": 1.0409009631664035, "train/extr_reward_mag": 1.01036122299376, "train/extr_reward_max": 1.01036122299376, "train/extr_reward_mean": 0.021809651752904294, "train/extr_reward_min": -0.46113182911797174, "train/extr_reward_std": 0.1365827579228651, "train/image_loss_mean": 8.690101653810531, "train/image_loss_std": 12.325634759569924, "train/model_loss_mean": 16.705822921934583, "train/model_loss_std": 16.11346200912718, "train/model_opt_grad_norm": 65.12932583642385, "train/model_opt_grad_steps": 15728.0, "train/model_opt_loss": 13368.190542069693, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 803.5714285714286, "train/policy_entropy_mag": 2.554815587543306, "train/policy_entropy_max": 2.554815587543306, "train/policy_entropy_mean": 0.7842331552316272, "train/policy_entropy_min": 0.07937527418373123, "train/policy_entropy_std": 0.7364553274616362, "train/policy_logprob_mag": 7.438381618923611, "train/policy_logprob_max": -0.00945576551621632, "train/policy_logprob_mean": -0.7843131186470153, "train/policy_logprob_min": -7.438381618923611, "train/policy_logprob_std": 1.2261879737415011, "train/policy_randomness_mag": 0.9017377860016293, "train/policy_randomness_max": 0.9017377860016293, "train/policy_randomness_mean": 0.2767998878917997, "train/policy_randomness_min": 0.028015988657162302, "train/policy_randomness_std": 0.2599364083910745, "train/post_ent_mag": 56.58108562893338, "train/post_ent_max": 56.58108562893338, "train/post_ent_mean": 38.661663782028924, "train/post_ent_min": 20.40215672387017, "train/post_ent_std": 6.805602278028216, "train/prior_ent_mag": 65.64930967300657, "train/prior_ent_max": 65.64930967300657, "train/prior_ent_mean": 52.0799805171906, "train/prior_ent_min": 31.16199233039977, "train/prior_ent_std": 5.796584269357106, "train/rep_loss_mean": 13.274462662045918, "train/rep_loss_std": 9.04632328427027, "train/reward_avg": 0.01994590149704544, "train/reward_loss_mean": 0.05071773128731856, "train/reward_loss_std": 0.25591584224076497, "train/reward_max_data": 1.0087301608115908, "train/reward_max_pred": 1.0051717171593317, "train/reward_neg_acc": 0.9937588756992703, "train/reward_neg_loss": 0.028531110727243007, "train/reward_pos_acc": 0.9555145762269459, "train/reward_pos_loss": 0.9166803137650565, "train/reward_pred": 0.019085198478211485, "train/reward_rate": 0.024855840773809524, "eval_stats/sum_log_reward": 4.537499910220504, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 2.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.50009053768008e-06, "report/cont_loss_std": 0.00010504041711101308, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004109575820621103, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.1103611490834737e-06, "report/cont_pred": 0.9941399693489075, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.955703735351562, "report/dyn_loss_std": 8.948613166809082, "report/image_loss_mean": 7.337575435638428, "report/image_loss_std": 9.140114784240723, "report/model_loss_mean": 15.165103912353516, "report/model_loss_std": 12.849045753479004, "report/post_ent_mag": 55.7088737487793, "report/post_ent_max": 55.7088737487793, "report/post_ent_mean": 37.958038330078125, "report/post_ent_min": 14.662015914916992, "report/post_ent_std": 6.83072566986084, "report/prior_ent_mag": 65.93839263916016, "report/prior_ent_max": 65.93839263916016, "report/prior_ent_mean": 51.83026885986328, "report/prior_ent_min": 29.801176071166992, "report/prior_ent_std": 5.9726433753967285, "report/rep_loss_mean": 12.955703735351562, "report/rep_loss_std": 8.948613166809082, "report/reward_avg": 0.02714843675494194, "report/reward_loss_mean": 0.05410107225179672, "report/reward_loss_std": 0.25790756940841675, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0013763904571533, "report/reward_neg_acc": 0.9949596524238586, "report/reward_neg_loss": 0.026196293532848358, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.9191492199897766, "report/reward_pred": 0.025364184752106667, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0004575405619107187, "eval/cont_loss_std": 0.014607193879783154, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.11711793392896652, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.874969761203829e-08, "eval/cont_pred": 0.9964593052864075, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.470216751098633, "eval/dyn_loss_std": 10.1868314743042, "eval/image_loss_mean": 20.029991149902344, "eval/image_loss_std": 22.960927963256836, "eval/model_loss_mean": 31.803348541259766, "eval/model_loss_std": 27.11986541748047, "eval/post_ent_mag": 55.04920196533203, "eval/post_ent_max": 55.04920196533203, "eval/post_ent_mean": 37.15204620361328, "eval/post_ent_min": 20.430133819580078, "eval/post_ent_std": 5.926084995269775, "eval/prior_ent_mag": 65.93839263916016, "eval/prior_ent_max": 65.93839263916016, "eval/prior_ent_mean": 53.2615966796875, "eval/prior_ent_min": 32.372711181640625, "eval/prior_ent_std": 4.707132816314697, "eval/rep_loss_mean": 19.470216751098633, "eval/rep_loss_std": 10.1868314743042, "eval/reward_avg": 0.02490234375, "eval/reward_loss_mean": 0.09077192097902298, "eval/reward_loss_std": 0.5898551344871521, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001912117004395, "eval/reward_neg_acc": 0.9909547567367554, "eval/reward_neg_loss": 0.03997906297445297, "eval/reward_pos_acc": 0.7586206793785095, "eval/reward_pos_loss": 1.833492398262024, "eval/reward_pred": 0.021262871101498604, "eval/reward_rate": 0.0283203125, "replay/size": 262993.0, "replay/inserts": 20160.0, "replay/samples": 20160.0, "replay/insert_wait_avg": 1.3958367090376596e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.152590857611762e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51864.0, "eval_replay/inserts": 3576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1107532236666753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2153956890106, "timer/env.step_count": 2520.0, "timer/env.step_total": 250.9799976348877, "timer/env.step_frac": 0.25092594926715467, "timer/env.step_avg": 0.09959523715670146, "timer/env.step_min": 0.023075342178344727, "timer/env.step_max": 4.0517168045043945, "timer/replay._sample_count": 20160.0, "timer/replay._sample_total": 10.461821794509888, "timer/replay._sample_frac": 0.010459568848471018, "timer/replay._sample_avg": 0.0005189395731403714, "timer/replay._sample_min": 0.0004215240478515625, "timer/replay._sample_max": 0.011478185653686523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2967.0, "timer/agent.policy_total": 50.98592972755432, "timer/agent.policy_frac": 0.05097494994308905, "timer/agent.policy_avg": 0.017184337623038195, "timer/agent.policy_min": 0.009389877319335938, "timer/agent.policy_max": 0.10446333885192871, "timer/dataset_train_count": 1260.0, "timer/dataset_train_total": 0.190873384475708, "timer/dataset_train_frac": 0.0001908322800252665, "timer/dataset_train_avg": 0.00015148681307595874, "timer/dataset_train_min": 0.00010514259338378906, "timer/dataset_train_max": 0.04266786575317383, "timer/agent.train_count": 1260.0, "timer/agent.train_total": 563.8322036266327, "timer/agent.train_frac": 0.5637107827541786, "timer/agent.train_avg": 0.44748587589415295, "timer/agent.train_min": 0.43520665168762207, "timer/agent.train_max": 1.3301572799682617, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46992063522338867, "timer/agent.report_frac": 0.00046981943814179954, "timer/agent.report_avg": 0.23496031761169434, "timer/agent.report_min": 0.22372126579284668, "timer/agent.report_max": 0.246199369430542, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741223212005487e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 20.15539999553873}
{"step": 263800, "time": 13309.839212179184, "episode/length": 148.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 263912, "time": 13315.526600599289, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 264016, "time": 13321.176020145416, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 264120, "time": 13326.378448009491, "episode/length": 39.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 264176, "time": 13330.1492664814, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 264240, "time": 13334.011945962906, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 264512, "time": 13345.489398956299, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 264552, "time": 13348.244047403336, "episode/length": 136.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 264592, "time": 13351.403278112411, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 265496, "time": 13385.87250828743, "episode/length": 269.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 265568, "time": 13390.216994285583, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 265600, "time": 13392.804302930832, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 265808, "time": 13401.964389801025, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 265832, "time": 13404.167785406113, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 265888, "time": 13408.01780462265, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 266136, "time": 13418.620857715607, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 266176, "time": 13421.893225193024, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 266824, "time": 13446.986481904984, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 266832, "time": 13449.02914428711, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 267024, "time": 13457.67004108429, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 267112, "time": 13462.254383802414, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 267168, "time": 13466.257425785065, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 267240, "time": 13470.16865491867, "episode/length": 51.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 267264, "time": 13472.845703840256, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 267328, "time": 13476.917506217957, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 267376, "time": 13480.11032485962, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 267784, "time": 13496.436566591263, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 268160, "time": 13512.179418563843, "episode/length": 141.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 268320, "time": 13519.734887599945, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 268360, "time": 13522.58265042305, "episode/length": 148.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 268480, "time": 13528.724924087524, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 268520, "time": 13531.42753148079, "episode/length": 156.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 268664, "time": 13538.313650131226, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 268872, "time": 13547.655302524567, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 269560, "time": 13574.398921251297, "episode/length": 221.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 269744, "time": 13582.762199163437, "episode/length": 172.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 269752, "time": 13584.417013645172, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 269800, "time": 13587.714067697525, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 269856, "time": 13591.567502737045, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 269872, "time": 13593.735119342804, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 13617.298158884048, "eval_episode/length": 38.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 270088, "time": 13620.177966833115, "eval_episode/length": 35.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 270088, "time": 13624.533148765564, "eval_episode/length": 149.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 270088, "time": 13626.42910027504, "eval_episode/length": 156.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 270088, "time": 13629.080392122269, "eval_episode/length": 184.0, "eval_episode/score": 7.100000038743019, "eval_episode/reward_rate": 0.972972972972973}
{"step": 270088, "time": 13631.466586112976, "eval_episode/length": 205.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 270088, "time": 13633.107811450958, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 270088, "time": 13634.852385997772, "eval_episode/length": 209.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 270360, "time": 13646.120904922485, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659574468085106, "episode/intrinsic_return": 0.0}
{"step": 270688, "time": 13659.976870775223, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 270944, "time": 13670.9573636055, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 271192, "time": 13681.40264582634, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 271256, "time": 13685.359622716904, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 271400, "time": 13692.09466290474, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 271592, "time": 13700.69790649414, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 271600, "time": 13702.715854167938, "episode/length": 50.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 271624, "time": 13704.955860376358, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 271752, "time": 13711.10253405571, "episode/length": 100.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 271976, "time": 13721.119196414948, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695817490494296, "episode/intrinsic_return": 0.0}
{"step": 272720, "time": 13750.387880802155, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 272872, "time": 13758.070212841034, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 272888, "time": 13760.719209194183, "episode/length": 160.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 272888, "time": 13760.769742488861, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 272912, "time": 13766.150611400604, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 273160, "time": 13777.195351600647, "episode/length": 33.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 273224, "time": 13781.080639123917, "episode/length": 183.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 273256, "time": 13783.87009859085, "episode/length": 159.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 273624, "time": 13798.849844932556, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 273968, "time": 13813.21599817276, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 274016, "time": 13816.552418708801, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 274336, "time": 13829.720061540604, "episode/length": 180.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 274536, "time": 13838.3922393322, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 274928, "time": 13855.298864364624, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 275048, "time": 13861.562683105469, "episode/length": 235.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 275112, "time": 13865.621034383774, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 275272, "time": 13872.862559556961, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 275480, "time": 13881.975214242935, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 275648, "time": 13889.803847074509, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 275800, "time": 13896.78899550438, "episode/length": 39.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 275808, "time": 13898.80678319931, "episode/length": 361.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 275968, "time": 13906.106676101685, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 276680, "time": 13933.485100507736, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 276736, "time": 13937.323038339615, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 276984, "time": 13947.671572685242, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 277024, "time": 13950.869823932648, "episode/length": 218.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 277200, "time": 13959.00993180275, "episode/length": 153.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 277320, "time": 13964.711154460907, "episode/length": 275.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 277384, "time": 13968.579986572266, "episode/length": 197.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 277400, "time": 13970.629331588745, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 277616, "time": 13980.328028917313, "episode/length": 320.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 277704, "time": 13984.894071102142, "episode/length": 37.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 277960, "time": 13995.944036483765, "episode/length": 79.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 278064, "time": 14001.441857337952, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 278408, "time": 14015.347511768341, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 278808, "time": 14032.91643834114, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 278824, "time": 14035.023875713348, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 279112, "time": 14047.118923425674, "episode/length": 215.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 279272, "time": 14054.571410655975, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 279336, "time": 14058.50774717331, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 279368, "time": 14061.23540520668, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 279512, "time": 14068.135064840317, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 279608, "time": 14073.184847831726, "episode/length": 237.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 14110.361759662628, "eval_episode/length": 147.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 280072, "time": 14111.980608224869, "eval_episode/length": 150.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 280072, "time": 14113.823654651642, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 280072, "time": 14115.617707490921, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 280072, "time": 14117.4273955822, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 280072, "time": 14119.183794260025, "eval_episode/length": 180.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 280072, "time": 14120.90489077568, "eval_episode/length": 182.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 280072, "time": 14122.898554563522, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 280248, "time": 14129.318001031876, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 280256, "time": 14131.438979387283, "episode/length": 142.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 280472, "time": 14140.599487781525, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 280488, "time": 14142.59163403511, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 280808, "time": 14155.8711977005, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 281032, "time": 14165.567230463028, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 281032, "time": 14165.618858575821, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 281144, "time": 14173.209416389465, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 281464, "time": 14186.37865614891, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 281592, "time": 14192.632461309433, "episode/length": 166.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 281624, "time": 14195.35990691185, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 282296, "time": 14221.310957193375, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 282408, "time": 14227.100742816925, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 282544, "time": 14233.757403612137, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 282560, "time": 14236.364139080048, "episode/length": 176.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 282608, "time": 14240.213857650757, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 282800, "time": 14249.435553789139, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 282880, "time": 14254.35175895691, "episode/length": 41.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 283168, "time": 14267.304239273071, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 283488, "time": 14281.047705411911, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 283624, "time": 14287.311391353607, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 283881, "time": 14299.267180919647, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.560009573388287, "train/action_min": 0.0, "train/action_std": 3.6472245820863978, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048813342520101805, "train/actor_opt_grad_steps": 17010.0, "train/actor_opt_loss": 1.4319357758930584, "train/adv_mag": 0.7583020794110036, "train/adv_max": 0.7385173397740041, "train/adv_mean": 0.0048066615514314225, "train/adv_min": -0.5323891979972208, "train/adv_std": 0.07872259889648656, "train/cont_avg": 0.9946019931102362, "train/cont_loss_mean": 0.00023157426045909734, "train/cont_loss_std": 0.006578054778404251, "train/cont_neg_acc": 0.9863170526159091, "train/cont_neg_loss": 0.035656389395970066, "train/cont_pos_acc": 0.9999380768753412, "train/cont_pos_loss": 0.00011779900973510972, "train/cont_pred": 0.9945906658810894, "train/cont_rate": 0.9946019931102362, "train/dyn_loss_mean": 13.352195446885476, "train/dyn_loss_std": 9.052034993809977, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9245361577807449, "train/extr_critic_critic_opt_grad_steps": 17010.0, "train/extr_critic_critic_opt_loss": 15419.849886195867, "train/extr_critic_mag": 4.585290942605086, "train/extr_critic_max": 4.585290942605086, "train/extr_critic_mean": 0.8878693925583456, "train/extr_critic_min": -0.32455129416908807, "train/extr_critic_std": 1.0024435534251956, "train/extr_return_normed_mag": 1.8756176486728697, "train/extr_return_normed_max": 1.8756176486728697, "train/extr_return_normed_mean": 0.31328360267042177, "train/extr_return_normed_min": -0.21746284338667637, "train/extr_return_normed_std": 0.337942861313895, "train/extr_return_rate": 0.46897763412768445, "train/extr_return_raw_mag": 5.712247045021358, "train/extr_return_raw_max": 5.712247045021358, "train/extr_return_raw_mean": 0.9026817214770579, "train/extr_return_raw_min": -0.7311829720425793, "train/extr_return_raw_std": 1.0401902156551992, "train/extr_reward_mag": 1.0135791095223015, "train/extr_reward_max": 1.0135791095223015, "train/extr_reward_mean": 0.022350823873375343, "train/extr_reward_min": -0.487463828146927, "train/extr_reward_std": 0.1384709952619132, "train/image_loss_mean": 8.256441705808864, "train/image_loss_std": 11.566898192007711, "train/model_loss_mean": 16.317373042970193, "train/model_loss_std": 15.386746136222298, "train/model_opt_grad_norm": 64.69101333618164, "train/model_opt_grad_steps": 16992.094488188977, "train/model_opt_loss": 12318.675585168554, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 757.8740157480315, "train/policy_entropy_mag": 2.530813115788257, "train/policy_entropy_max": 2.530813115788257, "train/policy_entropy_mean": 0.7025946172203604, "train/policy_entropy_min": 0.07937526210086553, "train/policy_entropy_std": 0.7084973492021636, "train/policy_logprob_mag": 7.438382479149525, "train/policy_logprob_max": -0.009455755352973938, "train/policy_logprob_mean": -0.7030284798990084, "train/policy_logprob_min": -7.438382479149525, "train/policy_logprob_std": 1.1920239315258236, "train/policy_randomness_mag": 0.8932659672939871, "train/policy_randomness_max": 0.8932659672939871, "train/policy_randomness_mean": 0.24798506568735978, "train/policy_randomness_min": 0.028015984251625894, "train/policy_randomness_std": 0.25006847083568573, "train/post_ent_mag": 56.90231176060954, "train/post_ent_max": 56.90231176060954, "train/post_ent_mean": 38.85810885091466, "train/post_ent_min": 20.59012686361478, "train/post_ent_std": 6.839630202045591, "train/prior_ent_mag": 65.86348183699481, "train/prior_ent_max": 65.86348183699481, "train/prior_ent_mean": 52.29476493174636, "train/prior_ent_min": 32.46728329395685, "train/prior_ent_std": 5.578336700679749, "train/rep_loss_mean": 13.352195446885476, "train/rep_loss_std": 9.052034993809977, "train/reward_avg": 0.020906126713306886, "train/reward_loss_mean": 0.049382585313493814, "train/reward_loss_std": 0.23937804269509053, "train/reward_max_data": 1.0055118123377402, "train/reward_max_pred": 1.004259493407302, "train/reward_neg_acc": 0.9936450410076952, "train/reward_neg_loss": 0.02732895102029241, "train/reward_pos_acc": 0.9631942153915646, "train/reward_pos_loss": 0.8848218307720395, "train/reward_pred": 0.0200122648072759, "train/reward_rate": 0.025736651082677166, "train_stats/sum_log_reward": 5.004347771665325, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.278260869565218, "train_stats/max_log_achievement_collect_sapling": 2.2956521739130435, "train_stats/max_log_achievement_collect_stone": 0.017391304347826087, "train_stats/max_log_achievement_collect_wood": 5.860869565217391, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.33043478260869563, "train_stats/max_log_achievement_eat_cow": 0.08695652173913043, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017391304347826087, "train_stats/max_log_achievement_make_wood_sword": 0.4782608695652174, "train_stats/max_log_achievement_place_plant": 2.121739130434783, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0608695652173914, "train_stats/max_log_achievement_wake_up": 2.0782608695652174, "train_stats/mean_log_entropy": 0.6314905367467715, "eval_stats/sum_log_reward": 5.037499912083149, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.25, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.139080875935178e-08, "report/cont_loss_std": 9.257229862669192e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2210846762172878e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.187434056111215e-08, "report/cont_pred": 0.9951172471046448, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.207518577575684, "report/dyn_loss_std": 8.99716567993164, "report/image_loss_mean": 8.161102294921875, "report/image_loss_std": 10.141379356384277, "report/model_loss_mean": 16.731075286865234, "report/model_loss_std": 13.850142478942871, "report/post_ent_mag": 52.71098709106445, "report/post_ent_max": 52.71098709106445, "report/post_ent_mean": 38.07651901245117, "report/post_ent_min": 21.476917266845703, "report/post_ent_std": 6.455448150634766, "report/prior_ent_mag": 66.08653259277344, "report/prior_ent_max": 66.08653259277344, "report/prior_ent_mean": 52.358856201171875, "report/prior_ent_min": 34.8862419128418, "report/prior_ent_std": 4.709174633026123, "report/rep_loss_mean": 14.207518577575684, "report/rep_loss_std": 8.99716567993164, "report/reward_avg": 0.01796874962747097, "report/reward_loss_mean": 0.045461706817150116, "report/reward_loss_std": 0.1915353238582611, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002007246017456, "report/reward_neg_acc": 0.9970000386238098, "report/reward_neg_loss": 0.02934304066002369, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7170729637145996, "report/reward_pred": 0.018293503671884537, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.66730741727406e-08, "eval/cont_loss_std": 7.399852961498254e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.74015438259812e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9207513801688947e-08, "eval/cont_pred": 0.9951171875, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.642900466918945, "eval/dyn_loss_std": 10.65799331665039, "eval/image_loss_mean": 16.861051559448242, "eval/image_loss_std": 23.128429412841797, "eval/model_loss_mean": 26.936992645263672, "eval/model_loss_std": 27.65794563293457, "eval/post_ent_mag": 57.749794006347656, "eval/post_ent_max": 57.749794006347656, "eval/post_ent_mean": 39.294151306152344, "eval/post_ent_min": 23.18743133544922, "eval/post_ent_std": 6.629721641540527, "eval/prior_ent_mag": 66.08653259277344, "eval/prior_ent_max": 66.08653259277344, "eval/prior_ent_mean": 53.3572883605957, "eval/prior_ent_min": 35.69074249267578, "eval/prior_ent_std": 5.758982181549072, "eval/rep_loss_mean": 16.642900466918945, "eval/rep_loss_std": 10.65799331665039, "eval/reward_avg": 0.01718749850988388, "eval/reward_loss_mean": 0.09020048379898071, "eval/reward_loss_std": 0.6248655915260315, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9998393058776855, "eval/reward_neg_acc": 0.9920159578323364, "eval/reward_neg_loss": 0.04432133957743645, "eval/reward_pos_acc": 0.7727273106575012, "eval/reward_pos_loss": 2.1797873973846436, "eval/reward_pred": 0.012772271409630775, "eval/reward_rate": 0.021484375, "replay/size": 283377.0, "replay/inserts": 20384.0, "replay/samples": 20384.0, "replay/insert_wait_avg": 1.3579589605705705e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.090722317598303e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 55096.0, "eval_replay/inserts": 3232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.088374912148655e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3046984672546, "timer/env.step_count": 2548.0, "timer/env.step_total": 251.63922023773193, "timer/env.step_frac": 0.25156256950838407, "timer/env.step_avg": 0.09875950558780688, "timer/env.step_min": 0.02307605743408203, "timer/env.step_max": 4.2632482051849365, "timer/replay._sample_count": 20384.0, "timer/replay._sample_total": 10.573601722717285, "timer/replay._sample_frac": 0.010570380943845398, "timer/replay._sample_avg": 0.0005187206496623472, "timer/replay._sample_min": 0.0003895759582519531, "timer/replay._sample_max": 0.010967493057250977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2952.0, "timer/agent.policy_total": 48.53572130203247, "timer/agent.policy_frac": 0.048520937046884524, "timer/agent.policy_avg": 0.016441640007463575, "timer/agent.policy_min": 0.009153366088867188, "timer/agent.policy_max": 0.09607672691345215, "timer/dataset_train_count": 1274.0, "timer/dataset_train_total": 0.1483011245727539, "timer/dataset_train_frac": 0.00014825595121165835, "timer/dataset_train_avg": 0.0001164059062580486, "timer/dataset_train_min": 0.00010538101196289062, "timer/dataset_train_max": 0.0004336833953857422, "timer/agent.train_count": 1274.0, "timer/agent.train_total": 566.6029915809631, "timer/agent.train_frac": 0.5664304011059397, "timer/agent.train_avg": 0.44474332149212176, "timer/agent.train_min": 0.4324989318847656, "timer/agent.train_max": 1.0717511177062988, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4703543186187744, "timer/agent.report_frac": 0.0004702110460337617, "timer/agent.report_avg": 0.2351771593093872, "timer/agent.report_min": 0.22830963134765625, "timer/agent.report_max": 0.24204468727111816, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026993634269093e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 20.37752548871339}
{"step": 283944, "time": 14301.391880273819, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 284112, "time": 14309.280069589615, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 284208, "time": 14314.371079683304, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 284296, "time": 14319.021943330765, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 284664, "time": 14334.119859457016, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 284792, "time": 14340.388750076294, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 284808, "time": 14342.451825857162, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 285256, "time": 14360.830052137375, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 285264, "time": 14363.276292800903, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 285440, "time": 14371.886232376099, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 285704, "time": 14383.70012664795, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 285720, "time": 14386.296907901764, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 286088, "time": 14402.019589185715, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 286160, "time": 14407.073293685913, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 286168, "time": 14409.244333028793, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 286864, "time": 14438.401607751846, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 286960, "time": 14443.541548252106, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 287208, "time": 14453.875594377518, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 287248, "time": 14457.082130670547, "episode/length": 225.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 287424, "time": 14465.086548805237, "episode/length": 166.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 287456, "time": 14467.937290668488, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 287496, "time": 14470.748250246048, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 288352, "time": 14503.643426895142, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 288392, "time": 14506.479794740677, "episode/length": 391.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 288528, "time": 14513.204347372055, "episode/length": 137.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 288608, "time": 14517.71611380577, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 288664, "time": 14521.08602643013, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 289192, "time": 14541.99570608139, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 289328, "time": 14548.648766040802, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 289592, "time": 14559.798124074936, "episode/length": 261.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 289704, "time": 14565.47706913948, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 289880, "time": 14573.45972442627, "episode/length": 151.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 290032, "time": 14580.734740972519, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 14598.924594640732, "eval_episode/length": 86.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9425287356321839}
{"step": 290056, "time": 14603.366823673248, "eval_episode/length": 162.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 290056, "time": 14605.019775152206, "eval_episode/length": 165.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 290056, "time": 14607.337331056595, "eval_episode/length": 182.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 290056, "time": 14609.111604690552, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 290056, "time": 14610.830910921097, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 290056, "time": 14612.342061281204, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 290056, "time": 14614.094719648361, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9653465346534653}
{"step": 290112, "time": 14616.43577837944, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 290672, "time": 14638.568598508835, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 290672, "time": 14638.614751577377, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 290904, "time": 14651.53395485878, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 291160, "time": 14663.285607099533, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 291240, "time": 14668.356280565262, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 291280, "time": 14672.12811255455, "episode/length": 145.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 291384, "time": 14677.794970750809, "episode/length": 59.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 291512, "time": 14684.465032815933, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 291848, "time": 14699.085597515106, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 292008, "time": 14707.169344186783, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 292456, "time": 14725.891017436981, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 292664, "time": 14735.981620311737, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 292752, "time": 14741.448610305786, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 292768, "time": 14744.15062379837, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 292888, "time": 14750.295668125153, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 293056, "time": 14758.76997590065, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 293080, "time": 14761.549176216125, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 293296, "time": 14771.918035268784, "episode/length": 180.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 293304, "time": 14773.93459057808, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 293824, "time": 14795.870062112808, "episode/length": 170.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 293944, "time": 14802.153584003448, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 294152, "time": 14812.007360696793, "episode/length": 40.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 294224, "time": 14816.367933273315, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 294232, "time": 14818.050023317337, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 294440, "time": 14827.300725460052, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 294448, "time": 14829.317317724228, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 294720, "time": 14840.84564948082, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 294912, "time": 14849.650394201279, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 295256, "time": 14865.213678836823, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 295336, "time": 14869.703423976898, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 295344, "time": 14871.818570137024, "episode/length": 148.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 295464, "time": 14877.482182502747, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 295888, "time": 14894.86015033722, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 296024, "time": 14901.201736688614, "episode/length": 196.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 296424, "time": 14917.389631986618, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 296568, "time": 14924.220419883728, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661654135338346, "episode/intrinsic_return": 0.0}
{"step": 296600, "time": 14926.933068275452, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 296640, "time": 14930.201138734818, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 296704, "time": 14934.111993074417, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 296880, "time": 14942.17689871788, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 297280, "time": 14958.270819187164, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 297496, "time": 14967.562846660614, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 297816, "time": 14980.85038304329, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 297824, "time": 14982.942022800446, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 297904, "time": 14987.434832572937, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 298032, "time": 14993.689284324646, "episode/length": 200.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 298080, "time": 14996.893632173538, "episode/length": 171.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 298320, "time": 15007.293303489685, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 298520, "time": 15015.812929868698, "episode/length": 154.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 298768, "time": 15026.568750619888, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 299280, "time": 15046.918789625168, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 299400, "time": 15052.732597589493, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 299576, "time": 15061.0511572361, "episode/length": 218.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 299600, "time": 15063.966077327728, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 15068.621401548386, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 299768, "time": 15073.166120052338, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 299896, "time": 15079.429800748825, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 300000, "time": 15085.14689040184, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 15104.107092142105, "eval_episode/length": 49.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.98}
{"step": 300040, "time": 15106.782316446304, "eval_episode/length": 79.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9375}
{"step": 300040, "time": 15111.357086658478, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 300040, "time": 15112.893788337708, "eval_episode/length": 159.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.99375}
{"step": 300040, "time": 15114.561447381973, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 300040, "time": 15116.220007896423, "eval_episode/length": 169.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 300040, "time": 15118.471502065659, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 300040, "time": 15120.607426404953, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 300776, "time": 15147.60276722908, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 300872, "time": 15152.747478485107, "episode/length": 158.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 300880, "time": 15154.764548063278, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 300992, "time": 15160.578799724579, "episode/length": 163.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 301080, "time": 15165.019536495209, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 301144, "time": 15168.891966104507, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 301376, "time": 15179.112689971924, "episode/length": 224.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 301384, "time": 15180.586499214172, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 301568, "time": 15189.099975347519, "episode/length": 86.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 301712, "time": 15195.894834518433, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 301976, "time": 15206.71489572525, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 302328, "time": 15221.192712068558, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 302568, "time": 15231.477521181107, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 302616, "time": 15234.792964458466, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 302624, "time": 15236.93816113472, "episode/length": 154.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 302680, "time": 15240.283862829208, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 302760, "time": 15244.804731369019, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 302784, "time": 15247.657754659653, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 302960, "time": 15255.62869644165, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 303136, "time": 15264.79081249237, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 304009, "time": 15299.336459159851, "train_stats/sum_log_reward": 5.099999939490642, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.053571428571429, "train_stats/max_log_achievement_collect_sapling": 2.017857142857143, "train_stats/max_log_achievement_collect_stone": 0.008928571428571428, "train_stats/max_log_achievement_collect_wood": 5.660714285714286, "train_stats/max_log_achievement_defeat_skeleton": 0.008928571428571428, "train_stats/max_log_achievement_defeat_zombie": 0.3125, "train_stats/max_log_achievement_eat_cow": 0.03571428571428571, "train_stats/max_log_achievement_make_wood_pickaxe": 0.026785714285714284, "train_stats/max_log_achievement_make_wood_sword": 0.6517857142857143, "train_stats/max_log_achievement_place_plant": 1.8928571428571428, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.8035714285714286, "train_stats/max_log_achievement_wake_up": 2.1875, "train_stats/mean_log_entropy": 0.6018048254773021, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.644135490296379, "train/action_min": 0.0, "train/action_std": 3.685776670773824, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05013115109787101, "train/actor_opt_grad_steps": 18275.0, "train/actor_opt_loss": 3.2185502612874624, "train/adv_mag": 0.7770947359857105, "train/adv_max": 0.7448455627475467, "train/adv_mean": 0.005458085282750997, "train/adv_min": -0.5341996042028306, "train/adv_std": 0.07884079699833242, "train/cont_avg": 0.9947064112103174, "train/cont_loss_mean": 0.0003572697372512658, "train/cont_loss_std": 0.009949496498238081, "train/cont_neg_acc": 0.982312927643458, "train/cont_neg_loss": 0.05433173738186356, "train/cont_pos_acc": 0.9999532491441757, "train/cont_pos_loss": 0.00012894046641386851, "train/cont_pred": 0.9947483478084443, "train/cont_rate": 0.9947064112103174, "train/dyn_loss_mean": 13.42845736609565, "train/dyn_loss_std": 9.06558602953714, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8945669096613688, "train/extr_critic_critic_opt_grad_steps": 18275.0, "train/extr_critic_critic_opt_loss": 15596.00341796875, "train/extr_critic_mag": 4.712976338371398, "train/extr_critic_max": 4.712976338371398, "train/extr_critic_mean": 0.9746069841914706, "train/extr_critic_min": -0.29853397229361156, "train/extr_critic_std": 1.0183478338377816, "train/extr_return_normed_mag": 1.820821277678959, "train/extr_return_normed_max": 1.820821277678959, "train/extr_return_normed_mean": 0.32039986290628947, "train/extr_return_normed_min": -0.21139408056698147, "train/extr_return_normed_std": 0.33183329788938404, "train/extr_return_rate": 0.5099805976663317, "train/extr_return_raw_mag": 5.776136947056604, "train/extr_return_raw_max": 5.776136947056604, "train/extr_return_raw_mean": 0.992005736581863, "train/extr_return_raw_min": -0.7036943835398507, "train/extr_return_raw_std": 1.0582260011680542, "train/extr_reward_mag": 1.0122779664539157, "train/extr_reward_max": 1.0122779664539157, "train/extr_reward_mean": 0.024340684093268856, "train/extr_reward_min": -0.46212854650285506, "train/extr_reward_std": 0.14399262896132847, "train/image_loss_mean": 8.058196696024092, "train/image_loss_std": 11.509413783512418, "train/model_loss_mean": 16.166713669186546, "train/model_loss_std": 15.326516340649317, "train/model_opt_grad_norm": 63.44690586853027, "train/model_opt_grad_steps": 18256.555555555555, "train/model_opt_loss": 15876.261180090525, "train/model_opt_model_opt_grad_overflow": 0.007936507936507936, "train/model_opt_model_opt_grad_scale": 972.2222222222222, "train/policy_entropy_mag": 2.5155015294514005, "train/policy_entropy_max": 2.5155015294514005, "train/policy_entropy_mean": 0.670459416414064, "train/policy_entropy_min": 0.0793752439674877, "train/policy_entropy_std": 0.6810023387273153, "train/policy_logprob_mag": 7.438382720190381, "train/policy_logprob_max": -0.009455728906369398, "train/policy_logprob_mean": -0.6711933189441287, "train/policy_logprob_min": -7.438382720190381, "train/policy_logprob_std": 1.167264535313561, "train/policy_randomness_mag": 0.887861649668406, "train/policy_randomness_max": 0.887861649668406, "train/policy_randomness_mean": 0.23664275225665835, "train/policy_randomness_min": 0.028015977540423, "train/policy_randomness_std": 0.2403639408331069, "train/post_ent_mag": 57.11815658448234, "train/post_ent_max": 57.11815658448234, "train/post_ent_mean": 39.03303582327707, "train/post_ent_min": 20.723197028750466, "train/post_ent_std": 6.946702419765412, "train/prior_ent_mag": 66.07350273737832, "train/prior_ent_max": 66.07350273737832, "train/prior_ent_mean": 52.57560478694855, "train/prior_ent_min": 33.422192195105175, "train/prior_ent_std": 5.325151329948788, "train/rep_loss_mean": 13.42845736609565, "train/rep_loss_std": 9.06558602953714, "train/reward_avg": 0.022016833735896007, "train/reward_loss_mean": 0.05108526054888018, "train/reward_loss_std": 0.25064591750029536, "train/reward_max_data": 1.007142858845847, "train/reward_max_pred": 1.00434677846848, "train/reward_neg_acc": 0.993443828253519, "train/reward_neg_loss": 0.02797310415744072, "train/reward_pos_acc": 0.9565474433558327, "train/reward_pos_loss": 0.9014347668678041, "train/reward_pred": 0.02122336551768794, "train/reward_rate": 0.026762462797619048, "eval_stats/sum_log_reward": 4.662499964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.4375, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 9.416404282092117e-06, "report/cont_loss_std": 0.00019731537031475455, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013463577488437295, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1425182694656542e-07, "report/cont_pred": 0.9931731224060059, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.902383804321289, "report/dyn_loss_std": 9.28826904296875, "report/image_loss_mean": 6.624619960784912, "report/image_loss_std": 10.00790786743164, "report/model_loss_mean": 14.417146682739258, "report/model_loss_std": 13.932933807373047, "report/post_ent_mag": 56.95188903808594, "report/post_ent_max": 56.95188903808594, "report/post_ent_mean": 39.876277923583984, "report/post_ent_min": 21.033390045166016, "report/post_ent_std": 7.249544143676758, "report/prior_ent_mag": 66.07940673828125, "report/prior_ent_max": 66.07940673828125, "report/prior_ent_mean": 52.902896881103516, "report/prior_ent_min": 33.469871520996094, "report/prior_ent_std": 4.949804306030273, "report/rep_loss_mean": 12.902383804321289, "report/rep_loss_std": 9.28826904296875, "report/reward_avg": 0.01611328125, "report/reward_loss_mean": 0.051086992025375366, "report/reward_loss_std": 0.22606436908245087, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.00620436668396, "report/reward_neg_acc": 0.9920000433921814, "report/reward_neg_loss": 0.031286031007766724, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.8761273622512817, "report/reward_pred": 0.01635696180164814, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 8.004192204680294e-05, "eval/cont_loss_std": 0.0017687854124233127, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004892227705568075, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.1679337047971785e-05, "eval/cont_pred": 0.9941190481185913, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.396270751953125, "eval/dyn_loss_std": 10.782947540283203, "eval/image_loss_mean": 15.24368667602539, "eval/image_loss_std": 20.354990005493164, "eval/model_loss_mean": 25.768207550048828, "eval/model_loss_std": 24.775392532348633, "eval/post_ent_mag": 55.49734878540039, "eval/post_ent_max": 55.49734878540039, "eval/post_ent_mean": 38.09523010253906, "eval/post_ent_min": 21.07219696044922, "eval/post_ent_std": 5.865938186645508, "eval/prior_ent_mag": 66.07940673828125, "eval/prior_ent_max": 66.07940673828125, "eval/prior_ent_mean": 52.94623947143555, "eval/prior_ent_min": 31.544309616088867, "eval/prior_ent_std": 5.678643703460693, "eval/rep_loss_mean": 17.396270751953125, "eval/rep_loss_std": 10.782947540283203, "eval/reward_avg": 0.02177734300494194, "eval/reward_loss_mean": 0.0866767019033432, "eval/reward_loss_std": 0.5307241082191467, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0003674030303955, "eval/reward_neg_acc": 0.9929719567298889, "eval/reward_neg_loss": 0.047624800354242325, "eval/reward_pos_acc": 0.8214285969734192, "eval/reward_pos_loss": 1.47580885887146, "eval/reward_pred": 0.01966813951730728, "eval/reward_rate": 0.02734375, "replay/size": 303505.0, "replay/inserts": 20128.0, "replay/samples": 20128.0, "replay/insert_wait_avg": 1.3804184613432528e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.137479116503499e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58296.0, "eval_replay/inserts": 3200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1124461889266968e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.054972410202, "timer/env.step_count": 2516.0, "timer/env.step_total": 257.38493371009827, "timer/env.step_frac": 0.25737078541770825, "timer/env.step_avg": 0.10229925823135862, "timer/env.step_min": 0.023096799850463867, "timer/env.step_max": 4.304086446762085, "timer/replay._sample_count": 20128.0, "timer/replay._sample_total": 10.498255252838135, "timer/replay._sample_frac": 0.010497678170167595, "timer/replay._sample_avg": 0.0005215746846600822, "timer/replay._sample_min": 0.0004019737243652344, "timer/replay._sample_max": 0.009095907211303711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2916.0, "timer/agent.policy_total": 49.36053800582886, "timer/agent.policy_frac": 0.04935782468724347, "timer/agent.policy_avg": 0.01692748216935146, "timer/agent.policy_min": 0.00927424430847168, "timer/agent.policy_max": 0.103240966796875, "timer/dataset_train_count": 1258.0, "timer/dataset_train_total": 0.14802289009094238, "timer/dataset_train_frac": 0.00014801475336320455, "timer/dataset_train_avg": 0.00011766525444431033, "timer/dataset_train_min": 0.00010442733764648438, "timer/dataset_train_max": 0.0010743141174316406, "timer/agent.train_count": 1258.0, "timer/agent.train_total": 561.1396067142487, "timer/agent.train_frac": 0.5611087612132593, "timer/agent.train_avg": 0.4460569210765093, "timer/agent.train_min": 0.43332338333129883, "timer/agent.train_max": 1.1282286643981934, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46541357040405273, "timer/agent.report_frac": 0.0004653879869047335, "timer/agent.report_avg": 0.23270678520202637, "timer/agent.report_min": 0.22185325622558594, "timer/agent.report_max": 0.2435603141784668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9800684172260695e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.12661284712267}
{"step": 304096, "time": 15302.728349685669, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 304256, "time": 15310.803821086884, "episode/length": 161.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 304288, "time": 15314.006549835205, "episode/length": 207.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 304368, "time": 15319.013101816177, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 304456, "time": 15323.515477895737, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 304480, "time": 15326.209047079086, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 304656, "time": 15334.187547206879, "episode/length": 260.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 304856, "time": 15342.936527490616, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 305336, "time": 15361.876857042313, "episode/length": 109.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 305584, "time": 15372.840005874634, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 305816, "time": 15382.654345989227, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 305864, "time": 15386.036504983902, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 305904, "time": 15389.227633476257, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 306488, "time": 15411.945773601532, "episode/length": 228.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 306616, "time": 15418.710922956467, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 306656, "time": 15422.4925968647, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 306936, "time": 15434.953034639359, "episode/length": 330.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 307216, "time": 15447.654179573059, "episode/length": 203.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 307472, "time": 15459.342243671417, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 307480, "time": 15460.904823303223, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 307568, "time": 15465.86734175682, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 307680, "time": 15472.096730709076, "episode/length": 132.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 307888, "time": 15481.955772399902, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 308480, "time": 15505.88449215889, "episode/length": 248.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 308488, "time": 15507.445466041565, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 308792, "time": 15520.273863554, "episode/length": 37.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 308848, "time": 15524.731867551804, "episode/length": 171.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 308904, "time": 15528.612991571426, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 308928, "time": 15531.697455406189, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 309064, "time": 15538.677695274353, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 309560, "time": 15559.231016159058, "episode/length": 208.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 309864, "time": 15571.83835864067, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 15579.406774997711, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 15593.593274116516, "eval_episode/length": 35.0, "eval_episode/score": 2.1000000312924385, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 310024, "time": 15599.668332338333, "eval_episode/length": 151.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 310024, "time": 15601.416748285294, "eval_episode/length": 156.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9872611464968153}
{"step": 310024, "time": 15604.241916894913, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 310024, "time": 15606.814429283142, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 310024, "time": 15609.12883734703, "eval_episode/length": 38.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.8974358974358975}
{"step": 310024, "time": 15611.028284072876, "eval_episode/length": 238.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 310024, "time": 15613.649768590927, "eval_episode/length": 262.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9809885931558935}
{"step": 310232, "time": 15622.800662994385, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 310328, "time": 15627.810053825378, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 310400, "time": 15632.34936952591, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 310520, "time": 15638.167396306992, "episode/length": 61.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 310616, "time": 15643.264418363571, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 310696, "time": 15647.811029434204, "episode/length": 401.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 310704, "time": 15649.88159275055, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 311392, "time": 15678.011412382126, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 311720, "time": 15691.30293917656, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 311752, "time": 15693.990311145782, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 311888, "time": 15700.838038921356, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 311904, "time": 15703.012315750122, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 312008, "time": 15708.174772262573, "episode/length": 35.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 312032, "time": 15710.821065664291, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 312088, "time": 15714.166066169739, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 312296, "time": 15723.29226064682, "episode/length": 48.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 312312, "time": 15725.500489473343, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 312608, "time": 15738.329804897308, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 313120, "time": 15759.619772195816, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 313168, "time": 15763.461119651794, "episode/length": 144.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 313432, "time": 15774.49827003479, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 313816, "time": 15790.026989221573, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 313832, "time": 15792.078866004944, "episode/length": 82.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 313848, "time": 15794.109503984451, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 314064, "time": 15803.795598745346, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 314208, "time": 15810.508975744247, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 314584, "time": 15825.643383979797, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 314704, "time": 15831.738485097885, "episode/length": 298.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 315184, "time": 15851.022060394287, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 315216, "time": 15853.794718503952, "episode/length": 261.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 315328, "time": 15859.350544214249, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 315400, "time": 15863.361481189728, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 315504, "time": 15868.97281551361, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 315560, "time": 15872.413772583008, "episode/length": 46.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 315704, "time": 15879.395267009735, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 315856, "time": 15886.701859474182, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 316424, "time": 15908.816930055618, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 316648, "time": 15918.64253783226, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 316808, "time": 15926.115822792053, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 316808, "time": 15926.166573047638, "episode/length": 155.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 316920, "time": 15933.676383018494, "episode/length": 176.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 317144, "time": 15943.452652692795, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 317176, "time": 15946.071467638016, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 317200, "time": 15948.766246318817, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 317416, "time": 15957.91629934311, "episode/length": 353.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9971751412429378, "episode/intrinsic_return": 0.0}
{"step": 318064, "time": 15983.285507440567, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 318128, "time": 15987.15123963356, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 318320, "time": 15995.75709271431, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 318408, "time": 16000.400925159454, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 318632, "time": 16010.138056516647, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 318720, "time": 16015.118052721024, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 318760, "time": 16017.9147772789, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 318848, "time": 16022.950256824493, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 319432, "time": 16045.355655670166, "episode/length": 162.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 319640, "time": 16055.905444383621, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 16090.449401378632, "eval_episode/length": 146.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 320008, "time": 16092.32925772667, "eval_episode/length": 154.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 320008, "time": 16094.048606872559, "eval_episode/length": 157.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 320008, "time": 16095.82628440857, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 320008, "time": 16097.392395734787, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 320008, "time": 16099.395119428635, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 320008, "time": 16101.681824207306, "eval_episode/length": 192.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 320008, "time": 16103.541509866714, "eval_episode/length": 40.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 320216, "time": 16111.224582910538, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 320240, "time": 16113.895015239716, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 320280, "time": 16116.910069942474, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 320424, "time": 16123.808329105377, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 320616, "time": 16132.523268699646, "episode/length": 318.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 320632, "time": 16134.627549886703, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 320664, "time": 16137.274526119232, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 321448, "time": 16167.510142803192, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 321488, "time": 16170.704407691956, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 321624, "time": 16177.241934537888, "episode/length": 167.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 321952, "time": 16191.104991436005, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 321984, "time": 16193.744212388992, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 321984, "time": 16193.790408372879, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 322264, "time": 16207.265875816345, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 322320, "time": 16211.153343439102, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 322856, "time": 16232.15682053566, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 322864, "time": 16234.225112199783, "episode/length": 171.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 323024, "time": 16241.770068645477, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 323176, "time": 16248.751988649368, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 323248, "time": 16253.302947044373, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 323320, "time": 16257.418135166168, "episode/length": 36.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 323384, "time": 16261.333637952805, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 323920, "time": 16282.917994976044, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 323992, "time": 16286.876772403717, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 324184, "time": 16295.61584854126, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 324192, "time": 16297.77326631546, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 324193, "time": 16300.018887043, "train_stats/sum_log_reward": 5.345613971091153, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.114035087719298, "train_stats/max_log_achievement_collect_sapling": 2.4649122807017543, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.964912280701754, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.39473684210526316, "train_stats/max_log_achievement_eat_cow": 0.08771929824561403, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008771929824561403, "train_stats/max_log_achievement_make_wood_sword": 1.0087719298245614, "train_stats/max_log_achievement_place_plant": 2.307017543859649, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.9473684210526316, "train_stats/max_log_achievement_wake_up": 2.2719298245614037, "train_stats/mean_log_entropy": 0.6206770795479155, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.802952842106895, "train/action_min": 0.0, "train/action_std": 3.6183033311177812, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047625358645168564, "train/actor_opt_grad_steps": 19535.0, "train/actor_opt_loss": -4.07326295714648, "train/adv_mag": 0.7453769445419312, "train/adv_max": 0.7153311856682338, "train/adv_mean": 0.004030384726738992, "train/adv_min": -0.5253775640139504, "train/adv_std": 0.07580187192393674, "train/cont_avg": 0.9944041418650794, "train/cont_loss_mean": 0.00028073765058174725, "train/cont_loss_std": 0.008347185655561173, "train/cont_neg_acc": 0.9869960953318884, "train/cont_neg_loss": 0.03865662032206721, "train/cont_pos_acc": 0.999968807848673, "train/cont_pos_loss": 9.028346338080075e-05, "train/cont_pred": 0.9944134406627171, "train/cont_rate": 0.9944041418650794, "train/dyn_loss_mean": 13.471032778422037, "train/dyn_loss_std": 9.081362694028824, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8852524454631503, "train/extr_critic_critic_opt_grad_steps": 19535.0, "train/extr_critic_critic_opt_loss": 15446.43734499008, "train/extr_critic_mag": 4.803636721202305, "train/extr_critic_max": 4.803636721202305, "train/extr_critic_mean": 0.9982616007328033, "train/extr_critic_min": -0.29755461783636183, "train/extr_critic_std": 1.06071984625998, "train/extr_return_normed_mag": 1.8389858376412165, "train/extr_return_normed_max": 1.8389858376412165, "train/extr_return_normed_mean": 0.3138106555219681, "train/extr_return_normed_min": -0.19771915011935765, "train/extr_return_normed_std": 0.33326284611035906, "train/extr_return_rate": 0.5235248513164974, "train/extr_return_raw_mag": 6.0396539180997815, "train/extr_return_raw_max": 6.0396539180997815, "train/extr_return_raw_mean": 1.011555491458802, "train/extr_return_raw_min": -0.6751456367118018, "train/extr_return_raw_std": 1.0988871776868427, "train/extr_reward_mag": 1.01167693213811, "train/extr_reward_max": 1.01167693213811, "train/extr_reward_mean": 0.023945369506402622, "train/extr_reward_min": -0.4720933569802178, "train/extr_reward_std": 0.1438187477252786, "train/image_loss_mean": 8.073048724068535, "train/image_loss_std": 11.727220251446678, "train/model_loss_mean": 16.207015310015, "train/model_loss_std": 15.508241479358976, "train/model_opt_grad_norm": 65.63529083251953, "train/model_opt_grad_steps": 19515.507936507936, "train/model_opt_loss": 12756.186957465277, "train/model_opt_model_opt_grad_overflow": 0.007936507936507936, "train/model_opt_model_opt_grad_scale": 796.1309523809524, "train/policy_entropy_mag": 2.516292579590328, "train/policy_entropy_max": 2.516292579590328, "train/policy_entropy_mean": 0.6862712388946897, "train/policy_entropy_min": 0.079375226819326, "train/policy_entropy_std": 0.7064489504647633, "train/policy_logprob_mag": 7.4383829434712725, "train/policy_logprob_max": -0.009455696990092596, "train/policy_logprob_mean": -0.6861218729662517, "train/policy_logprob_min": -7.4383829434712725, "train/policy_logprob_std": 1.1727251259107438, "train/policy_randomness_mag": 0.8881408562735905, "train/policy_randomness_max": 0.8881408562735905, "train/policy_randomness_mean": 0.24222363200452593, "train/policy_randomness_min": 0.02801597143508612, "train/policy_randomness_std": 0.24934547725651, "train/post_ent_mag": 57.193921740092925, "train/post_ent_max": 57.193921740092925, "train/post_ent_mean": 39.38910148257301, "train/post_ent_min": 20.693958547380234, "train/post_ent_std": 7.054019341393123, "train/prior_ent_mag": 66.13763815259176, "train/prior_ent_max": 66.13763815259176, "train/prior_ent_mean": 52.891886635432165, "train/prior_ent_min": 33.9724324392894, "train/prior_ent_std": 5.229136474548825, "train/rep_loss_mean": 13.471032778422037, "train/rep_loss_std": 9.081362694028824, "train/reward_avg": 0.021482824806183104, "train/reward_loss_mean": 0.05106618349987363, "train/reward_loss_std": 0.24499412661507017, "train/reward_max_data": 1.0119047647430783, "train/reward_max_pred": 1.0048336065004742, "train/reward_neg_acc": 0.9936693036367023, "train/reward_neg_loss": 0.028181465054374365, "train/reward_pos_acc": 0.9580060035463364, "train/reward_pos_loss": 0.8908747959704626, "train/reward_pred": 0.020671720956526106, "train/reward_rate": 0.026483444940476192, "eval_stats/sum_log_reward": 5.349999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.6875, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.7949162106087897e-06, "report/cont_loss_std": 2.7081598091172054e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015241015353240073, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.918991413025651e-06, "report/cont_pred": 0.9941385984420776, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.511285781860352, "report/dyn_loss_std": 9.02987003326416, "report/image_loss_mean": 6.052382469177246, "report/image_loss_std": 14.833038330078125, "report/model_loss_mean": 13.000879287719727, "report/model_loss_std": 18.194677352905273, "report/post_ent_mag": 57.16484832763672, "report/post_ent_max": 57.16484832763672, "report/post_ent_mean": 39.764427185058594, "report/post_ent_min": 19.904895782470703, "report/post_ent_std": 6.699294567108154, "report/prior_ent_mag": 65.75527954101562, "report/prior_ent_max": 65.75527954101562, "report/prior_ent_mean": 51.91914367675781, "report/prior_ent_min": 33.96729278564453, "report/prior_ent_std": 5.904576778411865, "report/rep_loss_mean": 11.511285781860352, "report/rep_loss_std": 9.02987003326416, "report/reward_avg": 0.01425781287252903, "report/reward_loss_mean": 0.041721098124980927, "report/reward_loss_std": 0.16861514747142792, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.004389762878418, "report/reward_neg_acc": 0.9970119595527649, "report/reward_neg_loss": 0.02737794630229473, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7617475390434265, "report/reward_pred": 0.013942348770797253, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0016815729904919863, "eval/cont_loss_std": 0.05238480493426323, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00017011324234772474, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.0016919763293117285, "eval/cont_pred": 0.9923290014266968, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 17.127166748046875, "eval/dyn_loss_std": 10.816397666931152, "eval/image_loss_mean": 16.88552474975586, "eval/image_loss_std": 21.90174102783203, "eval/model_loss_mean": 27.27576446533203, "eval/model_loss_std": 26.487455368041992, "eval/post_ent_mag": 57.28358459472656, "eval/post_ent_max": 57.28358459472656, "eval/post_ent_mean": 37.83113098144531, "eval/post_ent_min": 21.567224502563477, "eval/post_ent_std": 6.582987308502197, "eval/prior_ent_mag": 65.75527954101562, "eval/prior_ent_max": 65.75527954101562, "eval/prior_ent_mean": 52.88636779785156, "eval/prior_ent_min": 30.890094757080078, "eval/prior_ent_std": 5.045515537261963, "eval/rep_loss_mean": 17.127166748046875, "eval/rep_loss_std": 10.816397666931152, "eval/reward_avg": 0.02900390513241291, "eval/reward_loss_mean": 0.11225993186235428, "eval/reward_loss_std": 0.6938732266426086, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0062553882598877, "eval/reward_neg_acc": 0.9969635605812073, "eval/reward_neg_loss": 0.04503636062145233, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 1.9571737051010132, "eval/reward_pred": 0.020801682025194168, "eval/reward_rate": 0.03515625, "replay/size": 323689.0, "replay/inserts": 20184.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.3881645361393441e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.01117622502544e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61992.0, "eval_replay/inserts": 3696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1122974998507148e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.6710071563721, "timer/env.step_count": 2523.0, "timer/env.step_total": 253.75506353378296, "timer/env.step_frac": 0.2535849062469433, "timer/env.step_avg": 0.10057671959325523, "timer/env.step_min": 0.023036718368530273, "timer/env.step_max": 3.4334661960601807, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 10.518315553665161, "timer/replay._sample_frac": 0.010511262421357925, "timer/replay._sample_avg": 0.0005213280904869727, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.01158285140991211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2985.0, "timer/agent.policy_total": 49.38908553123474, "timer/agent.policy_frac": 0.04935596732395071, "timer/agent.policy_avg": 0.01654575729689606, "timer/agent.policy_min": 0.009387493133544922, "timer/agent.policy_max": 0.11413931846618652, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.14803290367126465, "timer/dataset_train_frac": 0.00014793363914073306, "timer/dataset_train_avg": 0.00011739326222939306, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0005781650543212891, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 562.5491931438446, "timer/agent.train_frac": 0.5621719717277035, "timer/agent.train_avg": 0.44611355522905993, "timer/agent.train_min": 0.42934370040893555, "timer/agent.train_max": 1.5069384574890137, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47786808013916016, "timer/agent.report_frac": 0.0004775476422536993, "timer/agent.report_avg": 0.23893404006958008, "timer/agent.report_min": 0.2317962646484375, "timer/agent.report_max": 0.24607181549072266, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002059693141733e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 20.170190388903592}
{"step": 324240, "time": 16301.996524095535, "episode/length": 39.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 324448, "time": 16311.207969665527, "episode/length": 149.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 324808, "time": 16325.820194244385, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 325072, "time": 16337.180440425873, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 325184, "time": 16342.863481283188, "episode/length": 148.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 325240, "time": 16346.237129688263, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 325432, "time": 16354.82055401802, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 325600, "time": 16362.881735086441, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 325680, "time": 16367.38373541832, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 326224, "time": 16389.06051015854, "episode/length": 98.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 326240, "time": 16391.108267068863, "episode/length": 124.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 326376, "time": 16397.456117391586, "episode/length": 148.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 326624, "time": 16408.2447783947, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 326728, "time": 16413.23891043663, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 327032, "time": 16425.8492705822, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 327160, "time": 16432.101136684418, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 327800, "time": 16458.46701478958, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 327960, "time": 16465.720584869385, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 328040, "time": 16470.27463078499, "episode/length": 304.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 328088, "time": 16473.65710759163, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 328120, "time": 16476.467571020126, "episode/length": 39.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 328136, "time": 16478.575608968735, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 328256, "time": 16484.73875117302, "episode/length": 152.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 328304, "time": 16488.155195474625, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 328768, "time": 16506.514948129654, "episode/length": 80.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 329080, "time": 16519.179803609848, "episode/length": 239.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 329528, "time": 16537.111624479294, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 329544, "time": 16539.24748659134, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 329648, "time": 16544.748728990555, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 329776, "time": 16551.02294945717, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 329888, "time": 16556.660420656204, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 16584.233175992966, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 330096, "time": 16586.056250810623, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 330096, "time": 16588.42382669449, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 330096, "time": 16590.509622573853, "eval_episode/length": 189.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 330096, "time": 16592.70101237297, "eval_episode/length": 205.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9611650485436893}
{"step": 330096, "time": 16594.58680176735, "eval_episode/length": 215.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 330096, "time": 16596.524475097656, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 330096, "time": 16598.26207780838, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 330336, "time": 16606.975722551346, "episode/length": 156.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 330736, "time": 16623.04908490181, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 330744, "time": 16624.628511428833, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 330816, "time": 16629.194127559662, "episode/length": 255.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 331136, "time": 16642.31712269783, "episode/length": 155.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 331224, "time": 16646.883118391037, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 331328, "time": 16652.49804663658, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 331784, "time": 16670.45018839836, "episode/length": 180.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 331968, "time": 16678.867386341095, "episode/length": 152.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 332184, "time": 16688.1439807415, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 332392, "time": 16697.34363102913, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 332576, "time": 16706.019000053406, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 332696, "time": 16712.31043100357, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 332728, "time": 16715.599406003952, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 333104, "time": 16731.966036081314, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 333288, "time": 16740.5764400959, "episode/length": 187.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 333344, "time": 16744.855137825012, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 333400, "time": 16748.8708922863, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 333632, "time": 16758.9484231472, "episode/length": 35.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 333736, "time": 16764.061237812042, "episode/length": 144.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 333792, "time": 16767.85427880287, "episode/length": 48.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 333944, "time": 16774.663903713226, "episode/length": 81.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 334048, "time": 16780.401814222336, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 334176, "time": 16786.510940790176, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 334352, "time": 16794.418119430542, "episode/length": 37.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 334440, "time": 16798.91972541809, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 335104, "time": 16824.804249048233, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 335104, "time": 16824.855273246765, "episode/length": 249.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 335184, "time": 16831.16573190689, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 335200, "time": 16833.30413532257, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 335256, "time": 16836.76547241211, "episode/length": 101.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 335512, "time": 16847.686175107956, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 335960, "time": 16867.109008073807, "episode/length": 106.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 336000, "time": 16870.391340970993, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 336088, "time": 16874.928827762604, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 336520, "time": 16892.127665758133, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9548022598870056, "episode/intrinsic_return": 0.0}
{"step": 336824, "time": 16904.937408924103, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 336992, "time": 16912.795840978622, "episode/length": 225.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 337056, "time": 16916.686926841736, "episode/length": 224.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 337480, "time": 16933.689961194992, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 337520, "time": 16936.9550344944, "episode/length": 289.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 338144, "time": 16961.423602819443, "episode/length": 256.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 338216, "time": 16965.36447238922, "episode/length": 152.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 338304, "time": 16970.391508102417, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 338512, "time": 16979.61225748062, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 338776, "time": 16991.336945295334, "episode/length": 346.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 338928, "time": 16999.263867378235, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 339320, "time": 17015.89866256714, "episode/length": 67.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 339432, "time": 17022.077499628067, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 339432, "time": 17022.130462884903, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 339608, "time": 17032.997729063034, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 339984, "time": 17049.20986890793, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 17071.803525447845, "eval_episode/length": 125.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9603174603174603}
{"step": 340080, "time": 17074.42006969452, "eval_episode/length": 149.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 340080, "time": 17077.722535848618, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 340080, "time": 17079.70508122444, "eval_episode/length": 166.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 340080, "time": 17082.095067977905, "eval_episode/length": 188.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 340080, "time": 17083.758549690247, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 340080, "time": 17086.751774549484, "eval_episode/length": 40.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 340080, "time": 17088.93227815628, "eval_episode/length": 242.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 340400, "time": 17100.534264564514, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 340488, "time": 17105.058012008667, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 340768, "time": 17117.033037662506, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 340776, "time": 17118.613702774048, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 340904, "time": 17124.83671951294, "episode/length": 183.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 341152, "time": 17135.58464050293, "episode/length": 453.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9977973568281938, "episode/intrinsic_return": 0.0}
{"step": 341264, "time": 17141.256942033768, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 341328, "time": 17145.115411043167, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 341848, "time": 17165.424322128296, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 341888, "time": 17168.616215229034, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 341936, "time": 17171.842519283295, "episode/length": 145.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 342152, "time": 17181.10160303116, "episode/length": 171.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 342448, "time": 17193.58616232872, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 342712, "time": 17204.575454711914, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 342776, "time": 17208.53836965561, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 343016, "time": 17218.86744785309, "episode/length": 210.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 343144, "time": 17225.003647089005, "episode/length": 53.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 343232, "time": 17230.134482383728, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 343312, "time": 17234.613305807114, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 343432, "time": 17240.283262252808, "episode/length": 159.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 344016, "time": 17263.44937324524, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 344136, "time": 17270.59700345993, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 344176, "time": 17273.8116543293, "episode/length": 290.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 344304, "time": 17279.92696738243, "episode/length": 301.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 344432, "time": 17286.107002735138, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 344584, "time": 17292.848805189133, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 344713, "time": 17300.08559036255, "train_stats/sum_log_reward": 5.485321068982466, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.275229357798165, "train_stats/max_log_achievement_collect_sapling": 2.458715596330275, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.926605504587156, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.44954128440366975, "train_stats/max_log_achievement_eat_cow": 0.13761467889908258, "train_stats/max_log_achievement_make_wood_pickaxe": 0.027522935779816515, "train_stats/max_log_achievement_make_wood_sword": 0.908256880733945, "train_stats/max_log_achievement_place_plant": 2.330275229357798, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.981651376146789, "train_stats/max_log_achievement_wake_up": 2.4954128440366974, "train_stats/mean_log_entropy": 0.615748758436343, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.58287239074707, "train/action_min": 0.0, "train/action_std": 3.5744397789239883, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048677149548893794, "train/actor_opt_grad_steps": 20805.0, "train/actor_opt_loss": 1.9411631170660257, "train/adv_mag": 0.738842599093914, "train/adv_max": 0.7197574251331389, "train/adv_mean": 0.004663070835590588, "train/adv_min": -0.5257892091758549, "train/adv_std": 0.07530496784602292, "train/cont_avg": 0.9946060180664062, "train/cont_loss_mean": 0.00020899922780470703, "train/cont_loss_std": 0.00603685813978716, "train/cont_neg_acc": 0.991629465483129, "train/cont_neg_loss": 0.02955625992769484, "train/cont_pos_acc": 0.9999615289270878, "train/cont_pos_loss": 7.84031544858177e-05, "train/cont_pred": 0.9946079682558775, "train/cont_rate": 0.9946060180664062, "train/dyn_loss_mean": 13.231530524790287, "train/dyn_loss_std": 9.082961209118366, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8395657236687839, "train/extr_critic_critic_opt_grad_steps": 20805.0, "train/extr_critic_critic_opt_loss": 15517.077209472656, "train/extr_critic_mag": 4.912262629717588, "train/extr_critic_max": 4.912262629717588, "train/extr_critic_mean": 1.0410789167508483, "train/extr_critic_min": -0.2784412261098623, "train/extr_critic_std": 1.0727364178746939, "train/extr_return_normed_mag": 1.8171717878431082, "train/extr_return_normed_max": 1.8171717878431082, "train/extr_return_normed_mean": 0.3084435457130894, "train/extr_return_normed_min": -0.2089500540168956, "train/extr_return_normed_std": 0.3312110072001815, "train/extr_return_rate": 0.5383982616476715, "train/extr_return_raw_mag": 6.127861384302378, "train/extr_return_raw_max": 6.127861384302378, "train/extr_return_raw_mean": 1.056731274817139, "train/extr_return_raw_min": -0.6823716963408515, "train/extr_return_raw_std": 1.1135925194248557, "train/extr_reward_mag": 1.0179725289344788, "train/extr_reward_max": 1.0179725289344788, "train/extr_reward_mean": 0.02523613213270437, "train/extr_reward_min": -0.5005694022402167, "train/extr_reward_std": 0.1465998685453087, "train/image_loss_mean": 7.652292028069496, "train/image_loss_std": 11.184871312230825, "train/model_loss_mean": 15.641876623034477, "train/model_loss_std": 15.00114381313324, "train/model_opt_grad_norm": 56.87464426457882, "train/model_opt_grad_steps": 20784.0, "train/model_opt_loss": 7113.732398986816, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 454.1015625, "train/policy_entropy_mag": 2.5332195088267326, "train/policy_entropy_max": 2.5332195088267326, "train/policy_entropy_mean": 0.6743015325628221, "train/policy_entropy_min": 0.07937522605061531, "train/policy_entropy_std": 0.6859139865264297, "train/policy_logprob_mag": 7.438382960855961, "train/policy_logprob_max": -0.009455709310714155, "train/policy_logprob_mean": -0.6741749534849077, "train/policy_logprob_min": -7.438382960855961, "train/policy_logprob_std": 1.167826277203858, "train/policy_randomness_mag": 0.8941153194755316, "train/policy_randomness_max": 0.8941153194755316, "train/policy_randomness_mean": 0.23799884761683643, "train/policy_randomness_min": 0.028015971067361534, "train/policy_randomness_std": 0.24209753621835262, "train/post_ent_mag": 57.661198765039444, "train/post_ent_max": 57.661198765039444, "train/post_ent_mean": 39.62073028087616, "train/post_ent_min": 20.7527594268322, "train/post_ent_std": 7.074331637471914, "train/prior_ent_mag": 66.28491187095642, "train/prior_ent_max": 66.28491187095642, "train/prior_ent_mean": 52.9667526781559, "train/prior_ent_min": 34.7513719946146, "train/prior_ent_std": 5.137458480894566, "train/rep_loss_mean": 13.231530524790287, "train/rep_loss_std": 9.082961209118366, "train/reward_avg": 0.02219848603272112, "train/reward_loss_mean": 0.05045730827259831, "train/reward_loss_std": 0.2389603944029659, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.0061851730570197, "train/reward_neg_acc": 0.9934206334874034, "train/reward_neg_loss": 0.0274300761448103, "train/reward_pos_acc": 0.9590130657888949, "train/reward_pos_loss": 0.8777010887861252, "train/reward_pred": 0.02137169901834568, "train/reward_rate": 0.0272216796875, "eval_stats/sum_log_reward": 5.3499999567866325, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.6875, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.6875, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.6587817981417174e-06, "report/cont_loss_std": 1.5121971955522895e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010866836964851245, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.222358130500652e-07, "report/cont_pred": 0.9931638836860657, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.564577102661133, "report/dyn_loss_std": 9.425057411193848, "report/image_loss_mean": 7.729652404785156, "report/image_loss_std": 9.685171127319336, "report/model_loss_mean": 15.909411430358887, "report/model_loss_std": 13.763649940490723, "report/post_ent_mag": 57.26615905761719, "report/post_ent_max": 57.26615905761719, "report/post_ent_mean": 39.288394927978516, "report/post_ent_min": 18.9451904296875, "report/post_ent_std": 7.420501232147217, "report/prior_ent_mag": 66.92288208007812, "report/prior_ent_max": 66.92288208007812, "report/prior_ent_mean": 52.95853042602539, "report/prior_ent_min": 31.540985107421875, "report/prior_ent_std": 5.690782070159912, "report/rep_loss_mean": 13.564577102661133, "report/rep_loss_std": 9.425057411193848, "report/reward_avg": 0.02236328087747097, "report/reward_loss_mean": 0.04101160913705826, "report/reward_loss_std": 0.16854409873485565, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022494792938232, "report/reward_neg_acc": 0.9939759969711304, "report/reward_neg_loss": 0.022575344890356064, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6968160271644592, "report/reward_pred": 0.023478955030441284, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.3863118258304894e-05, "eval/cont_loss_std": 0.0006842113216407597, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001584057608852163, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3070138922776096e-05, "eval/cont_pred": 0.9941189289093018, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.669851303100586, "eval/dyn_loss_std": 10.857525825500488, "eval/image_loss_mean": 17.668025970458984, "eval/image_loss_std": 26.748640060424805, "eval/model_loss_mean": 28.393123626708984, "eval/model_loss_std": 31.33489418029785, "eval/post_ent_mag": 60.005645751953125, "eval/post_ent_max": 60.005645751953125, "eval/post_ent_mean": 38.68352127075195, "eval/post_ent_min": 21.5198917388916, "eval/post_ent_std": 6.975714683532715, "eval/prior_ent_mag": 66.92288208007812, "eval/prior_ent_max": 66.92288208007812, "eval/prior_ent_mean": 53.50446319580078, "eval/prior_ent_min": 38.8926887512207, "eval/prior_ent_std": 4.932926177978516, "eval/rep_loss_mean": 17.669851303100586, "eval/rep_loss_std": 10.857525825500488, "eval/reward_avg": 0.03818359225988388, "eval/reward_loss_mean": 0.12316203862428665, "eval/reward_loss_std": 0.7506678700447083, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023269653320312, "eval/reward_neg_acc": 0.9898062944412231, "eval/reward_neg_loss": 0.030301135033369064, "eval/reward_pos_acc": 0.7441860437393188, "eval/reward_pos_loss": 2.2416863441467285, "eval/reward_pred": 0.029423678293824196, "eval/reward_rate": 0.0419921875, "replay/size": 344209.0, "replay/inserts": 20520.0, "replay/samples": 20528.0, "replay/insert_wait_avg": 1.3759958813762108e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.945117965305771e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65776.0, "eval_replay/inserts": 3784.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0853589967239734e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0517227649689, "timer/env.step_count": 2565.0, "timer/env.step_total": 243.11540293693542, "timer/env.step_frac": 0.2431028289864485, "timer/env.step_avg": 0.09478183350367853, "timer/env.step_min": 0.02356433868408203, "timer/env.step_max": 4.289893865585327, "timer/replay._sample_count": 20528.0, "timer/replay._sample_total": 10.604742765426636, "timer/replay._sample_frac": 0.010604194287177836, "timer/replay._sample_avg": 0.000516598926608858, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.011444807052612305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3038.0, "timer/agent.policy_total": 49.67456936836243, "timer/agent.policy_frac": 0.0496720001951708, "timer/agent.policy_avg": 0.01635107615811798, "timer/agent.policy_min": 0.009255170822143555, "timer/agent.policy_max": 0.10965633392333984, "timer/dataset_train_count": 1283.0, "timer/dataset_train_total": 0.148787260055542, "timer/dataset_train_frac": 0.00014877956476508147, "timer/dataset_train_avg": 0.00011596824634103039, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0004582405090332031, "timer/agent.train_count": 1283.0, "timer/agent.train_total": 569.927408695221, "timer/agent.train_frac": 0.569897931998428, "timer/agent.train_avg": 0.44421465993392123, "timer/agent.train_min": 0.43166613578796387, "timer/agent.train_max": 1.17332124710083, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46597814559936523, "timer/agent.report_frac": 0.00046595404516780074, "timer/agent.report_avg": 0.23298907279968262, "timer/agent.report_min": 0.2224712371826172, "timer/agent.report_max": 0.24350690841674805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5033950805664062e-05, "timer/dataset_eval_frac": 2.5032656047478774e-08, "timer/dataset_eval_avg": 2.5033950805664062e-05, "timer/dataset_eval_min": 2.5033950805664062e-05, "timer/dataset_eval_max": 2.5033950805664062e-05, "fps": 20.518675721636647}
{"step": 344760, "time": 17301.62702870369, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 345016, "time": 17312.40950870514, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 345216, "time": 17321.52591276169, "episode/length": 149.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 345416, "time": 17330.10205769539, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 345488, "time": 17334.469130277634, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 346008, "time": 17354.618184804916, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 346296, "time": 17366.824081659317, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 346296, "time": 17366.86845946312, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 346608, "time": 17383.086986780167, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 346840, "time": 17393.577779769897, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 347112, "time": 17405.92729640007, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 347176, "time": 17410.387387037277, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 347376, "time": 17419.95795083046, "episode/length": 367.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 347464, "time": 17424.960731506348, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 347640, "time": 17433.575865745544, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 348088, "time": 17452.488542079926, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 348120, "time": 17455.71867775917, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 348360, "time": 17466.751950740814, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 348560, "time": 17476.422850370407, "episode/length": 147.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 348720, "time": 17483.645992279053, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 348736, "time": 17485.665081739426, "episode/length": 194.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 348912, "time": 17493.522778511047, "episode/length": 43.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 349080, "time": 17501.119106292725, "episode/length": 42.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 349184, "time": 17507.14145755768, "episode/length": 192.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 349496, "time": 17520.619293689728, "episode/length": 38.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 349680, "time": 17529.547199964523, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 349744, "time": 17533.35118818283, "episode/length": 82.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 349784, "time": 17535.97067308426, "episode/length": 207.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 349800, "time": 17538.108960866928, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 350024, "time": 17547.82419848442, "episode/length": 319.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 17566.32316660881, "eval_episode/length": 50.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 350064, "time": 17569.265572071075, "eval_episode/length": 36.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.972972972972973}
{"step": 350064, "time": 17573.51074743271, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 350064, "time": 17575.57192325592, "eval_episode/length": 169.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 350064, "time": 17577.882669448853, "eval_episode/length": 187.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 350064, "time": 17579.836144685745, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 350064, "time": 17581.78088068962, "eval_episode/length": 209.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 350064, "time": 17583.571439027786, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 350312, "time": 17592.423490047455, "episode/length": 198.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 350664, "time": 17606.786192417145, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 350872, "time": 17615.926331996918, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 351200, "time": 17629.692268371582, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 351248, "time": 17632.977073907852, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 351408, "time": 17640.310703992844, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 351416, "time": 17641.962185144424, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 351872, "time": 17660.415758132935, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 351952, "time": 17664.835663080215, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 352024, "time": 17668.867609977722, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 352096, "time": 17673.30170750618, "episode/length": 152.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 352568, "time": 17693.220860481262, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 352696, "time": 17699.400096178055, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 352768, "time": 17703.812081575394, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 352768, "time": 17703.85405063629, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 353424, "time": 17731.110881090164, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 353496, "time": 17735.075227737427, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 353576, "time": 17739.71182370186, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 353808, "time": 17749.91954445839, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 353960, "time": 17756.831674337387, "episode/length": 148.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 354024, "time": 17760.693350315094, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 354152, "time": 17767.047749996185, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 354160, "time": 17769.277450561523, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 354712, "time": 17790.57841038704, "episode/length": 160.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 354832, "time": 17796.82889008522, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 354888, "time": 17800.128071546555, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 355288, "time": 17816.257957935333, "episode/length": 141.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 355304, "time": 17818.45354628563, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 355696, "time": 17834.612896203995, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 355936, "time": 17844.91205072403, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 356240, "time": 17857.68952035904, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 356264, "time": 17859.801871538162, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 356352, "time": 17864.840790987015, "episode/length": 317.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 356480, "time": 17871.075397968292, "episode/length": 205.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 356544, "time": 17874.9697804451, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 356944, "time": 17891.094573497772, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 357128, "time": 17899.06045269966, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 357304, "time": 17906.991741895676, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 357864, "time": 17928.999051332474, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 357864, "time": 17929.04954481125, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 357944, "time": 17935.29599261284, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 357968, "time": 17938.05637907982, "episode/length": 212.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 358280, "time": 17950.85987186432, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 358312, "time": 17953.484585523605, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 358792, "time": 17972.42026090622, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 358912, "time": 17978.71897149086, "episode/length": 222.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 358992, "time": 17983.13237309456, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 359024, "time": 17985.87574696541, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 359112, "time": 17990.38405585289, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 359152, "time": 17993.67826128006, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 359552, "time": 18010.083181142807, "episode/length": 54.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 359776, "time": 18020.534212589264, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 359848, "time": 18024.987068653107, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 18056.24570417404, "eval_episode/length": 137.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 360048, "time": 18058.195916891098, "eval_episode/length": 144.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.993103448275862}
{"step": 360048, "time": 18061.671333789825, "eval_episode/length": 191.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 360048, "time": 18063.2014067173, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 360048, "time": 18065.21562051773, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 360048, "time": 18067.087368011475, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 360048, "time": 18069.02245402336, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 360048, "time": 18072.526077508926, "eval_episode/length": 270.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.996309963099631}
{"step": 360392, "time": 18084.791565179825, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 360432, "time": 18087.97720527649, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 360496, "time": 18093.299583673477, "episode/length": 89.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 360632, "time": 18099.666382312775, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 360728, "time": 18104.725521087646, "episode/length": 212.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 361312, "time": 18127.839110851288, "episode/length": 299.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 361392, "time": 18132.37392783165, "episode/length": 192.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 361544, "time": 18139.10759782791, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 361856, "time": 18152.206949472427, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 361880, "time": 18154.432124853134, "episode/length": 180.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 362544, "time": 18180.44269990921, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 362552, "time": 18181.952810525894, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 362776, "time": 18191.703270196915, "episode/length": 255.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 362888, "time": 18197.35849404335, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 362896, "time": 18199.34484052658, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 363544, "time": 18224.307533979416, "episode/length": 393.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 363808, "time": 18235.682844877243, "episode/length": 32.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 363888, "time": 18240.095911741257, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 364064, "time": 18248.13575363159, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 364208, "time": 18255.0049366951, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 364408, "time": 18264.406336069107, "episode/length": 231.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 364472, "time": 18268.93047761917, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 364512, "time": 18272.545622110367, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 364768, "time": 18283.94905614853, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 365080, "time": 18296.705018281937, "episode/length": 70.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9436619718309859, "episode/intrinsic_return": 0.0}
{"step": 365113, "time": 18300.41509437561, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.7861127853393555, "train/action_min": 0.0, "train/action_std": 3.780516730621457, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048110686941072345, "train/actor_opt_grad_steps": 22085.0, "train/actor_opt_loss": -5.430775758693926, "train/adv_mag": 0.7386938128620386, "train/adv_max": 0.7087978709023446, "train/adv_mean": 0.003435237735487817, "train/adv_min": -0.534528441959992, "train/adv_std": 0.07567685138201341, "train/cont_avg": 0.9943161010742188, "train/cont_loss_mean": 0.0002633849803115318, "train/cont_loss_std": 0.006969379591426517, "train/cont_neg_acc": 0.9914620551280677, "train/cont_neg_loss": 0.021358997422069592, "train/cont_pos_acc": 0.999969341326505, "train/cont_pos_loss": 0.00012052459305078589, "train/cont_pred": 0.9943170719780028, "train/cont_rate": 0.9943161010742188, "train/dyn_loss_mean": 13.234109163284302, "train/dyn_loss_std": 9.117591463029385, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7969075471628457, "train/extr_critic_critic_opt_grad_steps": 22085.0, "train/extr_critic_critic_opt_loss": 15507.28630065918, "train/extr_critic_mag": 4.996330413967371, "train/extr_critic_max": 4.996330413967371, "train/extr_critic_mean": 1.073963908944279, "train/extr_critic_min": -0.26610691100358963, "train/extr_critic_std": 1.089371434878558, "train/extr_return_normed_mag": 1.8257677238434553, "train/extr_return_normed_max": 1.8257677238434553, "train/extr_return_normed_mean": 0.3128023811150342, "train/extr_return_normed_min": -0.19715588202234358, "train/extr_return_normed_std": 0.33294622343964875, "train/extr_return_rate": 0.5499084764160216, "train/extr_return_raw_mag": 6.198646638542414, "train/extr_return_raw_max": 6.198646638542414, "train/extr_return_raw_mean": 1.0855550691485405, "train/extr_return_raw_min": -0.6375348393339664, "train/extr_return_raw_std": 1.1248339843004942, "train/extr_reward_mag": 1.0148075055330992, "train/extr_reward_max": 1.0148075055330992, "train/extr_reward_mean": 0.025366190704517066, "train/extr_reward_min": -0.49608976021409035, "train/extr_reward_std": 0.1486754955840297, "train/image_loss_mean": 7.4708435125648975, "train/image_loss_std": 11.271616283804178, "train/model_loss_mean": 15.464339971542358, "train/model_loss_std": 15.066124886274338, "train/model_opt_grad_norm": 64.35146985948086, "train/model_opt_grad_steps": 22064.0, "train/model_opt_loss": 16042.305095672607, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1044.921875, "train/policy_entropy_mag": 2.5072981268167496, "train/policy_entropy_max": 2.5072981268167496, "train/policy_entropy_mean": 0.7039472898468375, "train/policy_entropy_min": 0.07937519263941795, "train/policy_entropy_std": 0.7282064529135823, "train/policy_logprob_mag": 7.43838307633996, "train/policy_logprob_max": -0.009455670500756241, "train/policy_logprob_mean": -0.7036273241974413, "train/policy_logprob_min": -7.43838307633996, "train/policy_logprob_std": 1.1809565806761384, "train/policy_randomness_mag": 0.8849662090651691, "train/policy_randomness_max": 0.8849662090651691, "train/policy_randomness_mean": 0.24846250005066395, "train/policy_randomness_min": 0.028015959527692758, "train/policy_randomness_std": 0.2570249172858894, "train/post_ent_mag": 57.77855342626572, "train/post_ent_max": 57.77855342626572, "train/post_ent_mean": 39.9942772090435, "train/post_ent_min": 20.704963490366936, "train/post_ent_std": 7.190864350646734, "train/prior_ent_mag": 66.30349797010422, "train/prior_ent_max": 66.30349797010422, "train/prior_ent_mean": 53.23010474443436, "train/prior_ent_min": 35.286363169550896, "train/prior_ent_std": 4.933799408376217, "train/rep_loss_mean": 13.234109163284302, "train/rep_loss_std": 9.117591463029385, "train/reward_avg": 0.023014831444015726, "train/reward_loss_mean": 0.0527675126795657, "train/reward_loss_std": 0.2552262144163251, "train/reward_max_data": 1.0085937520489097, "train/reward_max_pred": 1.0071533741429448, "train/reward_neg_acc": 0.9936462477780879, "train/reward_neg_loss": 0.02891452266339911, "train/reward_pos_acc": 0.9603721364401281, "train/reward_pos_loss": 0.8839982594363391, "train/reward_pred": 0.02215291076572612, "train/reward_rate": 0.02800750732421875, "train_stats/sum_log_reward": 5.766666605585703, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.861111111111111, "train_stats/max_log_achievement_collect_sapling": 2.314814814814815, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.342592592592593, "train_stats/max_log_achievement_defeat_skeleton": 0.009259259259259259, "train_stats/max_log_achievement_defeat_zombie": 0.5, "train_stats/max_log_achievement_eat_cow": 0.1388888888888889, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009259259259259259, "train_stats/max_log_achievement_make_wood_sword": 1.1944444444444444, "train_stats/max_log_achievement_place_plant": 2.25, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.074074074074074, "train_stats/max_log_achievement_wake_up": 2.6018518518518516, "train_stats/mean_log_entropy": 0.5950284587840239, "eval_stats/sum_log_reward": 5.412499904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 2.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 8.256793989858124e-06, "report/cont_loss_std": 0.00013313467206899077, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007831135881133378, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1555592866207007e-06, "report/cont_pred": 0.9921915531158447, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 14.570623397827148, "report/dyn_loss_std": 9.803531646728516, "report/image_loss_mean": 8.44391918182373, "report/image_loss_std": 11.433314323425293, "report/model_loss_mean": 17.25883674621582, "report/model_loss_std": 15.683598518371582, "report/post_ent_mag": 56.974830627441406, "report/post_ent_max": 56.974830627441406, "report/post_ent_mean": 39.39656448364258, "report/post_ent_min": 21.243772506713867, "report/post_ent_std": 7.4548139572143555, "report/prior_ent_mag": 65.71733093261719, "report/prior_ent_max": 65.71733093261719, "report/prior_ent_mean": 53.37955856323242, "report/prior_ent_min": 35.46425247192383, "report/prior_ent_std": 4.794722080230713, "report/rep_loss_mean": 14.570623397827148, "report/rep_loss_std": 9.803531646728516, "report/reward_avg": 0.03310547024011612, "report/reward_loss_mean": 0.07253582775592804, "report/reward_loss_std": 0.3446124792098999, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005617141723633, "report/reward_neg_acc": 0.9949135184288025, "report/reward_neg_loss": 0.035109877586364746, "report/reward_pos_acc": 0.9512194991111755, "report/reward_pos_loss": 0.9698458909988403, "report/reward_pred": 0.03294048085808754, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.9897520360245835e-06, "eval/cont_loss_std": 1.9601988242357038e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.186347309267148e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8725824020293658e-06, "eval/cont_pred": 0.9980452060699463, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.810857772827148, "eval/dyn_loss_std": 9.83660888671875, "eval/image_loss_mean": 13.500843048095703, "eval/image_loss_std": 15.23818588256836, "eval/model_loss_mean": 23.1213436126709, "eval/model_loss_std": 19.36931610107422, "eval/post_ent_mag": 59.4613037109375, "eval/post_ent_max": 59.4613037109375, "eval/post_ent_mean": 40.10991668701172, "eval/post_ent_min": 20.840099334716797, "eval/post_ent_std": 6.782327651977539, "eval/prior_ent_mag": 65.71733093261719, "eval/prior_ent_max": 65.71733093261719, "eval/prior_ent_mean": 53.26507568359375, "eval/prior_ent_min": 39.74143981933594, "eval/prior_ent_std": 4.89568567276001, "eval/rep_loss_mean": 15.810857772827148, "eval/rep_loss_std": 9.83660888671875, "eval/reward_avg": 0.02724609337747097, "eval/reward_loss_mean": 0.13398391008377075, "eval/reward_loss_std": 0.9012489318847656, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040087699890137, "eval/reward_neg_acc": 0.9899193048477173, "eval/reward_neg_loss": 0.041512250900268555, "eval/reward_pos_acc": 0.71875, "eval/reward_pos_loss": 3.000605583190918, "eval/reward_pred": 0.020149389281868935, "eval/reward_rate": 0.03125, "replay/size": 364609.0, "replay/inserts": 20400.0, "replay/samples": 20400.0, "replay/insert_wait_avg": 1.365483975877949e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.849347357656442e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 69656.0, "eval_replay/inserts": 3880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0879383873693722e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3189327716827, "timer/env.step_count": 2550.0, "timer/env.step_total": 245.38107466697693, "timer/env.step_frac": 0.24530283955245683, "timer/env.step_avg": 0.09622787241842233, "timer/env.step_min": 0.023684978485107422, "timer/env.step_max": 4.220527410507202, "timer/replay._sample_count": 20400.0, "timer/replay._sample_total": 10.478723287582397, "timer/replay._sample_frac": 0.010475382344856716, "timer/replay._sample_avg": 0.0005136629062540391, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.011319875717163086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3035.0, "timer/agent.policy_total": 49.65376901626587, "timer/agent.policy_frac": 0.04963793785116638, "timer/agent.policy_avg": 0.01636038517834131, "timer/agent.policy_min": 0.009356021881103516, "timer/agent.policy_max": 0.09585738182067871, "timer/dataset_train_count": 1275.0, "timer/dataset_train_total": 0.14679789543151855, "timer/dataset_train_frac": 0.0001467510916990955, "timer/dataset_train_avg": 0.00011513560426001456, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.00036454200744628906, "timer/agent.train_count": 1275.0, "timer/agent.train_total": 565.9085168838501, "timer/agent.train_frac": 0.5657280876568349, "timer/agent.train_avg": 0.443849817163804, "timer/agent.train_min": 0.43225646018981934, "timer/agent.train_max": 1.1491515636444092, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47570157051086426, "timer/agent.report_frac": 0.000475549902062526, "timer/agent.report_avg": 0.23785078525543213, "timer/agent.report_min": 0.2303769588470459, "timer/agent.report_max": 0.24532461166381836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.5264311767788866e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 20.39323018627108}
{"step": 365128, "time": 18300.56030011177, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 365400, "time": 18312.5958404541, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 365584, "time": 18321.12841153145, "episode/length": 171.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 365720, "time": 18327.486114501953, "episode/length": 206.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 365960, "time": 18337.94104862213, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 366088, "time": 18344.175897598267, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 366240, "time": 18351.47529911995, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 366376, "time": 18357.754830121994, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 366384, "time": 18359.8760137558, "episode/length": 156.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 366704, "time": 18373.166688919067, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 366776, "time": 18377.029050827026, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 367168, "time": 18393.030846357346, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 367560, "time": 18408.72139286995, "episode/length": 48.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 367568, "time": 18410.749102830887, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 367664, "time": 18415.89020872116, "episode/length": 196.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 367904, "time": 18426.404621124268, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 367960, "time": 18430.313450098038, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 367968, "time": 18432.89525461197, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 368008, "time": 18436.146849632263, "episode/length": 153.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 368472, "time": 18455.30199456215, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 368640, "time": 18463.366013288498, "episode/length": 133.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 368976, "time": 18478.743044614792, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 369008, "time": 18481.537675857544, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 369136, "time": 18487.860415935516, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 369432, "time": 18499.980733156204, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 369520, "time": 18504.80710554123, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 369656, "time": 18511.148263931274, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 369664, "time": 18513.18868994713, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 369776, "time": 18518.7754445076, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 18547.36101293564, "eval_episode/length": 130.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9541984732824428}
{"step": 370032, "time": 18549.15302991867, "eval_episode/length": 136.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 370032, "time": 18551.35318160057, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 370032, "time": 18553.09590125084, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 370032, "time": 18555.106838464737, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 370032, "time": 18555.159126996994, "eval_episode/length": 171.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 370032, "time": 18558.769561052322, "eval_episode/length": 179.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 370032, "time": 18560.40314912796, "eval_episode/length": 180.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.994475138121547}
{"step": 370352, "time": 18572.02804708481, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 370440, "time": 18576.706161737442, "episode/length": 182.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 370560, "time": 18582.82670402527, "episode/length": 193.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 370960, "time": 18598.752259016037, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 371024, "time": 18602.603713989258, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 371192, "time": 18610.027292966843, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 371216, "time": 18612.614785432816, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 371552, "time": 18626.38000369072, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 372080, "time": 18647.27564239502, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 372232, "time": 18654.190576314926, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 372240, "time": 18656.33046889305, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 372672, "time": 18673.717775583267, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 372904, "time": 18683.40687561035, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 372912, "time": 18685.512939214706, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 373072, "time": 18692.858399152756, "episode/length": 255.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 373576, "time": 18712.504534244537, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 373688, "time": 18718.080047607422, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 373880, "time": 18726.63792848587, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 374024, "time": 18733.480826854706, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 374112, "time": 18738.443279266357, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 374568, "time": 18756.50268959999, "episode/length": 207.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 374592, "time": 18759.198499917984, "episode/length": 209.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 374912, "time": 18772.40794968605, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 375216, "time": 18784.99601316452, "episode/length": 607.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9983552631578947, "episode/intrinsic_return": 0.0}
{"step": 375288, "time": 18789.06699848175, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 375464, "time": 18797.190185308456, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 375600, "time": 18804.579909801483, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 375616, "time": 18807.1096200943, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 376096, "time": 18827.191967010498, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 376144, "time": 18831.07305955887, "episode/length": 153.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 376248, "time": 18836.642597198486, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 376672, "time": 18854.750010252, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 376840, "time": 18863.33444929123, "episode/length": 171.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 376952, "time": 18870.732893943787, "episode/length": 207.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 377120, "time": 18879.476358652115, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 377200, "time": 18884.46895956993, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 377368, "time": 18892.549522161484, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 377552, "time": 18901.63437318802, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 378176, "time": 18927.030200719833, "episode/length": 121.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 378192, "time": 18929.662090539932, "episode/length": 189.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 378208, "time": 18932.191033124924, "episode/length": 263.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 378368, "time": 18940.20946598053, "episode/length": 176.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 378552, "time": 18948.900797843933, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 378624, "time": 18953.703139066696, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 378648, "time": 18956.286049604416, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 378776, "time": 18963.042209148407, "episode/length": 206.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 378888, "time": 18969.256835222244, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 379544, "time": 18995.727730989456, "episode/length": 170.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 379784, "time": 19006.465289592743, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 379920, "time": 19013.30874657631, "episode/length": 158.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 19036.333845615387, "eval_episode/length": 147.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 380016, "time": 19037.837094068527, "eval_episode/length": 148.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 380016, "time": 19039.56906223297, "eval_episode/length": 151.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.993421052631579}
{"step": 380016, "time": 19041.595802783966, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 380016, "time": 19043.580241918564, "eval_episode/length": 174.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 380016, "time": 19045.208674430847, "eval_episode/length": 177.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 380016, "time": 19046.95699071884, "eval_episode/length": 181.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9835164835164835}
{"step": 380016, "time": 19049.915693044662, "eval_episode/length": 221.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 380192, "time": 19056.431136608124, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 380288, "time": 19061.451613664627, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 380368, "time": 19065.90944957733, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 380368, "time": 19065.960641622543, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 380672, "time": 19080.46444940567, "episode/length": 287.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 381176, "time": 19100.36675810814, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 381240, "time": 19104.219551324844, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 381720, "time": 19123.54607629776, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 381776, "time": 19127.32266163826, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 381824, "time": 19130.69758605957, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 381880, "time": 19134.02091860771, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 381904, "time": 19136.66425895691, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 382376, "time": 19155.28525495529, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 382448, "time": 19159.701432466507, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 382552, "time": 19164.762907266617, "episode/length": 163.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 383040, "time": 19184.603807210922, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 383064, "time": 19186.802726507187, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 383176, "time": 19192.40358901024, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 383384, "time": 19201.55897450447, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 383440, "time": 19205.35059261322, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 383624, "time": 19213.263815402985, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 384136, "time": 19233.651269197464, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 384280, "time": 19240.707669973373, "episode/length": 151.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 384560, "time": 19252.6501390934, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 384680, "time": 19258.32974076271, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 384768, "time": 19263.37566757202, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 384824, "time": 19266.79201221466, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 384864, "time": 19269.875361204147, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 385416, "time": 19292.625851631165, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 385520, "time": 19298.331095933914, "episode/length": 119.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 385521, "time": 19300.463911294937, "train_stats/sum_log_reward": 6.044954092130748, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.770642201834862, "train_stats/max_log_achievement_collect_sapling": 2.7339449541284404, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.724770642201835, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.5412844036697247, "train_stats/max_log_achievement_eat_cow": 0.11009174311926606, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 1.0458715596330275, "train_stats/max_log_achievement_place_plant": 2.6422018348623855, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.2752293577981653, "train_stats/max_log_achievement_wake_up": 2.403669724770642, "train_stats/mean_log_entropy": 0.6200239959113095, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.9844235397699315, "train/action_min": 0.0, "train/action_std": 3.8704417803156095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04998094371453984, "train/actor_opt_grad_steps": 23360.0, "train/actor_opt_loss": -1.6065036374048924, "train/adv_mag": 0.7383033365715207, "train/adv_max": 0.7084566523709636, "train/adv_mean": 0.00442963100121283, "train/adv_min": -0.5312402473659966, "train/adv_std": 0.07652441787672794, "train/cont_avg": 0.994263656496063, "train/cont_loss_mean": 0.00019285607954439753, "train/cont_loss_std": 0.005615559657280845, "train/cont_neg_acc": 0.9915343929850866, "train/cont_neg_loss": 0.01821187843775295, "train/cont_pos_acc": 0.9999690069927005, "train/cont_pos_loss": 9.134840939324705e-05, "train/cont_pred": 0.9942599577227915, "train/cont_rate": 0.994263656496063, "train/dyn_loss_mean": 13.099413045748012, "train/dyn_loss_std": 9.061768389123632, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8376746635268054, "train/extr_critic_critic_opt_grad_steps": 23360.0, "train/extr_critic_critic_opt_loss": 15917.724940022146, "train/extr_critic_mag": 5.128758250259039, "train/extr_critic_max": 5.128758250259039, "train/extr_critic_mean": 1.1369912507027153, "train/extr_critic_min": -0.2893864132287934, "train/extr_critic_std": 1.1546409993659792, "train/extr_return_normed_mag": 1.7791073772850938, "train/extr_return_normed_max": 1.7791073772850938, "train/extr_return_normed_mean": 0.32794510262218984, "train/extr_return_normed_min": -0.17716087277714662, "train/extr_return_normed_std": 0.3400774971237333, "train/extr_return_rate": 0.5598061542342029, "train/extr_return_raw_mag": 6.251162232376459, "train/extr_return_raw_max": 6.251162232376459, "train/extr_return_raw_mean": 1.152520078843034, "train/extr_return_raw_min": -0.6222525715358614, "train/extr_return_raw_std": 1.194948201104412, "train/extr_reward_mag": 1.0137547817755872, "train/extr_reward_max": 1.0137547817755872, "train/extr_reward_mean": 0.027608801794099056, "train/extr_reward_min": -0.46245698478278213, "train/extr_reward_std": 0.15433754437551725, "train/image_loss_mean": 7.085359239202785, "train/image_loss_std": 10.920743104979747, "train/model_loss_mean": 14.99769832581047, "train/model_loss_std": 14.67660961000938, "train/model_opt_grad_norm": 58.08440122829648, "train/model_opt_grad_steps": 23337.992125984252, "train/model_opt_loss": 17726.68865726501, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1186.023622047244, "train/policy_entropy_mag": 2.5203941788260393, "train/policy_entropy_max": 2.5203941788260393, "train/policy_entropy_mean": 0.6870173117307228, "train/policy_entropy_min": 0.07937518020314495, "train/policy_entropy_std": 0.7197813532483859, "train/policy_logprob_mag": 7.438383136208602, "train/policy_logprob_max": -0.009455670602619648, "train/policy_logprob_mean": -0.6862708482685991, "train/policy_logprob_min": -7.438383136208602, "train/policy_logprob_std": 1.1724624380351991, "train/policy_randomness_mag": 0.8895885428105752, "train/policy_randomness_max": 0.8895885428105752, "train/policy_randomness_mean": 0.24248696335657374, "train/policy_randomness_min": 0.028015955109295883, "train/policy_randomness_std": 0.25405123020250964, "train/post_ent_mag": 58.00497250294122, "train/post_ent_max": 58.00497250294122, "train/post_ent_mean": 40.22010728130191, "train/post_ent_min": 20.578557337362934, "train/post_ent_std": 7.236937500360444, "train/prior_ent_mag": 66.4205632247324, "train/prior_ent_max": 66.4205632247324, "train/prior_ent_mean": 53.405199696698524, "train/prior_ent_min": 36.38111185088871, "train/prior_ent_std": 4.904192823124683, "train/rep_loss_mean": 13.099413045748012, "train/rep_loss_std": 9.061768389123632, "train/reward_avg": 0.02383504532218918, "train/reward_loss_mean": 0.05249840400995701, "train/reward_loss_std": 0.24853984272386145, "train/reward_max_data": 1.0094488211504118, "train/reward_max_pred": 1.0044385804904727, "train/reward_neg_acc": 0.9930749197644512, "train/reward_neg_loss": 0.02798002637834765, "train/reward_pos_acc": 0.9637463238295607, "train/reward_pos_loss": 0.878713246405594, "train/reward_pred": 0.02304100846563737, "train/reward_rate": 0.028881643700787402, "eval_stats/sum_log_reward": 5.537499964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.0625, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 2.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.017543859649122806, "eval_stats/max_log_achievement_eat_plant": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.002277257153764367, "report/cont_loss_std": 0.05191287398338318, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.19991056621074677, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.001307515543885529, "report/cont_pred": 0.9950176477432251, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.941429138183594, "report/dyn_loss_std": 9.545807838439941, "report/image_loss_mean": 7.182026386260986, "report/image_loss_std": 10.957359313964844, "report/model_loss_mean": 14.395891189575195, "report/model_loss_std": 14.902870178222656, "report/post_ent_mag": 61.37870788574219, "report/post_ent_max": 61.37870788574219, "report/post_ent_mean": 41.32823944091797, "report/post_ent_min": 20.03225326538086, "report/post_ent_std": 8.105388641357422, "report/prior_ent_mag": 66.1119384765625, "report/prior_ent_max": 66.1119384765625, "report/prior_ent_mean": 53.353790283203125, "report/prior_ent_min": 35.72267150878906, "report/prior_ent_std": 5.142932891845703, "report/rep_loss_mean": 11.941429138183594, "report/rep_loss_std": 9.545807838439941, "report/reward_avg": 0.0205078125, "report/reward_loss_mean": 0.04672972112894058, "report/reward_loss_std": 0.24989189207553864, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000126600265503, "report/reward_neg_acc": 0.9930000305175781, "report/reward_neg_loss": 0.026688290759921074, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.8817895650863647, "report/reward_pred": 0.021570414304733276, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.8390150216873735e-05, "eval/cont_loss_std": 0.000457268237369135, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003749499563127756, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.244951743563433e-08, "eval/cont_pred": 0.9951353073120117, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.413284301757812, "eval/dyn_loss_std": 9.708353042602539, "eval/image_loss_mean": 16.443161010742188, "eval/image_loss_std": 23.62359046936035, "eval/model_loss_mean": 26.96957778930664, "eval/model_loss_std": 26.500572204589844, "eval/post_ent_mag": 52.146881103515625, "eval/post_ent_max": 52.146881103515625, "eval/post_ent_mean": 38.34890365600586, "eval/post_ent_min": 19.99724578857422, "eval/post_ent_std": 6.313370227813721, "eval/prior_ent_mag": 66.1119384765625, "eval/prior_ent_max": 66.1119384765625, "eval/prior_ent_mean": 53.468284606933594, "eval/prior_ent_min": 37.774391174316406, "eval/prior_ent_std": 4.064722061157227, "eval/rep_loss_mean": 17.413284301757812, "eval/rep_loss_std": 9.708353042602539, "eval/reward_avg": 0.01982421986758709, "eval/reward_loss_mean": 0.07842694222927094, "eval/reward_loss_std": 0.4586048424243927, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000960111618042, "eval/reward_neg_acc": 0.9909819960594177, "eval/reward_neg_loss": 0.0366755872964859, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 1.6810368299484253, "eval/reward_pred": 0.018271103501319885, "eval/reward_rate": 0.025390625, "replay/size": 385017.0, "replay/inserts": 20408.0, "replay/samples": 20400.0, "replay/insert_wait_avg": 1.3672151270215533e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.897031073476753e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72880.0, "eval_replay/inserts": 3224.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0693339496924919e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0365099906921, "timer/env.step_count": 2551.0, "timer/env.step_total": 251.4607720375061, "timer/env.step_frac": 0.2514515915422394, "timer/env.step_avg": 0.0985734112259922, "timer/env.step_min": 0.023659467697143555, "timer/env.step_max": 3.4043357372283936, "timer/replay._sample_count": 20400.0, "timer/replay._sample_total": 10.502953290939331, "timer/replay._sample_frac": 0.010502569842212149, "timer/replay._sample_avg": 0.0005148506515166339, "timer/replay._sample_min": 0.00037980079650878906, "timer/replay._sample_max": 0.011518239974975586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2954.0, "timer/agent.policy_total": 48.510637521743774, "timer/agent.policy_frac": 0.04850886646348071, "timer/agent.policy_avg": 0.016422016764300534, "timer/agent.policy_min": 0.009207725524902344, "timer/agent.policy_max": 0.11838483810424805, "timer/dataset_train_count": 1275.0, "timer/dataset_train_total": 0.14791536331176758, "timer/dataset_train_frac": 0.00014790996312039078, "timer/dataset_train_avg": 0.00011601204965628829, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.00035119056701660156, "timer/agent.train_count": 1275.0, "timer/agent.train_total": 566.5301077365875, "timer/agent.train_frac": 0.5665094244827726, "timer/agent.train_avg": 0.4443373394012451, "timer/agent.train_min": 0.4312286376953125, "timer/agent.train_max": 1.1242806911468506, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46365857124328613, "timer/agent.report_frac": 0.00046364164369119045, "timer/agent.report_avg": 0.23182928562164307, "timer/agent.report_min": 0.2209458351135254, "timer/agent.report_max": 0.24271273612976074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194692321774005e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 20.4069922576274}
{"step": 385616, "time": 19304.20067167282, "episode/length": 184.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 385952, "time": 19318.15201497078, "episode/length": 158.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 386024, "time": 19322.156881809235, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 386032, "time": 19324.31236100197, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 386368, "time": 19338.21564555168, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 386720, "time": 19352.562888622284, "episode/length": 162.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 386728, "time": 19354.22118496895, "episode/length": 305.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 386776, "time": 19357.597652435303, "episode/length": 102.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 386888, "time": 19363.282170295715, "episode/length": 170.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 387064, "time": 19371.17545247078, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 387312, "time": 19382.028469324112, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 387384, "time": 19386.005711078644, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 387816, "time": 19403.238577127457, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 387848, "time": 19405.815783023834, "episode/length": 140.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 388104, "time": 19416.746788740158, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 388224, "time": 19422.852897644043, "episode/length": 166.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 388288, "time": 19426.709765434265, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 388784, "time": 19446.407539367676, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 389040, "time": 19457.342418909073, "episode/length": 206.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 389048, "time": 19459.374723911285, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 389096, "time": 19463.265640497208, "episode/length": 155.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 389264, "time": 19471.865245342255, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 389624, "time": 19486.93501996994, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 19522.665689229965, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 390000, "time": 19524.781435251236, "eval_episode/length": 158.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 390000, "time": 19527.11441040039, "eval_episode/length": 164.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 390000, "time": 19529.55590581894, "eval_episode/length": 175.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 390000, "time": 19531.69984436035, "eval_episode/length": 177.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 390000, "time": 19533.73019528389, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9608938547486033}
{"step": 390000, "time": 19536.9232006073, "eval_episode/length": 39.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.875}
{"step": 390000, "time": 19539.18397474289, "eval_episode/length": 32.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 390064, "time": 19541.59899711609, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673469387755103, "episode/intrinsic_return": 0.0}
{"step": 390176, "time": 19547.774279117584, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 390424, "time": 19558.907141923904, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700374531835206, "episode/intrinsic_return": 0.0}
{"step": 390440, "time": 19561.498023986816, "episode/length": 146.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 390600, "time": 19569.607977867126, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 390616, "time": 19572.296543598175, "episode/length": 189.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 390856, "time": 19583.35305261612, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 391296, "time": 19601.980090141296, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 391472, "time": 19609.990155935287, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 391752, "time": 19621.450452566147, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 391864, "time": 19627.325946569443, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 391920, "time": 19631.220898866653, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 391968, "time": 19634.647704839706, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 392032, "time": 19638.37109708786, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 392160, "time": 19644.70146226883, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 392272, "time": 19650.367273807526, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 392792, "time": 19670.668133735657, "episode/length": 129.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 392808, "time": 19672.80202269554, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 393384, "time": 19696.932935237885, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9665271966527197, "episode/intrinsic_return": 0.0}
{"step": 393392, "time": 19698.99190711975, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 393456, "time": 19702.974568605423, "episode/length": 269.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 393632, "time": 19710.948907852173, "episode/length": 169.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 393656, "time": 19713.168102025986, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 393872, "time": 19722.879192352295, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 393968, "time": 19727.963487148285, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 394168, "time": 19736.58185505867, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 394240, "time": 19740.969260692596, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 394640, "time": 19757.28283715248, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 394864, "time": 19767.632967472076, "episode/length": 183.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 395088, "time": 19777.588364124298, "episode/length": 181.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 395168, "time": 19782.673426628113, "episode/length": 149.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 395368, "time": 19791.96651005745, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 395392, "time": 19795.062705278397, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 395592, "time": 19804.189657211304, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 395728, "time": 19811.290964126587, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 395912, "time": 19819.26656460762, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 396064, "time": 19826.487160921097, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 396288, "time": 19836.324865579605, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 396392, "time": 19841.54962158203, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 396480, "time": 19846.458193063736, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 396968, "time": 19865.651571273804, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 397064, "time": 19870.73396039009, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 397432, "time": 19885.646979808807, "episode/length": 254.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 397464, "time": 19888.31987929344, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 397464, "time": 19888.37214779854, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 397624, "time": 19897.692249536514, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 397800, "time": 19905.631008386612, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 398088, "time": 19917.637664556503, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 398336, "time": 19928.74921274185, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 398416, "time": 19933.191307783127, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 398776, "time": 19947.59046149254, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 399304, "time": 19968.5676817894, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 399392, "time": 19973.621300458908, "episode/length": 162.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 399520, "time": 19979.858827114105, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 399552, "time": 19982.668459177017, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 400040, "time": 20001.767285823822, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 20019.419363737106, "eval_episode/length": 49.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.98}
{"step": 400088, "time": 20022.20384144783, "eval_episode/length": 32.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 400088, "time": 20026.15139722824, "eval_episode/length": 146.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 400088, "time": 20028.120158433914, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 400088, "time": 20029.738278388977, "eval_episode/length": 157.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 400088, "time": 20031.78612112999, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 400088, "time": 20033.81993317604, "eval_episode/length": 182.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 400088, "time": 20035.401030302048, "eval_episode/length": 185.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 400296, "time": 20044.23890686035, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659574468085106, "episode/intrinsic_return": 0.0}
{"step": 400312, "time": 20046.433342933655, "episode/length": 359.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 400600, "time": 20058.460924863815, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 400936, "time": 20072.26250886917, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 401056, "time": 20078.41134762764, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 401064, "time": 20080.089698791504, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 401120, "time": 20083.893328666687, "episode/length": 456.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9978118161925602, "episode/intrinsic_return": 0.0}
{"step": 401464, "time": 20099.112721920013, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 401504, "time": 20102.30707550049, "episode/length": 148.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 401704, "time": 20110.85743045807, "episode/length": 272.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 402104, "time": 20126.923091888428, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 402248, "time": 20133.756287813187, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 402632, "time": 20149.21214079857, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 402768, "time": 20155.95875811577, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 403008, "time": 20166.391814231873, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 403048, "time": 20169.151636600494, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 403608, "time": 20190.98583817482, "episode/length": 318.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 403656, "time": 20194.2812435627, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 403848, "time": 20202.94393324852, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 403968, "time": 20209.022569656372, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 404000, "time": 20211.75614953041, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 404184, "time": 20219.843926668167, "episode/length": 339.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9970588235294118, "episode/intrinsic_return": 0.0}
{"step": 404216, "time": 20222.588483810425, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 405200, "time": 20260.278634786606, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 405256, "time": 20263.62899684906, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 405264, "time": 20265.673653125763, "episode/length": 376.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761273209549072, "episode/intrinsic_return": 0.0}
{"step": 405296, "time": 20268.410913944244, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 405400, "time": 20273.51196193695, "episode/length": 293.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 405496, "time": 20278.66036629677, "episode/length": 229.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 405552, "time": 20282.577211141586, "episode/length": 36.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 405616, "time": 20286.495080947876, "episode/length": 39.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 405945, "time": 20300.87402367592, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.741978645324707, "train/action_min": 0.0, "train/action_std": 3.7842987459152937, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046787870553089306, "train/actor_opt_grad_steps": 24635.0, "train/actor_opt_loss": -4.527121742255986, "train/adv_mag": 0.7118572208564728, "train/adv_max": 0.6736842475365847, "train/adv_mean": 0.004045638543630048, "train/adv_min": -0.5228258355055004, "train/adv_std": 0.07173027063254267, "train/cont_avg": 0.99456787109375, "train/cont_loss_mean": 0.00014657537296008938, "train/cont_loss_std": 0.0044114586949692836, "train/cont_neg_acc": 0.9956287210807204, "train/cont_neg_loss": 0.012896972227022019, "train/cont_pos_acc": 0.9999769814312458, "train/cont_pos_loss": 7.8729255998361e-05, "train/cont_pred": 0.994571547023952, "train/cont_rate": 0.99456787109375, "train/dyn_loss_mean": 13.112395964562893, "train/dyn_loss_std": 9.061155080795288, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.83089798130095, "train/extr_critic_critic_opt_grad_steps": 24635.0, "train/extr_critic_critic_opt_loss": 15877.48430633545, "train/extr_critic_mag": 5.341004639863968, "train/extr_critic_max": 5.341004639863968, "train/extr_critic_mean": 1.1583779524080455, "train/extr_critic_min": -0.31705567985773087, "train/extr_critic_std": 1.191896025557071, "train/extr_return_normed_mag": 1.7301296135410666, "train/extr_return_normed_max": 1.7301296135410666, "train/extr_return_normed_mean": 0.32417080271989107, "train/extr_return_normed_min": -0.18629842827795073, "train/extr_return_normed_std": 0.3321038546273485, "train/extr_return_rate": 0.5701004317961633, "train/extr_return_raw_mag": 6.374460730701685, "train/extr_return_raw_max": 6.374460730701685, "train/extr_return_raw_mean": 1.1733324052765965, "train/extr_return_raw_min": -0.7136131243314594, "train/extr_return_raw_std": 1.2287781317718327, "train/extr_reward_mag": 1.012388402596116, "train/extr_reward_max": 1.012388402596116, "train/extr_reward_mean": 0.02661776003515115, "train/extr_reward_min": -0.4875386692583561, "train/extr_reward_std": 0.1524258439312689, "train/image_loss_mean": 6.985579311847687, "train/image_loss_std": 10.891312312334776, "train/model_loss_mean": 14.906360425055027, "train/model_loss_std": 14.624098144471645, "train/model_opt_grad_norm": 58.325109764933586, "train/model_opt_grad_steps": 24612.0, "train/model_opt_loss": 12582.355609893799, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 844.7265625, "train/policy_entropy_mag": 2.536025417968631, "train/policy_entropy_max": 2.536025417968631, "train/policy_entropy_mean": 0.6374322345945984, "train/policy_entropy_min": 0.07937512506032363, "train/policy_entropy_std": 0.6898367842659354, "train/policy_logprob_mag": 7.43838332220912, "train/policy_logprob_max": -0.009455661260290071, "train/policy_logprob_mean": -0.6379810974467546, "train/policy_logprob_min": -7.43838332220912, "train/policy_logprob_std": 1.156565754674375, "train/policy_randomness_mag": 0.8951056818477809, "train/policy_randomness_max": 0.8951056818477809, "train/policy_randomness_mean": 0.22498560487292707, "train/policy_randomness_min": 0.02801593576441519, "train/policy_randomness_std": 0.24348211311735213, "train/post_ent_mag": 57.927910417318344, "train/post_ent_max": 57.927910417318344, "train/post_ent_mean": 40.53383329510689, "train/post_ent_min": 20.492463126778603, "train/post_ent_std": 7.333572093397379, "train/prior_ent_mag": 66.52017146348953, "train/prior_ent_max": 66.52017146348953, "train/prior_ent_mean": 53.693630397319794, "train/prior_ent_min": 36.708368837833405, "train/prior_ent_std": 4.8053838312625885, "train/rep_loss_mean": 13.112395964562893, "train/rep_loss_std": 9.061155080795288, "train/reward_avg": 0.02396926856454229, "train/reward_loss_mean": 0.05319706161390059, "train/reward_loss_std": 0.25222403823863715, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.0045334743335843, "train/reward_neg_acc": 0.9929416896775365, "train/reward_neg_loss": 0.02868432572722668, "train/reward_pos_acc": 0.9618261051364243, "train/reward_pos_loss": 0.8804490189068019, "train/reward_pred": 0.023098885743820574, "train/reward_rate": 0.02880859375, "train_stats/sum_log_reward": 5.754545391554182, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.8, "train_stats/max_log_achievement_collect_sapling": 2.3181818181818183, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.272727272727273, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4636363636363636, "train_stats/max_log_achievement_eat_cow": 0.13636363636363635, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00909090909090909, "train_stats/max_log_achievement_make_wood_sword": 1.3818181818181818, "train_stats/max_log_achievement_place_plant": 2.190909090909091, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.9181818181818182, "train_stats/max_log_achievement_wake_up": 2.463636363636364, "train_stats/mean_log_entropy": 0.5553069838068702, "eval_stats/sum_log_reward": 5.099999938160181, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.3492153761471855e-07, "report/cont_loss_std": 5.4800343605165835e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.4718711908208206e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.807271546449556e-08, "report/cont_pred": 0.9951173663139343, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.937576293945312, "report/dyn_loss_std": 9.091102600097656, "report/image_loss_mean": 6.512446880340576, "report/image_loss_std": 10.680270195007324, "report/model_loss_mean": 14.90948486328125, "report/model_loss_std": 14.628106117248535, "report/post_ent_mag": 54.633445739746094, "report/post_ent_max": 54.633445739746094, "report/post_ent_mean": 39.47205352783203, "report/post_ent_min": 20.801462173461914, "report/post_ent_std": 6.832490921020508, "report/prior_ent_mag": 66.81295776367188, "report/prior_ent_max": 66.81295776367188, "report/prior_ent_mean": 53.669456481933594, "report/prior_ent_min": 37.90190505981445, "report/prior_ent_std": 4.354640960693359, "report/rep_loss_mean": 13.937576293945312, "report/rep_loss_std": 9.091102600097656, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.0344933345913887, "report/reward_loss_std": 0.1416349858045578, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018715858459473, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.016383113339543343, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.678699791431427, "report/reward_pred": 0.023926910012960434, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00017557582759764045, "eval/cont_loss_std": 0.0056142741814255714, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.059921666979789734, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4160229372682807e-08, "eval/cont_pred": 0.9972310066223145, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.908897399902344, "eval/dyn_loss_std": 10.323661804199219, "eval/image_loss_mean": 12.20541000366211, "eval/image_loss_std": 18.111560821533203, "eval/model_loss_mean": 22.4345645904541, "eval/model_loss_std": 22.506515502929688, "eval/post_ent_mag": 57.54130172729492, "eval/post_ent_max": 57.54130172729492, "eval/post_ent_mean": 39.58955001831055, "eval/post_ent_min": 20.85696029663086, "eval/post_ent_std": 6.702630996704102, "eval/prior_ent_mag": 66.81295776367188, "eval/prior_ent_max": 66.81295776367188, "eval/prior_ent_mean": 54.484092712402344, "eval/prior_ent_min": 40.405338287353516, "eval/prior_ent_std": 4.238668918609619, "eval/rep_loss_mean": 16.908897399902344, "eval/rep_loss_std": 10.323661804199219, "eval/reward_avg": 0.02695312537252903, "eval/reward_loss_mean": 0.0836397111415863, "eval/reward_loss_std": 0.5733656883239746, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023016929626465, "eval/reward_neg_acc": 0.9849094152450562, "eval/reward_neg_loss": 0.03158082440495491, "eval/reward_pos_acc": 0.8000000715255737, "eval/reward_pos_loss": 1.8085241317749023, "eval/reward_pred": 0.024794865399599075, "eval/reward_rate": 0.029296875, "replay/size": 405441.0, "replay/inserts": 20424.0, "replay/samples": 20432.0, "replay/insert_wait_avg": 1.3604240701378815e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.946508044643895e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76056.0, "eval_replay/inserts": 3176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1180750368824533e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.396910905838, "timer/env.step_count": 2553.0, "timer/env.step_total": 246.20564579963684, "timer/env.step_frac": 0.2461079628651621, "timer/env.step_avg": 0.09643777743816563, "timer/env.step_min": 0.02332329750061035, "timer/env.step_max": 3.402897834777832, "timer/replay._sample_count": 20432.0, "timer/replay._sample_total": 10.50961446762085, "timer/replay._sample_frac": 0.010505444742032058, "timer/replay._sample_avg": 0.0005143703243745522, "timer/replay._sample_min": 0.0003840923309326172, "timer/replay._sample_max": 0.027519941329956055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2950.0, "timer/agent.policy_total": 49.26962876319885, "timer/agent.policy_frac": 0.04925008086898855, "timer/agent.policy_avg": 0.016701569072270796, "timer/agent.policy_min": 0.009357213973999023, "timer/agent.policy_max": 0.10819149017333984, "timer/dataset_train_count": 1277.0, "timer/dataset_train_total": 0.1471705436706543, "timer/dataset_train_frac": 0.000147112153252647, "timer/dataset_train_avg": 0.00011524709762776375, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0003783702850341797, "timer/agent.train_count": 1277.0, "timer/agent.train_total": 569.1288514137268, "timer/agent.train_frac": 0.568903047589774, "timer/agent.train_avg": 0.4456764693921118, "timer/agent.train_min": 0.43265724182128906, "timer/agent.train_max": 1.6769583225250244, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47084903717041016, "timer/agent.report_frac": 0.0004706622261998654, "timer/agent.report_avg": 0.23542451858520508, "timer/agent.report_min": 0.22904562950134277, "timer/agent.report_max": 0.24180340766906738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4318695068359375e-05, "timer/dataset_eval_frac": 2.4309046542676064e-08, "timer/dataset_eval_avg": 2.4318695068359375e-05, "timer/dataset_eval_min": 2.4318695068359375e-05, "timer/dataset_eval_max": 2.4318695068359375e-05, "fps": 20.415637948997603}
{"step": 406128, "time": 20307.610987186432, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 406528, "time": 20323.778037548065, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 406752, "time": 20333.54816889763, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 406840, "time": 20338.125998020172, "episode/length": 204.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 406840, "time": 20338.172970294952, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 407032, "time": 20348.722941875458, "episode/length": 184.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 407032, "time": 20348.775357723236, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 407120, "time": 20355.581239700317, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 407360, "time": 20365.821209669113, "episode/length": 396.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9974811083123426, "episode/intrinsic_return": 0.0}
{"step": 407936, "time": 20388.407306432724, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 408104, "time": 20395.79653596878, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 408232, "time": 20401.868632555008, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 408656, "time": 20419.28701043129, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 408680, "time": 20421.46957540512, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 408704, "time": 20424.167532444, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 408744, "time": 20426.94578552246, "episode/length": 213.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 409448, "time": 20454.238029003143, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 409480, "time": 20456.940332889557, "episode/length": 155.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 409840, "time": 20473.747181892395, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 410040, "time": 20483.152480840683, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 410048, "time": 20485.54719877243, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 20505.815231084824, "eval_episode/length": 32.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 410072, "time": 20512.79799413681, "eval_episode/length": 144.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.993103448275862}
{"step": 410072, "time": 20514.82355952263, "eval_episode/length": 146.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 410072, "time": 20514.875468969345, "eval_episode/length": 146.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 410072, "time": 20518.237129688263, "eval_episode/length": 147.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 410072, "time": 20520.371509552002, "eval_episode/length": 159.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.99375}
{"step": 410072, "time": 20522.256201028824, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 410072, "time": 20524.6303293705, "eval_episode/length": 154.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 410144, "time": 20527.591824531555, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 410336, "time": 20536.135212183, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 410552, "time": 20545.3138692379, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 410720, "time": 20553.2042760849, "episode/length": 449.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 411192, "time": 20572.010061979294, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 411272, "time": 20576.46217274666, "episode/length": 323.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 411376, "time": 20582.08712530136, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 411408, "time": 20584.697418689728, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 411592, "time": 20592.801958322525, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 411752, "time": 20600.14471411705, "episode/length": 42.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 411984, "time": 20610.566905021667, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 412192, "time": 20619.94296836853, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 412272, "time": 20624.431240558624, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 412488, "time": 20633.591349601746, "episode/length": 161.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 412624, "time": 20640.317987680435, "episode/length": 79.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 412712, "time": 20644.842082977295, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 413072, "time": 20659.88480591774, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 413096, "time": 20662.188569545746, "episode/length": 214.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 413456, "time": 20677.26358938217, "episode/length": 47.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 413576, "time": 20682.945615530014, "episode/length": 287.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 414008, "time": 20700.65985274315, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 414048, "time": 20704.461661577225, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 414192, "time": 20711.901080608368, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 414216, "time": 20714.518115997314, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 414704, "time": 20734.993262052536, "episode/length": 200.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 414912, "time": 20744.32588338852, "episode/length": 166.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 414960, "time": 20747.62525701523, "episode/length": 280.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 415000, "time": 20750.461084127426, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 415232, "time": 20760.754420518875, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 415472, "time": 20771.879717111588, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 415512, "time": 20774.690458536148, "episode/length": 34.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 415704, "time": 20783.200758695602, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 415856, "time": 20790.362718820572, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 416104, "time": 20800.824890851974, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 416152, "time": 20804.15217232704, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 416312, "time": 20811.544464349747, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 416400, "time": 20816.65479159355, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 416408, "time": 20818.248626232147, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 416712, "time": 20831.121679782867, "episode/length": 154.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 417080, "time": 20846.207119703293, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 417272, "time": 20854.86286520958, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 417456, "time": 20863.385073184967, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 417536, "time": 20867.780438184738, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 417952, "time": 20886.16707801819, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 417984, "time": 20888.8943297863, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 418096, "time": 20894.498332738876, "episode/length": 211.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 418096, "time": 20894.551491975784, "episode/length": 242.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 418504, "time": 20912.336707115173, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 418616, "time": 20917.959858179092, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 418656, "time": 20921.13134932518, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 418872, "time": 20930.485992193222, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 419304, "time": 20947.875163793564, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 419424, "time": 20954.074318647385, "episode/length": 183.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 419472, "time": 20957.545351982117, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 419512, "time": 20960.412068128586, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 419776, "time": 20971.85985636711, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 419936, "time": 20979.340539693832, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 20999.283928394318, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.868421052631579}
{"step": 420056, "time": 21001.434554815292, "eval_episode/length": 52.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 420056, "time": 21007.543794870377, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 420056, "time": 21009.396362543106, "eval_episode/length": 176.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 420056, "time": 21011.65415406227, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 420056, "time": 21013.310995817184, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 420056, "time": 21014.93137693405, "eval_episode/length": 163.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 420056, "time": 21016.709176778793, "eval_episode/length": 207.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 420064, "time": 21017.228539705276, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 420072, "time": 21018.79505085945, "episode/length": 149.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 420184, "time": 21024.539077043533, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 420704, "time": 21045.137726783752, "episode/length": 174.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 420800, "time": 21050.218590021133, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 420832, "time": 21053.071301937103, "episode/length": 111.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 421024, "time": 21061.594440221786, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 421048, "time": 21063.81350183487, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 421296, "time": 21074.915776252747, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 421384, "time": 21079.479245185852, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 421512, "time": 21085.697964429855, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 421744, "time": 21096.08708500862, "episode/length": 245.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 422176, "time": 21113.288131713867, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 422240, "time": 21117.157658576965, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 422408, "time": 21124.59671998024, "episode/length": 82.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 422760, "time": 21139.090888261795, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 422896, "time": 21145.925419330597, "episode/length": 199.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 423056, "time": 21153.30540919304, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 423448, "time": 21169.09539747238, "episode/length": 241.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 423456, "time": 21171.195249080658, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 423696, "time": 21181.679419994354, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 424072, "time": 21196.776077985764, "episode/length": 408.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9902200488997555, "episode/intrinsic_return": 0.0}
{"step": 424144, "time": 21201.219289541245, "episode/length": 155.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 424184, "time": 21203.94695544243, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 424360, "time": 21211.89275407791, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 424368, "time": 21213.96701478958, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 424704, "time": 21227.803388357162, "episode/length": 156.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 424792, "time": 21232.372804641724, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 425344, "time": 21254.521518468857, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 425552, "time": 21263.747730970383, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 425624, "time": 21267.72022294998, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 425688, "time": 21271.559672117233, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 425904, "time": 21281.311936855316, "episode/length": 191.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 426216, "time": 21295.372079133987, "episode/length": 188.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 426297, "time": 21300.926782369614, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.761425589013287, "train/action_min": 0.0, "train/action_std": 3.8404187968396766, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0470203628514226, "train/actor_opt_grad_steps": 25910.0, "train/actor_opt_loss": -1.8153872408970135, "train/adv_mag": 0.6745199425013986, "train/adv_max": 0.6456942112427059, "train/adv_mean": 0.004233401399752317, "train/adv_min": -0.49912924419237875, "train/adv_std": 0.07191559965685597, "train/cont_avg": 0.9944405142716536, "train/cont_loss_mean": 0.0001881281318739055, "train/cont_loss_std": 0.005720983091325876, "train/cont_neg_acc": 0.9921041126326313, "train/cont_neg_loss": 0.021612160985080297, "train/cont_pos_acc": 0.999969041722966, "train/cont_pos_loss": 7.358171962362463e-05, "train/cont_pred": 0.9944466591820004, "train/cont_rate": 0.9944405142716536, "train/dyn_loss_mean": 13.014892187644177, "train/dyn_loss_std": 9.069818594324307, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8527292402710501, "train/extr_critic_critic_opt_grad_steps": 25910.0, "train/extr_critic_critic_opt_loss": 16043.597064160926, "train/extr_critic_mag": 5.483072370994748, "train/extr_critic_max": 5.483072370994748, "train/extr_critic_mean": 1.2075345201755132, "train/extr_critic_min": -0.30889342525812585, "train/extr_critic_std": 1.2179835255690448, "train/extr_return_normed_mag": 1.731285332694767, "train/extr_return_normed_max": 1.731285332694767, "train/extr_return_normed_mean": 0.32545672157618005, "train/extr_return_normed_min": -0.18541649828745624, "train/extr_return_normed_std": 0.3302655641253539, "train/extr_return_rate": 0.5893516538180704, "train/extr_return_raw_mag": 6.5606469544838735, "train/extr_return_raw_max": 6.5606469544838735, "train/extr_return_raw_mean": 1.2236218968714316, "train/extr_return_raw_min": -0.7158490942688439, "train/extr_return_raw_std": 1.2540688894865082, "train/extr_reward_mag": 1.0162798166275024, "train/extr_reward_max": 1.0162798166275024, "train/extr_reward_mean": 0.027887025569367598, "train/extr_reward_min": -0.5046258113515658, "train/extr_reward_std": 0.15551529373005618, "train/image_loss_mean": 6.783446863880307, "train/image_loss_std": 10.993375789462112, "train/model_loss_mean": 14.644923067468358, "train/model_loss_std": 14.746218846538873, "train/model_opt_grad_norm": 62.05309638075941, "train/model_opt_grad_steps": 25886.43307086614, "train/model_opt_loss": 18306.153750922735, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.54654145616246, "train/policy_entropy_max": 2.54654145616246, "train/policy_entropy_mean": 0.6204751213704507, "train/policy_entropy_min": 0.07937511590522105, "train/policy_entropy_std": 0.6881123907922759, "train/policy_logprob_mag": 7.438383335203636, "train/policy_logprob_max": -0.009455660358071327, "train/policy_logprob_mean": -0.6190126442064451, "train/policy_logprob_min": -7.438383335203636, "train/policy_logprob_std": 1.142387968348706, "train/policy_randomness_mag": 0.8988173829288933, "train/policy_randomness_max": 0.8988173829288933, "train/policy_randomness_mean": 0.2190004900449843, "train/policy_randomness_min": 0.028015932596222624, "train/policy_randomness_std": 0.2428734778888582, "train/post_ent_mag": 58.18984318530466, "train/post_ent_max": 58.18984318530466, "train/post_ent_mean": 40.68098665973333, "train/post_ent_min": 20.336569838636503, "train/post_ent_std": 7.306372206980788, "train/prior_ent_mag": 66.54369606558733, "train/prior_ent_max": 66.54369606558733, "train/prior_ent_mean": 53.753661058080475, "train/prior_ent_min": 36.59770315275418, "train/prior_ent_std": 4.670065714618352, "train/rep_loss_mean": 13.014892187644177, "train/rep_loss_std": 9.069818594324307, "train/reward_avg": 0.02324295629871877, "train/reward_loss_mean": 0.05235274015801159, "train/reward_loss_std": 0.23937914514635492, "train/reward_max_data": 1.0125984282005491, "train/reward_max_pred": 1.0066889055131927, "train/reward_neg_acc": 0.9928285578104454, "train/reward_neg_loss": 0.02864427578554848, "train/reward_pos_acc": 0.9598829239372193, "train/reward_pos_loss": 0.8770033055403101, "train/reward_pred": 0.022448573173500422, "train/reward_rate": 0.028281865157480313, "train_stats/sum_log_reward": 5.894642835749047, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.428571428571429, "train_stats/max_log_achievement_collect_sapling": 2.330357142857143, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.294642857142858, "train_stats/max_log_achievement_defeat_skeleton": 0.017857142857142856, "train_stats/max_log_achievement_defeat_zombie": 0.49107142857142855, "train_stats/max_log_achievement_eat_cow": 0.16071428571428573, "train_stats/max_log_achievement_eat_plant": 0.008928571428571428, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008928571428571428, "train_stats/max_log_achievement_make_wood_sword": 1.4285714285714286, "train_stats/max_log_achievement_place_plant": 2.2589285714285716, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.9196428571428572, "train_stats/max_log_achievement_wake_up": 2.3035714285714284, "train_stats/mean_log_entropy": 0.5577888788123216, "eval_stats/sum_log_reward": 5.099999985657632, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.110846020921599e-06, "report/cont_loss_std": 6.948810914764181e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000642910657916218, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.4581813679324114e-07, "report/cont_pred": 0.994144082069397, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.7105131149292, "report/dyn_loss_std": 9.040216445922852, "report/image_loss_mean": 6.660161972045898, "report/image_loss_std": 9.476551055908203, "report/model_loss_mean": 14.928221702575684, "report/model_loss_std": 13.224275588989258, "report/post_ent_mag": 58.781681060791016, "report/post_ent_max": 58.781681060791016, "report/post_ent_mean": 41.28800964355469, "report/post_ent_min": 21.557735443115234, "report/post_ent_std": 7.771427154541016, "report/prior_ent_mag": 66.73637390136719, "report/prior_ent_max": 66.73637390136719, "report/prior_ent_mean": 54.959266662597656, "report/prior_ent_min": 40.178096771240234, "report/prior_ent_std": 4.27182149887085, "report/rep_loss_mean": 13.7105131149292, "report/rep_loss_std": 9.040216445922852, "report/reward_avg": 0.02011718600988388, "report/reward_loss_mean": 0.041748497635126114, "report/reward_loss_std": 0.17777708172798157, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9986793994903564, "report/reward_neg_acc": 0.9929929971694946, "report/reward_neg_loss": 0.024677826091647148, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7238925099372864, "report/reward_pred": 0.019825568422675133, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 7.829305104678497e-05, "eval/cont_loss_std": 0.001772091374732554, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006531985709443688, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.433597784256563e-05, "eval/cont_pred": 0.9930962920188904, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 17.515823364257812, "eval/dyn_loss_std": 10.342389106750488, "eval/image_loss_mean": 12.615757942199707, "eval/image_loss_std": 17.377777099609375, "eval/model_loss_mean": 23.199230194091797, "eval/model_loss_std": 21.986480712890625, "eval/post_ent_mag": 58.32921600341797, "eval/post_ent_max": 58.32921600341797, "eval/post_ent_mean": 39.54085922241211, "eval/post_ent_min": 20.583799362182617, "eval/post_ent_std": 7.020559310913086, "eval/prior_ent_mag": 66.73637390136719, "eval/prior_ent_max": 66.73637390136719, "eval/prior_ent_mean": 54.63276290893555, "eval/prior_ent_min": 34.61933898925781, "eval/prior_ent_std": 4.4512152671813965, "eval/rep_loss_mean": 17.515823364257812, "eval/rep_loss_std": 10.342389106750488, "eval/reward_avg": 0.02021484449505806, "eval/reward_loss_mean": 0.07389914989471436, "eval/reward_loss_std": 0.4772069454193115, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9998137950897217, "eval/reward_neg_acc": 0.9909729361534119, "eval/reward_neg_loss": 0.03430033475160599, "eval/reward_pos_acc": 0.8148148059844971, "eval/reward_pos_loss": 1.5361218452453613, "eval/reward_pred": 0.015932150185108185, "eval/reward_rate": 0.0263671875, "replay/size": 425793.0, "replay/inserts": 20352.0, "replay/samples": 20352.0, "replay/insert_wait_avg": 1.3661740710900265e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.85637951497012e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 79224.0, "eval_replay/inserts": 3168.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1312088581046672e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0398654937744, "timer/env.step_count": 2544.0, "timer/env.step_total": 245.90287065505981, "timer/env.step_frac": 0.24589306800648802, "timer/env.step_avg": 0.09665993343359269, "timer/env.step_min": 0.023195743560791016, "timer/env.step_max": 3.4445641040802, "timer/replay._sample_count": 20352.0, "timer/replay._sample_total": 10.470225811004639, "timer/replay._sample_frac": 0.010469808426921976, "timer/replay._sample_avg": 0.0005144568499904009, "timer/replay._sample_min": 0.0004096031188964844, "timer/replay._sample_max": 0.017570018768310547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2940.0, "timer/agent.policy_total": 48.40536570549011, "timer/agent.policy_frac": 0.04840343607861046, "timer/agent.policy_avg": 0.0164644101039082, "timer/agent.policy_min": 0.009422063827514648, "timer/agent.policy_max": 0.0976259708404541, "timer/dataset_train_count": 1272.0, "timer/dataset_train_total": 0.1490645408630371, "timer/dataset_train_frac": 0.00014905859856840386, "timer/dataset_train_avg": 0.0001171891044520732, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.00035953521728515625, "timer/agent.train_count": 1272.0, "timer/agent.train_total": 566.6774959564209, "timer/agent.train_frac": 0.5666549059787943, "timer/agent.train_avg": 0.44550117606636863, "timer/agent.train_min": 0.4321436882019043, "timer/agent.train_max": 1.1588771343231201, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.466965913772583, "timer/agent.report_frac": 0.0004669472986879542, "timer/agent.report_avg": 0.2334829568862915, "timer/agent.report_min": 0.22211217880249023, "timer/agent.report_max": 0.24485373497009277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8370679901922932e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 20.350928485311307}
{"step": 426656, "time": 21314.217753648758, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 426712, "time": 21317.621527194977, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 426928, "time": 21327.261423110962, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 427032, "time": 21332.310532331467, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 427456, "time": 21349.66997909546, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 427576, "time": 21355.51644706726, "episode/length": 208.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 427840, "time": 21367.033941745758, "episode/length": 517.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9884169884169884, "episode/intrinsic_return": 0.0}
{"step": 427984, "time": 21373.79837322235, "episode/length": 165.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 428056, "time": 21377.771484375, "episode/length": 140.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 428304, "time": 21388.603429079056, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 428392, "time": 21393.138288021088, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 428432, "time": 21396.43692088127, "episode/length": 350.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 428656, "time": 21406.111356019974, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 429088, "time": 21423.421463251114, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 429104, "time": 21425.56196117401, "episode/length": 157.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 429248, "time": 21432.38751578331, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 429376, "time": 21438.60078907013, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 429552, "time": 21446.648257493973, "episode/length": 155.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 429920, "time": 21461.596821308136, "episode/length": 157.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 430032, "time": 21467.183602809906, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 21484.800304174423, "eval_episode/length": 86.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9425287356321839}
{"step": 430040, "time": 21489.04658985138, "eval_episode/length": 154.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.967741935483871}
{"step": 430040, "time": 21491.302719831467, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 430040, "time": 21493.87301683426, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 430040, "time": 21495.879851341248, "eval_episode/length": 204.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 430040, "time": 21498.25433945656, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 430040, "time": 21500.2454931736, "eval_episode/length": 237.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9747899159663865}
{"step": 430040, "time": 21502.26545071602, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 430072, "time": 21503.429938077927, "episode/length": 209.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 430608, "time": 21525.15653204918, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 430784, "time": 21533.05018544197, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 431120, "time": 21546.91539120674, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 431280, "time": 21554.3039021492, "episode/length": 271.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 431496, "time": 21563.586693048477, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 431512, "time": 21565.75197839737, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 432184, "time": 21592.125271081924, "episode/length": 328.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9848024316109423, "episode/intrinsic_return": 0.0}
{"step": 432256, "time": 21596.988860607147, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 432680, "time": 21614.8149664402, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 432688, "time": 21617.239859580994, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 432992, "time": 21630.373482465744, "episode/length": 275.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 433008, "time": 21632.456610441208, "episode/length": 39.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 433104, "time": 21637.615963459015, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 433584, "time": 21656.692791461945, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 433624, "time": 21659.511984586716, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 433640, "time": 21661.640169620514, "episode/length": 267.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 434120, "time": 21680.782238960266, "episode/length": 179.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 434224, "time": 21687.768738508224, "episode/length": 537.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9925650557620818, "episode/intrinsic_return": 0.0}
{"step": 434376, "time": 21694.621734380722, "episode/length": 158.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 434552, "time": 21702.76544070244, "episode/length": 53.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 434752, "time": 21711.748039722443, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 434856, "time": 21716.837168455124, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 434888, "time": 21719.537997961044, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 434904, "time": 21721.7461810112, "episode/length": 164.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 435160, "time": 21732.77673435211, "episode/length": 37.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 435248, "time": 21737.82332921028, "episode/length": 200.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 435472, "time": 21747.439709424973, "episode/length": 27.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 435736, "time": 21758.38153529167, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 436032, "time": 21770.813940525055, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 436152, "time": 21776.6388463974, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 436416, "time": 21788.153223752975, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 436488, "time": 21792.113694429398, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 436752, "time": 21803.45719385147, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 436760, "time": 21805.102838993073, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 436784, "time": 21807.75204706192, "episode/length": 236.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 437312, "time": 21828.5619764328, "episode/length": 196.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 437320, "time": 21830.096933841705, "episode/length": 103.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 437704, "time": 21845.566326141357, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 437840, "time": 21852.379309892654, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 437936, "time": 21857.437898874283, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 438080, "time": 21864.106499910355, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 438096, "time": 21866.295795440674, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 438496, "time": 21882.484718322754, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 438816, "time": 21895.653553009033, "episode/length": 39.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 438888, "time": 21899.6390645504, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 439080, "time": 21908.271978616714, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 439160, "time": 21912.729041337967, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 439344, "time": 21921.25392627716, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 439496, "time": 21928.141569375992, "episode/length": 51.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 439584, "time": 21933.074120521545, "episode/length": 187.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 439704, "time": 21938.856628656387, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 439712, "time": 21940.94965314865, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 21971.163432836533, "eval_episode/length": 89.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 440024, "time": 21974.279718875885, "eval_episode/length": 40.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.975609756097561}
{"step": 440024, "time": 21976.177438259125, "eval_episode/length": 141.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 440024, "time": 21978.058371543884, "eval_episode/length": 150.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 440024, "time": 21980.302571058273, "eval_episode/length": 171.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 440024, "time": 21982.367163419724, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 440024, "time": 21984.885202646255, "eval_episode/length": 212.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 440024, "time": 21987.281469106674, "eval_episode/length": 232.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 440528, "time": 22006.039528608322, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 440568, "time": 22009.317413568497, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 440616, "time": 22013.106950759888, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 440904, "time": 22025.11131811142, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 440952, "time": 22028.578971385956, "episode/length": 41.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 441104, "time": 22035.884001493454, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 441168, "time": 22040.235476017, "episode/length": 181.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 441232, "time": 22044.58486700058, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 441312, "time": 22049.539150476456, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 441592, "time": 22061.901426315308, "episode/length": 44.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 442072, "time": 22081.999589920044, "episode/length": 94.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 442176, "time": 22088.22575378418, "episode/length": 205.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 442248, "time": 22092.645924806595, "episode/length": 209.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 442272, "time": 22095.747673988342, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 442608, "time": 22111.81876349449, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 442680, "time": 22116.330745220184, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 442728, "time": 22120.217933177948, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 443240, "time": 22141.463000774384, "episode/length": 205.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 443456, "time": 22151.885283231735, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 443712, "time": 22163.499499320984, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 443960, "time": 22174.511899471283, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 443992, "time": 22177.85208106041, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 444088, "time": 22183.474236249924, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 444224, "time": 22190.62975549698, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 444824, "time": 22215.00798368454, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 444848, "time": 22218.124297618866, "episode/length": 200.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 445248, "time": 22235.082982301712, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 445312, "time": 22239.7123131752, "episode/length": 168.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 445328, "time": 22242.33047890663, "episode/length": 166.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 445600, "time": 22254.481462717056, "episode/length": 427.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 445736, "time": 22261.379247426987, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 445872, "time": 22268.89940595627, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 446064, "time": 22278.108466386795, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 446384, "time": 22292.06942152977, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 446424, "time": 22294.97369003296, "episode/length": 196.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 446520, "time": 22300.215929985046, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 446521, "time": 22302.929052591324, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.69817154050812, "train/action_min": 0.0, "train/action_std": 3.7279958462151956, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046746203426535675, "train/actor_opt_grad_steps": 27180.0, "train/actor_opt_loss": -0.21323396371105524, "train/adv_mag": 0.6871790151427112, "train/adv_max": 0.6488457225908445, "train/adv_mean": 0.004866540596243952, "train/adv_min": -0.5056008346906797, "train/adv_std": 0.07171779348859637, "train/cont_avg": 0.9945250984251969, "train/cont_loss_mean": 0.00024322448654774643, "train/cont_loss_std": 0.0072378916794565784, "train/cont_neg_acc": 0.9913854533293116, "train/cont_neg_loss": 0.023700526324920628, "train/cont_pos_acc": 0.9999767565351771, "train/cont_pos_loss": 8.846352677507207e-05, "train/cont_pred": 0.9945471582450266, "train/cont_rate": 0.9945250984251969, "train/dyn_loss_mean": 12.992831838412547, "train/dyn_loss_std": 9.048933400882511, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8543400121486093, "train/extr_critic_critic_opt_grad_steps": 27180.0, "train/extr_critic_critic_opt_loss": 16193.80046598179, "train/extr_critic_mag": 5.599038341852624, "train/extr_critic_max": 5.599038341852624, "train/extr_critic_mean": 1.3317303183510547, "train/extr_critic_min": -0.2883446347995067, "train/extr_critic_std": 1.25561840984765, "train/extr_return_normed_mag": 1.7302494968954973, "train/extr_return_normed_max": 1.7302494968954973, "train/extr_return_normed_mean": 0.34580109638022627, "train/extr_return_normed_min": -0.1696460305705784, "train/extr_return_normed_std": 0.3321037561170698, "train/extr_return_rate": 0.6343309487414173, "train/extr_return_raw_mag": 6.754651861866628, "train/extr_return_raw_max": 6.754651861866628, "train/extr_return_raw_mean": 1.350720625693404, "train/extr_return_raw_min": -0.6604981907005385, "train/extr_return_raw_std": 1.2963012372414897, "train/extr_reward_mag": 1.0152040560414473, "train/extr_reward_max": 1.0152040560414473, "train/extr_reward_mean": 0.029567636769470267, "train/extr_reward_min": -0.4864474459895937, "train/extr_reward_std": 0.1598362970774568, "train/image_loss_mean": 6.601003729452298, "train/image_loss_std": 10.456918641338198, "train/model_loss_mean": 14.450225867624358, "train/model_loss_std": 14.24850823560099, "train/model_opt_grad_norm": 59.36600153786795, "train/model_opt_grad_steps": 27155.283464566928, "train/model_opt_loss": 19323.160233144685, "train/model_opt_model_opt_grad_overflow": 0.007874015748031496, "train/model_opt_model_opt_grad_scale": 1328.740157480315, "train/policy_entropy_mag": 2.5489429751719075, "train/policy_entropy_max": 2.5489429751719075, "train/policy_entropy_mean": 0.5839550692265428, "train/policy_entropy_min": 0.07937509144150366, "train/policy_entropy_std": 0.668325599253647, "train/policy_logprob_mag": 7.4383834440877115, "train/policy_logprob_max": -0.009455658495426178, "train/policy_logprob_mean": -0.5840608829588402, "train/policy_logprob_min": -7.4383834440877115, "train/policy_logprob_std": 1.1266513058519738, "train/policy_randomness_mag": 0.8996650135423255, "train/policy_randomness_max": 0.8996650135423255, "train/policy_randomness_mean": 0.20611051475907874, "train/policy_randomness_min": 0.028015923913656256, "train/policy_randomness_std": 0.23588960740979262, "train/post_ent_mag": 57.92635790006382, "train/post_ent_max": 57.92635790006382, "train/post_ent_mean": 40.82533444382074, "train/post_ent_min": 20.562640978595404, "train/post_ent_std": 7.325397209858331, "train/prior_ent_mag": 66.59302190345103, "train/prior_ent_max": 66.59302190345103, "train/prior_ent_mean": 53.85910349568044, "train/prior_ent_min": 37.564205890565404, "train/prior_ent_std": 4.5653453004641795, "train/rep_loss_mean": 12.992831838412547, "train/rep_loss_std": 9.048933400882511, "train/reward_avg": 0.024901574407887504, "train/reward_loss_mean": 0.053279917657844664, "train/reward_loss_std": 0.2502197200857748, "train/reward_max_data": 1.0133858299630834, "train/reward_max_pred": 1.0085612741980965, "train/reward_neg_acc": 0.9930493479638588, "train/reward_neg_loss": 0.027807776405527368, "train/reward_pos_acc": 0.9574420010949684, "train/reward_pos_loss": 0.884403125976953, "train/reward_pred": 0.02406458612751421, "train/reward_rate": 0.029865895669291338, "train_stats/sum_log_reward": 6.008256815989083, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.954128440366972, "train_stats/max_log_achievement_collect_sapling": 2.81651376146789, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.788990825688073, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.44954128440366975, "train_stats/max_log_achievement_eat_cow": 0.1651376146788991, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 1.834862385321101, "train_stats/max_log_achievement_place_plant": 2.7522935779816513, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.3577981651376145, "train_stats/max_log_achievement_wake_up": 2.2477064220183487, "train_stats/mean_log_entropy": 0.5556035473806049, "eval_stats/sum_log_reward": 6.224999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.964531970268581e-06, "report/cont_loss_std": 4.5873905037296936e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00031784834573045373, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4243763618869707e-06, "report/cont_pred": 0.9951163530349731, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.554662704467773, "report/dyn_loss_std": 9.350764274597168, "report/image_loss_mean": 6.835732460021973, "report/image_loss_std": 11.797745704650879, "report/model_loss_mean": 15.623531341552734, "report/model_loss_std": 15.40648078918457, "report/post_ent_mag": 58.585662841796875, "report/post_ent_max": 58.585662841796875, "report/post_ent_mean": 40.470340728759766, "report/post_ent_min": 21.373151779174805, "report/post_ent_std": 7.696897029876709, "report/prior_ent_mag": 66.43882751464844, "report/prior_ent_max": 66.43882751464844, "report/prior_ent_mean": 54.74359893798828, "report/prior_ent_min": 40.53066635131836, "report/prior_ent_std": 4.040666580200195, "report/rep_loss_mean": 14.554662704467773, "report/rep_loss_std": 9.350764274597168, "report/reward_avg": 0.02783203125, "report/reward_loss_mean": 0.05499817430973053, "report/reward_loss_std": 0.2347874790430069, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0081448554992676, "report/reward_neg_acc": 0.9888888001441956, "report/reward_neg_loss": 0.03024454228579998, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.7757657170295715, "report/reward_pred": 0.03033934161067009, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.4059976062271744e-05, "eval/cont_loss_std": 0.0007168278098106384, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002259589673485607, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.2987878259737045e-05, "eval/cont_pred": 0.994099497795105, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.2696533203125, "eval/dyn_loss_std": 10.24319839477539, "eval/image_loss_mean": 11.391923904418945, "eval/image_loss_std": 15.644344329833984, "eval/model_loss_mean": 21.268310546875, "eval/model_loss_std": 19.89004898071289, "eval/post_ent_mag": 58.89673614501953, "eval/post_ent_max": 58.89673614501953, "eval/post_ent_mean": 40.55322265625, "eval/post_ent_min": 22.503028869628906, "eval/post_ent_std": 7.6580939292907715, "eval/prior_ent_mag": 66.43882751464844, "eval/prior_ent_max": 66.43882751464844, "eval/prior_ent_mean": 54.85700225830078, "eval/prior_ent_min": 42.73624801635742, "eval/prior_ent_std": 3.9328765869140625, "eval/rep_loss_mean": 16.2696533203125, "eval/rep_loss_std": 10.24319839477539, "eval/reward_avg": 0.02812499925494194, "eval/reward_loss_mean": 0.1145513653755188, "eval/reward_loss_std": 0.6901782155036926, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.9999445676803589, "eval/reward_neg_acc": 0.9858585000038147, "eval/reward_neg_loss": 0.050973206758499146, "eval/reward_pos_acc": 0.8529411554336548, "eval/reward_pos_loss": 1.9657974243164062, "eval/reward_pred": 0.02432139217853546, "eval/reward_rate": 0.033203125, "replay/size": 446017.0, "replay/inserts": 20224.0, "replay/samples": 20224.0, "replay/insert_wait_avg": 1.3693742736985412e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.747189153598834e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83080.0, "eval_replay/inserts": 3856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0984814513273754e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.9906709194183, "timer/env.step_count": 2528.0, "timer/env.step_total": 253.89339208602905, "timer/env.step_frac": 0.2533889780161911, "timer/env.step_avg": 0.10043251269225832, "timer/env.step_min": 0.023615121841430664, "timer/env.step_max": 2.2528865337371826, "timer/replay._sample_count": 20224.0, "timer/replay._sample_total": 10.339237928390503, "timer/replay._sample_frac": 0.010318696798746942, "timer/replay._sample_avg": 0.0005112360526300684, "timer/replay._sample_min": 0.0003924369812011719, "timer/replay._sample_max": 0.0074634552001953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3010.0, "timer/agent.policy_total": 50.87208032608032, "timer/agent.policy_frac": 0.05077101194904392, "timer/agent.policy_avg": 0.016901023364146287, "timer/agent.policy_min": 0.009165048599243164, "timer/agent.policy_max": 0.10595440864562988, "timer/dataset_train_count": 1264.0, "timer/dataset_train_total": 0.14912748336791992, "timer/dataset_train_frac": 0.00014883120940745065, "timer/dataset_train_avg": 0.00011798060393031639, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.00042247772216796875, "timer/agent.train_count": 1264.0, "timer/agent.train_total": 562.2926254272461, "timer/agent.train_frac": 0.5611755096594772, "timer/agent.train_avg": 0.4448517606228213, "timer/agent.train_min": 0.4327385425567627, "timer/agent.train_max": 1.1890475749969482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46980977058410645, "timer/agent.report_frac": 0.00046887639198577854, "timer/agent.report_avg": 0.23490488529205322, "timer/agent.report_min": 0.22905755043029785, "timer/agent.report_max": 0.2407522201538086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.593599509087673e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 20.183571122831466}
{"step": 446672, "time": 22308.47661972046, "episode/length": 167.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 446864, "time": 22317.267114400864, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 447048, "time": 22326.204689502716, "episode/length": 46.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 447168, "time": 22332.86136007309, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 447208, "time": 22336.1834089756, "episode/length": 85.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 447304, "time": 22341.731068372726, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 447456, "time": 22349.68238735199, "episode/length": 275.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 447496, "time": 22353.09153532982, "episode/length": 40.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 447616, "time": 22359.839760541916, "episode/length": 148.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 448032, "time": 22377.57171368599, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 448312, "time": 22389.963137626648, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 448600, "time": 22402.701234579086, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 448800, "time": 22411.743679523468, "episode/length": 218.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 448840, "time": 22414.506311416626, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 448848, "time": 22416.645116329193, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 448856, "time": 22418.38484120369, "episode/length": 174.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 449136, "time": 22430.30970287323, "episode/length": 189.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 449328, "time": 22438.9237678051, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 449528, "time": 22447.5513818264, "episode/length": 48.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 449736, "time": 22457.008055210114, "episode/length": 25.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 449816, "time": 22461.956365823746, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 449928, "time": 22468.00426697731, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 22486.61618423462, "eval_episode/length": 36.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.972972972972973}
{"step": 450008, "time": 22493.671149492264, "eval_episode/length": 173.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 450008, "time": 22495.356204032898, "eval_episode/length": 176.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 450008, "time": 22497.15159010887, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 450008, "time": 22498.74609375, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 450008, "time": 22500.324540376663, "eval_episode/length": 186.0, "eval_episode/score": 6.1000000461936, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 450008, "time": 22502.92660355568, "eval_episode/length": 176.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 450008, "time": 22505.782698631287, "eval_episode/length": 241.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 450336, "time": 22517.92459487915, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 450344, "time": 22519.480639219284, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 450504, "time": 22526.8728890419, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 450672, "time": 22536.310044527054, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 450960, "time": 22548.2072994709, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 451344, "time": 22563.658366680145, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 451408, "time": 22567.710917711258, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 451640, "time": 22577.556092500687, "episode/length": 36.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 451808, "time": 22585.402475833893, "episode/length": 183.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 451904, "time": 22590.39828324318, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 452040, "time": 22596.77967762947, "episode/length": 170.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 452304, "time": 22608.085624933243, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 452592, "time": 22620.073823451996, "episode/length": 260.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 452640, "time": 22623.329697847366, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 452728, "time": 22627.958611011505, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 452904, "time": 22635.944083452225, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 452912, "time": 22638.032550096512, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 452968, "time": 22641.47235107422, "episode/length": 40.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 453256, "time": 22653.53694844246, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 453272, "time": 22655.637843847275, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 453352, "time": 22660.11918401718, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 454280, "time": 22695.54681110382, "episode/length": 171.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 454304, "time": 22698.15276169777, "episode/length": 282.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 454440, "time": 22704.59260892868, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 454472, "time": 22707.884785413742, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 454528, "time": 22712.28368115425, "episode/length": 158.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 454576, "time": 22715.66351866722, "episode/length": 230.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 454616, "time": 22718.428425073624, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 454872, "time": 22729.224828720093, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 455432, "time": 22751.12861943245, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 455584, "time": 22758.343314647675, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 455728, "time": 22765.055671453476, "episode/length": 160.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 456064, "time": 22778.77751517296, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 456128, "time": 22782.700545310974, "episode/length": 188.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 456184, "time": 22786.110933303833, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 456184, "time": 22786.163016557693, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 456712, "time": 22808.639311790466, "episode/length": 72.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9315068493150684, "episode/intrinsic_return": 0.0}
{"step": 456720, "time": 22810.66226029396, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 456824, "time": 22815.760790109634, "episode/length": 173.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 457064, "time": 22825.928565740585, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 457312, "time": 22836.748408555984, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 457344, "time": 22839.490649461746, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 457488, "time": 22846.317322969437, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 458072, "time": 22869.01822733879, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 458312, "time": 22879.32257413864, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 458408, "time": 22884.30589580536, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 458416, "time": 22886.34245824814, "episode/length": 198.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 458568, "time": 22893.17479991913, "episode/length": 134.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 458824, "time": 22905.72975754738, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 459296, "time": 22924.576775550842, "episode/length": 152.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 459608, "time": 22937.60973215103, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 459648, "time": 22940.903259277344, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 459688, "time": 22943.691031217575, "episode/length": 48.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 459776, "time": 22948.681814432144, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 459928, "time": 22955.671255350113, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 459936, "time": 22957.799344062805, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 22983.28878045082, "eval_episode/length": 140.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 460096, "time": 22986.031158208847, "eval_episode/length": 167.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 460096, "time": 22988.043753147125, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 460096, "time": 22989.688004493713, "eval_episode/length": 180.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 460096, "time": 22991.63713002205, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 460096, "time": 22995.300124406815, "eval_episode/length": 247.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 460096, "time": 22998.789136886597, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 460096, "time": 23001.44538116455, "eval_episode/length": 144.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 460184, "time": 23004.433685541153, "episode/length": 433.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 460328, "time": 23011.367480039597, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 461008, "time": 23038.44680070877, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 461184, "time": 23047.29353451729, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 461424, "time": 23058.383519411087, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 461480, "time": 23062.17258810997, "episode/length": 161.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 461480, "time": 23062.22244668007, "episode/length": 58.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 461536, "time": 23068.97571992874, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 461936, "time": 23086.135744810104, "episode/length": 269.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 462728, "time": 23117.908665895462, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 462856, "time": 23124.838734149933, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 462912, "time": 23129.197196483612, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 463032, "time": 23135.620269298553, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 463200, "time": 23144.24334692955, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 463472, "time": 23156.451048374176, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 463488, "time": 23158.634590148926, "episode/length": 394.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9924050632911392, "episode/intrinsic_return": 0.0}
{"step": 463736, "time": 23168.95774292946, "episode/length": 224.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 464080, "time": 23183.394115924835, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 464384, "time": 23196.133645296097, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 464448, "time": 23200.02081131935, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 464528, "time": 23204.451080322266, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 464912, "time": 23219.953281641006, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 464960, "time": 23223.27230000496, "episode/length": 109.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 465088, "time": 23229.605164289474, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 465112, "time": 23231.73570919037, "episode/length": 274.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 465896, "time": 23261.89804983139, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 465968, "time": 23266.356678009033, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 466144, "time": 23274.323801994324, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 466440, "time": 23287.76876807213, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 466456, "time": 23289.971114635468, "episode/length": 240.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 466576, "time": 23296.082941532135, "episode/length": 207.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 466608, "time": 23298.888324022293, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 466665, "time": 23303.245074033737, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.610558403862847, "train/action_min": 0.0, "train/action_std": 3.596624928807455, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04626794966558615, "train/actor_opt_grad_steps": 28445.0, "train/actor_opt_loss": -5.869824379209488, "train/adv_mag": 0.6577001568816957, "train/adv_max": 0.6262605483569796, "train/adv_mean": 0.0029403977887052443, "train/adv_min": -0.48594040766594904, "train/adv_std": 0.0689097840693735, "train/cont_avg": 0.9945436507936508, "train/cont_loss_mean": 0.0002031069627462113, "train/cont_loss_std": 0.006118896801225789, "train/cont_neg_acc": 0.995811287845884, "train/cont_neg_loss": 0.007441676946243769, "train/cont_pos_acc": 0.9999765905122908, "train/cont_pos_loss": 0.00015900666851070215, "train/cont_pred": 0.9945143541646382, "train/cont_rate": 0.9945436507936508, "train/dyn_loss_mean": 13.0327744181194, "train/dyn_loss_std": 9.013943240756081, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8089474089561947, "train/extr_critic_critic_opt_grad_steps": 28445.0, "train/extr_critic_critic_opt_loss": 15906.142919146825, "train/extr_critic_mag": 5.690113506619892, "train/extr_critic_max": 5.690113506619892, "train/extr_critic_mean": 1.3863200020222437, "train/extr_critic_min": -0.2920289645119319, "train/extr_critic_std": 1.287529778858972, "train/extr_return_normed_mag": 1.7101048609567067, "train/extr_return_normed_max": 1.7101048609567067, "train/extr_return_normed_mean": 0.3458580541468802, "train/extr_return_normed_min": -0.1622886885962789, "train/extr_return_normed_std": 0.33088347173872446, "train/extr_return_rate": 0.6585457296598525, "train/extr_return_raw_mag": 6.8470336898924815, "train/extr_return_raw_max": 6.8470336898924815, "train/extr_return_raw_mean": 1.3980624060782174, "train/extr_return_raw_min": -0.6316109027654405, "train/extr_return_raw_std": 1.3216336833106146, "train/extr_reward_mag": 1.0164821904803079, "train/extr_reward_max": 1.0164821904803079, "train/extr_reward_mean": 0.029058525752690103, "train/extr_reward_min": -0.44215902260371615, "train/extr_reward_std": 0.15928032941051892, "train/image_loss_mean": 6.690724751305958, "train/image_loss_std": 10.576323274582151, "train/model_loss_mean": 14.563873487805564, "train/model_loss_std": 14.286080057658847, "train/model_opt_grad_norm": 57.6812671176971, "train/model_opt_grad_steps": 28419.007936507936, "train/model_opt_loss": 18788.170092385913, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1299.6031746031747, "train/policy_entropy_mag": 2.577399902873569, "train/policy_entropy_max": 2.577399902873569, "train/policy_entropy_mean": 0.5984816518094804, "train/policy_entropy_min": 0.07937508969316406, "train/policy_entropy_std": 0.6834649978175996, "train/policy_logprob_mag": 7.438383427877275, "train/policy_logprob_max": -0.009455661318959698, "train/policy_logprob_mean": -0.5972072167529, "train/policy_logprob_min": -7.438383427877275, "train/policy_logprob_std": 1.131429185942998, "train/policy_randomness_mag": 0.9097090604759398, "train/policy_randomness_max": 0.9097090604759398, "train/policy_randomness_mean": 0.21123776064505653, "train/policy_randomness_min": 0.028015923361101792, "train/policy_randomness_std": 0.24123315134691814, "train/post_ent_mag": 57.86099591330876, "train/post_ent_max": 57.86099591330876, "train/post_ent_mean": 40.924052404978916, "train/post_ent_min": 20.616806469266376, "train/post_ent_std": 7.33400413346669, "train/prior_ent_mag": 66.62499442933098, "train/prior_ent_max": 66.62499442933098, "train/prior_ent_mean": 54.00889953734383, "train/prior_ent_min": 37.977697160508896, "train/prior_ent_std": 4.48283899208856, "train/rep_loss_mean": 13.0327744181194, "train/rep_loss_std": 9.013943240756081, "train/reward_avg": 0.02553633429730932, "train/reward_loss_mean": 0.053281017682618566, "train/reward_loss_std": 0.24615399574949628, "train/reward_max_data": 1.013492066708822, "train/reward_max_pred": 1.0076662425010923, "train/reward_neg_acc": 0.9929278417239114, "train/reward_neg_loss": 0.027907322789172805, "train/reward_pos_acc": 0.9646629885075584, "train/reward_pos_loss": 0.8673908360420711, "train/reward_pred": 0.024657105871786673, "train/reward_rate": 0.030389694940476192, "train_stats/sum_log_reward": 6.000000001015988, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.5, "train_stats/max_log_achievement_collect_sapling": 2.536363636363636, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.0, "train_stats/max_log_achievement_defeat_skeleton": 0.02727272727272727, "train_stats/max_log_achievement_defeat_zombie": 0.6454545454545455, "train_stats/max_log_achievement_eat_cow": 0.12727272727272726, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 1.5818181818181818, "train_stats/max_log_achievement_place_plant": 2.4909090909090907, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.4909090909090907, "train_stats/max_log_achievement_wake_up": 2.0090909090909093, "train_stats/mean_log_entropy": 0.5515302410179919, "eval_stats/sum_log_reward": 6.287499874830246, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 2.25, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.1836154701304622e-05, "report/cont_loss_std": 0.00030823942506685853, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.683990795863792e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1526393538806587e-05, "report/cont_pred": 0.9931432008743286, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.488554000854492, "report/dyn_loss_std": 8.601374626159668, "report/image_loss_mean": 5.1639251708984375, "report/image_loss_std": 8.786178588867188, "report/model_loss_mean": 13.313238143920898, "report/model_loss_std": 12.44029426574707, "report/post_ent_mag": 55.166053771972656, "report/post_ent_max": 55.166053771972656, "report/post_ent_mean": 40.055084228515625, "report/post_ent_min": 21.054283142089844, "report/post_ent_std": 6.97072696685791, "report/prior_ent_mag": 66.545654296875, "report/prior_ent_max": 66.545654296875, "report/prior_ent_mean": 54.147918701171875, "report/prior_ent_min": 39.65863037109375, "report/prior_ent_std": 4.333247661590576, "report/rep_loss_mean": 13.488554000854492, "report/rep_loss_std": 8.601374626159668, "report/reward_avg": 0.04052734375, "report/reward_loss_mean": 0.05615914613008499, "report/reward_loss_std": 0.2202574759721756, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004166603088379, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.02130282111465931, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7807256579399109, "report/reward_pred": 0.037460871040821075, "report/reward_rate": 0.0458984375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.079665035940707e-05, "eval/cont_loss_std": 0.0016375607810914516, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.455471232882701e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.0848004068247974e-05, "eval/cont_pred": 0.9979876279830933, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.959781646728516, "eval/dyn_loss_std": 10.34765338897705, "eval/image_loss_mean": 13.962471008300781, "eval/image_loss_std": 21.845603942871094, "eval/model_loss_mean": 24.809587478637695, "eval/model_loss_std": 25.70741844177246, "eval/post_ent_mag": 55.36614227294922, "eval/post_ent_max": 55.36614227294922, "eval/post_ent_mean": 38.99790954589844, "eval/post_ent_min": 21.123191833496094, "eval/post_ent_std": 6.640418529510498, "eval/prior_ent_mag": 66.545654296875, "eval/prior_ent_max": 66.545654296875, "eval/prior_ent_mean": 54.46684265136719, "eval/prior_ent_min": 37.41648483276367, "eval/prior_ent_std": 3.942586660385132, "eval/rep_loss_mean": 17.959781646728516, "eval/rep_loss_std": 10.34765338897705, "eval/reward_avg": 0.03427734225988388, "eval/reward_loss_mean": 0.07118572294712067, "eval/reward_loss_std": 0.44190964102745056, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0049195289611816, "eval/reward_neg_acc": 0.986842155456543, "eval/reward_neg_loss": 0.04380935803055763, "eval/reward_pos_acc": 0.9722222089767456, "eval/reward_pos_loss": 0.8225146532058716, "eval/reward_pred": 0.039708010852336884, "eval/reward_rate": 0.03515625, "replay/size": 466161.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.432097459994582e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.806480451649006e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 87624.0, "eval_replay/inserts": 4544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0916674640816703e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.300618648529, "timer/env.step_count": 2518.0, "timer/env.step_total": 251.84241771697998, "timer/env.step_frac": 0.25176673194227894, "timer/env.step_avg": 0.10001684579705321, "timer/env.step_min": 0.023157835006713867, "timer/env.step_max": 4.433107376098633, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 10.408924102783203, "timer/replay._sample_frac": 0.010405795926474917, "timer/replay._sample_avg": 0.0005167257795265688, "timer/replay._sample_min": 0.00041484832763671875, "timer/replay._sample_max": 0.025594472885131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3086.0, "timer/agent.policy_total": 52.027586221694946, "timer/agent.policy_frac": 0.052011950459440466, "timer/agent.policy_avg": 0.01685923079121677, "timer/agent.policy_min": 0.009168148040771484, "timer/agent.policy_max": 1.2677488327026367, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.1478102207183838, "timer/dataset_train_frac": 0.00014776579956342023, "timer/dataset_train_avg": 0.00011740287586845417, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.00045990943908691406, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 560.0894207954407, "timer/agent.train_frac": 0.5599210980716555, "timer/agent.train_avg": 0.4448684835547583, "timer/agent.train_min": 0.4325430393218994, "timer/agent.train_max": 1.178074836730957, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47278571128845215, "timer/agent.report_frac": 0.00047264362580042816, "timer/agent.report_avg": 0.23639285564422607, "timer/agent.report_min": 0.22892236709594727, "timer/agent.report_max": 0.24386334419250488, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5979815105164364e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 20.137679166728223}
{"step": 466792, "time": 23307.681167840958, "episode/length": 228.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 467216, "time": 23326.65005993843, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 467456, "time": 23336.961419820786, "episode/length": 185.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 467944, "time": 23356.541379213333, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 467984, "time": 23360.41413283348, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 468120, "time": 23366.74894309044, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 468360, "time": 23377.182834148407, "episode/length": 51.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 468424, "time": 23380.965304374695, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 468736, "time": 23394.153746843338, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 468736, "time": 23394.207036972046, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 468784, "time": 23399.26484322548, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 469112, "time": 23412.67776441574, "episode/length": 40.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 469160, "time": 23416.019959926605, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 469376, "time": 23425.610332727432, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 469752, "time": 23440.979945659637, "episode/length": 173.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 470056, "time": 23453.63274550438, "episode/length": 258.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 23470.590522050858, "eval_episode/length": 38.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 470080, "time": 23476.831880807877, "eval_episode/length": 157.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 470080, "time": 23478.440349578857, "eval_episode/length": 158.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 470080, "time": 23480.81361722946, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 470080, "time": 23483.042382240295, "eval_episode/length": 192.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 470080, "time": 23484.650915145874, "eval_episode/length": 154.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 470080, "time": 23486.375376939774, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 470080, "time": 23489.112842082977, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9692982456140351}
{"step": 470136, "time": 23490.94176340103, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 470272, "time": 23497.75213265419, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 470328, "time": 23501.07454609871, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 470912, "time": 23524.000058412552, "episode/length": 144.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 471032, "time": 23529.85857629776, "episode/length": 239.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 471112, "time": 23534.94847559929, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 471352, "time": 23545.962415456772, "episode/length": 273.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 471432, "time": 23550.949149608612, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 471488, "time": 23555.10374522209, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 471608, "time": 23560.814700126648, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 471736, "time": 23567.12153983116, "episode/length": 199.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 471920, "time": 23576.206850528717, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 472488, "time": 23599.277310609818, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 472760, "time": 23610.728611946106, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 472912, "time": 23618.29669213295, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 472952, "time": 23621.04394340515, "episode/length": 189.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 473080, "time": 23627.286877155304, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 473304, "time": 23636.902942419052, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 473584, "time": 23648.95178771019, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 473912, "time": 23662.248999357224, "episode/length": 359.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 473936, "time": 23664.859795331955, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 474416, "time": 23683.969013929367, "episode/length": 206.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 474472, "time": 23687.429728746414, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 474760, "time": 23699.506951332092, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 474792, "time": 23702.15666460991, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 475120, "time": 23716.118042469025, "episode/length": 150.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 475328, "time": 23726.839619636536, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 475784, "time": 23744.776906728745, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 475792, "time": 23746.806995153427, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 476016, "time": 23756.500756263733, "episode/length": 303.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 476056, "time": 23759.5923910141, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 476168, "time": 23765.607288360596, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 476384, "time": 23775.37655687332, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 476896, "time": 23795.533641815186, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 477016, "time": 23801.95366716385, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 477104, "time": 23807.522576093674, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 477208, "time": 23813.068123579025, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 477224, "time": 23815.64232301712, "episode/length": 533.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 477376, "time": 23823.51650738716, "episode/length": 59.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 477472, "time": 23828.77060341835, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 477640, "time": 23836.176624536514, "episode/length": 183.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 478344, "time": 23863.616577386856, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 478552, "time": 23872.790346622467, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 478616, "time": 23876.657461881638, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 478728, "time": 23882.365731716156, "episode/length": 156.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 478752, "time": 23885.02856016159, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 479032, "time": 23896.743089437485, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 479088, "time": 23900.48768734932, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 479696, "time": 23924.235696554184, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 480000, "time": 23936.8573410511, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 480048, "time": 23940.16682243347, "episode/length": 186.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 23958.286356687546, "eval_episode/length": 47.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 480064, "time": 23964.52542924881, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 480064, "time": 23964.575850963593, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 480064, "time": 23968.597604990005, "eval_episode/length": 185.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 480064, "time": 23970.469369649887, "eval_episode/length": 192.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 480064, "time": 23972.33315229416, "eval_episode/length": 201.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.995049504950495}
{"step": 480064, "time": 23974.227603673935, "eval_episode/length": 163.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 480064, "time": 23977.845400571823, "eval_episode/length": 259.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 480128, "time": 23980.19342970848, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 480312, "time": 23988.156682491302, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 480440, "time": 23994.388329982758, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 480488, "time": 23997.788796663284, "episode/length": 219.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 480616, "time": 24004.032816410065, "episode/length": 197.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 481024, "time": 24020.716809272766, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 481440, "time": 24037.47670650482, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 481584, "time": 24044.305726528168, "episode/length": 181.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 481624, "time": 24047.083605766296, "episode/length": 163.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 481952, "time": 24060.84242272377, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 482144, "time": 24069.430723190308, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 482232, "time": 24073.92932009697, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 482760, "time": 24094.645923614502, "episode/length": 289.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 482856, "time": 24099.835550785065, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 482888, "time": 24102.563556194305, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 482920, "time": 24105.168508291245, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 483056, "time": 24111.913791656494, "episode/length": 304.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 483488, "time": 24130.722801923752, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 483528, "time": 24133.522629976273, "episode/length": 196.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 483920, "time": 24149.521684885025, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 483952, "time": 24152.24947619438, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 484144, "time": 24160.89715886116, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 484384, "time": 24171.18378186226, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 484656, "time": 24182.798264741898, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 484880, "time": 24192.713859319687, "episode/length": 227.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 484880, "time": 24192.75814294815, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 485064, "time": 24202.54148387909, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 485424, "time": 24217.489794254303, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 485432, "time": 24219.569456100464, "episode/length": 188.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 485456, "time": 24222.631240844727, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 485624, "time": 24230.675079345703, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 486264, "time": 24256.247980594635, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 486408, "time": 24263.085345745087, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 486440, "time": 24265.802112817764, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 486552, "time": 24271.457359313965, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 486808, "time": 24282.480585575104, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 486968, "time": 24289.904296159744, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 487096, "time": 24296.18841099739, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 487225, "time": 24303.483298778534, "train_stats/sum_log_reward": 6.338095197223482, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.571428571428571, "train_stats/max_log_achievement_collect_sapling": 2.6476190476190475, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.933333333333334, "train_stats/max_log_achievement_defeat_skeleton": 0.02857142857142857, "train_stats/max_log_achievement_defeat_zombie": 0.7333333333333333, "train_stats/max_log_achievement_eat_cow": 0.1523809523809524, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_sword": 1.8952380952380952, "train_stats/max_log_achievement_place_plant": 2.6, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.6666666666666665, "train_stats/max_log_achievement_wake_up": 1.7809523809523808, "train_stats/mean_log_entropy": 0.5156387121904464, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.45754337310791, "train/action_min": 0.0, "train/action_std": 3.5356784220784903, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04586451521026902, "train/actor_opt_grad_steps": 29715.0, "train/actor_opt_loss": -5.44607230136171, "train/adv_mag": 0.6517316785175353, "train/adv_max": 0.5983173716813326, "train/adv_mean": 0.003394946797769194, "train/adv_min": -0.5080446009524167, "train/adv_std": 0.06850696139736101, "train/cont_avg": 0.9946365356445312, "train/cont_loss_mean": 0.00030815506367209977, "train/cont_loss_std": 0.008808015191810625, "train/cont_neg_acc": 0.991592263802886, "train/cont_neg_loss": 0.02220465297557439, "train/cont_pos_acc": 0.9999385396949947, "train/cont_pos_loss": 0.00019033155881553743, "train/cont_pred": 0.9946215911768377, "train/cont_rate": 0.9946365356445312, "train/dyn_loss_mean": 12.94430946558714, "train/dyn_loss_std": 9.02243772149086, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7964996532537043, "train/extr_critic_critic_opt_grad_steps": 29715.0, "train/extr_critic_critic_opt_loss": 15837.597625732422, "train/extr_critic_mag": 5.709269262850285, "train/extr_critic_max": 5.709269262850285, "train/extr_critic_mean": 1.3525229399092495, "train/extr_critic_min": -0.2993738101795316, "train/extr_critic_std": 1.2908705277368426, "train/extr_return_normed_mag": 1.707273118197918, "train/extr_return_normed_max": 1.707273118197918, "train/extr_return_normed_mean": 0.3387615397805348, "train/extr_return_normed_min": -0.16291060933144763, "train/extr_return_normed_std": 0.3298293688567355, "train/extr_return_rate": 0.641753675416112, "train/extr_return_raw_mag": 6.880998447537422, "train/extr_return_raw_max": 6.880998447537422, "train/extr_return_raw_mean": 1.3661789307370782, "train/extr_return_raw_min": -0.6555334206204861, "train/extr_return_raw_std": 1.3291316865943372, "train/extr_reward_mag": 1.0186754241585732, "train/extr_reward_max": 1.0186754241585732, "train/extr_reward_mean": 0.02976549260347383, "train/extr_reward_min": -0.4813359063118696, "train/extr_reward_std": 0.1618520676274784, "train/image_loss_mean": 6.356586549431086, "train/image_loss_std": 10.465023335069418, "train/model_loss_mean": 14.176493428647518, "train/model_loss_std": 14.195091217756271, "train/model_opt_grad_norm": 54.779463425278664, "train/model_opt_grad_steps": 29687.703125, "train/model_opt_loss": 17869.294204711914, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.765625, "train/policy_entropy_mag": 2.560412673279643, "train/policy_entropy_max": 2.560412673279643, "train/policy_entropy_mean": 0.5544480399694294, "train/policy_entropy_min": 0.0793750878656283, "train/policy_entropy_std": 0.6372871110215783, "train/policy_logprob_mag": 7.438383486121893, "train/policy_logprob_max": -0.009455661260290071, "train/policy_logprob_mean": -0.5545434430241585, "train/policy_logprob_min": -7.438383486121893, "train/policy_logprob_std": 1.109555933624506, "train/policy_randomness_mag": 0.9037133120000362, "train/policy_randomness_max": 0.9037133120000362, "train/policy_randomness_mean": 0.19569582445546985, "train/policy_randomness_min": 0.028015922755002975, "train/policy_randomness_std": 0.22493438445962965, "train/post_ent_mag": 58.04007774591446, "train/post_ent_max": 58.04007774591446, "train/post_ent_mean": 41.034530997276306, "train/post_ent_min": 20.39952828735113, "train/post_ent_std": 7.40656903013587, "train/prior_ent_mag": 66.68381208181381, "train/prior_ent_max": 66.68381208181381, "train/prior_ent_mean": 54.05922198295593, "train/prior_ent_min": 38.23504066467285, "train/prior_ent_std": 4.437683271244168, "train/rep_loss_mean": 12.94430946558714, "train/rep_loss_std": 9.02243772149086, "train/reward_avg": 0.024963378622487653, "train/reward_loss_mean": 0.05301314339158125, "train/reward_loss_std": 0.2461636399384588, "train/reward_max_data": 1.0117187527939677, "train/reward_max_pred": 1.0068591572344303, "train/reward_neg_acc": 0.9932490522041917, "train/reward_neg_loss": 0.02874763593717944, "train/reward_pos_acc": 0.9691719422116876, "train/reward_pos_loss": 0.8358838283456862, "train/reward_pred": 0.02439621320081642, "train/reward_rate": 0.02986907958984375, "eval_stats/sum_log_reward": 5.912499964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.8125, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.186661959058256e-06, "report/cont_loss_std": 2.9293392799445428e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005001310491934419, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.235540806505014e-07, "report/cont_pred": 0.9970711469650269, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.850595474243164, "report/dyn_loss_std": 9.43793773651123, "report/image_loss_mean": 6.348859786987305, "report/image_loss_std": 13.346717834472656, "report/model_loss_mean": 13.508260726928711, "report/model_loss_std": 17.469865798950195, "report/post_ent_mag": 59.06126022338867, "report/post_ent_max": 59.06126022338867, "report/post_ent_mean": 40.64189910888672, "report/post_ent_min": 18.664480209350586, "report/post_ent_std": 7.127770900726318, "report/prior_ent_mag": 66.93901824951172, "report/prior_ent_max": 66.93901824951172, "report/prior_ent_mean": 52.89680099487305, "report/prior_ent_min": 36.63292694091797, "report/prior_ent_std": 4.8053178787231445, "report/rep_loss_mean": 11.850595474243164, "report/rep_loss_std": 9.43793773651123, "report/reward_avg": 0.01591796800494194, "report/reward_loss_mean": 0.04904124140739441, "report/reward_loss_std": 0.3145507872104645, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0055253505706787, "report/reward_neg_acc": 0.9970089793205261, "report/reward_neg_loss": 0.03310110792517662, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.810372531414032, "report/reward_pred": 0.01609759032726288, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0009396852110512555, "eval/cont_loss_std": 0.02882799133658409, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007641804404556751, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0009067995706573129, "eval/cont_pred": 0.9945640563964844, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.111366271972656, "eval/dyn_loss_std": 10.31072998046875, "eval/image_loss_mean": 10.654130935668945, "eval/image_loss_std": 19.276180267333984, "eval/model_loss_mean": 21.028465270996094, "eval/model_loss_std": 23.069149017333984, "eval/post_ent_mag": 61.090126037597656, "eval/post_ent_max": 61.090126037597656, "eval/post_ent_mean": 39.60717010498047, "eval/post_ent_min": 21.115591049194336, "eval/post_ent_std": 7.30750036239624, "eval/prior_ent_mag": 66.93901824951172, "eval/prior_ent_max": 66.93901824951172, "eval/prior_ent_mean": 54.22344970703125, "eval/prior_ent_min": 34.56761932373047, "eval/prior_ent_std": 4.418272972106934, "eval/rep_loss_mean": 17.111366271972656, "eval/rep_loss_std": 10.31072998046875, "eval/reward_avg": 0.02666015736758709, "eval/reward_loss_mean": 0.10657459497451782, "eval/reward_loss_std": 0.6888764500617981, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0154650211334229, "eval/reward_neg_acc": 0.9919273257255554, "eval/reward_neg_loss": 0.0659649446606636, "eval/reward_pos_acc": 0.9090908765792847, "eval/reward_pos_loss": 1.326094627380371, "eval/reward_pred": 0.02736346423625946, "eval/reward_rate": 0.0322265625, "replay/size": 486721.0, "replay/inserts": 20560.0, "replay/samples": 20560.0, "replay/insert_wait_avg": 1.3867124973104159e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.839286373746998e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91528.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1916043328457192e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2244658470154, "timer/env.step_count": 2570.0, "timer/env.step_total": 238.70377326011658, "timer/env.step_frac": 0.2386502044398366, "timer/env.step_avg": 0.0928808456265045, "timer/env.step_min": 0.022878646850585938, "timer/env.step_max": 3.302717924118042, "timer/replay._sample_count": 20560.0, "timer/replay._sample_total": 10.641396045684814, "timer/replay._sample_frac": 0.01063900795175352, "timer/replay._sample_avg": 0.000517577628681168, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.022192716598510742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3058.0, "timer/agent.policy_total": 51.435219049453735, "timer/agent.policy_frac": 0.05142367619042101, "timer/agent.policy_avg": 0.016819888505380555, "timer/agent.policy_min": 0.009392976760864258, "timer/agent.policy_max": 0.11389040946960449, "timer/dataset_train_count": 1285.0, "timer/dataset_train_total": 0.14992070198059082, "timer/dataset_train_frac": 0.00014988705745528247, "timer/dataset_train_avg": 0.00011666980698878663, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0004265308380126953, "timer/agent.train_count": 1285.0, "timer/agent.train_total": 573.1742744445801, "timer/agent.train_frac": 0.5730456452684364, "timer/agent.train_avg": 0.4460500190230195, "timer/agent.train_min": 0.4326481819152832, "timer/agent.train_max": 1.2926356792449951, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47243618965148926, "timer/agent.report_frac": 0.0004723301676603345, "timer/agent.report_avg": 0.23621809482574463, "timer/agent.report_min": 0.22985315322875977, "timer/agent.report_max": 0.2425830364227295, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5033950805664062e-05, "timer/dataset_eval_frac": 2.5028332799742784e-08, "timer/dataset_eval_avg": 2.5033950805664062e-05, "timer/dataset_eval_min": 2.5033950805664062e-05, "timer/dataset_eval_max": 2.5033950805664062e-05, "fps": 20.55512797913681}
{"step": 487496, "time": 24313.30640554428, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 487712, "time": 24322.916348457336, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 487888, "time": 24331.021968364716, "episode/length": 48.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 487904, "time": 24333.20266532898, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 488016, "time": 24338.96996331215, "episode/length": 218.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 488528, "time": 24359.09694123268, "episode/length": 246.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 488640, "time": 24364.686393499374, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 488800, "time": 24372.242617845535, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 489248, "time": 24390.084481716156, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 489648, "time": 24406.22795367241, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 489832, "time": 24414.217114448547, "episode/length": 264.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 489896, "time": 24418.151864767075, "episode/length": 250.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 24439.671097040176, "eval_episode/length": 38.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 490048, "time": 24447.11668419838, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 490048, "time": 24449.0695912838, "eval_episode/length": 201.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 490048, "time": 24449.11549639702, "eval_episode/length": 201.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 490048, "time": 24452.89163661003, "eval_episode/length": 210.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.985781990521327}
{"step": 490048, "time": 24455.190514564514, "eval_episode/length": 186.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.983957219251337}
{"step": 490048, "time": 24457.17916584015, "eval_episode/length": 235.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 490048, "time": 24458.757357120514, "eval_episode/length": 34.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 490120, "time": 24461.149327516556, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 490488, "time": 24475.99956393242, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 490696, "time": 24485.024175167084, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 491176, "time": 24505.56851053238, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 491192, "time": 24507.70663166046, "episode/length": 61.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 491216, "time": 24510.373309135437, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 491248, "time": 24513.081480026245, "episode/length": 554.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9981981981981982, "episode/intrinsic_return": 0.0}
{"step": 491688, "time": 24532.049191713333, "episode/length": 195.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 492080, "time": 24548.68556523323, "episode/length": 198.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 492104, "time": 24551.38530898094, "episode/length": 432.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 492168, "time": 24555.84240245819, "episode/length": 59.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 492496, "time": 24570.299842596054, "episode/length": 162.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 492632, "time": 24576.59791779518, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 492640, "time": 24578.562403917313, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 492648, "time": 24580.220962762833, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 493160, "time": 24600.362347841263, "episode/length": 407.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 493288, "time": 24606.692944049835, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 493568, "time": 24618.681846618652, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 493904, "time": 24632.464585781097, "episode/length": 157.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 494040, "time": 24638.880007267, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 494096, "time": 24642.784529924393, "episode/length": 182.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 494240, "time": 24649.56671333313, "episode/length": 134.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 494264, "time": 24651.72203016281, "episode/length": 201.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 494392, "time": 24657.933720350266, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 494536, "time": 24664.746393203735, "episode/length": 295.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 494640, "time": 24670.478462696075, "episode/length": 30.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 494992, "time": 24684.778339624405, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 495584, "time": 24707.99861431122, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 495680, "time": 24712.941030979156, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 495760, "time": 24717.382249832153, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 495816, "time": 24720.815338373184, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 495848, "time": 24723.56130695343, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 496152, "time": 24736.321759700775, "episode/length": 37.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 496200, "time": 24739.56019115448, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 496224, "time": 24742.240799188614, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 496520, "time": 24754.34843468666, "episode/length": 190.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 496864, "time": 24768.744580745697, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 497056, "time": 24777.27686572075, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 497232, "time": 24785.268404722214, "episode/length": 176.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 497480, "time": 24795.830248832703, "episode/length": 159.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 497592, "time": 24801.491297721863, "episode/length": 133.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 497688, "time": 24806.577193260193, "episode/length": 191.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 497936, "time": 24817.45476102829, "episode/length": 133.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9477611940298507, "episode/intrinsic_return": 0.0}
{"step": 498248, "time": 24830.22745680809, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 498288, "time": 24833.55531167984, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 498344, "time": 24836.957096099854, "episode/length": 264.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 498768, "time": 24854.18809080124, "episode/length": 191.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 498992, "time": 24863.928354263306, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 499040, "time": 24867.21427822113, "episode/length": 194.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 499152, "time": 24872.814494609833, "episode/length": 423.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 499400, "time": 24883.314786434174, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 499696, "time": 24895.87756037712, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 499720, "time": 24898.698514938354, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 24927.503494501114, "eval_episode/length": 47.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 500032, "time": 24930.137919425964, "eval_episode/length": 77.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 500032, "time": 24934.87574839592, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 500032, "time": 24937.236156225204, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 500032, "time": 24940.294479608536, "eval_episode/length": 213.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 500032, "time": 24942.40525484085, "eval_episode/length": 226.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 500032, "time": 24945.518119096756, "eval_episode/length": 215.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 500032, "time": 24948.366735696793, "eval_episode/length": 296.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9865319865319865}
{"step": 500200, "time": 24954.270190000534, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 500368, "time": 24962.25754904747, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 500480, "time": 24967.93014907837, "episode/length": 185.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 500552, "time": 24971.90089583397, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 500680, "time": 24978.087406635284, "episode/length": 204.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 501016, "time": 24991.80300474167, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 501064, "time": 24995.140207529068, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 501488, "time": 25012.479748487473, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 501624, "time": 25018.82110786438, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 501632, "time": 25020.920311689377, "episode/length": 157.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 501712, "time": 25025.443601369858, "episode/length": 427.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 501784, "time": 25029.36008119583, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 502016, "time": 25039.65430498123, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 502352, "time": 25053.477444410324, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 502368, "time": 25055.625114440918, "episode/length": 43.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 502752, "time": 25072.194471120834, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 502912, "time": 25080.144710302353, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 503008, "time": 25085.16935133934, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 503104, "time": 25090.3607172966, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 503504, "time": 25106.47201681137, "episode/length": 214.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 503824, "time": 25119.740971326828, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 503912, "time": 25124.187854528427, "episode/length": 428.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 504040, "time": 25130.352274656296, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 504176, "time": 25136.982776880264, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 504208, "time": 25139.762452602386, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 504448, "time": 25150.10583090782, "episode/length": 66.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 505240, "time": 25180.43544769287, "episode/length": 216.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 505240, "time": 25180.483368635178, "episode/length": 290.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 505632, "time": 25198.242463350296, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 505680, "time": 25201.562840938568, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 505680, "time": 25201.611727952957, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 505688, "time": 25205.05907344818, "episode/length": 232.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 506016, "time": 25218.78932094574, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 506256, "time": 25228.97825527191, "episode/length": 393.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 506912, "time": 25254.447543621063, "episode/length": 159.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 506928, "time": 25256.519983291626, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 506968, "time": 25259.227093219757, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 507040, "time": 25263.61468219757, "episode/length": 224.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 507056, "time": 25265.789408922195, "episode/length": 171.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 507120, "time": 25269.782202720642, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 507216, "time": 25274.73562979698, "episode/length": 35.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 507328, "time": 25280.330317497253, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 507898, "time": 25303.503725767136, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.655018414637839, "train/action_min": 0.0, "train/action_std": 3.6858260317366254, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04516637333950331, "train/actor_opt_grad_steps": 31000.0, "train/actor_opt_loss": -2.308504912280297, "train/adv_mag": 0.664391042650208, "train/adv_max": 0.6117471045301867, "train/adv_mean": 0.0037036798951795187, "train/adv_min": -0.5172334609105605, "train/adv_std": 0.06788623217464418, "train/cont_avg": 0.994632691375969, "train/cont_loss_mean": 0.00015050072156801722, "train/cont_loss_std": 0.0044353159201684965, "train/cont_neg_acc": 0.995265781879425, "train/cont_neg_loss": 0.017343231758349592, "train/cont_pos_acc": 0.999984761541204, "train/cont_pos_loss": 4.7624407112180085e-05, "train/cont_pred": 0.9946458196455195, "train/cont_rate": 0.994632691375969, "train/dyn_loss_mean": 12.665619133054747, "train/dyn_loss_std": 9.016379090242607, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8250204671260922, "train/extr_critic_critic_opt_grad_steps": 31000.0, "train/extr_critic_critic_opt_loss": 15831.972709241763, "train/extr_critic_mag": 5.69756742226061, "train/extr_critic_max": 5.69756742226061, "train/extr_critic_mean": 1.3653559915779172, "train/extr_critic_min": -0.27969331149907073, "train/extr_critic_std": 1.2754451748012572, "train/extr_return_normed_mag": 1.695380731146465, "train/extr_return_normed_max": 1.695380731146465, "train/extr_return_normed_mean": 0.3427068695079449, "train/extr_return_normed_min": -0.16817240506526113, "train/extr_return_normed_std": 0.3269765969625739, "train/extr_return_rate": 0.6677214891411537, "train/extr_return_raw_mag": 6.798723013826119, "train/extr_return_raw_max": 6.798723013826119, "train/extr_return_raw_mean": 1.3801460349282553, "train/extr_return_raw_min": -0.665710583098175, "train/extr_return_raw_std": 1.3097833002260488, "train/extr_reward_mag": 1.018639929534853, "train/extr_reward_max": 1.018639929534853, "train/extr_reward_mean": 0.030020756343769474, "train/extr_reward_min": -0.4984105243239292, "train/extr_reward_std": 0.16261474251054053, "train/image_loss_mean": 6.186237649400105, "train/image_loss_std": 10.200793480688287, "train/model_loss_mean": 13.83750245737475, "train/model_loss_std": 13.939889005912367, "train/model_opt_grad_norm": 60.102585420012474, "train/model_opt_grad_steps": 30971.01550387597, "train/model_opt_loss": 10568.361642290456, "train/model_opt_model_opt_grad_overflow": 0.007751937984496124, "train/model_opt_model_opt_grad_scale": 760.6589147286821, "train/policy_entropy_mag": 2.5784380047820337, "train/policy_entropy_max": 2.5784380047820337, "train/policy_entropy_mean": 0.5554809461730396, "train/policy_entropy_min": 0.07937507695236871, "train/policy_entropy_std": 0.6320362717144249, "train/policy_logprob_mag": 7.438383424004843, "train/policy_logprob_max": -0.009455659397870533, "train/policy_logprob_mean": -0.5550714028898136, "train/policy_logprob_min": -7.438383424004843, "train/policy_logprob_std": 1.1130062743674878, "train/policy_randomness_mag": 0.9100754621417023, "train/policy_randomness_max": 0.9100754621417023, "train/policy_randomness_mean": 0.1960603974817335, "train/policy_randomness_min": 0.02801591889976069, "train/policy_randomness_std": 0.22308106812857842, "train/post_ent_mag": 58.170772966488386, "train/post_ent_max": 58.170772966488386, "train/post_ent_mean": 41.408667542213614, "train/post_ent_min": 20.44577029324317, "train/post_ent_std": 7.459657044373741, "train/prior_ent_mag": 66.7925242934116, "train/prior_ent_max": 66.7925242934116, "train/prior_ent_mean": 54.14484062490537, "train/prior_ent_min": 38.670671122942785, "train/prior_ent_std": 4.454885554868121, "train/rep_loss_mean": 12.665619133054747, "train/rep_loss_std": 9.016379090242607, "train/reward_avg": 0.024825127116700475, "train/reward_loss_mean": 0.05174284653608189, "train/reward_loss_std": 0.23976783696995224, "train/reward_max_data": 1.010852715765783, "train/reward_max_pred": 1.0046744466752044, "train/reward_neg_acc": 0.9932743084523105, "train/reward_neg_loss": 0.027490220913418042, "train/reward_pos_acc": 0.9661842843358831, "train/reward_pos_loss": 0.8473052849141203, "train/reward_pred": 0.024013052983281685, "train/reward_rate": 0.0296375363372093, "train_stats/sum_log_reward": 6.062616838333763, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.813084112149533, "train_stats/max_log_achievement_collect_sapling": 2.5514018691588785, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.607476635514018, "train_stats/max_log_achievement_defeat_skeleton": 0.018691588785046728, "train_stats/max_log_achievement_defeat_zombie": 0.6355140186915887, "train_stats/max_log_achievement_eat_cow": 0.17757009345794392, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_sword": 1.6542056074766356, "train_stats/max_log_achievement_place_plant": 2.485981308411215, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.682242990654206, "train_stats/max_log_achievement_wake_up": 2.102803738317757, "train_stats/mean_log_entropy": 0.5195401157731208, "eval_stats/sum_log_reward": 5.912499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 2.125, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0034578372724354267, "report/cont_loss_std": 0.10596238076686859, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.272355287568644e-05, "report/cont_pos_acc": 0.9990195631980896, "report/cont_pos_loss": 0.003471112111583352, "report/cont_pred": 0.9950122237205505, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.727563858032227, "report/dyn_loss_std": 9.974173545837402, "report/image_loss_mean": 8.085212707519531, "report/image_loss_std": 14.132002830505371, "report/model_loss_mean": 15.755655288696289, "report/model_loss_std": 18.576528549194336, "report/post_ent_mag": 55.100425720214844, "report/post_ent_max": 55.100425720214844, "report/post_ent_mean": 41.03114700317383, "report/post_ent_min": 20.726619720458984, "report/post_ent_std": 7.045002460479736, "report/prior_ent_mag": 66.66844940185547, "report/prior_ent_max": 66.66844940185547, "report/prior_ent_mean": 53.87671661376953, "report/prior_ent_min": 37.97529602050781, "report/prior_ent_std": 4.530876159667969, "report/rep_loss_mean": 12.727563858032227, "report/rep_loss_std": 9.974173545837402, "report/reward_avg": 0.00927734375, "report/reward_loss_mean": 0.030448067933321, "report/reward_loss_std": 0.16160370409488678, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009639263153076, "report/reward_neg_acc": 0.9940594434738159, "report/reward_neg_loss": 0.02144867181777954, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6796901226043701, "report/reward_pred": 0.010168537497520447, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 7.475239272025647e-07, "eval/cont_loss_std": 2.5835304313659435e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.5045610022498295e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.042217475827783e-07, "eval/cont_pred": 0.999022901058197, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.72685432434082, "eval/dyn_loss_std": 10.51245403289795, "eval/image_loss_mean": 12.594043731689453, "eval/image_loss_std": 16.938053131103516, "eval/model_loss_mean": 22.711261749267578, "eval/model_loss_std": 21.033714294433594, "eval/post_ent_mag": 59.67644500732422, "eval/post_ent_max": 59.67644500732422, "eval/post_ent_mean": 39.82060623168945, "eval/post_ent_min": 21.496780395507812, "eval/post_ent_std": 7.010486602783203, "eval/prior_ent_mag": 66.66844940185547, "eval/prior_ent_max": 66.66844940185547, "eval/prior_ent_mean": 54.013668060302734, "eval/prior_ent_min": 41.704673767089844, "eval/prior_ent_std": 3.9538848400115967, "eval/rep_loss_mean": 16.72685432434082, "eval/rep_loss_std": 10.51245403289795, "eval/reward_avg": 0.03017578087747097, "eval/reward_loss_mean": 0.08110389113426208, "eval/reward_loss_std": 0.5567814707756042, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004944801330566, "eval/reward_neg_acc": 0.9909273982048035, "eval/reward_neg_loss": 0.020675625652074814, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 1.9543800354003906, "eval/reward_pred": 0.02655598521232605, "eval/reward_rate": 0.03125, "replay/size": 507394.0, "replay/inserts": 20673.0, "replay/samples": 20672.0, "replay/insert_wait_avg": 1.3937678189707362e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.814920908157302e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95800.0, "eval_replay/inserts": 4272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.100007067905383e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0100696086884, "timer/env.step_count": 2584.0, "timer/env.step_total": 238.33625555038452, "timer/env.step_frac": 0.2383338556217212, "timer/env.step_avg": 0.09223539301485469, "timer/env.step_min": 0.023427486419677734, "timer/env.step_max": 3.38873291015625, "timer/replay._sample_count": 20672.0, "timer/replay._sample_total": 10.695321083068848, "timer/replay._sample_frac": 0.010695213386455208, "timer/replay._sample_avg": 0.0005173820183373088, "timer/replay._sample_min": 0.0003941059112548828, "timer/replay._sample_max": 0.010951519012451172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3118.0, "timer/agent.policy_total": 50.783586263656616, "timer/agent.policy_frac": 0.0507830748979644, "timer/agent.policy_avg": 0.01628723100181418, "timer/agent.policy_min": 0.009195089340209961, "timer/agent.policy_max": 0.09252047538757324, "timer/dataset_train_count": 1292.0, "timer/dataset_train_total": 0.15009212493896484, "timer/dataset_train_frac": 0.00015009061358521825, "timer/dataset_train_avg": 0.00011617037533975607, "timer/dataset_train_min": 0.00010538101196289062, "timer/dataset_train_max": 0.0002758502960205078, "timer/agent.train_count": 1292.0, "timer/agent.train_total": 572.7045149803162, "timer/agent.train_frac": 0.5726987481280262, "timer/agent.train_avg": 0.4432697484367772, "timer/agent.train_min": 0.4315965175628662, "timer/agent.train_max": 1.8971569538116455, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475628137588501, "timer/agent.report_frac": 0.0004756233482475011, "timer/agent.report_avg": 0.2378140687942505, "timer/agent.report_min": 0.23339128494262695, "timer/agent.report_max": 0.24223685264587402, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.002716064453125e-05, "timer/dataset_eval_frac": 2.0026958980891094e-08, "timer/dataset_eval_avg": 2.002716064453125e-05, "timer/dataset_eval_min": 2.002716064453125e-05, "timer/dataset_eval_max": 2.002716064453125e-05, "fps": 20.67251277719067}
{"step": 508120, "time": 25312.584451675415, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 508448, "time": 25326.21587371826, "episode/length": 191.0, "episode/score": 7.1000000461936, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 508752, "time": 25338.94191145897, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 508768, "time": 25341.120754480362, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 508800, "time": 25343.92942738533, "episode/length": 317.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 508992, "time": 25352.526629447937, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 509136, "time": 25359.43318295479, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 509264, "time": 25365.635085344315, "episode/length": 241.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 509472, "time": 25374.651371479034, "episode/length": 301.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 509600, "time": 25380.86536359787, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 25411.672154426575, "eval_episode/length": 36.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.972972972972973}
{"step": 510016, "time": 25417.72706747055, "eval_episode/length": 127.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 510016, "time": 25420.5268471241, "eval_episode/length": 149.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 510016, "time": 25422.809320926666, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 510016, "time": 25426.20293712616, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 510016, "time": 25428.25287270546, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 510016, "time": 25432.652319431305, "eval_episode/length": 247.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758064516129032}
{"step": 510016, "time": 25436.78523826599, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 510032, "time": 25437.79446029663, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 510176, "time": 25445.293130397797, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 510432, "time": 25457.184524059296, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 510760, "time": 25471.431237459183, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 510808, "time": 25475.10750889778, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 510816, "time": 25477.51298069954, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 510992, "time": 25485.455000400543, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 511456, "time": 25504.26532292366, "episode/length": 247.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 511736, "time": 25516.680074453354, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 511768, "time": 25519.814948797226, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 511816, "time": 25523.679035425186, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 512192, "time": 25540.150871515274, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 512400, "time": 25549.922728300095, "episode/length": 277.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 512416, "time": 25552.55283522606, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 512456, "time": 25555.81988787651, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 513168, "time": 25584.66907143593, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 513616, "time": 25602.6951918602, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 513648, "time": 25605.347725629807, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 513992, "time": 25619.31789445877, "episode/length": 281.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 514024, "time": 25622.20444583893, "episode/length": 228.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 514056, "time": 25624.840732097626, "episode/length": 199.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 514520, "time": 25643.626293182373, "episode/length": 463.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9978448275862069, "episode/intrinsic_return": 0.0}
{"step": 514672, "time": 25651.526028633118, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 514928, "time": 25663.25137066841, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 514936, "time": 25665.20930290222, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 515248, "time": 25679.219075918198, "episode/length": 39.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 515288, "time": 25682.356423854828, "episode/length": 439.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 515320, "time": 25685.57008910179, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 515616, "time": 25698.810204982758, "episode/length": 45.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 515624, "time": 25700.344582796097, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 515744, "time": 25706.472739458084, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 515984, "time": 25716.870364665985, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 516000, "time": 25718.97224330902, "episode/length": 47.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 516080, "time": 25723.383885860443, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 516272, "time": 25733.49782013893, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 516896, "time": 25757.964702129364, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 516896, "time": 25758.014048099518, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 517160, "time": 25770.658767461777, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 517424, "time": 25782.1857047081, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 517472, "time": 25785.50462603569, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 517688, "time": 25794.73881483078, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 518048, "time": 25809.774909734726, "episode/length": 287.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 518416, "time": 25824.98732638359, "episode/length": 267.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 518464, "time": 25828.28207397461, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 518504, "time": 25831.054381132126, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 518888, "time": 25846.797607660294, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 518952, "time": 25850.66000676155, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 519176, "time": 25860.454506635666, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 519360, "time": 25868.95724081993, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 519504, "time": 25875.75708079338, "episode/length": 135.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.0}
{"step": 519824, "time": 25888.939141988754, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 25915.746886730194, "eval_episode/length": 158.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 520000, "time": 25918.176180124283, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 520000, "time": 25919.971633195877, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9625668449197861}
{"step": 520000, "time": 25921.50549340248, "eval_episode/length": 187.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 520000, "time": 25923.556968688965, "eval_episode/length": 197.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 520000, "time": 25925.176104307175, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 520000, "time": 25927.335283517838, "eval_episode/length": 212.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 520000, "time": 25932.687976121902, "eval_episode/length": 154.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 520168, "time": 25938.580868005753, "episode/length": 207.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 520328, "time": 25945.882579803467, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 520640, "time": 25959.137464284897, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 520784, "time": 25966.008767604828, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 520848, "time": 25969.92315840721, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 521176, "time": 25983.380164384842, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 521184, "time": 25985.670944452286, "episode/length": 41.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 521352, "time": 25993.28206062317, "episode/length": 230.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 521664, "time": 26006.487719774246, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 521960, "time": 26018.715669870377, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 522256, "time": 26031.425086975098, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 522456, "time": 26040.06231021881, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9902439024390244, "episode/intrinsic_return": 0.0}
{"step": 522472, "time": 26042.263047218323, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 522536, "time": 26046.193837165833, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 522792, "time": 26057.179014205933, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 523712, "time": 26092.61205816269, "episode/length": 181.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 523736, "time": 26094.83707165718, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691119691119691, "episode/intrinsic_return": 0.0}
{"step": 523768, "time": 26097.432695627213, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 524184, "time": 26114.445580482483, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 524344, "time": 26123.85006380081, "episode/length": 297.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 524352, "time": 26125.979320049286, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 524784, "time": 26143.306257009506, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 525024, "time": 26153.47526693344, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 525080, "time": 26156.729395627975, "episode/length": 325.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 525152, "time": 26161.1027071476, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 525248, "time": 26166.07293009758, "episode/length": 188.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 525352, "time": 26171.204880475998, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 525696, "time": 26185.462921619415, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 526248, "time": 26207.055090904236, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 526256, "time": 26209.201286792755, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 526424, "time": 26216.60578274727, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 526624, "time": 26225.65610766411, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 526776, "time": 26232.699605464935, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 526776, "time": 26232.751173496246, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 526840, "time": 26238.480010032654, "episode/length": 73.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.918918918918919, "episode/intrinsic_return": 0.0}
{"step": 526896, "time": 26242.294520139694, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 526944, "time": 26245.619851112366, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 527256, "time": 26258.369473934174, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 527576, "time": 26271.481917142868, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 527944, "time": 26286.515118598938, "episode/length": 280.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 527944, "time": 26286.565156936646, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 527992, "time": 26291.497930288315, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 528256, "time": 26302.93806552887, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 528257, "time": 26305.089769601822, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.532661498062254, "train/action_min": 0.0, "train/action_std": 3.56311437651867, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04535822370859582, "train/actor_opt_grad_steps": 32280.0, "train/actor_opt_loss": -1.7236377148647009, "train/adv_mag": 0.637256803709691, "train/adv_max": 0.595878413812382, "train/adv_mean": 0.003817286671461963, "train/adv_min": -0.4891171258265578, "train/adv_std": 0.06763896997284702, "train/cont_avg": 0.994386687992126, "train/cont_loss_mean": 0.0004115850338361338, "train/cont_loss_std": 0.012063319893549642, "train/cont_neg_acc": 0.9872234754675017, "train/cont_neg_loss": 0.033600888452476614, "train/cont_pos_acc": 0.9999303587778346, "train/cont_pos_loss": 0.00020829559092311366, "train/cont_pred": 0.9943883728793287, "train/cont_rate": 0.994386687992126, "train/dyn_loss_mean": 12.734398263645923, "train/dyn_loss_std": 9.05386091968206, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.833138416132589, "train/extr_critic_critic_opt_grad_steps": 32280.0, "train/extr_critic_critic_opt_loss": 15664.241080216536, "train/extr_critic_mag": 5.833605800087996, "train/extr_critic_max": 5.833605800087996, "train/extr_critic_mean": 1.4558355859884127, "train/extr_critic_min": -0.30438389083531897, "train/extr_critic_std": 1.342008389825896, "train/extr_return_normed_mag": 1.704516685853793, "train/extr_return_normed_max": 1.704516685853793, "train/extr_return_normed_mean": 0.35517538391699005, "train/extr_return_normed_min": -0.16092622749448762, "train/extr_return_normed_std": 0.3317259670946542, "train/extr_return_rate": 0.6747401326190768, "train/extr_return_raw_mag": 7.0804293211989515, "train/extr_return_raw_max": 7.0804293211989515, "train/extr_return_raw_mean": 1.4717188219385824, "train/extr_return_raw_min": -0.6731319394637281, "train/extr_return_raw_std": 1.37901531054279, "train/extr_reward_mag": 1.017263082068736, "train/extr_reward_max": 1.017263082068736, "train/extr_reward_mean": 0.031158584998700563, "train/extr_reward_min": -0.4804684824830904, "train/extr_reward_std": 0.16651291611391728, "train/image_loss_mean": 6.144103973869264, "train/image_loss_std": 10.539726369962917, "train/model_loss_mean": 13.837930266312727, "train/model_loss_std": 14.251331156633032, "train/model_opt_grad_norm": 57.507308157663495, "train/model_opt_grad_steps": 32250.543307086613, "train/model_opt_loss": 13462.893304779773, "train/model_opt_model_opt_grad_overflow": 0.007874015748031496, "train/model_opt_model_opt_grad_scale": 964.5669291338583, "train/policy_entropy_mag": 2.5349953287229763, "train/policy_entropy_max": 2.5349953287229763, "train/policy_entropy_mean": 0.5590314644528186, "train/policy_entropy_min": 0.07937506662579033, "train/policy_entropy_std": 0.6373886320534654, "train/policy_logprob_mag": 7.438383549217164, "train/policy_logprob_max": -0.009455658495426178, "train/policy_logprob_mean": -0.5583161268177934, "train/policy_logprob_min": -7.438383549217164, "train/policy_logprob_std": 1.1111473943304828, "train/policy_randomness_mag": 0.8947421058895081, "train/policy_randomness_max": 0.8947421058895081, "train/policy_randomness_mean": 0.197313575880734, "train/policy_randomness_min": 0.02801591524575639, "train/policy_randomness_std": 0.22497021882083473, "train/post_ent_mag": 58.297740305502586, "train/post_ent_max": 58.297740305502586, "train/post_ent_mean": 41.39596776887188, "train/post_ent_min": 20.27806906812773, "train/post_ent_std": 7.457642040853425, "train/prior_ent_mag": 66.87778623085322, "train/prior_ent_max": 66.87778623085322, "train/prior_ent_mean": 54.18596261692798, "train/prior_ent_min": 38.810151708407666, "train/prior_ent_std": 4.373205577294658, "train/rep_loss_mean": 12.734398263645923, "train/rep_loss_std": 9.05386091968206, "train/reward_avg": 0.025309116286262284, "train/reward_loss_mean": 0.05277581624393388, "train/reward_loss_std": 0.24064416514606926, "train/reward_max_data": 1.0110236246754805, "train/reward_max_pred": 1.0050157749746729, "train/reward_neg_acc": 0.9935049837029825, "train/reward_neg_loss": 0.028229133240643918, "train/reward_pos_acc": 0.9694883086549955, "train/reward_pos_loss": 0.8351548135749937, "train/reward_pred": 0.024574090059347978, "train/reward_rate": 0.030396468996062992, "train_stats/sum_log_reward": 6.321153811537302, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.903846153846154, "train_stats/max_log_achievement_collect_sapling": 2.548076923076923, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 10.067307692307692, "train_stats/max_log_achievement_defeat_skeleton": 0.009615384615384616, "train_stats/max_log_achievement_defeat_zombie": 0.875, "train_stats/max_log_achievement_eat_cow": 0.17307692307692307, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_sword": 1.5480769230769231, "train_stats/max_log_achievement_place_plant": 2.5096153846153846, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.0673076923076925, "train_stats/max_log_achievement_wake_up": 1.9038461538461537, "train_stats/mean_log_entropy": 0.5299994540042602, "eval_stats/sum_log_reward": 5.662499949336052, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1574854852369754e-06, "report/cont_loss_std": 2.2370209990185685e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00018345288117416203, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.305297427568803e-08, "report/cont_pred": 0.9941416382789612, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.669454574584961, "report/dyn_loss_std": 8.65517520904541, "report/image_loss_mean": 6.114344120025635, "report/image_loss_std": 10.80673599243164, "report/model_loss_mean": 13.17171859741211, "report/model_loss_std": 14.373435020446777, "report/post_ent_mag": 59.17303466796875, "report/post_ent_max": 59.17303466796875, "report/post_ent_mean": 42.39971923828125, "report/post_ent_min": 20.81114959716797, "report/post_ent_std": 7.122452259063721, "report/prior_ent_mag": 67.00415802001953, "report/prior_ent_max": 67.00415802001953, "report/prior_ent_mean": 54.308135986328125, "report/prior_ent_min": 38.286827087402344, "report/prior_ent_std": 4.911648750305176, "report/rep_loss_mean": 11.669454574584961, "report/rep_loss_std": 8.65517520904541, "report/reward_avg": 0.02753906324505806, "report/reward_loss_mean": 0.05570027977228165, "report/reward_loss_std": 0.24754096567630768, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0076251029968262, "report/reward_neg_acc": 0.9959636330604553, "report/reward_neg_loss": 0.027780350297689438, "report/reward_pos_acc": 0.939393937587738, "report/reward_pos_loss": 0.8941441774368286, "report/reward_pred": 0.025794189423322678, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.180824018680141e-07, "eval/cont_loss_std": 7.696505235799123e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.679922368377447e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.405093428274995e-07, "eval/cont_pred": 0.9960940480232239, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.421483993530273, "eval/dyn_loss_std": 11.055274963378906, "eval/image_loss_mean": 10.528826713562012, "eval/image_loss_std": 15.664419174194336, "eval/model_loss_mean": 19.903043746948242, "eval/model_loss_std": 20.578943252563477, "eval/post_ent_mag": 56.17908477783203, "eval/post_ent_max": 56.17908477783203, "eval/post_ent_mean": 41.2529411315918, "eval/post_ent_min": 19.549972534179688, "eval/post_ent_std": 7.7920660972595215, "eval/prior_ent_mag": 67.00415802001953, "eval/prior_ent_max": 67.00415802001953, "eval/prior_ent_mean": 54.50312423706055, "eval/prior_ent_min": 37.0681037902832, "eval/prior_ent_std": 3.9251303672790527, "eval/rep_loss_mean": 15.421483993530273, "eval/rep_loss_std": 11.055274963378906, "eval/reward_avg": 0.04238281399011612, "eval/reward_loss_mean": 0.12132672965526581, "eval/reward_loss_std": 0.712906002998352, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0111503601074219, "eval/reward_neg_acc": 0.9907881021499634, "eval/reward_neg_loss": 0.04346068575978279, "eval/reward_pos_acc": 0.8297871947288513, "eval/reward_pos_loss": 1.7399463653564453, "eval/reward_pred": 0.03616254776716232, "eval/reward_rate": 0.0458984375, "replay/size": 527753.0, "replay/inserts": 20359.0, "replay/samples": 20352.0, "replay/insert_wait_avg": 1.4129102601887429e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.876646031373701e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.156309484198019e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.5719645023346, "timer/env.step_count": 2545.0, "timer/env.step_total": 239.86924648284912, "timer/env.step_frac": 0.23949277234615526, "timer/env.step_avg": 0.09425117739994071, "timer/env.step_min": 0.023158788681030273, "timer/env.step_max": 3.411771774291992, "timer/replay._sample_count": 20352.0, "timer/replay._sample_total": 10.479728937149048, "timer/replay._sample_frac": 0.010463281030790694, "timer/replay._sample_avg": 0.0005149237881853895, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.010937929153442383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3123.0, "timer/agent.policy_total": 52.74152612686157, "timer/agent.policy_frac": 0.052658748443570914, "timer/agent.policy_avg": 0.01688809674251091, "timer/agent.policy_min": 0.009205102920532227, "timer/agent.policy_max": 0.12734508514404297, "timer/dataset_train_count": 1272.0, "timer/dataset_train_total": 0.15008187294006348, "timer/dataset_train_frac": 0.0001498463198444625, "timer/dataset_train_avg": 0.00011798889382080462, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0008678436279296875, "timer/agent.train_count": 1272.0, "timer/agent.train_total": 567.2602701187134, "timer/agent.train_frac": 0.5663699566516682, "timer/agent.train_avg": 0.4459593318543344, "timer/agent.train_min": 0.43257570266723633, "timer/agent.train_max": 1.2987661361694336, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4728109836578369, "timer/agent.report_frac": 0.00047206890809166097, "timer/agent.report_avg": 0.23640549182891846, "timer/agent.report_min": 0.22742748260498047, "timer/agent.report_max": 0.24538350105285645, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0469680868277604e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 20.326780423901923}
{"step": 528352, "time": 26308.834399700165, "episode/length": 196.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 528696, "time": 26322.74303650856, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 528896, "time": 26331.82806634903, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 529352, "time": 26349.80862569809, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 529424, "time": 26354.263554811478, "episode/length": 315.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 529504, "time": 26358.652589559555, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 529608, "time": 26363.808243513107, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 529680, "time": 26368.1555249691, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 529824, "time": 26374.957669973373, "episode/length": 49.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 26403.233919620514, "eval_episode/length": 107.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 530088, "time": 26406.69783592224, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 530088, "time": 26409.83264708519, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 530088, "time": 26412.009492874146, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 530088, "time": 26414.33778643608, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 530088, "time": 26416.398113965988, "eval_episode/length": 238.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.99581589958159}
{"step": 530088, "time": 26418.962415218353, "eval_episode/length": 263.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 530088, "time": 26421.0402469635, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 530344, "time": 26430.339768648148, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 530664, "time": 26443.60892224312, "episode/length": 288.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 530680, "time": 26445.714916706085, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 530928, "time": 26456.487114429474, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 531072, "time": 26463.257254838943, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 531072, "time": 26463.308171987534, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 531224, "time": 26471.94074034691, "episode/length": 174.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 531368, "time": 26478.74307370186, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 531512, "time": 26485.558722257614, "episode/length": 269.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 532032, "time": 26506.418120861053, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 532120, "time": 26511.04581928253, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 532272, "time": 26518.46165895462, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 532704, "time": 26537.374361753464, "episode/length": 148.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 532704, "time": 26537.413717508316, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 532712, "time": 26541.016192913055, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 532896, "time": 26549.502688407898, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 533104, "time": 26558.72830247879, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9861751152073732, "episode/intrinsic_return": 0.0}
{"step": 533664, "time": 26580.691952943802, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 533816, "time": 26587.745179891586, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 534040, "time": 26597.50359940529, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 534456, "time": 26614.319856643677, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 534488, "time": 26617.18859219551, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 534736, "time": 26628.05327129364, "episode/length": 114.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 535072, "time": 26641.966740608215, "episode/length": 245.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 535200, "time": 26648.302321195602, "episode/length": 88.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 535280, "time": 26652.875484228134, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 535312, "time": 26655.717630147934, "episode/length": 325.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 535408, "time": 26660.74728488922, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 535552, "time": 26667.489431381226, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 535800, "time": 26678.096124649048, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 535808, "time": 26680.190628290176, "episode/length": 65.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 536336, "time": 26701.734398126602, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 536480, "time": 26709.246007680893, "episode/length": 159.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 536592, "time": 26715.623553991318, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 536624, "time": 26718.801317453384, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 536800, "time": 26727.092455625534, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 537248, "time": 26745.052114009857, "episode/length": 211.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 537256, "time": 26746.713136672974, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 537768, "time": 26767.057765722275, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 537880, "time": 26772.658098459244, "episode/length": 174.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 538040, "time": 26780.674257993698, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 538136, "time": 26786.19952249527, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 538168, "time": 26789.012557029724, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 538520, "time": 26803.65188550949, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 539088, "time": 26826.079077720642, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 539192, "time": 26831.380088090897, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 539432, "time": 26841.704818725586, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 539584, "time": 26849.06432580948, "episode/length": 132.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 539776, "time": 26857.708209753036, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 539792, "time": 26859.88397026062, "episode/length": 252.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 26885.67569875717, "eval_episode/length": 33.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 540072, "time": 26889.206971645355, "eval_episode/length": 83.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 540072, "time": 26891.063778162003, "eval_episode/length": 91.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9456521739130435}
{"step": 540072, "time": 26893.876114845276, "eval_episode/length": 124.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.952}
{"step": 540072, "time": 26897.616963386536, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 540072, "time": 26899.47599673271, "eval_episode/length": 187.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 540072, "time": 26902.68421292305, "eval_episode/length": 40.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 540072, "time": 26905.078031778336, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 540112, "time": 26906.78986096382, "episode/length": 357.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 540800, "time": 26935.03917837143, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 540808, "time": 26936.714495658875, "episode/length": 365.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.0}
{"step": 540808, "time": 26936.75596499443, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 541016, "time": 26947.75955104828, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 541088, "time": 26952.15148997307, "episode/length": 35.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 541104, "time": 26954.297163963318, "episode/length": 208.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 541232, "time": 26960.52869272232, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 541296, "time": 26964.351621627808, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 541728, "time": 26982.24346423149, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 541744, "time": 26984.86753487587, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 542224, "time": 27004.988627910614, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 542392, "time": 27013.17996764183, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 542720, "time": 27026.935846567154, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 542832, "time": 27032.633003234863, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 542880, "time": 27035.840983629227, "episode/length": 197.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 542896, "time": 27038.032702207565, "episode/length": 223.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 543320, "time": 27054.8398938179, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 543688, "time": 27069.951102018356, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 544008, "time": 27083.18746304512, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 544072, "time": 27087.057461977005, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 544416, "time": 27101.518701791763, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 544616, "time": 27110.12589740753, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 545232, "time": 27134.516696691513, "episode/length": 293.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 545384, "time": 27141.52005791664, "episode/length": 310.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 545408, "time": 27144.076278209686, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 545496, "time": 27148.655990362167, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 545632, "time": 27155.331265211105, "episode/length": 349.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 545648, "time": 27157.64301967621, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 546416, "time": 27187.3300716877, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 547048, "time": 27211.597614765167, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 547072, "time": 27214.187338113785, "episode/length": 207.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 547104, "time": 27217.095829486847, "episode/length": 181.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 547184, "time": 27221.4881503582, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 547192, "time": 27223.11230111122, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 547368, "time": 27231.184396743774, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 547688, "time": 27244.42196726799, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 548048, "time": 27259.433176279068, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 548448, "time": 27275.615080356598, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 548520, "time": 27279.73598098755, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 548528, "time": 27281.770156621933, "episode/length": 181.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 548576, "time": 27285.07569360733, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 548800, "time": 27294.731887817383, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 548985, "time": 27305.354514837265, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.416810490534856, "train/action_min": 0.0, "train/action_std": 3.4588959602209237, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04392095716813436, "train/actor_opt_grad_steps": 33565.0, "train/actor_opt_loss": -2.4598797662470204, "train/adv_mag": 0.633054588161982, "train/adv_max": 0.579649955034256, "train/adv_mean": 0.0037312682157230135, "train/adv_min": -0.49063429373961226, "train/adv_std": 0.0662348839525993, "train/cont_avg": 0.9944486177884615, "train/cont_loss_mean": 0.00022959460591515872, "train/cont_loss_std": 0.0060502395871620904, "train/cont_neg_acc": 0.9946916979092818, "train/cont_neg_loss": 0.020645608187924852, "train/cont_pos_acc": 0.9999772993417887, "train/cont_pos_loss": 7.169325475104507e-05, "train/cont_pred": 0.9944408049950233, "train/cont_rate": 0.9944486177884615, "train/dyn_loss_mean": 12.669865600879376, "train/dyn_loss_std": 9.029538227961613, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8170499764955961, "train/extr_critic_critic_opt_grad_steps": 33565.0, "train/extr_critic_critic_opt_loss": 15660.527614182693, "train/extr_critic_mag": 6.017974956219013, "train/extr_critic_max": 6.017974956219013, "train/extr_critic_mean": 1.5054062027197617, "train/extr_critic_min": -0.29739272411052997, "train/extr_critic_std": 1.3731400549411774, "train/extr_return_normed_mag": 1.6834310467426594, "train/extr_return_normed_max": 1.6834310467426594, "train/extr_return_normed_mean": 0.36192347464653163, "train/extr_return_normed_min": -0.15323479358966535, "train/extr_return_normed_std": 0.33245764260108657, "train/extr_return_rate": 0.684727599299871, "train/extr_return_raw_mag": 7.121545593555157, "train/extr_return_raw_max": 7.121545593555157, "train/extr_return_raw_mean": 1.5212220320334802, "train/extr_return_raw_min": -0.6617556665952389, "train/extr_return_raw_std": 1.409144108570539, "train/extr_reward_mag": 1.0222448073900663, "train/extr_reward_max": 1.0222448073900663, "train/extr_reward_mean": 0.03234190175023217, "train/extr_reward_min": -0.4716845833338224, "train/extr_reward_std": 0.1698286293217769, "train/image_loss_mean": 6.117735261183519, "train/image_loss_std": 10.393635104252741, "train/model_loss_mean": 13.772366252312294, "train/model_loss_std": 14.112035692655123, "train/model_opt_grad_norm": 56.04489055046668, "train/model_opt_grad_steps": 33535.0, "train/model_opt_loss": 14368.045966045673, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1043.2692307692307, "train/policy_entropy_mag": 2.556297654371995, "train/policy_entropy_max": 2.556297654371995, "train/policy_entropy_mean": 0.5764164589918577, "train/policy_entropy_min": 0.0793750487267971, "train/policy_entropy_std": 0.6665382779561556, "train/policy_logprob_mag": 7.438383593926063, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5761198584850018, "train/policy_logprob_min": -7.438383593926063, "train/policy_logprob_std": 1.1255258257572467, "train/policy_randomness_mag": 0.9022608926663032, "train/policy_randomness_max": 0.9022608926663032, "train/policy_randomness_mean": 0.2034497156739235, "train/policy_randomness_min": 0.028015908914116712, "train/policy_randomness_std": 0.23525876242380875, "train/post_ent_mag": 58.00114775437575, "train/post_ent_max": 58.00114775437575, "train/post_ent_mean": 41.511288716242866, "train/post_ent_min": 20.42240494948167, "train/post_ent_std": 7.436527087138249, "train/prior_ent_mag": 66.82372759305514, "train/prior_ent_max": 66.82372759305514, "train/prior_ent_mean": 54.22726666377141, "train/prior_ent_min": 39.09721098679763, "train/prior_ent_std": 4.363802412840037, "train/rep_loss_mean": 12.669865600879376, "train/rep_loss_std": 9.029538227961613, "train/reward_avg": 0.026212439822176328, "train/reward_loss_mean": 0.052482060013482205, "train/reward_loss_std": 0.2428096174620665, "train/reward_max_data": 1.0115384642894452, "train/reward_max_pred": 1.0052503594985376, "train/reward_neg_acc": 0.9933552407301389, "train/reward_neg_loss": 0.02680518116372136, "train/reward_pos_acc": 0.963238242497811, "train/reward_pos_loss": 0.8574366982166584, "train/reward_pred": 0.025251728367920105, "train/reward_rate": 0.031084735576923078, "train_stats/sum_log_reward": 6.413725497675877, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.2254901960784315, "train_stats/max_log_achievement_collect_sapling": 2.6176470588235294, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 10.343137254901961, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.9215686274509803, "train_stats/max_log_achievement_eat_cow": 0.11764705882352941, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0196078431372549, "train_stats/max_log_achievement_make_wood_sword": 1.7254901960784315, "train_stats/max_log_achievement_place_plant": 2.5784313725490198, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.843137254901961, "train_stats/max_log_achievement_wake_up": 1.8725490196078431, "train_stats/mean_log_entropy": 0.5528154311811223, "eval_stats/sum_log_reward": 5.412500090897083, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 5.9001922636525705e-06, "report/cont_loss_std": 0.00011818317580036819, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00017492042388767004, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.233325398672605e-06, "report/cont_pred": 0.990231990814209, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 11.499687194824219, "report/dyn_loss_std": 8.54682731628418, "report/image_loss_mean": 4.2150068283081055, "report/image_loss_std": 7.765384197235107, "report/model_loss_mean": 11.166967391967773, "report/model_loss_std": 11.268864631652832, "report/post_ent_mag": 56.57033157348633, "report/post_ent_max": 56.57033157348633, "report/post_ent_mean": 41.770545959472656, "report/post_ent_min": 21.674592971801758, "report/post_ent_std": 6.88861083984375, "report/prior_ent_mag": 67.00028228759766, "report/prior_ent_max": 67.00028228759766, "report/prior_ent_mean": 53.396827697753906, "report/prior_ent_min": 39.56280517578125, "report/prior_ent_std": 4.243197441101074, "report/rep_loss_mean": 11.499687194824219, "report/rep_loss_std": 8.54682731628418, "report/reward_avg": 0.02841797098517418, "report/reward_loss_mean": 0.052142009139060974, "report/reward_loss_std": 0.17437656223773956, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020592212677002, "report/reward_neg_acc": 0.9908813834190369, "report/reward_neg_loss": 0.027626777067780495, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7061023116111755, "report/reward_pred": 0.02733084186911583, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 4.223427822580561e-06, "eval/cont_loss_std": 7.193456258391961e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00026160647394135594, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.4518626560166012e-06, "eval/cont_pred": 0.9931634664535522, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 17.052478790283203, "eval/dyn_loss_std": 10.599996566772461, "eval/image_loss_mean": 18.670848846435547, "eval/image_loss_std": 29.026113510131836, "eval/model_loss_mean": 28.99428939819336, "eval/model_loss_std": 32.61203384399414, "eval/post_ent_mag": 60.262420654296875, "eval/post_ent_max": 60.262420654296875, "eval/post_ent_mean": 40.70301055908203, "eval/post_ent_min": 20.73410987854004, "eval/post_ent_std": 7.5657453536987305, "eval/prior_ent_mag": 67.00028228759766, "eval/prior_ent_max": 67.00028228759766, "eval/prior_ent_mean": 54.91706848144531, "eval/prior_ent_min": 43.41412353515625, "eval/prior_ent_std": 4.056002140045166, "eval/rep_loss_mean": 17.052478790283203, "eval/rep_loss_std": 10.599996566772461, "eval/reward_avg": 0.02080078050494194, "eval/reward_loss_mean": 0.09194903075695038, "eval/reward_loss_std": 0.5685508847236633, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000586748123169, "eval/reward_neg_acc": 0.9869478940963745, "eval/reward_neg_loss": 0.05143588408827782, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.5330597162246704, "eval/reward_pred": 0.02305540069937706, "eval/reward_rate": 0.02734375, "replay/size": 548481.0, "replay/inserts": 20728.0, "replay/samples": 20736.0, "replay/insert_wait_avg": 1.3688479275926114e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.822189802004968e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0755618261333634e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2490780353546, "timer/env.step_count": 2591.0, "timer/env.step_total": 231.4730405807495, "timer/env.step_frac": 0.2314154000875449, "timer/env.step_avg": 0.0893373371596872, "timer/env.step_min": 0.023371219635009766, "timer/env.step_max": 3.5444445610046387, "timer/replay._sample_count": 20736.0, "timer/replay._sample_total": 10.662227630615234, "timer/replay._sample_frac": 0.010659572565222968, "timer/replay._sample_avg": 0.0005141892182974168, "timer/replay._sample_min": 0.00041556358337402344, "timer/replay._sample_max": 0.010999441146850586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3114.0, "timer/agent.policy_total": 50.711872816085815, "timer/agent.policy_frac": 0.05069924474781007, "timer/agent.policy_avg": 0.0162851229338747, "timer/agent.policy_min": 0.009426355361938477, "timer/agent.policy_max": 0.12424421310424805, "timer/dataset_train_count": 1296.0, "timer/dataset_train_total": 0.15333318710327148, "timer/dataset_train_frac": 0.00015329500468467495, "timer/dataset_train_avg": 0.00011831264436980825, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.0010805130004882812, "timer/agent.train_count": 1296.0, "timer/agent.train_total": 579.743486404419, "timer/agent.train_frac": 0.5795991209940685, "timer/agent.train_avg": 0.44733293704044674, "timer/agent.train_min": 0.4340066909790039, "timer/agent.train_max": 1.2481582164764404, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473313570022583, "timer/agent.report_frac": 0.0004731957073654542, "timer/agent.report_avg": 0.2366567850112915, "timer/agent.report_min": 0.22935795783996582, "timer/agent.report_max": 0.2439556121826172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.5266076160154535e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 20.72256305344585}
{"step": 549728, "time": 27332.605501174927, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 549816, "time": 27337.19385957718, "episode/length": 154.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 549904, "time": 27342.17331147194, "episode/length": 181.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 549952, "time": 27345.48755478859, "episode/length": 178.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 549952, "time": 27345.53662919998, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 27368.511096954346, "eval_episode/length": 74.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9466666666666667}
{"step": 550056, "time": 27373.10205936432, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 550056, "time": 27376.058921575546, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 550056, "time": 27379.200460910797, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 550056, "time": 27380.931876420975, "eval_episode/length": 35.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 550056, "time": 27383.276169776917, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 550056, "time": 27385.165123701096, "eval_episode/length": 216.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 550056, "time": 27386.700706005096, "eval_episode/length": 33.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 550200, "time": 27391.950669765472, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 550480, "time": 27403.929133415222, "episode/length": 65.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 550568, "time": 27408.62008881569, "episode/length": 421.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 550608, "time": 27411.880555152893, "episode/length": 225.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 550864, "time": 27422.805283784866, "episode/length": 291.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 551288, "time": 27439.788002967834, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 551400, "time": 27445.474671840668, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 551624, "time": 27455.19730257988, "episode/length": 208.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 551896, "time": 27466.930366516113, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 551976, "time": 27471.500054836273, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 552448, "time": 27490.652830839157, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 552688, "time": 27501.002489089966, "episode/length": 310.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 552696, "time": 27502.576101064682, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 552744, "time": 27505.826071739197, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 552760, "time": 27507.95114850998, "episode/length": 169.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 553216, "time": 27526.49361681938, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 553400, "time": 27534.488198041916, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 553872, "time": 27553.628122329712, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 554160, "time": 27565.753659248352, "episode/length": 282.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 554312, "time": 27572.71279478073, "episode/length": 193.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 554312, "time": 27572.759819746017, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 554336, "time": 27577.24879527092, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 554488, "time": 27583.986914873123, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 554840, "time": 27598.399540662766, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 554864, "time": 27600.990982294083, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.969811320754717, "episode/intrinsic_return": 0.0}
{"step": 555176, "time": 27613.834606170654, "episode/length": 38.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 555208, "time": 27616.62558412552, "episode/length": 45.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 555368, "time": 27623.996434688568, "episode/length": 131.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 555424, "time": 27627.745712518692, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 555720, "time": 27639.945949077606, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 555800, "time": 27644.40425014496, "episode/length": 240.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 556024, "time": 27654.01903605461, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 556368, "time": 27668.51455807686, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 556448, "time": 27672.860409498215, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 557040, "time": 27695.974746227264, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 557120, "time": 27702.168462514877, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 557240, "time": 27708.03001689911, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 557408, "time": 27716.000008821487, "episode/length": 274.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 557472, "time": 27719.8371694088, "episode/length": 372.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9865951742627346, "episode/intrinsic_return": 0.0}
{"step": 557800, "time": 27733.377481222153, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 558056, "time": 27744.315166950226, "episode/length": 126.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9448818897637795, "episode/intrinsic_return": 0.0}
{"step": 558136, "time": 27748.76575231552, "episode/length": 210.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 558200, "time": 27752.731153726578, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 558504, "time": 27765.540587186813, "episode/length": 172.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 558864, "time": 27780.543764591217, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 558880, "time": 27782.592135429382, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 559392, "time": 27803.03710913658, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 559528, "time": 27809.322966098785, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 559912, "time": 27825.167937278748, "episode/length": 213.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 27851.21891093254, "eval_episode/length": 180.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 560040, "time": 27852.858741283417, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9836956521739131}
{"step": 560040, "time": 27854.755069494247, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 560040, "time": 27856.410733938217, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 560040, "time": 27858.1128885746, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9644670050761421}
{"step": 560040, "time": 27860.952763795853, "eval_episode/length": 225.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.995575221238938}
{"step": 560040, "time": 27862.689919948578, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 560040, "time": 27866.563526391983, "eval_episode/length": 94.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 560352, "time": 27878.32869386673, "episode/length": 185.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 560352, "time": 27878.377821683884, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 560416, "time": 27883.87773323059, "episode/length": 294.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 560976, "time": 27905.852435588837, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 561448, "time": 27924.632529735565, "episode/length": 191.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 561504, "time": 27928.48096370697, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 561880, "time": 27943.872684001923, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 562144, "time": 27955.843732833862, "episode/length": 583.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9914383561643836, "episode/intrinsic_return": 0.0}
{"step": 562296, "time": 27962.775638580322, "episode/length": 234.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 562552, "time": 27973.63631772995, "episode/length": 196.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 562704, "time": 27981.02749824524, "episode/length": 477.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.997907949790795, "episode/intrinsic_return": 0.0}
{"step": 562840, "time": 27987.24290394783, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 563264, "time": 28004.473427295685, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 563408, "time": 28011.291248321533, "episode/length": 106.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 563440, "time": 28014.0635535717, "episode/length": 385.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 563552, "time": 28019.701331615448, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 563608, "time": 28023.03789949417, "episode/length": 163.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 563664, "time": 28026.873663425446, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 564048, "time": 28042.331271886826, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 564120, "time": 28046.28749012947, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 564568, "time": 28064.734436511993, "episode/length": 64.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 564848, "time": 28077.429246664047, "episode/length": 154.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 564872, "time": 28080.169892311096, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 565144, "time": 28092.58091902733, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 565160, "time": 28095.20761179924, "episode/length": 218.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 565184, "time": 28098.316826343536, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 565864, "time": 28127.10632634163, "episode/length": 87.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 566272, "time": 28143.724642276764, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 566408, "time": 28150.089080810547, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 566568, "time": 28157.43147611618, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 566584, "time": 28159.5111348629, "episode/length": 307.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 566648, "time": 28163.389574050903, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 567376, "time": 28191.69892168045, "episode/length": 120.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 567504, "time": 28197.794781923294, "episode/length": 294.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 567688, "time": 28205.81467652321, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 567704, "time": 28208.080223560333, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 568200, "time": 28227.699634313583, "episode/length": 203.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 568312, "time": 28233.33341884613, "episode/length": 429.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 568648, "time": 28247.2441072464, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 568944, "time": 28259.812683582306, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 569208, "time": 28270.921040296555, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 569640, "time": 28288.224364757538, "episode/length": 243.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 569688, "time": 28291.558946609497, "episode/length": 379.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 570001, "time": 28305.380286455154, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.480725004472806, "train/action_min": 0.0, "train/action_std": 3.5404992649573406, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042479136859187645, "train/actor_opt_grad_steps": 34870.0, "train/actor_opt_loss": -3.3523522566804904, "train/adv_mag": 0.6194459666277616, "train/adv_max": 0.5808288875881952, "train/adv_mean": 0.002957293812938893, "train/adv_min": -0.46796661842870346, "train/adv_std": 0.06414072465805606, "train/cont_avg": 0.9945953602099237, "train/cont_loss_mean": 0.0002980456770373833, "train/cont_loss_std": 0.008934921185286597, "train/cont_neg_acc": 0.9926282057395348, "train/cont_neg_loss": 0.04258577931281112, "train/cont_pos_acc": 0.9999474186933678, "train/cont_pos_loss": 0.00013724818587490105, "train/cont_pred": 0.9945976097165173, "train/cont_rate": 0.9945953602099237, "train/dyn_loss_mean": 12.590030750245539, "train/dyn_loss_std": 9.02640620806745, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8099485117060538, "train/extr_critic_critic_opt_grad_steps": 34870.0, "train/extr_critic_critic_opt_loss": 15525.066734255724, "train/extr_critic_mag": 6.143579574031684, "train/extr_critic_max": 6.143579574031684, "train/extr_critic_mean": 1.4744420219923704, "train/extr_critic_min": -0.27631712414836157, "train/extr_critic_std": 1.3630434643221265, "train/extr_return_normed_mag": 1.692445288177665, "train/extr_return_normed_max": 1.692445288177665, "train/extr_return_normed_mean": 0.34884831388943066, "train/extr_return_normed_min": -0.1515921871284492, "train/extr_return_normed_std": 0.32904018006706964, "train/extr_return_rate": 0.6724714115830778, "train/extr_return_raw_mag": 7.173249051771091, "train/extr_return_raw_max": 7.173249051771091, "train/extr_return_raw_mean": 1.4869330015801292, "train/extr_return_raw_min": -0.6300475765730589, "train/extr_return_raw_std": 1.3921480410881626, "train/extr_reward_mag": 1.0198698444220855, "train/extr_reward_max": 1.0198698444220855, "train/extr_reward_mean": 0.03088313975293218, "train/extr_reward_min": -0.4524051988397846, "train/extr_reward_std": 0.16584497053204603, "train/image_loss_mean": 6.0763574410940855, "train/image_loss_std": 10.550480627831613, "train/model_loss_mean": 13.682411004568785, "train/model_loss_std": 14.25268604191205, "train/model_opt_grad_norm": 58.02256560871619, "train/model_opt_grad_steps": 34838.99236641221, "train/model_opt_loss": 17508.997875417463, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1278.6259541984732, "train/policy_entropy_mag": 2.588819339985156, "train/policy_entropy_max": 2.588819339985156, "train/policy_entropy_mean": 0.5832298939464656, "train/policy_entropy_min": 0.07937504766324094, "train/policy_entropy_std": 0.6800848991816281, "train/policy_logprob_mag": 7.438383513734541, "train/policy_logprob_max": -0.009455658466988847, "train/policy_logprob_mean": -0.5818973438430378, "train/policy_logprob_min": -7.438383513734541, "train/policy_logprob_std": 1.1316843979231275, "train/policy_randomness_mag": 0.9137396184542707, "train/policy_randomness_max": 0.9137396184542707, "train/policy_randomness_mean": 0.20585455899020189, "train/policy_randomness_min": 0.02801590842258839, "train/policy_randomness_std": 0.2400401246001702, "train/post_ent_mag": 58.66258778462883, "train/post_ent_max": 58.66258778462883, "train/post_ent_mean": 41.639069244151806, "train/post_ent_min": 20.433951996664966, "train/post_ent_std": 7.446286725633927, "train/prior_ent_mag": 67.0174410870967, "train/prior_ent_max": 67.0174410870967, "train/prior_ent_mean": 54.2774452325952, "train/prior_ent_min": 38.880269887793155, "train/prior_ent_std": 4.406255707485985, "train/rep_loss_mean": 12.590030750245539, "train/rep_loss_std": 9.02640620806745, "train/reward_avg": 0.02589083353469845, "train/reward_loss_mean": 0.05173704844280964, "train/reward_loss_std": 0.23353819253335473, "train/reward_max_data": 1.017557256094372, "train/reward_max_pred": 1.0080816645658652, "train/reward_neg_acc": 0.9932376414764928, "train/reward_neg_loss": 0.02764541601747957, "train/reward_pos_acc": 0.9748706963226086, "train/reward_pos_loss": 0.8129212824442914, "train/reward_pred": 0.025303677677084472, "train/reward_rate": 0.03069089933206107, "train_stats/sum_log_reward": 6.378350506123808, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.56701030927835, "train_stats/max_log_achievement_collect_sapling": 2.8969072164948453, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.43298969072165, "train_stats/max_log_achievement_defeat_skeleton": 0.030927835051546393, "train_stats/max_log_achievement_defeat_zombie": 0.7938144329896907, "train_stats/max_log_achievement_eat_cow": 0.18556701030927836, "train_stats/max_log_achievement_eat_plant": 0.010309278350515464, "train_stats/max_log_achievement_make_wood_pickaxe": 0.020618556701030927, "train_stats/max_log_achievement_make_wood_sword": 1.4742268041237114, "train_stats/max_log_achievement_place_plant": 2.8556701030927836, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.7216494845360826, "train_stats/max_log_achievement_wake_up": 1.958762886597938, "train_stats/mean_log_entropy": 0.5668279393432066, "eval_stats/sum_log_reward": 5.724999941885471, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.859039563598344e-06, "report/cont_loss_std": 0.00013799815496895462, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015174860891420394, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.427434305398492e-06, "report/cont_pred": 0.9970663785934448, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.29513931274414, "report/dyn_loss_std": 9.052655220031738, "report/image_loss_mean": 4.764208793640137, "report/image_loss_std": 10.921456336975098, "report/model_loss_mean": 11.581586837768555, "report/model_loss_std": 14.625697135925293, "report/post_ent_mag": 59.119285583496094, "report/post_ent_max": 59.119285583496094, "report/post_ent_mean": 43.00657272338867, "report/post_ent_min": 20.355066299438477, "report/post_ent_std": 8.00414752960205, "report/prior_ent_mag": 66.85421752929688, "report/prior_ent_max": 66.85421752929688, "report/prior_ent_mean": 54.347564697265625, "report/prior_ent_min": 40.49959182739258, "report/prior_ent_std": 3.6796138286590576, "report/rep_loss_mean": 11.29513931274414, "report/rep_loss_std": 9.052655220031738, "report/reward_avg": 0.02207031287252903, "report/reward_loss_mean": 0.040290139615535736, "report/reward_loss_std": 0.26117393374443054, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00057053565979, "report/reward_neg_acc": 0.9959920048713684, "report/reward_neg_loss": 0.012023815885186195, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 1.1252820491790771, "report/reward_pred": 0.01884988695383072, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.403295008614805e-07, "eval/cont_loss_std": 8.262699338956736e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00018273750902153552, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.358352943105274e-08, "eval/cont_pred": 0.9980471134185791, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.336250305175781, "eval/dyn_loss_std": 10.279481887817383, "eval/image_loss_mean": 9.798564910888672, "eval/image_loss_std": 15.1048002243042, "eval/model_loss_mean": 19.106765747070312, "eval/model_loss_std": 19.135787963867188, "eval/post_ent_mag": 57.9117431640625, "eval/post_ent_max": 57.9117431640625, "eval/post_ent_mean": 40.95781707763672, "eval/post_ent_min": 19.53728485107422, "eval/post_ent_std": 7.283149242401123, "eval/prior_ent_mag": 66.85421752929688, "eval/prior_ent_max": 66.85421752929688, "eval/prior_ent_mean": 54.21718978881836, "eval/prior_ent_min": 35.48653793334961, "eval/prior_ent_std": 3.922992706298828, "eval/rep_loss_mean": 15.336250305175781, "eval/rep_loss_std": 10.279481887817383, "eval/reward_avg": 0.02714843675494194, "eval/reward_loss_mean": 0.10644929111003876, "eval/reward_loss_std": 0.779580295085907, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023672580718994, "eval/reward_neg_acc": 0.9899396300315857, "eval/reward_neg_loss": 0.015223374590277672, "eval/reward_pos_acc": 0.5666667222976685, "eval/reward_pos_loss": 3.12906813621521, "eval/reward_pred": 0.016373757272958755, "eval/reward_rate": 0.029296875, "replay/size": 569497.0, "replay/inserts": 21016.0, "replay/samples": 21008.0, "replay/insert_wait_avg": 1.3938570004431613e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.139870653058042e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0878729397023218e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4454126358032227e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0153391361237, "timer/env.step_count": 2627.0, "timer/env.step_total": 222.2250051498413, "timer/env.step_frac": 0.22222159646252354, "timer/env.step_avg": 0.08459269324318283, "timer/env.step_min": 0.02338409423828125, "timer/env.step_max": 3.406808853149414, "timer/replay._sample_count": 21008.0, "timer/replay._sample_total": 10.778793811798096, "timer/replay._sample_frac": 0.010778628476948661, "timer/replay._sample_avg": 0.0005130804365859718, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.008533239364624023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3134.0, "timer/agent.policy_total": 51.36811065673828, "timer/agent.policy_frac": 0.051367322726382676, "timer/agent.policy_avg": 0.016390590509488923, "timer/agent.policy_min": 0.009524822235107422, "timer/agent.policy_max": 0.10550761222839355, "timer/dataset_train_count": 1313.0, "timer/dataset_train_total": 0.15411376953125, "timer/dataset_train_frac": 0.00015411140559542136, "timer/dataset_train_avg": 0.00011737530048076923, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.0010836124420166016, "timer/agent.train_count": 1313.0, "timer/agent.train_total": 586.7098183631897, "timer/agent.train_frac": 0.586700818879465, "timer/agent.train_avg": 0.44684677712352605, "timer/agent.train_min": 0.4342033863067627, "timer/agent.train_max": 1.2962069511413574, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46973133087158203, "timer/agent.report_frac": 0.0004697241257092772, "timer/agent.report_avg": 0.23486566543579102, "timer/agent.report_min": 0.22792959213256836, "timer/agent.report_max": 0.24180173873901367, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9563450330804842e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 21.015398689505545}
{"step": 570024, "time": 28325.380950450897, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 570024, "time": 28327.433159589767, "eval_episode/length": 159.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 570024, "time": 28329.93633365631, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 570024, "time": 28332.33683681488, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 570024, "time": 28336.168697834015, "eval_episode/length": 215.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 570024, "time": 28339.539353132248, "eval_episode/length": 242.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 570024, "time": 28343.032835245132, "eval_episode/length": 292.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9795221843003413}
{"step": 570024, "time": 28345.720501422882, "eval_episode/length": 150.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 570216, "time": 28352.732409715652, "episode/length": 313.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 570216, "time": 28352.78187084198, "episode/length": 251.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 570440, "time": 28364.423627138138, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 570568, "time": 28370.707100391388, "episode/length": 398.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 570872, "time": 28383.315202474594, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 571120, "time": 28394.200325489044, "episode/length": 308.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 571560, "time": 28411.58061504364, "episode/length": 293.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 571560, "time": 28411.62985920906, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 571880, "time": 28426.613461494446, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 571936, "time": 28430.50930094719, "episode/length": 186.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 571944, "time": 28432.09668135643, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 572576, "time": 28457.09792137146, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 573040, "time": 28475.656042575836, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 573152, "time": 28481.414480686188, "episode/length": 198.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 573320, "time": 28488.91713833809, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 573496, "time": 28498.47844696045, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 573536, "time": 28501.63105726242, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 574056, "time": 28522.06615447998, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 574336, "time": 28534.051121234894, "episode/length": 298.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 574600, "time": 28545.089399814606, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 574648, "time": 28548.383006811142, "episode/length": 509.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 574848, "time": 28557.465945005417, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 574960, "time": 28563.119988441467, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 575008, "time": 28566.56486058235, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 575224, "time": 28575.686093091965, "episode/length": 46.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 575384, "time": 28583.110553741455, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 575512, "time": 28589.306979894638, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 575768, "time": 28600.184009552002, "episode/length": 47.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 576152, "time": 28615.80161356926, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 576432, "time": 28627.890036582947, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 576496, "time": 28631.791614294052, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 576632, "time": 28638.113919734955, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 576832, "time": 28647.3173558712, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 576888, "time": 28650.6849732399, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 577144, "time": 28661.69524025917, "episode/length": 311.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 577184, "time": 28664.85795044899, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 577816, "time": 28689.61575627327, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 577960, "time": 28697.250967502594, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 578016, "time": 28701.130964517593, "episode/length": 189.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 578088, "time": 28705.19303703308, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.961352657004831, "episode/intrinsic_return": 0.0}
{"step": 578360, "time": 28716.980303764343, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 578384, "time": 28720.117322206497, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 578864, "time": 28740.11626434326, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 578888, "time": 28742.356712818146, "episode/length": 256.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 579176, "time": 28754.498678684235, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 579688, "time": 28774.70631456375, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 579752, "time": 28778.739716768265, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 579760, "time": 28780.788819789886, "episode/length": 224.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 580000, "time": 28791.06671142578, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 28813.455843925476, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 580008, "time": 28815.189474105835, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 580008, "time": 28816.916518449783, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9665071770334929}
{"step": 580008, "time": 28819.032302856445, "eval_episode/length": 223.0, "eval_episode/score": 5.100000016391277, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 580008, "time": 28821.45952630043, "eval_episode/length": 247.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 580008, "time": 28823.725235700607, "eval_episode/length": 63.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.984375}
{"step": 580008, "time": 28825.392609119415, "eval_episode/length": 267.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.996268656716418}
{"step": 580008, "time": 28828.34696817398, "eval_episode/length": 302.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.976897689768977}
{"step": 580072, "time": 28830.69309616089, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 580632, "time": 28852.81863808632, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 580664, "time": 28855.479060649872, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 580896, "time": 28865.612134456635, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 581120, "time": 28875.45627474785, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 581424, "time": 28888.033141374588, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 581560, "time": 28894.2956430912, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 582064, "time": 28916.20299911499, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 582200, "time": 28922.427050590515, "episode/length": 304.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 582416, "time": 28932.121290445328, "episode/length": 218.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 582608, "time": 28940.6704120636, "episode/length": 185.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 583128, "time": 28961.0459754467, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 583448, "time": 28974.22743153572, "episode/length": 235.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 583544, "time": 28979.271060466766, "episode/length": 330.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 583672, "time": 28985.54153752327, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 583760, "time": 28990.67297244072, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 583776, "time": 28992.683289527893, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 583912, "time": 28998.872052907944, "episode/length": 527.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990530303030303, "episode/intrinsic_return": 0.0}
{"step": 584384, "time": 29018.01690530777, "episode/length": 58.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 584568, "time": 29026.0225212574, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 584640, "time": 29030.381674051285, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 584664, "time": 29032.60906124115, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 584984, "time": 29045.87644147873, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 585176, "time": 29054.532010793686, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 585184, "time": 29056.61837363243, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 585824, "time": 29081.710074186325, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 586072, "time": 29092.89754629135, "episode/length": 175.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 586200, "time": 29099.783646583557, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 586672, "time": 29119.92603468895, "episode/length": 253.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 586912, "time": 29131.004017591476, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 587096, "time": 29139.56070303917, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 587296, "time": 29148.546539783478, "episode/length": 468.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893390191897654, "episode/intrinsic_return": 0.0}
{"step": 587808, "time": 29168.856955766678, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 588000, "time": 29177.400614976883, "episode/length": 352.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 588200, "time": 29185.985909700394, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.964, "episode/intrinsic_return": 0.0}
{"step": 588400, "time": 29194.97357749939, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 588424, "time": 29197.310204029083, "episode/length": 188.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 588488, "time": 29201.219664812088, "episode/length": 437.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 588768, "time": 29213.228021383286, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 588864, "time": 29218.253124713898, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 589280, "time": 29235.089400053024, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 589376, "time": 29240.130156993866, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 589376, "time": 29240.17964029312, "episode/length": 110.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 589720, "time": 29255.761712551117, "episode/length": 54.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 589752, "time": 29258.605074882507, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 589856, "time": 29266.38724255562, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 590040, "time": 29275.09904742241, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 590080, "time": 29278.92456293106, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 29307.180791139603, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 590096, "time": 29309.173120498657, "eval_episode/length": 166.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 590096, "time": 29312.006457328796, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 590096, "time": 29314.65353822708, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 590096, "time": 29317.376872062683, "eval_episode/length": 209.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 590096, "time": 29319.739914894104, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 590096, "time": 29326.71913599968, "eval_episode/length": 326.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9938837920489296}
{"step": 590096, "time": 29329.76055431366, "eval_episode/length": 186.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 590097, "time": 29330.3837082386, "eval_stats/sum_log_reward": 6.683333297570546, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.041666666666667, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.833333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.2916666666666667, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 1.1666666666666667, "eval_stats/max_log_achievement_place_plant": 1.9166666666666667, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3357040163070435, "train/action_min": 0.0, "train/action_std": 3.456585482945518, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04285181024008327, "train/actor_opt_grad_steps": 36155.0, "train/actor_opt_loss": -2.1495481670375853, "train/adv_mag": 0.5924211702649556, "train/adv_max": 0.5576579887715597, "train/adv_mean": 0.0032775869601050904, "train/adv_min": -0.44189367076707264, "train/adv_std": 0.06390369999858123, "train/cont_avg": 0.9949311755952381, "train/cont_loss_mean": 0.0003175111728760764, "train/cont_loss_std": 0.009552008021024622, "train/cont_neg_acc": 0.9911816583739387, "train/cont_neg_loss": 0.04675360173094969, "train/cont_pos_acc": 0.9999376658409361, "train/cont_pos_loss": 0.00010655715464570636, "train/cont_pred": 0.994923384416671, "train/cont_rate": 0.9949311755952381, "train/dyn_loss_mean": 12.588431434025841, "train/dyn_loss_std": 9.00229697378855, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7922958088299584, "train/extr_critic_critic_opt_grad_steps": 36155.0, "train/extr_critic_critic_opt_loss": 15464.46878875248, "train/extr_critic_mag": 6.192417398331657, "train/extr_critic_max": 6.192417398331657, "train/extr_critic_mean": 1.494683009291452, "train/extr_critic_min": -0.27579758280799505, "train/extr_critic_std": 1.3425710811501457, "train/extr_return_normed_mag": 1.6680395413958837, "train/extr_return_normed_max": 1.6680395413958837, "train/extr_return_normed_mean": 0.34705521710335263, "train/extr_return_normed_min": -0.1553269046403113, "train/extr_return_normed_std": 0.32128863415074727, "train/extr_return_rate": 0.6826518421608304, "train/extr_return_raw_mag": 7.168080939186944, "train/extr_return_raw_max": 7.168080939186944, "train/extr_return_raw_mean": 1.508745109751111, "train/extr_return_raw_min": -0.6431069285387084, "train/extr_return_raw_std": 1.3765558434857263, "train/extr_reward_mag": 1.0194976083816043, "train/extr_reward_max": 1.0194976083816043, "train/extr_reward_mean": 0.03031667899931707, "train/extr_reward_min": -0.4689931964117383, "train/extr_reward_std": 0.16474464914155384, "train/image_loss_mean": 6.041895786921184, "train/image_loss_std": 10.398117678506035, "train/model_loss_mean": 13.647851262773786, "train/model_loss_std": 14.109820388612293, "train/model_opt_grad_norm": 58.05564612434024, "train/model_opt_grad_steps": 36122.28571428572, "train/model_opt_loss": 10940.744074745784, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 803.5714285714286, "train/policy_entropy_mag": 2.5981843736436634, "train/policy_entropy_max": 2.5981843736436634, "train/policy_entropy_mean": 0.553713592745009, "train/policy_entropy_min": 0.07937504912889193, "train/policy_entropy_std": 0.6431850488223727, "train/policy_logprob_mag": 7.438383548978775, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5538235950091529, "train/policy_logprob_min": -7.438383548978775, "train/policy_logprob_std": 1.1161211492523315, "train/policy_randomness_mag": 0.9170450677001287, "train/policy_randomness_max": 0.9170450677001287, "train/policy_randomness_mean": 0.19543659947221242, "train/policy_randomness_min": 0.02801590899212493, "train/policy_randomness_std": 0.22701609619553126, "train/post_ent_mag": 58.63680088709271, "train/post_ent_max": 58.63680088709271, "train/post_ent_mean": 41.7600282638792, "train/post_ent_min": 20.296963086203924, "train/post_ent_std": 7.47355596224467, "train/prior_ent_mag": 66.9188728938027, "train/prior_ent_max": 66.9188728938027, "train/prior_ent_mean": 54.38195658486987, "train/prior_ent_min": 39.33456366402762, "train/prior_ent_std": 4.321185713722592, "train/rep_loss_mean": 12.588431434025841, "train/rep_loss_std": 9.00229697378855, "train/reward_avg": 0.025813026597634667, "train/reward_loss_mean": 0.05257922966801931, "train/reward_loss_std": 0.24252979415986273, "train/reward_max_data": 1.0095238117944627, "train/reward_max_pred": 1.0064634680747986, "train/reward_neg_acc": 0.9935215829856812, "train/reward_neg_loss": 0.027387815675446913, "train/reward_pos_acc": 0.9643529388639662, "train/reward_pos_loss": 0.8555430457705543, "train/reward_pred": 0.024974501580886897, "train/reward_rate": 0.030552455357142856, "train_stats/sum_log_reward": 6.656701035106305, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.742268041237113, "train_stats/max_log_achievement_collect_sapling": 2.9381443298969074, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 10.474226804123711, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.1443298969072164, "train_stats/max_log_achievement_eat_cow": 0.21649484536082475, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.010309278350515464, "train_stats/max_log_achievement_make_wood_sword": 1.4123711340206186, "train_stats/max_log_achievement_place_plant": 2.88659793814433, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.556701030927835, "train_stats/max_log_achievement_wake_up": 1.9175257731958764, "train_stats/mean_log_entropy": 0.5327656150785918, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.108679938028217e-07, "report/cont_loss_std": 5.8138657550443895e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.830513641238213e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.0657678823663446e-07, "report/cont_pred": 0.99609375, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.020752906799316, "report/dyn_loss_std": 8.901476860046387, "report/image_loss_mean": 7.809044361114502, "report/image_loss_std": 14.82878303527832, "report/model_loss_mean": 16.270954132080078, "report/model_loss_std": 18.40792465209961, "report/post_ent_mag": 55.34082794189453, "report/post_ent_max": 55.34082794189453, "report/post_ent_mean": 39.844520568847656, "report/post_ent_min": 19.426414489746094, "report/post_ent_std": 6.940386772155762, "report/prior_ent_mag": 67.06098937988281, "report/prior_ent_max": 67.06098937988281, "report/prior_ent_mean": 54.39582824707031, "report/prior_ent_min": 44.27680969238281, "report/prior_ent_std": 3.6405060291290283, "report/rep_loss_mean": 14.020752906799316, "report/rep_loss_std": 8.901476860046387, "report/reward_avg": 0.02568359300494194, "report/reward_loss_mean": 0.04945807531476021, "report/reward_loss_std": 0.19915439188480377, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0057830810546875, "report/reward_neg_acc": 0.9959717988967896, "report/reward_neg_loss": 0.026159735396504402, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.7957563996315002, "report/reward_pred": 0.02460356429219246, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 9.39602330163325e-07, "eval/cont_loss_std": 8.612481906311586e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.200709999073297e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.816155640379293e-07, "eval/cont_pred": 0.9931643009185791, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.235443115234375, "eval/dyn_loss_std": 10.721735000610352, "eval/image_loss_mean": 10.9935941696167, "eval/image_loss_std": 13.662847518920898, "eval/model_loss_mean": 20.87661361694336, "eval/model_loss_std": 18.021648406982422, "eval/post_ent_mag": 59.51551818847656, "eval/post_ent_max": 59.51551818847656, "eval/post_ent_mean": 40.69257736206055, "eval/post_ent_min": 20.438949584960938, "eval/post_ent_std": 7.946414470672607, "eval/prior_ent_mag": 67.06098937988281, "eval/prior_ent_max": 67.06098937988281, "eval/prior_ent_mean": 55.3220100402832, "eval/prior_ent_min": 43.13040542602539, "eval/prior_ent_std": 3.9398629665374756, "eval/rep_loss_mean": 16.235443115234375, "eval/rep_loss_std": 10.721735000610352, "eval/reward_avg": 0.04619140550494194, "eval/reward_loss_mean": 0.14175520837306976, "eval/reward_loss_std": 0.673014760017395, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0122697353363037, "eval/reward_neg_acc": 0.9897013902664185, "eval/reward_neg_loss": 0.05727396532893181, "eval/reward_pos_acc": 0.849056601524353, "eval/reward_pos_loss": 1.6895155906677246, "eval/reward_pred": 0.037006016820669174, "eval/reward_rate": 0.0517578125, "replay/size": 589593.0, "replay/inserts": 20096.0, "replay/samples": 20096.0, "replay/insert_wait_avg": 1.37783539522985e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.806737331827735e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.8551488595506164e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1024.986294746399, "timer/env.step_count": 2512.0, "timer/env.step_total": 222.8051633834839, "timer/env.step_frac": 0.21737379760634762, "timer/env.step_avg": 0.08869632300297925, "timer/env.step_min": 0.023270368576049805, "timer/env.step_max": 3.4669077396392822, "timer/replay._sample_count": 20096.0, "timer/replay._sample_total": 10.313016414642334, "timer/replay._sample_frac": 0.010061613962549587, "timer/replay._sample_avg": 0.0005131875206330779, "timer/replay._sample_min": 0.00041294097900390625, "timer/replay._sample_max": 0.009854555130004883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3490.0, "timer/agent.policy_total": 58.422446727752686, "timer/agent.policy_frac": 0.056998271125378815, "timer/agent.policy_avg": 0.016739956082450626, "timer/agent.policy_min": 0.009518861770629883, "timer/agent.policy_max": 0.1323239803314209, "timer/dataset_train_count": 1256.0, "timer/dataset_train_total": 0.14652752876281738, "timer/dataset_train_frac": 0.00014295559805418772, "timer/dataset_train_avg": 0.00011666204519332594, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0006878376007080078, "timer/agent.train_count": 1256.0, "timer/agent.train_total": 562.0328402519226, "timer/agent.train_frac": 0.5483320539334433, "timer/agent.train_avg": 0.44747837599675366, "timer/agent.train_min": 0.4334714412689209, "timer/agent.train_max": 1.3226292133331299, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47812485694885254, "timer/agent.report_frac": 0.00046646951222616075, "timer/agent.report_avg": 0.23906242847442627, "timer/agent.report_min": 0.23129796981811523, "timer/agent.report_max": 0.2468268871307373, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.6982365830192887e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 19.60586029390631}
{"step": 590160, "time": 29333.05195569992, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 590208, "time": 29336.858693361282, "episode/length": 225.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 590536, "time": 29351.15592932701, "episode/length": 208.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 591216, "time": 29378.673355817795, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 591232, "time": 29380.90855693817, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 591264, "time": 29383.62208867073, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 591552, "time": 29395.66073870659, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 592024, "time": 29414.379563570023, "episode/length": 232.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 592088, "time": 29418.25728750229, "episode/length": 193.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 592264, "time": 29426.255602121353, "episode/length": 277.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 592288, "time": 29428.90462088585, "episode/length": 259.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 592704, "time": 29447.352641820908, "episode/length": 183.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 592784, "time": 29451.79399251938, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 592896, "time": 29457.438039541245, "episode/length": 209.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 593448, "time": 29479.10851573944, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 593512, "time": 29482.9630651474, "episode/length": 244.0, "episode/score": 6.10000005364418, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 593944, "time": 29500.425754070282, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 594064, "time": 29506.584755420685, "episode/length": 159.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 594400, "time": 29520.507888555527, "episode/length": 266.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 594472, "time": 29524.33201980591, "episode/length": 220.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 594576, "time": 29530.046924591064, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 594960, "time": 29545.56797838211, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 595008, "time": 29548.898814439774, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 595168, "time": 29556.291756629944, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 595288, "time": 29562.008304595947, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 595352, "time": 29566.009211063385, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 595760, "time": 29582.906104803085, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 595864, "time": 29588.737591028214, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 595968, "time": 29594.764705896378, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 596192, "time": 29604.964252471924, "episode/length": 53.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 596544, "time": 29619.478044748306, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 596648, "time": 29624.639309883118, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 597080, "time": 29642.1614112854, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 597208, "time": 29648.568799495697, "episode/length": 231.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 597320, "time": 29654.245079040527, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 597328, "time": 29656.298852443695, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 597688, "time": 29670.826872348785, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 597960, "time": 29682.46613931656, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 597984, "time": 29685.53570318222, "episode/length": 166.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 598440, "time": 29706.0431330204, "episode/length": 434.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954022988505747, "episode/intrinsic_return": 0.0}
{"step": 598520, "time": 29711.11469721794, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 598544, "time": 29713.773362636566, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 598984, "time": 29731.02650809288, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 599200, "time": 29740.810452461243, "episode/length": 233.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 599392, "time": 29749.28352689743, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 599840, "time": 29767.484970331192, "episode/length": 234.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 599992, "time": 29775.019139051437, "episode/length": 250.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 29799.469618320465, "eval_episode/length": 48.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 600080, "time": 29801.835126638412, "eval_episode/length": 56.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 600080, "time": 29808.65929555893, "eval_episode/length": 162.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 600080, "time": 29811.643850564957, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 600080, "time": 29815.098306655884, "eval_episode/length": 213.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 600080, "time": 29817.515075206757, "eval_episode/length": 225.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.995575221238938}
{"step": 600080, "time": 29821.22008228302, "eval_episode/length": 211.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 600080, "time": 29824.540522813797, "eval_episode/length": 287.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 600736, "time": 29849.47830271721, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 600976, "time": 29860.697521448135, "episode/length": 248.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 601008, "time": 29863.85551738739, "episode/length": 33.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 601112, "time": 29869.44841647148, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 601128, "time": 29872.259517908096, "episode/length": 325.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 601160, "time": 29875.3075633049, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 601312, "time": 29883.380833148956, "episode/length": 358.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 601664, "time": 29898.827804088593, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 602088, "time": 29916.667007684708, "episode/length": 442.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9932279909706546, "episode/intrinsic_return": 0.0}
{"step": 602352, "time": 29928.97864508629, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 602424, "time": 29933.484004974365, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 602440, "time": 29935.99608540535, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 602592, "time": 29943.286239624023, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 602720, "time": 29949.687413454056, "episode/length": 78.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 603000, "time": 29961.258821725845, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 603400, "time": 29977.36302423477, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 603424, "time": 29979.96080994606, "episode/length": 301.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 603488, "time": 29983.756980895996, "episode/length": 141.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 603640, "time": 29991.23101091385, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 603736, "time": 29996.8938062191, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 604120, "time": 30013.57976126671, "episode/length": 174.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 604464, "time": 30028.712581157684, "episode/length": 233.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 604664, "time": 30038.142108678818, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 604704, "time": 30041.805194616318, "episode/length": 284.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9719298245614035, "episode/intrinsic_return": 0.0}
{"step": 604880, "time": 30050.42133975029, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 604968, "time": 30054.941402196884, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 605048, "time": 30059.43158507347, "episode/length": 47.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 605408, "time": 30074.435317993164, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 605992, "time": 30097.287807941437, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 606056, "time": 30101.215095043182, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 606128, "time": 30105.573538780212, "episode/length": 134.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9481481481481482, "episode/intrinsic_return": 0.0}
{"step": 606232, "time": 30112.246260881424, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 606424, "time": 30120.642648935318, "episode/length": 214.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 606728, "time": 30133.40133523941, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 607688, "time": 30170.341552972794, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 607832, "time": 30177.139578819275, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 607848, "time": 30179.21510052681, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 607952, "time": 30184.788552761078, "episode/length": 478.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9979123173277662, "episode/intrinsic_return": 0.0}
{"step": 607960, "time": 30186.541330337524, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 608344, "time": 30202.1265103817, "episode/length": 285.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 608360, "time": 30204.30623102188, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 609104, "time": 30233.450142383575, "episode/length": 516.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9903288201160542, "episode/intrinsic_return": 0.0}
{"step": 609136, "time": 30236.152117967606, "episode/length": 180.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 609536, "time": 30252.40100288391, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 609552, "time": 30254.612775564194, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 609712, "time": 30262.05153942108, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 30295.098782777786, "eval_episode/length": 140.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9574468085106383}
{"step": 610064, "time": 30298.08588385582, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 610064, "time": 30299.797587633133, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 610064, "time": 30301.891622781754, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 610064, "time": 30303.543958425522, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 610064, "time": 30305.14143180847, "eval_episode/length": 198.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 610064, "time": 30306.963777065277, "eval_episode/length": 202.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 610064, "time": 30309.092526197433, "eval_episode/length": 219.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 610224, "time": 30314.95798587799, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 610432, "time": 30324.096720695496, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 610553, "time": 30330.83506321907, "train_stats/sum_log_reward": 6.489473675426684, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.978947368421053, "train_stats/max_log_achievement_collect_sapling": 2.957894736842105, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.736842105263158, "train_stats/max_log_achievement_defeat_skeleton": 0.031578947368421054, "train_stats/max_log_achievement_defeat_zombie": 1.063157894736842, "train_stats/max_log_achievement_eat_cow": 0.23157894736842105, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.021052631578947368, "train_stats/max_log_achievement_make_wood_sword": 1.4210526315789473, "train_stats/max_log_achievement_place_plant": 2.863157894736842, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.694736842105263, "train_stats/max_log_achievement_wake_up": 1.8526315789473684, "train_stats/mean_log_entropy": 0.538513337938409, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.738490581512451, "train/action_min": 0.0, "train/action_std": 3.88425587490201, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04206496053666342, "train/actor_opt_grad_steps": 37425.0, "train/actor_opt_loss": -7.027236874215305, "train/adv_mag": 0.581514191813767, "train/adv_max": 0.5493922277819365, "train/adv_mean": 0.002637861530665475, "train/adv_min": -0.4402168339584023, "train/adv_std": 0.06247632275335491, "train/cont_avg": 0.9946441650390625, "train/cont_loss_mean": 0.00021832614252303983, "train/cont_loss_std": 0.006018725043773543, "train/cont_neg_acc": 0.9929687511175871, "train/cont_neg_loss": 0.01913961213851678, "train/cont_pos_acc": 0.9999616574496031, "train/cont_pos_loss": 0.00011970545803979826, "train/cont_pred": 0.9946239260025322, "train/cont_rate": 0.9946441650390625, "train/dyn_loss_mean": 12.602235019207, "train/dyn_loss_std": 8.978974238038063, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7612276636064053, "train/extr_critic_critic_opt_grad_steps": 37425.0, "train/extr_critic_critic_opt_loss": 15329.100204467773, "train/extr_critic_mag": 6.371752712875605, "train/extr_critic_max": 6.371752712875605, "train/extr_critic_mean": 1.488189590163529, "train/extr_critic_min": -0.2712535699829459, "train/extr_critic_std": 1.4049620442092419, "train/extr_return_normed_mag": 1.66866151150316, "train/extr_return_normed_max": 1.66866151150316, "train/extr_return_normed_mean": 0.3445536030922085, "train/extr_return_normed_min": -0.13410296506481245, "train/extr_return_normed_std": 0.3278664688114077, "train/extr_return_rate": 0.6536601094994694, "train/extr_return_raw_mag": 7.310298532247543, "train/extr_return_raw_max": 7.310298532247543, "train/extr_return_raw_mean": 1.4997769771143794, "train/extr_return_raw_min": -0.6008443583268672, "train/extr_return_raw_std": 1.4389299731701612, "train/extr_reward_mag": 1.0248527768999338, "train/extr_reward_max": 1.0248527768999338, "train/extr_reward_mean": 0.030281785715487786, "train/extr_reward_min": -0.44270338024944067, "train/extr_reward_std": 0.16415397997479886, "train/image_loss_mean": 5.913446247577667, "train/image_loss_std": 10.696913294494152, "train/model_loss_mean": 13.52864484488964, "train/model_loss_std": 14.37326579540968, "train/model_opt_grad_norm": 55.38813643157482, "train/model_opt_grad_steps": 37391.890625, "train/model_opt_loss": 16716.57795715332, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1240.234375, "train/policy_entropy_mag": 2.5891288314014673, "train/policy_entropy_max": 2.5891288314014673, "train/policy_entropy_mean": 0.5576376200187951, "train/policy_entropy_min": 0.07937504490837455, "train/policy_entropy_std": 0.6266075999010354, "train/policy_logprob_mag": 7.438383627682924, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5571235215757042, "train/policy_logprob_min": -7.438383627682924, "train/policy_logprob_std": 1.1131107360124588, "train/policy_randomness_mag": 0.9138488559983671, "train/policy_randomness_max": 0.9138488559983671, "train/policy_randomness_mean": 0.19682160939555615, "train/policy_randomness_min": 0.028015907417284325, "train/policy_randomness_std": 0.22116498416289687, "train/post_ent_mag": 58.508545964956284, "train/post_ent_max": 58.508545964956284, "train/post_ent_mean": 41.76952901482582, "train/post_ent_min": 20.312357053160667, "train/post_ent_std": 7.45005452260375, "train/prior_ent_mag": 66.96756374835968, "train/prior_ent_max": 66.96756374835968, "train/prior_ent_mean": 54.44017407298088, "train/prior_ent_min": 39.642092019319534, "train/prior_ent_std": 4.303143076598644, "train/rep_loss_mean": 12.602235019207, "train/rep_loss_std": 8.978974238038063, "train/reward_avg": 0.026096343834069557, "train/reward_loss_mean": 0.053639268066035584, "train/reward_loss_std": 0.2439599126810208, "train/reward_max_data": 1.0085937520489097, "train/reward_max_pred": 1.0057691326364875, "train/reward_neg_acc": 0.9927403554320335, "train/reward_neg_loss": 0.028158144938061014, "train/reward_pos_acc": 0.9669409696944058, "train/reward_pos_loss": 0.8551753791980445, "train/reward_pred": 0.025244773758458905, "train/reward_rate": 0.03082275390625, "eval_stats/sum_log_reward": 6.6000000685453415, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.6875, "eval_stats/max_log_achievement_collect_sapling": 2.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 7.228008144011255e-06, "report/cont_loss_std": 0.000158230061060749, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014428826398216188, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.148793545435183e-06, "report/cont_pred": 0.9921825528144836, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.895722389221191, "report/dyn_loss_std": 8.890414237976074, "report/image_loss_mean": 6.100720405578613, "report/image_loss_std": 9.246329307556152, "report/model_loss_mean": 13.296981811523438, "report/model_loss_std": 12.836562156677246, "report/post_ent_mag": 58.88628005981445, "report/post_ent_max": 58.88628005981445, "report/post_ent_mean": 42.36103820800781, "report/post_ent_min": 20.907520294189453, "report/post_ent_std": 7.8228559494018555, "report/prior_ent_mag": 67.13420867919922, "report/prior_ent_max": 67.13420867919922, "report/prior_ent_mean": 54.45769500732422, "report/prior_ent_min": 37.28018569946289, "report/prior_ent_std": 4.472078323364258, "report/rep_loss_mean": 11.895722389221191, "report/rep_loss_std": 8.890414237976074, "report/reward_avg": 0.02333984524011612, "report/reward_loss_mean": 0.05882042646408081, "report/reward_loss_std": 0.29626208543777466, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015859603881836, "report/reward_neg_acc": 0.9939576983451843, "report/reward_neg_loss": 0.03481975570321083, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.8276160955429077, "report/reward_pred": 0.022233081981539726, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.563534280852764e-06, "eval/cont_loss_std": 1.9591321688494645e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00012962533219251782, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8146437241739477e-06, "eval/cont_pred": 0.994139552116394, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.879966735839844, "eval/dyn_loss_std": 10.87317943572998, "eval/image_loss_mean": 9.484029769897461, "eval/image_loss_std": 14.784478187561035, "eval/model_loss_mean": 19.763687133789062, "eval/model_loss_std": 19.110370635986328, "eval/post_ent_mag": 55.46860885620117, "eval/post_ent_max": 55.46860885620117, "eval/post_ent_mean": 39.89850616455078, "eval/post_ent_min": 20.517662048339844, "eval/post_ent_std": 7.4253411293029785, "eval/prior_ent_mag": 67.13420867919922, "eval/prior_ent_max": 67.13420867919922, "eval/prior_ent_mean": 54.476600646972656, "eval/prior_ent_min": 37.75752258300781, "eval/prior_ent_std": 4.159392833709717, "eval/rep_loss_mean": 16.879966735839844, "eval/rep_loss_std": 10.87317943572998, "eval/reward_avg": 0.04960937425494194, "eval/reward_loss_mean": 0.15167778730392456, "eval/reward_loss_std": 0.7439466118812561, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001054286956787, "eval/reward_neg_acc": 0.9731404781341553, "eval/reward_neg_loss": 0.0611112043261528, "eval/reward_pos_acc": 0.8214285969734192, "eval/reward_pos_loss": 1.7171859741210938, "eval/reward_pred": 0.04351971298456192, "eval/reward_rate": 0.0546875, "replay/size": 610049.0, "replay/inserts": 20456.0, "replay/samples": 20464.0, "replay/insert_wait_avg": 1.4413391466853113e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.786468382083036e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1694478237722803e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4412534236908, "timer/env.step_count": 2557.0, "timer/env.step_total": 230.21463084220886, "timer/env.step_frac": 0.23011309265223998, "timer/env.step_avg": 0.0900330977091157, "timer/env.step_min": 0.023276090621948242, "timer/env.step_max": 2.2387354373931885, "timer/replay._sample_count": 20464.0, "timer/replay._sample_total": 10.703224182128906, "timer/replay._sample_frac": 0.01069850343086167, "timer/replay._sample_avg": 0.0005230269830985587, "timer/replay._sample_min": 0.0004169940948486328, "timer/replay._sample_max": 0.011046648025512695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3065.0, "timer/agent.policy_total": 51.09451103210449, "timer/agent.policy_frac": 0.05107197534812748, "timer/agent.policy_avg": 0.016670313550441924, "timer/agent.policy_min": 0.009660482406616211, "timer/agent.policy_max": 0.10168766975402832, "timer/dataset_train_count": 1279.0, "timer/dataset_train_total": 0.15121841430664062, "timer/dataset_train_frac": 0.0001511517180935351, "timer/dataset_train_avg": 0.00011823175473545005, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.00020885467529296875, "timer/agent.train_count": 1279.0, "timer/agent.train_total": 573.6352736949921, "timer/agent.train_frac": 0.57338226680668, "timer/agent.train_avg": 0.448502950504294, "timer/agent.train_min": 0.43403196334838867, "timer/agent.train_max": 2.1360738277435303, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4736185073852539, "timer/agent.report_frac": 0.0004734096137723687, "timer/agent.report_avg": 0.23680925369262695, "timer/agent.report_min": 0.22969317436218262, "timer/agent.report_max": 0.2439253330230713, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7167730163629516e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 20.446706329308853}
{"step": 610648, "time": 30334.106161117554, "episode/length": 336.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 610704, "time": 30338.03137779236, "episode/length": 195.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 610824, "time": 30343.655476093292, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 610880, "time": 30347.434433221817, "episode/length": 145.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 610992, "time": 30353.015321731567, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 611216, "time": 30362.796787261963, "episode/length": 422.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 612056, "time": 30394.87679052353, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 612248, "time": 30403.585181951523, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 612264, "time": 30405.846980810165, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 612272, "time": 30407.913136720657, "episode/length": 255.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 612320, "time": 30411.200563907623, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 612496, "time": 30419.18058514595, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 612688, "time": 30427.82425737381, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 613752, "time": 30468.536891222, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 613768, "time": 30471.00786948204, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 613776, "time": 30473.566633701324, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 613920, "time": 30480.78933119774, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 614080, "time": 30488.355437994003, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 614200, "time": 30494.139043569565, "episode/length": 372.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9892761394101877, "episode/intrinsic_return": 0.0}
{"step": 614248, "time": 30497.849817752838, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 614424, "time": 30508.08440876007, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 614880, "time": 30526.692595005035, "episode/length": 137.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 615104, "time": 30536.38675045967, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 615432, "time": 30549.826580762863, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 615488, "time": 30553.523501634598, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 615728, "time": 30563.857029914856, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 615736, "time": 30565.510268211365, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 615896, "time": 30572.918009519577, "episode/length": 226.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 616032, "time": 30579.74428677559, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 616760, "time": 30607.630326986313, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 616984, "time": 30617.369645357132, "episode/length": 118.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 617152, "time": 30625.370698213577, "episode/length": 214.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 617384, "time": 30635.15456557274, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 617432, "time": 30638.542902231216, "episode/length": 242.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 618320, "time": 30672.715666294098, "episode/length": 145.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 618344, "time": 30674.817484378815, "episode/length": 305.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 618424, "time": 30679.343403100967, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 619048, "time": 30703.586970806122, "episode/length": 492.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9979716024340771, "episode/intrinsic_return": 0.0}
{"step": 619336, "time": 30715.57759952545, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 619360, "time": 30718.226390123367, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 619392, "time": 30720.902373313904, "episode/length": 456.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9978118161925602, "episode/intrinsic_return": 0.0}
{"step": 619872, "time": 30739.96226334572, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 619944, "time": 30743.910933971405, "episode/length": 111.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 30766.087359189987, "eval_episode/length": 94.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 620048, "time": 30770.691600561142, "eval_episode/length": 168.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 620048, "time": 30772.41207432747, "eval_episode/length": 173.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 620048, "time": 30773.91479086876, "eval_episode/length": 174.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 620048, "time": 30776.82080721855, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 620048, "time": 30778.98642873764, "eval_episode/length": 48.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 620048, "time": 30780.99732375145, "eval_episode/length": 228.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9737991266375546}
{"step": 620048, "time": 30784.53612780571, "eval_episode/length": 237.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9747899159663865}
{"step": 620152, "time": 30788.179391384125, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 620216, "time": 30792.118656635284, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 620416, "time": 30801.166736125946, "episode/length": 456.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9912472647702407, "episode/intrinsic_return": 0.0}
{"step": 621008, "time": 30824.42127776146, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 621288, "time": 30835.969148635864, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 621704, "time": 30852.703332185745, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 621712, "time": 30854.69215655327, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 621760, "time": 30857.95789361, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 621776, "time": 30860.170299768448, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 621928, "time": 30867.06837272644, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 622552, "time": 30891.433764219284, "episode/length": 401.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9900497512437811, "episode/intrinsic_return": 0.0}
{"step": 622656, "time": 30898.467356443405, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 622904, "time": 30908.731926202774, "episode/length": 236.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 623320, "time": 30925.45534992218, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 623368, "time": 30928.82112312317, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 623488, "time": 30934.944689273834, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 623568, "time": 30939.59937095642, "episode/length": 231.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 624088, "time": 30959.89685511589, "episode/length": 290.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 624336, "time": 30970.939074277878, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 624912, "time": 30993.511446475983, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 624968, "time": 30997.044847249985, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 625040, "time": 31001.42854309082, "episode/length": 183.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 625144, "time": 31006.586433172226, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 625376, "time": 31016.783202409744, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 625376, "time": 31016.83421278, "episode/length": 352.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 625520, "time": 31025.39429473877, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 625584, "time": 31029.51872587204, "episode/length": 282.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 626008, "time": 31046.34782552719, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 626160, "time": 31053.58781147003, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 626256, "time": 31058.829818725586, "episode/length": 91.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 626304, "time": 31062.16077852249, "episode/length": 36.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 626496, "time": 31070.797358751297, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 626824, "time": 31084.259840488434, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 626824, "time": 31084.30544066429, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 626904, "time": 31090.789477825165, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 627232, "time": 31104.646570682526, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 627752, "time": 31125.08408689499, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 627752, "time": 31125.1352622509, "episode/length": 186.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 627800, "time": 31130.068056821823, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 627856, "time": 31133.92396903038, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 628240, "time": 31149.46997141838, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 628288, "time": 31152.774727106094, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 628728, "time": 31170.06438922882, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 629200, "time": 31189.32337808609, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 629568, "time": 31205.160666942596, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 629600, "time": 31208.00934624672, "episode/length": 295.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 629624, "time": 31210.281851530075, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 629664, "time": 31213.607435703278, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 31228.618927955627, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 31243.210796117783, "eval_episode/length": 45.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 630032, "time": 31245.156222581863, "eval_episode/length": 56.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 630032, "time": 31249.896493911743, "eval_episode/length": 141.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 630032, "time": 31253.667582035065, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9639175257731959}
{"step": 630032, "time": 31255.25788784027, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 630032, "time": 31257.228559970856, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 630032, "time": 31259.085155248642, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 630032, "time": 31261.213829517365, "eval_episode/length": 229.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 630240, "time": 31270.380928993225, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 630624, "time": 31285.927250146866, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 630752, "time": 31292.11294412613, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 630760, "time": 31293.78325176239, "episode/length": 314.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 630952, "time": 31304.151375055313, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 631072, "time": 31310.326768636703, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 631384, "time": 31323.08375930786, "episode/length": 53.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 631529, "time": 31330.993715286255, "train_stats/sum_log_reward": 6.605050479522859, "train_stats/max_log_achievement_collect_coal": 0.010101010101010102, "train_stats/max_log_achievement_collect_drink": 5.1313131313131315, "train_stats/max_log_achievement_collect_sapling": 2.8181818181818183, "train_stats/max_log_achievement_collect_stone": 0.04040404040404041, "train_stats/max_log_achievement_collect_wood": 9.656565656565656, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.1818181818181819, "train_stats/max_log_achievement_eat_cow": 0.16161616161616163, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06060606060606061, "train_stats/max_log_achievement_make_wood_sword": 1.1818181818181819, "train_stats/max_log_achievement_place_plant": 2.797979797979798, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.717171717171717, "train_stats/max_log_achievement_wake_up": 1.505050505050505, "train_stats/mean_log_entropy": 0.5107288610453558, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.318459547203005, "train/action_min": 0.0, "train/action_std": 3.4197257529688248, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043936197965882204, "train/actor_opt_grad_steps": 38720.0, "train/actor_opt_loss": -0.3725596884734758, "train/adv_mag": 0.5936444711139184, "train/adv_max": 0.5569396253305537, "train/adv_mean": 0.0037493534095786184, "train/adv_min": -0.45582129413844974, "train/adv_std": 0.06503676025922062, "train/cont_avg": 0.9946326335877863, "train/cont_loss_mean": 0.00021204079616914784, "train/cont_loss_std": 0.005986327688456637, "train/cont_neg_acc": 0.9881406781327633, "train/cont_neg_loss": 0.023802663527688152, "train/cont_pos_acc": 0.9999549261486257, "train/cont_pos_loss": 8.275233730712305e-05, "train/cont_pred": 0.9946481508153086, "train/cont_rate": 0.9946326335877863, "train/dyn_loss_mean": 12.452108579737539, "train/dyn_loss_std": 8.978624787949423, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8282230323507586, "train/extr_critic_critic_opt_grad_steps": 38720.0, "train/extr_critic_critic_opt_loss": 15720.413577946088, "train/extr_critic_mag": 6.425626339803215, "train/extr_critic_max": 6.425626339803215, "train/extr_critic_mean": 1.5141845513846128, "train/extr_critic_min": -0.27158909262591646, "train/extr_critic_std": 1.3989523358017433, "train/extr_return_normed_mag": 1.6910358476274796, "train/extr_return_normed_max": 1.6910358476274796, "train/extr_return_normed_mean": 0.34988465563941545, "train/extr_return_normed_min": -0.14322174889327005, "train/extr_return_normed_std": 0.32569206454826677, "train/extr_return_rate": 0.6711668435853856, "train/extr_return_raw_mag": 7.422977483909548, "train/extr_return_raw_max": 7.422977483909548, "train/extr_return_raw_mean": 1.530645008305557, "train/extr_return_raw_min": -0.6354528492643633, "train/extr_return_raw_std": 1.4309119468426887, "train/extr_reward_mag": 1.0243066958798708, "train/extr_reward_max": 1.0243066958798708, "train/extr_reward_mean": 0.031807662983147696, "train/extr_reward_min": -0.49044566118080196, "train/extr_reward_std": 0.16790031931782498, "train/image_loss_mean": 5.637558010698275, "train/image_loss_std": 10.12823909657602, "train/model_loss_mean": 13.161505225960536, "train/model_loss_std": 13.806291776759023, "train/model_opt_grad_norm": 56.52331572088576, "train/model_opt_grad_steps": 38685.65648854962, "train/model_opt_loss": 16451.881522841126, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5452400564237405, "train/policy_entropy_max": 2.5452400564237405, "train/policy_entropy_mean": 0.5138942815420282, "train/policy_entropy_min": 0.07937504408013729, "train/policy_entropy_std": 0.5956456206227076, "train/policy_logprob_mag": 7.43838360109402, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5142621852969396, "train/policy_logprob_min": -7.43838360109402, "train/policy_logprob_std": 1.090613786500829, "train/policy_randomness_mag": 0.8983580433685361, "train/policy_randomness_max": 0.8983580433685361, "train/policy_randomness_mean": 0.18138212943805082, "train/policy_randomness_min": 0.028015907270876505, "train/policy_randomness_std": 0.21023676629739863, "train/post_ent_mag": 58.45857131026173, "train/post_ent_max": 58.45857131026173, "train/post_ent_mean": 41.935145662031104, "train/post_ent_min": 20.324821239209356, "train/post_ent_std": 7.488169611865327, "train/prior_ent_mag": 67.0047175866047, "train/prior_ent_max": 67.0047175866047, "train/prior_ent_mean": 54.44924804454541, "train/prior_ent_min": 39.55257147869081, "train/prior_ent_std": 4.297496455316325, "train/rep_loss_mean": 12.452108579737539, "train/rep_loss_std": 8.978624787949423, "train/reward_avg": 0.025923634004843144, "train/reward_loss_mean": 0.05247001199208143, "train/reward_loss_std": 0.241413630260766, "train/reward_max_data": 1.010687025448748, "train/reward_max_pred": 1.007954501923714, "train/reward_neg_acc": 0.9931812818723781, "train/reward_neg_loss": 0.027406809510279247, "train/reward_pos_acc": 0.9685479488991598, "train/reward_pos_loss": 0.8416528278634748, "train/reward_pred": 0.025166784818390853, "train/reward_rate": 0.030810174141221374, "eval_stats/sum_log_reward": 6.037499979138374, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.9375, "eval_stats/max_log_achievement_collect_sapling": 2.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.2064344446116593e-05, "report/cont_loss_std": 0.0003787791065406054, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0060788667760789394, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9193269906736532e-07, "report/cont_pred": 0.998058557510376, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 11.835638046264648, "report/dyn_loss_std": 8.575263977050781, "report/image_loss_mean": 4.083745002746582, "report/image_loss_std": 7.189913272857666, "report/model_loss_mean": 11.227771759033203, "report/model_loss_std": 10.802668571472168, "report/post_ent_mag": 58.52829360961914, "report/post_ent_max": 58.52829360961914, "report/post_ent_mean": 42.17243957519531, "report/post_ent_min": 20.044740676879883, "report/post_ent_std": 7.45104455947876, "report/prior_ent_mag": 66.60604858398438, "report/prior_ent_max": 66.60604858398438, "report/prior_ent_mean": 54.29474639892578, "report/prior_ent_min": 41.68476104736328, "report/prior_ent_std": 4.098283767700195, "report/rep_loss_mean": 11.835638046264648, "report/rep_loss_std": 8.575263977050781, "report/reward_avg": 0.02529297024011612, "report/reward_loss_mean": 0.0426323376595974, "report/reward_loss_std": 0.23087778687477112, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000605821609497, "report/reward_neg_acc": 0.9929719567298889, "report/reward_neg_loss": 0.0161710474640131, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.9838982820510864, "report/reward_pred": 0.022653505206108093, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.137357897590846e-05, "eval/cont_loss_std": 0.002193340566009283, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01808076910674572, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.484900947929418e-07, "eval/cont_pred": 0.9961613416671753, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.301115989685059, "eval/dyn_loss_std": 10.157578468322754, "eval/image_loss_mean": 8.925066947937012, "eval/image_loss_std": 14.116156578063965, "eval/model_loss_mean": 18.203651428222656, "eval/model_loss_std": 18.107009887695312, "eval/post_ent_mag": 57.21766662597656, "eval/post_ent_max": 57.21766662597656, "eval/post_ent_mean": 41.18253707885742, "eval/post_ent_min": 20.331642150878906, "eval/post_ent_std": 7.3797287940979, "eval/prior_ent_mag": 66.60604858398438, "eval/prior_ent_max": 66.60604858398438, "eval/prior_ent_mean": 54.70738220214844, "eval/prior_ent_min": 43.646549224853516, "eval/prior_ent_std": 3.851900577545166, "eval/rep_loss_mean": 15.301115989685059, "eval/rep_loss_std": 10.157578468322754, "eval/reward_avg": 0.02578125149011612, "eval/reward_loss_mean": 0.0978442132472992, "eval/reward_loss_std": 0.5418318510055542, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000560998916626, "eval/reward_neg_acc": 0.9818547964096069, "eval/reward_neg_loss": 0.04257374629378319, "eval/reward_pos_acc": 0.78125, "eval/reward_pos_loss": 1.8112282752990723, "eval/reward_pred": 0.024360837414860725, "eval/reward_rate": 0.03125, "replay/size": 631025.0, "replay/inserts": 20976.0, "replay/samples": 20976.0, "replay/insert_wait_avg": 1.373089150924159e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.847831232869652e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.092369739825909e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1461760997772, "timer/env.step_count": 2622.0, "timer/env.step_total": 225.50010323524475, "timer/env.step_frac": 0.2254671453273129, "timer/env.step_avg": 0.0860030904787356, "timer/env.step_min": 0.023340702056884766, "timer/env.step_max": 3.546400547027588, "timer/replay._sample_count": 20976.0, "timer/replay._sample_total": 10.833983421325684, "timer/replay._sample_frac": 0.010832399983344891, "timer/replay._sample_avg": 0.000516494251588753, "timer/replay._sample_min": 0.00039505958557128906, "timer/replay._sample_max": 0.010913372039794922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3090.0, "timer/agent.policy_total": 50.43956017494202, "timer/agent.policy_frac": 0.05043218819436853, "timer/agent.policy_avg": 0.016323482257262788, "timer/agent.policy_min": 0.009290218353271484, "timer/agent.policy_max": 0.10753083229064941, "timer/dataset_train_count": 1311.0, "timer/dataset_train_total": 0.1521921157836914, "timer/dataset_train_frac": 0.00015216987218527177, "timer/dataset_train_avg": 0.00011608857039183174, "timer/dataset_train_min": 0.00010442733764648438, "timer/dataset_train_max": 0.0010669231414794922, "timer/agent.train_count": 1311.0, "timer/agent.train_total": 584.8564183712006, "timer/agent.train_frac": 0.5847709388360984, "timer/agent.train_avg": 0.44611473559969533, "timer/agent.train_min": 0.4329874515533447, "timer/agent.train_max": 1.2729377746582031, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751455783843994, "timer/agent.report_frac": 0.00047507613360809134, "timer/agent.report_avg": 0.2375727891921997, "timer/agent.report_min": 0.23143768310546875, "timer/agent.report_max": 0.24370789527893066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908281543785938e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 20.972635421056243}
{"step": 631616, "time": 31334.209048509598, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 632056, "time": 31351.51078414917, "episode/length": 178.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 632184, "time": 31357.77973818779, "episode/length": 268.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 632216, "time": 31360.417848825455, "episode/length": 246.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 632400, "time": 31368.93433523178, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 632400, "time": 31368.98043179512, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 632512, "time": 31376.460455417633, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 632808, "time": 31388.709966421127, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 632896, "time": 31393.688270568848, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 633608, "time": 31421.098286390305, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 633752, "time": 31427.87990307808, "episode/length": 211.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 633960, "time": 31437.055646419525, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 634000, "time": 31440.269686698914, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 634104, "time": 31445.42449450493, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 634240, "time": 31452.27311682701, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 634368, "time": 31458.50315761566, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 634464, "time": 31463.564757347107, "episode/length": 284.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 634560, "time": 31468.56280231476, "episode/length": 74.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 634680, "time": 31474.329860925674, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 634960, "time": 31486.436128139496, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 635032, "time": 31490.40944480896, "episode/length": 58.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 635288, "time": 31501.50641131401, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 635440, "time": 31509.590568304062, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 635576, "time": 31516.472277641296, "episode/length": 111.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 635696, "time": 31523.249813318253, "episode/length": 198.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 635720, "time": 31525.927353858948, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 636336, "time": 31551.120523691177, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 636400, "time": 31555.021530628204, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 636432, "time": 31557.73461484909, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 636672, "time": 31568.045019626617, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 636816, "time": 31574.825621843338, "episode/length": 136.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 637168, "time": 31589.235515594482, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 637960, "time": 31619.742122411728, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 637976, "time": 31622.24522638321, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 638208, "time": 31633.22350525856, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 638392, "time": 31641.298573493958, "episode/length": 351.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 638696, "time": 31654.07521033287, "episode/length": 234.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 638840, "time": 31661.038731575012, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 639072, "time": 31672.805468082428, "episode/length": 299.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 639344, "time": 31684.31186771393, "episode/length": 487.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.985655737704918, "episode/intrinsic_return": 0.0}
{"step": 639552, "time": 31693.437012672424, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 639600, "time": 31696.666430950165, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 639752, "time": 31703.527782917023, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 639768, "time": 31705.706079483032, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 639816, "time": 31708.98655104637, "episode/length": 231.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 31732.90109229088, "eval_episode/length": 60.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9344262295081968}
{"step": 640016, "time": 31737.889111042023, "eval_episode/length": 149.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 640016, "time": 31739.46023917198, "eval_episode/length": 150.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 640016, "time": 31741.351662158966, "eval_episode/length": 159.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 640016, "time": 31743.31658053398, "eval_episode/length": 171.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 640016, "time": 31746.009477376938, "eval_episode/length": 198.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 640016, "time": 31747.83540868759, "eval_episode/length": 39.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.975}
{"step": 640016, "time": 31750.223938941956, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 640472, "time": 31766.570307016373, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 640536, "time": 31770.404385089874, "episode/length": 182.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 640728, "time": 31779.071578025818, "episode/length": 119.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 640888, "time": 31786.421134471893, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 641128, "time": 31797.43692421913, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 641520, "time": 31814.660021543503, "episode/length": 220.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9864253393665159, "episode/intrinsic_return": 0.0}
{"step": 641536, "time": 31817.259495973587, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 641640, "time": 31822.99458217621, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 641752, "time": 31829.183402061462, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 641872, "time": 31835.996005296707, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 642472, "time": 31860.49193263054, "episode/length": 217.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 642704, "time": 31871.65331888199, "episode/length": 147.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 642960, "time": 31883.23880290985, "episode/length": 177.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 642960, "time": 31883.290064811707, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 643240, "time": 31897.832460165024, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 643336, "time": 31903.473337173462, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 643400, "time": 31907.337195634842, "episode/length": 313.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777070063694268, "episode/intrinsic_return": 0.0}
{"step": 643472, "time": 31911.68668293953, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 644232, "time": 31940.848604679108, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 644480, "time": 31951.606464624405, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 644536, "time": 31954.918397188187, "episode/length": 257.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 644632, "time": 31960.160989761353, "episode/length": 144.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 644800, "time": 31968.739062070847, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 644880, "time": 31973.634766578674, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 645176, "time": 31986.628984451294, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 645720, "time": 32008.802020549774, "episode/length": 147.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 645752, "time": 32011.47380375862, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 646600, "time": 32043.833733081818, "episode/length": 177.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 646648, "time": 32047.73888039589, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 646656, "time": 32050.48276901245, "episode/length": 406.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 647128, "time": 32069.482034921646, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 647336, "time": 32080.297496318817, "episode/length": 316.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 647448, "time": 32085.841839551926, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 647672, "time": 32095.546211719513, "episode/length": 398.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 647800, "time": 32101.681891202927, "episode/length": 142.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 648032, "time": 32111.95193219185, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 648048, "time": 32114.072969675064, "episode/length": 426.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 648640, "time": 32137.45566034317, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 648744, "time": 32142.534940958023, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 649016, "time": 32153.955934286118, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 649080, "time": 32157.92914533615, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 649200, "time": 32164.10887813568, "episode/length": 143.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 649248, "time": 32167.46108865738, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 649280, "time": 32170.19710469246, "episode/length": 32.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 649448, "time": 32177.59173297882, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 649904, "time": 32195.87599849701, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 32219.587869644165, "eval_episode/length": 148.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 650000, "time": 32222.129710912704, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 650000, "time": 32225.738894224167, "eval_episode/length": 47.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 650000, "time": 32228.414273500443, "eval_episode/length": 209.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 650000, "time": 32230.65293097496, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 650000, "time": 32233.044076919556, "eval_episode/length": 218.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 650000, "time": 32235.170816659927, "eval_episode/length": 221.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 650000, "time": 32237.178435325623, "eval_episode/length": 222.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 650072, "time": 32239.6996614933, "episode/length": 178.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 650400, "time": 32254.23407101631, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 650504, "time": 32260.113268375397, "episode/length": 53.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 650816, "time": 32273.972230196, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 650888, "time": 32278.028995990753, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 651280, "time": 32294.609043121338, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 651616, "time": 32309.30256986618, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 651688, "time": 32313.372617721558, "episode/length": 304.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 651712, "time": 32315.90270423889, "episode/length": 303.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 652065, "time": 32331.045810461044, "train_stats/sum_log_reward": 6.559999985694885, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.38, "train_stats/max_log_achievement_collect_sapling": 2.62, "train_stats/max_log_achievement_collect_stone": 0.22, "train_stats/max_log_achievement_collect_wood": 10.5, "train_stats/max_log_achievement_defeat_skeleton": 0.01, "train_stats/max_log_achievement_defeat_zombie": 1.09, "train_stats/max_log_achievement_eat_cow": 0.14, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06, "train_stats/max_log_achievement_make_wood_sword": 1.22, "train_stats/max_log_achievement_place_plant": 2.56, "train_stats/max_log_achievement_place_stone": 0.01, "train_stats/max_log_achievement_place_table": 3.02, "train_stats/max_log_achievement_wake_up": 1.37, "train_stats/mean_log_entropy": 0.5236200147867203, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.2817559242248535, "train/action_min": 0.0, "train/action_std": 3.344515737146139, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04402808123268187, "train/actor_opt_grad_steps": 40015.0, "train/actor_opt_loss": -1.3152889010380022, "train/adv_mag": 0.6030149857979268, "train/adv_max": 0.567304776282981, "train/adv_mean": 0.0037166963905121975, "train/adv_min": -0.45097923395223916, "train/adv_std": 0.06501111321267672, "train/cont_avg": 0.9944076538085938, "train/cont_loss_mean": 0.00021647582516748365, "train/cont_loss_std": 0.006643337696031537, "train/cont_neg_acc": 0.9861111114732921, "train/cont_neg_loss": 0.035589833080173605, "train/cont_pos_acc": 0.9999538641422987, "train/cont_pos_loss": 0.00011050988733368738, "train/cont_pred": 0.9943958469666541, "train/cont_rate": 0.9944076538085938, "train/dyn_loss_mean": 12.440355114638805, "train/dyn_loss_std": 8.980415657162666, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7848552188370377, "train/extr_critic_critic_opt_grad_steps": 40015.0, "train/extr_critic_critic_opt_loss": 15608.375221252441, "train/extr_critic_mag": 6.46629948168993, "train/extr_critic_max": 6.46629948168993, "train/extr_critic_mean": 1.5900520328432322, "train/extr_critic_min": -0.27185369562357664, "train/extr_critic_std": 1.4133706372231245, "train/extr_return_normed_mag": 1.7070924146100879, "train/extr_return_normed_max": 1.7070924146100879, "train/extr_return_normed_mean": 0.3639155342243612, "train/extr_return_normed_min": -0.12913980751181953, "train/extr_return_normed_std": 0.3271439070813358, "train/extr_return_rate": 0.6834157654084265, "train/extr_return_raw_mag": 7.560828942805529, "train/extr_return_raw_max": 7.560828942805529, "train/extr_return_raw_mean": 1.606556155718863, "train/extr_return_raw_min": -0.5789358313195407, "train/extr_return_raw_std": 1.4504762962460518, "train/extr_reward_mag": 1.0227543991059065, "train/extr_reward_max": 1.0227543991059065, "train/extr_reward_mean": 0.03244850279588718, "train/extr_reward_min": -0.46482969354838133, "train/extr_reward_std": 0.17032945569371805, "train/image_loss_mean": 5.7892345283180475, "train/image_loss_std": 10.167227532714605, "train/model_loss_mean": 13.307840883731842, "train/model_loss_std": 13.809754319489002, "train/model_opt_grad_norm": 52.33822275698185, "train/model_opt_grad_steps": 39979.4453125, "train/model_opt_loss": 17069.1449508667, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1279.296875, "train/policy_entropy_mag": 2.5579917076975107, "train/policy_entropy_max": 2.5579917076975107, "train/policy_entropy_mean": 0.5540387292858213, "train/policy_entropy_min": 0.07937503687571734, "train/policy_entropy_std": 0.6408343452494591, "train/policy_logprob_mag": 7.438383597880602, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5543292469810694, "train/policy_logprob_min": -7.438383597880602, "train/policy_logprob_std": 1.1208241814747453, "train/policy_randomness_mag": 0.9028588170185685, "train/policy_randomness_max": 0.9028588170185685, "train/policy_randomness_mean": 0.19555135711561888, "train/policy_randomness_min": 0.028015904666972347, "train/policy_randomness_std": 0.22618640295695513, "train/post_ent_mag": 58.74291041493416, "train/post_ent_max": 58.74291041493416, "train/post_ent_mean": 42.03767052292824, "train/post_ent_min": 20.43179077655077, "train/post_ent_std": 7.556683260947466, "train/prior_ent_mag": 66.99911797046661, "train/prior_ent_max": 66.99911797046661, "train/prior_ent_mean": 54.549847185611725, "train/prior_ent_min": 39.09934638440609, "train/prior_ent_std": 4.333957511931658, "train/rep_loss_mean": 12.440355114638805, "train/rep_loss_std": 8.980415657162666, "train/reward_avg": 0.026831054456124548, "train/reward_loss_mean": 0.054176856530830264, "train/reward_loss_std": 0.2422309690155089, "train/reward_max_data": 1.0109375026077032, "train/reward_max_pred": 1.0067251520231366, "train/reward_neg_acc": 0.9927088916301727, "train/reward_neg_loss": 0.028871478913060855, "train/reward_pos_acc": 0.9721756372600794, "train/reward_pos_loss": 0.8286029910668731, "train/reward_pred": 0.026255291395500535, "train/reward_rate": 0.03180694580078125, "eval_stats/sum_log_reward": 6.099999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 7.966276825754903e-06, "report/cont_loss_std": 0.00015849442570470273, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.903139491332695e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.879149961809162e-06, "report/cont_pred": 0.9921799302101135, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.685379981994629, "report/dyn_loss_std": 9.563213348388672, "report/image_loss_mean": 7.317258834838867, "report/image_loss_std": 12.430131912231445, "report/model_loss_mean": 14.9850492477417, "report/model_loss_std": 16.087242126464844, "report/post_ent_mag": 61.02664566040039, "report/post_ent_max": 61.02664566040039, "report/post_ent_mean": 42.283958435058594, "report/post_ent_min": 20.252283096313477, "report/post_ent_std": 7.753269195556641, "report/prior_ent_mag": 66.9525146484375, "report/prior_ent_max": 66.9525146484375, "report/prior_ent_mean": 54.86441421508789, "report/prior_ent_min": 39.13090515136719, "report/prior_ent_std": 4.632213115692139, "report/rep_loss_mean": 12.685379981994629, "report/rep_loss_std": 9.563213348388672, "report/reward_avg": 0.02724609524011612, "report/reward_loss_mean": 0.05655514448881149, "report/reward_loss_std": 0.19924798607826233, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0052497386932373, "report/reward_neg_acc": 0.9939332008361816, "report/reward_neg_loss": 0.031165238469839096, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.7740013003349304, "report/reward_pred": 0.026854516938328743, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.172077857831027e-06, "eval/cont_loss_std": 0.00020118358952458948, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001621569273993373, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.411079761572182e-07, "eval/cont_pred": 0.9960992932319641, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.738130569458008, "eval/dyn_loss_std": 10.952357292175293, "eval/image_loss_mean": 10.719182968139648, "eval/image_loss_std": 21.17879867553711, "eval/model_loss_mean": 20.85584831237793, "eval/model_loss_std": 25.64653205871582, "eval/post_ent_mag": 53.932796478271484, "eval/post_ent_max": 53.932796478271484, "eval/post_ent_mean": 39.88258361816406, "eval/post_ent_min": 20.69599151611328, "eval/post_ent_std": 7.279710292816162, "eval/prior_ent_mag": 66.9525146484375, "eval/prior_ent_max": 66.9525146484375, "eval/prior_ent_mean": 54.27721405029297, "eval/prior_ent_min": 45.28559112548828, "eval/prior_ent_std": 3.707219123840332, "eval/rep_loss_mean": 16.738130569458008, "eval/rep_loss_std": 10.952357292175293, "eval/reward_avg": 0.04726562649011612, "eval/reward_loss_mean": 0.09378013759851456, "eval/reward_loss_std": 0.45757436752319336, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028886795043945, "eval/reward_neg_acc": 0.9897225499153137, "eval/reward_neg_loss": 0.042021773755550385, "eval/reward_pos_acc": 0.9411765336990356, "eval/reward_pos_loss": 1.0812486410140991, "eval/reward_pred": 0.045071788132190704, "eval/reward_rate": 0.0498046875, "replay/size": 651561.0, "replay/inserts": 20536.0, "replay/samples": 20528.0, "replay/insert_wait_avg": 1.4049931635037442e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.844305744602266e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.136421890600149e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3113021850585938e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0378882884979, "timer/env.step_count": 2567.0, "timer/env.step_total": 239.5792429447174, "timer/env.step_frac": 0.23957016604115094, "timer/env.step_avg": 0.0933304413497146, "timer/env.step_min": 0.023336410522460938, "timer/env.step_max": 4.1264119148254395, "timer/replay._sample_count": 20528.0, "timer/replay._sample_total": 10.681657552719116, "timer/replay._sample_frac": 0.0106812528583293, "timer/replay._sample_avg": 0.0005203457498401752, "timer/replay._sample_min": 0.00041866302490234375, "timer/replay._sample_max": 0.011577129364013672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3014.0, "timer/agent.policy_total": 50.02215003967285, "timer/agent.policy_frac": 0.05002025485782606, "timer/agent.policy_avg": 0.01659659921687885, "timer/agent.policy_min": 0.0094757080078125, "timer/agent.policy_max": 0.09926724433898926, "timer/dataset_train_count": 1283.0, "timer/dataset_train_total": 0.15161657333374023, "timer/dataset_train_frac": 0.00015161082905890944, "timer/dataset_train_avg": 0.00011817347882598615, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.0008597373962402344, "timer/agent.train_count": 1283.0, "timer/agent.train_total": 571.7110106945038, "timer/agent.train_frac": 0.571689350363466, "timer/agent.train_avg": 0.44560484075955087, "timer/agent.train_min": 0.4310448169708252, "timer/agent.train_max": 1.2418899536132812, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4740598201751709, "timer/agent.report_frac": 0.0004740418595404365, "timer/agent.report_avg": 0.23702991008758545, "timer/agent.report_min": 0.2291276454925537, "timer/agent.report_max": 0.2449321746826172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027801236383085e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 20.534943192919993}
{"step": 652072, "time": 32331.099811792374, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 652088, "time": 32333.668683052063, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 652552, "time": 32352.398956775665, "episode/length": 207.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 652568, "time": 32354.522089719772, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 652616, "time": 32357.889602184296, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 653016, "time": 32374.01081752777, "episode/length": 49.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 653144, "time": 32380.466546297073, "episode/length": 178.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 653152, "time": 32382.651789188385, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 653464, "time": 32395.45707130432, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 654088, "time": 32420.01903295517, "episode/length": 191.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 654144, "time": 32423.759832143784, "episode/length": 196.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 654384, "time": 32434.126957178116, "episode/length": 288.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 654592, "time": 32443.389253377914, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 654592, "time": 32443.437759637833, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 654736, "time": 32452.17520594597, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 655040, "time": 32464.79500937462, "episode/length": 236.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 655176, "time": 32471.317622184753, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 655280, "time": 32476.883363723755, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 655960, "time": 32504.843365430832, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 656112, "time": 32512.146037578583, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 656464, "time": 32526.58761715889, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 656496, "time": 32529.36910367012, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 656696, "time": 32538.167976617813, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 656896, "time": 32547.17244577408, "episode/length": 201.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 657024, "time": 32553.440196990967, "episode/length": 329.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 657080, "time": 32556.99294614792, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 657592, "time": 32577.214637994766, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 658120, "time": 32598.171045780182, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 658120, "time": 32598.221957206726, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 658392, "time": 32611.85495352745, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 658480, "time": 32616.842007875443, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 658544, "time": 32620.767010450363, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 658688, "time": 32627.60356593132, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 658984, "time": 32639.983595371246, "episode/length": 260.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 659208, "time": 32650.327909708023, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 659256, "time": 32653.709041118622, "episode/length": 645.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9984520123839009, "episode/intrinsic_return": 0.0}
{"step": 659280, "time": 32656.388632059097, "episode/length": 144.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 659320, "time": 32659.25825023651, "episode/length": 149.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 659880, "time": 32681.370819807053, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 32709.714136123657, "eval_episode/length": 164.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 660088, "time": 32711.314236164093, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 660088, "time": 32713.29258131981, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 660088, "time": 32715.526874780655, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 660088, "time": 32719.243663549423, "eval_episode/length": 247.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 660088, "time": 32719.29370188713, "eval_episode/length": 247.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 660088, "time": 32724.723483800888, "eval_episode/length": 297.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 660088, "time": 32726.973394155502, "eval_episode/length": 311.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9967948717948718}
{"step": 660192, "time": 32730.996193885803, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 660576, "time": 32746.531779050827, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 660880, "time": 32759.1232278347, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 661040, "time": 32766.881285190582, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 661144, "time": 32772.68770122528, "episode/length": 241.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 661616, "time": 32792.564888477325, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 661744, "time": 32798.858372449875, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 661856, "time": 32804.36880040169, "episode/length": 246.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 661976, "time": 32810.01917934418, "episode/length": 44.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 662088, "time": 32815.64845252037, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 662760, "time": 32841.66095781326, "episode/length": 201.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 663216, "time": 32860.314645051956, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 663224, "time": 32861.980201244354, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 663304, "time": 32866.40909528732, "episode/length": 282.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 663448, "time": 32873.26452755928, "episode/length": 169.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 663520, "time": 32877.674451351166, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 664080, "time": 32901.398350954056, "episode/length": 437.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 664480, "time": 32917.69420862198, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 664776, "time": 32929.867054224014, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 664960, "time": 32938.36082148552, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 664992, "time": 32941.00940990448, "episode/length": 220.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 665424, "time": 32958.502387046814, "episode/length": 767.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 665504, "time": 32962.976206064224, "episode/length": 256.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 665512, "time": 32964.57999110222, "episode/length": 178.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 665896, "time": 32980.10557746887, "episode/length": 48.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 665976, "time": 32984.62332367897, "episode/length": 186.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 666496, "time": 33005.28230714798, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 666680, "time": 33013.403945446014, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 666960, "time": 33025.325402736664, "episode/length": 272.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 667176, "time": 33034.581781864166, "episode/length": 494.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.997979797979798, "episode/intrinsic_return": 0.0}
{"step": 667192, "time": 33036.760961055756, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 667216, "time": 33039.45017981529, "episode/length": 212.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 667304, "time": 33043.989336013794, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 667872, "time": 33066.5239546299, "episode/length": 236.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 668056, "time": 33074.61247611046, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 668144, "time": 33079.551084280014, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 668160, "time": 33081.74214553833, "episode/length": 184.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 668528, "time": 33096.929711818695, "episode/length": 45.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 668560, "time": 33099.59220314026, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 668640, "time": 33104.11363506317, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 668784, "time": 33111.00391077995, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 669064, "time": 33122.493721961975, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 669288, "time": 33132.37297677994, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 669344, "time": 33136.20256853104, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 669456, "time": 33141.81811237335, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 33185.64362120628, "eval_episode/length": 145.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 670072, "time": 33187.73356795311, "eval_episode/length": 155.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 670072, "time": 33190.485189437866, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 670072, "time": 33190.53260397911, "eval_episode/length": 185.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.978494623655914}
{"step": 670072, "time": 33193.89062023163, "eval_episode/length": 187.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 670072, "time": 33195.4295771122, "eval_episode/length": 188.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 670072, "time": 33197.72686982155, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 670072, "time": 33200.267099142075, "eval_episode/length": 45.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 670128, "time": 33202.539425611496, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 670248, "time": 33208.394530534744, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 670408, "time": 33215.84468078613, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 670552, "time": 33222.84660863876, "episode/length": 157.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 670744, "time": 33231.39562559128, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 670832, "time": 33236.43476843834, "episode/length": 287.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 670888, "time": 33239.73464131355, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 671024, "time": 33246.581984996796, "episode/length": 209.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 671744, "time": 33274.4550409317, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 671864, "time": 33281.816657304764, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 671952, "time": 33286.932697057724, "episode/length": 174.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 672160, "time": 33296.08335494995, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 672280, "time": 33301.78914022446, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 672344, "time": 33305.67545056343, "episode/length": 261.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 672392, "time": 33309.05981826782, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 672632, "time": 33319.48071074486, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 672664, "time": 33322.16152834892, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 672841, "time": 33331.10546040535, "train_stats/sum_log_reward": 6.862376345856355, "train_stats/max_log_achievement_collect_coal": 0.039603960396039604, "train_stats/max_log_achievement_collect_drink": 4.881188118811881, "train_stats/max_log_achievement_collect_sapling": 2.5841584158415842, "train_stats/max_log_achievement_collect_stone": 0.36633663366336633, "train_stats/max_log_achievement_collect_wood": 9.653465346534654, "train_stats/max_log_achievement_defeat_skeleton": 0.009900990099009901, "train_stats/max_log_achievement_defeat_zombie": 1.0891089108910892, "train_stats/max_log_achievement_eat_cow": 0.19801980198019803, "train_stats/max_log_achievement_eat_plant": 0.019801980198019802, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1782178217821782, "train_stats/max_log_achievement_make_wood_sword": 0.900990099009901, "train_stats/max_log_achievement_place_plant": 2.495049504950495, "train_stats/max_log_achievement_place_stone": 0.0297029702970297, "train_stats/max_log_achievement_place_table": 2.5643564356435644, "train_stats/max_log_achievement_wake_up": 1.396039603960396, "train_stats/mean_log_entropy": 0.5735234137218778, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.467066838191106, "train/action_min": 0.0, "train/action_std": 3.4648431502855743, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04484502217517449, "train/actor_opt_grad_steps": 41305.0, "train/actor_opt_loss": -3.374861241877079, "train/adv_mag": 0.6040284674901228, "train/adv_max": 0.5727527893506563, "train/adv_mean": 0.003570478131866996, "train/adv_min": -0.45345495618306675, "train/adv_std": 0.06594375735865189, "train/cont_avg": 0.9945838341346154, "train/cont_loss_mean": 0.00022740329202996726, "train/cont_loss_std": 0.007019143923963174, "train/cont_neg_acc": 0.9952196386433387, "train/cont_neg_loss": 0.03017177539496593, "train/cont_pos_acc": 0.9999924325025998, "train/cont_pos_loss": 9.656165883652735e-05, "train/cont_pred": 0.9945947619584891, "train/cont_rate": 0.9945838341346154, "train/dyn_loss_mean": 12.470362435854398, "train/dyn_loss_std": 8.968304069225605, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7877075465825888, "train/extr_critic_critic_opt_grad_steps": 41305.0, "train/extr_critic_critic_opt_loss": 15776.277170973557, "train/extr_critic_mag": 6.649947723975548, "train/extr_critic_max": 6.649947723975548, "train/extr_critic_mean": 1.6847414401861338, "train/extr_critic_min": -0.2603959679603577, "train/extr_critic_std": 1.4706440347891587, "train/extr_return_normed_mag": 1.6831326273771432, "train/extr_return_normed_max": 1.6831326273771432, "train/extr_return_normed_mean": 0.3706875492747013, "train/extr_return_normed_min": -0.13808473208202765, "train/extr_return_normed_std": 0.32633682924967544, "train/extr_return_rate": 0.6884485517556851, "train/extr_return_raw_mag": 7.766206572606014, "train/extr_return_raw_max": 7.766206572606014, "train/extr_return_raw_mean": 1.7012234380612006, "train/extr_return_raw_min": -0.6505517927499918, "train/extr_return_raw_std": 1.5082965245613684, "train/extr_reward_mag": 1.0313576313165518, "train/extr_reward_max": 1.0313576313165518, "train/extr_reward_mean": 0.03293285146355629, "train/extr_reward_min": -0.5099475695536687, "train/extr_reward_std": 0.17081994265317918, "train/image_loss_mean": 5.749052476882935, "train/image_loss_std": 10.353549238351675, "train/model_loss_mean": 13.284514397841233, "train/model_loss_std": 14.047979105435886, "train/model_opt_grad_norm": 56.54151011246901, "train/model_opt_grad_steps": 41268.0, "train/model_opt_loss": 10423.894846754807, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 778.8461538461538, "train/policy_entropy_mag": 2.5517712611418504, "train/policy_entropy_max": 2.5517712611418504, "train/policy_entropy_mean": 0.5903491609371625, "train/policy_entropy_min": 0.07937504505881897, "train/policy_entropy_std": 0.6342728000420791, "train/policy_logprob_mag": 7.43838357925415, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.59119533094076, "train/policy_logprob_min": -7.43838357925415, "train/policy_logprob_std": 1.1435131375606244, "train/policy_randomness_mag": 0.9006632736096015, "train/policy_randomness_max": 0.9006632736096015, "train/policy_randomness_mean": 0.208367348748904, "train/policy_randomness_min": 0.02801590750996883, "train/policy_randomness_std": 0.22387046504479188, "train/post_ent_mag": 58.55140618544358, "train/post_ent_max": 58.55140618544358, "train/post_ent_mean": 42.03938457782452, "train/post_ent_min": 20.132149006770206, "train/post_ent_std": 7.554972989742573, "train/prior_ent_mag": 67.07414891169621, "train/prior_ent_max": 67.07414891169621, "train/prior_ent_mean": 54.602452146089995, "train/prior_ent_min": 39.56393315241887, "train/prior_ent_std": 4.246897677274851, "train/rep_loss_mean": 12.470362435854398, "train/rep_loss_std": 8.968304069225605, "train/reward_avg": 0.02694786645901891, "train/reward_loss_mean": 0.05301718047031989, "train/reward_loss_std": 0.23858816497600996, "train/reward_max_data": 1.0138461571473343, "train/reward_max_pred": 1.008390042415032, "train/reward_neg_acc": 0.9931475964876322, "train/reward_neg_loss": 0.027361518968469823, "train/reward_pos_acc": 0.9670044257090642, "train/reward_pos_loss": 0.8385718231017772, "train/reward_pred": 0.026349064281496862, "train/reward_rate": 0.03175330528846154, "eval_stats/sum_log_reward": 6.475000083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 9.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.024390243902439025, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.040537527951528e-07, "report/cont_loss_std": 6.31743250778527e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.7008561270777136e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.7161073035131267e-07, "report/cont_pred": 0.9941407442092896, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.009627342224121, "report/dyn_loss_std": 8.392396926879883, "report/image_loss_mean": 5.837382793426514, "report/image_loss_std": 6.834499835968018, "report/model_loss_mean": 13.088875770568848, "report/model_loss_std": 9.869850158691406, "report/post_ent_mag": 58.68416213989258, "report/post_ent_max": 58.68416213989258, "report/post_ent_mean": 42.22504806518555, "report/post_ent_min": 21.262027740478516, "report/post_ent_std": 7.441504955291748, "report/prior_ent_mag": 67.26411437988281, "report/prior_ent_max": 67.26411437988281, "report/prior_ent_mean": 54.69294738769531, "report/prior_ent_min": 34.97893142700195, "report/prior_ent_std": 4.601351261138916, "report/rep_loss_mean": 12.009627342224121, "report/rep_loss_std": 8.392396926879883, "report/reward_avg": 0.01396484300494194, "report/reward_loss_mean": 0.045716818422079086, "report/reward_loss_std": 0.1923118680715561, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029411315917969, "report/reward_neg_acc": 0.9970089793205261, "report/reward_neg_loss": 0.031034933403134346, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7469517588615417, "report/reward_pred": 0.015009123831987381, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 7.602230880365823e-07, "eval/cont_loss_std": 1.1851583622046746e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.704802995547652e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.874070214100357e-07, "eval/cont_pred": 0.9941404461860657, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.61644744873047, "eval/dyn_loss_std": 9.838407516479492, "eval/image_loss_mean": 11.809403419494629, "eval/image_loss_std": 13.262398719787598, "eval/model_loss_mean": 21.86844253540039, "eval/model_loss_std": 16.75922393798828, "eval/post_ent_mag": 55.70216369628906, "eval/post_ent_max": 55.70216369628906, "eval/post_ent_mean": 40.33489990234375, "eval/post_ent_min": 18.829975128173828, "eval/post_ent_std": 7.22146463394165, "eval/prior_ent_mag": 67.26411437988281, "eval/prior_ent_max": 67.26411437988281, "eval/prior_ent_mean": 55.06935119628906, "eval/prior_ent_min": 40.34607696533203, "eval/prior_ent_std": 3.833850860595703, "eval/rep_loss_mean": 16.61644744873047, "eval/rep_loss_std": 9.838407516479492, "eval/reward_avg": 0.04277343302965164, "eval/reward_loss_mean": 0.08916721493005753, "eval/reward_loss_std": 0.5200784802436829, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041747093200684, "eval/reward_neg_acc": 0.9897435307502747, "eval/reward_neg_loss": 0.02842037007212639, "eval/reward_pos_acc": 0.918367326259613, "eval/reward_pos_loss": 1.297905445098877, "eval/reward_pred": 0.03885876387357712, "eval/reward_rate": 0.0478515625, "replay/size": 672337.0, "replay/inserts": 20776.0, "replay/samples": 20784.0, "replay/insert_wait_avg": 1.376529909529776e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.982502725144549e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1342349069895762e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0412120819092, "timer/env.step_count": 2597.0, "timer/env.step_total": 229.37948966026306, "timer/env.step_frac": 0.22937003684351714, "timer/env.step_avg": 0.08832479386224992, "timer/env.step_min": 0.023483991622924805, "timer/env.step_max": 3.6514077186584473, "timer/replay._sample_count": 20784.0, "timer/replay._sample_total": 10.752814054489136, "timer/replay._sample_frac": 0.010752370926897778, "timer/replay._sample_avg": 0.0005173601835300778, "timer/replay._sample_min": 0.0003910064697265625, "timer/replay._sample_max": 0.010969400405883789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3143.0, "timer/agent.policy_total": 52.481669664382935, "timer/agent.policy_frac": 0.052479506874647065, "timer/agent.policy_avg": 0.016697954077118337, "timer/agent.policy_min": 0.009618997573852539, "timer/agent.policy_max": 0.10038566589355469, "timer/dataset_train_count": 1299.0, "timer/dataset_train_total": 0.15044260025024414, "timer/dataset_train_frac": 0.00015043640045298655, "timer/dataset_train_avg": 0.00011581416493475299, "timer/dataset_train_min": 0.00010561943054199219, "timer/dataset_train_max": 0.00036454200744628906, "timer/agent.train_count": 1299.0, "timer/agent.train_total": 578.5928666591644, "timer/agent.train_frac": 0.5785690226252139, "timer/agent.train_avg": 0.44541406209327516, "timer/agent.train_min": 0.4345967769622803, "timer/agent.train_max": 1.355262041091919, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4708230495452881, "timer/agent.report_frac": 0.00047080364674683523, "timer/agent.report_avg": 0.23541152477264404, "timer/agent.report_min": 0.22905373573303223, "timer/agent.report_max": 0.24176931381225586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6940189177193544e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 20.77485749041962}
{"step": 673096, "time": 33340.382417440414, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 673440, "time": 33354.68038225174, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 673688, "time": 33365.07403874397, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 673840, "time": 33372.55392885208, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 673864, "time": 33375.14272761345, "episode/length": 238.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 673904, "time": 33378.32500576973, "episode/length": 194.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 674056, "time": 33385.164513111115, "episode/length": 45.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 674168, "time": 33390.84247469902, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 674416, "time": 33401.64733624458, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 675008, "time": 33424.69056010246, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 675144, "time": 33431.02060818672, "episode/length": 212.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 675256, "time": 33436.70503139496, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 675296, "time": 33439.94162297249, "episode/length": 328.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 675320, "time": 33442.074016332626, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 675480, "time": 33449.51976394653, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 675648, "time": 33457.455814123154, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 675768, "time": 33463.157705545425, "episode/length": 168.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 675920, "time": 33470.46992301941, "episode/length": 232.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 676712, "time": 33500.63578224182, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 676720, "time": 33502.703604221344, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 676784, "time": 33506.590730667114, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 677000, "time": 33515.80541110039, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 677016, "time": 33518.02858686447, "episode/length": 388.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 677064, "time": 33521.37877559662, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 677096, "time": 33524.055401325226, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 677960, "time": 33557.33311152458, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 677968, "time": 33559.37677240372, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 678064, "time": 33564.503861904144, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 678136, "time": 33568.45990085602, "episode/length": 168.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 678296, "time": 33575.83485388756, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 678312, "time": 33578.09206867218, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 678536, "time": 33587.753190755844, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 678736, "time": 33596.89970374107, "episode/length": 214.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 679144, "time": 33613.26002430916, "episode/length": 50.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 679416, "time": 33624.731751680374, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 679472, "time": 33628.57792067528, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 679632, "time": 33636.001584768295, "episode/length": 186.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 679680, "time": 33639.3410077095, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 679960, "time": 33652.247836112976, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 33675.446575164795, "eval_episode/length": 141.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 680056, "time": 33677.5443007946, "eval_episode/length": 156.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 680056, "time": 33680.05450320244, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 680056, "time": 33681.651463508606, "eval_episode/length": 185.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 680056, "time": 33683.29565286636, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 680056, "time": 33684.9667737484, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 680056, "time": 33687.02139019966, "eval_episode/length": 202.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 680056, "time": 33690.24858021736, "eval_episode/length": 245.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967479674796748}
{"step": 680080, "time": 33691.356516599655, "episode/length": 220.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 680160, "time": 33695.84559345245, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 680744, "time": 33719.026958703995, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 680872, "time": 33725.92706823349, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 680904, "time": 33729.22220134735, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 680928, "time": 33732.52165102959, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 681000, "time": 33736.92328977585, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 681488, "time": 33757.71633028984, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 681648, "time": 33765.76566553116, "episode/length": 195.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 681944, "time": 33777.88462352753, "episode/length": 222.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 682040, "time": 33782.86340332031, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 682200, "time": 33790.4266936779, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 682296, "time": 33795.50471043587, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 682416, "time": 33801.64233708382, "episode/length": 46.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 682456, "time": 33804.46141719818, "episode/length": 190.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 682528, "time": 33808.86516022682, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 683048, "time": 33829.24256849289, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 683120, "time": 33833.56798315048, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 683656, "time": 33854.49911379814, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 683776, "time": 33860.631090164185, "episode/length": 228.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 683808, "time": 33863.291370630264, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 684096, "time": 33875.36155128479, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 684304, "time": 33884.59176492691, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 684376, "time": 33888.57365632057, "episode/length": 165.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 684616, "time": 33898.900164842606, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 684984, "time": 33913.92070388794, "episode/length": 335.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851190476190477, "episode/intrinsic_return": 0.0}
{"step": 685032, "time": 33917.258192539215, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 685296, "time": 33928.62234377861, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 685328, "time": 33931.26703834534, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 685824, "time": 33950.8785674572, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 686080, "time": 33961.71952867508, "episode/length": 247.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 686112, "time": 33964.482306957245, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 686272, "time": 33971.9413151741, "episode/length": 236.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 686472, "time": 33980.59690237045, "episode/length": 44.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 686552, "time": 33985.05869555473, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 686584, "time": 33987.7585978508, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 686584, "time": 33987.80681967735, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 687120, "time": 34011.36598920822, "episode/length": 227.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 687280, "time": 34019.37584781647, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 687912, "time": 34045.10334968567, "episode/length": 228.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 687928, "time": 34047.7093334198, "episode/length": 206.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 688168, "time": 34060.28084874153, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 688288, "time": 34066.37476468086, "episode/length": 226.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 688304, "time": 34068.64189815521, "episode/length": 214.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 688624, "time": 34081.93399524689, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 688944, "time": 34095.56629705429, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 689072, "time": 34102.346286296844, "episode/length": 314.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 689256, "time": 34111.16239905357, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 689296, "time": 34114.36723804474, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 689472, "time": 34122.42479491234, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 689768, "time": 34134.5566534996, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 34164.760937690735, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 690040, "time": 34166.35298871994, "eval_episode/length": 162.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 690040, "time": 34168.355957746506, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 690040, "time": 34169.94916129112, "eval_episode/length": 174.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 690040, "time": 34171.55370116234, "eval_episode/length": 177.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 690040, "time": 34173.7681248188, "eval_episode/length": 194.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 690040, "time": 34175.651990652084, "eval_episode/length": 201.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 690040, "time": 34178.04931664467, "eval_episode/length": 220.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 690104, "time": 34180.40158009529, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 690248, "time": 34187.21948552132, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 690328, "time": 34191.683448553085, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 690624, "time": 34204.24100494385, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 690736, "time": 34209.981130599976, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 690768, "time": 34212.78185129166, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 690960, "time": 34221.38988804817, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 691104, "time": 34228.25275349617, "episode/length": 230.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 691256, "time": 34235.24337410927, "episode/length": 222.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 691376, "time": 34241.465098142624, "episode/length": 140.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 691656, "time": 34253.161472558975, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 692288, "time": 34278.731261491776, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 692360, "time": 34282.65527176857, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 692696, "time": 34296.65552377701, "episode/length": 50.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 693136, "time": 34314.51751995087, "episode/length": 313.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 693152, "time": 34316.64320421219, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 693312, "time": 34324.00530529022, "episode/length": 275.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 693449, "time": 34331.47157549858, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.246805826822917, "train/action_min": 0.0, "train/action_std": 3.2401649841042452, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04321187884770623, "train/actor_opt_grad_steps": 42600.0, "train/actor_opt_loss": -2.78663146611332, "train/adv_mag": 0.5807684364244919, "train/adv_max": 0.5517141650351443, "train/adv_mean": 0.0035256050819713375, "train/adv_min": -0.4450082695761392, "train/adv_std": 0.0640608106934747, "train/cont_avg": 0.9949127906976745, "train/cont_loss_mean": 0.00016564969465060733, "train/cont_loss_std": 0.005055715643607954, "train/cont_neg_acc": 0.991131415200788, "train/cont_neg_loss": 0.021554362076497545, "train/cont_pos_acc": 0.9999847684719766, "train/cont_pos_loss": 4.723078085662071e-05, "train/cont_pred": 0.9949231041494266, "train/cont_rate": 0.9949127906976745, "train/dyn_loss_mean": 12.55818902984146, "train/dyn_loss_std": 9.02803704165673, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8236652021260225, "train/extr_critic_critic_opt_grad_steps": 42600.0, "train/extr_critic_critic_opt_loss": 15517.607452156008, "train/extr_critic_mag": 6.7348479004793385, "train/extr_critic_max": 6.7348479004793385, "train/extr_critic_mean": 1.7772910521011944, "train/extr_critic_min": -0.24291405012441236, "train/extr_critic_std": 1.4782246536062669, "train/extr_return_normed_mag": 1.6704094271327175, "train/extr_return_normed_max": 1.6704094271327175, "train/extr_return_normed_mean": 0.3715968209412671, "train/extr_return_normed_min": -0.1360166745130406, "train/extr_return_normed_std": 0.3233248693074367, "train/extr_return_rate": 0.709388159966284, "train/extr_return_raw_mag": 7.875046016633973, "train/extr_return_raw_max": 7.875046016633973, "train/extr_return_raw_mean": 1.7937074576237404, "train/extr_return_raw_min": -0.5823834928893303, "train/extr_return_raw_std": 1.5134061824443727, "train/extr_reward_mag": 1.0207933400028435, "train/extr_reward_max": 1.0207933400028435, "train/extr_reward_mean": 0.030470331827568455, "train/extr_reward_min": -0.4624146407888841, "train/extr_reward_std": 0.16400927767273069, "train/image_loss_mean": 6.113726628843204, "train/image_loss_std": 11.02552698933801, "train/model_loss_mean": 13.70349512174148, "train/model_loss_std": 14.715545550797337, "train/model_opt_grad_norm": 55.93259940036508, "train/model_opt_grad_steps": 42562.59689922481, "train/model_opt_loss": 18336.380094779553, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1337.2093023255813, "train/policy_entropy_mag": 2.6108373911805853, "train/policy_entropy_max": 2.6108373911805853, "train/policy_entropy_mean": 0.5300606295119884, "train/policy_entropy_min": 0.07937502999638402, "train/policy_entropy_std": 0.6146034570627434, "train/policy_logprob_mag": 7.438383634700331, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5288362572359484, "train/policy_logprob_min": -7.438383634700331, "train/policy_logprob_std": 1.0965616236361422, "train/policy_randomness_mag": 0.9215110267779624, "train/policy_randomness_max": 0.9215110267779624, "train/policy_randomness_mean": 0.1870881407990936, "train/policy_randomness_min": 0.028015902265906334, "train/policy_randomness_std": 0.21692805130814397, "train/post_ent_mag": 58.46784884430642, "train/post_ent_max": 58.46784884430642, "train/post_ent_mean": 42.00999388583871, "train/post_ent_min": 19.926759291064833, "train/post_ent_std": 7.53438121219014, "train/prior_ent_mag": 66.99617329678794, "train/prior_ent_max": 66.99617329678794, "train/prior_ent_mean": 54.629108635954154, "train/prior_ent_min": 40.0482221204181, "train/prior_ent_std": 4.205177686011145, "train/rep_loss_mean": 12.55818902984146, "train/rep_loss_std": 9.02803704165673, "train/reward_avg": 0.026458030342766944, "train/reward_loss_mean": 0.05468942565742389, "train/reward_loss_std": 0.25164289680100227, "train/reward_max_data": 1.0155038796654043, "train/reward_max_pred": 1.0107522953388304, "train/reward_neg_acc": 0.9926509335059528, "train/reward_neg_loss": 0.02903369359325531, "train/reward_pos_acc": 0.96656792200813, "train/reward_pos_loss": 0.8543228312980297, "train/reward_pred": 0.025798241571747055, "train/reward_rate": 0.031136446220930234, "train_stats/sum_log_reward": 6.894392583971825, "train_stats/max_log_achievement_collect_coal": 0.06542056074766354, "train_stats/max_log_achievement_collect_drink": 3.8317757009345796, "train_stats/max_log_achievement_collect_sapling": 1.8785046728971964, "train_stats/max_log_achievement_collect_stone": 0.4485981308411215, "train_stats/max_log_achievement_collect_wood": 13.373831775700934, "train_stats/max_log_achievement_defeat_skeleton": 0.009345794392523364, "train_stats/max_log_achievement_defeat_zombie": 0.8317757009345794, "train_stats/max_log_achievement_eat_cow": 0.09345794392523364, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 4.308411214953271, "train_stats/max_log_achievement_make_wood_sword": 0.2523364485981308, "train_stats/max_log_achievement_place_plant": 1.841121495327103, "train_stats/max_log_achievement_place_stone": 0.018691588785046728, "train_stats/max_log_achievement_place_table": 3.1682242990654204, "train_stats/max_log_achievement_wake_up": 1.1214953271028036, "train_stats/mean_log_entropy": 0.4472500453485507, "eval_stats/sum_log_reward": 6.349999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 0.9375, "eval_stats/max_log_achievement_collect_stone": 0.4375, "eval_stats/max_log_achievement_collect_wood": 13.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.9375, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 0.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.987801953073358e-06, "report/cont_loss_std": 8.065420115599409e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.337448626756668e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.845108600828098e-06, "report/cont_pred": 0.9960870742797852, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.392887115478516, "report/dyn_loss_std": 8.801496505737305, "report/image_loss_mean": 5.280822277069092, "report/image_loss_std": 10.114789962768555, "report/model_loss_mean": 12.15908432006836, "report/model_loss_std": 13.670568466186523, "report/post_ent_mag": 59.377662658691406, "report/post_ent_max": 59.377662658691406, "report/post_ent_mean": 42.6549186706543, "report/post_ent_min": 21.09995460510254, "report/post_ent_std": 7.599541664123535, "report/prior_ent_mag": 67.0526123046875, "report/prior_ent_max": 67.0526123046875, "report/prior_ent_mean": 54.030879974365234, "report/prior_ent_min": 39.58013916015625, "report/prior_ent_std": 4.25821590423584, "report/rep_loss_mean": 11.392887115478516, "report/rep_loss_std": 8.801496505737305, "report/reward_avg": 0.01796874776482582, "report/reward_loss_mean": 0.04252246022224426, "report/reward_loss_std": 0.16905884444713593, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011541843414307, "report/reward_neg_acc": 0.9840478897094727, "report/reward_neg_loss": 0.02927255444228649, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.675363302230835, "report/reward_pred": 0.019539769738912582, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.4207529349951074e-06, "eval/cont_loss_std": 8.784809324424714e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.396697714691982e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.0617480913642794e-06, "eval/cont_pred": 0.9960920810699463, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.338600158691406, "eval/dyn_loss_std": 10.76224422454834, "eval/image_loss_mean": 12.018828392028809, "eval/image_loss_std": 17.20061683654785, "eval/model_loss_mean": 21.92679786682129, "eval/model_loss_std": 21.527851104736328, "eval/post_ent_mag": 60.70817565917969, "eval/post_ent_max": 60.70817565917969, "eval/post_ent_mean": 40.998958587646484, "eval/post_ent_min": 18.889066696166992, "eval/post_ent_std": 7.553069591522217, "eval/prior_ent_mag": 67.0526123046875, "eval/prior_ent_max": 67.0526123046875, "eval/prior_ent_mean": 55.15342330932617, "eval/prior_ent_min": 41.88545227050781, "eval/prior_ent_std": 4.650859832763672, "eval/rep_loss_mean": 16.338600158691406, "eval/rep_loss_std": 10.76224422454834, "eval/reward_avg": 0.03496094048023224, "eval/reward_loss_mean": 0.10480869561433792, "eval/reward_loss_std": 0.6706458330154419, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.001180648803711, "eval/reward_neg_acc": 0.9908537268638611, "eval/reward_neg_loss": 0.02864835038781166, "eval/reward_pos_acc": 0.7750000357627869, "eval/reward_pos_loss": 1.9783531427383423, "eval/reward_pred": 0.027912374585866928, "eval/reward_rate": 0.0390625, "replay/size": 692945.0, "replay/inserts": 20608.0, "replay/samples": 20608.0, "replay/insert_wait_avg": 1.408055609797839e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.870890524076379e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1168531993727102e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3555865287781, "timer/env.step_count": 2576.0, "timer/env.step_total": 241.47908759117126, "timer/env.step_frac": 0.2413932514028345, "timer/env.step_avg": 0.09374188182887083, "timer/env.step_min": 0.022292137145996094, "timer/env.step_max": 3.2613914012908936, "timer/replay._sample_count": 20608.0, "timer/replay._sample_total": 10.703523874282837, "timer/replay._sample_frac": 0.010699719198274222, "timer/replay._sample_avg": 0.0005193868339617059, "timer/replay._sample_min": 0.0004086494445800781, "timer/replay._sample_max": 0.026283740997314453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3043.0, "timer/agent.policy_total": 49.98210263252258, "timer/agent.policy_frac": 0.049964335987726004, "timer/agent.policy_avg": 0.016425271979139858, "timer/agent.policy_min": 0.00944209098815918, "timer/agent.policy_max": 0.09846019744873047, "timer/dataset_train_count": 1288.0, "timer/dataset_train_total": 0.15276050567626953, "timer/dataset_train_frac": 0.00015270620540676607, "timer/dataset_train_avg": 0.00011860287707784902, "timer/dataset_train_min": 0.00010514259338378906, "timer/dataset_train_max": 0.0006499290466308594, "timer/agent.train_count": 1288.0, "timer/agent.train_total": 573.9633181095123, "timer/agent.train_frac": 0.5737592970327263, "timer/agent.train_avg": 0.445623694184404, "timer/agent.train_min": 0.43422913551330566, "timer/agent.train_max": 1.1554005146026611, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.481395959854126, "timer/agent.report_frac": 0.0004812248427827191, "timer/agent.report_avg": 0.240697979927063, "timer/agent.report_min": 0.2337803840637207, "timer/agent.report_max": 0.24761557579040527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693172288062343e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 20.600393318283718}
{"step": 693568, "time": 34335.852185726166, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 693696, "time": 34342.02445721626, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9808743169398907, "episode/intrinsic_return": 0.0}
{"step": 693736, "time": 34344.90993857384, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 693824, "time": 34349.98189043999, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 694552, "time": 34379.28723907471, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 694560, "time": 34381.79016971588, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 694776, "time": 34391.61612868309, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 694904, "time": 34397.93668079376, "episode/length": 150.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 694952, "time": 34401.09156513214, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 695000, "time": 34404.401810884476, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 695256, "time": 34415.26380419731, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 695536, "time": 34427.35642552376, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 695856, "time": 34440.610110759735, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 696184, "time": 34453.974885225296, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 696336, "time": 34462.8414683342, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 696456, "time": 34468.63674449921, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 696616, "time": 34476.17799663544, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 696832, "time": 34485.98689889908, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 696936, "time": 34491.00330376625, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 697312, "time": 34506.572675943375, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 697336, "time": 34508.69425749779, "episode/length": 224.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 697592, "time": 34519.696170806885, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 697888, "time": 34532.34430360794, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 697960, "time": 34536.36753940582, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 698328, "time": 34551.33370089531, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 698688, "time": 34566.332033872604, "episode/length": 218.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 698744, "time": 34569.636115312576, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 698848, "time": 34575.014909505844, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 698992, "time": 34581.8873257637, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 699144, "time": 34588.862080574036, "episode/length": 36.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 699424, "time": 34600.98488306999, "episode/length": 228.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 699456, "time": 34603.78566646576, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 699632, "time": 34611.77873158455, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 34646.6502995491, "eval_episode/length": 161.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 700024, "time": 34648.487843990326, "eval_episode/length": 167.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 700024, "time": 34650.23547744751, "eval_episode/length": 172.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 700024, "time": 34651.93663764, "eval_episode/length": 175.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 700024, "time": 34653.76831674576, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 700024, "time": 34655.700744628906, "eval_episode/length": 193.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9845360824742269}
{"step": 700024, "time": 34657.74909377098, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 700024, "time": 34659.309821367264, "eval_episode/length": 207.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 700064, "time": 34660.98523569107, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.0}
{"step": 700400, "time": 34674.656512737274, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 700744, "time": 34688.632316589355, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 700808, "time": 34692.42291998863, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 700968, "time": 34699.80831575394, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 700976, "time": 34701.92898488045, "episode/length": 285.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 701168, "time": 34710.449523448944, "episode/length": 252.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 701312, "time": 34717.34246301651, "episode/length": 289.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 701640, "time": 34730.50597882271, "episode/length": 250.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 701936, "time": 34743.032977581024, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 702256, "time": 34756.237619161606, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 702296, "time": 34758.93162894249, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 702320, "time": 34761.551267147064, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 702360, "time": 34764.365520477295, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 702568, "time": 34773.39239645004, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 703312, "time": 34802.3401222229, "episode/length": 171.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 703544, "time": 34812.19550919533, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 703544, "time": 34812.248967170715, "episode/length": 160.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 703728, "time": 34822.566586494446, "episode/length": 175.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 703928, "time": 34831.1851606369, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 703968, "time": 34834.41714930534, "episode/length": 174.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 704032, "time": 34838.424328804016, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 704392, "time": 34852.77141737938, "episode/length": 384.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9896103896103896, "episode/intrinsic_return": 0.0}
{"step": 704736, "time": 34868.65867614746, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 704952, "time": 34877.85467004776, "episode/length": 175.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 705224, "time": 34889.38617372513, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 705400, "time": 34897.48290705681, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9617224880382775, "episode/intrinsic_return": 0.0}
{"step": 705424, "time": 34900.007837057114, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 705480, "time": 34903.3326485157, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 705584, "time": 34908.950593709946, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 705920, "time": 34922.62808895111, "episode/length": 147.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 706280, "time": 34937.33172106743, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 706352, "time": 34942.35914134979, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 706544, "time": 34951.54133963585, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 706856, "time": 34965.076115608215, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 707408, "time": 34988.1252720356, "episode/length": 140.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 707448, "time": 34991.53402256966, "episode/length": 255.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 707648, "time": 35001.31879544258, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 707752, "time": 35006.9342610836, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 708112, "time": 35022.499295949936, "episode/length": 195.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 708152, "time": 35025.34369826317, "episode/length": 333.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 708288, "time": 35032.09964990616, "episode/length": 178.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 708392, "time": 35037.12904930115, "episode/length": 350.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 708888, "time": 35056.82139015198, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 709064, "time": 35064.83011007309, "episode/length": 176.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 709216, "time": 35074.075551986694, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 709240, "time": 35076.306594610214, "episode/length": 185.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 709672, "time": 35093.515436410904, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 35121.72470211983, "eval_episode/length": 39.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.975}
{"step": 710008, "time": 35123.37316298485, "eval_episode/length": 40.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.975609756097561}
{"step": 710008, "time": 35130.50885987282, "eval_episode/length": 152.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 710008, "time": 35132.20921039581, "eval_episode/length": 154.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9548387096774194}
{"step": 710008, "time": 35135.33733296394, "eval_episode/length": 154.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 710008, "time": 35137.186611652374, "eval_episode/length": 157.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 710008, "time": 35138.86748814583, "eval_episode/length": 201.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 710008, "time": 35141.301328897476, "eval_episode/length": 221.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 710024, "time": 35141.89853477478, "episode/length": 203.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 710272, "time": 35152.7656648159, "episode/length": 247.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 710336, "time": 35156.727601766586, "episode/length": 180.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 710416, "time": 35161.207573890686, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 710928, "time": 35181.43408370018, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 710960, "time": 35184.10347223282, "episode/length": 355.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 711064, "time": 35189.22916126251, "episode/length": 230.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 711536, "time": 35208.106534957886, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 711536, "time": 35208.144325494766, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 711816, "time": 35221.46980381012, "episode/length": 223.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 711904, "time": 35226.49619746208, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 712736, "time": 35260.18392491341, "episode/length": 289.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 712816, "time": 35264.64459037781, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 713040, "time": 35274.38304758072, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 713232, "time": 35282.97117114067, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 713288, "time": 35286.37790155411, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 713384, "time": 35291.455473184586, "episode/length": 306.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 713480, "time": 35296.59386873245, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 713616, "time": 35303.42669773102, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 713784, "time": 35310.78749203682, "episode/length": 352.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9915014164305949, "episode/intrinsic_return": 0.0}
{"step": 714281, "time": 35331.59592604637, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.2696063701923075, "train/action_min": 0.0, "train/action_std": 3.362205740121695, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04229794952731866, "train/actor_opt_grad_steps": 43895.0, "train/actor_opt_loss": -3.4745705467720445, "train/adv_mag": 0.5893332921541654, "train/adv_max": 0.5581612444840944, "train/adv_mean": 0.0032491243014541957, "train/adv_min": -0.44851951484496777, "train/adv_std": 0.0625680727740893, "train/cont_avg": 0.9947866586538462, "train/cont_loss_mean": 8.215540952698156e-05, "train/cont_loss_std": 0.002476733980174336, "train/cont_neg_acc": 0.9967948721005366, "train/cont_neg_loss": 0.006663286962332047, "train/cont_pos_acc": 0.9999849209418663, "train/cont_pos_loss": 4.870512413810082e-05, "train/cont_pred": 0.9947741380104652, "train/cont_rate": 0.9947866586538462, "train/dyn_loss_mean": 12.408185452681321, "train/dyn_loss_std": 9.004870128631591, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7815009236335755, "train/extr_critic_critic_opt_grad_steps": 43895.0, "train/extr_critic_critic_opt_loss": 15351.853733473557, "train/extr_critic_mag": 6.789354372024536, "train/extr_critic_max": 6.789354372024536, "train/extr_critic_mean": 1.816773588840778, "train/extr_critic_min": -0.2753552170900198, "train/extr_critic_std": 1.4983787160653335, "train/extr_return_normed_mag": 1.6712352468417242, "train/extr_return_normed_max": 1.6712352468417242, "train/extr_return_normed_mean": 0.3725510482604687, "train/extr_return_normed_min": -0.13502130531347714, "train/extr_return_normed_std": 0.32149918090838653, "train/extr_return_rate": 0.7270548268006398, "train/extr_return_raw_mag": 8.022343848301814, "train/extr_return_raw_max": 8.022343848301814, "train/extr_return_raw_mean": 1.832277185183305, "train/extr_return_raw_min": -0.5873090831133035, "train/extr_return_raw_std": 1.5325963277083177, "train/extr_reward_mag": 1.0297653051523061, "train/extr_reward_max": 1.0297653051523061, "train/extr_reward_mean": 0.0315522113456749, "train/extr_reward_min": -0.4693893359257625, "train/extr_reward_std": 0.16746389287022445, "train/image_loss_mean": 5.7997053073002744, "train/image_loss_std": 10.67229512654818, "train/model_loss_mean": 13.299389443030725, "train/model_loss_std": 14.350527125138504, "train/model_opt_grad_norm": 53.170033088097206, "train/model_opt_grad_steps": 43856.43076923077, "train/model_opt_loss": 17671.804033954326, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1326.923076923077, "train/policy_entropy_mag": 2.580952813075139, "train/policy_entropy_max": 2.580952813075139, "train/policy_entropy_mean": 0.5150664707789054, "train/policy_entropy_min": 0.07937501921103551, "train/policy_entropy_std": 0.6031453095949613, "train/policy_logprob_mag": 7.4383836782895605, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5158109550292675, "train/policy_logprob_min": -7.4383836782895605, "train/policy_logprob_std": 1.0892537566331717, "train/policy_randomness_mag": 0.9109630818550404, "train/policy_randomness_max": 0.9109630818550404, "train/policy_randomness_mean": 0.18179586346332843, "train/policy_randomness_min": 0.02801589842599172, "train/policy_randomness_std": 0.21288382903887676, "train/post_ent_mag": 58.408000095073994, "train/post_ent_max": 58.408000095073994, "train/post_ent_mean": 42.205430720402646, "train/post_ent_min": 19.963553054516133, "train/post_ent_std": 7.530212849837083, "train/prior_ent_mag": 67.07498949491061, "train/prior_ent_max": 67.07498949491061, "train/prior_ent_mean": 54.6979236309345, "train/prior_ent_min": 39.546412834754356, "train/prior_ent_std": 4.196754224483783, "train/rep_loss_mean": 12.408185452681321, "train/rep_loss_std": 9.004870128631591, "train/reward_avg": 0.027385065912340696, "train/reward_loss_mean": 0.05469088686200289, "train/reward_loss_std": 0.24715936527802393, "train/reward_max_data": 1.0184615428631123, "train/reward_max_pred": 1.0097617323581989, "train/reward_neg_acc": 0.9926470765700707, "train/reward_neg_loss": 0.028084829256225092, "train/reward_pos_acc": 0.9673878059937404, "train/reward_pos_loss": 0.8607749388768122, "train/reward_pred": 0.026447790366812395, "train/reward_rate": 0.03218149038461538, "train_stats/sum_log_reward": 7.81287139477116, "train_stats/max_log_achievement_collect_coal": 0.1485148514851485, "train_stats/max_log_achievement_collect_drink": 5.346534653465347, "train_stats/max_log_achievement_collect_sapling": 1.9306930693069306, "train_stats/max_log_achievement_collect_stone": 1.1485148514851484, "train_stats/max_log_achievement_collect_wood": 13.742574257425742, "train_stats/max_log_achievement_defeat_skeleton": 0.019801980198019802, "train_stats/max_log_achievement_defeat_zombie": 1.188118811881188, "train_stats/max_log_achievement_eat_cow": 0.1782178217821782, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.732673267326733, "train_stats/max_log_achievement_make_wood_sword": 0.6534653465346535, "train_stats/max_log_achievement_place_plant": 1.8316831683168318, "train_stats/max_log_achievement_place_stone": 0.09900990099009901, "train_stats/max_log_achievement_place_table": 3.4752475247524752, "train_stats/max_log_achievement_wake_up": 1.2277227722772277, "train_stats/mean_log_entropy": 0.45293226705329254, "eval_stats/sum_log_reward": 6.60000005364418, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 0.6875, "eval_stats/max_log_achievement_collect_wood": 10.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.07692307692307693, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00021815406216774136, "report/cont_loss_std": 0.006930644158273935, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.893757846322842e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00021945640037301928, "report/cont_pred": 0.992968738079071, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.253022193908691, "report/dyn_loss_std": 8.801298141479492, "report/image_loss_mean": 8.128198623657227, "report/image_loss_std": 11.731165885925293, "report/model_loss_mean": 16.141206741333008, "report/model_loss_std": 15.370715141296387, "report/post_ent_mag": 56.18111038208008, "report/post_ent_max": 56.18111038208008, "report/post_ent_mean": 41.692962646484375, "report/post_ent_min": 20.482154846191406, "report/post_ent_std": 7.505434989929199, "report/prior_ent_mag": 67.54396057128906, "report/prior_ent_max": 67.54396057128906, "report/prior_ent_mean": 54.920833587646484, "report/prior_ent_min": 41.75624084472656, "report/prior_ent_std": 4.25035285949707, "report/rep_loss_mean": 13.253022193908691, "report/rep_loss_std": 8.801298141479492, "report/reward_avg": 0.03291015326976776, "report/reward_loss_mean": 0.06097571924328804, "report/reward_loss_std": 0.2491716593503952, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005810022354126, "report/reward_neg_acc": 0.992893397808075, "report/reward_neg_loss": 0.030499586835503578, "report/reward_pos_acc": 0.9743589758872986, "report/reward_pos_loss": 0.8306936025619507, "report/reward_pred": 0.032527580857276917, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.3266425412439276e-05, "eval/cont_loss_std": 0.0003498595324344933, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.6523520975606516e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3198088709032163e-05, "eval/cont_pred": 0.9970574378967285, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.904747009277344, "eval/dyn_loss_std": 10.684915542602539, "eval/image_loss_mean": 9.922869682312012, "eval/image_loss_std": 15.699507713317871, "eval/model_loss_mean": 19.585899353027344, "eval/model_loss_std": 19.55812644958496, "eval/post_ent_mag": 60.26810836791992, "eval/post_ent_max": 60.26810836791992, "eval/post_ent_mean": 42.050270080566406, "eval/post_ent_min": 20.279996871948242, "eval/post_ent_std": 8.158217430114746, "eval/prior_ent_mag": 67.54396057128906, "eval/prior_ent_max": 67.54396057128906, "eval/prior_ent_mean": 55.308773040771484, "eval/prior_ent_min": 41.63756561279297, "eval/prior_ent_std": 3.943995714187622, "eval/rep_loss_mean": 15.904747009277344, "eval/rep_loss_std": 10.684915542602539, "eval/reward_avg": 0.03378906100988388, "eval/reward_loss_mean": 0.12016765028238297, "eval/reward_loss_std": 0.7669102549552917, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003281593322754, "eval/reward_neg_acc": 0.9847869873046875, "eval/reward_neg_loss": 0.034680236130952835, "eval/reward_pos_acc": 0.7631579041481018, "eval/reward_pos_loss": 2.338341236114502, "eval/reward_pred": 0.028326090425252914, "eval/reward_rate": 0.037109375, "replay/size": 713777.0, "replay/inserts": 20832.0, "replay/samples": 20832.0, "replay/insert_wait_avg": 1.4301795747056717e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.87140678517097e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1177950127180233e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1092314720154, "timer/env.step_count": 2604.0, "timer/env.step_total": 232.26221632957458, "timer/env.step_frac": 0.23223684875672868, "timer/env.step_avg": 0.08919439951212542, "timer/env.step_min": 0.02324080467224121, "timer/env.step_max": 3.426149606704712, "timer/replay._sample_count": 20832.0, "timer/replay._sample_total": 10.842411041259766, "timer/replay._sample_frac": 0.010841226838093788, "timer/replay._sample_avg": 0.0005204690399990287, "timer/replay._sample_min": 0.0004229545593261719, "timer/replay._sample_max": 0.01774454116821289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3034.0, "timer/agent.policy_total": 51.21997261047363, "timer/agent.policy_frac": 0.0512143783885339, "timer/agent.policy_avg": 0.016881994927644573, "timer/agent.policy_min": 0.009536266326904297, "timer/agent.policy_max": 0.13852334022521973, "timer/dataset_train_count": 1302.0, "timer/dataset_train_total": 0.15320372581481934, "timer/dataset_train_frac": 0.00015318699297408317, "timer/dataset_train_avg": 0.0001176679921772806, "timer/dataset_train_min": 0.00010728836059570312, "timer/dataset_train_max": 0.0004286766052246094, "timer/agent.train_count": 1302.0, "timer/agent.train_total": 579.2262961864471, "timer/agent.train_frac": 0.5791630333557768, "timer/agent.train_avg": 0.4448742674243066, "timer/agent.train_min": 0.4312896728515625, "timer/agent.train_max": 2.3616464138031006, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754152297973633, "timer/agent.report_frac": 0.0004753633051637981, "timer/agent.report_avg": 0.23770761489868164, "timer/agent.report_min": 0.23145270347595215, "timer/agent.report_max": 0.24396252632141113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8607104696031453e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 20.829428695567543}
{"step": 714464, "time": 35338.32051515579, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 714480, "time": 35340.48098897934, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 714792, "time": 35353.32506084442, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 715096, "time": 35366.03372502327, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 715128, "time": 35368.83692598343, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 715640, "time": 35389.11445426941, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 715728, "time": 35394.05855202675, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 715736, "time": 35395.734657526016, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 716304, "time": 35418.04319143295, "episode/length": 188.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 716576, "time": 35429.422352552414, "episode/length": 184.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 716584, "time": 35430.98769950867, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 716848, "time": 35442.335035562515, "episode/length": 382.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817232375979112, "episode/intrinsic_return": 0.0}
{"step": 716856, "time": 35444.04104113579, "episode/length": 404.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950617283950617, "episode/intrinsic_return": 0.0}
{"step": 716984, "time": 35450.12081813812, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 717384, "time": 35466.258934020996, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 717848, "time": 35484.76625227928, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 717920, "time": 35489.21191716194, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 718280, "time": 35503.784687280655, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 718720, "time": 35521.6344935894, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 718840, "time": 35527.53268790245, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 719136, "time": 35539.98645210266, "episode/length": 151.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 719504, "time": 35554.776787519455, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 719592, "time": 35559.48677325249, "episode/length": 341.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 719784, "time": 35568.056877851486, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 35599.40892291069, "eval_episode/length": 140.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 720096, "time": 35602.7658302784, "eval_episode/length": 183.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 720096, "time": 35604.44266915321, "eval_episode/length": 46.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 720096, "time": 35607.19497656822, "eval_episode/length": 217.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 720096, "time": 35609.502484083176, "eval_episode/length": 236.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9831223628691983}
{"step": 720096, "time": 35611.98935008049, "eval_episode/length": 261.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9770992366412213}
{"step": 720096, "time": 35615.32140207291, "eval_episode/length": 309.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 720096, "time": 35619.48651432991, "eval_episode/length": 370.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9757412398921833}
{"step": 720264, "time": 35625.352266550064, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 720328, "time": 35629.26302981377, "episode/length": 255.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 720464, "time": 35635.90091872215, "episode/length": 434.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9908045977011494, "episode/intrinsic_return": 0.0}
{"step": 720704, "time": 35646.05588674545, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 721016, "time": 35660.38809418678, "episode/length": 177.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 721160, "time": 35667.188584566116, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 721256, "time": 35672.17956185341, "episode/length": 115.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 721560, "time": 35684.75006532669, "episode/length": 49.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 721904, "time": 35699.002666950226, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 722640, "time": 35727.494965553284, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 722856, "time": 35736.836508989334, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 722984, "time": 35742.847584724426, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 723184, "time": 35751.876457452774, "episode/length": 459.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9978260869565218, "episode/intrinsic_return": 0.0}
{"step": 723216, "time": 35754.60861372948, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 723240, "time": 35756.75295162201, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 723280, "time": 35759.92698550224, "episode/length": 351.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 724072, "time": 35789.995499134064, "episode/length": 668.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940209267563528, "episode/intrinsic_return": 0.0}
{"step": 724256, "time": 35798.57973241806, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 724312, "time": 35801.94835114479, "episode/length": 165.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 724456, "time": 35808.78816533089, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 724840, "time": 35824.22401547432, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 724920, "time": 35828.75281715393, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 725264, "time": 35843.07001900673, "episode/length": 259.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 725432, "time": 35850.5404317379, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 725456, "time": 35853.279574394226, "episode/length": 279.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 725752, "time": 35865.55002236366, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 725864, "time": 35871.16699099541, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 726376, "time": 35891.45851135254, "episode/length": 114.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9478260869565217, "episode/intrinsic_return": 0.0}
{"step": 726384, "time": 35893.619843006134, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 726632, "time": 35903.991619586945, "episode/length": 296.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 726880, "time": 35914.94526576996, "episode/length": 254.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 727136, "time": 35926.49631690979, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 727288, "time": 35933.381714105606, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 727456, "time": 35941.6334233284, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 727672, "time": 35951.750044345856, "episode/length": 160.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 727760, "time": 35957.360827207565, "episode/length": 290.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 728120, "time": 35971.73229122162, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 728224, "time": 35977.34212851524, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 728464, "time": 35987.566314935684, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 728592, "time": 35993.81382346153, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 728752, "time": 36001.24323058128, "episode/length": 182.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 728808, "time": 36004.604080438614, "episode/length": 42.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 728984, "time": 36012.62509536743, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 729224, "time": 36024.55534148216, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 729464, "time": 36034.950157403946, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 36079.0027115345, "eval_episode/length": 168.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 730080, "time": 36080.94969344139, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 730080, "time": 36083.07044696808, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 730080, "time": 36086.306569099426, "eval_episode/length": 233.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 730080, "time": 36088.22743344307, "eval_episode/length": 49.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.98}
{"step": 730080, "time": 36089.8913629055, "eval_episode/length": 244.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9755102040816327}
{"step": 730080, "time": 36092.00414443016, "eval_episode/length": 258.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 730080, "time": 36095.691178798676, "eval_episode/length": 314.0, "eval_episode/score": 12.099999956786633, "eval_episode/reward_rate": 0.9968253968253968}
{"step": 730296, "time": 36103.48457765579, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 730304, "time": 36105.538833618164, "episode/length": 213.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 730504, "time": 36114.07804918289, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 730808, "time": 36126.893813848495, "episode/length": 249.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 730968, "time": 36134.296290397644, "episode/length": 355.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 731136, "time": 36142.16260623932, "episode/length": 208.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 731824, "time": 36168.79038190842, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 731904, "time": 36173.29686808586, "episode/length": 200.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 731912, "time": 36175.00629901886, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 732024, "time": 36180.78065729141, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 732096, "time": 36185.273529052734, "episode/length": 417.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.992822966507177, "episode/intrinsic_return": 0.0}
{"step": 732776, "time": 36211.531772613525, "episode/length": 225.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 732800, "time": 36214.11536860466, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 732872, "time": 36218.10972380638, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 733232, "time": 36233.136039972305, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 733240, "time": 36234.78990197182, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 733400, "time": 36242.21094369888, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 733568, "time": 36250.12153863907, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 733688, "time": 36255.765459775925, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 734664, "time": 36293.10842657089, "episode/length": 223.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 734912, "time": 36304.05990886688, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 735016, "time": 36309.31568789482, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 735240, "time": 36319.06091952324, "episode/length": 229.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 735529, "time": 36332.03149986267, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.237916415795348, "train/action_min": 0.0, "train/action_std": 3.1866043008359752, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04272819738975145, "train/actor_opt_grad_steps": 45210.0, "train/actor_opt_loss": -2.1847693275632265, "train/adv_mag": 0.5884147264007339, "train/adv_max": 0.5465856465630066, "train/adv_mean": 0.004005402315122862, "train/adv_min": -0.4476759379967711, "train/adv_std": 0.06260907159824121, "train/cont_avg": 0.9945004111842105, "train/cont_loss_mean": 0.00024015945945123356, "train/cont_loss_std": 0.007175727256834851, "train/cont_neg_acc": 0.9958974826604801, "train/cont_neg_loss": 0.019125558936945907, "train/cont_pos_acc": 0.999955659970305, "train/cont_pos_loss": 0.00010721330395595596, "train/cont_pred": 0.9944882903780256, "train/cont_rate": 0.9945004111842105, "train/dyn_loss_mean": 12.720868089145288, "train/dyn_loss_std": 8.99513056045188, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8084613828730762, "train/extr_critic_critic_opt_grad_steps": 45210.0, "train/extr_critic_critic_opt_loss": 15384.509706884399, "train/extr_critic_mag": 6.88145469364367, "train/extr_critic_max": 6.88145469364367, "train/extr_critic_mean": 1.8961910107978304, "train/extr_critic_min": -0.27208262547514495, "train/extr_critic_std": 1.5583280584865944, "train/extr_return_normed_mag": 1.6642266027909471, "train/extr_return_normed_max": 1.6642266027909471, "train/extr_return_normed_mean": 0.38333021137947426, "train/extr_return_normed_min": -0.14171760772964112, "train/extr_return_normed_std": 0.3268562317790842, "train/extr_return_rate": 0.7410230089847306, "train/extr_return_raw_mag": 8.169974054609026, "train/extr_return_raw_max": 8.169974054609026, "train/extr_return_raw_mean": 1.9157871796672505, "train/extr_return_raw_min": -0.6478873883423052, "train/extr_return_raw_std": 1.596035523522169, "train/extr_reward_mag": 1.0276279933470533, "train/extr_reward_max": 1.0276279933470533, "train/extr_reward_mean": 0.032328817643281216, "train/extr_reward_min": -0.4838663716065256, "train/extr_reward_std": 0.16960746475628444, "train/image_loss_mean": 6.007965700966971, "train/image_loss_std": 10.770321333318725, "train/model_loss_mean": 13.695693173802885, "train/model_loss_std": 14.456105877582292, "train/model_opt_grad_norm": 55.24487125425411, "train/model_opt_grad_steps": 45170.25563909775, "train/model_opt_loss": 18148.68197104088, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1325.187969924812, "train/policy_entropy_mag": 2.595633684244371, "train/policy_entropy_max": 2.595633684244371, "train/policy_entropy_mean": 0.4839641649023931, "train/policy_entropy_min": 0.07937502177586232, "train/policy_entropy_std": 0.5653363206332788, "train/policy_logprob_mag": 7.438383676055679, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4845693279477887, "train/policy_logprob_min": -7.438383676055679, "train/policy_logprob_std": 1.0642733390169932, "train/policy_randomness_mag": 0.9161447869207626, "train/policy_randomness_max": 0.9161447869207626, "train/policy_randomness_mean": 0.1708181131827204, "train/policy_randomness_min": 0.028015899324887676, "train/policy_randomness_std": 0.19953891265213042, "train/post_ent_mag": 58.308777170970025, "train/post_ent_max": 58.308777170970025, "train/post_ent_mean": 41.96683011736189, "train/post_ent_min": 19.87769385029499, "train/post_ent_std": 7.5400094627437735, "train/prior_ent_mag": 67.13585330131359, "train/prior_ent_max": 67.13585330131359, "train/prior_ent_mean": 54.77267404427206, "train/prior_ent_min": 39.79660412781221, "train/prior_ent_std": 4.145661042148905, "train/rep_loss_mean": 12.720868089145288, "train/rep_loss_std": 8.99513056045188, "train/reward_avg": 0.0285736310778928, "train/reward_loss_mean": 0.05496662453209099, "train/reward_loss_std": 0.2472292052623921, "train/reward_max_data": 1.011278198177653, "train/reward_max_pred": 1.0060993845301462, "train/reward_neg_acc": 0.9926260893506215, "train/reward_neg_loss": 0.028057531005513846, "train/reward_pos_acc": 0.9710632611934403, "train/reward_pos_loss": 0.8360029777189842, "train/reward_pred": 0.02764305741267097, "train/reward_rate": 0.033357319078947366, "train_stats/sum_log_reward": 8.13260889571646, "train_stats/max_log_achievement_collect_coal": 0.2391304347826087, "train_stats/max_log_achievement_collect_drink": 7.184782608695652, "train_stats/max_log_achievement_collect_sapling": 2.3152173913043477, "train_stats/max_log_achievement_collect_stone": 2.141304347826087, "train_stats/max_log_achievement_collect_wood": 13.01086956521739, "train_stats/max_log_achievement_defeat_skeleton": 0.021739130434782608, "train_stats/max_log_achievement_defeat_zombie": 1.173913043478261, "train_stats/max_log_achievement_eat_cow": 0.17391304347826086, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.9130434782608696, "train_stats/max_log_achievement_make_wood_sword": 0.8260869565217391, "train_stats/max_log_achievement_place_furnace": 0.05434782608695652, "train_stats/max_log_achievement_place_plant": 2.217391304347826, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.3152173913043477, "train_stats/max_log_achievement_wake_up": 1.1304347826086956, "train_stats/mean_log_entropy": 0.43692271524797316, "eval_stats/sum_log_reward": 7.787500202655792, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 7.1875, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 2.75, "eval_stats/max_log_achievement_collect_wood": 12.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.625, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0024677079636603594, "report/cont_loss_std": 0.07880724221467972, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00034239108208566904, "report/cont_pos_acc": 0.999020516872406, "report/cont_pos_loss": 0.0024739522486925125, "report/cont_pred": 0.9961703419685364, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.561824798583984, "report/dyn_loss_std": 9.045331001281738, "report/image_loss_mean": 6.239509582519531, "report/image_loss_std": 10.183382987976074, "report/model_loss_mean": 13.222175598144531, "report/model_loss_std": 13.8968505859375, "report/post_ent_mag": 60.288597106933594, "report/post_ent_max": 60.288597106933594, "report/post_ent_mean": 43.44151306152344, "report/post_ent_min": 20.49034881591797, "report/post_ent_std": 7.994112491607666, "report/prior_ent_mag": 67.71212005615234, "report/prior_ent_max": 67.71212005615234, "report/prior_ent_mean": 54.792877197265625, "report/prior_ent_min": 40.79597091674805, "report/prior_ent_std": 4.469938278198242, "report/rep_loss_mean": 11.561824798583984, "report/rep_loss_std": 9.045331001281738, "report/reward_avg": 0.03476562350988388, "report/reward_loss_mean": 0.04310355335474014, "report/reward_loss_std": 0.19377757608890533, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0070888996124268, "report/reward_neg_acc": 0.993914783000946, "report/reward_neg_loss": 0.014265392906963825, "report/reward_pos_acc": 0.9736841917037964, "report/reward_pos_loss": 0.7913779020309448, "report/reward_pred": 0.03334614634513855, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.9055437405768316e-06, "eval/cont_loss_std": 3.062255200347863e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006797522073611617, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.790337240796362e-07, "eval/cont_pred": 0.9980477690696716, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.684118270874023, "eval/dyn_loss_std": 9.870612144470215, "eval/image_loss_mean": 10.532465934753418, "eval/image_loss_std": 13.684110641479492, "eval/model_loss_mean": 20.62732696533203, "eval/model_loss_std": 17.619129180908203, "eval/post_ent_mag": 56.139366149902344, "eval/post_ent_max": 56.139366149902344, "eval/post_ent_mean": 39.644142150878906, "eval/post_ent_min": 20.876785278320312, "eval/post_ent_std": 6.518155574798584, "eval/prior_ent_mag": 67.71212005615234, "eval/prior_ent_max": 67.71212005615234, "eval/prior_ent_mean": 54.121822357177734, "eval/prior_ent_min": 42.66853332519531, "eval/prior_ent_std": 3.600956916809082, "eval/rep_loss_mean": 16.684118270874023, "eval/rep_loss_std": 9.870612144470215, "eval/reward_avg": 0.03476562350988388, "eval/reward_loss_mean": 0.08438794314861298, "eval/reward_loss_std": 0.44368916749954224, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017187595367432, "eval/reward_neg_acc": 0.9878172874450684, "eval/reward_neg_loss": 0.03481215238571167, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.3364946842193604, "eval/reward_pred": 0.02839117869734764, "eval/reward_rate": 0.0380859375, "replay/size": 735025.0, "replay/inserts": 21248.0, "replay/samples": 21248.0, "replay/insert_wait_avg": 1.3830140233039856e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.826924683099769e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5488.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0976464685823757e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4221761226654, "timer/env.step_count": 2656.0, "timer/env.step_total": 214.33617115020752, "timer/env.step_frac": 0.21424572172211323, "timer/env.step_avg": 0.08069885961980705, "timer/env.step_min": 0.022925138473510742, "timer/env.step_max": 2.1439545154571533, "timer/replay._sample_count": 21248.0, "timer/replay._sample_total": 11.017990112304688, "timer/replay._sample_frac": 0.011013340542896693, "timer/replay._sample_avg": 0.0005185424563396408, "timer/replay._sample_min": 0.0004086494445800781, "timer/replay._sample_max": 0.009721517562866211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3342.0, "timer/agent.policy_total": 54.495378255844116, "timer/agent.policy_frac": 0.054472381317107306, "timer/agent.policy_avg": 0.016306217311742702, "timer/agent.policy_min": 0.00956869125366211, "timer/agent.policy_max": 0.10052609443664551, "timer/dataset_train_count": 1328.0, "timer/dataset_train_total": 0.15507078170776367, "timer/dataset_train_frac": 0.0001550053421534209, "timer/dataset_train_avg": 0.00011677016694861722, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0004982948303222656, "timer/agent.train_count": 1328.0, "timer/agent.train_total": 588.35662317276, "timer/agent.train_frac": 0.5881083378749687, "timer/agent.train_avg": 0.4430396258831024, "timer/agent.train_min": 0.4316091537475586, "timer/agent.train_max": 1.3038744926452637, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745004177093506, "timer/agent.report_frac": 0.00047430017949859034, "timer/agent.report_avg": 0.2372502088546753, "timer/agent.report_min": 0.23047924041748047, "timer/agent.report_max": 0.24402117729187012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812152009966524e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 21.23873625268665}
{"step": 735664, "time": 36337.10792708397, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 735696, "time": 36339.82898187637, "episode/length": 361.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 736240, "time": 36361.29072833061, "episode/length": 432.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 736240, "time": 36361.33134174347, "episode/length": 196.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 736336, "time": 36368.250703811646, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 736768, "time": 36385.54182052612, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 736936, "time": 36393.06997394562, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 736992, "time": 36396.88101911545, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 737512, "time": 36418.73596405983, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 737552, "time": 36421.99204802513, "episode/length": 288.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 737592, "time": 36424.824714422226, "episode/length": 487.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9815573770491803, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 36432.13258218765, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 737864, "time": 36437.735687971115, "episode/length": 33.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 738128, "time": 36449.02592301369, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 738376, "time": 36459.54938864708, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 738472, "time": 36464.62559223175, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 738600, "time": 36470.965124845505, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 738656, "time": 36474.75853037834, "episode/length": 137.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 739016, "time": 36489.24781680107, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 739560, "time": 36510.50184583664, "episode/length": 255.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 739624, "time": 36514.31592154503, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 739736, "time": 36519.926635980606, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9900497512437811, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 36552.12263965607, "eval_episode/length": 152.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 740064, "time": 36553.90854907036, "eval_episode/length": 157.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 740064, "time": 36555.4964120388, "eval_episode/length": 160.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 740064, "time": 36558.43768239021, "eval_episode/length": 195.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 740064, "time": 36558.488468647, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 740064, "time": 36562.77135205269, "eval_episode/length": 217.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 740064, "time": 36564.5324010849, "eval_episode/length": 222.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 740064, "time": 36566.3920507431, "eval_episode/length": 77.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 740536, "time": 36583.61218428612, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 740648, "time": 36589.21748423576, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 740672, "time": 36591.84651970863, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 740704, "time": 36594.53750157356, "episode/length": 255.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 740944, "time": 36604.905107975006, "episode/length": 240.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 741448, "time": 36625.02895903587, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 741744, "time": 36637.716974020004, "episode/length": 264.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 742168, "time": 36654.48565483093, "episode/length": 203.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 742232, "time": 36658.47333073616, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 742320, "time": 36663.446120500565, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 742328, "time": 36664.98324108124, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 742488, "time": 36672.52857685089, "episode/length": 365.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 743224, "time": 36701.03857302666, "episode/length": 221.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 743240, "time": 36703.21146655083, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 743840, "time": 36726.994584560394, "episode/length": 208.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 744280, "time": 36744.35727477074, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 744336, "time": 36748.15116119385, "episode/length": 262.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 744440, "time": 36753.24036169052, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 744928, "time": 36772.82474064827, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624413145539906, "episode/intrinsic_return": 0.0}
{"step": 745024, "time": 36777.82001399994, "episode/length": 337.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 745336, "time": 36790.50127363205, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 745728, "time": 36808.35272049904, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 745800, "time": 36812.268998622894, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 746032, "time": 36822.68087339401, "episode/length": 348.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9914040114613181, "episode/intrinsic_return": 0.0}
{"step": 746560, "time": 36843.836893081665, "episode/length": 264.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 746608, "time": 36847.736211299896, "episode/length": 209.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 746728, "time": 36853.94519972801, "episode/length": 529.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9981132075471698, "episode/intrinsic_return": 0.0}
{"step": 746976, "time": 36865.30654883385, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 747056, "time": 36869.80042767525, "episode/length": 156.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 747312, "time": 36880.93379330635, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 747536, "time": 36890.563442230225, "episode/length": 225.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 748112, "time": 36913.30606675148, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 748192, "time": 36917.73840665817, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 748264, "time": 36921.65645456314, "episode/length": 206.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 748472, "time": 36930.88056921959, "episode/length": 186.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 748864, "time": 36947.060133218765, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 749128, "time": 36957.99252462387, "episode/length": 386.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9896640826873385, "episode/intrinsic_return": 0.0}
{"step": 749632, "time": 36978.38417649269, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 36995.255616903305, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 37016.458849430084, "eval_episode/length": 171.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 750048, "time": 37018.59332728386, "eval_episode/length": 185.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 750048, "time": 37020.78149199486, "eval_episode/length": 203.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 750048, "time": 37022.382994413376, "eval_episode/length": 206.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 750048, "time": 37024.09646821022, "eval_episode/length": 210.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.966824644549763}
{"step": 750048, "time": 37026.8512699604, "eval_episode/length": 238.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 750048, "time": 37029.359632492065, "eval_episode/length": 261.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9770992366412213}
{"step": 750048, "time": 37032.62284684181, "eval_episode/length": 134.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9703703703703703}
{"step": 750080, "time": 37035.31003642082, "episode/length": 345.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 750152, "time": 37039.20860671997, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 750200, "time": 37042.49777507782, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 750656, "time": 37061.0285449028, "episode/length": 307.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 751304, "time": 37086.036556720734, "episode/length": 470.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9893842887473461, "episode/intrinsic_return": 0.0}
{"step": 751312, "time": 37088.28758573532, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 751344, "time": 37090.93852376938, "episode/length": 142.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 751480, "time": 37097.214698553085, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 751528, "time": 37100.4726793766, "episode/length": 26.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 751536, "time": 37102.59682059288, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 752160, "time": 37127.01346206665, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 752224, "time": 37130.862885951996, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 752792, "time": 37153.05972695351, "episode/length": 163.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 752952, "time": 37160.43854379654, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 752992, "time": 37163.58159017563, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 753024, "time": 37166.39059519768, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 753112, "time": 37171.00210189819, "episode/length": 306.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 753208, "time": 37175.970861911774, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 753920, "time": 37205.47611737251, "episode/length": 211.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 754032, "time": 37211.223002672195, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 754560, "time": 37232.161979198456, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 754616, "time": 37235.430426836014, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 754880, "time": 37247.00597047806, "episode/length": 231.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 754928, "time": 37250.346905231476, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 755064, "time": 37256.67544770241, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 755248, "time": 37265.124671936035, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 755488, "time": 37275.63657999039, "episode/length": 52.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 755728, "time": 37285.88404250145, "episode/length": 366.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9863760217983651, "episode/intrinsic_return": 0.0}
{"step": 755800, "time": 37289.77374148369, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 756400, "time": 37313.45315885544, "episode/length": 189.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 756464, "time": 37317.3432738781, "episode/length": 230.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 756480, "time": 37319.58806157112, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 756761, "time": 37332.264766931534, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.041849925105733, "train/action_min": 0.0, "train/action_std": 3.1407872734213234, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04083748327049994, "train/actor_opt_grad_steps": 46540.0, "train/actor_opt_loss": -5.043865047129137, "train/adv_mag": 0.565847541156568, "train/adv_max": 0.5036750462718476, "train/adv_mean": 0.0033972990599567196, "train/adv_min": -0.4505566977020493, "train/adv_std": 0.05987034987350155, "train/cont_avg": 0.9946325775375939, "train/cont_loss_mean": 0.00016908895305137652, "train/cont_loss_std": 0.005117829750920156, "train/cont_neg_acc": 0.991077441609267, "train/cont_neg_loss": 0.023031404131071406, "train/cont_pos_acc": 0.9999852180480957, "train/cont_pos_loss": 4.142466809112295e-05, "train/cont_pred": 0.9946613491029668, "train/cont_rate": 0.9946325775375939, "train/dyn_loss_mean": 12.524659436448177, "train/dyn_loss_std": 9.021441000744812, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7711955913923737, "train/extr_critic_critic_opt_grad_steps": 46540.0, "train/extr_critic_critic_opt_loss": 15332.749500704887, "train/extr_critic_mag": 7.156653074393595, "train/extr_critic_max": 7.156653074393595, "train/extr_critic_mean": 2.0020020922323813, "train/extr_critic_min": -0.25867799887979837, "train/extr_critic_std": 1.6520354765698426, "train/extr_return_normed_mag": 1.6372008090628718, "train/extr_return_normed_max": 1.6372008090628718, "train/extr_return_normed_mean": 0.38421699079803956, "train/extr_return_normed_min": -0.12778829365856664, "train/extr_return_normed_std": 0.32793762338788884, "train/extr_return_rate": 0.7373571032868292, "train/extr_return_raw_mag": 8.460844380514962, "train/extr_return_raw_max": 8.460844380514962, "train/extr_return_raw_mean": 2.0194685208170036, "train/extr_return_raw_min": -0.6127600089499825, "train/extr_return_raw_std": 1.6857815084600807, "train/extr_reward_mag": 1.0351809415602147, "train/extr_reward_max": 1.0351809415602147, "train/extr_reward_mean": 0.03327728823331514, "train/extr_reward_min": -0.49168532504174944, "train/extr_reward_std": 0.17263033750810122, "train/image_loss_mean": 5.9349358243153505, "train/image_loss_std": 10.68370532989502, "train/model_loss_mean": 13.506001529837013, "train/model_loss_std": 14.370876197528123, "train/model_opt_grad_norm": 56.59566063271429, "train/model_opt_grad_steps": 46498.57142857143, "train/model_opt_loss": 13397.688557330826, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 991.5413533834586, "train/policy_entropy_mag": 2.5566102006381617, "train/policy_entropy_max": 2.5566102006381617, "train/policy_entropy_mean": 0.4780216355969135, "train/policy_entropy_min": 0.07937501992722203, "train/policy_entropy_std": 0.5522113012191945, "train/policy_logprob_mag": 7.438383611521327, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47791268278781635, "train/policy_logprob_min": -7.438383611521327, "train/policy_logprob_std": 1.060899333398145, "train/policy_randomness_mag": 0.902371208918722, "train/policy_randomness_max": 0.902371208918722, "train/policy_randomness_mean": 0.16872065833636693, "train/policy_randomness_min": 0.028015898694669392, "train/policy_randomness_std": 0.19490635719962587, "train/post_ent_mag": 59.00726843238773, "train/post_ent_max": 59.00726843238773, "train/post_ent_mean": 42.213915086330324, "train/post_ent_min": 19.846205646830395, "train/post_ent_std": 7.636374756805878, "train/prior_ent_mag": 67.12793066268577, "train/prior_ent_max": 67.12793066268577, "train/prior_ent_mean": 54.80157955427815, "train/prior_ent_min": 39.558923563562836, "train/prior_ent_std": 4.217832375289802, "train/rep_loss_mean": 12.524659436448177, "train/rep_loss_std": 9.021441000744812, "train/reward_avg": 0.02834454308354989, "train/reward_loss_mean": 0.05610103129332227, "train/reward_loss_std": 0.25219572766831044, "train/reward_max_data": 1.0157894774487144, "train/reward_max_pred": 1.0097860411593789, "train/reward_neg_acc": 0.9927827514203867, "train/reward_neg_loss": 0.029294619098641818, "train/reward_pos_acc": 0.9679573720559141, "train/reward_pos_loss": 0.8394726689596822, "train/reward_pred": 0.027781884802183264, "train/reward_rate": 0.03322515272556391, "train_stats/sum_log_reward": 8.325806619018637, "train_stats/max_log_achievement_collect_coal": 0.07526881720430108, "train_stats/max_log_achievement_collect_drink": 5.78494623655914, "train_stats/max_log_achievement_collect_sapling": 2.193548387096774, "train_stats/max_log_achievement_collect_stone": 1.956989247311828, "train_stats/max_log_achievement_collect_wood": 13.440860215053764, "train_stats/max_log_achievement_defeat_skeleton": 0.010752688172043012, "train_stats/max_log_achievement_defeat_zombie": 1.4946236559139785, "train_stats/max_log_achievement_eat_cow": 0.3118279569892473, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.3978494623655915, "train_stats/max_log_achievement_make_wood_sword": 1.086021505376344, "train_stats/max_log_achievement_place_furnace": 0.06451612903225806, "train_stats/max_log_achievement_place_plant": 2.021505376344086, "train_stats/max_log_achievement_place_stone": 0.0967741935483871, "train_stats/max_log_achievement_place_table": 3.4408602150537635, "train_stats/max_log_achievement_wake_up": 1.118279569892473, "train_stats/mean_log_entropy": 0.43987018046199633, "eval_stats/sum_log_reward": 8.350000113248825, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 2.8125, "eval_stats/max_log_achievement_collect_wood": 14.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.375, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.9375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.581942787102889e-06, "report/cont_loss_std": 3.58715005859267e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.4745733753661625e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.468993549584411e-06, "report/cont_pred": 0.994135320186615, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.672603607177734, "report/dyn_loss_std": 9.117341041564941, "report/image_loss_mean": 7.879597187042236, "report/image_loss_std": 12.942817687988281, "report/model_loss_mean": 16.14068603515625, "report/model_loss_std": 16.840557098388672, "report/post_ent_mag": 55.8343505859375, "report/post_ent_max": 55.8343505859375, "report/post_ent_mean": 41.320892333984375, "report/post_ent_min": 20.382659912109375, "report/post_ent_std": 7.375185489654541, "report/prior_ent_mag": 67.77767944335938, "report/prior_ent_max": 67.77767944335938, "report/prior_ent_mean": 55.206886291503906, "report/prior_ent_min": 38.241783142089844, "report/prior_ent_std": 3.8318400382995605, "report/rep_loss_mean": 13.672603607177734, "report/rep_loss_std": 9.117341041564941, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.05752066150307655, "report/reward_loss_std": 0.2379881739616394, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002366065979004, "report/reward_neg_acc": 0.995979905128479, "report/reward_neg_loss": 0.03444512188434601, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8492502570152283, "report/reward_pred": 0.02045951411128044, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 4.1445004171691835e-05, "eval/cont_loss_std": 0.0010005328804254532, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.903299537138082e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.1555060306563973e-05, "eval/cont_pred": 0.9911705255508423, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 15.677619934082031, "eval/dyn_loss_std": 9.760641098022461, "eval/image_loss_mean": 9.992286682128906, "eval/image_loss_std": 12.926875114440918, "eval/model_loss_mean": 19.52260398864746, "eval/model_loss_std": 16.610774993896484, "eval/post_ent_mag": 58.89186096191406, "eval/post_ent_max": 58.89186096191406, "eval/post_ent_mean": 41.313568115234375, "eval/post_ent_min": 19.555004119873047, "eval/post_ent_std": 7.532968044281006, "eval/prior_ent_mag": 67.77767944335938, "eval/prior_ent_max": 67.77767944335938, "eval/prior_ent_mean": 55.28879928588867, "eval/prior_ent_min": 42.43256378173828, "eval/prior_ent_std": 4.263020992279053, "eval/rep_loss_mean": 15.677619934082031, "eval/rep_loss_std": 9.760641098022461, "eval/reward_avg": 0.03955078125, "eval/reward_loss_mean": 0.12370306253433228, "eval/reward_loss_std": 0.6143195033073425, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.028205394744873, "eval/reward_neg_acc": 0.9877049922943115, "eval/reward_neg_loss": 0.05722428113222122, "eval/reward_pos_acc": 0.8541666865348816, "eval/reward_pos_loss": 1.4754383563995361, "eval/reward_pred": 0.035713665187358856, "eval/reward_rate": 0.046875, "replay/size": 756257.0, "replay/inserts": 21232.0, "replay/samples": 21232.0, "replay/insert_wait_avg": 1.3988338742116025e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.830577051181405e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0990852760116407e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.407499313354492e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2199592590332, "timer/env.step_count": 2654.0, "timer/env.step_total": 216.8026988506317, "timer/env.step_frac": 0.216755021576694, "timer/env.step_avg": 0.08168903498516643, "timer/env.step_min": 0.0235745906829834, "timer/env.step_max": 3.29003643989563, "timer/replay._sample_count": 21232.0, "timer/replay._sample_total": 10.987243890762329, "timer/replay._sample_frac": 0.010984827676206064, "timer/replay._sample_avg": 0.0005174851116598686, "timer/replay._sample_min": 0.00040030479431152344, "timer/replay._sample_max": 0.011156558990478516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3192.0, "timer/agent.policy_total": 53.40219831466675, "timer/agent.policy_frac": 0.05339045458983572, "timer/agent.policy_avg": 0.016730012003341715, "timer/agent.policy_min": 0.009440183639526367, "timer/agent.policy_max": 0.11668157577514648, "timer/dataset_train_count": 1327.0, "timer/dataset_train_total": 0.15502715110778809, "timer/dataset_train_frac": 0.00015499305894938628, "timer/dataset_train_avg": 0.00011682528342711989, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.0004980564117431641, "timer/agent.train_count": 1327.0, "timer/agent.train_total": 590.4124662876129, "timer/agent.train_frac": 0.5902826281581031, "timer/agent.train_avg": 0.4449227326960158, "timer/agent.train_min": 0.42970752716064453, "timer/agent.train_max": 1.3872549533843994, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751014709472656, "timer/agent.report_frac": 0.00047499699096109084, "timer/agent.report_avg": 0.2375507354736328, "timer/agent.report_min": 0.22881388664245605, "timer/agent.report_max": 0.24628758430480957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.669700860514381e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 21.227032763681365}
{"step": 756800, "time": 37333.73779654503, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 756872, "time": 37337.67311882973, "episode/length": 172.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 757024, "time": 37344.9503030777, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 757024, "time": 37344.98855423927, "episode/length": 67.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 757832, "time": 37377.54764890671, "episode/length": 170.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 757872, "time": 37380.73360490799, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 757952, "time": 37385.0658018589, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 757984, "time": 37387.91366624832, "episode/length": 281.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 758432, "time": 37405.66793560982, "episode/length": 203.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 758504, "time": 37409.48648548126, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 758544, "time": 37412.74792098999, "episode/length": 189.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 758888, "time": 37426.6461687088, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 759168, "time": 37438.66300988197, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 759304, "time": 37444.98242497444, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 759352, "time": 37448.44667363167, "episode/length": 170.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 759384, "time": 37451.141838788986, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 759824, "time": 37469.03478527069, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 759896, "time": 37473.41129684448, "episode/length": 182.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 759920, "time": 37476.597893476486, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 37501.22299814224, "eval_episode/length": 148.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 760032, "time": 37504.11041402817, "eval_episode/length": 183.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 760032, "time": 37506.397607564926, "eval_episode/length": 196.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 760032, "time": 37509.26126194, "eval_episode/length": 229.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 760032, "time": 37512.138264894485, "eval_episode/length": 266.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 760032, "time": 37513.93968319893, "eval_episode/length": 272.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9963369963369964}
{"step": 760032, "time": 37516.79045724869, "eval_episode/length": 305.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9869281045751634}
{"step": 760032, "time": 37519.9258916378, "eval_episode/length": 39.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9}
{"step": 760248, "time": 37527.53786587715, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 760912, "time": 37553.43216633797, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 760976, "time": 37557.23026871681, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 761128, "time": 37564.09973907471, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 761464, "time": 37577.970782756805, "episode/length": 286.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 761560, "time": 37582.978461265564, "episode/length": 216.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 761800, "time": 37593.222405433655, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 761808, "time": 37595.33483195305, "episode/length": 42.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 761840, "time": 37598.12106657028, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 762208, "time": 37614.61662173271, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 762208, "time": 37614.66364812851, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 762264, "time": 37619.750049352646, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 762952, "time": 37646.36413741112, "episode/length": 173.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 763040, "time": 37651.341593027115, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 763600, "time": 37673.39875507355, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 763760, "time": 37680.72184729576, "episode/length": 239.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 764256, "time": 37700.6038954258, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 764376, "time": 37706.35816550255, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 764440, "time": 37710.15257406235, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 764472, "time": 37712.867460250854, "episode/length": 282.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 764856, "time": 37728.53705954552, "episode/length": 465.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9892703862660944, "episode/intrinsic_return": 0.0}
{"step": 765016, "time": 37736.04357337952, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 765344, "time": 37749.950276613235, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 765912, "time": 37772.03436756134, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 765944, "time": 37774.75813913345, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 766000, "time": 37778.733021736145, "episode/length": 194.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 766040, "time": 37781.61361646652, "episode/length": 284.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 766136, "time": 37786.58148479462, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 766624, "time": 37806.19531869888, "episode/length": 220.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 766768, "time": 37813.13136768341, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 767368, "time": 37836.45447778702, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 767536, "time": 37844.453107357025, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 767696, "time": 37851.785839796066, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 768296, "time": 37875.08091330528, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 768848, "time": 37896.88376951218, "episode/length": 184.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 768920, "time": 37900.92428064346, "episode/length": 286.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 769000, "time": 37905.33508825302, "episode/length": 278.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 769144, "time": 37912.06928753853, "episode/length": 399.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 769328, "time": 37920.53413128853, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 769368, "time": 37923.33051323891, "episode/length": 431.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 769472, "time": 37928.918469429016, "episode/length": 221.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 769816, "time": 37942.72074484825, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 37970.981271505356, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 770016, "time": 37973.70082235336, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 770016, "time": 37975.30134654045, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 770016, "time": 37977.58845734596, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 770016, "time": 37979.291053295135, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 770016, "time": 37980.90446186066, "eval_episode/length": 216.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 770016, "time": 37983.82059764862, "eval_episode/length": 251.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 770016, "time": 37989.62794137001, "eval_episode/length": 329.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 770656, "time": 38015.16496992111, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 771048, "time": 38031.02250623703, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 771160, "time": 38036.66060709953, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 771400, "time": 38047.099811553955, "episode/length": 309.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 771424, "time": 38049.78884649277, "episode/length": 261.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 771824, "time": 38065.838601350784, "episode/length": 334.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 771904, "time": 38070.27039527893, "episode/length": 260.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 772024, "time": 38075.95261025429, "episode/length": 396.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 772432, "time": 38092.83832907677, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 772608, "time": 38100.799402952194, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 772816, "time": 38110.05473470688, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 772968, "time": 38117.001105070114, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 772992, "time": 38119.575749874115, "episode/length": 242.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 773184, "time": 38127.939123392105, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 773640, "time": 38145.94941878319, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 774272, "time": 38170.95602655411, "episode/length": 280.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9715302491103203, "episode/intrinsic_return": 0.0}
{"step": 774280, "time": 38172.65925073624, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 774360, "time": 38177.1587934494, "episode/length": 218.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 774424, "time": 38181.06732773781, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 774464, "time": 38184.255187511444, "episode/length": 183.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 774928, "time": 38202.719549655914, "episode/length": 263.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 775272, "time": 38216.66999197006, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 775400, "time": 38222.85054564476, "episode/length": 139.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 775480, "time": 38227.51847600937, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 775680, "time": 38236.5408103466, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 776232, "time": 38258.14288878441, "episode/length": 323.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 776384, "time": 38265.48884296417, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 776536, "time": 38272.39911723137, "episode/length": 200.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 776616, "time": 38276.87430548668, "episode/length": 273.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 777024, "time": 38293.61790704727, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 777360, "time": 38307.41715455055, "episode/length": 260.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 777592, "time": 38317.18740725517, "episode/length": 263.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 777945, "time": 38332.72683787346, "train_stats/sum_log_reward": 8.2397851456878, "train_stats/max_log_achievement_collect_coal": 0.21505376344086022, "train_stats/max_log_achievement_collect_drink": 4.473118279569892, "train_stats/max_log_achievement_collect_sapling": 1.89247311827957, "train_stats/max_log_achievement_collect_stone": 2.78494623655914, "train_stats/max_log_achievement_collect_wood": 13.56989247311828, "train_stats/max_log_achievement_defeat_skeleton": 0.021505376344086023, "train_stats/max_log_achievement_defeat_zombie": 1.3225806451612903, "train_stats/max_log_achievement_eat_cow": 0.24731182795698925, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.3225806451612905, "train_stats/max_log_achievement_make_wood_sword": 1.064516129032258, "train_stats/max_log_achievement_place_furnace": 0.08602150537634409, "train_stats/max_log_achievement_place_plant": 1.8602150537634408, "train_stats/max_log_achievement_place_stone": 0.11827956989247312, "train_stats/max_log_achievement_place_table": 3.3978494623655915, "train_stats/max_log_achievement_wake_up": 1.032258064516129, "train_stats/mean_log_entropy": 0.43880803338302077, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.120525013316762, "train/action_min": 0.0, "train/action_std": 3.0056224302812056, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.040896462318910795, "train/actor_opt_grad_steps": 47865.0, "train/actor_opt_loss": -2.306846575077736, "train/adv_mag": 0.554726685086886, "train/adv_max": 0.5056164962324229, "train/adv_mean": 0.003918040568488791, "train/adv_min": -0.4553893667956193, "train/adv_std": 0.06039170009281599, "train/cont_avg": 0.9948804450757576, "train/cont_loss_mean": 0.00017505644788436936, "train/cont_loss_std": 0.0052070988305095425, "train/cont_neg_acc": 0.9886190158720235, "train/cont_neg_loss": 0.027521174109048446, "train/cont_pos_acc": 0.9999776943163439, "train/cont_pos_loss": 5.296813802012399e-05, "train/cont_pred": 0.9948982510602835, "train/cont_rate": 0.9948804450757576, "train/dyn_loss_mean": 12.42108381878246, "train/dyn_loss_std": 9.04303299296986, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.847367285553253, "train/extr_critic_critic_opt_grad_steps": 47865.0, "train/extr_critic_critic_opt_loss": 15612.986779415247, "train/extr_critic_mag": 7.265583041942481, "train/extr_critic_max": 7.265583041942481, "train/extr_critic_mean": 2.0742824059544187, "train/extr_critic_min": -0.255666148481947, "train/extr_critic_std": 1.6399532150138507, "train/extr_return_normed_mag": 1.6204144990805425, "train/extr_return_normed_max": 1.6204144990805425, "train/extr_return_normed_mean": 0.3931086505904342, "train/extr_return_normed_min": -0.1299968883677414, "train/extr_return_normed_std": 0.3231616214369283, "train/extr_return_rate": 0.7742508505329941, "train/extr_return_raw_mag": 8.4581695542191, "train/extr_return_raw_max": 8.4581695542191, "train/extr_return_raw_mean": 2.094615051240632, "train/extr_return_raw_min": -0.6189399774778973, "train/extr_return_raw_std": 1.6759709760998234, "train/extr_reward_mag": 1.0337128115422798, "train/extr_reward_max": 1.0337128115422798, "train/extr_reward_mean": 0.03371733844731793, "train/extr_reward_min": -0.47789063688480493, "train/extr_reward_std": 0.1733379437390602, "train/image_loss_mean": 5.871913008617632, "train/image_loss_std": 10.809826691945394, "train/model_loss_mean": 13.379693016861424, "train/model_loss_std": 14.527456984375462, "train/model_opt_grad_norm": 54.44806223204642, "train/model_opt_grad_steps": 47823.0, "train/model_opt_loss": 14128.122865619081, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1065.340909090909, "train/policy_entropy_mag": 2.5729331717346655, "train/policy_entropy_max": 2.5729331717346655, "train/policy_entropy_mean": 0.48640495064583694, "train/policy_entropy_min": 0.07937501788590894, "train/policy_entropy_std": 0.5848181518641385, "train/policy_logprob_mag": 7.438383702075843, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4861594242128459, "train/policy_logprob_min": -7.438383702075843, "train/policy_logprob_std": 1.0718055164272136, "train/policy_randomness_mag": 0.9081324998176459, "train/policy_randomness_max": 0.9081324998176459, "train/policy_randomness_mean": 0.1716796030487978, "train/policy_randomness_min": 0.028015898032621903, "train/policy_randomness_std": 0.20641514354131438, "train/post_ent_mag": 58.86777516567346, "train/post_ent_max": 58.86777516567346, "train/post_ent_mean": 42.40968403671727, "train/post_ent_min": 19.997310465032403, "train/post_ent_std": 7.6518305756829, "train/prior_ent_mag": 67.16426450555974, "train/prior_ent_max": 67.16426450555974, "train/prior_ent_mean": 54.88472259405887, "train/prior_ent_min": 39.63366343758323, "train/prior_ent_std": 4.218811620365489, "train/rep_loss_mean": 12.42108381878246, "train/rep_loss_std": 9.04303299296986, "train/reward_avg": 0.028005149067294868, "train/reward_loss_mean": 0.0549547698235873, "train/reward_loss_std": 0.252155717800964, "train/reward_max_data": 1.0196969743930933, "train/reward_max_pred": 1.010617806152864, "train/reward_neg_acc": 0.9926250387321819, "train/reward_neg_loss": 0.02853461180700723, "train/reward_pos_acc": 0.9686536748300899, "train/reward_pos_loss": 0.8459322646711812, "train/reward_pred": 0.027302183090906703, "train/reward_rate": 0.03252249053030303, "eval_stats/sum_log_reward": 8.037500187754631, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 2.0, "eval_stats/max_log_achievement_collect_wood": 13.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.625, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.1875, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.08333333333333333, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.430506578501081e-06, "report/cont_loss_std": 8.161709411069751e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023021553352009505, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.322631073388038e-06, "report/cont_pred": 0.9951150417327881, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.763578414916992, "report/dyn_loss_std": 9.425065040588379, "report/image_loss_mean": 7.922784328460693, "report/image_loss_std": 11.65468692779541, "report/model_loss_mean": 16.228239059448242, "report/model_loss_std": 15.800614356994629, "report/post_ent_mag": 60.742000579833984, "report/post_ent_max": 60.742000579833984, "report/post_ent_mean": 41.44391632080078, "report/post_ent_min": 20.698780059814453, "report/post_ent_std": 7.7117133140563965, "report/prior_ent_mag": 66.66998291015625, "report/prior_ent_max": 66.66998291015625, "report/prior_ent_mean": 55.368587493896484, "report/prior_ent_min": 40.268306732177734, "report/prior_ent_std": 4.301867961883545, "report/rep_loss_mean": 13.763578414916992, "report/rep_loss_std": 9.425065040588379, "report/reward_avg": 0.01826171763241291, "report/reward_loss_mean": 0.0473024919629097, "report/reward_loss_std": 0.20414650440216064, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005791187286377, "report/reward_neg_acc": 0.9960039854049683, "report/reward_neg_loss": 0.02618313580751419, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.966453492641449, "report/reward_pred": 0.01621546596288681, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.1310365809767973e-06, "eval/cont_loss_std": 3.015025686181616e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00030892426730133593, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.256724418562953e-07, "eval/cont_pred": 0.9951181411743164, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.049606323242188, "eval/dyn_loss_std": 10.763169288635254, "eval/image_loss_mean": 9.181303024291992, "eval/image_loss_std": 16.98746109008789, "eval/model_loss_mean": 18.29397964477539, "eval/model_loss_std": 20.983463287353516, "eval/post_ent_mag": 59.29826354980469, "eval/post_ent_max": 59.29826354980469, "eval/post_ent_mean": 42.23185729980469, "eval/post_ent_min": 18.464298248291016, "eval/post_ent_std": 7.904606819152832, "eval/prior_ent_mag": 66.66998291015625, "eval/prior_ent_max": 66.66998291015625, "eval/prior_ent_mean": 54.9907341003418, "eval/prior_ent_min": 38.70439529418945, "eval/prior_ent_std": 4.598273754119873, "eval/rep_loss_mean": 15.049606323242188, "eval/rep_loss_std": 10.763169288635254, "eval/reward_avg": 0.03437500074505806, "eval/reward_loss_mean": 0.0829126387834549, "eval/reward_loss_std": 0.46515417098999023, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005638599395752, "eval/reward_neg_acc": 0.9857578873634338, "eval/reward_neg_loss": 0.03439962863922119, "eval/reward_pos_acc": 0.8780487775802612, "eval/reward_pos_loss": 1.2460416555404663, "eval/reward_pred": 0.032852232456207275, "eval/reward_rate": 0.0400390625, "replay/size": 777441.0, "replay/inserts": 21184.0, "replay/samples": 21184.0, "replay/insert_wait_avg": 1.4092289248982224e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.841229618856194e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1317828703208788e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4442994594574, "timer/env.step_count": 2648.0, "timer/env.step_total": 214.98622465133667, "timer/env.step_frac": 0.21489074880779896, "timer/env.step_avg": 0.08118815130337488, "timer/env.step_min": 0.02342081069946289, "timer/env.step_max": 3.3094053268432617, "timer/replay._sample_count": 21184.0, "timer/replay._sample_total": 11.031307220458984, "timer/replay._sample_frac": 0.011026408193258962, "timer/replay._sample_avg": 0.0005207376897875276, "timer/replay._sample_min": 0.0004220008850097656, "timer/replay._sample_max": 0.007238626480102539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3324.0, "timer/agent.policy_total": 54.003596782684326, "timer/agent.policy_frac": 0.05397961366950924, "timer/agent.policy_avg": 0.01624656942920708, "timer/agent.policy_min": 0.009582996368408203, "timer/agent.policy_max": 0.09607195854187012, "timer/dataset_train_count": 1324.0, "timer/dataset_train_total": 0.15495634078979492, "timer/dataset_train_frac": 0.0001548875243464511, "timer/dataset_train_avg": 0.00011703651117053997, "timer/dataset_train_min": 0.00010538101196289062, "timer/dataset_train_max": 0.0008614063262939453, "timer/agent.train_count": 1324.0, "timer/agent.train_total": 588.0061452388763, "timer/agent.train_frac": 0.5877450104484353, "timer/agent.train_avg": 0.444113402748396, "timer/agent.train_min": 0.43430447578430176, "timer/agent.train_max": 1.3152437210083008, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47444748878479004, "timer/agent.report_frac": 0.0004742367856372766, "timer/agent.report_avg": 0.23722374439239502, "timer/agent.report_min": 0.23041415214538574, "timer/agent.report_max": 0.2440333366394043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.526114587130973e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 21.17429283056857}
{"step": 778088, "time": 38337.854021310806, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 778216, "time": 38344.166741132736, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 778392, "time": 38353.97529530525, "episode/length": 269.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 778688, "time": 38366.63673686981, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 779104, "time": 38383.46956419945, "episode/length": 310.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 779208, "time": 38388.62033390999, "episode/length": 201.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 779480, "time": 38400.15646290779, "episode/length": 306.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.0}
{"step": 779968, "time": 38419.94094848633, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 38437.50241851807, "eval_episode/length": 48.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 780000, "time": 38441.86729025841, "eval_episode/length": 82.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.927710843373494}
{"step": 780000, "time": 38447.53889513016, "eval_episode/length": 178.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9553072625698324}
{"step": 780000, "time": 38449.13616371155, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 780000, "time": 38450.80609679222, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 780000, "time": 38453.35274076462, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 780000, "time": 38455.10202431679, "eval_episode/length": 164.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 780000, "time": 38458.642553567886, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 780264, "time": 38468.122045993805, "episode/length": 362.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9862258953168044, "episode/intrinsic_return": 0.0}
{"step": 780424, "time": 38475.514852523804, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 780784, "time": 38490.53346204758, "episode/length": 196.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 780816, "time": 38493.25393366814, "episode/length": 213.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 781088, "time": 38504.86802339554, "episode/length": 336.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9792284866468842, "episode/intrinsic_return": 0.0}
{"step": 781120, "time": 38507.590401887894, "episode/length": 204.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 781360, "time": 38518.137738227844, "episode/length": 408.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828850855745721, "episode/intrinsic_return": 0.0}
{"step": 781672, "time": 38531.3725631237, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624413145539906, "episode/intrinsic_return": 0.0}
{"step": 782112, "time": 38549.05334162712, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 782752, "time": 38574.148948431015, "episode/length": 290.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 782776, "time": 38576.42049074173, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 782840, "time": 38580.20617747307, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 783152, "time": 38593.363939762115, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 783184, "time": 38596.14690446854, "episode/length": 299.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 783208, "time": 38598.32680559158, "episode/length": 264.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 784264, "time": 38638.34378838539, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 784280, "time": 38640.51913309097, "episode/length": 364.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 784496, "time": 38650.385519981384, "episode/length": 297.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 784528, "time": 38653.10240936279, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 784728, "time": 38661.800629377365, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 785136, "time": 38678.64011454582, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 785152, "time": 38680.79555726051, "episode/length": 245.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 785376, "time": 38690.475643873215, "episode/length": 27.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 785592, "time": 38699.7978720665, "episode/length": 165.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 785648, "time": 38703.56891584396, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 785720, "time": 38707.64032435417, "episode/length": 179.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 786208, "time": 38727.26735472679, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.985981308411215, "episode/intrinsic_return": 0.0}
{"step": 786464, "time": 38739.919461250305, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 786600, "time": 38746.127228975296, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 787016, "time": 38762.7761721611, "episode/length": 285.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 787096, "time": 38767.239341020584, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 787104, "time": 38769.26990032196, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 787472, "time": 38784.28678441048, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 787488, "time": 38786.39166212082, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 788424, "time": 38821.94503283501, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 788560, "time": 38828.86928153038, "episode/length": 293.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 788568, "time": 38830.417930841446, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 788584, "time": 38832.55857181549, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 788784, "time": 38841.602069854736, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 788872, "time": 38846.16741037369, "episode/length": 402.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826302729528535, "episode/intrinsic_return": 0.0}
{"step": 788920, "time": 38849.52372932434, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 789624, "time": 38876.667457818985, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 789824, "time": 38885.776242256165, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 789888, "time": 38889.834193468094, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 38912.81591129303, "eval_episode/length": 38.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 790088, "time": 38918.90389442444, "eval_episode/length": 150.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 790088, "time": 38921.93139410019, "eval_episode/length": 185.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 790088, "time": 38925.21937394142, "eval_episode/length": 227.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 790088, "time": 38927.07639789581, "eval_episode/length": 236.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 790088, "time": 38928.88577747345, "eval_episode/length": 240.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.970954356846473}
{"step": 790088, "time": 38930.76329231262, "eval_episode/length": 251.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.996031746031746}
{"step": 790088, "time": 38932.69295787811, "eval_episode/length": 220.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 790096, "time": 38933.22352838516, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 790224, "time": 38939.5648932457, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 790264, "time": 38942.33511304855, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 790296, "time": 38945.06861066818, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 790360, "time": 38949.07696008682, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 791232, "time": 38982.730130434036, "episode/length": 141.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 791632, "time": 38998.947095155716, "episode/length": 225.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 791680, "time": 39002.340213537216, "episode/length": 256.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9688715953307393, "episode/intrinsic_return": 0.0}
{"step": 791768, "time": 39006.944647312164, "episode/length": 234.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 791808, "time": 39010.215005636215, "episode/length": 188.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 791920, "time": 39015.829318761826, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 791952, "time": 39018.50880384445, "episode/length": 39.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 792496, "time": 39039.86637878418, "episode/length": 278.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 792632, "time": 39046.1777908802, "episode/length": 283.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 792896, "time": 39057.59571647644, "episode/length": 207.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 793400, "time": 39077.49242854118, "episode/length": 198.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 793544, "time": 39084.22442507744, "episode/length": 221.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 793656, "time": 39089.95745706558, "episode/length": 246.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 793752, "time": 39095.032076358795, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 793848, "time": 39100.35466694832, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 794008, "time": 39107.876547813416, "episode/length": 260.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 794048, "time": 39111.257759571075, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 795208, "time": 39156.88290309906, "episode/length": 288.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 795272, "time": 39160.805653095245, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 795304, "time": 39163.57665467262, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 795432, "time": 39169.83235549927, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 795512, "time": 39174.34144306183, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 795584, "time": 39178.843718767166, "episode/length": 46.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 795624, "time": 39181.63350343704, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 795672, "time": 39184.99601006508, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 795680, "time": 39187.19113898277, "episode/length": 228.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 796832, "time": 39231.95736527443, "episode/length": 150.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 796856, "time": 39234.196422576904, "episode/length": 167.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 796880, "time": 39236.79658961296, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 796936, "time": 39240.15621423721, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 796976, "time": 39243.40930581093, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 796976, "time": 39243.461428403854, "episode/length": 208.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 797152, "time": 39253.686826467514, "episode/length": 184.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 797872, "time": 39282.94560289383, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 798248, "time": 39299.11123633385, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 798544, "time": 39312.450906038284, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 798640, "time": 39318.01714515686, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 798736, "time": 39323.46568989754, "episode/length": 234.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 798921, "time": 39333.234006643295, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.62384033203125, "train/action_min": 0.0, "train/action_std": 3.4586492221774034, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037988554842713226, "train/actor_opt_grad_steps": 49180.0, "train/actor_opt_loss": -3.6289440097415264, "train/adv_mag": 0.5350876159340371, "train/adv_max": 0.47671245027134435, "train/adv_mean": 0.00325654231227147, "train/adv_min": -0.4174944114594059, "train/adv_std": 0.055676619344540226, "train/cont_avg": 0.9951097328244275, "train/cont_loss_mean": 0.0001865121526204091, "train/cont_loss_std": 0.005684541235860491, "train/cont_neg_acc": 0.9961832065618675, "train/cont_neg_loss": 0.021870130476856906, "train/cont_pos_acc": 0.9999550489978936, "train/cont_pos_loss": 7.366056337804225e-05, "train/cont_pred": 0.9950940349629818, "train/cont_rate": 0.9951097328244275, "train/dyn_loss_mean": 12.494491642668047, "train/dyn_loss_std": 9.099120584153036, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8561047351997317, "train/extr_critic_critic_opt_grad_steps": 49180.0, "train/extr_critic_critic_opt_loss": 15497.933787571565, "train/extr_critic_mag": 7.748072041810014, "train/extr_critic_max": 7.748072041810014, "train/extr_critic_mean": 2.2152921106979138, "train/extr_critic_min": -0.2538745985686324, "train/extr_critic_std": 1.7789468355761229, "train/extr_return_normed_mag": 1.5748464951988395, "train/extr_return_normed_max": 1.5748464951988395, "train/extr_return_normed_mean": 0.38904293836983106, "train/extr_return_normed_min": -0.1082244299864041, "train/extr_return_normed_std": 0.3228756182521354, "train/extr_return_rate": 0.7862953634662483, "train/extr_return_raw_mag": 8.89978517648828, "train/extr_return_raw_max": 8.89978517648828, "train/extr_return_raw_mean": 2.2335849882082175, "train/extr_return_raw_min": -0.5611713186247658, "train/extr_return_raw_std": 1.8151753831455726, "train/extr_reward_mag": 1.0374045918006023, "train/extr_reward_max": 1.0374045918006023, "train/extr_reward_mean": 0.03469178089089976, "train/extr_reward_min": -0.45270809326463074, "train/extr_reward_std": 0.17577209556830747, "train/image_loss_mean": 6.048833271929326, "train/image_loss_std": 11.033340195663103, "train/model_loss_mean": 13.599101729065408, "train/model_loss_std": 14.803219220110478, "train/model_opt_grad_norm": 54.22587474793878, "train/model_opt_grad_steps": 49136.916030534354, "train/model_opt_loss": 17403.713315541507, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1278.6259541984732, "train/policy_entropy_mag": 2.5802341362902226, "train/policy_entropy_max": 2.5802341362902226, "train/policy_entropy_mean": 0.49665632206975047, "train/policy_entropy_min": 0.07937501757654525, "train/policy_entropy_std": 0.561956919331587, "train/policy_logprob_mag": 7.438383659333673, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4963707259593119, "train/policy_logprob_min": -7.438383659333673, "train/policy_logprob_std": 1.0745767855462227, "train/policy_randomness_mag": 0.9107094175032987, "train/policy_randomness_max": 0.9107094175032987, "train/policy_randomness_mean": 0.17529788704318855, "train/policy_randomness_min": 0.028015897886557433, "train/policy_randomness_std": 0.19834613367801404, "train/post_ent_mag": 58.87565516697541, "train/post_ent_max": 58.87565516697541, "train/post_ent_mean": 42.417873207849404, "train/post_ent_min": 19.84169150490797, "train/post_ent_std": 7.657988038681846, "train/prior_ent_mag": 67.13695788201485, "train/prior_ent_max": 67.13695788201485, "train/prior_ent_mean": 54.962924491358166, "train/prior_ent_min": 40.21351664302913, "train/prior_ent_std": 4.191562408709344, "train/rep_loss_mean": 12.494491642668047, "train/rep_loss_std": 9.099120584153036, "train/reward_avg": 0.027810412416419454, "train/reward_loss_mean": 0.053387039234392517, "train/reward_loss_std": 0.2408117728151438, "train/reward_max_data": 1.011450384409373, "train/reward_max_pred": 1.0071764993303605, "train/reward_neg_acc": 0.9928057767052687, "train/reward_neg_loss": 0.02800131373761492, "train/reward_pos_acc": 0.9729041297927158, "train/reward_pos_loss": 0.8170376888668264, "train/reward_pred": 0.027333252295453584, "train/reward_rate": 0.0322265625, "train_stats/sum_log_reward": 8.552631789759586, "train_stats/max_log_achievement_collect_coal": 0.21052631578947367, "train_stats/max_log_achievement_collect_drink": 5.91578947368421, "train_stats/max_log_achievement_collect_sapling": 2.031578947368421, "train_stats/max_log_achievement_collect_stone": 2.778947368421053, "train_stats/max_log_achievement_collect_wood": 11.989473684210527, "train_stats/max_log_achievement_defeat_skeleton": 0.042105263157894736, "train_stats/max_log_achievement_defeat_zombie": 1.6736842105263159, "train_stats/max_log_achievement_eat_cow": 0.21052631578947367, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.1473684210526316, "train_stats/max_log_achievement_make_wood_sword": 1.1789473684210525, "train_stats/max_log_achievement_place_furnace": 0.10526315789473684, "train_stats/max_log_achievement_place_plant": 1.8842105263157896, "train_stats/max_log_achievement_place_stone": 0.12631578947368421, "train_stats/max_log_achievement_place_table": 3.0526315789473686, "train_stats/max_log_achievement_wake_up": 1.0315789473684212, "train_stats/mean_log_entropy": 0.4852168790603939, "eval_stats/sum_log_reward": 7.287500245496631, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 2.4375, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 1.8125, "eval_stats/max_log_achievement_collect_wood": 9.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.375, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.6455072909593582e-05, "report/cont_loss_std": 0.0004819031455554068, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00012987654190510511, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5786576113896444e-05, "report/cont_pred": 0.9941258430480957, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.666831016540527, "report/dyn_loss_std": 9.107429504394531, "report/image_loss_mean": 5.911579132080078, "report/image_loss_std": 10.815210342407227, "report/model_loss_mean": 14.180341720581055, "report/model_loss_std": 14.103117942810059, "report/post_ent_mag": 60.12629699707031, "report/post_ent_max": 60.12629699707031, "report/post_ent_mean": 42.13706970214844, "report/post_ent_min": 19.381458282470703, "report/post_ent_std": 8.160918235778809, "report/prior_ent_mag": 67.45654296875, "report/prior_ent_max": 67.45654296875, "report/prior_ent_mean": 55.719154357910156, "report/prior_ent_min": 41.60517883300781, "report/prior_ent_std": 3.8680591583251953, "report/rep_loss_mean": 13.666831016540527, "report/rep_loss_std": 9.107429504394531, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.06864859163761139, "report/reward_loss_std": 0.47525301575660706, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034990310668945, "report/reward_neg_acc": 0.9889335632324219, "report/reward_neg_loss": 0.03684927895665169, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.1222656965255737, "report/reward_pred": 0.021389078348875046, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.265439201844856e-05, "eval/cont_loss_std": 0.0010254649678245187, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0021968905348330736, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.2084051781566814e-05, "eval/cont_pred": 0.9950965046882629, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.983659744262695, "eval/dyn_loss_std": 10.13671588897705, "eval/image_loss_mean": 7.3802690505981445, "eval/image_loss_std": 11.021679878234863, "eval/model_loss_mean": 17.06039810180664, "eval/model_loss_std": 14.630576133728027, "eval/post_ent_mag": 59.339134216308594, "eval/post_ent_max": 59.339134216308594, "eval/post_ent_mean": 41.82837677001953, "eval/post_ent_min": 18.94367218017578, "eval/post_ent_std": 7.673797130584717, "eval/prior_ent_mag": 67.45654296875, "eval/prior_ent_max": 67.45654296875, "eval/prior_ent_mean": 55.65378952026367, "eval/prior_ent_min": 42.08509826660156, "eval/prior_ent_std": 4.222568988800049, "eval/rep_loss_mean": 15.983659744262695, "eval/rep_loss_std": 10.13671588897705, "eval/reward_avg": 0.03203124925494194, "eval/reward_loss_mean": 0.08989384025335312, "eval/reward_loss_std": 0.4950869679450989, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002366542816162, "eval/reward_neg_acc": 0.9868153929710388, "eval/reward_neg_loss": 0.0348082073032856, "eval/reward_pos_acc": 0.8684210777282715, "eval/reward_pos_loss": 1.5192210674285889, "eval/reward_pred": 0.025801997631788254, "eval/reward_rate": 0.037109375, "replay/size": 798417.0, "replay/inserts": 20976.0, "replay/samples": 20976.0, "replay/insert_wait_avg": 1.388513159879194e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.014005890881897e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.110079634280605e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4952409267426, "timer/env.step_count": 2622.0, "timer/env.step_total": 223.59395551681519, "timer/env.step_frac": 0.2234832774513787, "timer/env.step_avg": 0.0852761081299829, "timer/env.step_min": 0.023303747177124023, "timer/env.step_max": 3.631387948989868, "timer/replay._sample_count": 20976.0, "timer/replay._sample_total": 10.902395725250244, "timer/replay._sample_frac": 0.010896999085324516, "timer/replay._sample_avg": 0.0005197557077255074, "timer/replay._sample_min": 0.0004208087921142578, "timer/replay._sample_max": 0.011526107788085938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3146.0, "timer/agent.policy_total": 52.92799663543701, "timer/agent.policy_frac": 0.05290179750021666, "timer/agent.policy_avg": 0.01682390229988462, "timer/agent.policy_min": 0.009451150894165039, "timer/agent.policy_max": 0.11355113983154297, "timer/dataset_train_count": 1311.0, "timer/dataset_train_total": 0.15504908561706543, "timer/dataset_train_frac": 0.0001549723369732833, "timer/dataset_train_avg": 0.00011826779986046181, "timer/dataset_train_min": 0.00010514259338378906, "timer/dataset_train_max": 0.0006616115570068359, "timer/agent.train_count": 1311.0, "timer/agent.train_total": 584.5521507263184, "timer/agent.train_frac": 0.5842627998758466, "timer/agent.train_avg": 0.4458826473884961, "timer/agent.train_min": 0.43251490592956543, "timer/agent.train_max": 1.3940377235412598, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751107692718506, "timer/agent.report_frac": 0.0004748755914438565, "timer/agent.report_avg": 0.2375553846359253, "timer/agent.report_min": 0.2310652732849121, "timer/agent.report_max": 0.24404549598693848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026417148956285e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 20.96531327877335}
{"step": 799288, "time": 39346.536172151566, "episode/length": 288.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 799504, "time": 39356.29432463646, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 799848, "time": 39370.23081088066, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 39398.63863444328, "eval_episode/length": 154.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 800072, "time": 39400.21346783638, "eval_episode/length": 155.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 800072, "time": 39402.167442560196, "eval_episode/length": 164.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 800072, "time": 39403.84619092941, "eval_episode/length": 168.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 800072, "time": 39407.9060189724, "eval_episode/length": 233.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 800072, "time": 39410.372769117355, "eval_episode/length": 257.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 800072, "time": 39417.101408958435, "eval_episode/length": 232.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 800072, "time": 39418.7945895195, "eval_episode/length": 234.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 800096, "time": 39419.9137609005, "episode/length": 230.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 800200, "time": 39425.058065891266, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 800408, "time": 39434.371721982956, "episode/length": 232.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 800680, "time": 39445.84039759636, "episode/length": 480.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9812889812889813, "episode/intrinsic_return": 0.0}
{"step": 800696, "time": 39447.991869688034, "episode/length": 256.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 801016, "time": 39461.29862856865, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 801128, "time": 39466.95491671562, "episode/length": 55.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 801336, "time": 39476.13542890549, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 801584, "time": 39487.104348897934, "episode/length": 56.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 801720, "time": 39493.44182562828, "episode/length": 233.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 802120, "time": 39509.651978969574, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 802128, "time": 39511.64433169365, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 802384, "time": 39522.658194065094, "episode/length": 386.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974160206718347, "episode/intrinsic_return": 0.0}
{"step": 802912, "time": 39545.12261843681, "episode/length": 236.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 803488, "time": 39567.93698525429, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 803488, "time": 39567.98125767708, "episode/length": 169.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 803632, "time": 39576.86245846748, "episode/length": 188.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 803840, "time": 39586.00661826134, "episode/length": 467.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 804064, "time": 39595.64218211174, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 804472, "time": 39611.873965501785, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.958974358974359, "episode/intrinsic_return": 0.0}
{"step": 804752, "time": 39623.85810995102, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 804816, "time": 39627.71136331558, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 805032, "time": 39636.93341970444, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 805048, "time": 39639.04445004463, "episode/length": 150.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 805840, "time": 39669.74250245094, "episode/length": 221.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 805992, "time": 39676.62836647034, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 806168, "time": 39684.59546780586, "episode/length": 141.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 806264, "time": 39689.69961977005, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 806424, "time": 39697.208015441895, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 807216, "time": 39727.87112426758, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 807240, "time": 39730.072897434235, "episode/length": 450.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9933481152993349, "episode/intrinsic_return": 0.0}
{"step": 807464, "time": 39739.77066683769, "episode/length": 496.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818913480885312, "episode/intrinsic_return": 0.0}
{"step": 807488, "time": 39742.37703251839, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 807560, "time": 39746.37468957901, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 807760, "time": 39755.552334070206, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 808288, "time": 39776.51629066467, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 808464, "time": 39784.4473900795, "episode/length": 327.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 808752, "time": 39796.81061553955, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 808888, "time": 39803.18073654175, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 809208, "time": 39816.60418844223, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 809240, "time": 39819.35476708412, "episode/length": 221.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 809608, "time": 39834.37506151199, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 809688, "time": 39838.96472740173, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 809816, "time": 39845.15224599838, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 809944, "time": 39851.431451797485, "episode/length": 439.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 39876.631333589554, "eval_episode/length": 164.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 810056, "time": 39880.16863775253, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 810056, "time": 39883.69467973709, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 810056, "time": 39885.33849811554, "eval_episode/length": 220.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 810056, "time": 39888.17334485054, "eval_episode/length": 251.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9801587301587301}
{"step": 810056, "time": 39889.947371959686, "eval_episode/length": 256.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9766536964980544}
{"step": 810056, "time": 39892.17534947395, "eval_episode/length": 53.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 810056, "time": 39893.84561228752, "eval_episode/length": 276.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9819494584837545}
{"step": 810216, "time": 39899.679401636124, "episode/length": 218.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 810576, "time": 39914.54220819473, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 810672, "time": 39919.5969645977, "episode/length": 132.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 810992, "time": 39932.74512338638, "episode/length": 218.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 811080, "time": 39938.99989748001, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 811472, "time": 39955.08191585541, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 811496, "time": 39957.24961900711, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 811864, "time": 39972.243997335434, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 811904, "time": 39975.563354969025, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 812056, "time": 39982.43390893936, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 812056, "time": 39982.479898929596, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 812472, "time": 40001.016714811325, "episode/length": 51.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 812912, "time": 40019.30385971069, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 813552, "time": 40045.54433774948, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 813704, "time": 40053.144211769104, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 813800, "time": 40058.80886006355, "episode/length": 339.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 813896, "time": 40064.537643909454, "episode/length": 299.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 813896, "time": 40064.59408783913, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 814104, "time": 40076.48411011696, "episode/length": 37.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 814464, "time": 40092.33096027374, "episode/length": 373.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 814952, "time": 40112.386530160904, "episode/length": 385.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9922279792746114, "episode/intrinsic_return": 0.0}
{"step": 815088, "time": 40119.6701772213, "episode/length": 271.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 815216, "time": 40125.921850681305, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 815432, "time": 40135.047417640686, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 815568, "time": 40141.80998182297, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 815792, "time": 40151.57987546921, "episode/length": 260.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 816120, "time": 40164.83609342575, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 816344, "time": 40174.53885769844, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 816560, "time": 40184.48196053505, "episode/length": 306.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 816656, "time": 40189.568863630295, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 816896, "time": 40199.94000649452, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 817064, "time": 40207.48117566109, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 817528, "time": 40226.0513010025, "episode/length": 216.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 817720, "time": 40235.46551823616, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 818648, "time": 40272.64328789711, "episode/length": 197.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 818760, "time": 40278.392478466034, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 818776, "time": 40280.90057897568, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 818792, "time": 40283.484688043594, "episode/length": 402.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975186104218362, "episode/intrinsic_return": 0.0}
{"step": 819056, "time": 40295.75018453598, "episode/length": 311.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 819288, "time": 40308.11605477333, "episode/length": 367.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9755434782608695, "episode/intrinsic_return": 0.0}
{"step": 819352, "time": 40312.55618596077, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 819376, "time": 40315.65226173401, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 819777, "time": 40333.3086771965, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.530343862680288, "train/action_min": 0.0, "train/action_std": 3.3139107135625987, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04000638739134257, "train/actor_opt_grad_steps": 50485.0, "train/actor_opt_loss": 0.487508120903602, "train/adv_mag": 0.5458725583094817, "train/adv_max": 0.48697403623507574, "train/adv_mean": 0.004270459547254946, "train/adv_min": -0.43286689451107613, "train/adv_std": 0.05790715011266562, "train/cont_avg": 0.9949819711538461, "train/cont_loss_mean": 0.00010327720492590778, "train/cont_loss_std": 0.003040838704723333, "train/cont_neg_acc": 0.9953846156597137, "train/cont_neg_loss": 0.014496219334698532, "train/cont_pos_acc": 0.9999999830356011, "train/cont_pos_loss": 2.9935059109220676e-05, "train/cont_pred": 0.9949877312550178, "train/cont_rate": 0.9949819711538461, "train/dyn_loss_mean": 12.442706849024846, "train/dyn_loss_std": 8.990261341975286, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.86246752509704, "train/extr_critic_critic_opt_grad_steps": 50485.0, "train/extr_critic_critic_opt_loss": 15929.0154296875, "train/extr_critic_mag": 7.952979344588059, "train/extr_critic_max": 7.952979344588059, "train/extr_critic_mean": 2.3208648681640627, "train/extr_critic_min": -0.25227349813167865, "train/extr_critic_std": 1.8300651009266193, "train/extr_return_normed_mag": 1.568315534408276, "train/extr_return_normed_max": 1.568315534408276, "train/extr_return_normed_mean": 0.39320683158361, "train/extr_return_normed_min": -0.11382145500526979, "train/extr_return_normed_std": 0.32394651621580123, "train/extr_return_rate": 0.7988772438122675, "train/extr_return_raw_mag": 9.108724601452167, "train/extr_return_raw_max": 9.108724601452167, "train/extr_return_raw_mean": 2.345455263211177, "train/extr_return_raw_min": -0.5742446886805388, "train/extr_return_raw_std": 1.8649228261067317, "train/extr_reward_mag": 1.0390374257014348, "train/extr_reward_max": 1.0390374257014348, "train/extr_reward_mean": 0.03656384787307336, "train/extr_reward_min": -0.44853211366213286, "train/extr_reward_std": 0.18083671778440474, "train/image_loss_mean": 5.854944324493408, "train/image_loss_std": 10.776143253766573, "train/model_loss_mean": 13.374573098696196, "train/model_loss_std": 14.441563004713792, "train/model_opt_grad_norm": 52.56317326472356, "train/model_opt_grad_steps": 50440.623076923075, "train/model_opt_loss": 16837.522701322116, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.6153846153845, "train/policy_entropy_mag": 2.5891126577670756, "train/policy_entropy_max": 2.5891126577670756, "train/policy_entropy_mean": 0.4923864564070335, "train/policy_entropy_min": 0.07937501972684494, "train/policy_entropy_std": 0.5596835260207836, "train/policy_logprob_mag": 7.438383601262019, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4915351830996, "train/policy_logprob_min": -7.438383601262019, "train/policy_logprob_std": 1.0723982402911554, "train/policy_randomness_mag": 0.913843147112773, "train/policy_randomness_max": 0.913843147112773, "train/policy_randomness_mean": 0.17379081272161923, "train/policy_randomness_min": 0.02801589868389643, "train/policy_randomness_std": 0.19754372411049329, "train/post_ent_mag": 58.98247756958008, "train/post_ent_max": 58.98247756958008, "train/post_ent_mean": 42.46063995361328, "train/post_ent_min": 20.070915192824145, "train/post_ent_std": 7.627860454412607, "train/prior_ent_mag": 67.19673620370718, "train/prior_ent_max": 67.19673620370718, "train/prior_ent_mean": 54.95794830322266, "train/prior_ent_min": 39.86229388897235, "train/prior_ent_std": 4.271918335327736, "train/rep_loss_mean": 12.442706849024846, "train/rep_loss_std": 8.990261341975286, "train/reward_avg": 0.02809570306338943, "train/reward_loss_mean": 0.05390149268966455, "train/reward_loss_std": 0.2378706809419852, "train/reward_max_data": 1.0138461571473343, "train/reward_max_pred": 1.0094117329670833, "train/reward_neg_acc": 0.9927035648089189, "train/reward_neg_loss": 0.02769807380839036, "train/reward_pos_acc": 0.9738284276081965, "train/reward_pos_loss": 0.832286949799611, "train/reward_pred": 0.027268562910075372, "train/reward_rate": 0.03267728365384615, "train_stats/sum_log_reward": 8.088889064888159, "train_stats/max_log_achievement_collect_coal": 0.25555555555555554, "train_stats/max_log_achievement_collect_drink": 5.6, "train_stats/max_log_achievement_collect_sapling": 1.2555555555555555, "train_stats/max_log_achievement_collect_stone": 2.7111111111111112, "train_stats/max_log_achievement_collect_wood": 10.677777777777777, "train_stats/max_log_achievement_defeat_skeleton": 0.022222222222222223, "train_stats/max_log_achievement_defeat_zombie": 1.6111111111111112, "train_stats/max_log_achievement_eat_cow": 0.17777777777777778, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011111111111111112, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7222222222222223, "train_stats/max_log_achievement_make_wood_sword": 1.011111111111111, "train_stats/max_log_achievement_place_furnace": 0.16666666666666666, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_stone": 0.2, "train_stats/max_log_achievement_place_table": 2.988888888888889, "train_stats/max_log_achievement_wake_up": 1.0888888888888888, "train_stats/mean_log_entropy": 0.5054086473253038, "eval_stats/sum_log_reward": 7.912500351667404, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 2.125, "eval_stats/max_log_achievement_collect_wood": 12.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8125, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.5772792469069827e-06, "report/cont_loss_std": 4.391224138089456e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004332225944381207, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.6420140620284656e-07, "report/cont_pred": 0.9951188564300537, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.348831176757812, "report/dyn_loss_std": 8.628277778625488, "report/image_loss_mean": 5.158205509185791, "report/image_loss_std": 8.922019958496094, "report/model_loss_mean": 12.023780822753906, "report/model_loss_std": 12.547141075134277, "report/post_ent_mag": 62.5025749206543, "report/post_ent_max": 62.5025749206543, "report/post_ent_mean": 43.18408203125, "report/post_ent_min": 21.051456451416016, "report/post_ent_std": 7.894345283508301, "report/prior_ent_mag": 67.50270080566406, "report/prior_ent_max": 67.50270080566406, "report/prior_ent_mean": 54.74384689331055, "report/prior_ent_min": 36.94439697265625, "report/prior_ent_std": 3.9931273460388184, "report/rep_loss_mean": 11.348831176757812, "report/rep_loss_std": 8.628277778625488, "report/reward_avg": 0.03583984076976776, "report/reward_loss_mean": 0.0562748983502388, "report/reward_loss_std": 0.24995774030685425, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001227855682373, "report/reward_neg_acc": 0.9877800941467285, "report/reward_neg_loss": 0.021695012226700783, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.8647855520248413, "report/reward_pred": 0.03473334386944771, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.6577600894815987e-06, "eval/cont_loss_std": 6.0279769968474284e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001614389766473323, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.8835634111601394e-06, "eval/cont_pred": 0.9951152205467224, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.55352783203125, "eval/dyn_loss_std": 9.96406364440918, "eval/image_loss_mean": 8.949662208557129, "eval/image_loss_std": 11.44792366027832, "eval/model_loss_mean": 18.412086486816406, "eval/model_loss_std": 15.314410209655762, "eval/post_ent_mag": 57.8599967956543, "eval/post_ent_max": 57.8599967956543, "eval/post_ent_mean": 41.814247131347656, "eval/post_ent_min": 19.83798599243164, "eval/post_ent_std": 7.869626045227051, "eval/prior_ent_mag": 67.50270080566406, "eval/prior_ent_max": 67.50270080566406, "eval/prior_ent_mean": 55.414161682128906, "eval/prior_ent_min": 30.457019805908203, "eval/prior_ent_std": 5.191417694091797, "eval/rep_loss_mean": 15.55352783203125, "eval/rep_loss_std": 9.96406364440918, "eval/reward_avg": 0.03789062425494194, "eval/reward_loss_mean": 0.13030290603637695, "eval/reward_loss_std": 0.6990565061569214, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017917156219482, "eval/reward_neg_acc": 0.9765305519104004, "eval/reward_neg_loss": 0.08136536926031113, "eval/reward_pos_acc": 0.9318181872367859, "eval/reward_pos_loss": 1.2202755212783813, "eval/reward_pred": 0.042351242154836655, "eval/reward_rate": 0.04296875, "replay/size": 819273.0, "replay/inserts": 20856.0, "replay/samples": 20848.0, "replay/insert_wait_avg": 1.3942388359687315e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.88503578783271e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5344.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1120549219097206e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0584859848022, "timer/env.step_count": 2607.0, "timer/env.step_total": 219.6823070049286, "timer/env.step_frac": 0.21966945942026342, "timer/env.step_avg": 0.08426632412923997, "timer/env.step_min": 0.023580312728881836, "timer/env.step_max": 4.106627464294434, "timer/replay._sample_count": 20848.0, "timer/replay._sample_total": 10.854695320129395, "timer/replay._sample_frac": 0.010854060509711381, "timer/replay._sample_avg": 0.0005206588315488005, "timer/replay._sample_min": 0.00042319297790527344, "timer/replay._sample_max": 0.00843954086303711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3275.0, "timer/agent.policy_total": 55.14793801307678, "timer/agent.policy_frac": 0.05514471282024085, "timer/agent.policy_avg": 0.016839065042160848, "timer/agent.policy_min": 0.009626388549804688, "timer/agent.policy_max": 0.10859370231628418, "timer/dataset_train_count": 1303.0, "timer/dataset_train_total": 0.1553022861480713, "timer/dataset_train_frac": 0.00015529320367212144, "timer/dataset_train_avg": 0.00011918824723566484, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.000492095947265625, "timer/agent.train_count": 1303.0, "timer/agent.train_total": 581.8884398937225, "timer/agent.train_frac": 0.5818544095655676, "timer/agent.train_avg": 0.446575932381982, "timer/agent.train_min": 0.43415284156799316, "timer/agent.train_max": 1.4129350185394287, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751548767089844, "timer/agent.report_frac": 0.0004751270884333111, "timer/agent.report_avg": 0.2375774383544922, "timer/agent.report_min": 0.2283005714416504, "timer/agent.report_max": 0.24685430526733398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218462582917383e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 20.854479756961325}
{"step": 820040, "time": 40357.746398210526, "eval_episode/length": 43.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 820040, "time": 40364.66702795029, "eval_episode/length": 181.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 820040, "time": 40366.384239673615, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 820040, "time": 40368.30331277847, "eval_episode/length": 194.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 820040, "time": 40368.35465168953, "eval_episode/length": 194.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 820040, "time": 40372.79259800911, "eval_episode/length": 36.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.8918918918918919}
{"step": 820040, "time": 40374.40870141983, "eval_episode/length": 222.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 820040, "time": 40376.25838327408, "eval_episode/length": 230.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 820272, "time": 40384.95543050766, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 820472, "time": 40393.74472308159, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 820544, "time": 40398.14535546303, "episode/length": 222.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 820704, "time": 40405.62072515488, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 820824, "time": 40411.328523635864, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 820904, "time": 40415.8206820488, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 820984, "time": 40420.424572229385, "episode/length": 63.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 821272, "time": 40432.390634059906, "episode/length": 239.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 821504, "time": 40442.4707775116, "episode/length": 338.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9970501474926253, "episode/intrinsic_return": 0.0}
{"step": 821936, "time": 40459.977264881134, "episode/length": 53.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 822024, "time": 40464.52968931198, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 822200, "time": 40472.624735593796, "episode/length": 186.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 822232, "time": 40475.41529130936, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 822240, "time": 40477.58066534996, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 822392, "time": 40484.48697352409, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 822832, "time": 40502.310975551605, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 822960, "time": 40508.5915453434, "episode/length": 89.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 823224, "time": 40519.56062436104, "episode/length": 243.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 823448, "time": 40529.22373962402, "episode/length": 307.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 823696, "time": 40540.13320684433, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 823896, "time": 40548.735624313354, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 824136, "time": 40559.07502627373, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 824608, "time": 40578.176256895065, "episode/length": 144.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 824640, "time": 40580.75254178047, "episode/length": 62.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 825008, "time": 40595.863535404205, "episode/length": 350.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 825032, "time": 40598.25488996506, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 825312, "time": 40610.13673686981, "episode/length": 364.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.989041095890411, "episode/intrinsic_return": 0.0}
{"step": 825648, "time": 40623.939948797226, "episode/length": 302.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.0}
{"step": 826336, "time": 40650.47008419037, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 826448, "time": 40656.054275751114, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 826608, "time": 40663.50315260887, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 826640, "time": 40666.233114004135, "episode/length": 249.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 827016, "time": 40681.3127617836, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 827088, "time": 40685.8061041832, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 827408, "time": 40700.846167087555, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 827472, "time": 40704.59610247612, "episode/length": 304.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 828000, "time": 40725.60448074341, "episode/length": 629.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 828184, "time": 40733.693148851395, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 828312, "time": 40739.9627096653, "episode/length": 232.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 828320, "time": 40742.03363990784, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 828456, "time": 40748.43202376366, "episode/length": 179.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 829104, "time": 40773.81014561653, "episode/length": 345.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 829208, "time": 40778.93277549744, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 829248, "time": 40782.10120034218, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 829360, "time": 40787.82688140869, "episode/length": 243.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 829648, "time": 40799.912031412125, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 829688, "time": 40802.659338474274, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 829808, "time": 40808.84046673775, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 40837.415095090866, "eval_episode/length": 164.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 830024, "time": 40840.16916704178, "eval_episode/length": 191.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 830024, "time": 40841.95102572441, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 830024, "time": 40843.491834163666, "eval_episode/length": 200.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 830024, "time": 40845.52541041374, "eval_episode/length": 211.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 830024, "time": 40848.54250264168, "eval_episode/length": 58.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 830024, "time": 40852.41138982773, "eval_episode/length": 58.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 830024, "time": 40855.88986110687, "eval_episode/length": 360.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9889196675900277}
{"step": 831000, "time": 40891.864966869354, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 831048, "time": 40895.128078222275, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 831152, "time": 40900.70199203491, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 831368, "time": 40909.8706099987, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 831632, "time": 40921.29727053642, "episode/length": 396.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 831712, "time": 40925.76514816284, "episode/length": 257.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 831824, "time": 40931.63078832626, "episode/length": 251.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 831872, "time": 40934.931134700775, "episode/length": 345.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 832384, "time": 40954.99516224861, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974811083123426, "episode/intrinsic_return": 0.0}
{"step": 832784, "time": 40971.3291554451, "episode/length": 222.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 833128, "time": 40985.2301864624, "episode/length": 42.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 833152, "time": 40988.04250788689, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 833208, "time": 40991.543546676636, "episode/length": 166.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 833216, "time": 40993.72059893608, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 833272, "time": 40997.217853307724, "episode/length": 237.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 833504, "time": 41009.5437579155, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 833816, "time": 41022.294171094894, "episode/length": 262.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 834848, "time": 41061.72587823868, "episode/length": 203.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 834920, "time": 41065.6218957901, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 835120, "time": 41074.63366174698, "episode/length": 230.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 835200, "time": 41079.18547010422, "episode/length": 258.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 835232, "time": 41081.85060429573, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 835280, "time": 41085.067289590836, "episode/length": 265.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 835952, "time": 41112.76125049591, "episode/length": 445.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 836024, "time": 41116.69989681244, "episode/length": 275.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 836536, "time": 41136.98805594444, "episode/length": 156.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 836824, "time": 41149.178283691406, "episode/length": 246.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 836928, "time": 41154.8324034214, "episode/length": 211.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 837080, "time": 41161.76733088493, "episode/length": 269.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 837104, "time": 41164.44217419624, "episode/length": 34.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 837168, "time": 41168.53571510315, "episode/length": 255.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 837264, "time": 41173.639830589294, "episode/length": 154.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 837280, "time": 41175.78118062019, "episode/length": 259.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 837624, "time": 41189.69941306114, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 838360, "time": 41218.48611974716, "episode/length": 159.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 838576, "time": 41228.31005716324, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 838656, "time": 41232.87996840477, "episode/length": 185.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 838848, "time": 41241.47412586212, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 838896, "time": 41244.805762290955, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 839216, "time": 41258.25437808037, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 839472, "time": 41269.09644770622, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 839600, "time": 41275.23406910896, "episode/length": 382.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947780678851175, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 41306.14336323738, "eval_episode/length": 39.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9}
{"step": 840008, "time": 41307.95169734955, "eval_episode/length": 47.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 840008, "time": 41313.564135313034, "eval_episode/length": 152.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 840008, "time": 41317.20436120033, "eval_episode/length": 199.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.965}
{"step": 840008, "time": 41318.89297747612, "eval_episode/length": 202.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 840008, "time": 41320.69922709465, "eval_episode/length": 209.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 840008, "time": 41322.49060797691, "eval_episode/length": 216.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 840008, "time": 41324.37182378769, "eval_episode/length": 187.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9893617021276596}
{"step": 840233, "time": 41333.62258672714, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.484447956085205, "train/action_min": 0.0, "train/action_std": 3.123670868575573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039298811825574376, "train/actor_opt_grad_steps": 51775.0, "train/actor_opt_loss": -5.51210210433419, "train/adv_mag": 0.5372888243291527, "train/adv_max": 0.46791510097682476, "train/adv_mean": 0.003006894728265763, "train/adv_min": -0.445918474229984, "train/adv_std": 0.056896797876106575, "train/cont_avg": 0.9948577880859375, "train/cont_loss_mean": 0.00017489823552629957, "train/cont_loss_std": 0.005354817045395421, "train/cont_neg_acc": 0.9964254475015355, "train/cont_neg_loss": 0.017697396319094626, "train/cont_pos_acc": 0.9999845842830837, "train/cont_pos_loss": 5.065508532586804e-05, "train/cont_pred": 0.9948572744615376, "train/cont_rate": 0.9948577880859375, "train/dyn_loss_mean": 12.38440889120102, "train/dyn_loss_std": 8.985001020133495, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8877733992412686, "train/extr_critic_critic_opt_grad_steps": 51775.0, "train/extr_critic_critic_opt_loss": 15662.152610778809, "train/extr_critic_mag": 8.112684525549412, "train/extr_critic_max": 8.112684525549412, "train/extr_critic_mean": 2.474444044753909, "train/extr_critic_min": -0.2567918701097369, "train/extr_critic_std": 1.8925328394398093, "train/extr_return_normed_mag": 1.545926827006042, "train/extr_return_normed_max": 1.545926827006042, "train/extr_return_normed_mean": 0.3952062663156539, "train/extr_return_normed_min": -0.11751603538868949, "train/extr_return_normed_std": 0.32108375208918005, "train/extr_return_rate": 0.8351700277999043, "train/extr_return_raw_mag": 9.389392592012882, "train/extr_return_raw_max": 9.389392592012882, "train/extr_return_raw_mean": 2.4924389524385333, "train/extr_return_raw_min": -0.5804037691559643, "train/extr_return_raw_std": 1.9243724439293146, "train/extr_reward_mag": 1.0400786995887756, "train/extr_reward_max": 1.0400786995887756, "train/extr_reward_mean": 0.035977614010334946, "train/extr_reward_min": -0.4937847824767232, "train/extr_reward_std": 0.1796457478776574, "train/image_loss_mean": 5.854162510484457, "train/image_loss_std": 11.127788297832012, "train/model_loss_mean": 13.34014043956995, "train/model_loss_std": 14.786451108753681, "train/model_opt_grad_norm": 55.30067923665047, "train/model_opt_grad_steps": 51729.40625, "train/model_opt_loss": 16809.602424621582, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.765625, "train/policy_entropy_mag": 2.5539582427591085, "train/policy_entropy_max": 2.5539582427591085, "train/policy_entropy_mean": 0.5034682638943195, "train/policy_entropy_min": 0.07937502110144123, "train/policy_entropy_std": 0.5721565939020365, "train/policy_logprob_mag": 7.438383590430021, "train/policy_logprob_max": -0.00945565848815022, "train/policy_logprob_mean": -0.5030133184045553, "train/policy_logprob_min": -7.438383590430021, "train/policy_logprob_std": 1.0817893976345658, "train/policy_randomness_mag": 0.9014351824298501, "train/policy_randomness_max": 0.9014351824298501, "train/policy_randomness_mean": 0.17770220362581313, "train/policy_randomness_min": 0.028015899151796475, "train/policy_randomness_std": 0.20194616972003132, "train/post_ent_mag": 58.79755017161369, "train/post_ent_max": 58.79755017161369, "train/post_ent_mean": 42.46388790011406, "train/post_ent_min": 19.794586032629013, "train/post_ent_std": 7.6248269602656364, "train/prior_ent_mag": 67.20827728509903, "train/prior_ent_max": 67.20827728509903, "train/prior_ent_mean": 54.92923554778099, "train/prior_ent_min": 39.399071261286736, "train/prior_ent_std": 4.249082999303937, "train/rep_loss_mean": 12.38440889120102, "train/rep_loss_std": 8.985001020133495, "train/reward_avg": 0.028732299761031754, "train/reward_loss_mean": 0.05515770745114423, "train/reward_loss_std": 0.24715788452886045, "train/reward_max_data": 1.0187500044703484, "train/reward_max_pred": 1.0110242562368512, "train/reward_neg_acc": 0.9926760392263532, "train/reward_neg_loss": 0.028477150677645113, "train/reward_pos_acc": 0.9711520532146096, "train/reward_pos_loss": 0.8283136673271656, "train/reward_pred": 0.028109307830163743, "train/reward_rate": 0.03331756591796875, "eval_stats/sum_log_reward": 6.683333491285642, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 3.7083333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.5833333333333333, "eval_stats/max_log_achievement_collect_stone": 1.2083333333333333, "eval_stats/max_log_achievement_collect_wood": 9.041666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9166666666666666, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0416666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.7083333333333334, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 2.8333333333333335, "eval_stats/max_log_achievement_wake_up": 0.8333333333333334, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 7.933333509167036, "train_stats/max_log_achievement_collect_coal": 0.3111111111111111, "train_stats/max_log_achievement_collect_drink": 5.477777777777778, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 2.6555555555555554, "train_stats/max_log_achievement_collect_wood": 10.722222222222221, "train_stats/max_log_achievement_defeat_skeleton": 0.03333333333333333, "train_stats/max_log_achievement_defeat_zombie": 1.2555555555555555, "train_stats/max_log_achievement_eat_cow": 0.17777777777777778, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011111111111111112, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2444444444444445, "train_stats/max_log_achievement_make_wood_sword": 0.9, "train_stats/max_log_achievement_place_furnace": 0.15555555555555556, "train_stats/max_log_achievement_place_plant": 1.4777777777777779, "train_stats/max_log_achievement_place_stone": 0.08888888888888889, "train_stats/max_log_achievement_place_table": 3.3666666666666667, "train_stats/max_log_achievement_wake_up": 1.011111111111111, "train_stats/mean_log_entropy": 0.5026429537269804, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00020548701286315918, "report/cont_loss_std": 0.0040513621643185616, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.014335338026285172, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.422834409633651e-05, "report/cont_pred": 0.9922016859054565, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.274820327758789, "report/dyn_loss_std": 8.969669342041016, "report/image_loss_mean": 5.354077339172363, "report/image_loss_std": 9.607994079589844, "report/model_loss_mean": 12.771089553833008, "report/model_loss_std": 13.089164733886719, "report/post_ent_mag": 60.01278305053711, "report/post_ent_max": 60.01278305053711, "report/post_ent_mean": 42.98004913330078, "report/post_ent_min": 22.07962417602539, "report/post_ent_std": 7.926636219024658, "report/prior_ent_mag": 67.23576354980469, "report/prior_ent_max": 67.23576354980469, "report/prior_ent_mean": 55.4262809753418, "report/prior_ent_min": 43.26773452758789, "report/prior_ent_std": 4.3013176918029785, "report/rep_loss_mean": 12.274820327758789, "report/rep_loss_std": 8.969669342041016, "report/reward_avg": 0.02998046763241291, "report/reward_loss_mean": 0.051914967596530914, "report/reward_loss_std": 0.20174533128738403, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000575065612793, "report/reward_neg_acc": 0.9878543019294739, "report/reward_neg_loss": 0.028518131002783775, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6940281987190247, "report/reward_pred": 0.030936460942029953, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.7644509853198542e-06, "eval/cont_loss_std": 2.928778121713549e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004791463434230536, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.302400260618015e-07, "eval/cont_pred": 0.9980470538139343, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.68686866760254, "eval/dyn_loss_std": 10.194833755493164, "eval/image_loss_mean": 7.651519775390625, "eval/image_loss_std": 11.640909194946289, "eval/model_loss_mean": 17.768198013305664, "eval/model_loss_std": 15.938844680786133, "eval/post_ent_mag": 57.954063415527344, "eval/post_ent_max": 57.954063415527344, "eval/post_ent_mean": 40.391658782958984, "eval/post_ent_min": 20.291217803955078, "eval/post_ent_std": 7.444859027862549, "eval/prior_ent_mag": 67.23576354980469, "eval/prior_ent_max": 67.23576354980469, "eval/prior_ent_mean": 54.84361267089844, "eval/prior_ent_min": 40.32744216918945, "eval/prior_ent_std": 3.6584744453430176, "eval/rep_loss_mean": 16.68686866760254, "eval/rep_loss_std": 10.194833755493164, "eval/reward_avg": 0.03925781324505806, "eval/reward_loss_mean": 0.10455463826656342, "eval/reward_loss_std": 0.7018820643424988, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.005925178527832, "eval/reward_neg_acc": 0.986761748790741, "eval/reward_neg_loss": 0.03381633013486862, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.7584837675094604, "eval/reward_pred": 0.03612507879734039, "eval/reward_rate": 0.041015625, "replay/size": 839729.0, "replay/inserts": 20456.0, "replay/samples": 20464.0, "replay/insert_wait_avg": 1.3764663557545673e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.812332790097378e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1037762572125691e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2988014221191, "timer/env.step_count": 2557.0, "timer/env.step_total": 207.26542687416077, "timer/env.step_frac": 0.20720351416945884, "timer/env.step_avg": 0.08105804727186577, "timer/env.step_min": 0.0234529972076416, "timer/env.step_max": 1.7816061973571777, "timer/replay._sample_count": 20464.0, "timer/replay._sample_total": 10.674226999282837, "timer/replay._sample_frac": 0.01067103847781018, "timer/replay._sample_avg": 0.0005216099980103028, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.018305063247680664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3377.0, "timer/agent.policy_total": 54.84855794906616, "timer/agent.policy_frac": 0.05483217401749185, "timer/agent.policy_avg": 0.01624179980724494, "timer/agent.policy_min": 0.009598255157470703, "timer/agent.policy_max": 0.09243512153625488, "timer/dataset_train_count": 1279.0, "timer/dataset_train_total": 0.15042829513549805, "timer/dataset_train_frac": 0.00015038336037355538, "timer/dataset_train_avg": 0.0001176139915054715, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0004227161407470703, "timer/agent.train_count": 1279.0, "timer/agent.train_total": 571.3197619915009, "timer/agent.train_frac": 0.5711491018276327, "timer/agent.train_avg": 0.44669254260477004, "timer/agent.train_min": 0.4322781562805176, "timer/agent.train_max": 2.641517162322998, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733860492706299, "timer/agent.report_frac": 0.00047324464309826187, "timer/agent.report_avg": 0.23669302463531494, "timer/agent.report_min": 0.22993206977844238, "timer/agent.report_max": 0.2434539794921875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.574151494169667e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 20.449602775728124}
{"step": 840256, "time": 41334.43049669266, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 840264, "time": 41336.25216984749, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 840792, "time": 41357.2021651268, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 840856, "time": 41361.21002173424, "episode/length": 250.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 840928, "time": 41365.58758211136, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 841080, "time": 41372.47308135033, "episode/length": 200.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 841400, "time": 41385.88258552551, "episode/length": 379.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 841920, "time": 41406.91715955734, "episode/length": 207.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 841968, "time": 41410.24971365929, "episode/length": 343.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 842296, "time": 41423.66569852829, "episode/length": 46.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 842440, "time": 41430.537249565125, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 842536, "time": 41435.6636197567, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 842568, "time": 41438.47477698326, "episode/length": 287.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 842640, "time": 41442.93714094162, "episode/length": 230.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 842888, "time": 41453.3295378685, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 843048, "time": 41460.700021743774, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 843808, "time": 41492.249360084534, "episode/length": 229.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 843872, "time": 41496.17201566696, "episode/length": 196.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 843880, "time": 41497.89263820648, "episode/length": 154.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 843944, "time": 41501.789924144745, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 844112, "time": 41509.7827937603, "episode/length": 37.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 844280, "time": 41517.24914884567, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 844352, "time": 41521.59914684296, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 844544, "time": 41530.17606925964, "episode/length": 53.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 844544, "time": 41530.210958480835, "episode/length": 250.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 844584, "time": 41534.721363306046, "episode/length": 191.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 844680, "time": 41539.8134663105, "episode/length": 263.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 845072, "time": 41555.816086769104, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 845704, "time": 41580.38436150551, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 846128, "time": 41597.890661001205, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 846176, "time": 41601.08582139015, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 846328, "time": 41607.928594350815, "episode/length": 222.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 846456, "time": 41614.13827204704, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 846600, "time": 41621.110580682755, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 846912, "time": 41634.13510107994, "episode/length": 379.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9973684210526316, "episode/intrinsic_return": 0.0}
{"step": 847000, "time": 41638.63498926163, "episode/length": 339.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9911764705882353, "episode/intrinsic_return": 0.0}
{"step": 847280, "time": 41650.91182899475, "episode/length": 196.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 847280, "time": 41650.961203575134, "episode/length": 143.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 847616, "time": 41666.54757785797, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 847936, "time": 41679.80286407471, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 848352, "time": 41696.671446084976, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 848440, "time": 41701.21203613281, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 848688, "time": 41712.12973856926, "episode/length": 175.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 848792, "time": 41717.27072429657, "episode/length": 291.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 849176, "time": 41732.991674661636, "episode/length": 154.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 849304, "time": 41739.339089393616, "episode/length": 118.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 849456, "time": 41746.68312096596, "episode/length": 229.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 849496, "time": 41749.495557785034, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 849880, "time": 41765.06388640404, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 41796.748399972916, "eval_episode/length": 183.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 850096, "time": 41798.839268922806, "eval_episode/length": 196.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 850096, "time": 41800.5538289547, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 850096, "time": 41802.39819717407, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 850096, "time": 41804.11668252945, "eval_episode/length": 211.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 850096, "time": 41805.66065311432, "eval_episode/length": 212.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 850096, "time": 41807.65124750137, "eval_episode/length": 222.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 850096, "time": 41812.75825667381, "eval_episode/length": 105.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9905660377358491}
{"step": 850192, "time": 41816.303871154785, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 850776, "time": 41838.99831676483, "episode/length": 247.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 850984, "time": 41848.13128614426, "episode/length": 225.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 851208, "time": 41858.156643390656, "episode/length": 237.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 851496, "time": 41870.41302609444, "episode/length": 572.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9982547993019197, "episode/intrinsic_return": 0.0}
{"step": 851760, "time": 41881.81142306328, "episode/length": 234.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 851768, "time": 41883.38663673401, "episode/length": 196.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 852248, "time": 41904.17049407959, "episode/length": 183.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 852296, "time": 41907.5032658577, "episode/length": 354.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9887323943661972, "episode/intrinsic_return": 0.0}
{"step": 852304, "time": 41909.60152220726, "episode/length": 350.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 852840, "time": 41930.66538286209, "episode/length": 203.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 853120, "time": 41942.773664951324, "episode/length": 266.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 853128, "time": 41944.48093914986, "episode/length": 109.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 853432, "time": 41957.29465198517, "episode/length": 208.0, "episode/score": 12.10000005364418, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 853456, "time": 41959.93880319595, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 853488, "time": 41962.5839138031, "episode/length": 80.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 853984, "time": 41982.38781833649, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 854064, "time": 41986.860547065735, "episode/length": 320.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781931464174455, "episode/intrinsic_return": 0.0}
{"step": 854424, "time": 42001.30857825279, "episode/length": 123.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 854472, "time": 42004.53520941734, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 854832, "time": 42019.6765794754, "episode/length": 316.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9810725552050473, "episode/intrinsic_return": 0.0}
{"step": 855176, "time": 42033.60060620308, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 855336, "time": 42041.11245179176, "episode/length": 234.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 855472, "time": 42047.83329439163, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 855864, "time": 42063.58988451958, "episode/length": 179.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 855944, "time": 42068.09981250763, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 855984, "time": 42071.31320476532, "episode/length": 143.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 856808, "time": 42102.786351680756, "episode/length": 291.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 857168, "time": 42117.89474487305, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 857408, "time": 42128.366355895996, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 857464, "time": 42131.69883942604, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 857496, "time": 42134.388613939285, "episode/length": 438.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 857536, "time": 42137.618413209915, "episode/length": 294.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 857560, "time": 42139.718339920044, "episode/length": 277.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 857648, "time": 42144.70086526871, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 858288, "time": 42169.84809470177, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 858744, "time": 42188.129185438156, "episode/length": 196.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 859032, "time": 42200.28661251068, "episode/length": 202.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 859176, "time": 42207.13314437866, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 859200, "time": 42209.765659570694, "episode/length": 216.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 859568, "time": 42224.90214753151, "episode/length": 48.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 859672, "time": 42230.096314668655, "episode/length": 271.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 859688, "time": 42232.30383658409, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 859752, "time": 42236.20415973663, "episode/length": 273.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 859968, "time": 42245.75447821617, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 42266.79718184471, "eval_episode/length": 60.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 860080, "time": 42271.46203160286, "eval_episode/length": 137.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 860080, "time": 42273.49450802803, "eval_episode/length": 152.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 860080, "time": 42278.19538068771, "eval_episode/length": 227.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 860080, "time": 42279.906702280045, "eval_episode/length": 231.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 860080, "time": 42281.53739976883, "eval_episode/length": 235.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 860080, "time": 42284.61283493042, "eval_episode/length": 272.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9816849816849816}
{"step": 860080, "time": 42284.65953087807, "eval_episode/length": 272.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9816849816849816}
{"step": 860808, "time": 42312.87905240059, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 860952, "time": 42319.77168059349, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 861257, "time": 42333.90268325806, "train_stats/sum_log_reward": 8.964583622912565, "train_stats/max_log_achievement_collect_coal": 0.3125, "train_stats/max_log_achievement_collect_drink": 5.34375, "train_stats/max_log_achievement_collect_sapling": 1.9791666666666667, "train_stats/max_log_achievement_collect_stone": 3.3125, "train_stats/max_log_achievement_collect_wood": 10.8125, "train_stats/max_log_achievement_defeat_skeleton": 0.052083333333333336, "train_stats/max_log_achievement_defeat_zombie": 1.40625, "train_stats/max_log_achievement_eat_cow": 0.23958333333333334, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010416666666666666, "train_stats/max_log_achievement_make_stone_sword": 0.020833333333333332, "train_stats/max_log_achievement_make_wood_pickaxe": 1.78125, "train_stats/max_log_achievement_make_wood_sword": 0.9895833333333334, "train_stats/max_log_achievement_place_furnace": 0.3333333333333333, "train_stats/max_log_achievement_place_plant": 1.9375, "train_stats/max_log_achievement_place_stone": 0.6666666666666666, "train_stats/max_log_achievement_place_table": 3.0729166666666665, "train_stats/max_log_achievement_wake_up": 1.1666666666666667, "train_stats/mean_log_entropy": 0.5881912705178062, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.597818085641572, "train/action_min": 0.0, "train/action_std": 3.4663368210648047, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03954679229663628, "train/actor_opt_grad_steps": 53075.0, "train/actor_opt_loss": -6.6417821351100095, "train/adv_mag": 0.5190524294069319, "train/adv_max": 0.4752691363294919, "train/adv_mean": 0.0024948656143048233, "train/adv_min": -0.42094231667843734, "train/adv_std": 0.05702588995071975, "train/cont_avg": 0.9948804450757576, "train/cont_loss_mean": 8.790347454024072e-05, "train/cont_loss_std": 0.0025793109871396305, "train/cont_neg_acc": 0.9987373740384073, "train/cont_neg_loss": 0.003237133538746231, "train/cont_pos_acc": 0.9999776536768133, "train/cont_pos_loss": 6.932699933339805e-05, "train/cont_pred": 0.9948526092550971, "train/cont_rate": 0.9948804450757576, "train/dyn_loss_mean": 12.349966713876436, "train/dyn_loss_std": 8.967197858926022, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8283092140248327, "train/extr_critic_critic_opt_grad_steps": 53075.0, "train/extr_critic_critic_opt_loss": 15380.746204723011, "train/extr_critic_mag": 8.145538019411491, "train/extr_critic_max": 8.145538019411491, "train/extr_critic_mean": 2.4990006974249175, "train/extr_critic_min": -0.2397543905359326, "train/extr_critic_std": 1.9170240127679072, "train/extr_return_normed_mag": 1.564564246119875, "train/extr_return_normed_max": 1.564564246119875, "train/extr_return_normed_mean": 0.40528037387764815, "train/extr_return_normed_min": -0.11092530348987291, "train/extr_return_normed_std": 0.3279171238342921, "train/extr_return_rate": 0.8143929979114821, "train/extr_return_raw_mag": 9.407029281963002, "train/extr_return_raw_max": 9.407029281963002, "train/extr_return_raw_mean": 2.513853036092989, "train/extr_return_raw_min": -0.5559754224889206, "train/extr_return_raw_std": 1.949806674863353, "train/extr_reward_mag": 1.0357924302419026, "train/extr_reward_max": 1.0357924302419026, "train/extr_reward_mean": 0.03863400999795307, "train/extr_reward_min": -0.48698045719753613, "train/extr_reward_std": 0.18585170873186804, "train/image_loss_mean": 5.704138777472756, "train/image_loss_std": 10.625675811912075, "train/model_loss_mean": 13.169147657625603, "train/model_loss_std": 14.283477176319469, "train/model_opt_grad_norm": 51.391867305293225, "train/model_opt_grad_steps": 53028.22727272727, "train/model_opt_loss": 17301.445430871212, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1325.7575757575758, "train/policy_entropy_mag": 2.6228730136697944, "train/policy_entropy_max": 2.6228730136697944, "train/policy_entropy_mean": 0.5443224010593963, "train/policy_entropy_min": 0.07937501653125792, "train/policy_entropy_std": 0.6184969171881676, "train/policy_logprob_mag": 7.438383669564218, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5441735235579086, "train/policy_logprob_min": -7.438383669564218, "train/policy_logprob_std": 1.110443433577364, "train/policy_randomness_mag": 0.9257590716535394, "train/policy_randomness_max": 0.9257590716535394, "train/policy_randomness_mean": 0.19212192206671744, "train/policy_randomness_min": 0.028015897595182512, "train/policy_randomness_std": 0.2183022719215263, "train/post_ent_mag": 58.84965607614228, "train/post_ent_max": 58.84965607614228, "train/post_ent_mean": 42.53182130871397, "train/post_ent_min": 19.70800326087258, "train/post_ent_std": 7.633479410951788, "train/prior_ent_mag": 67.23629893678607, "train/prior_ent_max": 67.23629893678607, "train/prior_ent_mean": 54.98163662534772, "train/prior_ent_min": 40.01404005108458, "train/prior_ent_std": 4.242538219148463, "train/rep_loss_mean": 12.349966713876436, "train/rep_loss_std": 8.967197858926022, "train/reward_avg": 0.0294367007445544, "train/reward_loss_mean": 0.05494096161176761, "train/reward_loss_std": 0.2439600620983225, "train/reward_max_data": 1.0174242465785055, "train/reward_max_pred": 1.0107973317305248, "train/reward_neg_acc": 0.9925390536134894, "train/reward_neg_loss": 0.027973020519835478, "train/reward_pos_acc": 0.9745202493486982, "train/reward_pos_loss": 0.8238083711176207, "train/reward_pred": 0.028816774318164044, "train/reward_rate": 0.03399473248106061, "eval_stats/sum_log_reward": 8.850000262260437, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 4.875, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 2.5625, "eval_stats/max_log_achievement_collect_wood": 10.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 0.875, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.7182832380058244e-05, "report/cont_loss_std": 0.0003370583290234208, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00045661404146812856, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5459574569831602e-05, "report/cont_pred": 0.996080219745636, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.858662605285645, "report/dyn_loss_std": 9.090703010559082, "report/image_loss_mean": 5.943470001220703, "report/image_loss_std": 9.863947868347168, "report/model_loss_mean": 13.697663307189941, "report/model_loss_std": 13.308955192565918, "report/post_ent_mag": 56.95914077758789, "report/post_ent_max": 56.95914077758789, "report/post_ent_mean": 42.10515594482422, "report/post_ent_min": 21.921964645385742, "report/post_ent_std": 7.505997180938721, "report/prior_ent_mag": 67.04582214355469, "report/prior_ent_max": 67.04582214355469, "report/prior_ent_mean": 55.25574493408203, "report/prior_ent_min": 36.0073356628418, "report/prior_ent_std": 4.4582085609436035, "report/rep_loss_mean": 12.858662605285645, "report/rep_loss_std": 9.090703010559082, "report/reward_avg": 0.01777343824505806, "report/reward_loss_mean": 0.03897831216454506, "report/reward_loss_std": 0.16844861209392548, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0046806335449219, "report/reward_neg_acc": 0.9940000176429749, "report/reward_neg_loss": 0.023354804143309593, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6899577975273132, "report/reward_pred": 0.018901266157627106, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.479861672734842e-05, "eval/cont_loss_std": 0.0010775511618703604, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015115946531295776, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.15127794642467e-07, "eval/cont_pred": 0.9971135854721069, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.36918830871582, "eval/dyn_loss_std": 10.330845832824707, "eval/image_loss_mean": 7.845885276794434, "eval/image_loss_std": 12.826478004455566, "eval/model_loss_mean": 17.778202056884766, "eval/model_loss_std": 16.94996452331543, "eval/post_ent_mag": 56.698524475097656, "eval/post_ent_max": 56.698524475097656, "eval/post_ent_mean": 40.38417053222656, "eval/post_ent_min": 17.641521453857422, "eval/post_ent_std": 7.417248725891113, "eval/prior_ent_mag": 67.04582214355469, "eval/prior_ent_max": 67.04582214355469, "eval/prior_ent_mean": 54.600486755371094, "eval/prior_ent_min": 40.604583740234375, "eval/prior_ent_std": 3.784693479537964, "eval/rep_loss_mean": 16.36918830871582, "eval/rep_loss_std": 10.330845832824707, "eval/reward_avg": 0.04326172173023224, "eval/reward_loss_mean": 0.11075714230537415, "eval/reward_loss_std": 0.6017504930496216, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.005401849746704, "eval/reward_neg_acc": 0.9897645711898804, "eval/reward_neg_loss": 0.03994322195649147, "eval/reward_pos_acc": 0.8297871947288513, "eval/reward_pos_loss": 1.5827827453613281, "eval/reward_pred": 0.038608819246292114, "eval/reward_rate": 0.0458984375, "replay/size": 860753.0, "replay/inserts": 21024.0, "replay/samples": 21024.0, "replay/insert_wait_avg": 1.3920111380392739e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.903625794560217e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.124517271831454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2679195404053, "timer/env.step_count": 2628.0, "timer/env.step_total": 219.69366717338562, "timer/env.step_frac": 0.21963482271262746, "timer/env.step_avg": 0.08359728583462162, "timer/env.step_min": 0.023565053939819336, "timer/env.step_max": 3.358792304992676, "timer/replay._sample_count": 21024.0, "timer/replay._sample_total": 10.977266311645508, "timer/replay._sample_frac": 0.010974326075247169, "timer/replay._sample_avg": 0.0005221302469389986, "timer/replay._sample_min": 0.0004029273986816406, "timer/replay._sample_max": 0.011061906814575195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3215.0, "timer/agent.policy_total": 53.97990584373474, "timer/agent.policy_frac": 0.05396544744585728, "timer/agent.policy_avg": 0.016790017369746422, "timer/agent.policy_min": 0.009389162063598633, "timer/agent.policy_max": 0.15401744842529297, "timer/dataset_train_count": 1314.0, "timer/dataset_train_total": 0.15407609939575195, "timer/dataset_train_frac": 0.0001540348304547701, "timer/dataset_train_avg": 0.00011725730547621914, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.0003459453582763672, "timer/agent.train_count": 1314.0, "timer/agent.train_total": 587.5123257637024, "timer/agent.train_frac": 0.5873549618922574, "timer/agent.train_avg": 0.44711744730875375, "timer/agent.train_min": 0.4335470199584961, "timer/agent.train_max": 1.3666138648986816, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4729495048522949, "timer/agent.report_frac": 0.0004728228263779586, "timer/agent.report_avg": 0.23647475242614746, "timer/agent.report_min": 0.22873544692993164, "timer/agent.report_max": 0.24421405792236328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9555985182627396e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 21.018056550475087}
{"step": 861560, "time": 42345.47144818306, "episode/length": 248.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 861640, "time": 42350.57765340805, "episode/length": 245.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 861688, "time": 42354.34334564209, "episode/length": 241.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 861696, "time": 42356.86888241768, "episode/length": 92.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 861968, "time": 42369.31060171127, "episode/length": 366.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9863760217983651, "episode/intrinsic_return": 0.0}
{"step": 862032, "time": 42373.70868444443, "episode/length": 257.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 862720, "time": 42401.067279577255, "episode/length": 238.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 862864, "time": 42407.97885012627, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 863176, "time": 42420.868208646774, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 863376, "time": 42430.13542032242, "episode/length": 210.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 863448, "time": 42433.960663080215, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 863456, "time": 42436.00580620766, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 863832, "time": 42451.2101225853, "episode/length": 266.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 863888, "time": 42455.09127163887, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 864296, "time": 42471.508976221085, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 864584, "time": 42483.55347967148, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 864600, "time": 42485.56756448746, "episode/length": 143.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 864872, "time": 42497.268389463425, "episode/length": 211.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 865232, "time": 42512.37875318527, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 865296, "time": 42516.46881055832, "episode/length": 229.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 865480, "time": 42524.63621354103, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 866144, "time": 42551.50586652756, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 866152, "time": 42553.83699178696, "episode/length": 346.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 866304, "time": 42561.66633105278, "episode/length": 250.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 866672, "time": 42577.33879375458, "episode/length": 179.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 866680, "time": 42579.02390217781, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 866880, "time": 42588.057901620865, "episode/length": 174.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 866928, "time": 42591.32383656502, "episode/length": 203.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 867848, "time": 42626.519745111465, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 868320, "time": 42645.831062316895, "episode/length": 204.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 868528, "time": 42656.86390423775, "episode/length": 231.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 868672, "time": 42663.585904836655, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 868856, "time": 42671.69831824303, "episode/length": 318.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 868896, "time": 42674.934839725494, "episode/length": 536.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9981378026070763, "episode/intrinsic_return": 0.0}
{"step": 868928, "time": 42677.6148583889, "episode/length": 347.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.0}
{"step": 868984, "time": 42681.017397880554, "episode/length": 256.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 869528, "time": 42702.50121283531, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 869848, "time": 42715.746492385864, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 42740.21584749222, "eval_episode/length": 43.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 870064, "time": 42746.40254497528, "eval_episode/length": 160.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 870064, "time": 42748.312437295914, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 870064, "time": 42750.92394685745, "eval_episode/length": 193.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9587628865979382}
{"step": 870064, "time": 42755.08302783966, "eval_episode/length": 214.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 870064, "time": 42756.85595846176, "eval_episode/length": 260.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 870064, "time": 42759.79343223572, "eval_episode/length": 295.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9898648648648649}
{"step": 870064, "time": 42761.884491205215, "eval_episode/length": 140.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 870080, "time": 42762.4825835228, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 870232, "time": 42769.41784405708, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 870352, "time": 42775.572998046875, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 870768, "time": 42792.414185762405, "episode/length": 85.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 871024, "time": 42803.27079510689, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 871088, "time": 42807.19763183594, "episode/length": 278.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 871472, "time": 42822.80708909035, "episode/length": 321.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 872024, "time": 42844.340423583984, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 872152, "time": 42850.75298500061, "episode/length": 239.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 872528, "time": 42866.383804798126, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 872576, "time": 42869.643238306046, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 872632, "time": 42873.14877939224, "episode/length": 455.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 872720, "time": 42878.34279370308, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 873224, "time": 42897.953830480576, "episode/length": 149.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 873224, "time": 42898.005920410156, "episode/length": 421.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 874000, "time": 42929.913555145264, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 874136, "time": 42936.378022909164, "episode/length": 194.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 874296, "time": 42943.8225505352, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 874368, "time": 42948.21614527702, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 874496, "time": 42954.35180568695, "episode/length": 377.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 875168, "time": 42980.55162715912, "episode/length": 242.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 875240, "time": 42984.457560539246, "episode/length": 314.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 875272, "time": 42987.13950920105, "episode/length": 158.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 876520, "time": 43034.54670882225, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 876536, "time": 43036.69714140892, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 876560, "time": 43041.065928697586, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 876848, "time": 43053.12940311432, "episode/length": 526.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9867172675521821, "episode/intrinsic_return": 0.0}
{"step": 877328, "time": 43072.35837030411, "episode/length": 59.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 877336, "time": 43074.04563117027, "episode/length": 399.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 877384, "time": 43077.33811593056, "episode/length": 276.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 877776, "time": 43093.53757047653, "episode/length": 312.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 877904, "time": 43099.71352028847, "episode/length": 425.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9882629107981221, "episode/intrinsic_return": 0.0}
{"step": 878120, "time": 43108.857892513275, "episode/length": 197.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 878656, "time": 43130.37762641907, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 878840, "time": 43138.485664606094, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 879008, "time": 43146.55968666077, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 879048, "time": 43149.331729888916, "episode/length": 115.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 879600, "time": 43171.26064991951, "episode/length": 283.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 879632, "time": 43174.0656311512, "episode/length": 383.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 879824, "time": 43182.707867860794, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 879936, "time": 43188.2830247879, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 879960, "time": 43190.48955869675, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 43215.6513607502, "eval_episode/length": 193.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 880048, "time": 43217.899381160736, "eval_episode/length": 208.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 880048, "time": 43220.53826498985, "eval_episode/length": 229.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9826086956521739}
{"step": 880048, "time": 43224.03136396408, "eval_episode/length": 234.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 880048, "time": 43225.61892604828, "eval_episode/length": 235.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 880048, "time": 43228.4942483902, "eval_episode/length": 269.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9740740740740741}
{"step": 880048, "time": 43231.35520553589, "eval_episode/length": 301.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 880048, "time": 43236.11790704727, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 880384, "time": 43248.57817196846, "episode/length": 55.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 880480, "time": 43253.68428206444, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 880624, "time": 43260.476749420166, "episode/length": 222.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 881064, "time": 43278.164747714996, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 881552, "time": 43298.076204538345, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 881760, "time": 43307.31625056267, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 881760, "time": 43307.36152648926, "episode/length": 159.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 882312, "time": 43330.5409924984, "episode/length": 310.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 882328, "time": 43332.63042783737, "episode/length": 70.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 882329, "time": 43335.20544719696, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.554826343332538, "train/action_min": 0.0, "train/action_std": 3.43577499972045, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03968703213595707, "train/actor_opt_grad_steps": 54390.0, "train/actor_opt_loss": -0.9334563728962236, "train/adv_mag": 0.5341227313944401, "train/adv_max": 0.4769904713594276, "train/adv_mean": 0.0035001484305746803, "train/adv_min": -0.43799468624682825, "train/adv_std": 0.05760347081049708, "train/cont_avg": 0.9947593630725191, "train/cont_loss_mean": 0.00010869863981892341, "train/cont_loss_std": 0.0032592671810173232, "train/cont_neg_acc": 0.9954892442426608, "train/cont_neg_loss": 0.010061543855780801, "train/cont_pos_acc": 0.9999849846344868, "train/cont_pos_loss": 4.228711320661335e-05, "train/cont_pred": 0.9947628051270055, "train/cont_rate": 0.9947593630725191, "train/dyn_loss_mean": 12.163301475175464, "train/dyn_loss_std": 9.03201716182796, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8855857994720227, "train/extr_critic_critic_opt_grad_steps": 54390.0, "train/extr_critic_critic_opt_loss": 15581.441562798187, "train/extr_critic_mag": 8.10976503095554, "train/extr_critic_max": 8.10976503095554, "train/extr_critic_mean": 2.4495063465060167, "train/extr_critic_min": -0.24339172039323181, "train/extr_critic_std": 1.873927045414466, "train/extr_return_normed_mag": 1.5681506295240561, "train/extr_return_normed_max": 1.5681506295240561, "train/extr_return_normed_mean": 0.40365038459537594, "train/extr_return_normed_min": -0.1139651749084014, "train/extr_return_normed_std": 0.3226527664952606, "train/extr_return_rate": 0.8118345896706326, "train/extr_return_raw_mag": 9.34157664175252, "train/extr_return_raw_max": 9.34157664175252, "train/extr_return_raw_mean": 2.4701646229692997, "train/extr_return_raw_min": -0.5839103559273799, "train/extr_return_raw_std": 1.9038492850674928, "train/extr_reward_mag": 1.0362750974320274, "train/extr_reward_max": 1.0362750974320274, "train/extr_reward_mean": 0.03741096668229758, "train/extr_reward_min": -0.49374039846522205, "train/extr_reward_std": 0.1829796190025242, "train/image_loss_mean": 5.874615654690575, "train/image_loss_std": 11.540369321371763, "train/model_loss_mean": 13.227510364911028, "train/model_loss_std": 15.21790204521354, "train/model_opt_grad_norm": 53.94426224977916, "train/model_opt_grad_steps": 54341.70229007633, "train/model_opt_loss": 14162.540486343034, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1073.473282442748, "train/policy_entropy_mag": 2.6218601219526683, "train/policy_entropy_max": 2.6218601219526683, "train/policy_entropy_mean": 0.5539666248186854, "train/policy_entropy_min": 0.07937501842966517, "train/policy_entropy_std": 0.6100137183684429, "train/policy_logprob_mag": 7.438383619293912, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5548421403833927, "train/policy_logprob_min": -7.438383619293912, "train/policy_logprob_std": 1.1117535806794203, "train/policy_randomness_mag": 0.9254015656827971, "train/policy_randomness_max": 0.9254015656827971, "train/policy_randomness_mean": 0.19552591113188794, "train/policy_randomness_min": 0.028015898099837414, "train/policy_randomness_std": 0.2153080742777759, "train/post_ent_mag": 59.12822807836169, "train/post_ent_max": 59.12822807836169, "train/post_ent_mean": 42.7449150959044, "train/post_ent_min": 19.647395141252126, "train/post_ent_std": 7.704720711890068, "train/prior_ent_mag": 67.25266050382425, "train/prior_ent_max": 67.25266050382425, "train/prior_ent_mean": 54.96364022757261, "train/prior_ent_min": 39.86380074770396, "train/prior_ent_std": 4.267680384730565, "train/rep_loss_mean": 12.163301475175464, "train/rep_loss_std": 9.03201716182796, "train/reward_avg": 0.02874075616389968, "train/reward_loss_mean": 0.05480513256754129, "train/reward_loss_std": 0.2416559793339431, "train/reward_max_data": 1.0167938971337471, "train/reward_max_pred": 1.0112292957669906, "train/reward_neg_acc": 0.9926003900193076, "train/reward_neg_loss": 0.028726900934831788, "train/reward_pos_acc": 0.9729743508892205, "train/reward_pos_loss": 0.8116143650681008, "train/reward_pred": 0.02821144428928845, "train/reward_rate": 0.03350876669847328, "train_stats/sum_log_reward": 8.87528109818362, "train_stats/max_log_achievement_collect_coal": 0.3146067415730337, "train_stats/max_log_achievement_collect_drink": 6.01123595505618, "train_stats/max_log_achievement_collect_sapling": 1.6404494382022472, "train_stats/max_log_achievement_collect_stone": 3.943820224719101, "train_stats/max_log_achievement_collect_wood": 10.50561797752809, "train_stats/max_log_achievement_defeat_skeleton": 0.06741573033707865, "train_stats/max_log_achievement_defeat_zombie": 1.4382022471910112, "train_stats/max_log_achievement_eat_cow": 0.29213483146067415, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.02247191011235955, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6404494382022472, "train_stats/max_log_achievement_make_wood_sword": 1.0674157303370786, "train_stats/max_log_achievement_place_furnace": 0.15730337078651685, "train_stats/max_log_achievement_place_plant": 1.5842696629213484, "train_stats/max_log_achievement_place_stone": 2.393258426966292, "train_stats/max_log_achievement_place_table": 2.955056179775281, "train_stats/max_log_achievement_wake_up": 1.1573033707865168, "train_stats/mean_log_entropy": 0.6515678574195068, "eval_stats/sum_log_reward": 8.85000017285347, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 3.4375, "eval_stats/max_log_achievement_collect_wood": 9.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.375, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.7574654975760495e-06, "report/cont_loss_std": 3.195469980710186e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00035153355565853417, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.119408814062808e-08, "report/cont_pred": 0.9951188564300537, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.38699722290039, "report/dyn_loss_std": 8.926946640014648, "report/image_loss_mean": 4.999833106994629, "report/image_loss_std": 7.4994988441467285, "report/model_loss_mean": 11.88045883178711, "report/model_loss_std": 10.894301414489746, "report/post_ent_mag": 60.9617919921875, "report/post_ent_max": 60.9617919921875, "report/post_ent_mean": 42.934425354003906, "report/post_ent_min": 21.571910858154297, "report/post_ent_std": 8.117196083068848, "report/prior_ent_mag": 67.27469635009766, "report/prior_ent_max": 67.27469635009766, "report/prior_ent_mean": 54.555320739746094, "report/prior_ent_min": 43.19038391113281, "report/prior_ent_std": 4.763011932373047, "report/rep_loss_mean": 11.38699722290039, "report/rep_loss_std": 8.926946640014648, "report/reward_avg": 0.0263671875, "report/reward_loss_mean": 0.048425380140542984, "report/reward_loss_std": 0.18565477430820465, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023434162139893, "report/reward_neg_acc": 0.9959717988967896, "report/reward_neg_loss": 0.025161808356642723, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.793610155582428, "report/reward_pred": 0.023754317313432693, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 5.559846613323316e-06, "eval/cont_loss_std": 0.0001589621533639729, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00018963539332617074, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.3799094530404545e-06, "eval/cont_pred": 0.9990183115005493, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.459732055664062, "eval/dyn_loss_std": 10.821170806884766, "eval/image_loss_mean": 11.849514961242676, "eval/image_loss_std": 15.841148376464844, "eval/model_loss_mean": 22.47007942199707, "eval/model_loss_std": 20.548418045043945, "eval/post_ent_mag": 60.14116668701172, "eval/post_ent_max": 60.14116668701172, "eval/post_ent_mean": 40.86594772338867, "eval/post_ent_min": 19.479400634765625, "eval/post_ent_std": 7.95072603225708, "eval/prior_ent_mag": 67.27469635009766, "eval/prior_ent_max": 67.27469635009766, "eval/prior_ent_mean": 55.792938232421875, "eval/prior_ent_min": 42.78217315673828, "eval/prior_ent_std": 4.02101469039917, "eval/rep_loss_mean": 17.459732055664062, "eval/rep_loss_std": 10.821170806884766, "eval/reward_avg": 0.03681640699505806, "eval/reward_loss_mean": 0.1447179764509201, "eval/reward_loss_std": 0.7941311001777649, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0085020065307617, "eval/reward_neg_acc": 0.9959308505058289, "eval/reward_neg_loss": 0.040942445397377014, "eval/reward_pos_acc": 0.6585365533828735, "eval/reward_pos_loss": 2.6327998638153076, "eval/reward_pred": 0.020438849925994873, "eval/reward_rate": 0.0400390625, "replay/size": 881825.0, "replay/inserts": 21072.0, "replay/samples": 21072.0, "replay/insert_wait_avg": 1.401331448247239e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.92216783956587e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1099224117980607e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2877130508423, "timer/env.step_count": 2634.0, "timer/env.step_total": 213.09040355682373, "timer/env.step_frac": 0.21281635715628086, "timer/env.step_avg": 0.08089992542020642, "timer/env.step_min": 0.02357006072998047, "timer/env.step_max": 3.217393159866333, "timer/replay._sample_count": 21072.0, "timer/replay._sample_total": 11.062512397766113, "timer/replay._sample_frac": 0.011048285376497368, "timer/replay._sample_avg": 0.0005249863514505559, "timer/replay._sample_min": 0.000408172607421875, "timer/replay._sample_max": 0.0111846923828125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3330.0, "timer/agent.policy_total": 54.1371808052063, "timer/agent.policy_frac": 0.05406755730603615, "timer/agent.policy_avg": 0.016257411653215106, "timer/agent.policy_min": 0.00946044921875, "timer/agent.policy_max": 0.11261773109436035, "timer/dataset_train_count": 1317.0, "timer/dataset_train_total": 0.15643095970153809, "timer/dataset_train_frac": 0.00015622978057416251, "timer/dataset_train_avg": 0.00011877825338005929, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0003025531768798828, "timer/agent.train_count": 1317.0, "timer/agent.train_total": 588.8470942974091, "timer/agent.train_frac": 0.5880898033825261, "timer/agent.train_avg": 0.4471124482136743, "timer/agent.train_min": 0.4364147186279297, "timer/agent.train_max": 1.423870325088501, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47161221504211426, "timer/agent.report_frac": 0.00047100569486181965, "timer/agent.report_avg": 0.23580610752105713, "timer/agent.report_min": 0.22915363311767578, "timer/agent.report_max": 0.24245858192443848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.833532314766885e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 21.04458993318829}
{"step": 882952, "time": 43358.11181139946, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 883096, "time": 43364.930577754974, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 883184, "time": 43369.876183748245, "episode/length": 108.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 883296, "time": 43375.490978717804, "episode/length": 217.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 883400, "time": 43380.62249135971, "episode/length": 592.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9983136593591906, "episode/intrinsic_return": 0.0}
{"step": 883496, "time": 43385.602811574936, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 883496, "time": 43385.64839577675, "episode/length": 388.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897172236503856, "episode/intrinsic_return": 0.0}
{"step": 883888, "time": 43403.713604688644, "episode/length": 407.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 884104, "time": 43413.077093839645, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 884176, "time": 43418.07307720184, "episode/length": 35.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 884296, "time": 43424.442106962204, "episode/length": 99.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 884512, "time": 43434.86193275452, "episode/length": 41.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 885096, "time": 43459.662484407425, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 885176, "time": 43464.22589302063, "episode/length": 248.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 885280, "time": 43470.0061981678, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 885320, "time": 43472.83175802231, "episode/length": 151.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 885400, "time": 43477.39854264259, "episode/length": 110.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 885608, "time": 43486.648720026016, "episode/length": 263.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 886232, "time": 43511.07922935486, "episode/length": 131.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 886312, "time": 43515.516229867935, "episode/length": 363.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 886872, "time": 43537.6372628212, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 887120, "time": 43548.45399427414, "episode/length": 188.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 887216, "time": 43553.4279127121, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9647577092511013, "episode/intrinsic_return": 0.0}
{"step": 887496, "time": 43564.97644948959, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 887520, "time": 43567.6451792717, "episode/length": 402.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9925558312655087, "episode/intrinsic_return": 0.0}
{"step": 887528, "time": 43569.296651124954, "episode/length": 151.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 888456, "time": 43604.904472351074, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974811083123426, "episode/intrinsic_return": 0.0}
{"step": 888464, "time": 43606.9321770668, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 888576, "time": 43612.561443567276, "episode/length": 130.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 888696, "time": 43618.276782512665, "episode/length": 227.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 888832, "time": 43625.116918087006, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 888888, "time": 43628.72107410431, "episode/length": 331.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9909638554216867, "episode/intrinsic_return": 0.0}
{"step": 889264, "time": 43644.263976335526, "episode/length": 220.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 889312, "time": 43647.63585138321, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 43693.69942045212, "eval_episode/length": 125.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9920634920634921}
{"step": 890032, "time": 43697.96997308731, "eval_episode/length": 189.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 890032, "time": 43700.624393463135, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 890032, "time": 43702.803247213364, "eval_episode/length": 229.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 890032, "time": 43704.49948477745, "eval_episode/length": 231.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 890032, "time": 43706.21703839302, "eval_episode/length": 234.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9744680851063829}
{"step": 890032, "time": 43707.68332195282, "eval_episode/length": 235.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 890032, "time": 43709.340942144394, "eval_episode/length": 47.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 890376, "time": 43721.99167537689, "episode/length": 185.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 890416, "time": 43725.29431295395, "episode/length": 243.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 890592, "time": 43733.248059272766, "episode/length": 219.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 890728, "time": 43739.632085084915, "episode/length": 253.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 890864, "time": 43746.579780101776, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 891064, "time": 43755.26776123047, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 891208, "time": 43762.068273067474, "episode/length": 328.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 891904, "time": 43789.36171293259, "episode/length": 146.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 892272, "time": 43804.599643707275, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 892384, "time": 43810.37910437584, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 892464, "time": 43814.898851156235, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 892512, "time": 43818.300054073334, "episode/length": 399.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 892576, "time": 43822.127655506134, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 892736, "time": 43829.5085811615, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 892880, "time": 43836.4817276001, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 893112, "time": 43848.02811741829, "episode/length": 104.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 893216, "time": 43853.65618085861, "episode/length": 93.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 893304, "time": 43858.24743390083, "episode/length": 174.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 893512, "time": 43867.540751218796, "episode/length": 124.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 893808, "time": 43880.10032224655, "episode/length": 177.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 894032, "time": 43889.82578372955, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 894168, "time": 43896.022169828415, "episode/length": 81.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 894344, "time": 43904.207352638245, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 894768, "time": 43921.41262078285, "episode/length": 74.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 894816, "time": 43924.62228488922, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 895016, "time": 43933.40061831474, "episode/length": 237.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 895112, "time": 43938.41217279434, "episode/length": 95.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 895128, "time": 43940.476770401, "episode/length": 238.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 895168, "time": 43943.70292401314, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 895456, "time": 43955.554186582565, "episode/length": 205.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 895472, "time": 43957.7784307003, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 896064, "time": 43980.81700134277, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 896528, "time": 43999.56349945068, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 896536, "time": 44001.242164850235, "episode/length": 177.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 896712, "time": 44009.24716210365, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 896952, "time": 44019.741778850555, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 897056, "time": 44025.20616436005, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 897200, "time": 44032.119117975235, "episode/length": 217.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 898144, "time": 44068.47645235062, "episode/length": 415.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 898360, "time": 44077.98277926445, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 898760, "time": 44094.12097239494, "episode/length": 278.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 898992, "time": 44104.33500504494, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 899016, "time": 44106.63546872139, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 899224, "time": 44115.80124783516, "episode/length": 394.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9924050632911392, "episode/intrinsic_return": 0.0}
{"step": 899464, "time": 44126.08372974396, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 899744, "time": 44138.11415672302, "episode/length": 400.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 899768, "time": 44140.33094573021, "episode/length": 37.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 44169.77653169632, "eval_episode/length": 147.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 900016, "time": 44172.893527030945, "eval_episode/length": 185.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 900016, "time": 44175.566633701324, "eval_episode/length": 212.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 900016, "time": 44177.299164772034, "eval_episode/length": 216.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 900016, "time": 44180.063477277756, "eval_episode/length": 247.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 900016, "time": 44182.664556741714, "eval_episode/length": 272.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9963369963369964}
{"step": 900016, "time": 44185.46582722664, "eval_episode/length": 304.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9901639344262295}
{"step": 900016, "time": 44188.59874486923, "eval_episode/length": 197.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 900096, "time": 44191.54300928116, "episode/length": 134.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 900800, "time": 44219.06090402603, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 900840, "time": 44221.78684616089, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 901024, "time": 44230.495354413986, "episode/length": 359.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 901136, "time": 44237.863367557526, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 901152, "time": 44240.05125570297, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 901320, "time": 44247.4807305336, "episode/length": 64.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 901408, "time": 44252.48087620735, "episode/length": 301.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 901560, "time": 44259.4620923996, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 901896, "time": 44273.267887830734, "episode/length": 131.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 901920, "time": 44275.934435367584, "episode/length": 268.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 902160, "time": 44286.265867471695, "episode/length": 127.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 902608, "time": 44304.21825480461, "episode/length": 197.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 902752, "time": 44311.02963089943, "episode/length": 167.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 903353, "time": 44335.488441467285, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.370345144560843, "train/action_min": 0.0, "train/action_std": 3.366055712555394, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03850676621677297, "train/actor_opt_grad_steps": 55705.0, "train/actor_opt_loss": -1.3551607209003784, "train/adv_mag": 0.5157503677588521, "train/adv_max": 0.45594865602977347, "train/adv_mean": 0.0039468771565225325, "train/adv_min": -0.42575549943880603, "train/adv_std": 0.05588927221569148, "train/cont_avg": 0.9947028882575758, "train/cont_loss_mean": 0.00027212149162765667, "train/cont_loss_std": 0.008363510015771446, "train/cont_neg_acc": 0.9886041456506452, "train/cont_neg_loss": 0.03411868313569288, "train/cont_pos_acc": 0.9999850893562491, "train/cont_pos_loss": 6.783840572099572e-05, "train/cont_pred": 0.994739496346676, "train/cont_rate": 0.9947028882575758, "train/dyn_loss_mean": 12.349213860251687, "train/dyn_loss_std": 8.986495870532412, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9404776597564871, "train/extr_critic_critic_opt_grad_steps": 55705.0, "train/extr_critic_critic_opt_loss": 15592.074588660038, "train/extr_critic_mag": 8.177127650289824, "train/extr_critic_max": 8.177127650289824, "train/extr_critic_mean": 2.6016927316333307, "train/extr_critic_min": -0.2428597193775755, "train/extr_critic_std": 1.9450045959516005, "train/extr_return_normed_mag": 1.53471819469423, "train/extr_return_normed_max": 1.53471819469423, "train/extr_return_normed_mean": 0.4127321807724057, "train/extr_return_normed_min": -0.11542487737130035, "train/extr_return_normed_std": 0.32803906658382126, "train/extr_return_rate": 0.8276648742683006, "train/extr_return_raw_mag": 9.400244066209504, "train/extr_return_raw_max": 9.400244066209504, "train/extr_return_raw_mean": 2.6255448722478114, "train/extr_return_raw_min": -0.5645144512933312, "train/extr_return_raw_std": 1.9816524440591985, "train/extr_reward_mag": 1.0387913819515344, "train/extr_reward_max": 1.0387913819515344, "train/extr_reward_mean": 0.039572087709199295, "train/extr_reward_min": -0.49324927546761255, "train/extr_reward_std": 0.18756487254392018, "train/image_loss_mean": 6.020691320751652, "train/image_loss_std": 10.970086523980806, "train/model_loss_mean": 13.487665913321756, "train/model_loss_std": 14.623992522557577, "train/model_opt_grad_norm": 55.31720937382091, "train/model_opt_grad_steps": 55655.969696969696, "train/model_opt_loss": 12797.468487363873, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 951.7045454545455, "train/policy_entropy_mag": 2.623114677992734, "train/policy_entropy_max": 2.623114677992734, "train/policy_entropy_mean": 0.5222466996673382, "train/policy_entropy_min": 0.07937501641837033, "train/policy_entropy_std": 0.5942499208630938, "train/policy_logprob_mag": 7.438383676789024, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5219274788643374, "train/policy_logprob_min": -7.438383676789024, "train/policy_logprob_std": 1.0909210818283486, "train/policy_randomness_mag": 0.9258443704157164, "train/policy_randomness_max": 0.9258443704157164, "train/policy_randomness_mean": 0.18433016854705234, "train/policy_randomness_min": 0.028015897482294928, "train/policy_randomness_std": 0.20974414660172028, "train/post_ent_mag": 58.769129955407344, "train/post_ent_max": 58.769129955407344, "train/post_ent_mean": 42.61950042031028, "train/post_ent_min": 19.71595207127658, "train/post_ent_std": 7.648466742399967, "train/prior_ent_mag": 67.19430281899191, "train/prior_ent_max": 67.19430281899191, "train/prior_ent_mean": 55.017741376703434, "train/prior_ent_min": 39.425584157307945, "train/prior_ent_std": 4.314287317521645, "train/rep_loss_mean": 12.349213860251687, "train/rep_loss_std": 8.986495870532412, "train/reward_avg": 0.0298916899570913, "train/reward_loss_mean": 0.05717422945820021, "train/reward_loss_std": 0.2500743211218805, "train/reward_max_data": 1.0227272781458767, "train/reward_max_pred": 1.0114663776123163, "train/reward_neg_acc": 0.9923098123434818, "train/reward_neg_loss": 0.02900832045512895, "train/reward_pos_acc": 0.9664133498162935, "train/reward_pos_loss": 0.8410546165524106, "train/reward_pred": 0.029037109540888305, "train/reward_rate": 0.034734552556818184, "train_stats/sum_log_reward": 9.131579175748323, "train_stats/max_log_achievement_collect_coal": 0.4, "train_stats/max_log_achievement_collect_drink": 4.2, "train_stats/max_log_achievement_collect_sapling": 1.4105263157894736, "train_stats/max_log_achievement_collect_stone": 8.68421052631579, "train_stats/max_log_achievement_collect_wood": 10.105263157894736, "train_stats/max_log_achievement_defeat_skeleton": 0.1368421052631579, "train_stats/max_log_achievement_defeat_zombie": 1.0526315789473684, "train_stats/max_log_achievement_eat_cow": 0.2, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010526315789473684, "train_stats/max_log_achievement_make_wood_pickaxe": 1.263157894736842, "train_stats/max_log_achievement_make_wood_sword": 1.0947368421052632, "train_stats/max_log_achievement_place_furnace": 0.22105263157894736, "train_stats/max_log_achievement_place_plant": 1.368421052631579, "train_stats/max_log_achievement_place_stone": 6.421052631578948, "train_stats/max_log_achievement_place_table": 2.8, "train_stats/max_log_achievement_wake_up": 1.0526315789473684, "train_stats/mean_log_entropy": 0.6037435064190313, "eval_stats/sum_log_reward": 9.475000217556953, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_sapling": 1.0625, "eval_stats/max_log_achievement_collect_stone": 8.75, "eval_stats/max_log_achievement_collect_wood": 10.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.4375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.3125, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 6.1875, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.000277422193903476, "report/cont_loss_std": 0.008804111741483212, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.704203067580238e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002791574806906283, "report/cont_pred": 0.9919463992118835, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.288410186767578, "report/dyn_loss_std": 8.606637954711914, "report/image_loss_mean": 6.521218776702881, "report/image_loss_std": 9.141847610473633, "report/model_loss_mean": 14.569896697998047, "report/model_loss_std": 12.343706130981445, "report/post_ent_mag": 56.69456481933594, "report/post_ent_max": 56.69456481933594, "report/post_ent_mean": 40.666473388671875, "report/post_ent_min": 19.905094146728516, "report/post_ent_std": 7.149716377258301, "report/prior_ent_mag": 67.17488098144531, "report/prior_ent_max": 67.17488098144531, "report/prior_ent_mean": 54.12433624267578, "report/prior_ent_min": 37.80432891845703, "report/prior_ent_std": 4.835993766784668, "report/rep_loss_mean": 13.288410186767578, "report/rep_loss_std": 8.606637954711914, "report/reward_avg": 0.04160156100988388, "report/reward_loss_mean": 0.07535439729690552, "report/reward_loss_std": 0.2614978551864624, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018317699432373, "report/reward_neg_acc": 0.9979487061500549, "report/reward_neg_loss": 0.03800492733716965, "report/reward_pos_acc": 0.9591836333274841, "report/reward_pos_loss": 0.8185325860977173, "report/reward_pred": 0.038447700440883636, "report/reward_rate": 0.0478515625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00022601928503718227, "eval/cont_loss_std": 0.006101888604462147, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.036752987653017044, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0732632290455513e-05, "eval/cont_pred": 0.994327962398529, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.406742095947266, "eval/dyn_loss_std": 10.583906173706055, "eval/image_loss_mean": 9.237768173217773, "eval/image_loss_std": 11.218439102172852, "eval/model_loss_mean": 19.196949005126953, "eval/model_loss_std": 15.507516860961914, "eval/post_ent_mag": 56.144508361816406, "eval/post_ent_max": 56.144508361816406, "eval/post_ent_mean": 40.272396087646484, "eval/post_ent_min": 20.051942825317383, "eval/post_ent_std": 7.2419023513793945, "eval/prior_ent_mag": 67.17488098144531, "eval/prior_ent_max": 67.17488098144531, "eval/prior_ent_mean": 54.464111328125, "eval/prior_ent_min": 35.82672119140625, "eval/prior_ent_std": 4.470243453979492, "eval/rep_loss_mean": 16.406742095947266, "eval/rep_loss_std": 10.583906173706055, "eval/reward_avg": 0.0498046875, "eval/reward_loss_mean": 0.1149107813835144, "eval/reward_loss_std": 0.6492659449577332, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010020732879639, "eval/reward_neg_acc": 0.9834882020950317, "eval/reward_neg_loss": 0.0569877102971077, "eval/reward_pos_acc": 0.9272726774215698, "eval/reward_pos_loss": 1.135409951210022, "eval/reward_pred": 0.04856985807418823, "eval/reward_rate": 0.0537109375, "replay/size": 902849.0, "replay/inserts": 21024.0, "replay/samples": 21024.0, "replay/insert_wait_avg": 1.3924647502521764e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.79793414895393e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1010529243782776e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2681746482849, "timer/env.step_count": 2628.0, "timer/env.step_total": 219.3268654346466, "timer/env.step_frac": 0.2192680632988913, "timer/env.step_avg": 0.08345771135260525, "timer/env.step_min": 0.02342057228088379, "timer/env.step_max": 3.5789458751678467, "timer/replay._sample_count": 21024.0, "timer/replay._sample_total": 10.975642204284668, "timer/replay._sample_frac": 0.010972699604427514, "timer/replay._sample_avg": 0.0005220529967791414, "timer/replay._sample_min": 0.0003986358642578125, "timer/replay._sample_max": 0.011214256286621094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3212.0, "timer/agent.policy_total": 52.84285116195679, "timer/agent.policy_frac": 0.052828683848246426, "timer/agent.policy_avg": 0.016451697123896884, "timer/agent.policy_min": 0.009510040283203125, "timer/agent.policy_max": 0.10994672775268555, "timer/dataset_train_count": 1314.0, "timer/dataset_train_total": 0.15499114990234375, "timer/dataset_train_frac": 0.000154949596348841, "timer/dataset_train_avg": 0.00011795369094546709, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0003662109375, "timer/agent.train_count": 1314.0, "timer/agent.train_total": 586.6586105823517, "timer/agent.train_frac": 0.5865013257955878, "timer/agent.train_avg": 0.4464677401692174, "timer/agent.train_min": 0.4331018924713135, "timer/agent.train_max": 1.5162005424499512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47196412086486816, "timer/agent.report_frac": 0.0004718375859861987, "timer/agent.report_avg": 0.23598206043243408, "timer/agent.report_min": 0.23026061058044434, "timer/agent.report_max": 0.24170351028442383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027104161995879e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.0180521820363}
{"step": 903488, "time": 44340.4889216423, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 903528, "time": 44343.305193185806, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 903728, "time": 44352.39721035957, "episode/length": 225.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 903880, "time": 44359.36407852173, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 904120, "time": 44369.644805669785, "episode/length": 319.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 904432, "time": 44382.87776851654, "episode/length": 117.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 904512, "time": 44387.35806155205, "episode/length": 219.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 904648, "time": 44393.683049201965, "episode/length": 415.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 904856, "time": 44402.76523280144, "episode/length": 140.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 905520, "time": 44428.85882616043, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 905600, "time": 44433.35358333588, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 905816, "time": 44442.81148028374, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9900249376558603, "episode/intrinsic_return": 0.0}
{"step": 906032, "time": 44452.53513932228, "episode/length": 189.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 906104, "time": 44456.62708067894, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 906288, "time": 44465.12501502037, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 906344, "time": 44468.568930864334, "episode/length": 277.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 906352, "time": 44470.669972896576, "episode/length": 186.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 906592, "time": 44480.77256011963, "episode/length": 69.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 906896, "time": 44493.59953093529, "episode/length": 98.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 907168, "time": 44505.37474775314, "episode/length": 205.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 907240, "time": 44509.326162815094, "episode/length": 177.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 907640, "time": 44525.622174263, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 907864, "time": 44535.64474081993, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 907904, "time": 44538.860226631165, "episode/length": 163.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 907960, "time": 44542.29485011101, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 908344, "time": 44558.07349944115, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9737609329446064, "episode/intrinsic_return": 0.0}
{"step": 908512, "time": 44566.06741189957, "episode/length": 108.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 908552, "time": 44568.90089273453, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 908928, "time": 44584.37591671944, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 909352, "time": 44603.390129327774, "episode/length": 104.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 909360, "time": 44605.96470952034, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 909368, "time": 44607.876019239426, "episode/length": 274.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 909880, "time": 44629.38681578636, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 44660.69715356827, "eval_episode/length": 177.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 910000, "time": 44663.74234247208, "eval_episode/length": 197.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 910000, "time": 44666.40966677666, "eval_episode/length": 209.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 910000, "time": 44668.736560344696, "eval_episode/length": 217.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 910000, "time": 44671.45471787453, "eval_episode/length": 231.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 910000, "time": 44674.822459220886, "eval_episode/length": 259.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9769230769230769}
{"step": 910000, "time": 44679.8301551342, "eval_episode/length": 293.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9863945578231292}
{"step": 910000, "time": 44683.70773935318, "eval_episode/length": 145.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 910424, "time": 44699.59670114517, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746031746031746, "episode/intrinsic_return": 0.0}
{"step": 910800, "time": 44716.22046995163, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 911000, "time": 44724.90211081505, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 911520, "time": 44745.71508145332, "episode/length": 268.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 911576, "time": 44749.130266189575, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 911608, "time": 44751.95037603378, "episode/length": 280.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 911632, "time": 44754.62797999382, "episode/length": 458.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 911728, "time": 44759.69570660591, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 912232, "time": 44779.51709508896, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 912512, "time": 44791.5067615509, "episode/length": 188.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 912816, "time": 44804.283348321915, "episode/length": 72.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 912856, "time": 44807.715572595596, "episode/length": 256.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 913000, "time": 44815.38855910301, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 913048, "time": 44818.73762059212, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 913232, "time": 44827.26779937744, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 913480, "time": 44837.623990535736, "episode/length": 218.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 913600, "time": 44843.70482516289, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 913656, "time": 44846.94962787628, "episode/length": 104.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 914352, "time": 44874.32722425461, "episode/length": 229.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 914536, "time": 44882.379608392715, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 915032, "time": 44902.2311706543, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9889705882352942, "episode/intrinsic_return": 0.0}
{"step": 915176, "time": 44909.12197422981, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 915192, "time": 44911.280126571655, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 915360, "time": 44919.37256407738, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 915504, "time": 44926.258016586304, "episode/length": 143.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 915736, "time": 44936.57400178909, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 915752, "time": 44938.63427233696, "episode/length": 261.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 916136, "time": 44954.26941919327, "episode/length": 49.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 916816, "time": 44981.015580654144, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 916888, "time": 44984.92909002304, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 916928, "time": 44988.15590929985, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.0}
{"step": 916968, "time": 44990.99888801575, "episode/length": 303.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 917144, "time": 44999.23913168907, "episode/length": 243.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 917168, "time": 45002.36900925636, "episode/length": 176.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 917384, "time": 45012.51565885544, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 917704, "time": 45028.159057855606, "episode/length": 91.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 918000, "time": 45040.972828388214, "episode/length": 147.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 918040, "time": 45043.83087229729, "episode/length": 138.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 918128, "time": 45048.79338979721, "episode/length": 119.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 918144, "time": 45050.975824832916, "episode/length": 124.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 918240, "time": 45056.02597284317, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 918320, "time": 45060.52183890343, "episode/length": 178.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 919168, "time": 45093.383415699005, "episode/length": 222.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 919528, "time": 45108.94766449928, "episode/length": 190.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 919760, "time": 45119.31306052208, "episode/length": 256.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 919856, "time": 45124.37615132332, "episode/length": 213.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 919904, "time": 45128.36989760399, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 919984, "time": 45133.28720712662, "episode/length": 217.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 45155.945111989975, "eval_episode/length": 127.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9921875}
{"step": 920088, "time": 45158.88861203194, "eval_episode/length": 158.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 920088, "time": 45160.63301682472, "eval_episode/length": 164.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 920088, "time": 45163.42167019844, "eval_episode/length": 195.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 920088, "time": 45165.31594491005, "eval_episode/length": 203.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 920088, "time": 45167.945306539536, "eval_episode/length": 231.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 920088, "time": 45171.53197431564, "eval_episode/length": 87.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 920088, "time": 45174.18113899231, "eval_episode/length": 311.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9775641025641025}
{"step": 920536, "time": 45190.68909454346, "episode/length": 311.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 920632, "time": 45195.698457956314, "episode/length": 312.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 920816, "time": 45204.22191476822, "episode/length": 131.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 921008, "time": 45212.784360170364, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 921136, "time": 45219.17243075371, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 921248, "time": 45224.828721284866, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 921448, "time": 45233.46175956726, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 921912, "time": 45252.02393436432, "episode/length": 96.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 921952, "time": 45255.350610256195, "episode/length": 261.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 922336, "time": 45270.863285541534, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 922528, "time": 45279.656000852585, "episode/length": 248.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 922664, "time": 45285.93341064453, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 922736, "time": 45290.30338549614, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 922768, "time": 45293.05712771416, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 923264, "time": 45312.74416422844, "episode/length": 226.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 923720, "time": 45330.72971487045, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 923785, "time": 45335.69904446602, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.728971004486084, "train/action_min": 0.0, "train/action_std": 3.658554559573531, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03749596308625769, "train/actor_opt_grad_steps": 57005.0, "train/actor_opt_loss": -5.215464324108325, "train/adv_mag": 0.5487162407953292, "train/adv_max": 0.4839262547902763, "train/adv_mean": 0.002536999882725155, "train/adv_min": -0.44169173552654684, "train/adv_std": 0.054243236809270456, "train/cont_avg": 0.9950637817382812, "train/cont_loss_mean": 0.00013898413424612288, "train/cont_loss_std": 0.004198960897326298, "train/cont_neg_acc": 0.994140625, "train/cont_neg_loss": 0.013661426914209684, "train/cont_pos_acc": 0.9999692714773118, "train/cont_pos_loss": 8.385986161335568e-05, "train/cont_pred": 0.9950488088652492, "train/cont_rate": 0.9950637817382812, "train/dyn_loss_mean": 12.45017646998167, "train/dyn_loss_std": 9.002663481980562, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9061819277703762, "train/extr_critic_critic_opt_grad_steps": 57005.0, "train/extr_critic_critic_opt_loss": 15480.647071838379, "train/extr_critic_mag": 8.516697503626347, "train/extr_critic_max": 8.516697503626347, "train/extr_critic_mean": 2.665778855793178, "train/extr_critic_min": -0.24120399449020624, "train/extr_critic_std": 1.9908801531419158, "train/extr_return_normed_mag": 1.5261564226821065, "train/extr_return_normed_max": 1.5261564226821065, "train/extr_return_normed_mean": 0.39727196865715086, "train/extr_return_normed_min": -0.12507678009569645, "train/extr_return_normed_std": 0.32492307806387544, "train/extr_return_rate": 0.8691894970834255, "train/extr_return_raw_mag": 9.692635744810104, "train/extr_return_raw_max": 9.692635744810104, "train/extr_return_raw_mean": 2.681558193638921, "train/extr_return_raw_min": -0.5622651167213917, "train/extr_return_raw_std": 2.018207708373666, "train/extr_reward_mag": 1.0425676368176937, "train/extr_reward_max": 1.0425676368176937, "train/extr_reward_mean": 0.03943658640491776, "train/extr_reward_min": -0.49316498823463917, "train/extr_reward_std": 0.1872460531303659, "train/image_loss_mean": 6.043151371181011, "train/image_loss_std": 11.514348771423101, "train/model_loss_mean": 13.569931454956532, "train/model_loss_std": 15.162229515612125, "train/model_opt_grad_norm": 48.84697189927101, "train/model_opt_grad_steps": 56955.0, "train/model_opt_loss": 10572.08479309082, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 781.25, "train/policy_entropy_mag": 2.5593840535730124, "train/policy_entropy_max": 2.5593840535730124, "train/policy_entropy_mean": 0.5375055426266044, "train/policy_entropy_min": 0.07937501941341907, "train/policy_entropy_std": 0.6100909821689129, "train/policy_logprob_mag": 7.438383676111698, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.537888205377385, "train/policy_logprob_min": -7.438383676111698, "train/policy_logprob_std": 1.0999628850258887, "train/policy_randomness_mag": 0.9033502535894513, "train/policy_randomness_max": 0.9033502535894513, "train/policy_randomness_mean": 0.18971586972475052, "train/policy_randomness_min": 0.028015898482408375, "train/policy_randomness_std": 0.21533534466288984, "train/post_ent_mag": 58.82425957918167, "train/post_ent_max": 58.82425957918167, "train/post_ent_mean": 42.54678812623024, "train/post_ent_min": 19.573100209236145, "train/post_ent_std": 7.5883278623223305, "train/prior_ent_mag": 67.40107029676437, "train/prior_ent_max": 67.40107029676437, "train/prior_ent_mean": 55.07797047495842, "train/prior_ent_min": 39.18773566186428, "train/prior_ent_std": 4.358606547117233, "train/rep_loss_mean": 12.45017646998167, "train/rep_loss_std": 9.002663481980562, "train/reward_avg": 0.028946685924893245, "train/reward_loss_mean": 0.05653521468047984, "train/reward_loss_std": 0.2506806586170569, "train/reward_max_data": 1.0234375055879354, "train/reward_max_pred": 1.0152973784133792, "train/reward_neg_acc": 0.9922614609822631, "train/reward_neg_loss": 0.02913002943387255, "train/reward_pos_acc": 0.9699463467113674, "train/reward_pos_loss": 0.8418828179128468, "train/reward_pred": 0.028050656255800277, "train/reward_rate": 0.03359222412109375, "train_stats/sum_log_reward": 9.460824959056893, "train_stats/max_log_achievement_collect_coal": 0.6082474226804123, "train_stats/max_log_achievement_collect_drink": 4.092783505154639, "train_stats/max_log_achievement_collect_sapling": 1.5051546391752577, "train_stats/max_log_achievement_collect_stone": 8.154639175257731, "train_stats/max_log_achievement_collect_wood": 10.391752577319588, "train_stats/max_log_achievement_defeat_skeleton": 0.10309278350515463, "train_stats/max_log_achievement_defeat_zombie": 1.0824742268041236, "train_stats/max_log_achievement_eat_cow": 0.10309278350515463, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.020618556701030927, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3402061855670102, "train_stats/max_log_achievement_make_wood_sword": 1.0103092783505154, "train_stats/max_log_achievement_place_furnace": 0.5360824742268041, "train_stats/max_log_achievement_place_plant": 1.4845360824742269, "train_stats/max_log_achievement_place_stone": 4.34020618556701, "train_stats/max_log_achievement_place_table": 2.814432989690722, "train_stats/max_log_achievement_wake_up": 1.092783505154639, "train_stats/mean_log_entropy": 0.5907892713841704, "eval_stats/sum_log_reward": 8.975000321865082, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.6875, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 6.0625, "eval_stats/max_log_achievement_collect_wood": 7.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.5625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.0625, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.368008937191917e-06, "report/cont_loss_std": 8.31189172458835e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.08966763340868e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.11887696525082e-06, "report/cont_pred": 0.9960869550704956, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.703544616699219, "report/dyn_loss_std": 8.661145210266113, "report/image_loss_mean": 4.615675926208496, "report/image_loss_std": 8.609525680541992, "report/model_loss_mean": 11.085058212280273, "report/model_loss_std": 12.061930656433105, "report/post_ent_mag": 61.884403228759766, "report/post_ent_max": 61.884403228759766, "report/post_ent_mean": 43.99617004394531, "report/post_ent_min": 20.26321029663086, "report/post_ent_std": 7.7064666748046875, "report/prior_ent_mag": 67.0926513671875, "report/prior_ent_max": 67.0926513671875, "report/prior_ent_mean": 55.3515739440918, "report/prior_ent_min": 41.233341217041016, "report/prior_ent_std": 4.29592227935791, "report/rep_loss_mean": 10.703544616699219, "report/rep_loss_std": 8.661145210266113, "report/reward_avg": 0.02392578125, "report/reward_loss_mean": 0.04724942147731781, "report/reward_loss_std": 0.20391695201396942, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0031425952911377, "report/reward_neg_acc": 0.9899497628211975, "report/reward_neg_loss": 0.027818072587251663, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7139456868171692, "report/reward_pred": 0.025459524244070053, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.183065953431651e-05, "eval/cont_loss_std": 0.0005476936348713934, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004407252185046673, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.632926447811769e-06, "eval/cont_pred": 0.9961062073707581, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.876026153564453, "eval/dyn_loss_std": 10.257112503051758, "eval/image_loss_mean": 9.78738021850586, "eval/image_loss_std": 13.490675926208496, "eval/model_loss_mean": 21.248735427856445, "eval/model_loss_std": 17.678016662597656, "eval/post_ent_mag": 56.72691345214844, "eval/post_ent_max": 56.72691345214844, "eval/post_ent_mean": 39.409603118896484, "eval/post_ent_min": 19.787813186645508, "eval/post_ent_std": 7.424386024475098, "eval/prior_ent_mag": 67.0926513671875, "eval/prior_ent_max": 67.0926513671875, "eval/prior_ent_mean": 55.805763244628906, "eval/prior_ent_min": 43.37129211425781, "eval/prior_ent_std": 3.844167470932007, "eval/rep_loss_mean": 18.876026153564453, "eval/rep_loss_std": 10.257112503051758, "eval/reward_avg": 0.0400390625, "eval/reward_loss_mean": 0.13571873307228088, "eval/reward_loss_std": 0.7341716289520264, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0591542720794678, "eval/reward_neg_acc": 0.9877426624298096, "eval/reward_neg_loss": 0.04821169376373291, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.039483070373535, "eval/reward_pred": 0.031103305518627167, "eval/reward_rate": 0.0439453125, "replay/size": 923281.0, "replay/inserts": 20432.0, "replay/samples": 20432.0, "replay/insert_wait_avg": 1.4021911001242784e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.958993747445318e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1792066712049568e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1973447799683, "timer/env.step_count": 2554.0, "timer/env.step_total": 227.08956170082092, "timer/env.step_frac": 0.22704475560348342, "timer/env.step_avg": 0.08891525516868477, "timer/env.step_min": 0.023741722106933594, "timer/env.step_max": 2.2480454444885254, "timer/replay._sample_count": 20432.0, "timer/replay._sample_total": 10.733154535293579, "timer/replay._sample_frac": 0.010731036821193269, "timer/replay._sample_avg": 0.0005253110089709073, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.02803659439086914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3190.0, "timer/agent.policy_total": 53.995957136154175, "timer/agent.policy_frac": 0.053985303418329564, "timer/agent.policy_avg": 0.016926632331082814, "timer/agent.policy_min": 0.009540557861328125, "timer/agent.policy_max": 0.12701845169067383, "timer/dataset_train_count": 1277.0, "timer/dataset_train_total": 0.1545119285583496, "timer/dataset_train_frac": 0.00015448144245207974, "timer/dataset_train_avg": 0.00012099602862830823, "timer/dataset_train_min": 0.00010824203491210938, "timer/dataset_train_max": 0.000682830810546875, "timer/agent.train_count": 1277.0, "timer/agent.train_total": 570.4665067195892, "timer/agent.train_frac": 0.5703539503447544, "timer/agent.train_avg": 0.4467239676739148, "timer/agent.train_min": 0.4352903366088867, "timer/agent.train_max": 1.356389045715332, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4713902473449707, "timer/agent.report_frac": 0.0004712972392949824, "timer/agent.report_avg": 0.23569512367248535, "timer/agent.report_min": 0.227400541305542, "timer/agent.report_max": 0.2439897060394287, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8604584526747986e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 20.427691316342745}
{"step": 924016, "time": 45344.39986515045, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 924096, "time": 45348.80061721802, "episode/length": 165.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 924096, "time": 45348.86497592926, "episode/length": 272.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 924240, "time": 45357.3917016983, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 924512, "time": 45368.92613220215, "episode/length": 221.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 924736, "time": 45378.685980558395, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 925456, "time": 45406.67827916145, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 925528, "time": 45410.70546293259, "episode/length": 188.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 925880, "time": 45426.950612306595, "episode/length": 269.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 925888, "time": 45428.97197818756, "episode/length": 171.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 925936, "time": 45432.325368881226, "episode/length": 229.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 926696, "time": 45461.536710977554, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 926856, "time": 45468.885966300964, "episode/length": 523.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9980916030534351, "episode/intrinsic_return": 0.0}
{"step": 927144, "time": 45480.95110988617, "episode/length": 362.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9889807162534435, "episode/intrinsic_return": 0.0}
{"step": 927296, "time": 45488.472309827805, "episode/length": 220.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 927720, "time": 45505.49007892609, "episode/length": 229.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 927736, "time": 45507.67301797867, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 927752, "time": 45509.824377536774, "episode/length": 131.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 927944, "time": 45518.446967601776, "episode/length": 135.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 928016, "time": 45522.821751117706, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 928096, "time": 45527.24784183502, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 928680, "time": 45550.036603450775, "episode/length": 492.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9918864097363083, "episode/intrinsic_return": 0.0}
{"step": 928872, "time": 45558.63182067871, "episode/length": 96.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 928928, "time": 45562.49038672447, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 929392, "time": 45581.06202459335, "episode/length": 280.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9928825622775801, "episode/intrinsic_return": 0.0}
{"step": 929528, "time": 45587.40993452072, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 929808, "time": 45599.489381313324, "episode/length": 232.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 929888, "time": 45603.847786426544, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 45626.77617812157, "eval_episode/length": 39.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.975}
{"step": 930072, "time": 45628.731481313705, "eval_episode/length": 50.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 930072, "time": 45635.61282110214, "eval_episode/length": 183.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 930072, "time": 45638.00759720802, "eval_episode/length": 197.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 930072, "time": 45640.93119239807, "eval_episode/length": 45.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 930072, "time": 45643.28184700012, "eval_episode/length": 248.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 930072, "time": 45645.47402834892, "eval_episode/length": 224.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 930072, "time": 45647.4242413044, "eval_episode/length": 276.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9711191335740073}
{"step": 930192, "time": 45652.05193066597, "episode/length": 188.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 930432, "time": 45662.40711712837, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 930592, "time": 45669.870896101, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 930680, "time": 45674.475368499756, "episode/length": 218.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 931120, "time": 45692.41100382805, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 931184, "time": 45696.45633172989, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 931704, "time": 45716.88666462898, "episode/length": 236.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 931808, "time": 45722.49191117287, "episode/length": 201.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 932024, "time": 45731.88042926788, "episode/length": 266.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 932152, "time": 45738.09531378746, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 932376, "time": 45747.76487636566, "episode/length": 156.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 932488, "time": 45753.44683551788, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 932768, "time": 45765.62807559967, "episode/length": 92.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 932904, "time": 45771.81342625618, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 933280, "time": 45787.45679187775, "episode/length": 196.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 933320, "time": 45790.28784060478, "episode/length": 329.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 933680, "time": 45805.3174803257, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 933728, "time": 45808.71385240555, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 933784, "time": 45812.04080200195, "episode/length": 161.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 934056, "time": 45825.657403469086, "episode/length": 237.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 934384, "time": 45840.2363243103, "episode/length": 137.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 934696, "time": 45853.72852516174, "episode/length": 223.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 934696, "time": 45853.77758932114, "episode/length": 240.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 934832, "time": 45862.33609867096, "episode/length": 143.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 935336, "time": 45882.946986436844, "episode/length": 251.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 935592, "time": 45894.47558379173, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 935640, "time": 45898.28825211525, "episode/length": 238.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 935912, "time": 45910.698982954025, "episode/length": 39.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 935960, "time": 45914.57618975639, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 935968, "time": 45917.11028242111, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 936104, "time": 45924.08979034424, "episode/length": 158.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 936312, "time": 45933.97585391998, "episode/length": 201.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 936536, "time": 45944.37833571434, "episode/length": 53.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 936736, "time": 45953.47518777847, "episode/length": 102.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 937104, "time": 45968.63946866989, "episode/length": 142.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 937168, "time": 45972.53713917732, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 937248, "time": 45977.00187921524, "episode/length": 398.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 937456, "time": 45986.14092063904, "episode/length": 89.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 937640, "time": 45994.268458127975, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 937672, "time": 45997.10443305969, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 938072, "time": 46013.277107954025, "episode/length": 341.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9970760233918129, "episode/intrinsic_return": 0.0}
{"step": 938104, "time": 46016.059844493866, "episode/length": 195.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 938576, "time": 46035.115619659424, "episode/length": 116.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 938648, "time": 46039.06669998169, "episode/length": 192.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 939048, "time": 46055.35005927086, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 939120, "time": 46059.91915893555, "episode/length": 130.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 939600, "time": 46079.08674407005, "episode/length": 240.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 939848, "time": 46089.570207834244, "episode/length": 298.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 46118.24103140831, "eval_episode/length": 169.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 940056, "time": 46121.0344889164, "eval_episode/length": 200.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 940056, "time": 46122.83101987839, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 940056, "time": 46124.51479458809, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 940056, "time": 46126.3972325325, "eval_episode/length": 216.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 940056, "time": 46128.273263931274, "eval_episode/length": 226.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 940056, "time": 46128.323152542114, "eval_episode/length": 226.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 940056, "time": 46136.788625240326, "eval_episode/length": 160.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 940072, "time": 46137.3834168911, "episode/length": 245.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 940120, "time": 46140.833824157715, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 940160, "time": 46144.0366024971, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 940360, "time": 46152.76651954651, "episode/length": 213.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 940488, "time": 46159.00520467758, "episode/length": 170.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 940560, "time": 46163.309584379196, "episode/length": 188.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 941384, "time": 46194.69246888161, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 941520, "time": 46201.36357021332, "episode/length": 208.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 941552, "time": 46204.057643413544, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 941624, "time": 46208.12304973602, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 942376, "time": 46239.151042699814, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 943048, "time": 46265.30145406723, "episode/length": 83.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 943096, "time": 46268.75240135193, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 943096, "time": 46268.80285167694, "episode/length": 192.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 943560, "time": 46288.98187184334, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 943640, "time": 46293.54186010361, "episode/length": 393.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 943776, "time": 46300.454961538315, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 944176, "time": 46316.599927425385, "episode/length": 134.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 944200, "time": 46318.70990276337, "episode/length": 504.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.998019801980198, "episode/intrinsic_return": 0.0}
{"step": 944424, "time": 46328.44112634659, "episode/length": 107.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 944561, "time": 46335.74424409866, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.7189449339874034, "train/action_min": 0.0, "train/action_std": 3.6322223567223366, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03899907013184802, "train/actor_opt_grad_steps": 58290.0, "train/actor_opt_loss": -3.5726626158453696, "train/adv_mag": 0.5312967767087065, "train/adv_max": 0.461144473894622, "train/adv_mean": 0.003568811778564822, "train/adv_min": -0.440100834697716, "train/adv_std": 0.056926366750353063, "train/cont_avg": 0.9947613856589147, "train/cont_loss_mean": 0.0002684233179907061, "train/cont_loss_std": 0.008246455147237371, "train/cont_neg_acc": 0.9919250649075175, "train/cont_neg_loss": 0.018221273787311257, "train/cont_pos_acc": 0.9999542897061784, "train/cont_pos_loss": 0.00017111081392263101, "train/cont_pred": 0.9947473037150479, "train/cont_rate": 0.9947613856589147, "train/dyn_loss_mean": 12.39638831264289, "train/dyn_loss_std": 9.037925114003263, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8883607017901517, "train/extr_critic_critic_opt_grad_steps": 58290.0, "train/extr_critic_critic_opt_loss": 15581.238886870155, "train/extr_critic_mag": 8.690323075582814, "train/extr_critic_max": 8.690323075582814, "train/extr_critic_mean": 2.8215477651403855, "train/extr_critic_min": -0.2329180166702862, "train/extr_critic_std": 1.9742071674775707, "train/extr_return_normed_mag": 1.551362541294837, "train/extr_return_normed_max": 1.551362541294837, "train/extr_return_normed_mean": 0.4121424784494001, "train/extr_return_normed_min": -0.13609317314717195, "train/extr_return_normed_std": 0.32441369969715445, "train/extr_return_rate": 0.9056141468905663, "train/extr_return_raw_mag": 9.896728042484254, "train/extr_return_raw_max": 9.896728042484254, "train/extr_return_raw_mean": 2.843601792357689, "train/extr_return_raw_min": -0.549976424422375, "train/extr_return_raw_std": 2.008499631586001, "train/extr_reward_mag": 1.0371304390042326, "train/extr_reward_max": 1.0371304390042326, "train/extr_reward_mean": 0.044112959010309954, "train/extr_reward_min": -0.5169326676878818, "train/extr_reward_std": 0.19721239089041717, "train/image_loss_mean": 5.878626653390337, "train/image_loss_std": 10.971127413964087, "train/model_loss_mean": 13.374566041221915, "train/model_loss_std": 14.691627931225208, "train/model_opt_grad_norm": 51.65940680984379, "train/model_opt_grad_steps": 58239.52713178295, "train/model_opt_loss": 16718.20756873789, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5272630148155746, "train/policy_entropy_max": 2.5272630148155746, "train/policy_entropy_mean": 0.5154016493826874, "train/policy_entropy_min": 0.07937501486419707, "train/policy_entropy_std": 0.5922532679960709, "train/policy_logprob_mag": 7.438383690146512, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5163842640643896, "train/policy_logprob_min": -7.438383690146512, "train/policy_logprob_std": 1.0850932477980622, "train/policy_randomness_mag": 0.8920129357382308, "train/policy_randomness_max": 0.8920129357382308, "train/policy_randomness_mean": 0.18191416561603546, "train/policy_randomness_min": 0.028015897010070408, "train/policy_randomness_std": 0.2090394141138062, "train/post_ent_mag": 59.04629419016283, "train/post_ent_max": 59.04629419016283, "train/post_ent_mean": 42.62644621383312, "train/post_ent_min": 19.521284613498423, "train/post_ent_std": 7.667652935944786, "train/prior_ent_mag": 67.3736817707387, "train/prior_ent_max": 67.3736817707387, "train/prior_ent_mean": 55.0990165592164, "train/prior_ent_min": 39.132477560708686, "train/prior_ent_std": 4.338066467019015, "train/rep_loss_mean": 12.39638831264289, "train/rep_loss_std": 9.037925114003263, "train/reward_avg": 0.031589147078898525, "train/reward_loss_mean": 0.05783807012692902, "train/reward_loss_std": 0.25043360149675564, "train/reward_max_data": 1.0217054315315661, "train/reward_max_pred": 1.0135807565940442, "train/reward_neg_acc": 0.9922989264939183, "train/reward_neg_loss": 0.0288650881888908, "train/reward_pos_acc": 0.9726151417392169, "train/reward_pos_loss": 0.8282394427661748, "train/reward_pred": 0.030805330665767655, "train/reward_rate": 0.03628421753875969, "train_stats/sum_log_reward": 9.183333600560823, "train_stats/max_log_achievement_collect_coal": 0.4895833333333333, "train_stats/max_log_achievement_collect_drink": 4.677083333333333, "train_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "train_stats/max_log_achievement_collect_stone": 8.75, "train_stats/max_log_achievement_collect_wood": 9.4375, "train_stats/max_log_achievement_defeat_skeleton": 0.0625, "train_stats/max_log_achievement_defeat_zombie": 1.2083333333333333, "train_stats/max_log_achievement_eat_cow": 0.19791666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010416666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 1.34375, "train_stats/max_log_achievement_make_wood_sword": 1.0208333333333333, "train_stats/max_log_achievement_place_furnace": 0.28125, "train_stats/max_log_achievement_place_plant": 1.40625, "train_stats/max_log_achievement_place_stone": 6.260416666666667, "train_stats/max_log_achievement_place_table": 2.5416666666666665, "train_stats/max_log_achievement_wake_up": 1.15625, "train_stats/mean_log_entropy": 0.5958547870007654, "eval_stats/sum_log_reward": 9.100000083446503, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 10.0625, "eval_stats/max_log_achievement_collect_wood": 8.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 7.3125, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 0.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.3439586155072902e-06, "report/cont_loss_std": 5.359733677323675e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.877681153127924e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0795159823828726e-06, "report/cont_pred": 0.9960929155349731, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 9.569049835205078, "report/dyn_loss_std": 8.714609146118164, "report/image_loss_mean": 4.3571696281433105, "report/image_loss_std": 8.351354598999023, "report/model_loss_mean": 10.138847351074219, "report/model_loss_std": 12.382779121398926, "report/post_ent_mag": 61.09237289428711, "report/post_ent_max": 61.09237289428711, "report/post_ent_mean": 44.40641784667969, "report/post_ent_min": 18.39409828186035, "report/post_ent_std": 7.932351589202881, "report/prior_ent_mag": 67.4718017578125, "report/prior_ent_max": 67.4718017578125, "report/prior_ent_mean": 54.423377990722656, "report/prior_ent_min": 38.24929428100586, "report/prior_ent_std": 4.95382833480835, "report/rep_loss_mean": 9.569049835205078, "report/rep_loss_std": 8.714609146118164, "report/reward_avg": 0.0224609375, "report/reward_loss_mean": 0.04024679213762283, "report/reward_loss_std": 0.1937454491853714, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.116999626159668, "report/reward_neg_acc": 0.9949899911880493, "report/reward_neg_loss": 0.02208208665251732, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7374920845031738, "report/reward_pred": 0.023970622569322586, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.1111640560557134e-05, "eval/cont_loss_std": 0.0003143647045362741, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0034193145111203194, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0973317330353893e-06, "eval/cont_pred": 0.9970791935920715, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.048240661621094, "eval/dyn_loss_std": 10.517999649047852, "eval/image_loss_mean": 10.802403450012207, "eval/image_loss_std": 13.39241886138916, "eval/model_loss_mean": 21.166059494018555, "eval/model_loss_std": 17.27515983581543, "eval/post_ent_mag": 59.96460723876953, "eval/post_ent_max": 59.96460723876953, "eval/post_ent_mean": 40.71662139892578, "eval/post_ent_min": 20.16515350341797, "eval/post_ent_std": 8.091205596923828, "eval/prior_ent_mag": 67.4718017578125, "eval/prior_ent_max": 67.4718017578125, "eval/prior_ent_mean": 55.63754653930664, "eval/prior_ent_min": 45.09698486328125, "eval/prior_ent_std": 3.8619585037231445, "eval/rep_loss_mean": 17.048240661621094, "eval/rep_loss_std": 10.517999649047852, "eval/reward_avg": 0.0517578125, "eval/reward_loss_mean": 0.13470005989074707, "eval/reward_loss_std": 0.6390562653541565, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012285709381104, "eval/reward_neg_acc": 0.9772492051124573, "eval/reward_neg_loss": 0.06311256438493729, "eval/reward_pos_acc": 0.8771929740905762, "eval/reward_pos_loss": 1.3491754531860352, "eval/reward_pred": 0.04921894147992134, "eval/reward_rate": 0.0556640625, "replay/size": 944057.0, "replay/inserts": 20776.0, "replay/samples": 20768.0, "replay/insert_wait_avg": 1.3918499327825958e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.744011783452908e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5112.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1019863433121517e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0315382480621, "timer/env.step_count": 2597.0, "timer/env.step_total": 224.18940544128418, "timer/env.step_frac": 0.22418233512318791, "timer/env.step_avg": 0.08632630167165352, "timer/env.step_min": 0.023825883865356445, "timer/env.step_max": 3.397675037384033, "timer/replay._sample_count": 20768.0, "timer/replay._sample_total": 10.864593267440796, "timer/replay._sample_frac": 0.01086425062800948, "timer/replay._sample_avg": 0.0005231410471610553, "timer/replay._sample_min": 0.0004012584686279297, "timer/replay._sample_max": 0.011029243469238281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3236.0, "timer/agent.policy_total": 53.346131563186646, "timer/agent.policy_frac": 0.0533444491727159, "timer/agent.policy_avg": 0.016485207528796862, "timer/agent.policy_min": 0.009569168090820312, "timer/agent.policy_max": 0.10578465461730957, "timer/dataset_train_count": 1298.0, "timer/dataset_train_total": 0.15594124794006348, "timer/dataset_train_frac": 0.0001559363299814066, "timer/dataset_train_avg": 0.00012013963631746031, "timer/dataset_train_min": 0.00010633468627929688, "timer/dataset_train_max": 0.0003762245178222656, "timer/agent.train_count": 1298.0, "timer/agent.train_total": 580.6072280406952, "timer/agent.train_frac": 0.5805889172833998, "timer/agent.train_avg": 0.4473091125120918, "timer/agent.train_min": 0.4353780746459961, "timer/agent.train_max": 1.3559741973876953, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4929831027984619, "timer/agent.report_frac": 0.000492967555465411, "timer/agent.report_avg": 0.24649155139923096, "timer/agent.report_min": 0.23691248893737793, "timer/agent.report_max": 0.256070613861084, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.52715723636475e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 20.775055853540536}
{"step": 944752, "time": 46343.425721645355, "episode/length": 121.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 944928, "time": 46351.547335386276, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 945000, "time": 46355.56096577644, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 945072, "time": 46360.078464746475, "episode/length": 460.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9804772234273319, "episode/intrinsic_return": 0.0}
{"step": 945088, "time": 46362.147998571396, "episode/length": 110.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 945568, "time": 46381.24999308586, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 945960, "time": 46397.26695394516, "episode/length": 191.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 946048, "time": 46402.78585577011, "episode/length": 368.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 946240, "time": 46412.14833164215, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 946336, "time": 46417.731451034546, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 946392, "time": 46421.10617804527, "episode/length": 173.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 946720, "time": 46434.93392753601, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 947056, "time": 46448.93262887001, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 947096, "time": 46451.76766562462, "episode/length": 190.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 947424, "time": 46465.48907876015, "episode/length": 171.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 947840, "time": 46482.34789776802, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 947912, "time": 46486.28046274185, "episode/length": 243.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 948856, "time": 46522.65488934517, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 949008, "time": 46530.118938207626, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 949040, "time": 46532.88519310951, "episode/length": 201.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 949408, "time": 46547.99139332771, "episode/length": 383.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 949736, "time": 46561.436661720276, "episode/length": 236.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 949760, "time": 46564.668535232544, "episode/length": 420.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 949784, "time": 46567.507822752, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 46594.348568439484, "eval_episode/length": 43.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 950040, "time": 46597.9196600914, "eval_episode/length": 73.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9324324324324325}
{"step": 950040, "time": 46603.96638560295, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 950040, "time": 46607.33550953865, "eval_episode/length": 203.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 950040, "time": 46609.98673129082, "eval_episode/length": 44.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 950040, "time": 46612.21148467064, "eval_episode/length": 224.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 950040, "time": 46616.26200842857, "eval_episode/length": 268.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9888475836431226}
{"step": 950040, "time": 46620.11789250374, "eval_episode/length": 307.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9837662337662337}
{"step": 950384, "time": 46635.26579594612, "episode/length": 308.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 950440, "time": 46639.143440485, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 950528, "time": 46644.13509297371, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 950776, "time": 46654.561750650406, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 951024, "time": 46665.57822847366, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 951408, "time": 46681.63377928734, "episode/length": 47.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 951608, "time": 46690.37876653671, "episode/length": 227.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 951632, "time": 46693.1123611927, "episode/length": 236.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 951888, "time": 46703.95548939705, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 952184, "time": 46716.05942392349, "episode/length": 302.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 952336, "time": 46723.509548187256, "episode/length": 194.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 952416, "time": 46727.92916440964, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 952448, "time": 46730.66487622261, "episode/length": 239.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 953128, "time": 46756.89971470833, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 953824, "time": 46784.30638885498, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 953880, "time": 46787.728597164154, "episode/length": 248.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 954216, "time": 46801.56325221062, "episode/length": 234.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 954424, "time": 46811.00703883171, "episode/length": 351.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9857954545454546, "episode/intrinsic_return": 0.0}
{"step": 954560, "time": 46817.79997444153, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 954568, "time": 46819.50899195671, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 955224, "time": 46845.06450366974, "episode/length": 350.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9857549857549858, "episode/intrinsic_return": 0.0}
{"step": 955568, "time": 46859.48978352547, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 955872, "time": 46872.45786690712, "episode/length": 80.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 955984, "time": 46878.23938751221, "episode/length": 543.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9871323529411765, "episode/intrinsic_return": 0.0}
{"step": 956208, "time": 46888.02333235741, "episode/length": 290.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 956456, "time": 46899.37611222267, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 956864, "time": 46916.40978503227, "episode/length": 304.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 956880, "time": 46918.63020277023, "episode/length": 381.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.0}
{"step": 957480, "time": 46942.30776190758, "episode/length": 238.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 957832, "time": 46956.97923231125, "episode/length": 118.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 958168, "time": 46970.90001869202, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 958344, "time": 46979.026587724686, "episode/length": 471.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9978813559322034, "episode/intrinsic_return": 0.0}
{"step": 958416, "time": 46983.39539361, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 958520, "time": 46990.56685590744, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 958576, "time": 46994.35277700424, "episode/length": 337.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 959024, "time": 47012.14290523529, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 959304, "time": 47023.9110584259, "episode/length": 110.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 959496, "time": 47032.37285280228, "episode/length": 207.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 959624, "time": 47038.706244945526, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 959664, "time": 47041.94904446602, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 959904, "time": 47052.4590485096, "episode/length": 172.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 959944, "time": 47055.31806612015, "episode/length": 199.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 47074.277599573135, "eval_episode/length": 43.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 960024, "time": 47080.91167783737, "eval_episode/length": 166.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 960024, "time": 47082.79807329178, "eval_episode/length": 175.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 960024, "time": 47084.92399263382, "eval_episode/length": 185.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 960024, "time": 47086.72963500023, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 960024, "time": 47088.426582336426, "eval_episode/length": 195.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 960024, "time": 47091.5782251358, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 960024, "time": 47095.36429166794, "eval_episode/length": 290.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9965635738831615}
{"step": 960136, "time": 47099.49279689789, "episode/length": 194.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 960304, "time": 47107.470834732056, "episode/length": 49.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 960696, "time": 47123.11392426491, "episode/length": 128.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 960912, "time": 47132.715281009674, "episode/length": 200.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 961072, "time": 47140.13306212425, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 961112, "time": 47142.90871214867, "episode/length": 185.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 961304, "time": 47151.40800118446, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 961472, "time": 47159.32895612717, "episode/length": 305.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 962136, "time": 47185.17988038063, "episode/length": 152.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 962224, "time": 47190.23838543892, "episode/length": 239.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 962288, "time": 47194.13578414917, "episode/length": 146.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 962320, "time": 47196.90858078003, "episode/length": 272.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 962488, "time": 47204.29944872856, "episode/length": 176.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 962704, "time": 47213.99824547768, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 963312, "time": 47237.85248589516, "episode/length": 135.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 963400, "time": 47242.302085876465, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 963648, "time": 47253.16095781326, "episode/length": 271.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 964040, "time": 47268.95883893967, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 964048, "time": 47271.0626308918, "episode/length": 418.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9904534606205251, "episode/intrinsic_return": 0.0}
{"step": 964304, "time": 47282.11650967598, "episode/length": 112.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 964488, "time": 47290.54919028282, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 964744, "time": 47302.200919151306, "episode/length": 306.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 964976, "time": 47313.07262778282, "episode/length": 283.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 965160, "time": 47321.23157501221, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 965240, "time": 47325.73447012901, "episode/length": 93.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 965392, "time": 47333.05855059624, "episode/length": 168.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 965401, "time": 47335.79376792908, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.40368233018249, "train/action_min": 0.0, "train/action_std": 3.3278002848151984, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03787878030584059, "train/actor_opt_grad_steps": 59590.0, "train/actor_opt_loss": -7.372934257959989, "train/adv_mag": 0.5004822968981648, "train/adv_max": 0.46216921087439733, "train/adv_mean": 0.0024802405634531837, "train/adv_min": -0.3992474790065343, "train/adv_std": 0.05426362918988439, "train/cont_avg": 0.9947966364503816, "train/cont_loss_mean": 0.00030273557415564257, "train/cont_loss_std": 0.009015750488615352, "train/cont_neg_acc": 0.9894220292113209, "train/cont_neg_loss": 0.03617021389679901, "train/cont_pos_acc": 0.9999624376988593, "train/cont_pos_loss": 0.0001011731648929981, "train/cont_pred": 0.9947948314761388, "train/cont_rate": 0.9947966364503816, "train/dyn_loss_mean": 12.407967676643198, "train/dyn_loss_std": 9.068228776218326, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8660349399988888, "train/extr_critic_critic_opt_grad_steps": 59590.0, "train/extr_critic_critic_opt_loss": 15340.635145813454, "train/extr_critic_mag": 8.712116306974687, "train/extr_critic_max": 8.712116306974687, "train/extr_critic_mean": 2.778853829580409, "train/extr_critic_min": -0.22995755963653097, "train/extr_critic_std": 2.022689762916274, "train/extr_return_normed_mag": 1.5213301800589525, "train/extr_return_normed_max": 1.5213301800589525, "train/extr_return_normed_mean": 0.4026041898791117, "train/extr_return_normed_min": -0.1285828566960706, "train/extr_return_normed_std": 0.3259966504255324, "train/extr_return_rate": 0.8923207371289493, "train/extr_return_raw_mag": 9.839033709227584, "train/extr_return_raw_max": 9.839033709227584, "train/extr_return_raw_mean": 2.794491483964993, "train/extr_return_raw_min": -0.5502261893667337, "train/extr_return_raw_std": 2.0533318783490713, "train/extr_reward_mag": 1.0386893003041509, "train/extr_reward_max": 1.0386893003041509, "train/extr_reward_mean": 0.04383878203691872, "train/extr_reward_min": -0.4967424842237516, "train/extr_reward_std": 0.1963403608280284, "train/image_loss_mean": 6.126592934586619, "train/image_loss_std": 11.641370285558336, "train/model_loss_mean": 13.630899203642635, "train/model_loss_std": 15.340652138222264, "train/model_opt_grad_norm": 55.49432606005487, "train/model_opt_grad_steps": 59538.29770992367, "train/model_opt_loss": 17038.624001073473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5726592577140748, "train/policy_entropy_max": 2.5726592577140748, "train/policy_entropy_mean": 0.5057425469387579, "train/policy_entropy_min": 0.07937501507406017, "train/policy_entropy_std": 0.6076444724133907, "train/policy_logprob_mag": 7.438383746693153, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5045063077038481, "train/policy_logprob_min": -7.438383746693153, "train/policy_logprob_std": 1.0746544685982566, "train/policy_randomness_mag": 0.908035820222083, "train/policy_randomness_max": 0.908035820222083, "train/policy_randomness_mean": 0.1785049255340154, "train/policy_randomness_min": 0.028015897118749508, "train/policy_randomness_std": 0.21447183271400802, "train/post_ent_mag": 58.75112917951045, "train/post_ent_max": 58.75112917951045, "train/post_ent_mean": 42.672905084741025, "train/post_ent_min": 19.76749254183005, "train/post_ent_std": 7.637203151033125, "train/prior_ent_mag": 67.46712854982333, "train/prior_ent_max": 67.46712854982333, "train/prior_ent_mean": 55.17939071072877, "train/prior_ent_min": 39.54596493262371, "train/prior_ent_std": 4.451745501001373, "train/rep_loss_mean": 12.407967676643198, "train/rep_loss_std": 9.068228776218326, "train/reward_avg": 0.03184041010486033, "train/reward_loss_mean": 0.059222960034172045, "train/reward_loss_std": 0.25450759204744383, "train/reward_max_data": 1.0190839740156217, "train/reward_max_pred": 1.0098342786308463, "train/reward_neg_acc": 0.99153391960013, "train/reward_neg_loss": 0.029548419035174918, "train/reward_pos_acc": 0.9662332876038006, "train/reward_pos_loss": 0.8506619006622839, "train/reward_pred": 0.030994782921012123, "train/reward_rate": 0.036281906011450385, "train_stats/sum_log_reward": 9.056521937898967, "train_stats/max_log_achievement_collect_coal": 0.3804347826086957, "train_stats/max_log_achievement_collect_drink": 4.010869565217392, "train_stats/max_log_achievement_collect_sapling": 1.3478260869565217, "train_stats/max_log_achievement_collect_stone": 13.282608695652174, "train_stats/max_log_achievement_collect_wood": 9.869565217391305, "train_stats/max_log_achievement_defeat_skeleton": 0.08695652173913043, "train_stats/max_log_achievement_defeat_zombie": 1.141304347826087, "train_stats/max_log_achievement_eat_cow": 0.1956521739130435, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010869565217391304, "train_stats/max_log_achievement_make_wood_pickaxe": 1.315217391304348, "train_stats/max_log_achievement_make_wood_sword": 0.9565217391304348, "train_stats/max_log_achievement_place_furnace": 0.10869565217391304, "train_stats/max_log_achievement_place_plant": 1.315217391304348, "train_stats/max_log_achievement_place_stone": 11.402173913043478, "train_stats/max_log_achievement_place_table": 2.489130434782609, "train_stats/max_log_achievement_wake_up": 1.1956521739130435, "train_stats/mean_log_entropy": 0.5851951306280883, "eval_stats/sum_log_reward": 7.975000321865082, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 1.625, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 10.75, "eval_stats/max_log_achievement_collect_wood": 7.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 9.5, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.8834485419793054e-05, "report/cont_loss_std": 0.0007746552000753582, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.137320724519668e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.899070932471659e-05, "report/cont_pred": 0.9931355714797974, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.83216667175293, "report/dyn_loss_std": 8.672168731689453, "report/image_loss_mean": 5.2780351638793945, "report/image_loss_std": 8.860870361328125, "report/model_loss_mean": 12.429420471191406, "report/model_loss_std": 12.292516708374023, "report/post_ent_mag": 59.811317443847656, "report/post_ent_max": 59.811317443847656, "report/post_ent_mean": 43.27909851074219, "report/post_ent_min": 18.553558349609375, "report/post_ent_std": 7.842502117156982, "report/prior_ent_mag": 67.54220581054688, "report/prior_ent_max": 67.54220581054688, "report/prior_ent_mean": 55.19731903076172, "report/prior_ent_min": 34.683082580566406, "report/prior_ent_std": 4.442164897918701, "report/rep_loss_mean": 11.83216667175293, "report/rep_loss_std": 8.672168731689453, "report/reward_avg": 0.02626952901482582, "report/reward_loss_mean": 0.052056070417165756, "report/reward_loss_std": 0.1830187737941742, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0914151668548584, "report/reward_neg_acc": 0.9909182786941528, "report/reward_neg_loss": 0.0298080462962389, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7201709747314453, "report/reward_pred": 0.026926785707473755, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.14902315242216e-05, "eval/cont_loss_std": 0.0008529760525561869, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006579692475497723, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.5850228010094725e-05, "eval/cont_pred": 0.9961034059524536, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.745532989501953, "eval/dyn_loss_std": 10.287219047546387, "eval/image_loss_mean": 8.057755470275879, "eval/image_loss_std": 11.685585975646973, "eval/model_loss_mean": 18.202465057373047, "eval/model_loss_std": 15.848907470703125, "eval/post_ent_mag": 57.45600891113281, "eval/post_ent_max": 57.45600891113281, "eval/post_ent_mean": 40.829200744628906, "eval/post_ent_min": 19.987241744995117, "eval/post_ent_std": 7.945528507232666, "eval/prior_ent_mag": 67.54220581054688, "eval/prior_ent_max": 67.54220581054688, "eval/prior_ent_mean": 55.587257385253906, "eval/prior_ent_min": 40.023460388183594, "eval/prior_ent_std": 3.7540602684020996, "eval/rep_loss_mean": 16.745532989501953, "eval/rep_loss_std": 10.287219047546387, "eval/reward_avg": 0.03964843600988388, "eval/reward_loss_mean": 0.0973471999168396, "eval/reward_loss_std": 0.5175702571868896, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0658142566680908, "eval/reward_neg_acc": 0.9887754917144775, "eval/reward_neg_loss": 0.05649217218160629, "eval/reward_pos_acc": 0.9545454978942871, "eval/reward_pos_loss": 1.0073000192642212, "eval/reward_pred": 0.03975846245884895, "eval/reward_rate": 0.04296875, "replay/size": 964897.0, "replay/inserts": 20840.0, "replay/samples": 20848.0, "replay/insert_wait_avg": 1.4148037630399679e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.780167293475393e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1686092625078255e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0348942279816, "timer/env.step_count": 2605.0, "timer/env.step_total": 219.04874634742737, "timer/env.step_frac": 0.21904110307723926, "timer/env.step_avg": 0.08408781049805274, "timer/env.step_min": 0.023468494415283203, "timer/env.step_max": 2.1807057857513428, "timer/replay._sample_count": 20848.0, "timer/replay._sample_total": 10.979515552520752, "timer/replay._sample_frac": 0.010979132444170205, "timer/replay._sample_avg": 0.0005266459877456232, "timer/replay._sample_min": 0.00042176246643066406, "timer/replay._sample_max": 0.0272216796875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3204.0, "timer/agent.policy_total": 54.2249710559845, "timer/agent.policy_frac": 0.054223078983504584, "timer/agent.policy_avg": 0.016924148269658084, "timer/agent.policy_min": 0.009550094604492188, "timer/agent.policy_max": 0.1167759895324707, "timer/dataset_train_count": 1303.0, "timer/dataset_train_total": 0.15656566619873047, "timer/dataset_train_frac": 0.00015656020315130888, "timer/dataset_train_avg": 0.00012015784052089829, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0008823871612548828, "timer/agent.train_count": 1303.0, "timer/agent.train_total": 581.9937479496002, "timer/agent.train_frac": 0.5819734404356904, "timer/agent.train_avg": 0.4466567520718344, "timer/agent.train_min": 0.4349067211151123, "timer/agent.train_max": 1.4730651378631592, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47641682624816895, "timer/agent.report_frac": 0.0004764002026308879, "timer/agent.report_avg": 0.23820841312408447, "timer/agent.report_min": 0.2307724952697754, "timer/agent.report_max": 0.24564433097839355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7894000415273005e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 20.83898724595994}
{"step": 965576, "time": 47342.022064208984, "episode/length": 74.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 965608, "time": 47344.694700956345, "episode/length": 45.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 965608, "time": 47344.742480516434, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9721254355400697, "episode/intrinsic_return": 0.0}
{"step": 965808, "time": 47355.711797237396, "episode/length": 132.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 965848, "time": 47358.555548906326, "episode/length": 85.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 966024, "time": 47366.535985946655, "episode/length": 55.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 966296, "time": 47378.16212940216, "episode/length": 248.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 966680, "time": 47395.37528204918, "episode/length": 328.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 967096, "time": 47412.262954473495, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 967256, "time": 47419.60129404068, "episode/length": 232.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9613733905579399, "episode/intrinsic_return": 0.0}
{"step": 967480, "time": 47429.3768093586, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 967840, "time": 47444.524154663086, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 967872, "time": 47447.21988964081, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 968080, "time": 47456.406203746796, "episode/length": 308.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 968648, "time": 47478.72577047348, "episode/length": 145.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 968712, "time": 47482.65026283264, "episode/length": 253.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 968800, "time": 47487.624888420105, "episode/length": 212.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 968840, "time": 47490.46097397804, "episode/length": 197.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 968848, "time": 47492.52290844917, "episode/length": 374.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 969056, "time": 47501.772003650665, "episode/length": 151.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 969368, "time": 47514.391332387924, "episode/length": 38.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 969504, "time": 47521.16616892815, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 969568, "time": 47524.99447965622, "episode/length": 95.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 47557.40871119499, "eval_episode/length": 46.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 970008, "time": 47564.04460668564, "eval_episode/length": 164.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 970008, "time": 47569.67154335976, "eval_episode/length": 240.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995850622406639}
{"step": 970008, "time": 47572.980825185776, "eval_episode/length": 222.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 970008, "time": 47574.68589377403, "eval_episode/length": 33.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8529411764705882}
{"step": 970008, "time": 47576.42973470688, "eval_episode/length": 277.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 970008, "time": 47578.596244335175, "eval_episode/length": 294.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9966101694915255}
{"step": 970008, "time": 47580.28706765175, "eval_episode/length": 298.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9899665551839465}
{"step": 970088, "time": 47583.25978112221, "episode/length": 154.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 970584, "time": 47605.79617404938, "episode/length": 217.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 970696, "time": 47611.5385890007, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 970896, "time": 47620.64771604538, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 970976, "time": 47625.108345746994, "episode/length": 290.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 971080, "time": 47630.23173904419, "episode/length": 374.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973333333333333, "episode/intrinsic_return": 0.0}
{"step": 971352, "time": 47641.798946619034, "episode/length": 329.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 971704, "time": 47656.36092400551, "episode/length": 266.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 972008, "time": 47669.17139649391, "episode/length": 239.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 972080, "time": 47673.68171072006, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 972400, "time": 47687.13417553902, "episode/length": 187.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 972440, "time": 47690.02576947212, "episode/length": 217.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 972472, "time": 47692.66454100609, "episode/length": 186.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 973136, "time": 47718.859870672226, "episode/length": 82.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 973552, "time": 47735.631279706955, "episode/length": 274.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 973776, "time": 47745.50869679451, "episode/length": 220.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 974064, "time": 47757.53815841675, "episode/length": 372.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758713136729222, "episode/intrinsic_return": 0.0}
{"step": 974208, "time": 47764.427525281906, "episode/length": 225.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 974520, "time": 47777.21145415306, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 974904, "time": 47794.46950650215, "episode/length": 352.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801699716713881, "episode/intrinsic_return": 0.0}
{"step": 975288, "time": 47810.2079911232, "episode/length": 188.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 975368, "time": 47814.73415398598, "episode/length": 365.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 975464, "time": 47819.834421634674, "episode/length": 238.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 975832, "time": 47834.924924850464, "episode/length": 163.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 976208, "time": 47850.54285311699, "episode/length": 267.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 976608, "time": 47866.89561057091, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 976664, "time": 47870.23979663849, "episode/length": 306.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 976992, "time": 47884.0118367672, "episode/length": 481.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 977024, "time": 47886.86455011368, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 977144, "time": 47892.595690488815, "episode/length": 221.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 977472, "time": 47906.30690717697, "episode/length": 320.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 977792, "time": 47919.67280673981, "episode/length": 197.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 977944, "time": 47926.62738108635, "episode/length": 309.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 978176, "time": 47936.89036178589, "episode/length": 188.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 978760, "time": 47959.815912008286, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 978784, "time": 47962.54275178909, "episode/length": 271.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 978832, "time": 47965.759456157684, "episode/length": 129.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 978896, "time": 47969.68093705177, "episode/length": 218.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 979392, "time": 47989.53174805641, "episode/length": 295.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 980008, "time": 48014.56205201149, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9810725552050473, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 48040.95178985596, "eval_episode/length": 100.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9504950495049505}
{"step": 980096, "time": 48048.523651361465, "eval_episode/length": 180.0, "eval_episode/score": 12.100000031292439, "eval_episode/reward_rate": 0.9834254143646409}
{"step": 980096, "time": 48052.169444322586, "eval_episode/length": 214.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9674418604651163}
{"step": 980096, "time": 48054.7937271595, "eval_episode/length": 227.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 980096, "time": 48056.92954611778, "eval_episode/length": 231.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 980096, "time": 48059.12273812294, "eval_episode/length": 235.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 980096, "time": 48062.16628885269, "eval_episode/length": 263.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 980096, "time": 48064.245844364166, "eval_episode/length": 40.0, "eval_episode/score": 2.1000000163912773, "eval_episode/reward_rate": 0.975609756097561}
{"step": 980320, "time": 48072.9058637619, "episode/length": 191.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 980352, "time": 48076.04827475548, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 980680, "time": 48090.28705406189, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 980688, "time": 48092.78664755821, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 980792, "time": 48098.59415125847, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 980888, "time": 48104.09472489357, "episode/length": 248.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 981136, "time": 48115.58223962784, "episode/length": 369.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 981736, "time": 48140.00491976738, "episode/length": 130.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 981752, "time": 48142.5657851696, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 981784, "time": 48145.85712862015, "episode/length": 298.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 981872, "time": 48151.294744729996, "episode/length": 122.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 982120, "time": 48162.60038232803, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 982792, "time": 48189.34313607216, "episode/length": 304.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 982832, "time": 48192.6099152565, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 983096, "time": 48205.31207823753, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 983344, "time": 48216.26103234291, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 983440, "time": 48221.40285086632, "episode/length": 210.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 983936, "time": 48241.17611479759, "episode/length": 268.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 984056, "time": 48247.05747461319, "episode/length": 241.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 984072, "time": 48249.22062087059, "episode/length": 121.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 984248, "time": 48257.19434928894, "episode/length": 445.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 984288, "time": 48260.48533701897, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 984656, "time": 48275.41263461113, "episode/length": 151.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 984672, "time": 48277.803265571594, "episode/length": 91.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 984816, "time": 48284.64432358742, "episode/length": 70.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 985624, "time": 48315.74704194069, "episode/length": 120.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 985656, "time": 48318.43397283554, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 985768, "time": 48324.05535411835, "episode/length": 118.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 986025, "time": 48336.014046907425, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.299675046935562, "train/action_min": 0.0, "train/action_std": 3.3232962734015414, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03788935936005541, "train/actor_opt_grad_steps": 60890.0, "train/actor_opt_loss": -4.406688441370809, "train/adv_mag": 0.5129428027674209, "train/adv_max": 0.4464039670866589, "train/adv_mean": 0.0029908884599895236, "train/adv_min": -0.4239858596823936, "train/adv_std": 0.0549211990694667, "train/cont_avg": 0.9947992369186046, "train/cont_loss_mean": 0.00013904947524384949, "train/cont_loss_std": 0.004116161783005645, "train/cont_neg_acc": 0.9914974787438563, "train/cont_neg_loss": 0.030461417597671455, "train/cont_pos_acc": 0.9999923669090567, "train/cont_pos_loss": 3.765570565009469e-05, "train/cont_pred": 0.9948200828345247, "train/cont_rate": 0.9947992369186046, "train/dyn_loss_mean": 12.547986829003623, "train/dyn_loss_std": 9.0705031794171, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8288234070289967, "train/extr_critic_critic_opt_grad_steps": 60890.0, "train/extr_critic_critic_opt_loss": 15470.432942708334, "train/extr_critic_mag": 8.77567590669144, "train/extr_critic_max": 8.77567590669144, "train/extr_critic_mean": 2.8028882113538045, "train/extr_critic_min": -0.2378234770870948, "train/extr_critic_std": 1.9663318534230076, "train/extr_return_normed_mag": 1.5159536054892133, "train/extr_return_normed_max": 1.5159536054892133, "train/extr_return_normed_mean": 0.40747598252555195, "train/extr_return_normed_min": -0.131195260688316, "train/extr_return_normed_std": 0.3167679075353829, "train/extr_return_rate": 0.9033698203951813, "train/extr_return_raw_mag": 9.798493851062863, "train/extr_return_raw_max": 9.798493851062863, "train/extr_return_raw_mean": 2.8217128884884737, "train/extr_return_raw_min": -0.5686854301959046, "train/extr_return_raw_std": 1.9939939975738525, "train/extr_reward_mag": 1.0469697907913562, "train/extr_reward_max": 1.0469697907913562, "train/extr_reward_mean": 0.04342620155608007, "train/extr_reward_min": -0.4853506892226463, "train/extr_reward_std": 0.19495064505310947, "train/image_loss_mean": 6.125993131667144, "train/image_loss_std": 11.635169435841169, "train/model_loss_mean": 13.71212100982666, "train/model_loss_std": 15.343724354292995, "train/model_opt_grad_norm": 51.52560948216638, "train/model_opt_grad_steps": 60837.06201550388, "train/model_opt_loss": 18736.626302083332, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1385.6589147286822, "train/policy_entropy_mag": 2.6382622182831286, "train/policy_entropy_max": 2.6382622182831286, "train/policy_entropy_mean": 0.48897871629212253, "train/policy_entropy_min": 0.07937501457541488, "train/policy_entropy_std": 0.6034200829128886, "train/policy_logprob_mag": 7.4383837640747545, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4884598407634469, "train/policy_logprob_min": -7.4383837640747545, "train/policy_logprob_std": 1.067786365516426, "train/policy_randomness_mag": 0.9311907868976741, "train/policy_randomness_max": 0.9311907868976741, "train/policy_randomness_mean": 0.1725880293421043, "train/policy_randomness_min": 0.02801589693787486, "train/policy_randomness_std": 0.212980810754983, "train/post_ent_mag": 58.88533602574075, "train/post_ent_max": 58.88533602574075, "train/post_ent_mean": 42.54585751082546, "train/post_ent_min": 19.81559465837109, "train/post_ent_std": 7.642815948456757, "train/prior_ent_mag": 67.4554672241211, "train/prior_ent_max": 67.4554672241211, "train/prior_ent_mean": 55.15309565935948, "train/prior_ent_min": 39.631207429161364, "train/prior_ent_std": 4.359717345052911, "train/rep_loss_mean": 12.547986829003623, "train/rep_loss_std": 9.0705031794171, "train/reward_avg": 0.030296147858738437, "train/reward_loss_mean": 0.05719685203634029, "train/reward_loss_std": 0.24851437271103377, "train/reward_max_data": 1.0201550435650257, "train/reward_max_pred": 1.0163617355878962, "train/reward_neg_acc": 0.9914423786392508, "train/reward_neg_loss": 0.02941591149672519, "train/reward_pos_acc": 0.9691580935966136, "train/reward_pos_loss": 0.8294786561367123, "train/reward_pred": 0.029737557768244154, "train/reward_rate": 0.034876150678294575, "train_stats/sum_log_reward": 9.418681584871733, "train_stats/max_log_achievement_collect_coal": 0.6263736263736264, "train_stats/max_log_achievement_collect_drink": 4.4945054945054945, "train_stats/max_log_achievement_collect_sapling": 1.2527472527472527, "train_stats/max_log_achievement_collect_stone": 15.296703296703297, "train_stats/max_log_achievement_collect_wood": 9.043956043956044, "train_stats/max_log_achievement_defeat_skeleton": 0.13186813186813187, "train_stats/max_log_achievement_defeat_zombie": 1.054945054945055, "train_stats/max_log_achievement_eat_cow": 0.23076923076923078, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01098901098901099, "train_stats/max_log_achievement_make_stone_sword": 0.01098901098901099, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2417582417582418, "train_stats/max_log_achievement_make_wood_sword": 0.9120879120879121, "train_stats/max_log_achievement_place_furnace": 0.06593406593406594, "train_stats/max_log_achievement_place_plant": 1.2087912087912087, "train_stats/max_log_achievement_place_stone": 12.472527472527473, "train_stats/max_log_achievement_place_table": 2.2527472527472527, "train_stats/max_log_achievement_wake_up": 1.1538461538461537, "train_stats/mean_log_entropy": 0.5560048892275318, "eval_stats/sum_log_reward": 7.850000165402889, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 4.5625, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.6875, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_iron": 0.017241379310344827, "eval_stats/max_log_achievement_collect_iron": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 3.4719355426204856e-06, "report/cont_loss_std": 4.876461753156036e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020405925170052797, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6933291817622376e-06, "report/cont_pred": 0.9912111163139343, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 11.870418548583984, "report/dyn_loss_std": 9.104767799377441, "report/image_loss_mean": 5.94104528427124, "report/image_loss_std": 14.060470581054688, "report/model_loss_mean": 13.112041473388672, "report/model_loss_std": 17.815799713134766, "report/post_ent_mag": 58.24798583984375, "report/post_ent_max": 58.24798583984375, "report/post_ent_mean": 43.037254333496094, "report/post_ent_min": 18.62783432006836, "report/post_ent_std": 7.520170211791992, "report/prior_ent_mag": 67.47158813476562, "report/prior_ent_max": 67.47158813476562, "report/prior_ent_mean": 55.1929817199707, "report/prior_ent_min": 39.88459014892578, "report/prior_ent_std": 4.301388263702393, "report/rep_loss_mean": 11.870418548583984, "report/rep_loss_std": 9.104767799377441, "report/reward_avg": 0.01708984375, "report/reward_loss_mean": 0.04874177277088165, "report/reward_loss_std": 0.22056171298027039, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018069744110107, "report/reward_neg_acc": 0.9910000562667847, "report/reward_neg_loss": 0.030872607603669167, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.7932903170585632, "report/reward_pred": 0.01711660996079445, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.2195079079901916e-06, "eval/cont_loss_std": 1.4928530617908109e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.1562162146437913e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1196912055311259e-06, "eval/cont_pred": 0.9951162338256836, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.916688919067383, "eval/dyn_loss_std": 10.825908660888672, "eval/image_loss_mean": 10.23252010345459, "eval/image_loss_std": 17.443754196166992, "eval/model_loss_mean": 19.918354034423828, "eval/model_loss_std": 21.387781143188477, "eval/post_ent_mag": 58.471839904785156, "eval/post_ent_max": 58.471839904785156, "eval/post_ent_mean": 41.544700622558594, "eval/post_ent_min": 19.792043685913086, "eval/post_ent_std": 7.951075077056885, "eval/prior_ent_mag": 67.47158813476562, "eval/prior_ent_max": 67.47158813476562, "eval/prior_ent_mean": 55.50244903564453, "eval/prior_ent_min": 40.43417739868164, "eval/prior_ent_std": 4.537224769592285, "eval/rep_loss_mean": 15.916688919067383, "eval/rep_loss_std": 10.825908660888672, "eval/reward_avg": 0.04560546576976776, "eval/reward_loss_mean": 0.1358197182416916, "eval/reward_loss_std": 0.7785515189170837, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028660297393799, "eval/reward_neg_acc": 0.9876670241355896, "eval/reward_neg_loss": 0.04084945097565651, "eval/reward_pos_acc": 0.8039215803146362, "eval/reward_pos_loss": 1.9477035999298096, "eval/reward_pred": 0.03860840946435928, "eval/reward_rate": 0.0498046875, "replay/size": 985521.0, "replay/inserts": 20624.0, "replay/samples": 20624.0, "replay/insert_wait_avg": 1.4017611348971181e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.76675341201439e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2160187036218777e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2059214115143, "timer/env.step_count": 2578.0, "timer/env.step_total": 218.3975772857666, "timer/env.step_frac": 0.21835261380732357, "timer/env.step_avg": 0.08471589499059992, "timer/env.step_min": 0.023494958877563477, "timer/env.step_max": 3.46537184715271, "timer/replay._sample_count": 20624.0, "timer/replay._sample_total": 10.847645998001099, "timer/replay._sample_frac": 0.010845412695310426, "timer/replay._sample_avg": 0.0005259719743018376, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.011393547058105469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3146.0, "timer/agent.policy_total": 54.20115780830383, "timer/agent.policy_frac": 0.05418999892723478, "timer/agent.policy_avg": 0.017228594344661105, "timer/agent.policy_min": 0.009873628616333008, "timer/agent.policy_max": 0.11150074005126953, "timer/dataset_train_count": 1289.0, "timer/dataset_train_total": 0.1543598175048828, "timer/dataset_train_frac": 0.0001543280380574498, "timer/dataset_train_avg": 0.00011975160396034353, "timer/dataset_train_min": 0.00010657310485839844, "timer/dataset_train_max": 0.0005793571472167969, "timer/agent.train_count": 1289.0, "timer/agent.train_total": 578.8958797454834, "timer/agent.train_frac": 0.578776697231038, "timer/agent.train_avg": 0.44910463905778386, "timer/agent.train_min": 0.4341700077056885, "timer/agent.train_max": 3.1283514499664307, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.481386661529541, "timer/agent.report_frac": 0.00048128755411705297, "timer/agent.report_avg": 0.2406933307647705, "timer/agent.report_min": 0.2304854393005371, "timer/agent.report_max": 0.2509012222290039, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.884270873999343e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 20.61944775845822}
{"step": 986136, "time": 48340.07413101196, "episode/length": 348.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.997134670487106, "episode/intrinsic_return": 0.0}
{"step": 986240, "time": 48345.69920516014, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 986352, "time": 48351.393191576004, "episode/length": 257.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 986416, "time": 48355.24832653999, "episode/length": 452.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9889624724061811, "episode/intrinsic_return": 0.0}
{"step": 987080, "time": 48381.00376081467, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 987096, "time": 48383.15748023987, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 987224, "time": 48389.39231348038, "episode/length": 122.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 987256, "time": 48392.129893779755, "episode/length": 139.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 987424, "time": 48400.272681474686, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 987536, "time": 48405.917707920074, "episode/length": 357.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 987992, "time": 48423.83134555817, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 988280, "time": 48436.01673722267, "episode/length": 147.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 988656, "time": 48451.59884381294, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 988984, "time": 48465.05640363693, "episode/length": 219.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 989144, "time": 48472.37261176109, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 989336, "time": 48480.99482297897, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 989384, "time": 48484.256052970886, "episode/length": 378.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9947229551451188, "episode/intrinsic_return": 0.0}
{"step": 989400, "time": 48486.511150598526, "episode/length": 139.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 48527.26748251915, "eval_episode/length": 41.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9047619047619048}
{"step": 990080, "time": 48530.81506037712, "eval_episode/length": 91.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 990080, "time": 48533.45915269852, "eval_episode/length": 121.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9590163934426229}
{"step": 990080, "time": 48538.186856508255, "eval_episode/length": 203.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 990080, "time": 48540.35522317886, "eval_episode/length": 175.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 990080, "time": 48542.991017341614, "eval_episode/length": 242.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 990080, "time": 48544.63963222504, "eval_episode/length": 245.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9715447154471545}
{"step": 990080, "time": 48547.967843294144, "eval_episode/length": 286.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9790940766550522}
{"step": 990440, "time": 48560.99692583084, "episode/length": 137.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 990632, "time": 48569.642669439316, "episode/length": 400.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 990728, "time": 48574.75064826012, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 990776, "time": 48578.11664009094, "episode/length": 264.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 991000, "time": 48587.98050284386, "episode/length": 432.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 991152, "time": 48595.37100839615, "episode/length": 46.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 991192, "time": 48598.2703397274, "episode/length": 225.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 991488, "time": 48613.58628201485, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 991872, "time": 48630.083423137665, "episode/length": 308.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 992080, "time": 48640.041712760925, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 992184, "time": 48645.75700831413, "episode/length": 217.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 992312, "time": 48652.51448750496, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 992344, "time": 48655.741854429245, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 992640, "time": 48669.274156332016, "episode/length": 185.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 992728, "time": 48674.30721402168, "episode/length": 215.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 992848, "time": 48681.14646053314, "episode/length": 169.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 993008, "time": 48689.02787065506, "episode/length": 141.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 993288, "time": 48700.66727185249, "episode/length": 54.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 993704, "time": 48717.422036886215, "episode/length": 132.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 994064, "time": 48732.92918539047, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 994176, "time": 48739.08367776871, "episode/length": 228.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 995368, "time": 48785.677345991135, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 995544, "time": 48793.9046061039, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 995584, "time": 48797.20688009262, "episode/length": 437.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 995752, "time": 48804.71678519249, "episode/length": 377.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 995760, "time": 48806.82002043724, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 995760, "time": 48806.87117433548, "episode/length": 430.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.988399071925754, "episode/intrinsic_return": 0.0}
{"step": 996248, "time": 48827.86236143112, "episode/length": 369.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 996632, "time": 48843.49748182297, "episode/length": 130.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 997008, "time": 48859.137226104736, "episode/length": 412.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 997112, "time": 48864.214416503906, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 997376, "time": 48875.62549686432, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 997424, "time": 48879.11815404892, "episode/length": 207.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 997512, "time": 48883.54865908623, "episode/length": 267.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 997544, "time": 48886.275643110275, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 998544, "time": 48924.46244740486, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 998728, "time": 48932.51293683052, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 998752, "time": 48935.08251786232, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 998784, "time": 48937.93568992615, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 998888, "time": 48943.11204767227, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 998968, "time": 48947.613844156265, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 999120, "time": 48954.82762980461, "episode/length": 358.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9972144846796658, "episode/intrinsic_return": 0.0}
{"step": 999440, "time": 48969.80255436897, "episode/length": 88.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 999880, "time": 48987.34203195572, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 49016.381689310074, "eval_episode/length": 185.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 1000064, "time": 49018.77699804306, "eval_episode/length": 206.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.966183574879227}
{"step": 1000064, "time": 49021.49454855919, "eval_episode/length": 234.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 1000064, "time": 49023.24710607529, "eval_episode/length": 238.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.99581589958159}
{"step": 1000064, "time": 49025.41057682037, "eval_episode/length": 253.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9763779527559056}
{"step": 1000064, "time": 49027.1810939312, "eval_episode/length": 254.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.996078431372549}
{"step": 1000064, "time": 49030.18151140213, "eval_episode/length": 290.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9828178694158075}
{"step": 1000064, "time": 49035.92659282684, "eval_episode/length": 208.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 1000464, "time": 49050.69989705086, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1000544, "time": 49055.07045722008, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1000624, "time": 49059.67244410515, "episode/length": 216.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1000704, "time": 49064.18552613258, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1000808, "time": 49069.34168720245, "episode/length": 282.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 1000880, "time": 49073.63334107399, "episode/length": 41.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1001080, "time": 49082.15796685219, "episode/length": 24.0, "episode/score": 1.1000000163912773, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 1001184, "time": 49087.836135149, "episode/length": 303.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 1001624, "time": 49105.25305604935, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1002232, "time": 49129.1762034893, "episode/length": 143.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1002384, "time": 49136.50241661072, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 1002440, "time": 49139.903802871704, "episode/length": 216.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 1002784, "time": 49154.42814040184, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 1003112, "time": 49167.63443136215, "episode/length": 330.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 1003136, "time": 49170.32385587692, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1003264, "time": 49176.66469693184, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 1003536, "time": 49188.23199510574, "episode/length": 363.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9862637362637363, "episode/intrinsic_return": 0.0}
{"step": 1004016, "time": 49207.50080227852, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 1004304, "time": 49219.862986803055, "episode/length": 232.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1004336, "time": 49223.01368880272, "episode/length": 152.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1004440, "time": 49228.77244925499, "episode/length": 146.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 1004456, "time": 49231.400362730026, "episode/length": 164.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 1005008, "time": 49254.55910420418, "episode/length": 277.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 1005128, "time": 49260.21061086655, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 1005808, "time": 49287.09345912933, "episode/length": 84.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1005928, "time": 49292.815935611725, "episode/length": 442.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954853273137697, "episode/intrinsic_return": 0.0}
{"step": 1006008, "time": 49297.4964799881, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1006016, "time": 49299.52028179169, "episode/length": 125.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 1006312, "time": 49311.58586525917, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1006921, "time": 49336.53078651428, "train_stats/sum_log_reward": 9.308791413411988, "train_stats/max_log_achievement_collect_coal": 0.6153846153846154, "train_stats/max_log_achievement_collect_drink": 7.3076923076923075, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3846153846153846, "train_stats/max_log_achievement_collect_stone": 12.912087912087912, "train_stats/max_log_achievement_collect_wood": 9.813186813186814, "train_stats/max_log_achievement_defeat_skeleton": 0.14285714285714285, "train_stats/max_log_achievement_defeat_zombie": 1.1868131868131868, "train_stats/max_log_achievement_eat_cow": 0.25274725274725274, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2747252747252746, "train_stats/max_log_achievement_make_wood_sword": 0.945054945054945, "train_stats/max_log_achievement_place_furnace": 0.06593406593406594, "train_stats/max_log_achievement_place_plant": 1.3406593406593406, "train_stats/max_log_achievement_place_stone": 10.615384615384615, "train_stats/max_log_achievement_place_table": 2.3956043956043955, "train_stats/max_log_achievement_wake_up": 1.2967032967032968, "train_stats/mean_log_entropy": 0.535244148183655, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3454031137319715, "train/action_min": 0.0, "train/action_std": 3.2943068247575025, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03693411249953967, "train/actor_opt_grad_steps": 62185.0, "train/actor_opt_loss": -9.077472313626025, "train/adv_mag": 0.5280907734082295, "train/adv_max": 0.4556596680329396, "train/adv_mean": 0.0018486455376520237, "train/adv_min": -0.44210414382127616, "train/adv_std": 0.05413653982373384, "train/cont_avg": 0.9947716346153846, "train/cont_loss_mean": 0.0001886861849545067, "train/cont_loss_std": 0.005712323942115151, "train/cont_neg_acc": 0.9896703312030205, "train/cont_neg_loss": 0.029841988585681416, "train/cont_pos_acc": 0.9999924247081463, "train/cont_pos_loss": 3.7047977529716454e-05, "train/cont_pred": 0.9948015460601219, "train/cont_rate": 0.9947716346153846, "train/dyn_loss_mean": 12.328412011953501, "train/dyn_loss_std": 9.035746574401855, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8592849401327279, "train/extr_critic_critic_opt_grad_steps": 62185.0, "train/extr_critic_critic_opt_loss": 15304.291556490385, "train/extr_critic_mag": 8.782413211235633, "train/extr_critic_max": 8.782413211235633, "train/extr_critic_mean": 2.7189769378075233, "train/extr_critic_min": -0.24764754130290104, "train/extr_critic_std": 2.008668256722964, "train/extr_return_normed_mag": 1.5240608627979573, "train/extr_return_normed_max": 1.5240608627979573, "train/extr_return_normed_mean": 0.3959196599630209, "train/extr_return_normed_min": -0.12915121189390238, "train/extr_return_normed_std": 0.3262373257141847, "train/extr_return_rate": 0.8925761672166678, "train/extr_return_raw_mag": 9.764497426839975, "train/extr_return_raw_max": 9.764497426839975, "train/extr_return_raw_mean": 2.7304900435300974, "train/extr_return_raw_min": -0.544079106931503, "train/extr_return_raw_std": 2.0347021689781775, "train/extr_reward_mag": 1.0477380220706647, "train/extr_reward_max": 1.0477380220706647, "train/extr_reward_mean": 0.0431089584214183, "train/extr_reward_min": -0.49790215217150174, "train/extr_reward_std": 0.19518057864445906, "train/image_loss_mean": 5.903382757993845, "train/image_loss_std": 11.037751935078548, "train/model_loss_mean": 13.358536500197191, "train/model_loss_std": 14.738496457613431, "train/model_opt_grad_norm": 50.96142328247544, "train/model_opt_grad_steps": 62130.723076923074, "train/model_opt_loss": 16820.415377103367, "train/model_opt_model_opt_grad_overflow": 0.007692307692307693, "train/model_opt_model_opt_grad_scale": 1259.6153846153845, "train/policy_entropy_mag": 2.628877485715426, "train/policy_entropy_max": 2.628877485715426, "train/policy_entropy_mean": 0.49826745436741754, "train/policy_entropy_min": 0.07937501433950205, "train/policy_entropy_std": 0.6125677961569566, "train/policy_logprob_mag": 7.438383766321036, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4975824963587981, "train/policy_logprob_min": -7.438383766321036, "train/policy_logprob_std": 1.075806772708893, "train/policy_randomness_mag": 0.9278783894502199, "train/policy_randomness_max": 0.9278783894502199, "train/policy_randomness_mean": 0.175866545851414, "train/policy_randomness_min": 0.02801589687856344, "train/policy_randomness_std": 0.21620955100426306, "train/post_ent_mag": 59.176727177546574, "train/post_ent_max": 59.176727177546574, "train/post_ent_mean": 42.888173176692085, "train/post_ent_min": 19.540686225891115, "train/post_ent_std": 7.6829053401947025, "train/prior_ent_mag": 67.49041460477389, "train/prior_ent_max": 67.49041460477389, "train/prior_ent_mean": 55.27228939349835, "train/prior_ent_min": 39.19289412865272, "train/prior_ent_std": 4.403983332560613, "train/rep_loss_mean": 12.328412011953501, "train/rep_loss_std": 9.035746574401855, "train/reward_avg": 0.030749699057867893, "train/reward_loss_mean": 0.05791797067683477, "train/reward_loss_std": 0.25031074526218267, "train/reward_max_data": 1.0176923119104826, "train/reward_max_pred": 1.0099780623729413, "train/reward_neg_acc": 0.9919160017600426, "train/reward_neg_loss": 0.029268145854943074, "train/reward_pos_acc": 0.9698401639094719, "train/reward_pos_loss": 0.8433416834244362, "train/reward_pred": 0.02984516144945071, "train/reward_rate": 0.03528395432692308, "eval_stats/sum_log_reward": 8.78750017285347, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 7.6875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 15.875, "eval_stats/max_log_achievement_collect_wood": 8.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 0.9375, "eval_stats/max_log_achievement_place_stone": 13.625, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.5676497443782864e-06, "report/cont_loss_std": 3.3438474929425865e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014063325943425298, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.297462742717471e-06, "report/cont_pred": 0.9980449676513672, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.145164489746094, "report/dyn_loss_std": 8.56579875946045, "report/image_loss_mean": 5.542973041534424, "report/image_loss_std": 12.968839645385742, "report/model_loss_mean": 12.87370491027832, "report/model_loss_std": 16.58539581298828, "report/post_ent_mag": 56.06562805175781, "report/post_ent_max": 56.06562805175781, "report/post_ent_mean": 42.13716125488281, "report/post_ent_min": 19.24582290649414, "report/post_ent_std": 6.99198579788208, "report/prior_ent_mag": 67.79182434082031, "report/prior_ent_max": 67.79182434082031, "report/prior_ent_mean": 54.65753936767578, "report/prior_ent_min": 43.929527282714844, "report/prior_ent_std": 4.117973327636719, "report/rep_loss_mean": 12.145164489746094, "report/rep_loss_std": 8.56579875946045, "report/reward_avg": 0.02382812462747097, "report/reward_loss_mean": 0.04363027215003967, "report/reward_loss_std": 0.1890449821949005, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029809474945068, "report/reward_neg_acc": 0.9899699091911316, "report/reward_neg_loss": 0.02452547661960125, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.7490925788879395, "report/reward_pred": 0.023883281275629997, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.1137558582704514e-05, "eval/cont_loss_std": 0.0008691014372743666, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.2299391528358683e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.125064515392296e-05, "eval/cont_pred": 0.9960530996322632, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.10273551940918, "eval/dyn_loss_std": 11.076263427734375, "eval/image_loss_mean": 9.430317878723145, "eval/image_loss_std": 15.01949691772461, "eval/model_loss_mean": 19.7862548828125, "eval/model_loss_std": 19.320781707763672, "eval/post_ent_mag": 59.885379791259766, "eval/post_ent_max": 59.885379791259766, "eval/post_ent_mean": 41.277801513671875, "eval/post_ent_min": 18.093463897705078, "eval/post_ent_std": 8.522253036499023, "eval/prior_ent_mag": 67.79182434082031, "eval/prior_ent_max": 67.79182434082031, "eval/prior_ent_mean": 56.04366683959961, "eval/prior_ent_min": 37.546512603759766, "eval/prior_ent_std": 4.500103950500488, "eval/rep_loss_mean": 17.10273551940918, "eval/rep_loss_std": 11.076263427734375, "eval/reward_avg": 0.03056640550494194, "eval/reward_loss_mean": 0.09425478428602219, "eval/reward_loss_std": 0.506613552570343, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0082168579101562, "eval/reward_neg_acc": 0.9848330616950989, "eval/reward_neg_loss": 0.04826335236430168, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.3938411474227905, "eval/reward_pred": 0.030636057257652283, "eval/reward_rate": 0.0341796875, "replay/size": 1000000.0, "replay/inserts": 20896.0, "replay/samples": 20896.0, "replay/insert_wait_avg": 1.3843133109999652e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.662802341338504e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1368580927247526e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.497394323349, "timer/env.step_count": 2612.0, "timer/env.step_total": 219.41003680229187, "timer/env.step_frac": 0.21930095775080163, "timer/env.step_avg": 0.08400077978648234, "timer/env.step_min": 0.0237429141998291, "timer/env.step_max": 3.2356181144714355, "timer/replay._sample_count": 20896.0, "timer/replay._sample_total": 11.043993473052979, "timer/replay._sample_frac": 0.011038502984330302, "timer/replay._sample_avg": 0.0005285218928528416, "timer/replay._sample_min": 0.0004169940948486328, "timer/replay._sample_max": 0.017079830169677734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3294.0, "timer/agent.policy_total": 54.592474699020386, "timer/agent.policy_frac": 0.05456533421153193, "timer/agent.policy_avg": 0.01657330743746824, "timer/agent.policy_min": 0.009240865707397461, "timer/agent.policy_max": 0.10704684257507324, "timer/dataset_train_count": 1306.0, "timer/dataset_train_total": 0.15651559829711914, "timer/dataset_train_frac": 0.00015643778702989318, "timer/dataset_train_avg": 0.00011984349027344498, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0002875328063964844, "timer/agent.train_count": 1306.0, "timer/agent.train_total": 583.0898702144623, "timer/agent.train_frac": 0.5827999888083811, "timer/agent.train_avg": 0.4464700384490523, "timer/agent.train_min": 0.4337639808654785, "timer/agent.train_max": 1.3773777484893799, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48135972023010254, "timer/agent.report_frac": 0.000481120413667497, "timer/agent.report_avg": 0.24067986011505127, "timer/agent.report_min": 0.23498082160949707, "timer/agent.report_max": 0.24637889862060547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.0503997802734375e-05, "timer/dataset_eval_frac": 2.0493804300811325e-08, "timer/dataset_eval_avg": 2.0503997802734375e-05, "timer/dataset_eval_min": 2.0503997802734375e-05, "timer/dataset_eval_max": 2.0503997802734375e-05, "fps": 20.88529509020421}
{"step": 1007008, "time": 49339.79268479347, "episode/length": 318.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 1007048, "time": 49342.6362156868, "episode/length": 129.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 1007568, "time": 49363.65657162666, "episode/length": 390.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9923273657289002, "episode/intrinsic_return": 0.0}
{"step": 1007600, "time": 49366.49101471901, "episode/length": 411.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9927184466019418, "episode/intrinsic_return": 0.0}
{"step": 1007648, "time": 49371.57236266136, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1008008, "time": 49386.07310676575, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9672727272727273, "episode/intrinsic_return": 0.0}
{"step": 1008520, "time": 49406.567452669144, "episode/length": 188.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1008904, "time": 49422.34499120712, "episode/length": 371.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 1008960, "time": 49426.243019104004, "episode/length": 367.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 1009192, "time": 49436.09599900246, "episode/length": 198.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1009392, "time": 49445.284586429596, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 1009552, "time": 49452.78995895386, "episode/length": 192.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 1009848, "time": 49464.93829035759, "episode/length": 349.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 49491.51906275749, "eval_episode/length": 123.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9919354838709677}
{"step": 1010048, "time": 49494.370873212814, "eval_episode/length": 156.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9554140127388535}
{"step": 1010048, "time": 49497.19128704071, "eval_episode/length": 186.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 1010048, "time": 49499.2302672863, "eval_episode/length": 198.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 1010048, "time": 49500.939319849014, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 1010048, "time": 49503.34904265404, "eval_episode/length": 225.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 1010048, "time": 49508.057087183, "eval_episode/length": 252.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 1010048, "time": 49513.386283159256, "eval_episode/length": 223.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 1010472, "time": 49528.731055259705, "episode/length": 188.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1010848, "time": 49544.51462125778, "episode/length": 409.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9926829268292683, "episode/intrinsic_return": 0.0}
{"step": 1010920, "time": 49548.43888783455, "episode/length": 299.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1011376, "time": 49566.99373984337, "episode/length": 308.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 1011464, "time": 49571.565412044525, "episode/length": 238.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1011552, "time": 49576.72008395195, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1011968, "time": 49593.49202179909, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 1012400, "time": 49610.93663048744, "episode/length": 375.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 1012912, "time": 49631.55335903168, "episode/length": 257.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1013200, "time": 49643.68661355972, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 1013272, "time": 49647.69299912453, "episode/length": 225.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 1013312, "time": 49651.0130136013, "episode/length": 241.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 1013320, "time": 49652.564670562744, "episode/length": 515.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903100775193798, "episode/intrinsic_return": 0.0}
{"step": 1013496, "time": 49660.72484230995, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 1013952, "time": 49679.298264980316, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1014144, "time": 49688.04100680351, "episode/length": 217.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1014208, "time": 49691.943768024445, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 1014448, "time": 49702.357402801514, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 1014632, "time": 49710.36392211914, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 1014680, "time": 49713.678164958954, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1014920, "time": 49724.01429390907, "episode/length": 177.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1015048, "time": 49730.23491740227, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1015808, "time": 49760.157767534256, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 1015936, "time": 49768.37170290947, "episode/length": 223.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 1015992, "time": 49771.74356460571, "episode/length": 222.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1016064, "time": 49776.15946340561, "episode/length": 178.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 1016448, "time": 49791.90631580353, "episode/length": 396.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9974811083123426, "episode/intrinsic_return": 0.0}
{"step": 1016768, "time": 49805.203283548355, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1016920, "time": 49812.22184944153, "episode/length": 308.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 1017352, "time": 49829.565210819244, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1017360, "time": 49831.6248524189, "episode/length": 288.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9930795847750865, "episode/intrinsic_return": 0.0}
{"step": 1017512, "time": 49838.68876719475, "episode/length": 189.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1017808, "time": 49851.31973052025, "episode/length": 217.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1018232, "time": 49868.37382602692, "episode/length": 108.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 1018384, "time": 49875.806156396866, "episode/length": 71.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 1018680, "time": 49888.05331349373, "episode/length": 165.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 1018752, "time": 49892.37044143677, "episode/length": 228.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1018856, "time": 49897.846599817276, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1019184, "time": 49911.70901751518, "episode/length": 40.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1019352, "time": 49919.24348497391, "episode/length": 120.0, "episode/score": 8.100000061094761, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 1020008, "time": 49945.008862018585, "episode/length": 444.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
