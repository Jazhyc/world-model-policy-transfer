{"step": 248, "time": 130.84245443344116, "episode/length": 30.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 624, "time": 133.39798021316528, "episode/length": 77.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 880, "time": 135.49158477783203, "episode/length": 109.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 1408, "time": 138.4466519355774, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 1424, "time": 139.92772793769836, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1488, "time": 141.45194387435913, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 154.99735713005066, "eval_episode/length": 36.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8648648648648649}
{"step": 1560, "time": 156.85267639160156, "eval_episode/length": 54.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 1560, "time": 160.3804166316986, "eval_episode/length": 147.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 162.05453610420227, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 1560, "time": 163.50158739089966, "eval_episode/length": 163.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 1560, "time": 165.31309008598328, "eval_episode/length": 182.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 1560, "time": 166.91794562339783, "train_stats/sum_log_reward": 0.433333287636439, "train_stats/max_log_achievement_collect_sapling": 0.6666666666666666, "train_stats/max_log_achievement_place_plant": 0.6666666666666666, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/sum_log_reward": 0.266666645805041, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.16666666666666666, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 1.1666666666666667}
{"step": 1560, "time": 201.7250440120697, "eval_episode/length": 46.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9148936170212766}
{"step": 1560, "time": 207.1231496334076, "eval_episode/length": 136.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 1560, "time": 209.82269620895386, "eval_episode/length": 159.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 1560, "time": 212.304292678833, "eval_episode/length": 177.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 1560, "time": 214.22899460792542, "eval_episode/length": 181.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 1560, "time": 215.80711197853088, "eval_episode/length": 183.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 1560, "time": 218.16889667510986, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 1560, "time": 220.98544573783875, "eval_episode/length": 182.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.994535519125683}
{"step": 1561, "time": 339.2312366962433, "eval_stats/sum_log_reward": 0.9749999865889549, "eval_stats/max_log_achievement_collect_sapling": 0.375, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/max_log_achievement_collect_drink": 0.3333333333333333, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.16827392578125, "train/action_min": 0.0, "train/action_std": 5.59432315826416, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000489548547193408, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.354740858078003, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.998046875, "train/cont_loss_mean": 0.6710651516914368, "train/cont_loss_std": 0.27245578169822693, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 1.1631765365600586, "train/cont_pos_acc": 0.5782778859138489, "train/cont_pos_loss": 0.6701021194458008, "train/cont_pred": 0.5300676822662354, "train/cont_rate": 0.998046875, "train/dyn_loss_mean": 10.633098602294922, "train/dyn_loss_std": 0.47961318492889404, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 8.422629356384277, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 34320.45703125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3596.884765625, "train/image_loss_std": 176.18515014648438, "train/model_loss_mean": 3609.47705078125, "train/model_loss_std": 176.1536407470703, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36094772.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7560155391693115, "train/policy_entropy_max": 2.7560155391693115, "train/policy_entropy_mean": 2.5454208850860596, "train/policy_entropy_min": 1.6230896711349487, "train/policy_entropy_std": 0.10511303693056107, "train/policy_logprob_mag": 5.937178611755371, "train/policy_logprob_max": -0.47009795904159546, "train/policy_logprob_mean": -2.545259952545166, "train/policy_logprob_min": -5.937178611755371, "train/policy_logprob_std": 0.7325167655944824, "train/policy_randomness_mag": 0.9727525115013123, "train/policy_randomness_max": 0.9727525115013123, "train/policy_randomness_mean": 0.8984218835830688, "train/policy_randomness_min": 0.572879433631897, "train/policy_randomness_std": 0.03710029274225235, "train/post_ent_mag": 106.20751953125, "train/post_ent_max": 106.20751953125, "train/post_ent_mean": 105.62007141113281, "train/post_ent_min": 105.0981216430664, "train/post_ent_std": 0.17069025337696075, "train/prior_ent_mag": 106.5007553100586, "train/prior_ent_max": 106.5007553100586, "train/prior_ent_mean": 105.58828735351562, "train/prior_ent_min": 104.65440368652344, "train/prior_ent_std": 0.3247370719909668, "train/rep_loss_mean": 10.633098602294922, "train/rep_loss_std": 0.47961318492889404, "train/reward_avg": 0.01005859300494194, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541264057159424, "train/reward_pred": 0.0, "train/reward_rate": 0.013671875, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.6034696102142334, "report/cont_loss_std": 0.25360357761383057, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.1357533931732178, "report/cont_pos_acc": 0.6849315166473389, "report/cont_pos_loss": 0.6024279594421387, "report/cont_pred": 0.564427375793457, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 10.661392211914062, "report/dyn_loss_std": 0.4938734471797943, "report/image_loss_mean": 3595.680419921875, "report/image_loss_std": 175.90162658691406, "report/model_loss_mean": 3608.22216796875, "report/model_loss_std": 175.863525390625, "report/post_ent_mag": 106.11664581298828, "report/post_ent_max": 106.11664581298828, "report/post_ent_mean": 105.62921142578125, "report/post_ent_min": 105.13912200927734, "report/post_ent_std": 0.14717556536197662, "report/prior_ent_mag": 106.62721252441406, "report/prior_ent_max": 106.62721252441406, "report/prior_ent_mean": 105.61723327636719, "report/prior_ent_min": 104.52438354492188, "report/prior_ent_std": 0.3383215367794037, "report/rep_loss_mean": 10.661392211914062, "report/rep_loss_std": 0.4938734471797943, "report/reward_avg": 0.01005859300494194, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541264057159424, "report/reward_pred": 0.0, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.5994317531585693, "eval/cont_loss_std": 0.2564508318901062, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 1.1846981048583984, "eval/cont_pos_acc": 0.6898238658905029, "eval/cont_pos_loss": 0.5982864499092102, "eval/cont_pred": 0.5668359398841858, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.72222900390625, "eval/dyn_loss_std": 0.4293981194496155, "eval/image_loss_mean": 3539.646484375, "eval/image_loss_std": 203.1620635986328, "eval/model_loss_mean": 3552.220703125, "eval/model_loss_std": 203.0758514404297, "eval/post_ent_mag": 105.97035217285156, "eval/post_ent_max": 105.97035217285156, "eval/post_ent_mean": 105.58689880371094, "eval/post_ent_min": 105.06941223144531, "eval/post_ent_std": 0.14890716969966888, "eval/prior_ent_mag": 106.57539367675781, "eval/prior_ent_max": 106.57539367675781, "eval/prior_ent_mean": 105.59647369384766, "eval/prior_ent_min": 104.60243225097656, "eval/prior_ent_std": 0.3151809871196747, "eval/rep_loss_mean": 10.72222900390625, "eval/rep_loss_std": 0.4293981194496155, "eval/reward_avg": 0.00986328162252903, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.548376738166553e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0126953125, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.4823906356248522e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.621386119297572e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2896.0, "eval_replay/inserts": 2896.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.3064449004705439e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 220.3825602531433, "timer/env.step_count": 196.0, "timer/env.step_total": 24.093416690826416, "timer/env.step_frac": 0.10932542331458268, "timer/env.step_avg": 0.12292559536135926, "timer/env.step_min": 0.019629716873168945, "timer/env.step_max": 11.234280347824097, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.08265805244445801, "timer/replay._sample_frac": 0.00037506621372177776, "timer/replay._sample_avg": 0.0007380183253969465, "timer/replay._sample_min": 0.0003643035888671875, "timer/replay._sample_max": 0.0016429424285888672, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.775980949401855, "timer/agent.save_frac": 0.03982157635033049, "timer/agent.save_avg": 8.775980949401855, "timer/agent.save_min": 8.775980949401855, "timer/agent.save_max": 8.775980949401855, "timer/agent.policy_count": 231.0, "timer/agent.policy_total": 22.353583574295044, "timer/agent.policy_frac": 0.10143081897505188, "timer/agent.policy_avg": 0.09676876006188331, "timer/agent.policy_min": 0.010082244873046875, "timer/agent.policy_max": 16.25838279724121, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.2901763916015625e-05, "timer/dataset_train_frac": 1.492938637169061e-07, "timer/dataset_train_avg": 3.2901763916015625e-05, "timer/dataset_train_min": 3.2901763916015625e-05, "timer/dataset_train_max": 3.2901763916015625e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.974294424057, "timer/agent.train_frac": 0.4173392591428758, "timer/agent.train_avg": 91.974294424057, "timer/agent.train_min": 91.974294424057, "timer/agent.train_max": 91.974294424057, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.011672258377075, "timer/agent.report_frac": 0.10895450271017802, "timer/agent.report_avg": 12.005836129188538, "timer/agent.report_min": 0.24466204643249512, "timer/agent.report_max": 23.76701021194458, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 1.5686674086196657e-07, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05}
{"step": 1576, "time": 339.3116235733032, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 1584, "time": 341.9309251308441, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 1648, "time": 345.5990037918091, "episode/length": 127.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 1648, "time": 345.60708475112915, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 1968, "time": 359.76970982551575, "episode/length": 39.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 2464, "time": 378.1000978946686, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 2584, "time": 383.4848487377167, "episode/length": 144.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 2864, "time": 394.85403776168823, "episode/length": 171.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 2928, "time": 398.64251589775085, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 3136, "time": 407.2532625198364, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 3184, "time": 410.47755241394043, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 3312, "time": 416.2866475582123, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 3448, "time": 422.4217915534973, "episode/length": 64.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 3776, "time": 435.57949113845825, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 3872, "time": 440.4693486690521, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 4528, "time": 464.07505202293396, "episode/length": 167.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 4616, "time": 468.45290875434875, "episode/length": 218.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 4784, "time": 476.0225439071655, "episode/length": 205.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 4952, "time": 483.1856269836426, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 5128, "time": 490.76794385910034, "episode/length": 209.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 5144, "time": 493.0067663192749, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 5256, "time": 498.4899981021881, "episode/length": 79.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 5392, "time": 504.9111695289612, "episode/length": 365.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 5528, "time": 510.8655319213867, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 5680, "time": 517.8539175987244, "episode/length": 111.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 5912, "time": 527.0236372947693, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 6304, "time": 541.9563484191895, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 6424, "time": 547.3554377555847, "episode/length": 92.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.0}
{"step": 6440, "time": 549.5472180843353, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 6632, "time": 557.6957745552063, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 6672, "time": 560.8816673755646, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 6768, "time": 565.7101283073425, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 6824, "time": 568.9614279270172, "episode/length": 195.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 7408, "time": 590.5745272636414, "episode/length": 186.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 7432, "time": 592.8416843414307, "episode/length": 123.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 7656, "time": 602.1677503585815, "episode/length": 153.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 7920, "time": 612.8012762069702, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 8056, "time": 618.8463253974915, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 8096, "time": 621.957319021225, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 8104, "time": 623.6448714733124, "episode/length": 224.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 8120, "time": 625.7218770980835, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 8416, "time": 639.4071090221405, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 8744, "time": 651.9033048152924, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 8912, "time": 659.465231180191, "episode/length": 106.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 8944, "time": 662.3384273052216, "episode/length": 65.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 9032, "time": 666.6167805194855, "episode/length": 138.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 9128, "time": 671.5723855495453, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 9424, "time": 683.4162979125977, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 9512, "time": 687.7688360214233, "episode/length": 175.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 9664, "time": 694.9641137123108, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 728.7638251781464, "eval_episode/length": 109.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 10088, "time": 732.132940530777, "eval_episode/length": 149.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 10088, "time": 734.0128247737885, "eval_episode/length": 154.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 10088, "time": 735.9060144424438, "eval_episode/length": 162.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 10088, "time": 737.8489170074463, "eval_episode/length": 170.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 10088, "time": 739.977906703949, "eval_episode/length": 183.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 10088, "time": 742.3467164039612, "eval_episode/length": 199.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 10088, "time": 744.2935206890106, "eval_episode/length": 208.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 10136, "time": 745.9170999526978, "episode/length": 148.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 10312, "time": 753.5660681724548, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 10600, "time": 765.0238280296326, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 10680, "time": 769.3237595558167, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 10768, "time": 774.1850099563599, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 10816, "time": 777.4450531005859, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 10928, "time": 782.9411075115204, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 11048, "time": 788.4007863998413, "episode/length": 202.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 11520, "time": 806.3236610889435, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 11640, "time": 811.8371579647064, "episode/length": 108.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 11912, "time": 822.6251983642578, "episode/length": 163.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 12056, "time": 829.1031980514526, "episode/length": 217.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 12208, "time": 836.0451662540436, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 12216, "time": 837.7013607025146, "episode/length": 191.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 12240, "time": 840.2998213768005, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 12600, "time": 853.9396300315857, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 12776, "time": 861.539941072464, "episode/length": 141.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 12944, "time": 869.0771145820618, "episode/length": 177.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 13208, "time": 879.4102022647858, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 13248, "time": 882.5175020694733, "episode/length": 148.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 13464, "time": 891.252094745636, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 13544, "time": 895.5606684684753, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 14008, "time": 912.9884538650513, "episode/length": 224.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 14088, "time": 917.3399806022644, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 14160, "time": 921.5275089740753, "episode/length": 194.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 14336, "time": 929.1926021575928, "episode/length": 194.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 14504, "time": 936.3757693767548, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 14680, "time": 944.1362512111664, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 14968, "time": 955.4132306575775, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 15024, "time": 959.1463057994843, "episode/length": 126.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 15120, "time": 964.0016968250275, "episode/length": 97.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 15472, "time": 977.5537252426147, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 15664, "time": 985.6271953582764, "episode/length": 306.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 15664, "time": 985.6362307071686, "episode/length": 196.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 15936, "time": 998.0513112545013, "episode/length": 178.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 16424, "time": 1017.4957683086395, "episode/length": 174.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 16568, "time": 1024.6219296455383, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 16752, "time": 1032.7010114192963, "episode/length": 203.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 16768, "time": 1034.719200372696, "episode/length": 260.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 16840, "time": 1038.4857892990112, "episode/length": 146.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 17040, "time": 1047.0314450263977, "episode/length": 195.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 17168, "time": 1053.3077590465546, "episode/length": 187.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 17176, "time": 1055.0232303142548, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 17200, "time": 1057.7002980709076, "episode/length": 78.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9493670886075949, "episode/intrinsic_return": 0.0}
{"step": 17992, "time": 1085.783844947815, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 18264, "time": 1096.5856778621674, "episode/length": 229.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9869565217391304, "episode/intrinsic_return": 0.0}
{"step": 18360, "time": 1101.4669494628906, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 18360, "time": 1101.473937511444, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 18392, "time": 1106.1444296836853, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 18408, "time": 1108.3814010620117, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 19000, "time": 1130.29221534729, "episode/length": 75.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 19064, "time": 1134.0769016742706, "episode/length": 81.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 19288, "time": 1143.293139219284, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 19360, "time": 1147.6439080238342, "episode/length": 272.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 19624, "time": 1157.9176831245422, "episode/length": 32.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 19832, "time": 1166.4817163944244, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 19992, "time": 1173.5326480865479, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 19992, "time": 1173.545936346054, "episode/length": 402.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9801488833746899, "episode/intrinsic_return": 0.0}
{"step": 20048, "time": 1179.1001720428467, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1199.858063697815, "eval_episode/length": 123.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9596774193548387}
{"step": 20072, "time": 1202.986745595932, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 20072, "time": 1205.53298330307, "eval_episode/length": 173.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 20072, "time": 1207.2062480449677, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 20072, "time": 1209.934471130371, "eval_episode/length": 200.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 20072, "time": 1212.1408104896545, "eval_episode/length": 216.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 20072, "time": 1214.5243623256683, "eval_episode/length": 233.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9914529914529915}
{"step": 20072, "time": 1218.0703268051147, "eval_episode/length": 277.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9892086330935251}
{"step": 20080, "time": 1218.5647821426392, "episode/length": 98.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 20208, "time": 1224.6926062107086, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 20800, "time": 1246.3164262771606, "episode/length": 100.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 21120, "time": 1258.7528915405273, "episode/length": 256.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 21360, "time": 1269.0872731208801, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 21424, "time": 1273.0933372974396, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 21424, "time": 1273.1121942996979, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 21616, "time": 1283.3014216423035, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 21704, "time": 1287.6996817588806, "episode/length": 259.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 22376, "time": 1312.001502752304, "episode/length": 118.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 22417, "time": 1315.7587909698486, "train_stats/sum_log_reward": 1.1084033376028557, "train_stats/max_log_achievement_collect_drink": 2.899159663865546, "train_stats/max_log_achievement_collect_sapling": 8.647058823529411, "train_stats/max_log_achievement_collect_wood": 0.19327731092436976, "train_stats/max_log_achievement_place_plant": 0.7058823529411765, "train_stats/max_log_achievement_wake_up": 0.6302521008403361, "train_stats/mean_log_entropy": 0.9751951305680916, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.315069110576923, "train/action_min": 0.0, "train/action_std": 2.5052402881475597, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.022773841016169173, "train/actor_opt_grad_steps": 655.0, "train/actor_opt_loss": 179.80649260511765, "train/adv_mag": 1.907413709597089, "train/adv_max": 1.902211807643135, "train/adv_mean": 0.03265817966731937, "train/adv_min": -0.31504441921211906, "train/adv_std": 0.15863889176577617, "train/cont_avg": 0.9946138822115385, "train/cont_loss_mean": 0.026930402548840413, "train/cont_loss_std": 0.24577916373427097, "train/cont_neg_acc": 0.05390110004406709, "train/cont_neg_loss": 3.181757379953678, "train/cont_pos_acc": 0.9970811316600212, "train/cont_pos_loss": 0.010072202987234609, "train/cont_pred": 0.9909752511061155, "train/cont_rate": 0.9946138822115385, "train/dyn_loss_mean": 5.545719723518078, "train/dyn_loss_std": 7.282138875757273, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.757366296878228, "train/extr_critic_critic_opt_grad_steps": 655.0, "train/extr_critic_critic_opt_loss": 23274.011876502405, "train/extr_critic_mag": 0.3197815647492042, "train/extr_critic_max": 0.3197815638322097, "train/extr_critic_mean": 0.11015531810549778, "train/extr_critic_min": -0.06099655811603253, "train/extr_critic_std": 0.11167911522024339, "train/extr_return_normed_mag": 2.1998681073972524, "train/extr_return_normed_max": 2.198865086853934, "train/extr_return_normed_mean": 0.2254466614471032, "train/extr_return_normed_min": -0.16493933086234253, "train/extr_return_normed_std": 0.212418126592932, "train/extr_return_rate": 0.08899088893164074, "train/extr_return_raw_mag": 2.3986346479003817, "train/extr_return_raw_max": 2.3978205838240685, "train/extr_return_raw_mean": 0.15024194710422306, "train/extr_return_raw_min": -0.313821851870363, "train/extr_return_raw_std": 0.2601030773133971, "train/extr_reward_mag": 0.6038331948793851, "train/extr_reward_max": 0.6037827170812167, "train/extr_reward_mean": 0.007923617128492948, "train/extr_reward_min": -0.047316952852102426, "train/extr_reward_std": 0.04783114867069199, "train/image_loss_mean": 93.53736196664663, "train/image_loss_std": 50.52616864717924, "train/model_loss_mean": 97.2137682401217, "train/model_loss_std": 51.932371381612924, "train/model_opt_grad_norm": 415.02789987417367, "train/model_opt_grad_steps": 646.0, "train/model_opt_loss": 2047.6915184607872, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 24.03846153846154, "train/policy_entropy_mag": 1.393923389281218, "train/policy_entropy_max": 1.393923389281218, "train/policy_entropy_mean": 0.9028680842083234, "train/policy_entropy_min": 0.7101852100629072, "train/policy_entropy_std": 0.12302755538302546, "train/policy_logprob_mag": 6.782257608266977, "train/policy_logprob_max": -0.3568485946752704, "train/policy_logprob_mean": -0.9031767345391787, "train/policy_logprob_min": -6.782257608266977, "train/policy_logprob_std": 0.7983883208953417, "train/policy_randomness_mag": 0.4919937864232522, "train/policy_randomness_max": 0.4919937864232522, "train/policy_randomness_mean": 0.3186728159252268, "train/policy_randomness_min": 0.2506642138442168, "train/policy_randomness_std": 0.043423328248676486, "train/post_ent_mag": 50.07899662898137, "train/post_ent_max": 50.07899662898137, "train/post_ent_mean": 34.13867441324087, "train/post_ent_min": 17.201453986534705, "train/post_ent_std": 5.973274179032216, "train/prior_ent_mag": 56.063958916297324, "train/prior_ent_max": 56.063958916297324, "train/prior_ent_mean": 40.078840255737305, "train/prior_ent_min": 22.280214617802546, "train/prior_ent_std": 5.507197989294162, "train/rep_loss_mean": 5.545719723518078, "train/rep_loss_std": 7.282138875757273, "train/reward_avg": 0.007271634552699442, "train/reward_loss_mean": 0.32204468158575206, "train/reward_loss_std": 0.6492662886014351, "train/reward_max_data": 1.0023076928578891, "train/reward_max_pred": 0.6890946333224957, "train/reward_neg_acc": 0.997703376183143, "train/reward_neg_loss": 0.2878861725330353, "train/reward_pos_acc": 0.47937682546102084, "train/reward_pos_loss": 3.057181473878714, "train/reward_pred": 0.004894255078397691, "train/reward_rate": 0.012154447115384616, "train_stats/max_log_achievement_make_wood_pickaxe": 0.010309278350515464, "train_stats/max_log_achievement_place_table": 0.010309278350515464, "train_stats/max_log_achievement_eat_cow": 0.15789473684210525, "eval_stats/sum_log_reward": 1.8499999418854713, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 7.5625, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "train_stats/max_log_achievement_defeat_zombie": 0.37681159420289856, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0169668011367321, "report/cont_loss_std": 0.1637507677078247, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 1.7515596151351929, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003308589104562998, "report/cont_pred": 0.9951410293579102, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.432765007019043, "report/dyn_loss_std": 6.379791259765625, "report/image_loss_mean": 32.18656921386719, "report/image_loss_std": 24.49509620666504, "report/model_loss_mean": 36.224586486816406, "report/model_loss_std": 26.17338752746582, "report/post_ent_mag": 45.04766082763672, "report/post_ent_max": 45.04766082763672, "report/post_ent_mean": 31.002012252807617, "report/post_ent_min": 13.593481063842773, "report/post_ent_std": 4.913151741027832, "report/prior_ent_mag": 53.84389114379883, "report/prior_ent_max": 53.84389114379883, "report/prior_ent_mean": 37.73191452026367, "report/prior_ent_min": 16.578723907470703, "report/prior_ent_std": 5.260196208953857, "report/rep_loss_mean": 6.432765007019043, "report/rep_loss_std": 6.379791259765625, "report/reward_avg": 0.007226563058793545, "report/reward_loss_mean": 0.16139212250709534, "report/reward_loss_std": 0.5265737175941467, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9877206087112427, "report/reward_neg_acc": 0.9950446486473083, "report/reward_neg_loss": 0.14160455763339996, "report/reward_pos_acc": 0.8000000715255737, "report/reward_pos_loss": 1.492436408996582, "report/reward_pred": 0.0072456542402505875, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.008852114900946617, "eval/cont_loss_std": 0.16393160820007324, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 2.9547266960144043, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00019626434368547052, "eval/cont_pred": 0.999608039855957, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 8.745628356933594, "eval/dyn_loss_std": 7.162326335906982, "eval/image_loss_mean": 54.86211395263672, "eval/image_loss_std": 68.41361236572266, "eval/model_loss_mean": 60.27759552001953, "eval/model_loss_std": 69.6884536743164, "eval/post_ent_mag": 52.08395767211914, "eval/post_ent_max": 52.08395767211914, "eval/post_ent_mean": 29.639328002929688, "eval/post_ent_min": 13.188539505004883, "eval/post_ent_std": 6.155208110809326, "eval/prior_ent_mag": 55.496971130371094, "eval/prior_ent_max": 55.496971130371094, "eval/prior_ent_mean": 36.46148681640625, "eval/prior_ent_min": 16.469552993774414, "eval/prior_ent_std": 6.5049591064453125, "eval/rep_loss_mean": 8.745628356933594, "eval/rep_loss_std": 7.162326335906982, "eval/reward_avg": 0.01689453050494194, "eval/reward_loss_mean": 0.15925279259681702, "eval/reward_loss_std": 0.9442318081855774, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9888747930526733, "eval/reward_neg_acc": 0.9910358786582947, "eval/reward_neg_loss": 0.08859854191541672, "eval/reward_pos_acc": 0.45000001788139343, "eval/reward_pos_loss": 3.7060959339141846, "eval/reward_pred": 0.013560277409851551, "eval/reward_rate": 0.01953125, "replay/size": 21913.0, "replay/inserts": 20856.0, "replay/samples": 20848.0, "replay/insert_wait_avg": 1.4838744362149606e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.223967447522413e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6792.0, "eval_replay/inserts": 3896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.322378612886464e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.5135359764099, "timer/env.step_count": 2607.0, "timer/env.step_total": 265.6084609031677, "timer/env.step_frac": 0.2719967016510298, "timer/env.step_avg": 0.10188280049987254, "timer/env.step_min": 0.023227691650390625, "timer/env.step_max": 3.6199588775634766, "timer/replay._sample_count": 20848.0, "timer/replay._sample_total": 11.54747486114502, "timer/replay._sample_frac": 0.011825207163768364, "timer/replay._sample_avg": 0.0005538888555806322, "timer/replay._sample_min": 0.000362396240234375, "timer/replay._sample_max": 0.012099981307983398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3094.0, "timer/agent.policy_total": 53.32564401626587, "timer/agent.policy_frac": 0.05460819748181563, "timer/agent.policy_avg": 0.01723517906149511, "timer/agent.policy_min": 0.009910106658935547, "timer/agent.policy_max": 0.11063885688781738, "timer/dataset_train_count": 1303.0, "timer/dataset_train_total": 0.1494290828704834, "timer/dataset_train_frac": 0.00015302305330675234, "timer/dataset_train_avg": 0.00011468080036107705, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0006175041198730469, "timer/agent.train_count": 1303.0, "timer/agent.train_total": 589.5481579303741, "timer/agent.train_frac": 0.6037275841147338, "timer/agent.train_avg": 0.45245445735255113, "timer/agent.train_min": 0.4373054504394531, "timer/agent.train_max": 1.3945271968841553, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4743530750274658, "timer/agent.report_frac": 0.00048576190452205364, "timer/agent.report_avg": 0.2371765375137329, "timer/agent.report_min": 0.22794032096862793, "timer/agent.report_max": 0.2464127540588379, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.711123572619167e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 21.357358181496085}
{"step": 22520, "time": 1319.3241772651672, "episode/length": 101.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 22544, "time": 1322.1732075214386, "episode/length": 217.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 22824, "time": 1333.037288427353, "episode/length": 182.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 22904, "time": 1337.4000594615936, "episode/length": 47.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 23032, "time": 1343.2821583747864, "episode/length": 352.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745042492917847, "episode/intrinsic_return": 0.0}
{"step": 23136, "time": 1348.61301612854, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 23160, "time": 1350.8729951381683, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 23200, "time": 1354.1518468856812, "episode/length": 259.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 23248, "time": 1357.4457256793976, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 23696, "time": 1374.2155644893646, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 23816, "time": 1379.6672735214233, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 24480, "time": 1404.0718021392822, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 24528, "time": 1407.296310186386, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 24608, "time": 1413.1967511177063, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 24624, "time": 1415.4205522537231, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 24776, "time": 1421.920073747635, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 24936, "time": 1428.9439001083374, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 25288, "time": 1442.544180393219, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 25296, "time": 1444.725491285324, "episode/length": 255.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 25328, "time": 1447.462284564972, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 25712, "time": 1462.0023036003113, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 25936, "time": 1471.241266965866, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 26016, "time": 1475.6040208339691, "episode/length": 134.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 26080, "time": 1479.9333341121674, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 26136, "time": 1483.6734325885773, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 26320, "time": 1492.2043416500092, "episode/length": 128.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.0}
{"step": 26520, "time": 1500.279690504074, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 26856, "time": 1513.3727433681488, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 26976, "time": 1519.3075714111328, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 27472, "time": 1537.7734441757202, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 27632, "time": 1544.7295515537262, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 27664, "time": 1547.3416748046875, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 27832, "time": 1554.3689470291138, "episode/length": 226.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 28216, "time": 1569.0279083251953, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 28256, "time": 1572.1666464805603, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 28320, "time": 1576.0724697113037, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 28584, "time": 1586.2821311950684, "episode/length": 45.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 28768, "time": 1594.4626450538635, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 28816, "time": 1597.6813521385193, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 29200, "time": 1612.4330592155457, "episode/length": 359.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 29216, "time": 1615.0334243774414, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 29416, "time": 1623.9037787914276, "episode/length": 222.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 29464, "time": 1627.0401709079742, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 29576, "time": 1632.3838608264923, "episode/length": 156.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 29656, "time": 1636.7459156513214, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1672.4398584365845, "eval_episode/length": 129.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 30056, "time": 1675.6714866161346, "eval_episode/length": 150.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 30056, "time": 1678.4252514839172, "eval_episode/length": 165.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 30056, "time": 1680.2681198120117, "eval_episode/length": 170.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 30056, "time": 1682.6050169467926, "eval_episode/length": 186.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 30056, "time": 1685.1328997612, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 30056, "time": 1686.993509054184, "eval_episode/length": 213.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 30056, "time": 1692.0879657268524, "eval_episode/length": 296.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9932659932659933}
{"step": 30120, "time": 1694.2161736488342, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 30192, "time": 1698.462247133255, "episode/length": 177.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 30472, "time": 1709.275658607483, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 30528, "time": 1713.0865051746368, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 30672, "time": 1719.5101373195648, "episode/length": 126.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 31096, "time": 1735.1697375774384, "episode/length": 209.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 31136, "time": 1738.2965559959412, "episode/length": 239.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 31232, "time": 1743.23894572258, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 31816, "time": 1764.3410441875458, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 31832, "time": 1766.351309299469, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 32040, "time": 1774.9541206359863, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 32080, "time": 1778.115365743637, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 32176, "time": 1782.916263103485, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 32344, "time": 1789.9299495220184, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 32576, "time": 1799.498637676239, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 32688, "time": 1805.084540605545, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 33072, "time": 1820.8570363521576, "episode/length": 90.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 33168, "time": 1825.685061454773, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 33192, "time": 1827.8382172584534, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 33360, "time": 1835.4464268684387, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 34048, "time": 1860.1232767105103, "episode/length": 233.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 34064, "time": 1862.4507944583893, "episode/length": 247.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 34088, "time": 1864.6301367282867, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 34160, "time": 1868.9237880706787, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 34256, "time": 1873.8034670352936, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 34392, "time": 1879.7117140293121, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 34512, "time": 1885.7090628147125, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 35192, "time": 1910.171196937561, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 35280, "time": 1915.3775346279144, "episode/length": 239.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 35328, "time": 1919.1471354961395, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 35488, "time": 1926.9473145008087, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 35800, "time": 1939.126210451126, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 35800, "time": 1939.1351101398468, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 35872, "time": 1945.2656691074371, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 35904, "time": 1947.8316566944122, "episode/length": 231.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 36408, "time": 1966.1348731517792, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 36968, "time": 1986.6461510658264, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 37016, "time": 1989.9034702777863, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 37152, "time": 1996.1952865123749, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 37208, "time": 1999.4981260299683, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 37328, "time": 2005.2691917419434, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 37584, "time": 2015.6442785263062, "episode/length": 261.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 37624, "time": 2018.4396007061005, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 37632, "time": 2020.510145187378, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 38528, "time": 2052.3546130657196, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 38560, "time": 2054.9251050949097, "episode/length": 115.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 38568, "time": 2056.457392692566, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 38568, "time": 2056.4659819602966, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 38792, "time": 2067.3733711242676, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 38856, "time": 2071.146807909012, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 38992, "time": 2077.828873872757, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 38992, "time": 2077.8392300605774, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 39360, "time": 2093.508001089096, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 39832, "time": 2110.7361550331116, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 39840, "time": 2112.853264570236, "episode/length": 158.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 39984, "time": 2119.878641605377, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2138.397329568863, "eval_episode/length": 48.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9183673469387755}
{"step": 40040, "time": 2141.7290794849396, "eval_episode/length": 89.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 40040, "time": 2146.213859796524, "eval_episode/length": 156.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 40040, "time": 2148.2511830329895, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 40040, "time": 2151.239465236664, "eval_episode/length": 198.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 40040, "time": 2152.985750436783, "eval_episode/length": 204.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 40040, "time": 2154.722443342209, "eval_episode/length": 207.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 40040, "time": 2156.3934638500214, "eval_episode/length": 208.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 40216, "time": 2162.412449836731, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 40360, "time": 2168.903567790985, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 40600, "time": 2178.477234363556, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 40632, "time": 2181.1804780960083, "episode/length": 229.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 40736, "time": 2186.353931427002, "episode/length": 64.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 41072, "time": 2200.582968235016, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 41080, "time": 2202.272136449814, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 41192, "time": 2207.5552220344543, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 41240, "time": 2210.833250761032, "episode/length": 75.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 41480, "time": 2220.3767850399017, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 41696, "time": 2229.5310196876526, "episode/length": 119.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 41760, "time": 2233.217135667801, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 41848, "time": 2237.556037902832, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 42320, "time": 2255.2204370498657, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 42344, "time": 2257.5564284324646, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 42384, "time": 2260.8263459205627, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 42456, "time": 2264.612746477127, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 42848, "time": 2279.700884580612, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 43032, "time": 2287.27011346817, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 43296, "time": 2297.9975016117096, "episode/length": 199.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 43640, "time": 2310.8581941127777, "episode/length": 161.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 43648, "time": 2313.145706653595, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 43657, "time": 2315.7726922035217, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.452827625704887, "train/action_min": 0.0, "train/action_std": 2.4111749794250144, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02972135789468324, "train/actor_opt_grad_steps": 1970.0, "train/actor_opt_loss": 5.4531092623570805, "train/adv_mag": 1.5501872417622042, "train/adv_max": 1.5488829679955216, "train/adv_mean": 0.008333217489285416, "train/adv_min": -0.5423960522153324, "train/adv_std": 0.11356770899847038, "train/cont_avg": 0.9942287359022557, "train/cont_loss_mean": 0.003848385385648917, "train/cont_loss_std": 0.06567112680672185, "train/cont_neg_acc": 0.8325224727617971, "train/cont_neg_loss": 0.469956902506965, "train/cont_pos_acc": 0.9997782303874654, "train/cont_pos_loss": 0.001141316280176794, "train/cont_pred": 0.994372426567221, "train/cont_rate": 0.9942287359022557, "train/dyn_loss_mean": 6.266159946757152, "train/dyn_loss_std": 5.8697749976825, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3923419745344865, "train/extr_critic_critic_opt_grad_steps": 1970.0, "train/extr_critic_critic_opt_loss": 15691.56929188205, "train/extr_critic_mag": 1.6136756194265265, "train/extr_critic_max": 1.6136756194265265, "train/extr_critic_mean": 0.30378025487989635, "train/extr_critic_min": -0.3786764064229521, "train/extr_critic_std": 0.6360667141756617, "train/extr_return_normed_mag": 2.3579855852557303, "train/extr_return_normed_max": 2.3579855852557303, "train/extr_return_normed_mean": 0.3480028839487779, "train/extr_return_normed_min": -0.18486861691327022, "train/extr_return_normed_std": 0.35710566496490537, "train/extr_return_rate": 0.3091048101397385, "train/extr_return_raw_mag": 4.257331023538919, "train/extr_return_raw_max": 4.257331023538919, "train/extr_return_raw_mean": 0.3215018389816571, "train/extr_return_raw_min": -0.7400244696247846, "train/extr_return_raw_std": 0.7069510653951114, "train/extr_reward_mag": 0.9989817115597259, "train/extr_reward_max": 0.9989817115597259, "train/extr_reward_mean": 0.012626154710629717, "train/extr_reward_min": -0.21663779782173329, "train/extr_reward_std": 0.09074455141124868, "train/image_loss_mean": 15.890515352550306, "train/image_loss_std": 14.0569933841103, "train/model_loss_mean": 19.729374899900048, "train/model_loss_std": 15.864967503942045, "train/model_opt_grad_norm": 125.38132554247863, "train/model_opt_grad_steps": 1961.0, "train/model_opt_loss": 1079.9544654788829, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 57.27208646616541, "train/policy_entropy_mag": 1.7645552705105085, "train/policy_entropy_max": 1.7645552705105085, "train/policy_entropy_mean": 0.21088208538249023, "train/policy_entropy_min": 0.0794234160417901, "train/policy_entropy_std": 0.23500955777060717, "train/policy_logprob_mag": 7.4381910947928755, "train/policy_logprob_max": -0.00946279426098318, "train/policy_logprob_mean": -0.21044036958898818, "train/policy_logprob_min": -7.4381910947928755, "train/policy_logprob_std": 0.840548158588266, "train/policy_randomness_mag": 0.6228105757469521, "train/policy_randomness_max": 0.6228105757469521, "train/policy_randomness_mean": 0.07443212255611456, "train/policy_randomness_min": 0.02803298048114866, "train/policy_randomness_std": 0.08294806046817536, "train/post_ent_mag": 41.25124947110513, "train/post_ent_max": 41.25124947110513, "train/post_ent_mean": 30.372895965002535, "train/post_ent_min": 13.544963220008334, "train/post_ent_std": 4.301333590557701, "train/prior_ent_mag": 51.63437904988913, "train/prior_ent_max": 51.63437904988913, "train/prior_ent_mean": 36.98360288232789, "train/prior_ent_min": 17.13546425955636, "train/prior_ent_std": 5.026274727699452, "train/rep_loss_mean": 6.266159946757152, "train/rep_loss_std": 5.8697749976825, "train/reward_avg": 0.008302249720309601, "train/reward_loss_mean": 0.07531507091974854, "train/reward_loss_std": 0.3606657534837723, "train/reward_max_data": 1.0127819579346735, "train/reward_max_pred": 0.996260396519998, "train/reward_neg_acc": 0.9962106651829598, "train/reward_neg_loss": 0.05814805631070657, "train/reward_pos_acc": 0.8687546947844943, "train/reward_pos_loss": 1.3387085813328736, "train/reward_pred": 0.00754704299869534, "train/reward_rate": 0.013547051221804511, "train_stats/sum_log_reward": 2.2788616984598034, "train_stats/max_log_achievement_collect_drink": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.7398373983739837, "train_stats/max_log_achievement_collect_wood": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2032520325203252, "train_stats/max_log_achievement_eat_cow": 0.0975609756097561, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 2.5853658536585367, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.2439024390243902, "train_stats/mean_log_entropy": 0.14458203951760037, "eval_stats/sum_log_reward": 2.34999992698431, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 3.25, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 3.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.015384615384615385, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0003964202478528023, "report/cont_loss_std": 0.005921670701354742, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001002259086817503, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003916498681064695, "report/cont_pred": 0.991823673248291, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.138307571411133, "report/dyn_loss_std": 5.931164741516113, "report/image_loss_mean": 12.859667778015137, "report/image_loss_std": 13.501328468322754, "report/model_loss_mean": 16.591670989990234, "report/model_loss_std": 15.222509384155273, "report/post_ent_mag": 40.79058837890625, "report/post_ent_max": 40.79058837890625, "report/post_ent_mean": 30.67322540283203, "report/post_ent_min": 13.036004066467285, "report/post_ent_std": 3.8773210048675537, "report/prior_ent_mag": 50.472923278808594, "report/prior_ent_max": 50.472923278808594, "report/prior_ent_mean": 37.4506950378418, "report/prior_ent_min": 15.36355972290039, "report/prior_ent_std": 4.618490695953369, "report/rep_loss_mean": 6.138307571411133, "report/rep_loss_std": 5.931164741516113, "report/reward_avg": 0.0035156249068677425, "report/reward_loss_mean": 0.04862010478973389, "report/reward_loss_std": 0.21294596791267395, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0002682209014893, "report/reward_neg_acc": 0.9970414042472839, "report/reward_neg_loss": 0.03854057937860489, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 1.0706840753555298, "report/reward_pred": 0.002673207549378276, "report/reward_rate": 0.009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 8.932787022786215e-05, "eval/cont_loss_std": 0.002788335783407092, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08927247673273087, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.1498187834367855e-06, "eval/cont_pred": 0.9991046786308289, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 10.226908683776855, "eval/dyn_loss_std": 6.660369396209717, "eval/image_loss_mean": 28.99787712097168, "eval/image_loss_std": 22.16624641418457, "eval/model_loss_mean": 35.198326110839844, "eval/model_loss_std": 24.632511138916016, "eval/post_ent_mag": 45.890541076660156, "eval/post_ent_max": 45.890541076660156, "eval/post_ent_mean": 29.032779693603516, "eval/post_ent_min": 13.951043128967285, "eval/post_ent_std": 5.403021335601807, "eval/prior_ent_mag": 53.224693298339844, "eval/prior_ent_max": 53.224693298339844, "eval/prior_ent_mean": 36.80262756347656, "eval/prior_ent_min": 14.256433486938477, "eval/prior_ent_std": 7.7249345779418945, "eval/rep_loss_mean": 10.226908683776855, "eval/rep_loss_std": 6.660369396209717, "eval/reward_avg": 0.01357421837747097, "eval/reward_loss_mean": 0.0642116516828537, "eval/reward_loss_std": 0.5763589143753052, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018408298492432, "eval/reward_neg_acc": 0.997026801109314, "eval/reward_neg_loss": 0.016912803053855896, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.2458479404449463, "eval/reward_pred": 0.009088380262255669, "eval/reward_rate": 0.0146484375, "replay/size": 43153.0, "replay/inserts": 21240.0, "replay/samples": 21248.0, "replay/insert_wait_avg": 1.4052440442158903e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.110803345599807e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10840.0, "eval_replay/inserts": 4048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2532288849118198e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.00634765625, "timer/env.step_count": 2655.0, "timer/env.step_total": 276.2485890388489, "timer/env.step_frac": 0.27624683551889684, "timer/env.step_avg": 0.10404843278299393, "timer/env.step_min": 0.023349761962890625, "timer/env.step_max": 3.534902811050415, "timer/replay._sample_count": 21248.0, "timer/replay._sample_total": 11.503230094909668, "timer/replay._sample_frac": 0.011503157076822755, "timer/replay._sample_avg": 0.0005413794284125408, "timer/replay._sample_min": 0.0003845691680908203, "timer/replay._sample_max": 0.010357379913330078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3161.0, "timer/agent.policy_total": 54.27404260635376, "timer/agent.policy_frac": 0.054273698095574835, "timer/agent.policy_avg": 0.017169896427191952, "timer/agent.policy_min": 0.00944972038269043, "timer/agent.policy_max": 0.13044023513793945, "timer/dataset_train_count": 1328.0, "timer/dataset_train_total": 0.15995264053344727, "timer/dataset_train_frac": 0.00015995162521551377, "timer/dataset_train_avg": 0.00012044626546193318, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.011457681655883789, "timer/agent.train_count": 1328.0, "timer/agent.train_total": 600.0547878742218, "timer/agent.train_frac": 0.6000509789568749, "timer/agent.train_avg": 0.4518484848450465, "timer/agent.train_min": 0.436917781829834, "timer/agent.train_max": 1.5327260494232178, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4732375144958496, "timer/agent.report_frac": 0.0004732345105658509, "timer/agent.report_avg": 0.2366187572479248, "timer/agent.report_min": 0.2299175262451172, "timer/agent.report_max": 0.24331998825073242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3139972133965945e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 21.239617390505895}
{"step": 43920, "time": 2324.619631767273, "episode/length": 191.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 44176, "time": 2334.731048822403, "episode/length": 214.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 44232, "time": 2338.1020200252533, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 44536, "time": 2350.0896706581116, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 44664, "time": 2356.0483360290527, "episode/length": 362.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 44784, "time": 2361.97949385643, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 44896, "time": 2367.8819086551666, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 45504, "time": 2390.4780852794647, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 45600, "time": 2395.325564146042, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 45864, "time": 2405.7438282966614, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 45864, "time": 2405.751212835312, "episode/length": 134.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 45952, "time": 2412.3868460655212, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 46080, "time": 2418.281913757324, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 46104, "time": 2420.5280158519745, "episode/length": 74.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 46248, "time": 2426.8310511112213, "episode/length": 47.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 46536, "time": 2438.1442382335663, "episode/length": 361.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751381215469613, "episode/intrinsic_return": 0.0}
{"step": 46624, "time": 2443.0053486824036, "episode/length": 244.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 47088, "time": 2460.91801571846, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 47104, "time": 2463.2617468833923, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 47432, "time": 2475.6123926639557, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 47472, "time": 2478.803949356079, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 47840, "time": 2493.40598487854, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 47864, "time": 2495.9626471996307, "episode/length": 201.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 47872, "time": 2498.5557379722595, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 48000, "time": 2504.9963479042053, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 48696, "time": 2530.142333507538, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 48712, "time": 2532.762724876404, "episode/length": 159.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 49048, "time": 2546.290668487549, "episode/length": 242.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 49128, "time": 2550.6769258975983, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 49184, "time": 2555.911987066269, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 49288, "time": 2561.3133883476257, "episode/length": 160.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 49568, "time": 2572.588281393051, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 49576, "time": 2574.25013923645, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 49848, "time": 2585.1259326934814, "episode/length": 82.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2610.546419620514, "eval_episode/length": 112.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 50024, "time": 2612.9740719795227, "eval_episode/length": 130.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9618320610687023}
{"step": 50024, "time": 2615.6291716098785, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 50024, "time": 2617.39307141304, "eval_episode/length": 157.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 50024, "time": 2619.4040253162384, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 50024, "time": 2621.166930913925, "eval_episode/length": 172.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 50024, "time": 2623.463767528534, "eval_episode/length": 189.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 50024, "time": 2625.958241224289, "eval_episode/length": 209.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 50040, "time": 2626.5197949409485, "episode/length": 167.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 50272, "time": 2636.1008989810944, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 50440, "time": 2643.2375934123993, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 50472, "time": 2646.0212347507477, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 50600, "time": 2651.909206867218, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 50984, "time": 2666.4469726085663, "episode/length": 175.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 51168, "time": 2674.5843555927277, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 51248, "time": 2678.9296424388885, "episode/length": 32.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 51320, "time": 2682.6866664886475, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 51344, "time": 2685.3092081546783, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 51384, "time": 2687.993063688278, "episode/length": 117.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 51680, "time": 2699.739486694336, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 51752, "time": 2704.2014656066895, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 52344, "time": 2726.265721797943, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 52608, "time": 2737.296609401703, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 52632, "time": 2739.53484416008, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 52672, "time": 2742.7367470264435, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 52752, "time": 2747.0199024677277, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 52880, "time": 2753.0408124923706, "episode/length": 30.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 52888, "time": 2754.695723295212, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 53008, "time": 2760.669942378998, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 53072, "time": 2764.623775243759, "episode/length": 237.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 53248, "time": 2772.1817989349365, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 53600, "time": 2785.6820619106293, "episode/length": 89.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 54000, "time": 2801.2038807868958, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 54040, "time": 2804.0015103816986, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 54152, "time": 2809.3172421455383, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 54176, "time": 2812.0747628211975, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 54272, "time": 2817.0266678333282, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 54424, "time": 2823.546733379364, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 54496, "time": 2827.881860971451, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 54584, "time": 2832.1613483428955, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 54632, "time": 2835.2743215560913, "episode/length": 73.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 54840, "time": 2843.822015285492, "episode/length": 85.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 55280, "time": 2860.46067738533, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 55808, "time": 2879.820072889328, "episode/length": 191.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 55992, "time": 2887.6135165691376, "episode/length": 175.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 56096, "time": 2892.9061641693115, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 56104, "time": 2894.574851512909, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 56112, "time": 2896.782162666321, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 56160, "time": 2900.10635972023, "episode/length": 247.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 56200, "time": 2902.8179428577423, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 56632, "time": 2919.0961101055145, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 57336, "time": 2944.4038441181183, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 57592, "time": 2955.868907213211, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 57616, "time": 2958.5865976810455, "episode/length": 187.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 57616, "time": 2958.594511985779, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 57736, "time": 2965.8211250305176, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 57960, "time": 2975.2021749019623, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 57976, "time": 2977.3579802513123, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 58008, "time": 2980.1238763332367, "episode/length": 48.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 58200, "time": 2988.3506021499634, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 58328, "time": 2994.3412714004517, "episode/length": 73.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.918918918918919, "episode/intrinsic_return": 0.0}
{"step": 58848, "time": 3014.0294229984283, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 58912, "time": 3017.821774482727, "episode/length": 112.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 58936, "time": 3020.1937856674194, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 59200, "time": 3030.839825630188, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 59296, "time": 3035.8183352947235, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 59328, "time": 3038.5545601844788, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 59392, "time": 3042.264250278473, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 59792, "time": 3057.2864542007446, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3086.3834204673767, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 60008, "time": 3088.2294211387634, "eval_episode/length": 172.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 60008, "time": 3090.0641033649445, "eval_episode/length": 175.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 60008, "time": 3091.7150359153748, "eval_episode/length": 176.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 60008, "time": 3094.5323996543884, "eval_episode/length": 36.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8918918918918919}
{"step": 60008, "time": 3096.4265875816345, "eval_episode/length": 210.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 60008, "time": 3098.3308849334717, "eval_episode/length": 220.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.995475113122172}
{"step": 60008, "time": 3100.051944732666, "eval_episode/length": 222.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 60048, "time": 3101.6190094947815, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 60312, "time": 3111.88809800148, "episode/length": 126.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 60376, "time": 3115.661523103714, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 60504, "time": 3121.460093975067, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 60584, "time": 3125.91565656662, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 60608, "time": 3128.5580911636353, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 60920, "time": 3140.3251469135284, "episode/length": 41.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 61080, "time": 3147.2887048721313, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 61192, "time": 3152.874192237854, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 61552, "time": 3166.9860920906067, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 61848, "time": 3178.3880593776703, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 61920, "time": 3182.7390060424805, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 62008, "time": 3187.0450780391693, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 62024, "time": 3189.169759273529, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 62176, "time": 3196.137771844864, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 62840, "time": 3219.954125404358, "episode/length": 101.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 62896, "time": 3223.6948103904724, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 63040, "time": 3230.2941064834595, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 63064, "time": 3232.563831090927, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 63160, "time": 3237.3983199596405, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 63216, "time": 3241.2049090862274, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 63472, "time": 3251.593643426895, "episode/length": 71.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 63480, "time": 3253.2411239147186, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 63520, "time": 3256.407684803009, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 63528, "time": 3258.1498486995697, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 64320, "time": 3286.5704843997955, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 64648, "time": 3299.411570072174, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 64776, "time": 3305.4747128486633, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 64928, "time": 3312.3711585998535, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 64969, "time": 3316.135881662369, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.483787593984962, "train/action_min": 0.0, "train/action_std": 2.675172437402539, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044719276347554716, "train/actor_opt_grad_steps": 3300.0, "train/actor_opt_loss": 16.389206138488493, "train/adv_mag": 1.7697061134460277, "train/adv_max": 1.7695130042563705, "train/adv_mean": 0.011243203268821887, "train/adv_min": -0.6368442973248044, "train/adv_std": 0.12208287832432223, "train/cont_avg": 0.9941993656015038, "train/cont_loss_mean": 0.0007167350850033841, "train/cont_loss_std": 0.01973566933966687, "train/cont_neg_acc": 0.9722460943057125, "train/cont_neg_loss": 0.07840398273494661, "train/cont_pos_acc": 0.9998965227514282, "train/cont_pos_loss": 0.0002814471125301016, "train/cont_pred": 0.9942176494383275, "train/cont_rate": 0.9941993656015038, "train/dyn_loss_mean": 6.384009375608057, "train/dyn_loss_std": 6.0282575743538995, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3196177294379787, "train/extr_critic_critic_opt_grad_steps": 3300.0, "train/extr_critic_critic_opt_loss": 14095.283438087406, "train/extr_critic_mag": 1.9292883747502376, "train/extr_critic_max": 1.9292883747502376, "train/extr_critic_mean": 0.36062279606896236, "train/extr_critic_min": -0.27499673958111526, "train/extr_critic_std": 0.5541726971479287, "train/extr_return_normed_mag": 2.7902983319490477, "train/extr_return_normed_max": 2.7902983319490477, "train/extr_return_normed_mean": 0.356044616466178, "train/extr_return_normed_min": -0.21763253357625545, "train/extr_return_normed_std": 0.37822215225463524, "train/extr_return_rate": 0.3146812505739972, "train/extr_return_raw_mag": 4.265020225281106, "train/extr_return_raw_max": 4.265020225281106, "train/extr_return_raw_mean": 0.37860243252121417, "train/extr_return_raw_min": -0.5410445496103817, "train/extr_return_raw_std": 0.6056053329231148, "train/extr_reward_mag": 1.0051132117895256, "train/extr_reward_max": 1.0051132117895256, "train/extr_reward_mean": 0.011196798746495094, "train/extr_reward_min": -0.26513807666032835, "train/extr_reward_std": 0.08805424599607188, "train/image_loss_mean": 13.935031801238097, "train/image_loss_std": 15.969545091901507, "train/model_loss_mean": 17.82070663280057, "train/model_loss_std": 17.87857021245741, "train/model_opt_grad_norm": 144.14202321561655, "train/model_opt_grad_steps": 3291.0, "train/model_opt_loss": 2430.1255640015565, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 133.92857142857142, "train/policy_entropy_mag": 2.2581613314779183, "train/policy_entropy_max": 2.2581613314779183, "train/policy_entropy_mean": 0.44622402453332916, "train/policy_entropy_min": 0.07947694835134018, "train/policy_entropy_std": 0.4146713874393836, "train/policy_logprob_mag": 7.437811059163029, "train/policy_logprob_max": -0.00947008362474074, "train/policy_logprob_mean": -0.44619874824258615, "train/policy_logprob_min": -7.437811059163029, "train/policy_logprob_std": 1.05707651869695, "train/policy_randomness_mag": 0.7970318547765115, "train/policy_randomness_max": 0.7970318547765115, "train/policy_randomness_mean": 0.15749749941821384, "train/policy_randomness_min": 0.028051875069513357, "train/policy_randomness_std": 0.14636080275128657, "train/post_ent_mag": 41.363009173170965, "train/post_ent_max": 41.363009173170965, "train/post_ent_mean": 31.34117469213959, "train/post_ent_min": 13.44338673756535, "train/post_ent_std": 4.7549457980277845, "train/prior_ent_mag": 52.84730873968368, "train/prior_ent_max": 52.84730873968368, "train/prior_ent_mean": 37.73043192239632, "train/prior_ent_min": 15.687496464951595, "train/prior_ent_std": 5.556275446612136, "train/rep_loss_mean": 6.384009375608057, "train/rep_loss_std": 6.0282575743538995, "train/reward_avg": 0.010679775568887703, "train/reward_loss_mean": 0.05455236268558897, "train/reward_loss_std": 0.29728677219018, "train/reward_max_data": 1.0052631591495715, "train/reward_max_pred": 1.0014050311612008, "train/reward_neg_acc": 0.9955888905919584, "train/reward_neg_loss": 0.03607144736145672, "train/reward_pos_acc": 0.8998874457258927, "train/reward_pos_loss": 1.1812456366711093, "train/reward_pred": 0.009799179089731797, "train/reward_rate": 0.015962758458646618, "train_stats/sum_log_reward": 2.519354779333357, "train_stats/max_log_achievement_collect_drink": 11.725806451612904, "train_stats/max_log_achievement_collect_sapling": 2.879032258064516, "train_stats/max_log_achievement_collect_wood": 0.4596774193548387, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.21774193548387097, "train_stats/max_log_achievement_eat_cow": 0.13709677419354838, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 1.8870967741935485, "train_stats/max_log_achievement_place_table": 0.008064516129032258, "train_stats/max_log_achievement_wake_up": 1.25, "train_stats/mean_log_entropy": 0.41343105374084366, "eval_stats/sum_log_reward": 2.599999912083149, "eval_stats/max_log_achievement_collect_drink": 7.75, "eval_stats/max_log_achievement_collect_sapling": 2.8125, "eval_stats/max_log_achievement_collect_wood": 0.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0001244252489414066, "report/cont_loss_std": 0.0038925071712583303, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.014071979559957981, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.523606200265931e-07, "report/cont_pred": 0.9913266897201538, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 6.358056545257568, "report/dyn_loss_std": 6.242227077484131, "report/image_loss_mean": 21.29123306274414, "report/image_loss_std": 41.02592086791992, "report/model_loss_mean": 25.160802841186523, "report/model_loss_std": 42.695980072021484, "report/post_ent_mag": 42.157264709472656, "report/post_ent_max": 42.157264709472656, "report/post_ent_mean": 32.519039154052734, "report/post_ent_min": 16.35249137878418, "report/post_ent_std": 3.9781641960144043, "report/prior_ent_mag": 55.938446044921875, "report/prior_ent_max": 55.938446044921875, "report/prior_ent_mean": 39.768898010253906, "report/prior_ent_min": 16.449779510498047, "report/prior_ent_std": 5.190816402435303, "report/rep_loss_mean": 6.358056545257568, "report/rep_loss_std": 6.242227077484131, "report/reward_avg": 0.010839843191206455, "report/reward_loss_mean": 0.05461159721016884, "report/reward_loss_std": 0.2667633593082428, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9973407983779907, "report/reward_neg_acc": 0.9960199594497681, "report/reward_neg_loss": 0.03841787949204445, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.9111742973327637, "report/reward_pred": 0.01135244220495224, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0022400098387151957, "eval/cont_loss_std": 0.03847149387001991, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.035826366394758224, "eval/cont_pos_acc": 0.9980372786521912, "eval/cont_pos_loss": 0.0020752092823386192, "eval/cont_pred": 0.9937783479690552, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 11.907809257507324, "eval/dyn_loss_std": 6.768775463104248, "eval/image_loss_mean": 36.35795593261719, "eval/image_loss_std": 42.881690979003906, "eval/model_loss_mean": 43.561500549316406, "eval/model_loss_std": 44.071929931640625, "eval/post_ent_mag": 43.920570373535156, "eval/post_ent_max": 43.920570373535156, "eval/post_ent_mean": 30.104408264160156, "eval/post_ent_min": 16.495811462402344, "eval/post_ent_std": 4.457347869873047, "eval/prior_ent_mag": 58.59381103515625, "eval/prior_ent_max": 58.59381103515625, "eval/prior_ent_mean": 39.58723449707031, "eval/prior_ent_min": 20.522335052490234, "eval/prior_ent_std": 6.2817606925964355, "eval/rep_loss_mean": 11.907809257507324, "eval/rep_loss_std": 6.768775463104248, "eval/reward_avg": 0.004589843563735485, "eval/reward_loss_mean": 0.05661769583821297, "eval/reward_loss_std": 0.37108010053634644, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9933013916015625, "eval/reward_neg_acc": 0.9960591197013855, "eval/reward_neg_loss": 0.04117347300052643, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 1.798383116722107, "eval/reward_pred": 0.0035952008329331875, "eval/reward_rate": 0.0087890625, "replay/size": 64465.0, "replay/inserts": 21312.0, "replay/samples": 21312.0, "replay/insert_wait_avg": 1.4223896705352509e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.092616963314938e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14304.0, "eval_replay/inserts": 3464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2414422376601856e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3496067523956, "timer/env.step_count": 2664.0, "timer/env.step_total": 281.4583911895752, "timer/env.step_frac": 0.28136002582469266, "timer/env.step_avg": 0.10565254924533603, "timer/env.step_min": 0.023242473602294922, "timer/env.step_max": 3.447085380554199, "timer/replay._sample_count": 21312.0, "timer/replay._sample_total": 11.552693605422974, "timer/replay._sample_frac": 0.011548656117263283, "timer/replay._sample_avg": 0.0005420745873415435, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.010464191436767578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3097.0, "timer/agent.policy_total": 52.17373967170715, "timer/agent.policy_frac": 0.052155505754720694, "timer/agent.policy_avg": 0.016846541708655845, "timer/agent.policy_min": 0.009621381759643555, "timer/agent.policy_max": 0.09282445907592773, "timer/dataset_train_count": 1332.0, "timer/dataset_train_total": 0.14989924430847168, "timer/dataset_train_frac": 0.00014984685683549673, "timer/dataset_train_avg": 0.00011253697020155532, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0004413127899169922, "timer/agent.train_count": 1332.0, "timer/agent.train_total": 601.4414417743683, "timer/agent.train_frac": 0.6012312472705712, "timer/agent.train_avg": 0.45153261394472094, "timer/agent.train_min": 0.4391636848449707, "timer/agent.train_max": 1.2611854076385498, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4797546863555908, "timer/agent.report_frac": 0.000479587019495214, "timer/agent.report_avg": 0.2398773431777954, "timer/agent.report_min": 0.23274016380310059, "timer/agent.report_max": 0.24701452255249023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 4.004032292180094e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 21.30427546910505}
{"step": 65280, "time": 3326.692163705826, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 65912, "time": 3351.343354701996, "episode/length": 297.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 65928, "time": 3353.5256085395813, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 65960, "time": 3356.2788898944855, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 66160, "time": 3365.0481629371643, "episode/length": 389.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 66264, "time": 3369.969556093216, "episode/length": 427.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 66312, "time": 3373.0725066661835, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 66376, "time": 3376.8522539138794, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 66752, "time": 3391.251480817795, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 66888, "time": 3397.3160984516144, "episode/length": 119.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 67280, "time": 3412.2425367832184, "episode/length": 164.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 67544, "time": 3422.6696512699127, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 67640, "time": 3427.5396785736084, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 67664, "time": 3430.2143924236298, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 67688, "time": 3432.4342896938324, "episode/length": 50.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 67896, "time": 3440.982682943344, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 68240, "time": 3454.567197084427, "episode/length": 290.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 68408, "time": 3461.612829208374, "episode/length": 189.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 68440, "time": 3464.3057000637054, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 68832, "time": 3479.2982342243195, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 68992, "time": 3486.476642847061, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 69064, "time": 3490.4251873493195, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 69320, "time": 3500.58828997612, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 69464, "time": 3506.992127418518, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 69752, "time": 3518.617832183838, "episode/length": 167.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 69768, "time": 3520.749240398407, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 69864, "time": 3525.5821554660797, "episode/length": 177.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3555.91379737854, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9551282051282052}
{"step": 70096, "time": 3557.9529960155487, "eval_episode/length": 161.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 70096, "time": 3559.8041870594025, "eval_episode/length": 167.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 70096, "time": 3562.067046880722, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 70096, "time": 3564.984784603119, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 70096, "time": 3568.3232946395874, "eval_episode/length": 215.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 70096, "time": 3570.5233561992645, "eval_episode/length": 230.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 70096, "time": 3574.4289915561676, "eval_episode/length": 278.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.985663082437276}
{"step": 70504, "time": 3587.922550678253, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 70600, "time": 3592.7912402153015, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 70648, "time": 3595.9156794548035, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 70712, "time": 3599.756965637207, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 70984, "time": 3610.7575047016144, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 71008, "time": 3613.357981443405, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 71064, "time": 3616.545287847519, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 71400, "time": 3629.6042664051056, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 71456, "time": 3633.442479133606, "episode/length": 48.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 71936, "time": 3651.370321750641, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 72136, "time": 3659.3776574134827, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 72144, "time": 3661.3847811222076, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 72152, "time": 3663.1218779087067, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 72240, "time": 3668.0003089904785, "episode/length": 190.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 72512, "time": 3678.81165099144, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 72736, "time": 3687.8364703655243, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 73344, "time": 3709.9447712898254, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 73584, "time": 3719.8198852539062, "episode/length": 265.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 73672, "time": 3724.263568878174, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 73840, "time": 3733.129823923111, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 73904, "time": 3736.8809666633606, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 73928, "time": 3739.0649812221527, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 74096, "time": 3746.6458683013916, "episode/length": 244.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 74392, "time": 3758.138128757477, "episode/length": 234.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 74712, "time": 3770.551982164383, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 75016, "time": 3782.4356293678284, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 75040, "time": 3785.094885826111, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 75400, "time": 3798.645732164383, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 75576, "time": 3806.1373245716095, "episode/length": 248.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 75608, "time": 3808.812641143799, "episode/length": 188.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 75824, "time": 3817.9222598075867, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 76264, "time": 3834.229220867157, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 76280, "time": 3836.448921442032, "episode/length": 235.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 76336, "time": 3840.222035884857, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 76376, "time": 3843.2170662879944, "episode/length": 99.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 76816, "time": 3860.0090339183807, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 76880, "time": 3863.781952857971, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 77104, "time": 3873.174630880356, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 77456, "time": 3886.6482536792755, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 77536, "time": 3890.979899406433, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 77704, "time": 3898.114446401596, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 77968, "time": 3908.9560158252716, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 78368, "time": 3924.1303215026855, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 78416, "time": 3927.3323974609375, "episode/length": 259.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 78568, "time": 3934.0205092430115, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 78760, "time": 3942.2073328495026, "episode/length": 162.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 78760, "time": 3942.2161536216736, "episode/length": 206.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 78992, "time": 3953.6614425182343, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 79192, "time": 3961.8062131404877, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 79256, "time": 3965.6066246032715, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 79824, "time": 3986.7163677215576, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 79960, "time": 3992.8139448165894, "episode/length": 87.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 79984, "time": 3995.6018500328064, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 79984, "time": 3995.616606235504, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4019.4678881168365, "eval_episode/length": 87.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9431818181818182}
{"step": 80080, "time": 4024.8201224803925, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 80080, "time": 4026.5308332443237, "eval_episode/length": 170.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 80080, "time": 4028.4302310943604, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 80080, "time": 4030.5564329624176, "eval_episode/length": 189.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 80080, "time": 4032.2399995326996, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 80080, "time": 4033.9613802433014, "eval_episode/length": 193.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 80080, "time": 4036.2308526039124, "eval_episode/length": 207.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 80144, "time": 4038.3956258296967, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 80184, "time": 4041.136902332306, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 80376, "time": 4049.2192261219025, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 80496, "time": 4055.19992518425, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 80568, "time": 4058.9334201812744, "episode/length": 47.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 81136, "time": 4079.6723186969757, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 81416, "time": 4090.71093583107, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 81496, "time": 4095.1646962165833, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 81552, "time": 4098.868829488754, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 81600, "time": 4102.085342884064, "episode/length": 181.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 81824, "time": 4111.791512012482, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 81872, "time": 4115.2254502773285, "episode/length": 162.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 81896, "time": 4117.374576807022, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 82344, "time": 4135.334500789642, "episode/length": 55.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 82400, "time": 4139.080253124237, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 82712, "time": 4150.989402770996, "episode/length": 45.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 82904, "time": 4159.03878903389, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 83016, "time": 4164.47758102417, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 83296, "time": 4175.931739330292, "episode/length": 177.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 83304, "time": 4177.6442694664, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 83424, "time": 4183.418444156647, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 83672, "time": 4193.134362220764, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 84016, "time": 4206.594965934753, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 84288, "time": 4217.316220283508, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 84464, "time": 4224.852592229843, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 84592, "time": 4230.92197394371, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 84648, "time": 4234.37712097168, "episode/length": 78.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 84680, "time": 4237.07973575592, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 84792, "time": 4242.428416967392, "episode/length": 186.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 84952, "time": 4249.341050386429, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 85216, "time": 4260.02316236496, "episode/length": 52.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.0}
{"step": 85496, "time": 4270.977363348007, "episode/length": 273.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 85736, "time": 4280.711009025574, "episode/length": 158.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 85856, "time": 4286.599637746811, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 86040, "time": 4294.430771827698, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 86104, "time": 4298.133888244629, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 86120, "time": 4300.282172203064, "episode/length": 47.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 86352, "time": 4310.037376880646, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 86400, "time": 4313.279704093933, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 86425, "time": 4316.477504968643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.271071248979711, "train/action_min": 0.0, "train/action_std": 2.2329306851572066, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048295453719016335, "train/actor_opt_grad_steps": 4635.0, "train/actor_opt_loss": 10.182277876494537, "train/adv_mag": 1.3074884637078243, "train/adv_max": 1.3074884637078243, "train/adv_mean": 0.00590697873393317, "train/adv_min": -0.5670258927701125, "train/adv_std": 0.09938191797639896, "train/cont_avg": 0.9943811217350746, "train/cont_loss_mean": 0.0004127686389449727, "train/cont_loss_std": 0.011000310754038357, "train/cont_neg_acc": 0.991720373917343, "train/cont_neg_loss": 0.03036378648085476, "train/cont_pos_acc": 0.9999119114519944, "train/cont_pos_loss": 0.00022858434569273664, "train/cont_pred": 0.9943265834851052, "train/cont_rate": 0.9943811217350746, "train/dyn_loss_mean": 8.031754934965674, "train/dyn_loss_std": 6.9064081035443206, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0984401751810045, "train/extr_critic_critic_opt_grad_steps": 4635.0, "train/extr_critic_critic_opt_loss": 14163.796678229945, "train/extr_critic_mag": 2.1425882844782587, "train/extr_critic_max": 2.1425882844782587, "train/extr_critic_mean": 0.48263287622092377, "train/extr_critic_min": -0.26673932573688564, "train/extr_critic_std": 0.6403035617141581, "train/extr_return_normed_mag": 2.289245886589164, "train/extr_return_normed_max": 2.289245886589164, "train/extr_return_normed_mean": 0.3670545906495692, "train/extr_return_normed_min": -0.21224586459905354, "train/extr_return_normed_std": 0.36985428408900306, "train/extr_return_rate": 0.3402416805055604, "train/extr_return_raw_mag": 4.009750859061284, "train/extr_return_raw_max": 4.009750859061284, "train/extr_return_raw_mean": 0.4933705226476513, "train/extr_return_raw_min": -0.566771767477491, "train/extr_return_raw_std": 0.676742069311996, "train/extr_reward_mag": 1.005257116324866, "train/extr_reward_max": 1.005257116324866, "train/extr_reward_mean": 0.010874982155275657, "train/extr_reward_min": -0.29427366915033826, "train/extr_reward_std": 0.08933305234384181, "train/image_loss_mean": 17.435596700924545, "train/image_loss_std": 22.695959397216342, "train/model_loss_mean": 22.307872622760375, "train/model_loss_std": 25.268277218092734, "train/model_opt_grad_norm": 118.98175082989593, "train/model_opt_grad_steps": 4626.0, "train/model_opt_loss": 8339.750236852846, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 374.30037313432837, "train/policy_entropy_mag": 2.260315763416575, "train/policy_entropy_max": 2.260315763416575, "train/policy_entropy_mean": 0.6691887625562611, "train/policy_entropy_min": 0.07942357859504756, "train/policy_entropy_std": 0.4454666373889838, "train/policy_logprob_mag": 7.437841746344495, "train/policy_logprob_max": -0.009462879352104752, "train/policy_logprob_mean": -0.6689996674879274, "train/policy_logprob_min": -7.437841746344495, "train/policy_logprob_std": 1.1130540673412495, "train/policy_randomness_mag": 0.7977922741156905, "train/policy_randomness_max": 0.7977922741156905, "train/policy_randomness_mean": 0.23619426653456332, "train/policy_randomness_min": 0.028033037836760727, "train/policy_randomness_std": 0.15723017391873828, "train/post_ent_mag": 44.481821316391674, "train/post_ent_max": 44.481821316391674, "train/post_ent_mean": 32.67147418634215, "train/post_ent_min": 15.499512679541288, "train/post_ent_std": 4.74189910603993, "train/prior_ent_mag": 56.74615603774341, "train/prior_ent_max": 56.74615603774341, "train/prior_ent_mean": 40.79223484779472, "train/prior_ent_min": 17.64132110396428, "train/prior_ent_std": 6.175947349462936, "train/rep_loss_mean": 8.031754934965674, "train/rep_loss_std": 6.9064081035443206, "train/reward_avg": 0.012854185917956838, "train/reward_loss_mean": 0.052810404338498616, "train/reward_loss_std": 0.2764968731398903, "train/reward_max_data": 1.008208957181048, "train/reward_max_pred": 1.0013257122751493, "train/reward_neg_acc": 0.9936961322578032, "train/reward_neg_loss": 0.033246304436739704, "train/reward_pos_acc": 0.9105793380025607, "train/reward_pos_loss": 1.126559688528972, "train/reward_pred": 0.011899339393087065, "train/reward_rate": 0.017884211753731342, "train_stats/sum_log_reward": 3.2416665961345035, "train_stats/max_log_achievement_collect_drink": 11.966666666666667, "train_stats/max_log_achievement_collect_sapling": 2.9, "train_stats/max_log_achievement_collect_wood": 1.275, "train_stats/max_log_achievement_defeat_skeleton": 0.008333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.175, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 2.425, "train_stats/max_log_achievement_place_table": 0.03333333333333333, "train_stats/max_log_achievement_wake_up": 1.4666666666666666, "train_stats/mean_log_entropy": 0.7464454288283984, "eval_stats/sum_log_reward": 3.16249992698431, "eval_stats/max_log_achievement_collect_drink": 6.4375, "eval_stats/max_log_achievement_collect_sapling": 2.8125, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00032411926076747477, "report/cont_loss_std": 0.006751122418791056, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.024829907342791557, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0001311602973146364, "report/cont_pred": 0.9922404289245605, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 9.028576850891113, "report/dyn_loss_std": 7.700170516967773, "report/image_loss_mean": 16.40465545654297, "report/image_loss_std": 18.876211166381836, "report/model_loss_mean": 21.880393981933594, "report/model_loss_std": 21.867769241333008, "report/post_ent_mag": 45.60277557373047, "report/post_ent_max": 45.60277557373047, "report/post_ent_mean": 32.8749885559082, "report/post_ent_min": 14.925882339477539, "report/post_ent_std": 4.966531753540039, "report/prior_ent_mag": 59.3255615234375, "report/prior_ent_max": 59.3255615234375, "report/prior_ent_mean": 41.486045837402344, "report/prior_ent_min": 17.097888946533203, "report/prior_ent_std": 6.974890232086182, "report/rep_loss_mean": 9.028576850891113, "report/rep_loss_std": 7.700170516967773, "report/reward_avg": 0.01806640625, "report/reward_loss_mean": 0.0582696832716465, "report/reward_loss_std": 0.24862048029899597, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001072645187378, "report/reward_neg_acc": 0.9930000305175781, "report/reward_neg_loss": 0.03779791295528412, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.9112601280212402, "report/reward_pred": 0.017712250351905823, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.010142199695110321, "eval/cont_loss_std": 0.1570875346660614, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007135006599128246, "eval/cont_pos_acc": 0.9951028227806091, "eval/cont_pos_loss": 0.010151036083698273, "eval/cont_pred": 0.992749810218811, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 13.426315307617188, "eval/dyn_loss_std": 7.2824015617370605, "eval/image_loss_mean": 30.129404067993164, "eval/image_loss_std": 31.325620651245117, "eval/model_loss_mean": 38.305816650390625, "eval/model_loss_std": 33.147216796875, "eval/post_ent_mag": 43.88947677612305, "eval/post_ent_max": 43.88947677612305, "eval/post_ent_mean": 30.83903694152832, "eval/post_ent_min": 16.07693099975586, "eval/post_ent_std": 4.9381632804870605, "eval/prior_ent_mag": 58.42111587524414, "eval/prior_ent_max": 58.42111587524414, "eval/prior_ent_mean": 41.398406982421875, "eval/prior_ent_min": 18.6477108001709, "eval/prior_ent_std": 6.698709964752197, "eval/rep_loss_mean": 13.426315307617188, "eval/rep_loss_std": 7.2824015617370605, "eval/reward_avg": 0.01328125037252903, "eval/reward_loss_mean": 0.11048334836959839, "eval/reward_loss_std": 0.6709285378456116, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9998548030853271, "eval/reward_neg_acc": 0.9980139136314392, "eval/reward_neg_loss": 0.06008448079228401, "eval/reward_pos_acc": 0.6470588445663452, "eval/reward_pos_loss": 3.0958755016326904, "eval/reward_pred": 0.005545207764953375, "eval/reward_rate": 0.0166015625, "replay/size": 85921.0, "replay/inserts": 21456.0, "replay/samples": 21456.0, "replay/insert_wait_avg": 1.4188661226845784e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.742125686827566e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18200.0, "eval_replay/inserts": 3896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3066513092855653e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3307662010193, "timer/env.step_count": 2682.0, "timer/env.step_total": 269.1946063041687, "timer/env.step_frac": 0.2691055952687486, "timer/env.step_avg": 0.10037084500528289, "timer/env.step_min": 0.024009227752685547, "timer/env.step_max": 3.5040407180786133, "timer/replay._sample_count": 21456.0, "timer/replay._sample_total": 11.35072922706604, "timer/replay._sample_frac": 0.011346976030911239, "timer/replay._sample_avg": 0.0005290235471227647, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.009293794631958008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3169.0, "timer/agent.policy_total": 53.8942084312439, "timer/agent.policy_frac": 0.05387638794307932, "timer/agent.policy_avg": 0.01700669246804793, "timer/agent.policy_min": 0.009541034698486328, "timer/agent.policy_max": 0.11960172653198242, "timer/dataset_train_count": 1341.0, "timer/dataset_train_total": 0.14657807350158691, "timer/dataset_train_frac": 0.00014652960646032118, "timer/dataset_train_avg": 0.000109305051082466, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0002923011779785156, "timer/agent.train_count": 1341.0, "timer/agent.train_total": 607.4447193145752, "timer/agent.train_frac": 0.6072438635687303, "timer/agent.train_avg": 0.45297891074912394, "timer/agent.train_min": 0.43677687644958496, "timer/agent.train_max": 1.4789972305297852, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47510385513305664, "timer/agent.report_frac": 0.00047494675879796263, "timer/agent.report_avg": 0.23755192756652832, "timer/agent.report_min": 0.23100066184997559, "timer/agent.report_max": 0.24410319328308105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.360590395613692e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 21.44865338681801}
{"step": 86784, "time": 4328.7521851062775, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 86808, "time": 4330.9610459804535, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 87192, "time": 4345.5200390815735, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 87256, "time": 4349.326382398605, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 87288, "time": 4352.108293056488, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 87528, "time": 4361.888424873352, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 87632, "time": 4367.260678052902, "episode/length": 159.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 87784, "time": 4373.766577959061, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 88584, "time": 4402.2792711257935, "episode/length": 221.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 88680, "time": 4407.131019592285, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 88728, "time": 4410.282149553299, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 88960, "time": 4420.161768913269, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 88968, "time": 4421.761158704758, "episode/length": 47.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 89088, "time": 4427.64258980751, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 89360, "time": 4438.538118600845, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 89760, "time": 4454.321047782898, "episode/length": 265.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 89816, "time": 4457.698378562927, "episode/length": 253.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 89904, "time": 4462.502577781677, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4485.459048271179, "eval_episode/length": 58.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 90064, "time": 4489.161107301712, "eval_episode/length": 106.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9626168224299065}
{"step": 90064, "time": 4492.340870857239, "eval_episode/length": 143.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 90064, "time": 4494.1906814575195, "eval_episode/length": 150.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 90064, "time": 4496.074702501297, "eval_episode/length": 157.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 90064, "time": 4497.883367061615, "eval_episode/length": 159.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.96875}
{"step": 90064, "time": 4500.305171012878, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 90064, "time": 4503.7303302288055, "eval_episode/length": 154.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 90296, "time": 4512.807832956314, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 90336, "time": 4516.505997419357, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 90408, "time": 4520.313789129257, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 90752, "time": 4533.7972185611725, "episode/length": 223.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 91080, "time": 4546.256546735764, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 91128, "time": 4549.527762889862, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 91256, "time": 4555.869655132294, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 91352, "time": 4560.568696498871, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 91624, "time": 4571.456748247147, "episode/length": 160.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 91912, "time": 4582.657062768936, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 92120, "time": 4591.513365507126, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 92248, "time": 4597.52978682518, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 92256, "time": 4599.637921094894, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 92360, "time": 4604.474991321564, "episode/length": 153.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 92656, "time": 4616.131087064743, "episode/length": 162.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 92888, "time": 4625.4324679374695, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 93120, "time": 4635.0949447155, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 93528, "time": 4650.155357122421, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 93592, "time": 4654.081105709076, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 93600, "time": 4656.289664268494, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 93864, "time": 4666.5269510746, "episode/length": 41.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 93960, "time": 4671.352736234665, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 94144, "time": 4679.338836193085, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 94224, "time": 4683.754622220993, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 94240, "time": 4685.833913564682, "episode/length": 290.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 94464, "time": 4695.004863023758, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 95032, "time": 4715.494522809982, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 95208, "time": 4723.022104501724, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 95216, "time": 4725.126491069794, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 95536, "time": 4737.477264165878, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 95568, "time": 4740.089301586151, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 95736, "time": 4747.156409263611, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 95856, "time": 4753.012446403503, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 95928, "time": 4756.8123462200165, "episode/length": 182.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 96424, "time": 4775.09020280838, "episode/length": 106.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 96640, "time": 4784.260184288025, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 97040, "time": 4799.314743757248, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 97080, "time": 4802.181892633438, "episode/length": 152.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 97160, "time": 4806.604921102524, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 97328, "time": 4814.157766342163, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 97360, "time": 4817.330675601959, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 97896, "time": 4837.332798242569, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 97920, "time": 4840.076584339142, "episode/length": 94.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 98000, "time": 4844.34344124794, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 98128, "time": 4850.189346075058, "episode/length": 135.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 98384, "time": 4861.643225669861, "episode/length": 162.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 98544, "time": 4868.863451004028, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 98704, "time": 4875.789904356003, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 98792, "time": 4880.176364660263, "episode/length": 406.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 99400, "time": 4902.147346019745, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 99832, "time": 4918.214335203171, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 99840, "time": 4920.363559961319, "episode/length": 242.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 99896, "time": 4923.784211397171, "episode/length": 168.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 100016, "time": 4929.609977245331, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4952.249713897705, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 100048, "time": 4954.220982074738, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 100048, "time": 4956.653589010239, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 100048, "time": 4958.2394988536835, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 100048, "time": 4960.673543691635, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 100048, "time": 4962.5609221458435, "eval_episode/length": 205.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 100048, "time": 4964.183315753937, "eval_episode/length": 206.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 100048, "time": 4967.098049402237, "eval_episode/length": 234.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 100088, "time": 4968.212025403976, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 100248, "time": 4975.148991823196, "episode/length": 290.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 100840, "time": 4996.606046915054, "episode/length": 255.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 101072, "time": 5006.315548181534, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9617224880382775, "episode/intrinsic_return": 0.0}
{"step": 101096, "time": 5008.546911716461, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 101104, "time": 5010.577246427536, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 101296, "time": 5018.717853307724, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 101328, "time": 5021.303303480148, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 101344, "time": 5023.556582212448, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 101456, "time": 5028.834938287735, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 102352, "time": 5060.502887010574, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 102512, "time": 5067.416000843048, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 102744, "time": 5076.626154184341, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 102744, "time": 5076.634929656982, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 102880, "time": 5084.915449380875, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 102888, "time": 5086.552474975586, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 103000, "time": 5091.9851179122925, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 103096, "time": 5096.696243047714, "episode/length": 252.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 103728, "time": 5119.850895643234, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 103896, "time": 5126.919431686401, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 104080, "time": 5134.981180667877, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 104184, "time": 5139.999157905579, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 104264, "time": 5144.216769456863, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 104360, "time": 5149.030584096909, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 104688, "time": 5162.0661289691925, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 104728, "time": 5164.724185466766, "episode/length": 247.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 105032, "time": 5176.535577297211, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 105120, "time": 5181.274008989334, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 105536, "time": 5196.796395301819, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 105632, "time": 5201.563826084137, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 106096, "time": 5218.932943105698, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 106176, "time": 5223.214814186096, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 106232, "time": 5226.4649868011475, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 106440, "time": 5235.490658521652, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 106808, "time": 5250.818211317062, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 106872, "time": 5254.871874809265, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 106872, "time": 5254.880162477493, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 107016, "time": 5263.356439828873, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 107288, "time": 5274.008834600449, "episode/length": 365.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 107632, "time": 5287.553174972534, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 107912, "time": 5298.247224569321, "episode/length": 226.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 107992, "time": 5302.462725877762, "episode/length": 121.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 108248, "time": 5312.872030735016, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 108281, "time": 5316.623124599457, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.364274741959398, "train/action_min": 0.0, "train/action_std": 2.824105814425615, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05107795497416145, "train/actor_opt_grad_steps": 5990.0, "train/actor_opt_loss": 6.217457207667566, "train/adv_mag": 1.218315355534101, "train/adv_max": 1.2132313823612937, "train/adv_mean": 0.005894888087431666, "train/adv_min": -0.5542566580493955, "train/adv_std": 0.097467602903608, "train/cont_avg": 0.9940479584854015, "train/cont_loss_mean": 0.0004810155377205059, "train/cont_loss_std": 0.012277701737612404, "train/cont_neg_acc": 0.9855897374396777, "train/cont_neg_loss": 0.03833826022029135, "train/cont_pos_acc": 0.9999211600227077, "train/cont_pos_loss": 0.0002319091996878487, "train/cont_pred": 0.9940243781048016, "train/cont_rate": 0.9940479584854015, "train/dyn_loss_mean": 10.113013928824097, "train/dyn_loss_std": 7.856178210599579, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0362937028390649, "train/extr_critic_critic_opt_grad_steps": 5990.0, "train/extr_critic_critic_opt_loss": 14266.154745951186, "train/extr_critic_mag": 2.354888265150307, "train/extr_critic_max": 2.354888265150307, "train/extr_critic_mean": 0.4839579713170546, "train/extr_critic_min": -0.30541372908292896, "train/extr_critic_std": 0.6545896214725327, "train/extr_return_normed_mag": 2.2206367289062836, "train/extr_return_normed_max": 2.2206367289062836, "train/extr_return_normed_mean": 0.3574491337920627, "train/extr_return_normed_min": -0.2305560421851212, "train/extr_return_normed_std": 0.3614548149987729, "train/extr_return_rate": 0.35347049900867644, "train/extr_return_raw_mag": 4.062545544909735, "train/extr_return_raw_max": 4.062545544909735, "train/extr_return_raw_mean": 0.49526893178911974, "train/extr_return_raw_min": -0.630590969954964, "train/extr_return_raw_std": 0.6923624716535972, "train/extr_reward_mag": 1.0079504991099781, "train/extr_reward_max": 1.0079504991099781, "train/extr_reward_mean": 0.011507965698260406, "train/extr_reward_min": -0.29693858640907456, "train/extr_reward_std": 0.0953340027617277, "train/image_loss_mean": 16.90009858486426, "train/image_loss_std": 19.96796195176396, "train/model_loss_mean": 23.022442441787163, "train/model_loss_std": 23.303122123662572, "train/model_opt_grad_norm": 99.87629003594391, "train/model_opt_grad_steps": 5980.540145985401, "train/model_opt_loss": 14748.689838047445, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 638.6861313868613, "train/policy_entropy_mag": 2.3718238329365304, "train/policy_entropy_max": 2.3718238329365304, "train/policy_entropy_mean": 0.6855036276970466, "train/policy_entropy_min": 0.07938860008751389, "train/policy_entropy_std": 0.4731084545598413, "train/policy_logprob_mag": 7.438204472952515, "train/policy_logprob_max": -0.009458107221191817, "train/policy_logprob_mean": -0.6851684807860938, "train/policy_logprob_min": -7.438204472952515, "train/policy_logprob_std": 1.1335199818994006, "train/policy_randomness_mag": 0.8371497279536115, "train/policy_randomness_max": 0.8371497279536115, "train/policy_randomness_mean": 0.24195269772606173, "train/policy_randomness_min": 0.028020691955937958, "train/policy_randomness_std": 0.16698652233955633, "train/post_ent_mag": 46.38454818725586, "train/post_ent_max": 46.38454818725586, "train/post_ent_mean": 33.847156747414246, "train/post_ent_min": 17.29914899116015, "train/post_ent_std": 4.834886498694872, "train/prior_ent_mag": 59.18094693483227, "train/prior_ent_max": 59.18094693483227, "train/prior_ent_mean": 44.12679984099673, "train/prior_ent_min": 19.874660575476877, "train/prior_ent_std": 6.813449883983083, "train/rep_loss_mean": 10.113013928824097, "train/rep_loss_std": 7.856178210599579, "train/reward_avg": 0.014622775946546644, "train/reward_loss_mean": 0.05405445761271637, "train/reward_loss_std": 0.27816267083161067, "train/reward_max_data": 1.0131386892638938, "train/reward_max_pred": 1.002230531977911, "train/reward_neg_acc": 0.9930735534995142, "train/reward_neg_loss": 0.03378082953230308, "train/reward_pos_acc": 0.9289595993765949, "train/reward_pos_loss": 1.0675513979292264, "train/reward_pred": 0.013679890623180209, "train/reward_rate": 0.019873403284671534, "train_stats/sum_log_reward": 3.743478182087774, "train_stats/max_log_achievement_collect_drink": 10.130434782608695, "train_stats/max_log_achievement_collect_sapling": 3.1913043478260867, "train_stats/max_log_achievement_collect_wood": 1.9391304347826086, "train_stats/max_log_achievement_defeat_skeleton": 0.02608695652173913, "train_stats/max_log_achievement_defeat_zombie": 0.1826086956521739, "train_stats/max_log_achievement_eat_cow": 0.06956521739130435, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 2.982608695652174, "train_stats/max_log_achievement_place_table": 0.06956521739130435, "train_stats/max_log_achievement_wake_up": 1.6869565217391305, "train_stats/mean_log_entropy": 0.7483356198538904, "eval_stats/sum_log_reward": 3.7249999111518264, "eval_stats/max_log_achievement_collect_drink": 6.8125, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_wood": 1.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.589665670413524e-05, "report/cont_loss_std": 0.0009240587241947651, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005193721735849977, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.316498572938144e-05, "report/cont_pred": 0.994091272354126, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.454556465148926, "report/dyn_loss_std": 8.493260383605957, "report/image_loss_mean": 27.694467544555664, "report/image_loss_std": 36.35293960571289, "report/model_loss_mean": 36.42279815673828, "report/model_loss_std": 39.20177459716797, "report/post_ent_mag": 49.00922393798828, "report/post_ent_max": 49.00922393798828, "report/post_ent_mean": 34.859073638916016, "report/post_ent_min": 16.997398376464844, "report/post_ent_std": 5.032190799713135, "report/prior_ent_mag": 61.411155700683594, "report/prior_ent_max": 61.411155700683594, "report/prior_ent_mean": 48.633750915527344, "report/prior_ent_min": 19.492084503173828, "report/prior_ent_std": 7.5171074867248535, "report/rep_loss_mean": 14.454556465148926, "report/rep_loss_std": 8.493260383605957, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.05554273724555969, "report/reward_loss_std": 0.2403838336467743, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002009630203247, "report/reward_neg_acc": 0.9959840178489685, "report/reward_neg_loss": 0.031042814254760742, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 0.927040159702301, "report/reward_pred": 0.020723525434732437, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0007810654933564365, "eval/cont_loss_std": 0.02484516054391861, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.26654061675071716, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8541115309744782e-07, "eval/cont_pred": 0.9976100325584412, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.55954360961914, "eval/dyn_loss_std": 7.937329292297363, "eval/image_loss_mean": 17.79979705810547, "eval/image_loss_std": 15.956849098205566, "eval/model_loss_mean": 26.60537338256836, "eval/model_loss_std": 19.11993980407715, "eval/post_ent_mag": 42.353126525878906, "eval/post_ent_max": 42.353126525878906, "eval/post_ent_mean": 30.88629913330078, "eval/post_ent_min": 19.37225341796875, "eval/post_ent_std": 3.9185962677001953, "eval/prior_ent_mag": 57.786170959472656, "eval/prior_ent_max": 57.786170959472656, "eval/prior_ent_mean": 42.453155517578125, "eval/prior_ent_min": 19.39394187927246, "eval/prior_ent_std": 6.2763190269470215, "eval/rep_loss_mean": 14.55954360961914, "eval/rep_loss_std": 7.937329292297363, "eval/reward_avg": 0.01582031324505806, "eval/reward_loss_mean": 0.06907033920288086, "eval/reward_loss_std": 0.6278037428855896, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0053620338439941, "eval/reward_neg_acc": 0.998009979724884, "eval/reward_neg_loss": 0.011956516653299332, "eval/reward_pos_acc": 0.6315789222717285, "eval/reward_pos_loss": 3.0900912284851074, "eval/reward_pred": 0.008531288243830204, "eval/reward_rate": 0.0185546875, "replay/size": 107777.0, "replay/inserts": 21856.0, "replay/samples": 21856.0, "replay/insert_wait_avg": 1.3455770375264336e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.309197286212078e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21792.0, "eval_replay/inserts": 3592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.210080488752947e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1335380077362, "timer/env.step_count": 2732.0, "timer/env.step_total": 262.8210163116455, "timer/env.step_frac": 0.26278592440283965, "timer/env.step_avg": 0.09620095765433584, "timer/env.step_min": 0.02350926399230957, "timer/env.step_max": 3.6707067489624023, "timer/replay._sample_count": 21856.0, "timer/replay._sample_total": 11.370385885238647, "timer/replay._sample_frac": 0.011368867709294532, "timer/replay._sample_avg": 0.0005202409354519879, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.022341012954711914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3181.0, "timer/agent.policy_total": 53.0701048374176, "timer/agent.policy_frac": 0.053063018907588216, "timer/agent.policy_avg": 0.016683465840118705, "timer/agent.policy_min": 0.009631872177124023, "timer/agent.policy_max": 0.11111640930175781, "timer/dataset_train_count": 1366.0, "timer/dataset_train_total": 0.18262243270874023, "timer/dataset_train_frac": 0.00018259804892906971, "timer/dataset_train_avg": 0.0001336913855847293, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.03829622268676758, "timer/agent.train_count": 1366.0, "timer/agent.train_total": 617.1946668624878, "timer/agent.train_frac": 0.617112258920882, "timer/agent.train_avg": 0.45182625685394423, "timer/agent.train_min": 0.43572378158569336, "timer/agent.train_max": 1.4820530414581299, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4693577289581299, "timer/agent.report_frac": 0.0004692950602307462, "timer/agent.report_avg": 0.23467886447906494, "timer/agent.report_min": 0.2232499122619629, "timer/agent.report_max": 0.246107816696167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218221063041881e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 21.85282325494005}
{"step": 108288, "time": 5316.647089719772, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 108304, "time": 5319.429753541946, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 108720, "time": 5335.082899093628, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 109120, "time": 5350.315670013428, "episode/length": 280.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 109200, "time": 5354.6054475307465, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 109256, "time": 5357.966464042664, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 109592, "time": 5370.895931959152, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 109792, "time": 5379.650596857071, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 109864, "time": 5383.507623434067, "episode/length": 196.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5406.601301193237, "eval_episode/length": 53.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 110032, "time": 5414.119518280029, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 110032, "time": 5416.351468324661, "eval_episode/length": 182.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 110032, "time": 5418.576874256134, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 110032, "time": 5421.677145242691, "eval_episode/length": 203.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 110032, "time": 5423.825466632843, "eval_episode/length": 204.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 110032, "time": 5426.807180643082, "eval_episode/length": 220.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 110032, "time": 5431.482881784439, "eval_episode/length": 270.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.985239852398524}
{"step": 110144, "time": 5435.484323263168, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 110480, "time": 5448.917008638382, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 110616, "time": 5454.78813624382, "episode/length": 337.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 110680, "time": 5458.551984071732, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 110688, "time": 5460.618515968323, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 111048, "time": 5474.152151107788, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 111088, "time": 5477.277309656143, "episode/length": 49.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 111248, "time": 5484.279496908188, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 111256, "time": 5485.99601483345, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 111392, "time": 5492.424475669861, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 111968, "time": 5513.359778165817, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 112032, "time": 5517.075114488602, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 112216, "time": 5524.610488176346, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 112528, "time": 5537.034251689911, "episode/length": 141.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 112632, "time": 5541.884074211121, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 112704, "time": 5546.159201383591, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 112736, "time": 5548.720761060715, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 112832, "time": 5553.695222377777, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 113328, "time": 5571.884050369263, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 113648, "time": 5584.260445594788, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 113808, "time": 5591.104376792908, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 113880, "time": 5594.934187889099, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 114088, "time": 5603.516370773315, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 114344, "time": 5613.7474796772, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 114344, "time": 5613.756371974945, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 114704, "time": 5630.727873086929, "episode/length": 171.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 114928, "time": 5639.742578983307, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 115056, "time": 5645.608100414276, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 115488, "time": 5661.65954041481, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 115536, "time": 5664.975212335587, "episode/length": 148.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 115568, "time": 5667.676897764206, "episode/length": 184.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 115808, "time": 5677.403509616852, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 115984, "time": 5685.32852268219, "episode/length": 431.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 116168, "time": 5692.907245874405, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 116296, "time": 5698.923904418945, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 116792, "time": 5717.869656562805, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 116856, "time": 5721.505032539368, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 116936, "time": 5725.943965911865, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 117064, "time": 5731.90621972084, "episode/length": 134.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 117256, "time": 5739.947163820267, "episode/length": 214.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 117448, "time": 5747.946593046188, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 117496, "time": 5751.023096084595, "episode/length": 53.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 117504, "time": 5753.110606908798, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 117648, "time": 5759.43207359314, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 118304, "time": 5783.293688058853, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 118344, "time": 5786.018833637238, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 118512, "time": 5793.497210025787, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 118544, "time": 5796.265609502792, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 118976, "time": 5812.3225293159485, "episode/length": 190.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 119024, "time": 5815.487245321274, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 119216, "time": 5823.4776475429535, "episode/length": 113.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 119296, "time": 5827.743986129761, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 119488, "time": 5835.955452203751, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 119840, "time": 5849.499789237976, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 119912, "time": 5853.404356718063, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5880.5415625572205, "eval_episode/length": 175.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 120016, "time": 5882.702486753464, "eval_episode/length": 186.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 120016, "time": 5884.598207950592, "eval_episode/length": 193.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 120016, "time": 5886.198652267456, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 120016, "time": 5888.2560040950775, "eval_episode/length": 208.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 120016, "time": 5890.90415430069, "eval_episode/length": 231.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 120016, "time": 5893.486624240875, "eval_episode/length": 21.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 120016, "time": 5895.776894330978, "eval_episode/length": 268.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9814126394052045}
{"step": 120024, "time": 5895.832034111023, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 120384, "time": 5909.623171567917, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 120536, "time": 5916.050844907761, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 120576, "time": 5919.197496652603, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 120776, "time": 5927.29530787468, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 120840, "time": 5930.990334033966, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 121344, "time": 5949.892250537872, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 121480, "time": 5955.776964664459, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 121672, "time": 5963.759750366211, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 121680, "time": 5965.736737012863, "episode/length": 104.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 121952, "time": 5976.707714080811, "episode/length": 171.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 121960, "time": 5978.322549104691, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 122056, "time": 5983.078227996826, "episode/length": 253.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 122088, "time": 5985.716922283173, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 122504, "time": 6001.287632703781, "episode/length": 55.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 123088, "time": 6024.297671318054, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 123144, "time": 6027.665102005005, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 123200, "time": 6031.297250509262, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 123272, "time": 6035.240580320358, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 123272, "time": 6035.249794960022, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 123800, "time": 6056.509671926498, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 123872, "time": 6061.252483129501, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 124424, "time": 6081.850796222687, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 124544, "time": 6087.711512088776, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 124608, "time": 6091.532650947571, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 124656, "time": 6094.758164167404, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 124776, "time": 6100.112770080566, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 125088, "time": 6112.429069519043, "episode/length": 374.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9973333333333333, "episode/intrinsic_return": 0.0}
{"step": 125328, "time": 6122.294646978378, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 125672, "time": 6135.192423343658, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 125872, "time": 6143.8011593818665, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 125984, "time": 6149.197121620178, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 126048, "time": 6153.106969356537, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 126056, "time": 6154.719709157944, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 126384, "time": 6167.628598690033, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 126408, "time": 6169.788907766342, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 126776, "time": 6183.756436347961, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 127144, "time": 6197.5669095516205, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 127216, "time": 6201.954894781113, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 127296, "time": 6206.216160774231, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 127472, "time": 6213.7148406505585, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 127632, "time": 6220.651558876038, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 128032, "time": 6235.616441011429, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 128176, "time": 6242.126345157623, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 128280, "time": 6246.9409766197205, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 128304, "time": 6249.563460826874, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 128472, "time": 6256.6897439956665, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 128704, "time": 6266.247317075729, "episode/length": 175.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 128776, "time": 6270.04757976532, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 128936, "time": 6277.064092636108, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 129040, "time": 6282.403601884842, "episode/length": 125.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 129632, "time": 6304.016377449036, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 129672, "time": 6306.70050907135, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 129897, "time": 6316.844339609146, "train_stats/sum_log_reward": 3.80085461669498, "train_stats/max_log_achievement_collect_drink": 9.846153846153847, "train_stats/max_log_achievement_collect_sapling": 2.5128205128205128, "train_stats/max_log_achievement_collect_wood": 2.1709401709401708, "train_stats/max_log_achievement_defeat_skeleton": 0.017094017094017096, "train_stats/max_log_achievement_defeat_zombie": 0.1111111111111111, "train_stats/max_log_achievement_eat_cow": 0.06837606837606838, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017094017094017096, "train_stats/max_log_achievement_place_plant": 2.4188034188034186, "train_stats/max_log_achievement_place_table": 0.10256410256410256, "train_stats/max_log_achievement_wake_up": 1.5384615384615385, "train_stats/mean_log_entropy": 0.7438119634603843, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.233606861255787, "train/action_min": 0.0, "train/action_std": 3.0718779104727285, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049086427619611774, "train/actor_opt_grad_steps": 7350.0, "train/actor_opt_loss": 9.133136395613352, "train/adv_mag": 0.9672670037658126, "train/adv_max": 0.9595731461489642, "train/adv_mean": 0.006586133646972788, "train/adv_min": -0.5398384632887664, "train/adv_std": 0.08899914787875282, "train/cont_avg": 0.9941116898148148, "train/cont_loss_mean": 0.0005018240660460918, "train/cont_loss_std": 0.01279195648064194, "train/cont_neg_acc": 0.9913903598432188, "train/cont_neg_loss": 0.030627291376633906, "train/cont_pos_acc": 0.999919832194293, "train/cont_pos_loss": 0.00031129745444186737, "train/cont_pred": 0.9941024387324298, "train/cont_rate": 0.9941116898148148, "train/dyn_loss_mean": 11.496660797684282, "train/dyn_loss_std": 8.318069154244881, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0520211762852139, "train/extr_critic_critic_opt_grad_steps": 7350.0, "train/extr_critic_critic_opt_loss": 14814.53197337963, "train/extr_critic_mag": 2.6287996945557772, "train/extr_critic_max": 2.6287996945557772, "train/extr_critic_mean": 0.5995785141432727, "train/extr_critic_min": -0.32104634797131576, "train/extr_critic_std": 0.7422231215017813, "train/extr_return_normed_mag": 1.9603330885922468, "train/extr_return_normed_max": 1.9603330885922468, "train/extr_return_normed_mean": 0.3640668855773078, "train/extr_return_normed_min": -0.22871874035508544, "train/extr_return_normed_std": 0.3554940661898366, "train/extr_return_rate": 0.38420044404489023, "train/extr_return_raw_mag": 4.118142057348181, "train/extr_return_raw_max": 4.118142057348181, "train/extr_return_raw_mean": 0.6139547049999237, "train/extr_return_raw_min": -0.6877535153318335, "train/extr_return_raw_std": 0.7806271358772561, "train/extr_reward_mag": 1.0077344046698675, "train/extr_reward_max": 1.0077344046698675, "train/extr_reward_mean": 0.013005067549507927, "train/extr_reward_min": -0.32365825882664434, "train/extr_reward_std": 0.10466922422250112, "train/image_loss_mean": 15.257017354611998, "train/image_loss_std": 18.79735630883111, "train/model_loss_mean": 22.206850631148725, "train/model_loss_std": 22.381437951547127, "train/model_opt_grad_norm": 102.79164408931025, "train/model_opt_grad_steps": 7339.281481481482, "train/model_opt_loss": 13972.297504340278, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 629.6296296296297, "train/policy_entropy_mag": 2.519626103507148, "train/policy_entropy_max": 2.519626103507148, "train/policy_entropy_mean": 0.7029211494657729, "train/policy_entropy_min": 0.0793800276738626, "train/policy_entropy_std": 0.5339833623833127, "train/policy_logprob_mag": 7.4382543846412945, "train/policy_logprob_max": -0.009456842834198917, "train/policy_logprob_mean": -0.702504433967449, "train/policy_logprob_min": -7.4382543846412945, "train/policy_logprob_std": 1.1830686860614352, "train/policy_randomness_mag": 0.8893174454017921, "train/policy_randomness_max": 0.8893174454017921, "train/policy_randomness_mean": 0.24810031818019018, "train/policy_randomness_min": 0.02801766623225477, "train/policy_randomness_std": 0.18847269625575455, "train/post_ent_mag": 48.27565073083948, "train/post_ent_max": 48.27565073083948, "train/post_ent_mean": 34.7819248340748, "train/post_ent_min": 18.584558946115, "train/post_ent_std": 5.043168117381908, "train/prior_ent_mag": 60.19234774554217, "train/prior_ent_max": 60.19234774554217, "train/prior_ent_mean": 46.43700310035988, "train/prior_ent_min": 21.54248572455512, "train/prior_ent_std": 6.8694257736206055, "train/rep_loss_mean": 11.496660797684282, "train/rep_loss_std": 8.318069154244881, "train/reward_avg": 0.015036168875155487, "train/reward_loss_mean": 0.05133501934232535, "train/reward_loss_std": 0.26674785006929325, "train/reward_max_data": 1.0044444455040826, "train/reward_max_pred": 1.0024960041046143, "train/reward_neg_acc": 0.9944981155572115, "train/reward_neg_loss": 0.03197295271136143, "train/reward_pos_acc": 0.9439641003255491, "train/reward_pos_loss": 0.9887269686769556, "train/reward_pred": 0.01417002774671548, "train/reward_rate": 0.020146122685185185, "eval_stats/sum_log_reward": 3.5374998822808266, "eval_stats/max_log_achievement_collect_drink": 20.25, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_wood": 1.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.6820620658108965e-05, "report/cont_loss_std": 0.00017417855269741267, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023357837926596403, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.554306800244376e-05, "report/cont_pred": 0.994126558303833, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.765361785888672, "report/dyn_loss_std": 8.137669563293457, "report/image_loss_mean": 11.084827423095703, "report/image_loss_std": 12.532060623168945, "report/model_loss_mean": 18.188623428344727, "report/model_loss_std": 16.17371940612793, "report/post_ent_mag": 48.91335678100586, "report/post_ent_max": 48.91335678100586, "report/post_ent_mean": 35.73606491088867, "report/post_ent_min": 17.368276596069336, "report/post_ent_std": 5.9921183586120605, "report/prior_ent_mag": 59.7672119140625, "report/prior_ent_max": 59.7672119140625, "report/prior_ent_mean": 47.229400634765625, "report/prior_ent_min": 21.654808044433594, "report/prior_ent_std": 7.097217559814453, "report/rep_loss_mean": 11.765361785888672, "report/rep_loss_std": 8.137669563293457, "report/reward_avg": 0.013085938058793545, "report/reward_loss_mean": 0.044561419636011124, "report/reward_loss_std": 0.2459767609834671, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9992541074752808, "report/reward_neg_acc": 0.996023952960968, "report/reward_neg_loss": 0.027858732268214226, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 0.9780559539794922, "report/reward_pred": 0.012827998027205467, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 6.881837180117145e-05, "eval/cont_loss_std": 0.0009592939750291407, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010378007777035236, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.8390179068082944e-05, "eval/cont_pred": 0.9961056709289551, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.13054656982422, "eval/dyn_loss_std": 7.713150501251221, "eval/image_loss_mean": 26.172462463378906, "eval/image_loss_std": 26.886343002319336, "eval/model_loss_mean": 35.968326568603516, "eval/model_loss_std": 29.30120849609375, "eval/post_ent_mag": 48.207305908203125, "eval/post_ent_max": 48.207305908203125, "eval/post_ent_mean": 33.117088317871094, "eval/post_ent_min": 19.703203201293945, "eval/post_ent_std": 4.700387001037598, "eval/prior_ent_mag": 59.646751403808594, "eval/prior_ent_max": 59.646751403808594, "eval/prior_ent_mean": 46.08531951904297, "eval/prior_ent_min": 22.948333740234375, "eval/prior_ent_std": 6.533944129943848, "eval/rep_loss_mean": 16.13054656982422, "eval/rep_loss_std": 7.713150501251221, "eval/reward_avg": 0.00966796837747097, "eval/reward_loss_mean": 0.11746624112129211, "eval/reward_loss_std": 0.8601850867271423, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9995094537734985, "eval/reward_neg_acc": 0.999009907245636, "eval/reward_neg_loss": 0.049400538206100464, "eval/reward_pos_acc": 0.4285714626312256, "eval/reward_pos_loss": 5.027920722961426, "eval/reward_pred": 0.001995458034798503, "eval/reward_rate": 0.013671875, "replay/size": 129393.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.331707180031664e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.499838527620148e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26112.0, "eval_replay/inserts": 4320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2638392271818937e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.207713842392, "timer/env.step_count": 2702.0, "timer/env.step_total": 261.1156358718872, "timer/env.step_frac": 0.2610614098033567, "timer/env.step_avg": 0.09663791112949194, "timer/env.step_min": 0.02342534065246582, "timer/env.step_max": 3.4604740142822266, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.588554620742798, "timer/replay._sample_frac": 0.011586148017419577, "timer/replay._sample_avg": 0.0005361100398197076, "timer/replay._sample_min": 0.0003573894500732422, "timer/replay._sample_max": 0.010771036148071289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3242.0, "timer/agent.policy_total": 55.1371808052063, "timer/agent.policy_frac": 0.05512573042792445, "timer/agent.policy_avg": 0.017007150155831676, "timer/agent.policy_min": 0.009519338607788086, "timer/agent.policy_max": 0.12229681015014648, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.14975309371948242, "timer/dataset_train_frac": 0.00014972199438873735, "timer/dataset_train_avg": 0.00011084610934084561, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.00043702125549316406, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 610.9592065811157, "timer/agent.train_frac": 0.6108323282511574, "timer/agent.train_avg": 0.45222739199194356, "timer/agent.train_min": 0.4383368492126465, "timer/agent.train_max": 1.3853733539581299, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4730679988861084, "timer/agent.report_frac": 0.0004729697565206463, "timer/agent.report_avg": 0.2365339994430542, "timer/agent.report_min": 0.22971606254577637, "timer/agent.report_max": 0.24335193634033203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003450238490218e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.611248889223752}
{"step": 129936, "time": 6318.224732160568, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6342.2900195121765, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 130000, "time": 6344.342289209366, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 130000, "time": 6346.161347150803, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 130000, "time": 6348.369641304016, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 130000, "time": 6350.433220148087, "eval_episode/length": 203.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 130000, "time": 6350.443291425705, "eval_episode/length": 203.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 130000, "time": 6357.123064994812, "eval_episode/length": 283.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 130000, "time": 6360.503450870514, "eval_episode/length": 163.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 130144, "time": 6365.407388925552, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 130328, "time": 6372.912373304367, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 130536, "time": 6381.537970781326, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.0}
{"step": 130568, "time": 6384.2906041145325, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 130696, "time": 6390.122452020645, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 130952, "time": 6400.405223846436, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 130992, "time": 6403.534809589386, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 131232, "time": 6414.290818929672, "episode/length": 161.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 131664, "time": 6430.4247460365295, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 131736, "time": 6434.158139705658, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 131984, "time": 6444.518523693085, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 132280, "time": 6457.132667064667, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 132520, "time": 6466.728632211685, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 132528, "time": 6468.926498413086, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 132584, "time": 6472.05651140213, "episode/length": 105.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 133408, "time": 6501.804162502289, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 133488, "time": 6506.099515676498, "episode/length": 281.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 133536, "time": 6509.267111778259, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 133576, "time": 6512.144602537155, "episode/length": 428.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 133760, "time": 6520.150156497955, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 133936, "time": 6527.605757713318, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 134000, "time": 6531.435584306717, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 134304, "time": 6543.258340597153, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 134576, "time": 6553.968096494675, "episode/length": 124.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 134752, "time": 6561.496977090836, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 134856, "time": 6566.393248558044, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 135072, "time": 6575.5313839912415, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 135160, "time": 6579.882700920105, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 135384, "time": 6588.972751379013, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 135648, "time": 6599.6891877651215, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 135936, "time": 6611.178363084793, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 136088, "time": 6617.653064250946, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 136424, "time": 6630.546006679535, "episode/length": 264.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 136568, "time": 6637.075148820877, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 136744, "time": 6644.525225639343, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 136784, "time": 6647.8138382434845, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 137048, "time": 6658.072935581207, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 137112, "time": 6662.470796346664, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 137400, "time": 6673.964767694473, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 137432, "time": 6676.668079853058, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 138192, "time": 6703.905532360077, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 138304, "time": 6709.22886633873, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 138312, "time": 6710.876298189163, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 138544, "time": 6720.6536729335785, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 138672, "time": 6726.696236371994, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 139056, "time": 6741.316838979721, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 139360, "time": 6754.571532011032, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 139544, "time": 6762.124253749847, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 139776, "time": 6771.675979614258, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 139840, "time": 6775.511721134186, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 139848, "time": 6777.139545202255, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6801.760725736618, "eval_episode/length": 48.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9387755102040817}
{"step": 140088, "time": 6807.39332818985, "eval_episode/length": 146.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 140088, "time": 6809.370412349701, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 140088, "time": 6810.989672422409, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 140088, "time": 6813.27676486969, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 140088, "time": 6813.284100055695, "eval_episode/length": 171.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 140088, "time": 6817.497862577438, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 140088, "time": 6819.511212110519, "eval_episode/length": 49.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.98}
{"step": 140184, "time": 6822.759163379669, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 140472, "time": 6834.417634725571, "episode/length": 427.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 140608, "time": 6840.713737726212, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 140792, "time": 6848.28537607193, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 140832, "time": 6851.379791259766, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 141064, "time": 6860.532448768616, "episode/length": 109.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 141112, "time": 6863.768666744232, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 141176, "time": 6867.420695066452, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 141664, "time": 6885.656194448471, "episode/length": 235.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 141688, "time": 6887.734796524048, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 142048, "time": 6901.625648975372, "episode/length": 47.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 142256, "time": 6910.532298088074, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 142376, "time": 6916.573834657669, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 142424, "time": 6920.275800228119, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 142552, "time": 6926.4269099235535, "episode/length": 242.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 142584, "time": 6929.074569225311, "episode/length": 175.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 142760, "time": 6936.726785182953, "episode/length": 88.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9325842696629213, "episode/intrinsic_return": 0.0}
{"step": 142840, "time": 6941.041537761688, "episode/length": 143.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 143528, "time": 6965.819369316101, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 143896, "time": 6979.5885853767395, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 143936, "time": 6982.7577912807465, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 144376, "time": 6998.785016775131, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 144384, "time": 7000.86585855484, "episode/length": 408.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 144392, "time": 7002.42920422554, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 144576, "time": 7010.284279346466, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 144744, "time": 7017.163246393204, "episode/length": 247.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 145184, "time": 7033.865748882294, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 145472, "time": 7045.206065654755, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 145752, "time": 7056.010475873947, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 145760, "time": 7058.133667230606, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 145952, "time": 7066.004051685333, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 145960, "time": 7067.631441354752, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 146192, "time": 7077.329262971878, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 146336, "time": 7083.937642335892, "episode/length": 299.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 146640, "time": 7095.710245370865, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 146792, "time": 7102.231157541275, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 147184, "time": 7117.2378623485565, "episode/length": 152.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 147256, "time": 7120.968341827393, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 147272, "time": 7123.179436922073, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 147400, "time": 7128.928295850754, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 147608, "time": 7138.8156645298, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 148016, "time": 7154.492524147034, "episode/length": 281.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 148128, "time": 7159.908640861511, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 148440, "time": 7171.864315748215, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 148512, "time": 7176.030052185059, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 148712, "time": 7184.076507568359, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 148744, "time": 7186.6060881614685, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 148840, "time": 7191.426665067673, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 148952, "time": 7196.777275800705, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 149504, "time": 7217.181304216385, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 149584, "time": 7221.384334564209, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 149768, "time": 7229.0442934036255, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 150024, "time": 7239.387627363205, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7258.144935369492, "eval_episode/length": 57.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 150072, "time": 7259.8718819618225, "eval_episode/length": 61.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 150072, "time": 7262.799275875092, "eval_episode/length": 90.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9340659340659341}
{"step": 150072, "time": 7266.165318012238, "eval_episode/length": 134.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9555555555555556}
{"step": 150072, "time": 7268.973016023636, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 150072, "time": 7271.11502456665, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 150072, "time": 7274.399174213409, "eval_episode/length": 213.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.985981308411215}
{"step": 150072, "time": 7276.831980228424, "eval_episode/length": 231.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.978448275862069}
{"step": 150152, "time": 7279.5253393650055, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 150440, "time": 7290.7692658901215, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 150504, "time": 7295.12865281105, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 150560, "time": 7298.866860866547, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 150872, "time": 7310.787194490433, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 150985, "time": 7317.210308551788, "train_stats/sum_log_reward": 4.081818111376329, "train_stats/max_log_achievement_collect_drink": 9.772727272727273, "train_stats/max_log_achievement_collect_sapling": 3.0454545454545454, "train_stats/max_log_achievement_collect_wood": 1.8545454545454545, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.08181818181818182, "train_stats/max_log_achievement_eat_cow": 0.13636363636363635, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03636363636363636, "train_stats/max_log_achievement_place_plant": 2.7545454545454544, "train_stats/max_log_achievement_place_table": 0.3090909090909091, "train_stats/max_log_achievement_wake_up": 1.4727272727272727, "train_stats/mean_log_entropy": 0.7617362103678963, "eval_stats/sum_log_reward": 3.683333252867063, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_wood": 1.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.16666666666666666, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6666666666666665, "eval_stats/max_log_achievement_place_table": 0.20833333333333334, "eval_stats/max_log_achievement_wake_up": 1.2916666666666667, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.840728759765625, "train/action_min": 0.0, "train/action_std": 3.798092341784275, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04917348808411396, "train/actor_opt_grad_steps": 8685.0, "train/actor_opt_loss": 19.013779241069585, "train/adv_mag": 0.8793607801198959, "train/adv_max": 0.8700382817875255, "train/adv_mean": 0.0069431153380554115, "train/adv_min": -0.5421246021534457, "train/adv_std": 0.08534479468609348, "train/cont_avg": 0.9943773674242424, "train/cont_loss_mean": 0.0005635462456413362, "train/cont_loss_std": 0.016086274110348728, "train/cont_neg_acc": 0.9763828791452177, "train/cont_neg_loss": 0.06610167568240657, "train/cont_pos_acc": 0.9999330219897357, "train/cont_pos_loss": 0.00019286501268793316, "train/cont_pred": 0.9944025923808416, "train/cont_rate": 0.9943773674242424, "train/dyn_loss_mean": 12.788694981372718, "train/dyn_loss_std": 8.633353500655204, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0913911479892153, "train/extr_critic_critic_opt_grad_steps": 8685.0, "train/extr_critic_critic_opt_loss": 15142.540741891571, "train/extr_critic_mag": 3.0112513809493096, "train/extr_critic_max": 3.0112513809493096, "train/extr_critic_mean": 0.6903188829169129, "train/extr_critic_min": -0.3087193351803404, "train/extr_critic_std": 0.8481653513330402, "train/extr_return_normed_mag": 1.869605617089705, "train/extr_return_normed_max": 1.869605617089705, "train/extr_return_normed_mean": 0.3468145459438815, "train/extr_return_normed_min": -0.18675685374800002, "train/extr_return_normed_std": 0.35064710292852286, "train/extr_return_rate": 0.38977521420879796, "train/extr_return_raw_mag": 4.563218795891964, "train/extr_return_raw_max": 4.563218795891964, "train/extr_return_raw_mean": 0.707768707790158, "train/extr_return_raw_min": -0.6422489308046572, "train/extr_return_raw_std": 0.8885779755585121, "train/extr_reward_mag": 1.0061223190842252, "train/extr_reward_max": 1.0061223190842252, "train/extr_reward_mean": 0.014996247736483136, "train/extr_reward_min": -0.3014130357540015, "train/extr_reward_std": 0.11081101039819645, "train/image_loss_mean": 14.204829721739799, "train/image_loss_std": 17.487966046188816, "train/model_loss_mean": 21.92914936759255, "train/model_loss_std": 21.22551975105748, "train/model_opt_grad_norm": 90.9816097201723, "train/model_opt_grad_steps": 8673.219696969696, "train/model_opt_loss": 16827.04621656013, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 762.310606060606, "train/policy_entropy_mag": 2.46295489506288, "train/policy_entropy_max": 2.46295489506288, "train/policy_entropy_mean": 0.7598219035249768, "train/policy_entropy_min": 0.0793784222368038, "train/policy_entropy_std": 0.5761199011044069, "train/policy_logprob_mag": 7.438320969090317, "train/policy_logprob_max": -0.009456555803560397, "train/policy_logprob_mean": -0.7594308446754109, "train/policy_logprob_min": -7.438320969090317, "train/policy_logprob_std": 1.2093649289824746, "train/policy_randomness_mag": 0.869314995227438, "train/policy_randomness_max": 0.869314995227438, "train/policy_randomness_mean": 0.26818378709933977, "train/policy_randomness_min": 0.02801709965040738, "train/policy_randomness_std": 0.2033450442055861, "train/post_ent_mag": 49.73522559079257, "train/post_ent_max": 49.73522559079257, "train/post_ent_mean": 35.855066964120574, "train/post_ent_min": 19.420207991744533, "train/post_ent_std": 5.268096179673166, "train/prior_ent_mag": 61.0189093098496, "train/prior_ent_max": 61.0189093098496, "train/prior_ent_mean": 48.78810570456765, "train/prior_ent_min": 24.415835423903033, "train/prior_ent_std": 6.448468721274174, "train/rep_loss_mean": 12.788694981372718, "train/rep_loss_std": 8.633353500655204, "train/reward_avg": 0.015195164423802811, "train/reward_loss_mean": 0.05053913836000544, "train/reward_loss_std": 0.25436303736359783, "train/reward_max_data": 1.008333335320155, "train/reward_max_pred": 1.0032922237208395, "train/reward_neg_acc": 0.994148926301436, "train/reward_neg_loss": 0.03172457099638202, "train/reward_pos_acc": 0.9465702690861442, "train/reward_pos_loss": 0.9659397060220892, "train/reward_pred": 0.014505628408215038, "train/reward_rate": 0.020219282670454544, "train_stats/max_log_achievement_collect_coal": 0.01098901098901099, "train_stats/max_log_achievement_make_wood_sword": 0.02197802197802198, "train_stats/max_log_achievement_collect_stone": 0.013333333333333334, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00014040809764992446, "report/cont_loss_std": 0.0023881010711193085, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0023631153162568808, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00012290646554902196, "report/cont_pred": 0.99208664894104, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 15.090343475341797, "report/dyn_loss_std": 8.915868759155273, "report/image_loss_mean": 15.119873046875, "report/image_loss_std": 18.732248306274414, "report/model_loss_mean": 24.238691329956055, "report/model_loss_std": 22.652545928955078, "report/post_ent_mag": 49.619895935058594, "report/post_ent_max": 49.619895935058594, "report/post_ent_mean": 35.19476318359375, "report/post_ent_min": 18.01605224609375, "report/post_ent_std": 5.257344722747803, "report/prior_ent_mag": 61.48851013183594, "report/prior_ent_max": 61.48851013183594, "report/prior_ent_mean": 50.442752838134766, "report/prior_ent_min": 20.399478912353516, "report/prior_ent_std": 7.437158584594727, "report/rep_loss_mean": 15.090343475341797, "report/rep_loss_std": 8.915868759155273, "report/reward_avg": 0.01767577975988388, "report/reward_loss_mean": 0.06447190046310425, "report/reward_loss_std": 0.3201204538345337, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0003859996795654, "report/reward_neg_acc": 0.9930000305175781, "report/reward_neg_loss": 0.039625056087970734, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 1.099757194519043, "report/reward_pred": 0.01921696960926056, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.908631232567132e-06, "eval/cont_loss_std": 0.00013307121116667986, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00029186654137447476, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.074278528307332e-06, "eval/cont_pred": 0.9970641732215881, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 10.858377456665039, "eval/dyn_loss_std": 8.170797348022461, "eval/image_loss_mean": 14.191234588623047, "eval/image_loss_std": 17.69361686706543, "eval/model_loss_mean": 20.793701171875, "eval/model_loss_std": 21.205665588378906, "eval/post_ent_mag": 46.2753791809082, "eval/post_ent_max": 46.2753791809082, "eval/post_ent_mean": 35.08224105834961, "eval/post_ent_min": 19.59264373779297, "eval/post_ent_std": 5.624508857727051, "eval/prior_ent_mag": 60.45134353637695, "eval/prior_ent_max": 60.45134353637695, "eval/prior_ent_mean": 44.14722442626953, "eval/prior_ent_min": 18.357654571533203, "eval/prior_ent_std": 7.888101100921631, "eval/rep_loss_mean": 10.858377456665039, "eval/rep_loss_std": 8.170797348022461, "eval/reward_avg": 0.015527344308793545, "eval/reward_loss_mean": 0.08743280172348022, "eval/reward_loss_std": 0.7903797626495361, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020051002502441, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.03418951854109764, "eval/reward_pos_acc": 0.7894737124443054, "eval/reward_pos_loss": 2.9037227630615234, "eval/reward_pred": 0.011894367635250092, "eval/reward_rate": 0.0185546875, "replay/size": 150481.0, "replay/inserts": 21088.0, "replay/samples": 21088.0, "replay/insert_wait_avg": 1.3136425040017854e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.492983527176297e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 32216.0, "eval_replay/inserts": 6104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2230669999028878e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3542971611023, "timer/env.step_count": 2636.0, "timer/env.step_total": 248.4159712791443, "timer/env.step_frac": 0.2483279893774856, "timer/env.step_avg": 0.09423974631227021, "timer/env.step_min": 0.023074865341186523, "timer/env.step_max": 2.214881658554077, "timer/replay._sample_count": 21088.0, "timer/replay._sample_total": 11.409223079681396, "timer/replay._sample_frac": 0.011405182255986246, "timer/replay._sample_avg": 0.0005410291672838295, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.025927066802978516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3399.0, "timer/agent.policy_total": 56.604055881500244, "timer/agent.policy_frac": 0.05658400832798585, "timer/agent.policy_avg": 0.016653149715063327, "timer/agent.policy_min": 0.00966954231262207, "timer/agent.policy_max": 0.1045677661895752, "timer/dataset_train_count": 1318.0, "timer/dataset_train_total": 0.14008426666259766, "timer/dataset_train_frac": 0.0001400346527826608, "timer/dataset_train_avg": 0.00010628548305204678, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0010595321655273438, "timer/agent.train_count": 1318.0, "timer/agent.train_total": 597.3267676830292, "timer/agent.train_frac": 0.5971152114587583, "timer/agent.train_avg": 0.4532069557534364, "timer/agent.train_min": 0.43801236152648926, "timer/agent.train_max": 1.4874260425567627, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4707181453704834, "timer/agent.report_frac": 0.0004705514303345632, "timer/agent.report_avg": 0.2353590726852417, "timer/agent.report_min": 0.22820830345153809, "timer/agent.report_max": 0.2425098419189453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241344276705858e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 21.08027482018078}
{"step": 151072, "time": 7320.201190710068, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 151088, "time": 7322.421268701553, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 151328, "time": 7332.245823144913, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 151480, "time": 7338.706404685974, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 151744, "time": 7349.47666478157, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 151744, "time": 7349.48407626152, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 151968, "time": 7360.476091384888, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 152080, "time": 7366.244765281677, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 152432, "time": 7379.764159679413, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 152816, "time": 7394.2530744075775, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 152856, "time": 7397.022057294846, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 153288, "time": 7413.205503940582, "episode/length": 192.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 153296, "time": 7415.311898231506, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 153320, "time": 7417.442716598511, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 153448, "time": 7423.35350561142, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 153768, "time": 7435.816302537918, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 153880, "time": 7441.51834154129, "episode/length": 127.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9453125, "episode/intrinsic_return": 0.0}
{"step": 153904, "time": 7444.290018320084, "episode/length": 302.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 154336, "time": 7460.360285997391, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 154520, "time": 7467.893059253693, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 154672, "time": 7474.832809448242, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 154824, "time": 7481.308386802673, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 155112, "time": 7492.585272312164, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 155304, "time": 7500.653882980347, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 155416, "time": 7506.108111143112, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 155744, "time": 7520.08149433136, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 155944, "time": 7528.246310472488, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 156072, "time": 7534.156865119934, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 156080, "time": 7536.322911739349, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 156120, "time": 7539.014343738556, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 156224, "time": 7544.249995470047, "episode/length": 138.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 156536, "time": 7556.17803812027, "episode/length": 328.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993920972644377, "episode/intrinsic_return": 0.0}
{"step": 156680, "time": 7562.67103600502, "episode/length": 56.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 156680, "time": 7562.6803340911865, "episode/length": 75.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 156728, "time": 7567.846089839935, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 156768, "time": 7570.901557683945, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 157368, "time": 7592.663377523422, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 157608, "time": 7602.307355642319, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 157872, "time": 7613.029139995575, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 157992, "time": 7618.376260519028, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 158144, "time": 7625.325427770615, "episode/length": 176.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 158192, "time": 7628.587747097015, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 158208, "time": 7630.726540327072, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 158248, "time": 7633.466057062149, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 158960, "time": 7659.258869171143, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 159328, "time": 7673.365737915039, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 159352, "time": 7675.436661481857, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 159520, "time": 7683.021159648895, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 159536, "time": 7685.113043546677, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 159624, "time": 7689.459939002991, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 159680, "time": 7693.136442661285, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 159704, "time": 7695.291617393494, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 159736, "time": 7697.893274307251, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 159976, "time": 7707.465171813965, "episode/length": 56.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7731.363872528076, "eval_episode/length": 116.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9572649572649573}
{"step": 160056, "time": 7735.005373239517, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 160056, "time": 7737.5259919166565, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 160056, "time": 7739.672183513641, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 160056, "time": 7743.161156654358, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 160056, "time": 7746.032091617584, "eval_episode/length": 57.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 160056, "time": 7748.306361436844, "eval_episode/length": 238.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.99581589958159}
{"step": 160056, "time": 7750.958473443985, "eval_episode/length": 263.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 160192, "time": 7755.7439506053925, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 160648, "time": 7772.45259475708, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 160736, "time": 7777.19159245491, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 160864, "time": 7783.164368867874, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 160872, "time": 7784.868003368378, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 161024, "time": 7791.819040775299, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 161184, "time": 7798.877717018127, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 161320, "time": 7804.845810651779, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 161712, "time": 7819.6453166008, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 162064, "time": 7833.066701173782, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 162136, "time": 7836.76074385643, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 162192, "time": 7840.3218150138855, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 162344, "time": 7846.880568742752, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 162496, "time": 7854.38857293129, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 162608, "time": 7859.734000444412, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 163224, "time": 7881.910245418549, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 163232, "time": 7884.02184009552, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 163352, "time": 7889.5057327747345, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 163616, "time": 7900.166622161865, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 163616, "time": 7900.175803422928, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 163840, "time": 7911.205609798431, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 164016, "time": 7919.980822563171, "episode/length": 49.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 164160, "time": 7926.444526195526, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 164224, "time": 7930.138450622559, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 164528, "time": 7941.9205548763275, "episode/length": 113.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 164552, "time": 7944.1616196632385, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 164648, "time": 7948.888902902603, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 164768, "time": 7954.808607339859, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 165464, "time": 7979.303696155548, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 165496, "time": 7982.443472862244, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 165696, "time": 7991.334747076035, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 165856, "time": 7998.310234069824, "episode/length": 419.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9976190476190476, "episode/intrinsic_return": 0.0}
{"step": 166032, "time": 8005.800492525101, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 166088, "time": 8008.957902431488, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 166128, "time": 8012.261474132538, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 166440, "time": 8024.167277336121, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 166640, "time": 8032.690702676773, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 166712, "time": 8036.493066549301, "episode/length": 269.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 167032, "time": 8049.1950340271, "episode/length": 124.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 167088, "time": 8052.900361061096, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 167128, "time": 8055.7539892196655, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 167312, "time": 8063.877690553665, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 167512, "time": 8071.937505483627, "episode/length": 172.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 167760, "time": 8082.087122678757, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 168304, "time": 8102.341519832611, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 168488, "time": 8109.900165557861, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 168496, "time": 8111.923866033554, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 168504, "time": 8113.47994017601, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 168760, "time": 8123.729565858841, "episode/length": 255.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 168792, "time": 8126.445827007294, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 168880, "time": 8131.222294092178, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 169096, "time": 8140.012459039688, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 169760, "time": 8164.018293619156, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 169952, "time": 8172.075124263763, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8191.705986738205, "eval_episode/length": 56.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 170040, "time": 8197.282232046127, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 170040, "time": 8199.410200595856, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 170040, "time": 8201.053471326828, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 170040, "time": 8203.095449447632, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 170040, "time": 8205.66804265976, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 170040, "time": 8207.489241361618, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 170040, "time": 8209.331933021545, "eval_episode/length": 47.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 170064, "time": 8210.357672214508, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 170088, "time": 8212.601916790009, "episode/length": 161.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 170096, "time": 8214.651628732681, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 170208, "time": 8219.93983912468, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 170288, "time": 8224.259734869003, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 170344, "time": 8227.438055753708, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 171008, "time": 8251.52606511116, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 171384, "time": 8265.56989312172, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 171456, "time": 8269.812862157822, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 171496, "time": 8272.511934518814, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 171592, "time": 8277.224247932434, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 171640, "time": 8280.544879198074, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 171680, "time": 8283.819755792618, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 172120, "time": 8301.120038986206, "episode/length": 54.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 172376, "time": 8311.291110038757, "episode/length": 302.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 172489, "time": 8317.65343260765, "train_stats/sum_log_reward": 4.205690980926762, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.983739837398374, "train_stats/max_log_achievement_collect_sapling": 2.3495934959349594, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.016260162601626, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.056910569105691054, "train_stats/max_log_achievement_eat_cow": 0.06504065040650407, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016260162601626018, "train_stats/max_log_achievement_make_wood_sword": 0.016260162601626018, "train_stats/max_log_achievement_place_plant": 2.1951219512195124, "train_stats/max_log_achievement_place_table": 0.6829268292682927, "train_stats/max_log_achievement_wake_up": 1.1626016260162602, "train_stats/mean_log_entropy": 0.6490757823959599, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.379232378148321, "train/action_min": 0.0, "train/action_std": 2.901220762907569, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046142707203528775, "train/actor_opt_grad_steps": 10015.0, "train/actor_opt_loss": -10.66958071469371, "train/adv_mag": 0.8261131112700077, "train/adv_max": 0.8173916620105061, "train/adv_mean": 0.0027274657085800116, "train/adv_min": -0.491063300575783, "train/adv_std": 0.07827902804893344, "train/cont_avg": 0.994453999533582, "train/cont_loss_mean": 0.000520058923426496, "train/cont_loss_std": 0.014663909668422717, "train/cont_neg_acc": 0.9818644883917339, "train/cont_neg_loss": 0.05994940608544895, "train/cont_pos_acc": 0.999948667056525, "train/cont_pos_loss": 0.0001754448115895681, "train/cont_pred": 0.9944832396151414, "train/cont_rate": 0.994453999533582, "train/dyn_loss_mean": 13.429538577350218, "train/dyn_loss_std": 8.92039236737721, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.029922596554258, "train/extr_critic_critic_opt_grad_steps": 10015.0, "train/extr_critic_critic_opt_loss": 14929.537947469682, "train/extr_critic_mag": 3.2585003482761667, "train/extr_critic_max": 3.2585003482761667, "train/extr_critic_mean": 0.7275543046086582, "train/extr_critic_min": -0.3109641030653199, "train/extr_critic_std": 0.8887119609028545, "train/extr_return_normed_mag": 1.8105598314484554, "train/extr_return_normed_max": 1.8105598314484554, "train/extr_return_normed_mean": 0.3386017216452912, "train/extr_return_normed_min": -0.1842764032198422, "train/extr_return_normed_std": 0.3470802307128906, "train/extr_return_rate": 0.4015654359958065, "train/extr_return_raw_mag": 4.646817929709136, "train/extr_return_raw_max": 4.646817929709136, "train/extr_return_raw_mean": 0.7347682985796857, "train/extr_return_raw_min": -0.6539512663634856, "train/extr_return_raw_std": 0.9222964777875302, "train/extr_reward_mag": 1.0058934323823274, "train/extr_reward_max": 1.0058934323823274, "train/extr_reward_mean": 0.014827172094678034, "train/extr_reward_min": -0.329862968245549, "train/extr_reward_std": 0.11123280121541734, "train/image_loss_mean": 12.786619207752285, "train/image_loss_std": 16.300582501425673, "train/model_loss_mean": 20.89637120802011, "train/model_loss_std": 20.168709633955316, "train/model_opt_grad_norm": 90.29286302025639, "train/model_opt_grad_steps": 10001.820895522387, "train/model_opt_loss": 13626.997901119403, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 648.320895522388, "train/policy_entropy_mag": 2.381866940811499, "train/policy_entropy_max": 2.381866940811499, "train/policy_entropy_mean": 0.6762087580873005, "train/policy_entropy_min": 0.07937764937975514, "train/policy_entropy_std": 0.507586885521661, "train/policy_logprob_mag": 7.438363498716212, "train/policy_logprob_max": -0.009456332550564809, "train/policy_logprob_mean": -0.6770798439410195, "train/policy_logprob_min": -7.438363498716212, "train/policy_logprob_std": 1.153767382920678, "train/policy_randomness_mag": 0.8406945035528781, "train/policy_randomness_max": 0.8406945035528781, "train/policy_randomness_mean": 0.23867201527108006, "train/policy_randomness_min": 0.02801682669391383, "train/policy_randomness_std": 0.1791558956254774, "train/post_ent_mag": 51.010039599973766, "train/post_ent_max": 51.010039599973766, "train/post_ent_mean": 36.32978948906286, "train/post_ent_min": 19.637107265529348, "train/post_ent_std": 5.554272523566858, "train/prior_ent_mag": 61.662403249028905, "train/prior_ent_max": 61.662403249028905, "train/prior_ent_mean": 49.9136957197047, "train/prior_ent_min": 25.629479621773335, "train/prior_ent_std": 6.335582327486864, "train/rep_loss_mean": 13.429538577350218, "train/rep_loss_std": 8.92039236737721, "train/reward_avg": 0.016057894048246264, "train/reward_loss_mean": 0.05150884816617663, "train/reward_loss_std": 0.2636392163251763, "train/reward_max_data": 1.0074626883464073, "train/reward_max_pred": 1.0042976906050498, "train/reward_neg_acc": 0.994263574258605, "train/reward_neg_loss": 0.031595912251148876, "train/reward_pos_acc": 0.9434519352307961, "train/reward_pos_loss": 0.9722499455978622, "train/reward_pred": 0.015339336192075496, "train/reward_rate": 0.02112727378731343, "eval_stats/sum_log_reward": 4.099999882280827, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.375, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_table": 0.8125, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.88123740372248e-05, "report/cont_loss_std": 0.0003185989917255938, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0029744261410087347, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.3098525566165335e-06, "report/cont_pred": 0.9951274394989014, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.393592834472656, "report/dyn_loss_std": 9.225022315979004, "report/image_loss_mean": 8.16390609741211, "report/image_loss_std": 11.784330368041992, "report/model_loss_mean": 15.645645141601562, "report/model_loss_std": 15.947223663330078, "report/post_ent_mag": 51.750423431396484, "report/post_ent_max": 51.750423431396484, "report/post_ent_mean": 35.065216064453125, "report/post_ent_min": 20.48301124572754, "report/post_ent_std": 5.726131916046143, "report/prior_ent_mag": 62.565303802490234, "report/prior_ent_max": 62.565303802490234, "report/prior_ent_mean": 48.285301208496094, "report/prior_ent_min": 22.136241912841797, "report/prior_ent_std": 7.135585784912109, "report/rep_loss_mean": 12.393592834472656, "report/rep_loss_std": 9.225022315979004, "report/reward_avg": 0.01679687574505806, "report/reward_loss_mean": 0.04556417465209961, "report/reward_loss_std": 0.29216405749320984, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017235279083252, "report/reward_neg_acc": 0.9980059862136841, "report/reward_neg_loss": 0.03162774443626404, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7111947536468506, "report/reward_pred": 0.016650144010782242, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0012414687080308795, "eval/cont_loss_std": 0.03948384150862694, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001056446461006999, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0012418306432664394, "eval/cont_pred": 0.9973434209823608, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 9.695195198059082, "eval/dyn_loss_std": 8.400459289550781, "eval/image_loss_mean": 12.073503494262695, "eval/image_loss_std": 34.68769836425781, "eval/model_loss_mean": 17.940048217773438, "eval/model_loss_std": 37.594688415527344, "eval/post_ent_mag": 49.42707824707031, "eval/post_ent_max": 49.42707824707031, "eval/post_ent_mean": 36.43840789794922, "eval/post_ent_min": 19.518295288085938, "eval/post_ent_std": 5.340107440948486, "eval/prior_ent_mag": 62.565303802490234, "eval/prior_ent_max": 62.565303802490234, "eval/prior_ent_mean": 45.835453033447266, "eval/prior_ent_min": 20.16387176513672, "eval/prior_ent_std": 6.996523380279541, "eval/rep_loss_mean": 9.695195198059082, "eval/rep_loss_std": 8.400459289550781, "eval/reward_avg": 0.0185546875, "eval/reward_loss_mean": 0.04818495735526085, "eval/reward_loss_std": 0.44570544362068176, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0003223419189453, "eval/reward_neg_acc": 0.9960119724273682, "eval/reward_neg_loss": 0.019733119755983353, "eval/reward_pos_acc": 0.9047619104385376, "eval/reward_pos_loss": 1.4070991277694702, "eval/reward_pred": 0.017872996628284454, "eval/reward_rate": 0.0205078125, "replay/size": 171985.0, "replay/inserts": 21504.0, "replay/samples": 21504.0, "replay/insert_wait_avg": 1.2995054324467976e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.713409659408387e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36032.0, "eval_replay/inserts": 3816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2082123906357484e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4307823181152, "timer/env.step_count": 2688.0, "timer/env.step_total": 269.44718074798584, "timer/env.step_frac": 0.2693311576475538, "timer/env.step_avg": 0.10024076664731615, "timer/env.step_min": 0.022845029830932617, "timer/env.step_max": 3.5768070220947266, "timer/replay._sample_count": 21504.0, "timer/replay._sample_total": 11.592182159423828, "timer/replay._sample_frac": 0.011587190602595599, "timer/replay._sample_avg": 0.0005390709709553491, "timer/replay._sample_min": 0.0003876686096191406, "timer/replay._sample_max": 0.011755228042602539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3165.0, "timer/agent.policy_total": 53.234297037124634, "timer/agent.policy_frac": 0.05321137451785973, "timer/agent.policy_avg": 0.01681968310809625, "timer/agent.policy_min": 0.009528875350952148, "timer/agent.policy_max": 0.1285872459411621, "timer/dataset_train_count": 1344.0, "timer/dataset_train_total": 0.1474299430847168, "timer/dataset_train_frac": 0.00014736646021937106, "timer/dataset_train_avg": 0.00010969489812850952, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0005450248718261719, "timer/agent.train_count": 1344.0, "timer/agent.train_total": 609.4832768440247, "timer/agent.train_frac": 0.6092208352803585, "timer/agent.train_avg": 0.4534845809851374, "timer/agent.train_min": 0.440112829208374, "timer/agent.train_max": 1.3712737560272217, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4716651439666748, "timer/agent.report_frac": 0.0004714620464534003, "timer/agent.report_avg": 0.2358325719833374, "timer/agent.report_min": 0.2241976261138916, "timer/agent.report_max": 0.2474675178527832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8597910018216602e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 21.494480546776106}
{"step": 172520, "time": 8318.42597579956, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 172608, "time": 8323.465534687042, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 172680, "time": 8327.280291318893, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 172712, "time": 8330.02971792221, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 173016, "time": 8342.005773544312, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 173144, "time": 8347.774107456207, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 173296, "time": 8354.68778181076, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 173800, "time": 8373.024065494537, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 173872, "time": 8377.192390203476, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 173880, "time": 8378.912497997284, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 174456, "time": 8399.717222452164, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 174600, "time": 8406.23298239708, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 174632, "time": 8408.87647652626, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 174712, "time": 8413.19892334938, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 175120, "time": 8428.763802289963, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 175128, "time": 8430.381112575531, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 175184, "time": 8434.189930200577, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 175968, "time": 8462.142644166946, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 176104, "time": 8467.99562573433, "episode/length": 205.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 176136, "time": 8470.72838306427, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 176136, "time": 8470.738452196121, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 176400, "time": 8483.305139064789, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 176432, "time": 8486.392077207565, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 176448, "time": 8488.924418449402, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 176584, "time": 8494.826461076736, "episode/length": 487.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9979508196721312, "episode/intrinsic_return": 0.0}
{"step": 176720, "time": 8501.200391292572, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 177512, "time": 8529.102206707, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 177528, "time": 8531.207476854324, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 177616, "time": 8535.939334154129, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 177624, "time": 8537.545587301254, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 177752, "time": 8543.388653039932, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 178064, "time": 8555.784430027008, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 178104, "time": 8558.408826589584, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 178272, "time": 8565.79917049408, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 178752, "time": 8583.431126356125, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 179008, "time": 8593.566919088364, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 179024, "time": 8595.633537530899, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 179184, "time": 8602.646535873413, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 179208, "time": 8604.908988714218, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 179472, "time": 8615.593854188919, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9532163742690059, "episode/intrinsic_return": 0.0}
{"step": 179624, "time": 8622.009280204773, "episode/length": 54.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 179824, "time": 8630.4545109272, "episode/length": 219.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8655.206217050552, "eval_episode/length": 92.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.989247311827957}
{"step": 180024, "time": 8658.916828393936, "eval_episode/length": 144.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 180024, "time": 8660.744408130646, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 180024, "time": 8662.973694562912, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9819277108433735}
{"step": 180024, "time": 8665.20839715004, "eval_episode/length": 181.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 180024, "time": 8667.08925485611, "eval_episode/length": 189.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.968421052631579}
{"step": 180024, "time": 8669.040361642838, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 180024, "time": 8670.945652723312, "eval_episode/length": 205.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 180104, "time": 8673.72803902626, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 180208, "time": 8678.976917743683, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 180248, "time": 8683.101425170898, "episode/length": 246.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 180352, "time": 8688.470509290695, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 180576, "time": 8697.56082868576, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 180768, "time": 8705.679687738419, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 180864, "time": 8710.470983505249, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 181304, "time": 8726.480853796005, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 181544, "time": 8736.087831020355, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 181624, "time": 8740.233494997025, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 181672, "time": 8743.437708854675, "episode/length": 182.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 181920, "time": 8753.617244005203, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 182304, "time": 8767.97933626175, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 182568, "time": 8778.132135391235, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 182688, "time": 8783.884575605392, "episode/length": 126.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 182696, "time": 8785.582712173462, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 182792, "time": 8790.261036396027, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 183368, "time": 8811.024233818054, "episode/length": 312.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9808306709265175, "episode/intrinsic_return": 0.0}
{"step": 183376, "time": 8813.11896944046, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 183672, "time": 8824.510820627213, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 183928, "time": 8834.555930137634, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 184208, "time": 8845.792182207108, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 184240, "time": 8848.401868104935, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 184512, "time": 8859.221841812134, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 184560, "time": 8862.400016784668, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 184656, "time": 8867.108005046844, "episode/length": 51.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 184728, "time": 8870.871787071228, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 184808, "time": 8875.158021450043, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 185192, "time": 8890.225701093674, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 185264, "time": 8894.485707521439, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 185352, "time": 8898.734175920486, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 185600, "time": 8908.823064088821, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 185680, "time": 8912.983175754547, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 185856, "time": 8920.34439587593, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 186344, "time": 8937.889795064926, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 186488, "time": 8944.496854782104, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 186560, "time": 8948.734609127045, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 186624, "time": 8952.453298330307, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 186728, "time": 8957.315366744995, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 186952, "time": 8966.456687927246, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 187272, "time": 8978.803051233292, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 187688, "time": 8994.334699869156, "episode/length": 51.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 187872, "time": 9002.363347768784, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 187920, "time": 9005.521298646927, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 187984, "time": 9009.250070095062, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 188200, "time": 9017.843977212906, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 188216, "time": 9020.190071582794, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 188368, "time": 9027.136986017227, "episode/length": 20.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 188528, "time": 9036.123406410217, "episode/length": 365.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 188640, "time": 9041.448623657227, "episode/length": 52.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 188728, "time": 9045.54470872879, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 189296, "time": 9066.216096401215, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 189304, "time": 9067.820966959, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 189352, "time": 9070.947441101074, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 189408, "time": 9074.678969621658, "episode/length": 109.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 189880, "time": 9091.967767477036, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9117.75042128563, "eval_episode/length": 161.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 190008, "time": 9119.393987178802, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 190008, "time": 9120.914838314056, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 190008, "time": 9122.743101119995, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 190008, "time": 9125.398971557617, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 190008, "time": 9127.535660505295, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 190008, "time": 9129.648701667786, "eval_episode/length": 217.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 190008, "time": 9131.359158992767, "eval_episode/length": 221.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 190016, "time": 9131.858169555664, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 190016, "time": 9131.868134260178, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 190088, "time": 9137.368941545486, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 190544, "time": 9154.38456082344, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 190616, "time": 9158.141132354736, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 190936, "time": 9170.335728168488, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 191080, "time": 9176.735299348831, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 191240, "time": 9184.529289245605, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 191368, "time": 9190.429468631744, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 191440, "time": 9194.68367099762, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 191776, "time": 9207.32773065567, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 191968, "time": 9215.489165782928, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 192280, "time": 9227.206304311752, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 192344, "time": 9230.896198034286, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 192496, "time": 9237.75264787674, "episode/length": 156.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 192688, "time": 9245.906653404236, "episode/length": 218.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 192736, "time": 9249.05683708191, "episode/length": 170.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 192904, "time": 9256.097492933273, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 192992, "time": 9260.808516263962, "episode/length": 31.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 193368, "time": 9274.976008176804, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 193536, "time": 9282.281437635422, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 193680, "time": 9288.590434551239, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 193984, "time": 9300.273382425308, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 194256, "time": 9311.167239904404, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 194393, "time": 9318.021493673325, "train_stats/sum_log_reward": 4.5918032067721, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.89344262295082, "train_stats/max_log_achievement_collect_sapling": 2.8278688524590163, "train_stats/max_log_achievement_collect_stone": 0.01639344262295082, "train_stats/max_log_achievement_collect_wood": 3.221311475409836, "train_stats/max_log_achievement_defeat_skeleton": 0.00819672131147541, "train_stats/max_log_achievement_defeat_zombie": 0.13934426229508196, "train_stats/max_log_achievement_eat_cow": 0.09836065573770492, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01639344262295082, "train_stats/max_log_achievement_make_wood_sword": 0.02459016393442623, "train_stats/max_log_achievement_place_plant": 2.6639344262295084, "train_stats/max_log_achievement_place_table": 1.221311475409836, "train_stats/max_log_achievement_wake_up": 1.278688524590164, "train_stats/mean_log_entropy": 0.5568228946601759, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.8136414019730838, "train/action_min": 0.0, "train/action_std": 2.487706428026631, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04605626541930829, "train/actor_opt_grad_steps": 11370.0, "train/actor_opt_loss": -5.593338237844244, "train/adv_mag": 0.848168398994599, "train/adv_max": 0.8349269785150124, "train/adv_mean": 0.003208263553606761, "train/adv_min": -0.501591864075974, "train/adv_std": 0.07875217437526605, "train/cont_avg": 0.9945255474452555, "train/cont_loss_mean": 0.00034450113611352994, "train/cont_loss_std": 0.00975303269434255, "train/cont_neg_acc": 0.9908759141490407, "train/cont_neg_loss": 0.034887977109762165, "train/cont_pos_acc": 0.9999569215043618, "train/cont_pos_loss": 0.0001465561433162482, "train/cont_pred": 0.9945116025688004, "train/cont_rate": 0.9945255474452555, "train/dyn_loss_mean": 13.918664222216083, "train/dyn_loss_std": 9.018269678101923, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0270842940267855, "train/extr_critic_critic_opt_grad_steps": 11370.0, "train/extr_critic_critic_opt_loss": 15213.375734203923, "train/extr_critic_mag": 3.3209365702023472, "train/extr_critic_max": 3.3209365702023472, "train/extr_critic_mean": 0.6718572339002233, "train/extr_critic_min": -0.33959295975900916, "train/extr_critic_std": 0.9071398795086102, "train/extr_return_normed_mag": 1.8337238609355733, "train/extr_return_normed_max": 1.8337238609355733, "train/extr_return_normed_mean": 0.3292606891724315, "train/extr_return_normed_min": -0.18988314178520746, "train/extr_return_normed_std": 0.35155808273023065, "train/extr_return_rate": 0.3833708946939802, "train/extr_return_raw_mag": 4.695806440645761, "train/extr_return_raw_max": 4.695806440645761, "train/extr_return_raw_mean": 0.6804163081802591, "train/extr_return_raw_min": -0.7056059722047653, "train/extr_return_raw_std": 0.9384815553679083, "train/extr_reward_mag": 1.0062134666164426, "train/extr_reward_max": 1.0062134666164426, "train/extr_reward_mean": 0.01608423910436839, "train/extr_reward_min": -0.3345379368232114, "train/extr_reward_std": 0.11684130877256393, "train/image_loss_mean": 11.665051689983285, "train/image_loss_std": 14.912133265585794, "train/model_loss_mean": 20.069768724650363, "train/model_loss_std": 18.78465825101755, "train/model_opt_grad_norm": 79.28217613610038, "train/model_opt_grad_steps": 11355.627737226278, "train/model_opt_loss": 13899.272760321624, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 693.4306569343066, "train/policy_entropy_mag": 2.452618752082769, "train/policy_entropy_max": 2.452618752082769, "train/policy_entropy_mean": 0.578861761484703, "train/policy_entropy_min": 0.07937625181065859, "train/policy_entropy_std": 0.47479191857532865, "train/policy_logprob_mag": 7.438372441451915, "train/policy_logprob_max": -0.009456020501190729, "train/policy_logprob_mean": -0.5784788449315259, "train/policy_logprob_min": -7.438372441451915, "train/policy_logprob_std": 1.0952739532846605, "train/policy_randomness_mag": 0.8656667884248886, "train/policy_randomness_max": 0.8656667884248886, "train/policy_randomness_mean": 0.2043127994032672, "train/policy_randomness_min": 0.028016333556632057, "train/policy_randomness_std": 0.16758071201561142, "train/post_ent_mag": 51.863603522307685, "train/post_ent_max": 51.863603522307685, "train/post_ent_mean": 36.7168890403135, "train/post_ent_min": 19.996814101281828, "train/post_ent_std": 5.795782200611421, "train/prior_ent_mag": 62.323024916822895, "train/prior_ent_max": 62.323024916822895, "train/prior_ent_mean": 50.80956329568459, "train/prior_ent_min": 27.560895126231394, "train/prior_ent_std": 6.075782817645664, "train/rep_loss_mean": 13.918664222216083, "train/rep_loss_std": 9.018269678101923, "train/reward_avg": 0.017552463279996256, "train/reward_loss_mean": 0.05317406341379141, "train/reward_loss_std": 0.26724600922452274, "train/reward_max_data": 1.0160583979892035, "train/reward_max_pred": 1.004424909605597, "train/reward_neg_acc": 0.9937869641032532, "train/reward_neg_loss": 0.032306689728241765, "train/reward_pos_acc": 0.9483698980651633, "train/reward_pos_loss": 0.9625366012545398, "train/reward_pred": 0.016752714736482304, "train/reward_rate": 0.022560732208029198, "eval_stats/sum_log_reward": 4.474999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.5, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_stone": 0.01282051282051282, "eval_stats/max_log_achievement_place_stone": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.5188228391925804e-05, "report/cont_loss_std": 0.0002892310731112957, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00039352892781607807, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3017264538793825e-05, "report/cont_pred": 0.994120180606842, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.36073112487793, "report/dyn_loss_std": 9.465169906616211, "report/image_loss_mean": 11.769429206848145, "report/image_loss_std": 15.338388442993164, "report/model_loss_mean": 19.23946189880371, "report/model_loss_std": 19.252933502197266, "report/post_ent_mag": 53.667686462402344, "report/post_ent_max": 53.667686462402344, "report/post_ent_mean": 39.32600402832031, "report/post_ent_min": 20.723485946655273, "report/post_ent_std": 6.540650844573975, "report/prior_ent_mag": 62.992889404296875, "report/prior_ent_max": 62.992889404296875, "report/prior_ent_mean": 51.799983978271484, "report/prior_ent_min": 34.12994384765625, "report/prior_ent_std": 5.136031627655029, "report/rep_loss_mean": 12.36073112487793, "report/rep_loss_std": 9.465169906616211, "report/reward_avg": 0.009863280691206455, "report/reward_loss_mean": 0.05356834456324577, "report/reward_loss_std": 0.30829131603240967, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0046353340148926, "report/reward_neg_acc": 0.9950397610664368, "report/reward_neg_loss": 0.03550276160240173, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.1917002201080322, "report/reward_pred": 0.008984566666185856, "report/reward_rate": 0.015625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0001635322259971872, "eval/cont_loss_std": 0.004735838156193495, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012252695159986615, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00015727445133961737, "eval/cont_pred": 0.994002103805542, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 14.252435684204102, "eval/dyn_loss_std": 8.835312843322754, "eval/image_loss_mean": 15.957818984985352, "eval/image_loss_std": 23.521547317504883, "eval/model_loss_mean": 24.581295013427734, "eval/model_loss_std": 26.395938873291016, "eval/post_ent_mag": 48.61731719970703, "eval/post_ent_max": 48.61731719970703, "eval/post_ent_mean": 37.38093566894531, "eval/post_ent_min": 20.49072265625, "eval/post_ent_std": 5.422696113586426, "eval/prior_ent_mag": 62.477088928222656, "eval/prior_ent_max": 62.477088928222656, "eval/prior_ent_mean": 48.234886169433594, "eval/prior_ent_min": 24.631366729736328, "eval/prior_ent_std": 7.015426158905029, "eval/rep_loss_mean": 14.252435684204102, "eval/rep_loss_std": 8.835312843322754, "eval/reward_avg": 0.01279296912252903, "eval/reward_loss_mean": 0.0718516856431961, "eval/reward_loss_std": 0.4703351557254791, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020055770874023, "eval/reward_neg_acc": 0.9980120062828064, "eval/reward_neg_loss": 0.04657793417572975, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.484373927116394, "eval/reward_pred": 0.011189321056008339, "eval/reward_rate": 0.017578125, "replay/size": 193889.0, "replay/inserts": 21904.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.2948880498647864e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.75402402494666e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 39456.0, "eval_replay/inserts": 3424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1366661463942484e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3531353473663, "timer/env.step_count": 2738.0, "timer/env.step_total": 267.7768363952637, "timer/env.step_frac": 0.2676823083103347, "timer/env.step_avg": 0.09780015938468359, "timer/env.step_min": 0.022386789321899414, "timer/env.step_max": 3.5156760215759277, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 11.324243068695068, "timer/replay._sample_frac": 0.01132024548987173, "timer/replay._sample_avg": 0.0005169942964159545, "timer/replay._sample_min": 0.0004050731658935547, "timer/replay._sample_max": 0.010326385498046875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3166.0, "timer/agent.policy_total": 51.0279803276062, "timer/agent.policy_frac": 0.05100996690522398, "timer/agent.policy_avg": 0.016117492207077134, "timer/agent.policy_min": 0.009409904479980469, "timer/agent.policy_max": 0.10500288009643555, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.1468198299407959, "timer/dataset_train_frac": 0.00014676800097179047, "timer/dataset_train_avg": 0.00010724604086252439, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0010635852813720703, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 617.5922200679779, "timer/agent.train_frac": 0.6173742034142002, "timer/agent.train_avg": 0.45112653036375305, "timer/agent.train_min": 0.4369821548461914, "timer/agent.train_max": 1.5837759971618652, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.477161169052124, "timer/agent.report_frac": 0.00047699272606011554, "timer/agent.report_avg": 0.238580584526062, "timer/agent.report_min": 0.23137378692626953, "timer/agent.report_max": 0.2457873821258545, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836179536062933e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 21.89597190747678}
{"step": 194408, "time": 9318.117649316788, "episode/length": 265.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 194592, "time": 9326.474640846252, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 194904, "time": 9338.374349594116, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 195072, "time": 9345.693978309631, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 195480, "time": 9360.57318520546, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 195496, "time": 9362.884830474854, "episode/length": 135.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 195728, "time": 9372.350716590881, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 195792, "time": 9376.082609176636, "episode/length": 387.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9871134020618557, "episode/intrinsic_return": 0.0}
{"step": 196008, "time": 9384.557811260223, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 196064, "time": 9388.131084918976, "episode/length": 183.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 196376, "time": 9399.887573003769, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 196488, "time": 9405.24897813797, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 196552, "time": 9408.931539773941, "episode/length": 131.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 196856, "time": 9421.925298929214, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 196960, "time": 9427.119147539139, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 197264, "time": 9438.803248167038, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 197368, "time": 9443.625679016113, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 197424, "time": 9447.298207521439, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 197584, "time": 9454.235040187836, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 197728, "time": 9460.58711194992, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 197976, "time": 9470.187910556793, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 198336, "time": 9484.073437452316, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 198552, "time": 9492.717104673386, "episode/length": 160.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 198872, "time": 9505.026148796082, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 199000, "time": 9511.004209518433, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 199032, "time": 9513.809293746948, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 199112, "time": 9518.05799484253, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 199328, "time": 9527.081590890884, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 200088, "time": 9553.890189647675, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9577.068536043167, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 200096, "time": 9578.747601747513, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 200096, "time": 9580.434760808945, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 200096, "time": 9582.048565149307, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 200096, "time": 9584.780576705933, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 200096, "time": 9586.695300579071, "eval_episode/length": 205.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 200096, "time": 9588.370337247849, "eval_episode/length": 208.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 200096, "time": 9590.310044765472, "eval_episode/length": 217.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 200112, "time": 9590.868767738342, "episode/length": 266.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 200296, "time": 9598.34339761734, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 200376, "time": 9602.716655015945, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 200384, "time": 9604.786696195602, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 200392, "time": 9606.370213747025, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 200608, "time": 9615.291932582855, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 200952, "time": 9627.976538419724, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 201336, "time": 9642.82503938675, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 201424, "time": 9647.64306974411, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 201712, "time": 9658.928837537766, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 201928, "time": 9667.579751253128, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 202160, "time": 9677.079862356186, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 202272, "time": 9682.420850515366, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 202320, "time": 9685.663022994995, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 202576, "time": 9695.830446481705, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 202728, "time": 9702.283505916595, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 202968, "time": 9711.904240131378, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 203024, "time": 9715.691025733948, "episode/length": 136.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 203480, "time": 9732.308797121048, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 203696, "time": 9741.23901796341, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 203880, "time": 9748.82959651947, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 204008, "time": 9754.741795778275, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 204064, "time": 9758.353920221329, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 204352, "time": 9769.61471915245, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 204624, "time": 9780.150785446167, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 205040, "time": 9797.182650089264, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 205192, "time": 9803.657193183899, "episode/length": 270.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 205200, "time": 9805.728367567062, "episode/length": 327.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 205256, "time": 9808.864414930344, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 205272, "time": 9810.926898241043, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 205344, "time": 9815.317999839783, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 205664, "time": 9827.544525384903, "episode/length": 129.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 205704, "time": 9830.33327293396, "episode/length": 55.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 206088, "time": 9844.824055671692, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 206528, "time": 9861.496096372604, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 206528, "time": 9861.50366139412, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 206600, "time": 9867.17654633522, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 206872, "time": 9877.860746383667, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 207048, "time": 9885.307623147964, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 207088, "time": 9888.580842256546, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 207232, "time": 9895.145381689072, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 207824, "time": 9916.431409597397, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 208048, "time": 9925.487776756287, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 208112, "time": 9929.271938562393, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 208320, "time": 9937.799633979797, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 208328, "time": 9939.42700099945, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 208544, "time": 9948.441072940826, "episode/length": 181.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 208600, "time": 9951.690037250519, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 209208, "time": 9973.691757202148, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 209400, "time": 9981.664269924164, "episode/length": 270.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 209472, "time": 9985.84815454483, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 209488, "time": 9987.988835811615, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 209840, "time": 10001.391713142395, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 209984, "time": 10007.87803697586, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10032.59813785553, "eval_episode/length": 170.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 210080, "time": 10034.173013687134, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 210080, "time": 10036.260380268097, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 210080, "time": 10038.67078781128, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 210080, "time": 10041.635900259018, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 210080, "time": 10043.761878490448, "eval_episode/length": 208.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 210080, "time": 10046.73817372322, "eval_episode/length": 228.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.982532751091703}
{"step": 210080, "time": 10050.681015014648, "eval_episode/length": 269.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9851851851851852}
{"step": 210184, "time": 10054.073403596878, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 210512, "time": 10066.783330202103, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 210648, "time": 10072.651829242706, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 210808, "time": 10079.485566139221, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 211072, "time": 10090.166029930115, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 211176, "time": 10094.943538427353, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 211424, "time": 10104.98659157753, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 211528, "time": 10109.633276224136, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 211712, "time": 10117.66507768631, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 211856, "time": 10123.987296581268, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 211960, "time": 10128.688715219498, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 212136, "time": 10136.027389764786, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 212464, "time": 10148.784605026245, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 212720, "time": 10158.879378080368, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 212968, "time": 10168.481900453568, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 213056, "time": 10174.673856496811, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 213096, "time": 10177.423689365387, "episode/length": 46.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 213160, "time": 10181.205963611603, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 213304, "time": 10187.44241309166, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 213384, "time": 10191.624535560608, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 213432, "time": 10194.791393518448, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 213792, "time": 10208.59332227707, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 214440, "time": 10231.572971105576, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 214504, "time": 10235.441615343094, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 214568, "time": 10239.13041305542, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 214712, "time": 10245.430479049683, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 214736, "time": 10248.09685254097, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 214768, "time": 10250.725717306137, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 214944, "time": 10258.117257595062, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 215208, "time": 10268.395899772644, "episode/length": 176.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 215792, "time": 10289.576499938965, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 215864, "time": 10293.49317741394, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 216104, "time": 10303.551512241364, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 216473, "time": 10318.326734781265, "train_stats/sum_log_reward": 4.92758611975045, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.913793103448276, "train_stats/max_log_achievement_collect_sapling": 2.853448275862069, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.094827586206897, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.19827586206896552, "train_stats/max_log_achievement_eat_cow": 0.07758620689655173, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017241379310344827, "train_stats/max_log_achievement_make_wood_sword": 0.02586206896551724, "train_stats/max_log_achievement_place_plant": 2.6982758620689653, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.6637931034482758, "train_stats/max_log_achievement_wake_up": 1.5086206896551724, "train_stats/mean_log_entropy": 0.5836168198749937, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.736427196557971, "train/action_min": 0.0, "train/action_std": 2.653010534203571, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04935955380400022, "train/actor_opt_grad_steps": 12745.0, "train/actor_opt_loss": 3.562333626713118, "train/adv_mag": 0.8229815612236658, "train/adv_max": 0.8130914983542069, "train/adv_mean": 0.00482618166247646, "train/adv_min": -0.5137676054584808, "train/adv_std": 0.08169273891742679, "train/cont_avg": 0.9941830842391305, "train/cont_loss_mean": 0.0004147518499278051, "train/cont_loss_std": 0.011848095739868886, "train/cont_neg_acc": 0.9800178313600845, "train/cont_neg_loss": 0.04736159109673749, "train/cont_pos_acc": 0.9999643451925637, "train/cont_pos_loss": 0.00013132492916319595, "train/cont_pred": 0.994215008141338, "train/cont_rate": 0.9941830842391305, "train/dyn_loss_mean": 14.30428083392157, "train/dyn_loss_std": 9.178430481233459, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9520895310502121, "train/extr_critic_critic_opt_grad_steps": 12745.0, "train/extr_critic_critic_opt_loss": 15245.866097712862, "train/extr_critic_mag": 3.463674103004345, "train/extr_critic_max": 3.463674103004345, "train/extr_critic_mean": 0.683035925462626, "train/extr_critic_min": -0.31830523497816443, "train/extr_critic_std": 0.9281390844911769, "train/extr_return_normed_mag": 1.8497380216916401, "train/extr_return_normed_max": 1.8497380216916401, "train/extr_return_normed_mean": 0.3181099665985591, "train/extr_return_normed_min": -0.16698753515231438, "train/extr_return_normed_std": 0.35309525590012036, "train/extr_return_rate": 0.37449899996104447, "train/extr_return_raw_mag": 4.878570971281632, "train/extr_return_raw_max": 4.878570971281632, "train/extr_return_raw_mean": 0.696179209627967, "train/extr_return_raw_min": -0.6285735854636068, "train/extr_return_raw_std": 0.9641573869663737, "train/extr_reward_mag": 1.008974413940872, "train/extr_reward_max": 1.008974413940872, "train/extr_reward_mean": 0.01852185716447623, "train/extr_reward_min": -0.3364789555038231, "train/extr_reward_std": 0.12528606736357661, "train/image_loss_mean": 10.97555176762567, "train/image_loss_std": 14.597781609797824, "train/model_loss_mean": 19.610929558242578, "train/model_loss_std": 18.5147424849911, "train/model_opt_grad_norm": 82.68627592446147, "train/model_opt_grad_steps": 12729.688405797102, "train/model_opt_loss": 16268.158104053442, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 833.3333333333334, "train/policy_entropy_mag": 2.4532759535139887, "train/policy_entropy_max": 2.4532759535139887, "train/policy_entropy_mean": 0.5875770244477452, "train/policy_entropy_min": 0.07937578376436578, "train/policy_entropy_std": 0.5003041158551755, "train/policy_logprob_mag": 7.438378061073414, "train/policy_logprob_max": -0.009455933343565119, "train/policy_logprob_mean": -0.5872845973657526, "train/policy_logprob_min": -7.438378061073414, "train/policy_logprob_std": 1.1067118661991064, "train/policy_randomness_mag": 0.8658987538538118, "train/policy_randomness_max": 0.8658987538538118, "train/policy_randomness_mean": 0.20738890216402386, "train/policy_randomness_min": 0.028016168327219246, "train/policy_randomness_std": 0.17658539883036545, "train/post_ent_mag": 52.52705480050349, "train/post_ent_max": 52.52705480050349, "train/post_ent_mean": 37.01987642481707, "train/post_ent_min": 20.283113852791164, "train/post_ent_std": 6.005417927451756, "train/prior_ent_mag": 62.81987975300222, "train/prior_ent_max": 62.81987975300222, "train/prior_ent_mean": 51.47409345101619, "train/prior_ent_min": 29.149437075075895, "train/prior_ent_std": 5.906363103700721, "train/rep_loss_mean": 14.30428083392157, "train/rep_loss_std": 9.178430481233459, "train/reward_avg": 0.018805904529880787, "train/reward_loss_mean": 0.05239460308212733, "train/reward_loss_std": 0.2503786941693313, "train/reward_max_data": 1.01449275707853, "train/reward_max_pred": 1.0070505366809126, "train/reward_neg_acc": 0.9937047958374023, "train/reward_neg_loss": 0.031119413100237, "train/reward_pos_acc": 0.955794080875922, "train/reward_pos_loss": 0.9211852274079254, "train/reward_pred": 0.018036476052973583, "train/reward_rate": 0.023975317028985508, "eval_stats/sum_log_reward": 5.037499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.25, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.916605293052271e-05, "report/cont_loss_std": 0.0026388131082057953, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.385143696097657e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.960995182860643e-05, "report/cont_pred": 0.9940550923347473, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 9.642888069152832, "report/dyn_loss_std": 8.491287231445312, "report/image_loss_mean": 6.228366374969482, "report/image_loss_std": 11.940343856811523, "report/model_loss_mean": 12.053155899047852, "report/model_loss_std": 15.62608814239502, "report/post_ent_mag": 50.61811828613281, "report/post_ent_max": 50.61811828613281, "report/post_ent_mean": 38.11137008666992, "report/post_ent_min": 21.74038314819336, "report/post_ent_std": 6.181063652038574, "report/prior_ent_mag": 63.32238006591797, "report/prior_ent_max": 63.32238006591797, "report/prior_ent_mean": 49.050880432128906, "report/prior_ent_min": 25.307701110839844, "report/prior_ent_std": 6.634698390960693, "report/rep_loss_mean": 9.642888069152832, "report/rep_loss_std": 8.491287231445312, "report/reward_avg": 0.02333984151482582, "report/reward_loss_mean": 0.038967669010162354, "report/reward_loss_std": 0.17786385118961334, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021381378173828, "report/reward_neg_acc": 0.9979920387268066, "report/reward_neg_loss": 0.019614245742559433, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7273967266082764, "report/reward_pred": 0.023060858249664307, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00037407741183415055, "eval/cont_loss_std": 0.011942576617002487, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1274983286857605, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.487287353389547e-07, "eval/cont_pred": 0.9973803162574768, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.120326042175293, "eval/dyn_loss_std": 10.984719276428223, "eval/image_loss_mean": 14.157033920288086, "eval/image_loss_std": 23.2159366607666, "eval/model_loss_mean": 23.27452850341797, "eval/model_loss_std": 27.896316528320312, "eval/post_ent_mag": 49.17194366455078, "eval/post_ent_max": 49.17194366455078, "eval/post_ent_mean": 36.921539306640625, "eval/post_ent_min": 20.732948303222656, "eval/post_ent_std": 5.688553810119629, "eval/prior_ent_mag": 63.32238006591797, "eval/prior_ent_max": 63.32238006591797, "eval/prior_ent_mean": 49.74659729003906, "eval/prior_ent_min": 24.356979370117188, "eval/prior_ent_std": 6.841024398803711, "eval/rep_loss_mean": 15.120326042175293, "eval/rep_loss_std": 10.984719276428223, "eval/reward_avg": 0.02080078050494194, "eval/reward_loss_mean": 0.0449259877204895, "eval/reward_loss_std": 0.36080560088157654, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0023982524871826, "eval/reward_neg_acc": 0.9980019927024841, "eval/reward_neg_loss": 0.012047006748616695, "eval/reward_pos_acc": 0.8695652484893799, "eval/reward_pos_loss": 1.4758765697479248, "eval/reward_pred": 0.017061056569218636, "eval/reward_rate": 0.0224609375, "replay/size": 215969.0, "replay/inserts": 22080.0, "replay/samples": 22080.0, "replay/insert_wait_avg": 1.280398472495701e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.930006752843442e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 43360.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1754817649966382e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2929904460907, "timer/env.step_count": 2760.0, "timer/env.step_total": 257.8001182079315, "timer/env.step_frac": 0.2577246073602525, "timer/env.step_avg": 0.09340583993040998, "timer/env.step_min": 0.02318406105041504, "timer/env.step_max": 3.5349409580230713, "timer/replay._sample_count": 22080.0, "timer/replay._sample_total": 11.393028020858765, "timer/replay._sample_frac": 0.011389690950226423, "timer/replay._sample_avg": 0.0005159885879012122, "timer/replay._sample_min": 0.00035262107849121094, "timer/replay._sample_max": 0.029029130935668945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3248.0, "timer/agent.policy_total": 53.43846273422241, "timer/agent.policy_frac": 0.05342281036118327, "timer/agent.policy_avg": 0.01645272867432956, "timer/agent.policy_min": 0.009318828582763672, "timer/agent.policy_max": 0.1299142837524414, "timer/dataset_train_count": 1380.0, "timer/dataset_train_total": 0.14605212211608887, "timer/dataset_train_frac": 0.00014600934277361622, "timer/dataset_train_avg": 0.00010583487109861512, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.00047898292541503906, "timer/agent.train_count": 1380.0, "timer/agent.train_total": 620.105232000351, "timer/agent.train_frac": 0.6199236003081545, "timer/agent.train_avg": 0.44935161739155866, "timer/agent.train_min": 0.43515801429748535, "timer/agent.train_max": 1.5542514324188232, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47561192512512207, "timer/agent.report_frac": 0.0004754726161912003, "timer/agent.report_avg": 0.23780596256256104, "timer/agent.report_min": 0.22940683364868164, "timer/agent.report_max": 0.24620509147644043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8125151933173105e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.07324883831346}
{"step": 216528, "time": 10320.243401765823, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 216792, "time": 10330.712276220322, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 216800, "time": 10332.785374403, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 217080, "time": 10343.514054059982, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 217104, "time": 10346.150148391724, "episode/length": 269.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 217208, "time": 10350.942845582962, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 217232, "time": 10353.62518620491, "episode/length": 53.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 217704, "time": 10370.622846364975, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 217904, "time": 10378.966665744781, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 217976, "time": 10382.7526242733, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 218352, "time": 10397.058374881744, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 218408, "time": 10400.418738126755, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 218744, "time": 10413.22066283226, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 218800, "time": 10416.936879873276, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 219096, "time": 10428.212265729904, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 219344, "time": 10438.289994001389, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10482.908462285995, "eval_episode/length": 141.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 220064, "time": 10485.289809465408, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 220064, "time": 10488.08220076561, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 220064, "time": 10489.742525339127, "eval_episode/length": 189.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 220064, "time": 10491.971461296082, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 220064, "time": 10493.854786872864, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 220064, "time": 10496.038833379745, "eval_episode/length": 227.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 220064, "time": 10498.22348189354, "eval_episode/length": 240.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.979253112033195}
{"step": 220080, "time": 10498.7624502182, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 220088, "time": 10500.37732386589, "episode/length": 123.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 220136, "time": 10503.730002641678, "episode/length": 222.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 220224, "time": 10508.541832447052, "episode/length": 392.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949109414758269, "episode/intrinsic_return": 0.0}
{"step": 220616, "time": 10522.797177553177, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 220632, "time": 10524.989593744278, "episode/length": 331.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 220672, "time": 10528.145319700241, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 221088, "time": 10543.497805595398, "episode/length": 56.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 221448, "time": 10558.029874801636, "episode/length": 330.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 221512, "time": 10561.833480119705, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 221704, "time": 10569.950401306152, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 221880, "time": 10577.349611520767, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 221960, "time": 10581.554941177368, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 222128, "time": 10588.825673818588, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 222192, "time": 10592.635351419449, "episode/length": 84.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9294117647058824, "episode/intrinsic_return": 0.0}
{"step": 222216, "time": 10594.823027133942, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 222568, "time": 10608.1724255085, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 222848, "time": 10619.650315761566, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 223048, "time": 10627.692373991013, "episode/length": 167.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 223136, "time": 10632.318935632706, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 223344, "time": 10640.71293759346, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 223464, "time": 10645.950803995132, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 223560, "time": 10650.781003952026, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 223576, "time": 10653.040051221848, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 223744, "time": 10660.472816944122, "episode/length": 190.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 223904, "time": 10667.268689155579, "episode/length": 54.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 224008, "time": 10672.087485551834, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 224400, "time": 10686.880051136017, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 224888, "time": 10704.37170124054, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 225040, "time": 10711.391227722168, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 225096, "time": 10714.710592269897, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 225104, "time": 10716.877301216125, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 225104, "time": 10716.88647532463, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 225128, "time": 10720.712636470795, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 225560, "time": 10736.687780857086, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 226280, "time": 10762.407925844193, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 226352, "time": 10766.700618505478, "episode/length": 243.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 226560, "time": 10775.331880569458, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 226792, "time": 10784.396558046341, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 226792, "time": 10784.408131361008, "episode/length": 54.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 227016, "time": 10795.211241006851, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 227088, "time": 10799.43701505661, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 227144, "time": 10802.91715836525, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 228336, "time": 10844.273086309433, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 228376, "time": 10846.971736907959, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 228424, "time": 10850.2624604702, "episode/length": 422.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 228440, "time": 10852.348747015, "episode/length": 269.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 228488, "time": 10855.580189228058, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 228736, "time": 10865.653392076492, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 228760, "time": 10867.873657464981, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 228760, "time": 10867.88291978836, "episode/length": 274.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 229704, "time": 10904.163601636887, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 229720, "time": 10906.430772304535, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 229808, "time": 10911.030413150787, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 229840, "time": 10913.564221143723, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 230016, "time": 10920.93697309494, "episode/length": 159.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10924.108063936234, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10944.614228725433, "eval_episode/length": 72.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9452054794520548}
{"step": 230048, "time": 10950.578693151474, "eval_episode/length": 156.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 230048, "time": 10952.765363454819, "eval_episode/length": 161.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 230048, "time": 10956.00459909439, "eval_episode/length": 201.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.995049504950495}
{"step": 230048, "time": 10958.456055402756, "eval_episode/length": 218.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 230048, "time": 10960.4038875103, "eval_episode/length": 228.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9650655021834061}
{"step": 230048, "time": 10962.162422180176, "eval_episode/length": 233.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9658119658119658}
{"step": 230048, "time": 10964.500132799149, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 230064, "time": 10966.55480837822, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 230680, "time": 10988.314544200897, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 231040, "time": 11002.092720508575, "episode/length": 166.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 231200, "time": 11008.998242616653, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 231344, "time": 11015.579657316208, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 231480, "time": 11021.974111557007, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 231648, "time": 11029.42829465866, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 231928, "time": 11040.094965457916, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 232224, "time": 11051.97963309288, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 232248, "time": 11054.11295247078, "episode/length": 272.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 232560, "time": 11066.335403203964, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 232592, "time": 11069.049283742905, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 232816, "time": 11078.074232339859, "episode/length": 221.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 233176, "time": 11091.522750377655, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 233360, "time": 11099.579192876816, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 233736, "time": 11113.622004270554, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 233816, "time": 11117.805676221848, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 233840, "time": 11120.372648000717, "episode/length": 294.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 233896, "time": 11123.769034385681, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 233984, "time": 11128.589622974396, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 234384, "time": 11143.499653816223, "episode/length": 49.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 234432, "time": 11146.700588703156, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 234568, "time": 11152.583163022995, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 235088, "time": 11171.64126944542, "episode/length": 168.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 235128, "time": 11174.376343727112, "episode/length": 288.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9896193771626297, "episode/intrinsic_return": 0.0}
{"step": 235360, "time": 11183.876765966415, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 235552, "time": 11191.736950874329, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 235552, "time": 11191.761295318604, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 235880, "time": 11205.921538114548, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 236208, "time": 11218.539294481277, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 236624, "time": 11234.17803645134, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 236800, "time": 11241.724012851715, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 236952, "time": 11248.175287246704, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 237064, "time": 11253.54967713356, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 237064, "time": 11253.559665441513, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 237304, "time": 11264.804577112198, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 237544, "time": 11274.374532461166, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 237576, "time": 11277.473054885864, "episode/length": 392.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9872773536895675, "episode/intrinsic_return": 0.0}
{"step": 238064, "time": 11296.761333227158, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 238280, "time": 11305.29508304596, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 238288, "time": 11307.354615211487, "episode/length": 166.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 238448, "time": 11314.323678255081, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 238505, "time": 11318.592085838318, "train_stats/sum_log_reward": 4.986956458506377, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.773913043478261, "train_stats/max_log_achievement_collect_sapling": 2.8173913043478263, "train_stats/max_log_achievement_collect_stone": 0.09565217391304348, "train_stats/max_log_achievement_collect_wood": 4.6869565217391305, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.19130434782608696, "train_stats/max_log_achievement_eat_cow": 0.09565217391304348, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06086956521739131, "train_stats/max_log_achievement_make_wood_sword": 0.034782608695652174, "train_stats/max_log_achievement_place_plant": 2.6782608695652175, "train_stats/max_log_achievement_place_stone": 0.008695652173913044, "train_stats/max_log_achievement_place_table": 1.9565217391304348, "train_stats/max_log_achievement_wake_up": 1.434782608695652, "train_stats/mean_log_entropy": 0.5725315433481465, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.016575910043025, "train/action_min": 0.0, "train/action_std": 3.0355992680010586, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04928766836182795, "train/actor_opt_grad_steps": 14125.0, "train/actor_opt_loss": 5.095872702994856, "train/adv_mag": 0.7813727825448133, "train/adv_max": 0.7709305778793667, "train/adv_mean": 0.00578019474594022, "train/adv_min": -0.5118922070748564, "train/adv_std": 0.08173418290697146, "train/cont_avg": 0.9944590692934783, "train/cont_loss_mean": 0.000317795074537805, "train/cont_loss_std": 0.009162524181581408, "train/cont_neg_acc": 0.9854296078716499, "train/cont_neg_loss": 0.034815806424587106, "train/cont_pos_acc": 0.9999573239381763, "train/cont_pos_loss": 0.0001577265336262508, "train/cont_pred": 0.9944526155789694, "train/cont_rate": 0.9944590692934783, "train/dyn_loss_mean": 14.802141244860662, "train/dyn_loss_std": 9.236971616744995, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9665011374846749, "train/extr_critic_critic_opt_grad_steps": 14125.0, "train/extr_critic_critic_opt_loss": 15661.080339956974, "train/extr_critic_mag": 3.6582168807154116, "train/extr_critic_max": 3.6582168807154116, "train/extr_critic_mean": 0.7144442038691562, "train/extr_critic_min": -0.3055856746176015, "train/extr_critic_std": 0.9409004164778668, "train/extr_return_normed_mag": 1.8302072087923686, "train/extr_return_normed_max": 1.8302072087923686, "train/extr_return_normed_mean": 0.3154841233854708, "train/extr_return_normed_min": -0.1555710882758317, "train/extr_return_normed_std": 0.34870499210513156, "train/extr_return_rate": 0.3848241450993911, "train/extr_return_raw_mag": 4.984312387480252, "train/extr_return_raw_max": 4.984312387480252, "train/extr_return_raw_mean": 0.7307912718126739, "train/extr_return_raw_min": -0.5922412729781606, "train/extr_return_raw_std": 0.9797865437424701, "train/extr_reward_mag": 1.0108825797620027, "train/extr_reward_max": 1.0108825797620027, "train/extr_reward_mean": 0.018840065492533038, "train/extr_reward_min": -0.3318700228912243, "train/extr_reward_std": 0.1265898339882277, "train/image_loss_mean": 10.87625851838485, "train/image_loss_std": 14.768985264543174, "train/model_loss_mean": 19.810079795726832, "train/model_loss_std": 18.69572291166886, "train/model_opt_grad_norm": 78.37486343107362, "train/model_opt_grad_steps": 14108.63768115942, "train/model_opt_loss": 15142.496327275816, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 765.3985507246376, "train/policy_entropy_mag": 2.4498333205347476, "train/policy_entropy_max": 2.4498333205347476, "train/policy_entropy_mean": 0.5880274932453597, "train/policy_entropy_min": 0.07937546673676242, "train/policy_entropy_std": 0.5181298003248547, "train/policy_logprob_mag": 7.438378202742425, "train/policy_logprob_max": -0.009455895820713562, "train/policy_logprob_mean": -0.5880385475314182, "train/policy_logprob_min": -7.438378202742425, "train/policy_logprob_std": 1.0987584426783132, "train/policy_randomness_mag": 0.8646836548611738, "train/policy_randomness_max": 0.8646836548611738, "train/policy_randomness_mean": 0.20754789906567422, "train/policy_randomness_min": 0.028016056528018005, "train/policy_randomness_std": 0.18287708221570306, "train/post_ent_mag": 53.15244331912718, "train/post_ent_max": 53.15244331912718, "train/post_ent_mean": 37.23529511603756, "train/post_ent_min": 20.426723348921623, "train/post_ent_std": 6.127522876297218, "train/prior_ent_mag": 63.38795158828514, "train/prior_ent_max": 63.38795158828514, "train/prior_ent_mean": 52.1342599288277, "train/prior_ent_min": 30.60746977985769, "train/prior_ent_std": 5.658965756927711, "train/rep_loss_mean": 14.802141244860662, "train/rep_loss_std": 9.236971616744995, "train/reward_avg": 0.019899230008350983, "train/reward_loss_mean": 0.0522188919501892, "train/reward_loss_std": 0.25212250790302304, "train/reward_max_data": 1.0152173949324566, "train/reward_max_pred": 1.0097798895144807, "train/reward_neg_acc": 0.9936501198056815, "train/reward_neg_loss": 0.03053516564566804, "train/reward_pos_acc": 0.9592642840267955, "train/reward_pos_loss": 0.9054917071176611, "train/reward_pred": 0.019026753310438082, "train/reward_rate": 0.024859884510869564, "eval_stats/sum_log_reward": 4.974999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.9375, "eval_stats/max_log_achievement_collect_sapling": 3.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.2, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.38908227806678e-06, "report/cont_loss_std": 4.551480378722772e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015037001867312938, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.672787215691642e-06, "report/cont_pred": 0.995114266872406, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.556602478027344, "report/dyn_loss_std": 8.206404685974121, "report/image_loss_mean": 7.202960968017578, "report/image_loss_std": 9.134462356567383, "report/model_loss_mean": 14.788350105285645, "report/model_loss_std": 12.344047546386719, "report/post_ent_mag": 53.97265625, "report/post_ent_max": 53.97265625, "report/post_ent_mean": 38.94699478149414, "report/post_ent_min": 20.710538864135742, "report/post_ent_std": 6.4806294441223145, "report/prior_ent_mag": 64.16627502441406, "report/prior_ent_max": 64.16627502441406, "report/prior_ent_mean": 52.01958084106445, "report/prior_ent_min": 29.407451629638672, "report/prior_ent_std": 5.376709461212158, "report/rep_loss_mean": 12.556602478027344, "report/rep_loss_std": 8.206404685974121, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.051424697041511536, "report/reward_loss_std": 0.2303514927625656, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0040338039398193, "report/reward_neg_acc": 0.9929929971694946, "report/reward_neg_loss": 0.029518133029341698, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.9268110394477844, "report/reward_pred": 0.018636275082826614, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.4683606423204765e-05, "eval/cont_loss_std": 0.00027954185497947037, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00038915639743208885, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3583292457042262e-05, "eval/cont_pred": 0.9970579147338867, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.067636489868164, "eval/dyn_loss_std": 10.011214256286621, "eval/image_loss_mean": 26.68045425415039, "eval/image_loss_std": 40.53845977783203, "eval/model_loss_mean": 37.58427810668945, "eval/model_loss_std": 43.36890411376953, "eval/post_ent_mag": 52.462852478027344, "eval/post_ent_max": 52.462852478027344, "eval/post_ent_mean": 37.58669662475586, "eval/post_ent_min": 21.18939971923828, "eval/post_ent_std": 5.8027119636535645, "eval/prior_ent_mag": 64.16627502441406, "eval/prior_ent_max": 64.16627502441406, "eval/prior_ent_mean": 52.48807144165039, "eval/prior_ent_min": 30.3646240234375, "eval/prior_ent_std": 5.910971164703369, "eval/rep_loss_mean": 18.067636489868164, "eval/rep_loss_std": 10.011214256286621, "eval/reward_avg": 0.00917968712747097, "eval/reward_loss_mean": 0.06322940438985825, "eval/reward_loss_std": 0.42625993490219116, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002234935760498, "eval/reward_neg_acc": 0.9920713901519775, "eval/reward_neg_loss": 0.038887351751327515, "eval/reward_pos_acc": 0.8666667342185974, "eval/reward_pos_loss": 1.7006384134292603, "eval/reward_pred": 0.006583093199878931, "eval/reward_rate": 0.0146484375, "replay/size": 238001.0, "replay/inserts": 22032.0, "replay/samples": 22032.0, "replay/insert_wait_avg": 1.2770955252664715e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.901414788106948e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47328.0, "eval_replay/inserts": 3968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1816981338685558e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2518222332001, "timer/env.step_count": 2754.0, "timer/env.step_total": 259.442734003067, "timer/env.step_frac": 0.25937741700267575, "timer/env.step_avg": 0.09420578576727197, "timer/env.step_min": 0.02264237403869629, "timer/env.step_max": 3.549654722213745, "timer/replay._sample_count": 22032.0, "timer/replay._sample_total": 11.457578420639038, "timer/replay._sample_frac": 0.011454693874047052, "timer/replay._sample_avg": 0.0005200425935293681, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.021372079849243164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3250.0, "timer/agent.policy_total": 52.60735321044922, "timer/agent.policy_frac": 0.052594108844506826, "timer/agent.policy_avg": 0.016186877910907452, "timer/agent.policy_min": 0.009375572204589844, "timer/agent.policy_max": 0.08804535865783691, "timer/dataset_train_count": 1377.0, "timer/dataset_train_total": 0.1476452350616455, "timer/dataset_train_frac": 0.00014760806406931322, "timer/dataset_train_avg": 0.00010722239292784713, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0007274150848388672, "timer/agent.train_count": 1377.0, "timer/agent.train_total": 616.3725941181183, "timer/agent.train_frac": 0.6162174168720648, "timer/agent.train_avg": 0.4476198940581832, "timer/agent.train_min": 0.4348721504211426, "timer/agent.train_max": 1.5015418529510498, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46578383445739746, "timer/agent.report_frac": 0.0004656665692619993, "timer/agent.report_avg": 0.23289191722869873, "timer/agent.report_min": 0.22196745872497559, "timer/agent.report_max": 0.24381637573242188, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8364668059031334e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 22.02616577350611}
{"step": 238792, "time": 11327.97514796257, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 238864, "time": 11332.211334228516, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 238936, "time": 11335.840023994446, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 239208, "time": 11346.534534454346, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 239392, "time": 11354.45493888855, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 239448, "time": 11358.063688993454, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 239664, "time": 11367.248536109924, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 239672, "time": 11368.892235279083, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11399.904906272888, "eval_episode/length": 92.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.989247311827957}
{"step": 240032, "time": 11401.946346521378, "eval_episode/length": 98.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9494949494949495}
{"step": 240032, "time": 11408.944075107574, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 240032, "time": 11411.469362974167, "eval_episode/length": 208.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 240032, "time": 11414.271111011505, "eval_episode/length": 237.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9831932773109243}
{"step": 240032, "time": 11416.22418665886, "eval_episode/length": 247.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 240032, "time": 11418.355707883835, "eval_episode/length": 259.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 240032, "time": 11420.721107006073, "eval_episode/length": 186.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 240128, "time": 11423.922610998154, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 240248, "time": 11429.248528242111, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 240320, "time": 11433.786301851273, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 240584, "time": 11443.782661437988, "episode/length": 56.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 240704, "time": 11449.453651189804, "episode/length": 47.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 240768, "time": 11453.205177307129, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 241104, "time": 11466.047135829926, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 241128, "time": 11468.088271856308, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 241152, "time": 11470.642637252808, "episode/length": 55.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 241424, "time": 11481.270094394684, "episode/length": 219.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 241512, "time": 11485.596933841705, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 241808, "time": 11497.489506959915, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 242040, "time": 11506.533312797546, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 242224, "time": 11514.524204969406, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 242544, "time": 11526.85758137703, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 242544, "time": 11526.876008272171, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 242696, "time": 11535.08562207222, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 242744, "time": 11538.335039138794, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 242776, "time": 11540.946356534958, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 242952, "time": 11548.82243180275, "episode/length": 50.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 243024, "time": 11553.166693687439, "episode/length": 40.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 243504, "time": 11570.648906946182, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 243712, "time": 11579.175687074661, "episode/length": 185.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 243720, "time": 11580.730447769165, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 243984, "time": 11591.370587587357, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 244160, "time": 11598.688614368439, "episode/length": 54.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 244192, "time": 11601.28584909439, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 244224, "time": 11603.850378990173, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 244280, "time": 11607.059906721115, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 244368, "time": 11611.840394496918, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 245264, "time": 11643.15225982666, "episode/length": 219.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 245552, "time": 11654.342821121216, "episode/length": 195.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 245592, "time": 11657.072152614594, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 245664, "time": 11661.163281917572, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 245744, "time": 11665.474905014038, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 245840, "time": 11671.547704219818, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 246248, "time": 11686.541063785553, "episode/length": 256.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 246880, "time": 11709.54856300354, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 246904, "time": 11711.74464225769, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 246920, "time": 11713.801291704178, "episode/length": 318.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 246976, "time": 11717.510214805603, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 247144, "time": 11724.431757688522, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 247160, "time": 11726.486148357391, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 247192, "time": 11729.179632663727, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 247848, "time": 11752.56845164299, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 248008, "time": 11759.642262458801, "episode/length": 140.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 248352, "time": 11773.017159938812, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 248648, "time": 11784.317691087723, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 248664, "time": 11786.422032117844, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 248704, "time": 11789.609557151794, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 248712, "time": 11791.185597658157, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 248872, "time": 11798.221901416779, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 249192, "time": 11810.42265701294, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 249464, "time": 11821.030202627182, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 249584, "time": 11826.967640161514, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 249760, "time": 11834.446117162704, "episode/length": 131.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11863.919383049011, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 250016, "time": 11865.663823366165, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 250016, "time": 11867.650964975357, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 250016, "time": 11869.675662994385, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 250016, "time": 11871.72089791298, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 250016, "time": 11873.451696872711, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9578947368421052}
{"step": 250016, "time": 11876.109604120255, "eval_episode/length": 213.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 250016, "time": 11879.466123104095, "eval_episode/length": 257.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9806201550387597}
{"step": 250128, "time": 11883.324836730957, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 250144, "time": 11885.46558713913, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 250544, "time": 11900.665452003479, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 250584, "time": 11903.358911514282, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 251080, "time": 11921.33167886734, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 251112, "time": 11923.968764781952, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 251200, "time": 11928.736981153488, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 251456, "time": 11938.733597755432, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 251512, "time": 11942.01244187355, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 251672, "time": 11949.03426361084, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 251744, "time": 11953.290248155594, "episode/length": 144.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 251952, "time": 11961.785821199417, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 252544, "time": 11983.085002660751, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 252840, "time": 11994.363095998764, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 252896, "time": 11998.102500915527, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 252936, "time": 12000.922817707062, "episode/length": 231.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 252984, "time": 12004.229285955429, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 253088, "time": 12009.44347858429, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 253504, "time": 12024.837699890137, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 253520, "time": 12026.852799415588, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 253816, "time": 12038.238015174866, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 254304, "time": 12057.59886097908, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 254624, "time": 12069.889600038528, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 254648, "time": 12072.002571821213, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 254696, "time": 12075.223224639893, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 254736, "time": 12078.353088378906, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 254880, "time": 12084.719192743301, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 255440, "time": 12105.099593162537, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 255568, "time": 12110.97165298462, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 255696, "time": 12116.921114683151, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 255864, "time": 12124.014069318771, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 256200, "time": 12136.798887491226, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 256248, "time": 12139.941043138504, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 256600, "time": 12153.233951330185, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 256736, "time": 12159.539817810059, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 256832, "time": 12164.496569395065, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 256968, "time": 12170.411212205887, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 257072, "time": 12175.80559849739, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 257080, "time": 12177.425962209702, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 258048, "time": 12212.52031159401, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 258064, "time": 12214.627535104752, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 258304, "time": 12224.40508723259, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 258344, "time": 12227.6263859272, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 258632, "time": 12239.34150147438, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 258656, "time": 12242.033043146133, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 259224, "time": 12262.282219171524, "episode/length": 109.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 259544, "time": 12274.575050354004, "episode/length": 184.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 259552, "time": 12276.70997595787, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 259784, "time": 12285.77879190445, "episode/length": 368.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.989159891598916, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12314.431562423706, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 260000, "time": 12316.484582901001, "eval_episode/length": 178.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9888268156424581}
{"step": 260000, "time": 12318.187153339386, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 260000, "time": 12320.624692201614, "eval_episode/length": 201.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 260000, "time": 12323.153400421143, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 260000, "time": 12325.341016054153, "eval_episode/length": 217.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 260000, "time": 12327.516386270523, "eval_episode/length": 220.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9909502262443439}
{"step": 260000, "time": 12331.529046297073, "eval_episode/length": 266.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9812734082397003}
{"step": 260001, "time": 12332.131026506424, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.840329753818797, "train/action_min": 0.0, "train/action_std": 2.7915578778110333, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0469949650091689, "train/actor_opt_grad_steps": 15485.0, "train/actor_opt_loss": -3.7282221839943928, "train/adv_mag": 0.7165289885962187, "train/adv_max": 0.7031112620190009, "train/adv_mean": 0.0040535245595913405, "train/adv_min": -0.4803975793852735, "train/adv_std": 0.07691720219801611, "train/cont_avg": 0.994315531716418, "train/cont_loss_mean": 0.00025333325556908646, "train/cont_loss_std": 0.007136235249658763, "train/cont_neg_acc": 0.9944086395092865, "train/cont_neg_loss": 0.02278615449961138, "train/cont_pos_acc": 0.9999706318129354, "train/cont_pos_loss": 0.0001259541517856548, "train/cont_pred": 0.9943105213677705, "train/cont_rate": 0.994315531716418, "train/dyn_loss_mean": 14.695574304950771, "train/dyn_loss_std": 9.206967958763464, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0061661525448757, "train/extr_critic_critic_opt_grad_steps": 15485.0, "train/extr_critic_critic_opt_loss": 16147.115868411847, "train/extr_critic_mag": 3.9645583060250353, "train/extr_critic_max": 3.9645583060250353, "train/extr_critic_mean": 0.8160523218450262, "train/extr_critic_min": -0.3168168770733164, "train/extr_critic_std": 1.052847606032642, "train/extr_return_normed_mag": 1.7444122700548883, "train/extr_return_normed_max": 1.7444122700548883, "train/extr_return_normed_mean": 0.30821038849318205, "train/extr_return_normed_min": -0.14043509337439467, "train/extr_return_normed_std": 0.3431620706817997, "train/extr_return_rate": 0.40161936529981557, "train/extr_return_raw_mag": 5.387620538028319, "train/extr_return_raw_max": 5.387620538028319, "train/extr_return_raw_mean": 0.8288850241632604, "train/extr_return_raw_min": -0.5945458178644749, "train/extr_return_raw_std": 1.0892233225836683, "train/extr_reward_mag": 1.0109209498362755, "train/extr_reward_max": 1.0109209498362755, "train/extr_reward_mean": 0.020730797437700763, "train/extr_reward_min": -0.3321552543497797, "train/extr_reward_std": 0.13291785910503187, "train/image_loss_mean": 10.406233477948318, "train/image_loss_std": 14.208218816500992, "train/model_loss_mean": 19.275960822603597, "train/model_loss_std": 18.070490253505422, "train/model_opt_grad_norm": 77.11647802324437, "train/model_opt_grad_steps": 15467.380597014926, "train/model_opt_loss": 12153.502521571829, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 629.6641791044776, "train/policy_entropy_mag": 2.4644994878057225, "train/policy_entropy_max": 2.4644994878057225, "train/policy_entropy_mean": 0.5857367838051781, "train/policy_entropy_min": 0.07937533297200701, "train/policy_entropy_std": 0.5526379237868893, "train/policy_logprob_mag": 7.438380433552301, "train/policy_logprob_max": -0.009455892354694765, "train/policy_logprob_mean": -0.5865977784590934, "train/policy_logprob_min": -7.438380433552301, "train/policy_logprob_std": 1.1107935291617663, "train/policy_randomness_mag": 0.8698601651547561, "train/policy_randomness_max": 0.8698601651547561, "train/policy_randomness_mean": 0.20673937906525028, "train/policy_randomness_min": 0.02801600935410208, "train/policy_randomness_std": 0.19505693429886406, "train/post_ent_mag": 54.28548254895566, "train/post_ent_max": 54.28548254895566, "train/post_ent_mean": 37.79838727125481, "train/post_ent_min": 20.632972873858552, "train/post_ent_std": 6.467683720944533, "train/prior_ent_mag": 63.77686842163997, "train/prior_ent_max": 63.77686842163997, "train/prior_ent_mean": 52.67569248711885, "train/prior_ent_min": 32.95734701583635, "train/prior_ent_std": 5.3502811887371005, "train/rep_loss_mean": 14.695574304950771, "train/rep_loss_std": 9.206967958763464, "train/reward_avg": 0.019957585142119164, "train/reward_loss_mean": 0.052129475163546074, "train/reward_loss_std": 0.25367871683035326, "train/reward_max_data": 1.0097014948503296, "train/reward_max_pred": 1.00501729570218, "train/reward_neg_acc": 0.9934130351045238, "train/reward_neg_loss": 0.030153379580979026, "train/reward_pos_acc": 0.9564413766362774, "train/reward_pos_loss": 0.9152794249022185, "train/reward_pred": 0.01921296641300085, "train/reward_rate": 0.024836753731343284, "train_stats/sum_log_reward": 5.029203495620626, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.566371681415929, "train_stats/max_log_achievement_collect_sapling": 2.566371681415929, "train_stats/max_log_achievement_collect_stone": 0.008849557522123894, "train_stats/max_log_achievement_collect_wood": 5.699115044247788, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.2831858407079646, "train_stats/max_log_achievement_eat_cow": 0.05309734513274336, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05309734513274336, "train_stats/max_log_achievement_make_wood_sword": 0.008849557522123894, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.4867256637168142, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.415929203539823, "train_stats/max_log_achievement_wake_up": 1.424778761061947, "train_stats/mean_log_entropy": 0.5651818339803577, "eval_stats/sum_log_reward": 5.224999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.875, "eval_stats/max_log_achievement_collect_sapling": 2.9166666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4583333333333333, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.8333333333333335, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.9216304281144403e-06, "report/cont_loss_std": 2.521281385270413e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00022601932869292796, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0428157111164182e-06, "report/cont_pred": 0.9960936903953552, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.10957145690918, "report/dyn_loss_std": 9.866536140441895, "report/image_loss_mean": 10.69694709777832, "report/image_loss_std": 15.59438419342041, "report/model_loss_mean": 19.811092376708984, "report/model_loss_std": 19.751426696777344, "report/post_ent_mag": 52.91319274902344, "report/post_ent_max": 52.91319274902344, "report/post_ent_mean": 36.8719482421875, "report/post_ent_min": 20.436626434326172, "report/post_ent_std": 6.128194808959961, "report/prior_ent_mag": 63.0663948059082, "report/prior_ent_max": 63.0663948059082, "report/prior_ent_mean": 52.336814880371094, "report/prior_ent_min": 32.88862991333008, "report/prior_ent_std": 5.584038734436035, "report/rep_loss_mean": 15.10957145690918, "report/rep_loss_std": 9.866536140441895, "report/reward_avg": 0.02822265401482582, "report/reward_loss_mean": 0.048401542007923126, "report/reward_loss_std": 0.21016767621040344, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0027616024017334, "report/reward_neg_acc": 0.9939515590667725, "report/reward_neg_loss": 0.025874774903059006, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7467312216758728, "report/reward_pred": 0.028941210359334946, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.7267238692729734e-05, "eval/cont_loss_std": 0.0008472612244077027, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.2456245864741504e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.7207672246731818e-05, "eval/cont_pred": 0.9960672855377197, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 14.84831714630127, "eval/dyn_loss_std": 8.695170402526855, "eval/image_loss_mean": 9.731769561767578, "eval/image_loss_std": 9.61340618133545, "eval/model_loss_mean": 18.703414916992188, "eval/model_loss_std": 13.19322395324707, "eval/post_ent_mag": 52.92979431152344, "eval/post_ent_max": 52.92979431152344, "eval/post_ent_mean": 39.715553283691406, "eval/post_ent_min": 20.960596084594727, "eval/post_ent_std": 5.961702823638916, "eval/prior_ent_mag": 63.0663948059082, "eval/prior_ent_max": 63.0663948059082, "eval/prior_ent_mean": 52.84446716308594, "eval/prior_ent_min": 30.794178009033203, "eval/prior_ent_std": 4.868950843811035, "eval/rep_loss_mean": 14.84831714630127, "eval/rep_loss_std": 8.695170402526855, "eval/reward_avg": 0.01162109337747097, "eval/reward_loss_mean": 0.06262858957052231, "eval/reward_loss_std": 0.4592890441417694, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000992774963379, "eval/reward_neg_acc": 0.9960318207740784, "eval/reward_neg_loss": 0.03212355822324753, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 1.984445571899414, "eval/reward_pred": 0.010490015149116516, "eval/reward_rate": 0.015625, "replay/size": 259497.0, "replay/inserts": 21496.0, "replay/samples": 21488.0, "replay/insert_wait_avg": 1.28907522038984e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.807218705018953e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 53768.0, "eval_replay/inserts": 6440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1706944578182624e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1013.5259127616882, "timer/env.step_count": 2687.0, "timer/env.step_total": 252.59946537017822, "timer/env.step_frac": 0.24922842345676888, "timer/env.step_avg": 0.09400798860073623, "timer/env.step_min": 0.02279376983642578, "timer/env.step_max": 3.393935203552246, "timer/replay._sample_count": 21488.0, "timer/replay._sample_total": 11.256166219711304, "timer/replay._sample_frac": 0.01110594813411345, "timer/replay._sample_avg": 0.0005238349878867881, "timer/replay._sample_min": 0.0004208087921142578, "timer/replay._sample_max": 0.00916433334350586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3492.0, "timer/agent.policy_total": 57.86654734611511, "timer/agent.policy_frac": 0.05709429489418625, "timer/agent.policy_avg": 0.016571176215955073, "timer/agent.policy_min": 0.009426593780517578, "timer/agent.policy_max": 0.11871957778930664, "timer/dataset_train_count": 1343.0, "timer/dataset_train_total": 0.14289498329162598, "timer/dataset_train_frac": 0.0001409879920112364, "timer/dataset_train_avg": 0.00010639983863858971, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00026297569274902344, "timer/agent.train_count": 1343.0, "timer/agent.train_total": 603.0930137634277, "timer/agent.train_frac": 0.5950444938502858, "timer/agent.train_avg": 0.44906404598914945, "timer/agent.train_min": 0.43545103073120117, "timer/agent.train_max": 1.4583182334899902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5018472671508789, "timer/agent.report_frac": 0.0004951499126287055, "timer/agent.report_avg": 0.25092363357543945, "timer/agent.report_min": 0.24793457984924316, "timer/agent.report_max": 0.25391268730163574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.487701416015625e-05, "timer/dataset_eval_frac": 8.37442961165942e-08, "timer/dataset_eval_avg": 8.487701416015625e-05, "timer/dataset_eval_min": 8.487701416015625e-05, "timer/dataset_eval_max": 8.487701416015625e-05, "fps": 21.20885513502596}
{"step": 260128, "time": 12336.622807741165, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 260320, "time": 12344.592389345169, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 260784, "time": 12361.468513965607, "episode/length": 265.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 260832, "time": 12364.826940059662, "episode/length": 87.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 260960, "time": 12370.730933189392, "episode/length": 485.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 261264, "time": 12382.422007799149, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 261384, "time": 12387.811667203903, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 261512, "time": 12393.752293348312, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 261592, "time": 12398.027905225754, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 261912, "time": 12410.215345621109, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
