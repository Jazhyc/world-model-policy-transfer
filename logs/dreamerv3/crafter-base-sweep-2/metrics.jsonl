{"step": 1128, "time": 192.7803704738617, "episode/length": 140.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 1240, "time": 194.62007594108582, "episode/length": 154.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1328, "time": 196.24740982055664, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 1392, "time": 197.7734990119934, "episode/length": 173.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 1416, "time": 199.48519921302795, "episode/length": 176.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1488, "time": 201.1561484336853, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 217.74633383750916, "eval_episode/length": 163.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 1560, "time": 219.24784231185913, "eval_episode/length": 166.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 1560, "time": 220.68059945106506, "eval_episode/length": 168.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1560, "time": 222.30358743667603, "eval_episode/length": 173.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 1560, "time": 224.2686767578125, "train_stats/sum_log_reward": 1.0999999741713207, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_drink": 0.25, "train_stats/max_log_achievement_collect_sapling": 0.75, "train_stats/max_log_achievement_collect_wood": 0.25, "train_stats/max_log_achievement_place_plant": 0.5, "eval_stats/sum_log_reward": 0.5999999940395355, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_wake_up": 2.25}
{"step": 1560, "time": 259.65518450737, "eval_episode/length": 131.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 1560, "time": 261.9672021865845, "eval_episode/length": 148.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 1560, "time": 263.68388509750366, "eval_episode/length": 150.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 1560, "time": 265.94484066963196, "eval_episode/length": 162.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 1560, "time": 267.84341263771057, "eval_episode/length": 165.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 1560, "time": 270.3542399406433, "eval_episode/length": 183.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 1560, "time": 272.5712285041809, "eval_episode/length": 191.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 1560, "time": 275.53136372566223, "eval_episode/length": 216.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 1561, "time": 393.32914543151855, "eval_stats/sum_log_reward": 0.9749999707564712, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_wake_up": 1.875, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.06805419921875, "train/action_min": 0.0, "train/action_std": 5.693212509155273, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007108657155185938, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -3.1780004501342773, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.998046875, "train/cont_loss_mean": 0.5841813683509827, "train/cont_loss_std": 0.2477104812860489, "train/cont_neg_acc": 0.5, "train/cont_neg_loss": 0.7573109865188599, "train/cont_pos_acc": 0.6908023357391357, "train/cont_pos_loss": 0.5838425755500793, "train/cont_pred": 0.5740800499916077, "train/cont_rate": 0.998046875, "train/dyn_loss_mean": 10.774317741394043, "train/dyn_loss_std": 0.45589250326156616, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 11.313159942626953, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 46448.64453125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3528.5625, "train/image_loss_std": 177.7279510498047, "train/model_loss_mean": 3541.15234375, "train/model_loss_std": 177.64947509765625, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 35411524.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.768897533416748, "train/policy_entropy_max": 2.768897533416748, "train/policy_entropy_mean": 2.537083625793457, "train/policy_entropy_min": 1.6439213752746582, "train/policy_entropy_std": 0.10620550066232681, "train/policy_logprob_mag": 6.265646457672119, "train/policy_logprob_max": -0.47494953870773315, "train/policy_logprob_mean": -2.529843807220459, "train/policy_logprob_min": -6.265646457672119, "train/policy_logprob_std": 0.7315954566001892, "train/policy_randomness_mag": 0.9772993326187134, "train/policy_randomness_max": 0.9772993326187134, "train/policy_randomness_mean": 0.8954792022705078, "train/policy_randomness_min": 0.5802320837974548, "train/policy_randomness_std": 0.03748588263988495, "train/post_ent_mag": 106.0154800415039, "train/post_ent_max": 106.0154800415039, "train/post_ent_mean": 105.54624938964844, "train/post_ent_min": 105.11090850830078, "train/post_ent_std": 0.14887100458145142, "train/prior_ent_mag": 106.59129333496094, "train/prior_ent_max": 106.59129333496094, "train/prior_ent_mean": 105.59617614746094, "train/prior_ent_min": 104.11250305175781, "train/prior_ent_std": 0.3258930742740631, "train/rep_loss_mean": 10.774317741394043, "train/rep_loss_std": 0.45589250326156616, "train/reward_avg": 0.01191406324505806, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.548376738166553e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541264057159424, "train/reward_pred": 0.0, "train/reward_rate": 0.013671875, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.6006811857223511, "report/cont_loss_std": 0.2521279454231262, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 0.943474531173706, "report/cont_pos_acc": 0.6868884563446045, "report/cont_pos_loss": 0.6000103950500488, "report/cont_pred": 0.5654027462005615, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 10.722689628601074, "report/dyn_loss_std": 0.41585007309913635, "report/image_loss_mean": 3525.31884765625, "report/image_loss_std": 178.06460571289062, "report/model_loss_mean": 3537.89453125, "report/model_loss_std": 178.01727294921875, "report/post_ent_mag": 106.00352478027344, "report/post_ent_max": 106.00352478027344, "report/post_ent_mean": 105.54649353027344, "report/post_ent_min": 104.90154266357422, "report/post_ent_std": 0.16141116619110107, "report/prior_ent_mag": 106.49794006347656, "report/prior_ent_max": 106.49794006347656, "report/prior_ent_mean": 105.61085510253906, "report/prior_ent_min": 104.61116027832031, "report/prior_ent_std": 0.311397522687912, "report/rep_loss_mean": 10.722689628601074, "report/rep_loss_std": 0.41585007309913635, "report/reward_avg": 0.01191406324505806, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.548376738166553e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541264057159424, "report/reward_pred": 0.0, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.6145856380462646, "eval/cont_loss_std": 0.2708778977394104, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.7943751215934753, "eval/cont_pos_acc": 0.6771036982536316, "eval/cont_pos_loss": 0.6142338514328003, "eval/cont_pred": 0.5596487522125244, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.717730522155762, "eval/dyn_loss_std": 0.4131840169429779, "eval/image_loss_mean": 3575.6669921875, "eval/image_loss_std": 179.58287048339844, "eval/model_loss_mean": 3588.25341796875, "eval/model_loss_std": 179.53919982910156, "eval/post_ent_mag": 105.94672393798828, "eval/post_ent_max": 105.94672393798828, "eval/post_ent_mean": 105.57487487792969, "eval/post_ent_min": 105.09977722167969, "eval/post_ent_std": 0.13635790348052979, "eval/prior_ent_mag": 106.50846862792969, "eval/prior_ent_max": 106.50846862792969, "eval/prior_ent_mean": 105.61559295654297, "eval/prior_ent_min": 104.60285949707031, "eval/prior_ent_std": 0.3173848092556, "eval/rep_loss_mean": 10.717730522155762, "eval/rep_loss_std": 0.4131840169429779, "eval/reward_avg": 0.013671875, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541263103485107, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.015625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5308863730958416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.258994238717216e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2792.0, "eval_replay/inserts": 2792.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 2.5429322589775893e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 215.17890572547913, "timer/env.step_count": 196.0, "timer/env.step_total": 24.419125080108643, "timer/env.step_frac": 0.11348289460706741, "timer/env.step_avg": 0.12458737285769715, "timer/env.step_min": 0.021001577377319336, "timer/env.step_max": 11.204735040664673, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.1041407585144043, "timer/replay._sample_frac": 0.0004839728976373965, "timer/replay._sample_avg": 0.0009298282010214669, "timer/replay._sample_min": 0.0003342628479003906, "timer/replay._sample_max": 0.009914636611938477, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.697157621383667, "timer/agent.save_frac": 0.04041826308234565, "timer/agent.save_avg": 8.697157621383667, "timer/agent.save_min": 8.697157621383667, "timer/agent.save_max": 8.697157621383667, "timer/agent.policy_count": 218.0, "timer/agent.policy_total": 19.056139707565308, "timer/agent.policy_frac": 0.08855951582854847, "timer/agent.policy_avg": 0.08741348489708857, "timer/agent.policy_min": 0.010055780410766602, "timer/agent.policy_max": 13.075534343719482, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.886222839355469e-05, "timer/dataset_train_frac": 1.8060426630821483e-07, "timer/dataset_train_avg": 3.886222839355469e-05, "timer/dataset_train_min": 3.886222839355469e-05, "timer/dataset_train_max": 3.886222839355469e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.31295156478882, "timer/agent.train_frac": 0.4243582857572667, "timer/agent.train_avg": 91.31295156478882, "timer/agent.train_min": 91.31295156478882, "timer/agent.train_max": 91.31295156478882, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.216801404953003, "timer/agent.report_frac": 0.11254263666461947, "timer/agent.report_avg": 12.108400702476501, "timer/agent.report_min": 0.24506711959838867, "timer/agent.report_max": 23.971734285354614, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.555152893066406e-05, "timer/dataset_eval_frac": 2.581643806737059e-07, "timer/dataset_eval_avg": 5.555152893066406e-05, "timer/dataset_eval_min": 5.555152893066406e-05, "timer/dataset_eval_max": 5.555152893066406e-05}
{"step": 1576, "time": 393.4106345176697, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 1640, "time": 397.548787355423, "episode/length": 204.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 2488, "time": 427.84634160995483, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 2608, "time": 433.8459393978119, "episode/length": 159.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 2664, "time": 437.0398225784302, "episode/length": 135.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 2800, "time": 443.82696056365967, "episode/length": 208.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 2920, "time": 449.3228805065155, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 2984, "time": 453.0762321949005, "episode/length": 61.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 3200, "time": 462.246289730072, "episode/length": 222.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 3240, "time": 464.9161648750305, "episode/length": 218.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 3336, "time": 469.876047372818, "episode/length": 211.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 3640, "time": 481.6596693992615, "episode/length": 49.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 3904, "time": 492.31014370918274, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 3984, "time": 496.5818088054657, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 4024, "time": 499.4333233833313, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 4152, "time": 505.31557178497314, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 4712, "time": 525.723387002945, "episode/length": 188.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 4752, "time": 528.9535851478577, "episode/length": 138.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 4808, "time": 532.2459154129028, "episode/length": 227.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 5072, "time": 542.8140766620636, "episode/length": 135.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 5136, "time": 546.4752728939056, "episode/length": 153.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 5224, "time": 550.8108053207397, "episode/length": 235.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 5240, "time": 552.9443514347076, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 5240, "time": 552.9529564380646, "episode/length": 151.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 5760, "time": 574.062016248703, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 6224, "time": 591.3846361637115, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 6336, "time": 596.7189502716064, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 6376, "time": 599.4240064620972, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 6544, "time": 606.890941619873, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 6712, "time": 613.9845042228699, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 6728, "time": 616.1365735530853, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 6952, "time": 625.407407283783, "episode/length": 213.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 7016, "time": 629.2259531021118, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 7400, "time": 643.811970949173, "episode/length": 55.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 7576, "time": 651.4352204799652, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 7672, "time": 656.2970111370087, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 7776, "time": 661.7232248783112, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 8000, "time": 671.0616772174835, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 8168, "time": 678.687490940094, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 8248, "time": 684.2055468559265, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 8416, "time": 691.8899137973785, "episode/length": 79.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 8592, "time": 699.3264961242676, "episode/length": 232.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 8664, "time": 703.075799703598, "episode/length": 123.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 8992, "time": 716.0324287414551, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 9144, "time": 722.585333108902, "episode/length": 217.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 9224, "time": 726.899411201477, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 9384, "time": 733.8936724662781, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 9608, "time": 743.1138882637024, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 9656, "time": 746.3044722080231, "episode/length": 175.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 10016, "time": 760.3901543617249, "episode/length": 177.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 779.3240320682526, "eval_episode/length": 42.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8837209302325582}
{"step": 10088, "time": 785.7291378974915, "eval_episode/length": 150.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 10088, "time": 788.0800745487213, "eval_episode/length": 156.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 10088, "time": 790.4684941768646, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 10088, "time": 792.725284576416, "eval_episode/length": 164.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 10088, "time": 795.2871615886688, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 10088, "time": 798.0452904701233, "eval_episode/length": 186.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 10088, "time": 799.9770181179047, "eval_episode/length": 189.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 10592, "time": 817.4068582057953, "episode/length": 199.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 10600, "time": 819.1163189411163, "episode/length": 241.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 10640, "time": 822.3318116664886, "episode/length": 77.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 10720, "time": 826.7123880386353, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 10752, "time": 829.5841038227081, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 10840, "time": 834.0517611503601, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 10856, "time": 836.268835067749, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 11144, "time": 847.9012615680695, "episode/length": 239.0, "episode/score": 2.0999999567866325, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 11920, "time": 876.1197552680969, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 11960, "time": 878.8509986400604, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 12080, "time": 884.8111510276794, "episode/length": 169.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 12080, "time": 884.8202583789825, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 12112, "time": 889.5678517818451, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 12376, "time": 899.9059629440308, "episode/length": 216.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 12464, "time": 904.8023624420166, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 12640, "time": 912.2748098373413, "episode/length": 224.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 13320, "time": 936.5951557159424, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 13384, "time": 940.4763395786285, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 13432, "time": 943.6632087230682, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 13552, "time": 949.5604662895203, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 13632, "time": 953.910181760788, "episode/length": 38.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 13920, "time": 965.4888150691986, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 14016, "time": 970.4567589759827, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 14048, "time": 973.1626017093658, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 14632, "time": 994.290899515152, "episode/length": 88.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 14760, "time": 1000.2028760910034, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 14792, "time": 1002.8819446563721, "episode/length": 338.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 14896, "time": 1008.2381775379181, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 14896, "time": 1008.2472813129425, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 15040, "time": 1016.5401623249054, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 15392, "time": 1030.157765865326, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 15520, "time": 1036.5401480197906, "episode/length": 183.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 15872, "time": 1049.9884147644043, "episode/length": 103.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 16080, "time": 1058.574340581894, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 16296, "time": 1067.2759175300598, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 16352, "time": 1071.1540880203247, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 16424, "time": 1076.1161646842957, "episode/length": 223.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 17216, "time": 1104.6002213954926, "episode/length": 211.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 17328, "time": 1109.9107875823975, "episode/length": 316.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9936908517350158, "episode/intrinsic_return": 0.0}
{"step": 17440, "time": 1115.4203610420227, "episode/length": 255.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 17480, "time": 1118.145994901657, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 17560, "time": 1122.4122722148895, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 17584, "time": 1124.98956990242, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 17696, "time": 1130.3080124855042, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 17920, "time": 1139.3391287326813, "episode/length": 186.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 18200, "time": 1150.040863752365, "episode/length": 79.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 18720, "time": 1169.4936699867249, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 18824, "time": 1174.481882572174, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 19024, "time": 1183.0921306610107, "episode/length": 179.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 19040, "time": 1185.526563167572, "episode/length": 167.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 19080, "time": 1188.8342385292053, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 19200, "time": 1195.1860439777374, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 19384, "time": 1202.7615168094635, "episode/length": 242.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 20016, "time": 1225.9303193092346, "episode/length": 226.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1251.1805255413055, "eval_episode/length": 122.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.967479674796748}
{"step": 20072, "time": 1254.1769762039185, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 20072, "time": 1256.6569151878357, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.96875}
{"step": 20072, "time": 1258.811716556549, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 20072, "time": 1260.9296519756317, "eval_episode/length": 164.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 20072, "time": 1263.8734865188599, "eval_episode/length": 181.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 20072, "time": 1265.6360704898834, "eval_episode/length": 185.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 20072, "time": 1271.3404853343964, "eval_episode/length": 116.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9572649572649573}
{"step": 20224, "time": 1276.6295771598816, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 20296, "time": 1280.4682042598724, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 20352, "time": 1284.2465364933014, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 20712, "time": 1297.8308837413788, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 20752, "time": 1301.0004713535309, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 20816, "time": 1304.84526181221, "episode/length": 221.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 20888, "time": 1308.759785413742, "episode/length": 66.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9402985074626866, "episode/intrinsic_return": 0.0}
{"step": 20912, "time": 1311.3190703392029, "episode/length": 111.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 21224, "time": 1323.1461403369904, "episode/length": 252.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 21560, "time": 1337.1223423480988, "episode/length": 166.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 21648, "time": 1341.9964408874512, "episode/length": 52.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 21832, "time": 1349.5507197380066, "episode/length": 33.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 22168, "time": 1362.4716811180115, "episode/length": 233.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 22248, "time": 1366.7655897140503, "episode/length": 186.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 22257, "time": 1369.640981912613, "train_stats/sum_log_reward": 0.9559321705946477, "train_stats/max_log_achievement_collect_drink": 7.8474576271186445, "train_stats/max_log_achievement_collect_sapling": 7.398305084745763, "train_stats/max_log_achievement_collect_wood": 0.576271186440678, "train_stats/max_log_achievement_place_plant": 0.15254237288135594, "train_stats/max_log_achievement_wake_up": 0.5932203389830508, "train_stats/mean_log_entropy": 0.9552363426250926, "train_stats/max_log_achievement_place_table": 0.05128205128205128, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.761924566224564, "train/action_min": 0.0, "train/action_std": 2.0453802319460137, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026649512180448472, "train/actor_opt_grad_steps": 650.0, "train/actor_opt_loss": 158.9892777573577, "train/adv_mag": 2.021586311560543, "train/adv_max": 2.0125170318001895, "train/adv_mean": 0.032303826908590884, "train/adv_min": -0.3811170880235154, "train/adv_std": 0.15068231735201626, "train/cont_avg": 0.994625121124031, "train/cont_loss_mean": 0.026581952189521273, "train/cont_loss_std": 0.24434234525344167, "train/cont_neg_acc": 0.06474580679290978, "train/cont_neg_loss": 3.1935781129570895, "train/cont_pos_acc": 0.9975448518760445, "train/cont_pos_loss": 0.009857436234597117, "train/cont_pred": 0.9910451982372491, "train/cont_rate": 0.994625121124031, "train/dyn_loss_mean": 5.731312016184016, "train/dyn_loss_std": 7.430433021165257, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.638923553533332, "train/extr_critic_critic_opt_grad_steps": 650.0, "train/extr_critic_critic_opt_loss": 22496.064082182656, "train/extr_critic_mag": 0.3057177695193032, "train/extr_critic_max": 0.30571776859520017, "train/extr_critic_mean": 0.10307185756529465, "train/extr_critic_min": -0.05597372757372006, "train/extr_critic_std": 0.10797522414030403, "train/extr_return_normed_mag": 2.3441077910486405, "train/extr_return_normed_max": 2.3439795916806183, "train/extr_return_normed_mean": 0.23048310658836724, "train/extr_return_normed_min": -0.2657621295048987, "train/extr_return_normed_std": 0.21319766518075106, "train/extr_return_rate": 0.08101280332957403, "train/extr_return_raw_mag": 2.362491128213574, "train/extr_return_raw_max": 2.36058979468283, "train/extr_return_raw_mean": 0.13695488446807244, "train/extr_return_raw_min": -0.39189284631996885, "train/extr_return_raw_std": 0.22849990767535083, "train/extr_reward_mag": 0.6310274065002914, "train/extr_reward_max": 0.6309622406035431, "train/extr_reward_mean": 0.00738729251231213, "train/extr_reward_min": -0.09282447016516397, "train/extr_reward_std": 0.04038406825842572, "train/image_loss_mean": 98.70827847857808, "train/image_loss_std": 52.02510276321293, "train/model_loss_mean": 102.48212265783502, "train/model_loss_std": 53.506174752878586, "train/model_opt_grad_norm": 421.23560321423435, "train/model_opt_grad_steps": 641.0, "train/model_opt_loss": 2178.9935061432593, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 23.921996124031008, "train/policy_entropy_mag": 1.585478351444237, "train/policy_entropy_max": 1.585478351444237, "train/policy_entropy_mean": 0.8857724235732426, "train/policy_entropy_min": 0.69899688782387, "train/policy_entropy_std": 0.1531895892586299, "train/policy_logprob_mag": 6.9302225445592125, "train/policy_logprob_max": -0.32873323026235945, "train/policy_logprob_mean": -0.8845985527763995, "train/policy_logprob_min": -6.9302225445592125, "train/policy_logprob_std": 0.8111378934032233, "train/policy_randomness_mag": 0.5596042801012364, "train/policy_randomness_max": 0.5596042801012364, "train/policy_randomness_mean": 0.312638799883714, "train/policy_randomness_min": 0.24671522712753724, "train/policy_randomness_std": 0.054069203012370205, "train/post_ent_mag": 51.07594736971596, "train/post_ent_max": 51.07594736971596, "train/post_ent_mean": 33.65207958960718, "train/post_ent_min": 15.992671108985132, "train/post_ent_std": 6.656038908417835, "train/prior_ent_mag": 56.9805811800698, "train/prior_ent_max": 56.9805811800698, "train/prior_ent_mean": 40.01690670870995, "train/prior_ent_min": 22.06821911834007, "train/prior_ent_std": 6.462100780345211, "train/rep_loss_mean": 5.731312016184016, "train/rep_loss_std": 7.430433021165257, "train/reward_avg": 0.007359041843668002, "train/reward_loss_mean": 0.3084782649033753, "train/reward_loss_std": 0.6314192842015286, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.7014630247456158, "train/reward_neg_acc": 0.9964962527733441, "train/reward_neg_loss": 0.2738791963504266, "train/reward_pos_acc": 0.4751082198448883, "train/reward_pos_loss": 3.066389192906461, "train/reward_pred": 0.00521115276713444, "train/reward_rate": 0.012286518895348836, "train_stats/max_log_achievement_eat_cow": 0.1282051282051282, "train_stats/max_log_achievement_defeat_zombie": 0.18571428571428572, "eval_stats/sum_log_reward": 0.2874999837949872, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_sapling": 6.0625, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00894469115883112, "report/cont_loss_std": 0.16075871884822845, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.5032192468643188, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0016126278787851334, "report/cont_pred": 0.9959550499916077, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.497642993927002, "report/dyn_loss_std": 6.471100330352783, "report/image_loss_mean": 41.497467041015625, "report/image_loss_std": 32.46864700317383, "report/model_loss_mean": 46.09991455078125, "report/model_loss_std": 34.02598190307617, "report/post_ent_mag": 43.75349044799805, "report/post_ent_max": 43.75349044799805, "report/post_ent_mean": 31.964189529418945, "report/post_ent_min": 11.503988265991211, "report/post_ent_std": 5.033616542816162, "report/prior_ent_mag": 49.3833122253418, "report/prior_ent_max": 49.3833122253418, "report/prior_ent_mean": 39.61579895019531, "report/prior_ent_min": 16.185251235961914, "report/prior_ent_std": 4.852604389190674, "report/rep_loss_mean": 7.497642993927002, "report/rep_loss_std": 6.471100330352783, "report/reward_avg": 0.006054687779396772, "report/reward_loss_mean": 0.09492199122905731, "report/reward_loss_std": 0.46485063433647156, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9819631576538086, "report/reward_neg_acc": 0.9911155700683594, "report/reward_neg_loss": 0.08513342589139938, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.9963595867156982, "report/reward_pred": 0.008317282423377037, "report/reward_rate": 0.0107421875, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.006758126430213451, "eval/cont_loss_std": 0.07693590223789215, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.994140625, "eval/cont_pos_loss": 0.006758126430213451, "eval/cont_pred": 0.9954506754875183, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 8.255352020263672, "eval/dyn_loss_std": 5.966763973236084, "eval/image_loss_mean": 36.862693786621094, "eval/image_loss_std": 22.292726516723633, "eval/model_loss_mean": 41.899810791015625, "eval/model_loss_std": 24.1728458404541, "eval/post_ent_mag": 46.883567810058594, "eval/post_ent_max": 46.883567810058594, "eval/post_ent_mean": 29.808605194091797, "eval/post_ent_min": 11.358976364135742, "eval/post_ent_std": 6.622797012329102, "eval/prior_ent_mag": 50.42091751098633, "eval/prior_ent_max": 50.42091751098633, "eval/prior_ent_mean": 36.17657470703125, "eval/prior_ent_min": 15.902609825134277, "eval/prior_ent_std": 7.19783878326416, "eval/rep_loss_mean": 8.255352020263672, "eval/rep_loss_std": 5.966763973236084, "eval/reward_avg": 0.01298828050494194, "eval/reward_loss_mean": 0.07714910805225372, "eval/reward_loss_std": 0.4330042898654938, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9774366617202759, "eval/reward_neg_acc": 0.996039628982544, "eval/reward_neg_loss": 0.04703185707330704, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 2.249894142150879, "eval/reward_pred": 0.005687848199158907, "eval/reward_rate": 0.013671875, "replay/size": 21753.0, "replay/inserts": 20696.0, "replay/samples": 20688.0, "replay/insert_wait_avg": 1.5313117532689552e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.756765909925137e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6528.0, "eval_replay/inserts": 3736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3412959570547753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.3011462688446, "timer/env.step_count": 2587.0, "timer/env.step_total": 263.0495386123657, "timer/env.step_frac": 0.2694348353657772, "timer/env.step_avg": 0.1016813059962759, "timer/env.step_min": 0.023075103759765625, "timer/env.step_max": 3.588209390640259, "timer/replay._sample_count": 20688.0, "timer/replay._sample_total": 11.207684516906738, "timer/replay._sample_frac": 0.011479741225071215, "timer/replay._sample_avg": 0.0005417480914978121, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.034445762634277344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3054.0, "timer/agent.policy_total": 53.34922409057617, "timer/agent.policy_frac": 0.05464422969742715, "timer/agent.policy_avg": 0.017468639191413286, "timer/agent.policy_min": 0.009878873825073242, "timer/agent.policy_max": 0.11369919776916504, "timer/dataset_train_count": 1293.0, "timer/dataset_train_total": 0.14921092987060547, "timer/dataset_train_frac": 0.00015283289427739458, "timer/dataset_train_avg": 0.0001153990176880166, "timer/dataset_train_min": 8.130073547363281e-05, "timer/dataset_train_max": 0.0004374980926513672, "timer/agent.train_count": 1293.0, "timer/agent.train_total": 584.8942029476166, "timer/agent.train_frac": 0.5990919965452483, "timer/agent.train_avg": 0.4523543719625805, "timer/agent.train_min": 0.43727660179138184, "timer/agent.train_max": 1.252706527709961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737668037414551, "timer/agent.report_frac": 0.00048526707722515943, "timer/agent.report_avg": 0.23688340187072754, "timer/agent.report_min": 0.22741389274597168, "timer/agent.report_max": 0.2463529109954834, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.981590270996094e-05, "timer/dataset_eval_frac": 4.078239881426587e-08, "timer/dataset_eval_avg": 3.981590270996094e-05, "timer/dataset_eval_min": 3.981590270996094e-05, "timer/dataset_eval_max": 3.981590270996094e-05, "fps": 21.198125332573305}
{"step": 22296, "time": 1371.0371134281158, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 22320, "time": 1373.7113547325134, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 22392, "time": 1377.5703706741333, "episode/length": 184.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 22432, "time": 1380.7605500221252, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 22520, "time": 1385.1142630577087, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 22744, "time": 1394.3312814235687, "episode/length": 136.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 23384, "time": 1417.6427104473114, "episode/length": 79.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 23584, "time": 1426.193054676056, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 23664, "time": 1430.616541147232, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 23696, "time": 1433.3953576087952, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 23944, "time": 1443.7479362487793, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 23960, "time": 1445.8957591056824, "episode/length": 265.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 24128, "time": 1453.3224649429321, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 24184, "time": 1456.5775113105774, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 24768, "time": 1479.421951532364, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 24976, "time": 1488.0644099712372, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 25032, "time": 1491.5029146671295, "episode/length": 170.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 25080, "time": 1494.9009664058685, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 25160, "time": 1499.217048883438, "episode/length": 128.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 25624, "time": 1516.401433467865, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 25640, "time": 1518.5000445842743, "episode/length": 242.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 25736, "time": 1523.4500496387482, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 26136, "time": 1538.5239264965057, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 26216, "time": 1542.8774211406708, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 26464, "time": 1553.038753271103, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 26504, "time": 1555.750670671463, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 26672, "time": 1563.1674926280975, "episode/length": 128.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 26920, "time": 1572.8701479434967, "episode/length": 219.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 27040, "time": 1578.7734215259552, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 27440, "time": 1593.8675858974457, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 27776, "time": 1606.8083219528198, "episode/length": 204.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 27912, "time": 1612.8934767246246, "episode/length": 154.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 28312, "time": 1627.9743535518646, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 28312, "time": 1627.983737707138, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 28424, "time": 1635.0635821819305, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 28512, "time": 1639.8515574932098, "episode/length": 250.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 28576, "time": 1643.5740773677826, "episode/length": 368.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 28688, "time": 1648.8560070991516, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 29072, "time": 1663.5463738441467, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 29192, "time": 1668.9890265464783, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 29624, "time": 1685.0805099010468, "episode/length": 53.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 29744, "time": 1690.987542629242, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 29984, "time": 1700.935596704483, "episode/length": 194.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 30024, "time": 1704.039974451065, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1727.8617584705353, "eval_episode/length": 151.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 30056, "time": 1729.959356546402, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 30056, "time": 1729.9769315719604, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 30056, "time": 1733.5734667778015, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 30056, "time": 1735.5129835605621, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 30056, "time": 1737.534740447998, "eval_episode/length": 175.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 30056, "time": 1739.528793334961, "eval_episode/length": 181.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 30056, "time": 1741.7443470954895, "eval_episode/length": 39.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 30120, "time": 1743.8817014694214, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 30208, "time": 1748.739690542221, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 30208, "time": 1748.7491948604584, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 30632, "time": 1765.9903118610382, "episode/length": 52.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.0}
{"step": 30688, "time": 1769.805981874466, "episode/length": 201.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 31080, "time": 1784.444444179535, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 31144, "time": 1788.22749376297, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 31248, "time": 1793.8114614486694, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 31336, "time": 1798.1691536903381, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 31576, "time": 1807.7872915267944, "episode/length": 53.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 31592, "time": 1809.9015431404114, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 31680, "time": 1814.5451214313507, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 31776, "time": 1819.4795162677765, "episode/length": 135.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 32312, "time": 1838.90860247612, "episode/length": 89.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 32328, "time": 1841.0401861667633, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 32336, "time": 1843.1004226207733, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 32584, "time": 1852.7635979652405, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 32656, "time": 1856.91078042984, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 32784, "time": 1864.0395500659943, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 33008, "time": 1873.1360716819763, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 33304, "time": 1884.3798451423645, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 33312, "time": 1886.368486881256, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 33600, "time": 1897.5672504901886, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 33840, "time": 1907.1533901691437, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 34408, "time": 1927.8026149272919, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 34440, "time": 1930.4361727237701, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 34480, "time": 1933.6703824996948, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 34512, "time": 1936.4006838798523, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 34880, "time": 1950.315179347992, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 34880, "time": 1950.3241925239563, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 35128, "time": 1961.7727563381195, "episode/length": 317.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 35728, "time": 1983.8482999801636, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 35736, "time": 1985.4343011379242, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 35968, "time": 1994.9915688037872, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 35984, "time": 1997.2171659469604, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 36104, "time": 2002.6648535728455, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 36320, "time": 2011.7576050758362, "episode/length": 229.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 36504, "time": 2019.3550667762756, "episode/length": 171.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 37232, "time": 2046.0312197208405, "episode/length": 423.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 37264, "time": 2048.8198370933533, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 37568, "time": 2060.827291250229, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 37672, "time": 2065.585489988327, "episode/length": 50.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 37784, "time": 2071.0168113708496, "episode/length": 226.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 37800, "time": 2073.1309909820557, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 38072, "time": 2083.7607645988464, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 38968, "time": 2115.229889154434, "episode/length": 161.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 39176, "time": 2123.8335156440735, "episode/length": 398.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 39216, "time": 2126.951689004898, "episode/length": 361.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9972375690607734, "episode/intrinsic_return": 0.0}
{"step": 39224, "time": 2128.5032539367676, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 2132.7777602672577, "episode/length": 399.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 39352, "time": 2135.99165558815, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 39400, "time": 2139.2251279354095, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 39456, "time": 2143.0069041252136, "episode/length": 60.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 39536, "time": 2147.355375766754, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2184.312678337097, "eval_episode/length": 90.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9560439560439561}
{"step": 40040, "time": 2186.851679086685, "eval_episode/length": 113.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.956140350877193}
{"step": 40040, "time": 2190.4533364772797, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 40040, "time": 2192.7547006607056, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 40040, "time": 2195.2085287570953, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 40040, "time": 2197.1688804626465, "eval_episode/length": 191.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 40040, "time": 2201.276503801346, "eval_episode/length": 245.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 40040, "time": 2202.915417909622, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 40400, "time": 2215.4037249088287, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 40432, "time": 2218.175637483597, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9426229508196722, "episode/intrinsic_return": 0.0}
{"step": 40632, "time": 2226.2866475582123, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 40656, "time": 2228.873188972473, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 40672, "time": 2230.904482603073, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 40776, "time": 2235.661775112152, "episode/length": 42.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 40800, "time": 2238.283386707306, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 40832, "time": 2241.073224544525, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 41568, "time": 2268.585610151291, "episode/length": 98.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 41944, "time": 2282.736913919449, "episode/length": 323.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 42176, "time": 2292.432158470154, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 42320, "time": 2298.95556807518, "episode/length": 207.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 42448, "time": 2304.8108172416687, "episode/length": 201.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 42776, "time": 2317.0553636550903, "episode/length": 296.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 42808, "time": 2319.670224905014, "episode/length": 266.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 42968, "time": 2326.438985824585, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 43088, "time": 2332.4490337371826, "episode/length": 34.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 43232, "time": 2338.763237953186, "episode/length": 324.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 43760, "time": 2358.1774570941925, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 43896, "time": 2364.7648379802704, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 43977, "time": 2370.110236644745, "train_stats/sum_log_reward": 2.36271180124101, "train_stats/max_log_achievement_collect_drink": 23.161016949152543, "train_stats/max_log_achievement_collect_sapling": 2.0508474576271185, "train_stats/max_log_achievement_collect_wood": 0.559322033898305, "train_stats/max_log_achievement_defeat_zombie": 0.1271186440677966, "train_stats/max_log_achievement_eat_cow": 0.11016949152542373, "train_stats/max_log_achievement_place_plant": 1.4745762711864407, "train_stats/max_log_achievement_place_table": 0.00847457627118644, "train_stats/max_log_achievement_wake_up": 1.728813559322034, "train_stats/mean_log_entropy": 0.4349053937752368, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.279719184426701, "train/action_min": 0.0, "train/action_std": 2.725655628477826, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04158327343654545, "train/actor_opt_grad_steps": 1975.0, "train/actor_opt_loss": 26.60398869008264, "train/adv_mag": 1.5131858565351541, "train/adv_max": 1.512993752518121, "train/adv_mean": 0.013644591916839572, "train/adv_min": -0.522062232827439, "train/adv_std": 0.12043545093825635, "train/cont_avg": 0.9945930032169118, "train/cont_loss_mean": 0.006452361357921344, "train/cont_loss_std": 0.08865669491912259, "train/cont_neg_acc": 0.6790266192025122, "train/cont_neg_loss": 0.8293906143001496, "train/cont_pos_acc": 0.9996819386587423, "train/cont_pos_loss": 0.0019299068925152717, "train/cont_pred": 0.994688971515964, "train/cont_rate": 0.9945930032169118, "train/dyn_loss_mean": 7.515857300337623, "train/dyn_loss_std": 6.283216763945187, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4448376262889189, "train/extr_critic_critic_opt_grad_steps": 1975.0, "train/extr_critic_critic_opt_loss": 17182.789644129138, "train/extr_critic_mag": 1.566395756076364, "train/extr_critic_max": 1.566395756076364, "train/extr_critic_mean": 0.36203155236537843, "train/extr_critic_min": -0.4574871036936255, "train/extr_critic_std": 0.6411116300698589, "train/extr_return_normed_mag": 2.3395814974518383, "train/extr_return_normed_max": 2.3395814974518383, "train/extr_return_normed_mean": 0.4052184293156161, "train/extr_return_normed_min": -0.21203968145281954, "train/extr_return_normed_std": 0.35563190851141424, "train/extr_return_rate": 0.37936487311826034, "train/extr_return_raw_mag": 4.3624632358551025, "train/extr_return_raw_max": 4.3624632358551025, "train/extr_return_raw_mean": 0.3891777712303926, "train/extr_return_raw_min": -0.8722775276092922, "train/extr_return_raw_std": 0.7304811512722689, "train/extr_reward_mag": 0.9933377144967809, "train/extr_reward_max": 0.9933377144967809, "train/extr_reward_mean": 0.0118800276900669, "train/extr_reward_min": -0.28355666469125185, "train/extr_reward_std": 0.08729000063613057, "train/image_loss_mean": 27.302367266486673, "train/image_loss_std": 23.445788839284113, "train/model_loss_mean": 31.90892270032097, "train/model_loss_std": 25.606341193704043, "train/model_opt_grad_norm": 169.01939840877756, "train/model_opt_grad_steps": 1966.0, "train/model_opt_loss": 1771.2749759449678, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 57.44485294117647, "train/policy_entropy_mag": 2.131569744032972, "train/policy_entropy_max": 2.131569744032972, "train/policy_entropy_mean": 0.4367994294666192, "train/policy_entropy_min": 0.07973884287125924, "train/policy_entropy_std": 0.3631298835663235, "train/policy_logprob_mag": 7.437450065332301, "train/policy_logprob_max": -0.009505991152871181, "train/policy_logprob_mean": -0.4364588575108963, "train/policy_logprob_min": -7.437450065332301, "train/policy_logprob_std": 1.03230902289643, "train/policy_randomness_mag": 0.7523505792898291, "train/policy_randomness_max": 0.7523505792898291, "train/policy_randomness_mean": 0.15417103222845233, "train/policy_randomness_min": 0.028144312310306466, "train/policy_randomness_std": 0.1281689134262064, "train/post_ent_mag": 44.23840309591854, "train/post_ent_max": 44.23840309591854, "train/post_ent_mean": 31.686072125154382, "train/post_ent_min": 14.53216041536892, "train/post_ent_std": 4.70025372505188, "train/prior_ent_mag": 54.88484522875618, "train/prior_ent_max": 54.88484522875618, "train/prior_ent_mean": 39.47650791617001, "train/prior_ent_min": 18.77498703143176, "train/prior_ent_std": 5.464953080696218, "train/rep_loss_mean": 7.515857300337623, "train/rep_loss_std": 6.283216763945187, "train/reward_avg": 0.008361816348042339, "train/reward_loss_mean": 0.09058839389506508, "train/reward_loss_std": 0.4117399226216709, "train/reward_max_data": 1.0066176486365936, "train/reward_max_pred": 0.9902698143440134, "train/reward_neg_acc": 0.9952437868889641, "train/reward_neg_loss": 0.0709418241509839, "train/reward_pos_acc": 0.8286321515984395, "train/reward_pos_loss": 1.5465579909436844, "train/reward_pred": 0.007191504980095059, "train/reward_rate": 0.013334386488970588, "eval_stats/sum_log_reward": 2.4124999158084393, "eval_stats/max_log_achievement_collect_drink": 23.75, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0003857457486446947, "report/cont_loss_std": 0.007380063179880381, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03772909566760063, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002025104477070272, "report/cont_pred": 0.9950963258743286, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.713570594787598, "report/dyn_loss_std": 6.476522445678711, "report/image_loss_mean": 18.466842651367188, "report/image_loss_std": 14.192850112915039, "report/model_loss_mean": 23.14895248413086, "report/model_loss_std": 16.792531967163086, "report/post_ent_mag": 45.54534912109375, "report/post_ent_max": 45.54534912109375, "report/post_ent_mean": 32.47624969482422, "report/post_ent_min": 16.793386459350586, "report/post_ent_std": 4.980389595031738, "report/prior_ent_mag": 56.86525344848633, "report/prior_ent_max": 56.86525344848633, "report/prior_ent_mean": 40.63893127441406, "report/prior_ent_min": 17.14773941040039, "report/prior_ent_std": 5.460681915283203, "report/rep_loss_mean": 7.713570594787598, "report/rep_loss_std": 6.476522445678711, "report/reward_avg": 0.0049804686568677425, "report/reward_loss_mean": 0.05358040705323219, "report/reward_loss_std": 0.2876431345939636, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9932609796524048, "report/reward_neg_acc": 0.9940828680992126, "report/reward_neg_loss": 0.038521286100149155, "report/reward_pos_acc": 0.800000011920929, "report/reward_pos_loss": 1.5805749893188477, "report/reward_pred": 0.0040557486936450005, "report/reward_rate": 0.009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 2.707765088416636e-05, "eval/cont_loss_std": 0.0005102887516841292, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015246366150677204, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2200538549222983e-05, "eval/cont_pred": 0.9990260601043701, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 11.331068992614746, "eval/dyn_loss_std": 6.818419933319092, "eval/image_loss_mean": 34.98651123046875, "eval/image_loss_std": 31.126020431518555, "eval/model_loss_mean": 41.849220275878906, "eval/model_loss_std": 33.52980041503906, "eval/post_ent_mag": 52.416927337646484, "eval/post_ent_max": 52.416927337646484, "eval/post_ent_mean": 31.231266021728516, "eval/post_ent_min": 14.686280250549316, "eval/post_ent_std": 5.543008327484131, "eval/prior_ent_mag": 54.827308654785156, "eval/prior_ent_max": 54.827308654785156, "eval/prior_ent_mean": 39.98124694824219, "eval/prior_ent_min": 15.419890403747559, "eval/prior_ent_std": 6.113132953643799, "eval/rep_loss_mean": 11.331068992614746, "eval/rep_loss_std": 6.818419933319092, "eval/reward_avg": 0.006640625186264515, "eval/reward_loss_mean": 0.06404145061969757, "eval/reward_loss_std": 0.4940435290336609, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9953793287277222, "eval/reward_neg_acc": 0.9990147948265076, "eval/reward_neg_loss": 0.04120945930480957, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.6389825344085693, "eval/reward_pred": 0.0020069745369255543, "eval/reward_rate": 0.0087890625, "replay/size": 43473.0, "replay/inserts": 21720.0, "replay/samples": 21728.0, "replay/insert_wait_avg": 1.460665058255415e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.889672858023328e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10072.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3503210270108811e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4574959278107, "timer/env.step_count": 2715.0, "timer/env.step_total": 263.2664439678192, "timer/env.step_frac": 0.26314605571890837, "timer/env.step_avg": 0.09696738267691316, "timer/env.step_min": 0.022430419921875, "timer/env.step_max": 3.41745924949646, "timer/replay._sample_count": 21728.0, "timer/replay._sample_total": 11.803159236907959, "timer/replay._sample_frac": 0.011797761808923097, "timer/replay._sample_avg": 0.0005432234553068832, "timer/replay._sample_min": 0.000377655029296875, "timer/replay._sample_max": 0.028146982192993164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3158.0, "timer/agent.policy_total": 54.83221626281738, "timer/agent.policy_frac": 0.05480714221843751, "timer/agent.policy_avg": 0.01736295638467935, "timer/agent.policy_min": 0.009503841400146484, "timer/agent.policy_max": 0.12718939781188965, "timer/dataset_train_count": 1358.0, "timer/dataset_train_total": 0.15389561653137207, "timer/dataset_train_frac": 0.0001538252421095125, "timer/dataset_train_avg": 0.00011332519626757884, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0010669231414794922, "timer/agent.train_count": 1358.0, "timer/agent.train_total": 613.0425896644592, "timer/agent.train_frac": 0.6127622534287994, "timer/agent.train_avg": 0.4514304783979818, "timer/agent.train_min": 0.43683934211730957, "timer/agent.train_max": 1.4256653785705566, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4777216911315918, "timer/agent.report_frac": 0.0004775032353459046, "timer/agent.report_avg": 0.2388608455657959, "timer/agent.report_min": 0.23260045051574707, "timer/agent.report_max": 0.24512124061584473, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.288671837627942e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.709799054297353}
{"step": 44248, "time": 2379.054354906082, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 44376, "time": 2384.8633472919464, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 44592, "time": 2393.9509975910187, "episode/length": 283.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 44896, "time": 2405.729333639145, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 44928, "time": 2408.3047370910645, "episode/length": 68.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 44944, "time": 2410.373579978943, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 45096, "time": 2416.805511236191, "episode/length": 166.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 45384, "time": 2428.032724380493, "episode/length": 54.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 45808, "time": 2444.0602757930756, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 45864, "time": 2447.276375770569, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 45928, "time": 2451.064115047455, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 46200, "time": 2461.6295120716095, "episode/length": 427.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 46216, "time": 2463.7042951583862, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 46320, "time": 2469.038479566574, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 46360, "time": 2471.7523753643036, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 46528, "time": 2479.274274110794, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 46768, "time": 2488.925052881241, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 47264, "time": 2507.3196868896484, "episode/length": 132.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 47336, "time": 2511.276470899582, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 47664, "time": 2524.663081407547, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 47704, "time": 2527.3772077560425, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 47976, "time": 2538.2644720077515, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 48224, "time": 2548.5993955135345, "episode/length": 294.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 48352, "time": 2555.0661618709564, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 48568, "time": 2563.7980773448944, "episode/length": 162.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 48656, "time": 2568.639480829239, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 48880, "time": 2577.7837715148926, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 49048, "time": 2584.7748005390167, "episode/length": 172.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 49088, "time": 2588.009605884552, "episode/length": 394.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772151898734177, "episode/intrinsic_return": 0.0}
{"step": 49104, "time": 2590.1414091587067, "episode/length": 140.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 49192, "time": 2595.6900210380554, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 49576, "time": 2610.2087552547455, "episode/length": 114.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 49832, "time": 2620.4223086833954, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2644.8441236019135, "eval_episode/length": 77.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 50024, "time": 2647.8969209194183, "eval_episode/length": 110.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.954954954954955}
{"step": 50024, "time": 2650.281824827194, "eval_episode/length": 131.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 50024, "time": 2653.065873861313, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 50024, "time": 2655.023262023926, "eval_episode/length": 165.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 50024, "time": 2656.9200513362885, "eval_episode/length": 172.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 50024, "time": 2659.962202310562, "eval_episode/length": 204.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 50024, "time": 2664.3851504325867, "eval_episode/length": 139.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.95}
{"step": 50240, "time": 2671.8252840042114, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 50272, "time": 2674.427890062332, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 50384, "time": 2679.7884817123413, "episode/length": 159.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 50696, "time": 2691.7017447948456, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 50952, "time": 2701.9155910015106, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 51008, "time": 2705.6621012687683, "episode/length": 244.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 51024, "time": 2707.8485476970673, "episode/length": 148.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 51504, "time": 2725.6937732696533, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 51672, "time": 2732.709680557251, "episode/length": 261.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 51976, "time": 2744.6153864860535, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 52032, "time": 2748.386087656021, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 52248, "time": 2757.005069255829, "episode/length": 161.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 52304, "time": 2760.6418483257294, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 52416, "time": 2765.9747467041016, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 52752, "time": 2778.8520123958588, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 52992, "time": 2788.772555589676, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 53000, "time": 2790.5127613544464, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 53104, "time": 2795.813681602478, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 53432, "time": 2808.2179720401764, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 53512, "time": 2812.5872309207916, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 53728, "time": 2821.6139075756073, "episode/length": 36.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 53760, "time": 2824.154986858368, "episode/length": 94.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 54000, "time": 2833.9191727638245, "episode/length": 245.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 54096, "time": 2838.741446495056, "episode/length": 137.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 54440, "time": 2851.5609016418457, "episode/length": 266.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 54608, "time": 2859.044766187668, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 54720, "time": 2864.4630150794983, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 54896, "time": 2871.9537482261658, "episode/length": 172.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 54984, "time": 2876.32758641243, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 55192, "time": 2885.0046088695526, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 55512, "time": 2897.431191921234, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 56048, "time": 2917.248268842697, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 56072, "time": 2919.4273381233215, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 56144, "time": 2923.680727005005, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 56392, "time": 2933.4875893592834, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 56400, "time": 2935.5620963573456, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 56840, "time": 2951.7812745571136, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 57144, "time": 2963.597053050995, "episode/length": 316.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 57200, "time": 2967.3877789974213, "episode/length": 250.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 57704, "time": 2987.178538799286, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 57768, "time": 2991.057553052902, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 57912, "time": 2997.5183708667755, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 58048, "time": 3003.840205192566, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 58432, "time": 3018.2923521995544, "episode/length": 297.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 58496, "time": 3022.2311239242554, "episode/length": 168.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 58904, "time": 3037.668151140213, "episode/length": 257.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 59112, "time": 3046.2432787418365, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 59160, "time": 3049.515551328659, "episode/length": 244.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 59376, "time": 3058.4983739852905, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 59432, "time": 3061.6890494823456, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 59696, "time": 3072.3941309452057, "episode/length": 39.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 59760, "time": 3076.080811738968, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 59880, "time": 3081.712190389633, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 59904, "time": 3084.3085885047913, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3104.4567863941193, "eval_episode/length": 41.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9047619047619048}
{"step": 60008, "time": 3111.1625425815582, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 60008, "time": 3112.872360944748, "eval_episode/length": 163.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 60008, "time": 3114.585193634033, "eval_episode/length": 166.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 60008, "time": 3116.3131799697876, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 60008, "time": 3118.803702354431, "eval_episode/length": 191.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 60008, "time": 3120.5587565898895, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 60008, "time": 3122.5019967556, "eval_episode/length": 37.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 60616, "time": 3142.91716504097, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 60632, "time": 3145.0303440093994, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 60664, "time": 3147.6900951862335, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 60696, "time": 3150.2627017498016, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 61016, "time": 3162.531774997711, "episode/length": 43.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 61088, "time": 3166.7329308986664, "episode/length": 58.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 61120, "time": 3169.437859773636, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 61152, "time": 3172.1555914878845, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 61176, "time": 3174.3009264469147, "episode/length": 161.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 61240, "time": 3178.132542848587, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 61904, "time": 3202.2105588912964, "episode/length": 101.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 61936, "time": 3204.826363801956, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 62232, "time": 3216.1277809143066, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 62400, "time": 3223.5405724048615, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 62744, "time": 3236.516800880432, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 63072, "time": 3249.31476521492, "episode/length": 228.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 63112, "time": 3252.1095073223114, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 63224, "time": 3257.3299775123596, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 63384, "time": 3264.3227219581604, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 63608, "time": 3273.390608072281, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 63720, "time": 3278.8339190483093, "episode/length": 377.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 64232, "time": 3297.6910049915314, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 64280, "time": 3301.0504956245422, "episode/length": 255.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 64384, "time": 3306.325343608856, "episode/length": 163.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 64416, "time": 3308.9985332489014, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 64576, "time": 3315.8496940135956, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 64752, "time": 3323.3031556606293, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 64824, "time": 3327.032001018524, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 65056, "time": 3336.5780453681946, "episode/length": 37.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 65760, "time": 3363.1246716976166, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 65856, "time": 3367.835105419159, "episode/length": 266.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 65865, "time": 3370.495940685272, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.524770472171533, "train/action_min": 0.0, "train/action_std": 2.970353394529245, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051540380398178626, "train/actor_opt_grad_steps": 3340.0, "train/actor_opt_loss": 59.80415957720175, "train/adv_mag": 1.4035742417739256, "train/adv_max": 1.403182922053511, "train/adv_mean": 0.01271678474179939, "train/adv_min": -0.5538948445859617, "train/adv_std": 0.10851521925987119, "train/cont_avg": 0.9945683166058394, "train/cont_loss_mean": 0.0008608379599755495, "train/cont_loss_std": 0.02282475650637244, "train/cont_neg_acc": 0.9694212770810092, "train/cont_neg_loss": 0.1078815713471072, "train/cont_pos_acc": 0.9999282843005048, "train/cont_pos_loss": 0.000275730123987664, "train/cont_pred": 0.9946265590451929, "train/cont_rate": 0.9945683166058394, "train/dyn_loss_mean": 9.084132500808604, "train/dyn_loss_std": 7.241180764497631, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.326436459148017, "train/extr_critic_critic_opt_grad_steps": 3340.0, "train/extr_critic_critic_opt_loss": 14988.234047103102, "train/extr_critic_mag": 2.0101772694692124, "train/extr_critic_max": 2.0101772694692124, "train/extr_critic_mean": 0.4884306989120741, "train/extr_critic_min": -0.18529406777263557, "train/extr_critic_std": 0.6092457249216789, "train/extr_return_normed_mag": 2.2724611123983007, "train/extr_return_normed_max": 2.2724611123983007, "train/extr_return_normed_mean": 0.34420874171013377, "train/extr_return_normed_min": -0.15000776600867619, "train/extr_return_normed_std": 0.3525082595156927, "train/extr_return_rate": 0.32796914799370036, "train/extr_return_raw_mag": 4.093685005703112, "train/extr_return_raw_max": 4.093685005703112, "train/extr_return_raw_mean": 0.5119104320659255, "train/extr_return_raw_min": -0.40622687997826695, "train/extr_return_raw_std": 0.65520164588072, "train/extr_reward_mag": 1.0006548714463728, "train/extr_reward_max": 1.0006548714463728, "train/extr_reward_mean": 0.011791646191646365, "train/extr_reward_min": -0.2853971467400989, "train/extr_reward_std": 0.08821269472802643, "train/image_loss_mean": 22.051895559269145, "train/image_loss_std": 22.12942538992332, "train/model_loss_mean": 27.56309769623471, "train/model_loss_std": 25.062528074222758, "train/model_opt_grad_norm": 140.9649449090888, "train/model_opt_grad_steps": 3331.0, "train/model_opt_loss": 3776.102569357322, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 136.86131386861314, "train/policy_entropy_mag": 2.351531817095123, "train/policy_entropy_max": 2.351531817095123, "train/policy_entropy_mean": 0.8028279299283549, "train/policy_entropy_min": 0.07969414132789973, "train/policy_entropy_std": 0.4988889652882179, "train/policy_logprob_mag": 7.437162322719602, "train/policy_logprob_max": -0.009499768515790466, "train/policy_logprob_mean": -0.8022007441868747, "train/policy_logprob_min": -7.437162322719602, "train/policy_logprob_std": 1.1891849911125907, "train/policy_randomness_mag": 0.8299875416024758, "train/policy_randomness_max": 0.8299875416024758, "train/policy_randomness_mean": 0.28336302522760237, "train/policy_randomness_min": 0.02812853473218253, "train/policy_randomness_std": 0.17608591174557262, "train/post_ent_mag": 45.96471488562813, "train/post_ent_max": 45.96471488562813, "train/post_ent_mean": 33.10733090700024, "train/post_ent_min": 17.102825116067038, "train/post_ent_std": 4.733922873100225, "train/prior_ent_mag": 57.86547060778541, "train/prior_ent_max": 57.86547060778541, "train/prior_ent_mean": 42.510958789908976, "train/prior_ent_min": 20.5589974605254, "train/prior_ent_std": 6.3505765643433065, "train/rep_loss_mean": 9.084132500808604, "train/rep_loss_std": 7.241180764497631, "train/reward_avg": 0.011308878774068108, "train/reward_loss_mean": 0.0598619116646965, "train/reward_loss_std": 0.3102724006141189, "train/reward_max_data": 1.005109490269292, "train/reward_max_pred": 0.9979083120387836, "train/reward_neg_acc": 0.9946550696435636, "train/reward_neg_loss": 0.04060877038397058, "train/reward_pos_acc": 0.9005273719773675, "train/reward_pos_loss": 1.2264769816920704, "train/reward_pred": 0.01017970801840951, "train/reward_rate": 0.016166742700729927, "train_stats/sum_log_reward": 3.13389825719898, "train_stats/max_log_achievement_collect_drink": 8.796610169491526, "train_stats/max_log_achievement_collect_sapling": 1.88135593220339, "train_stats/max_log_achievement_collect_wood": 1.3728813559322033, "train_stats/max_log_achievement_defeat_zombie": 0.2457627118644068, "train_stats/max_log_achievement_eat_cow": 0.059322033898305086, "train_stats/max_log_achievement_place_plant": 1.2881355932203389, "train_stats/max_log_achievement_place_table": 0.288135593220339, "train_stats/max_log_achievement_wake_up": 1.6101694915254237, "train_stats/mean_log_entropy": 0.8222231359805091, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0297029702970297, "train_stats/max_log_achievement_make_wood_sword": 0.009900990099009901, "eval_stats/sum_log_reward": 2.9749999716877937, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_wood": 1.5625, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 0.4375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 6.326520087895915e-05, "report/cont_loss_std": 0.0007791162352077663, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0016492343274876475, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.860515739186667e-05, "report/cont_pred": 0.9970170259475708, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 9.689923286437988, "report/dyn_loss_std": 7.498551845550537, "report/image_loss_mean": 18.44678497314453, "report/image_loss_std": 21.853267669677734, "report/model_loss_mean": 24.324262619018555, "report/model_loss_std": 25.271303176879883, "report/post_ent_mag": 45.24299240112305, "report/post_ent_max": 45.24299240112305, "report/post_ent_mean": 33.027366638183594, "report/post_ent_min": 15.638998985290527, "report/post_ent_std": 4.604506492614746, "report/prior_ent_mag": 58.34727096557617, "report/prior_ent_max": 58.34727096557617, "report/prior_ent_mean": 42.965370178222656, "report/prior_ent_min": 21.00484848022461, "report/prior_ent_std": 6.627175331115723, "report/rep_loss_mean": 9.689923286437988, "report/rep_loss_std": 7.498551845550537, "report/reward_avg": 0.01298828050494194, "report/reward_loss_mean": 0.06345846503973007, "report/reward_loss_std": 0.3706108033657074, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9962328672409058, "report/reward_neg_acc": 0.9980139136314392, "report/reward_neg_loss": 0.03994331881403923, "report/reward_pos_acc": 0.8823529481887817, "report/reward_pos_loss": 1.4563848972320557, "report/reward_pred": 0.009320156648755074, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.010812725871801376, "eval/cont_loss_std": 0.20588023960590363, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0022108308039605618, "eval/cont_pos_acc": 0.9960899353027344, "eval/cont_pos_loss": 0.01082113478332758, "eval/cont_pred": 0.9956780672073364, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 12.670726776123047, "eval/dyn_loss_std": 7.018552303314209, "eval/image_loss_mean": 26.64615821838379, "eval/image_loss_std": 22.57145881652832, "eval/model_loss_mean": 34.33153533935547, "eval/model_loss_std": 24.746408462524414, "eval/post_ent_mag": 45.73103332519531, "eval/post_ent_max": 45.73103332519531, "eval/post_ent_mean": 31.84119415283203, "eval/post_ent_min": 16.314525604248047, "eval/post_ent_std": 4.83801794052124, "eval/prior_ent_mag": 58.324363708496094, "eval/prior_ent_max": 58.324363708496094, "eval/prior_ent_mean": 42.730010986328125, "eval/prior_ent_min": 19.622238159179688, "eval/prior_ent_std": 5.954644680023193, "eval/rep_loss_mean": 12.670726776123047, "eval/rep_loss_std": 7.018552303314209, "eval/reward_avg": 0.00966796837747097, "eval/reward_loss_mean": 0.07212749123573303, "eval/reward_loss_std": 0.5188753008842468, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9985466003417969, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.049817152321338654, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 1.9536333084106445, "eval/reward_pred": 0.005187666043639183, "eval/reward_rate": 0.01171875, "replay/size": 65361.0, "replay/inserts": 21888.0, "replay/samples": 21888.0, "replay/insert_wait_avg": 1.4505648647832592e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.0574660496405e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13864.0, "eval_replay/inserts": 3792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2401287062761653e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3656640052795, "timer/env.step_count": 2736.0, "timer/env.step_total": 261.1722991466522, "timer/env.step_frac": 0.2610768327463045, "timer/env.step_avg": 0.09545771167640797, "timer/env.step_min": 0.02295684814453125, "timer/env.step_max": 2.1222007274627686, "timer/replay._sample_count": 21888.0, "timer/replay._sample_total": 12.119610071182251, "timer/replay._sample_frac": 0.012115179985943908, "timer/replay._sample_avg": 0.0005537102554450955, "timer/replay._sample_min": 0.00039076805114746094, "timer/replay._sample_max": 0.025737762451171875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3210.0, "timer/agent.policy_total": 54.61802101135254, "timer/agent.policy_frac": 0.05459805646734421, "timer/agent.policy_avg": 0.01701495981662073, "timer/agent.policy_min": 0.009613275527954102, "timer/agent.policy_max": 0.09870672225952148, "timer/dataset_train_count": 1368.0, "timer/dataset_train_total": 0.15704607963562012, "timer/dataset_train_frac": 0.00015698867452810863, "timer/dataset_train_avg": 0.00011479976581551178, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0010693073272705078, "timer/agent.train_count": 1368.0, "timer/agent.train_total": 617.9851443767548, "timer/agent.train_frac": 0.6177592520543501, "timer/agent.train_avg": 0.451743526591195, "timer/agent.train_min": 0.43704962730407715, "timer/agent.train_max": 1.4419307708740234, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46925902366638184, "timer/agent.report_frac": 0.0004690874952540407, "timer/agent.report_avg": 0.23462951183319092, "timer/agent.report_min": 0.2223834991455078, "timer/agent.report_max": 0.24687552452087402, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.100799560546875e-05, "timer/dataset_eval_frac": 4.0993005938728744e-08, "timer/dataset_eval_avg": 4.100799560546875e-05, "timer/dataset_eval_min": 4.100799560546875e-05, "timer/dataset_eval_max": 4.100799560546875e-05, "fps": 21.879691546783206}
{"step": 66160, "time": 3380.564366579056, "episode/length": 217.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 66216, "time": 3383.86710524559, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 66240, "time": 3386.925899028778, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 66512, "time": 3397.6224114894867, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9661654135338346, "episode/intrinsic_return": 0.0}
{"step": 66704, "time": 3405.6438839435577, "episode/length": 234.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 66816, "time": 3411.010697364807, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 67232, "time": 3426.596592903137, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 67312, "time": 3430.956704378128, "episode/length": 143.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 67656, "time": 3443.836361169815, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 67720, "time": 3447.4999566078186, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 67832, "time": 3452.959829568863, "episode/length": 406.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 67976, "time": 3459.520184278488, "episode/length": 276.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 68040, "time": 3463.292550086975, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 68408, "time": 3477.2742505073547, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 68672, "time": 3487.9871158599854, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 68776, "time": 3492.842948436737, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 68896, "time": 3498.7106564044952, "episode/length": 27.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 69008, "time": 3503.990829229355, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 69120, "time": 3509.355595111847, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 69528, "time": 3524.503707408905, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 69888, "time": 3538.4274883270264, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 70048, "time": 3545.3526062965393, "episode/length": 258.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3563.269355535507, "eval_episode/length": 35.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8611111111111112}
{"step": 70096, "time": 3569.88787651062, "eval_episode/length": 155.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 70096, "time": 3572.806572675705, "eval_episode/length": 187.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 70096, "time": 3574.9735300540924, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 70096, "time": 3576.9228761196136, "eval_episode/length": 206.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 70096, "time": 3578.7970740795135, "eval_episode/length": 215.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9675925925925926}
{"step": 70096, "time": 3580.564703941345, "eval_episode/length": 219.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 70096, "time": 3580.5731382369995, "eval_episode/length": 219.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 70280, "time": 3586.5367612838745, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 70384, "time": 3591.908080816269, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 70456, "time": 3595.7404685020447, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 70712, "time": 3605.883633375168, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 70736, "time": 3608.470687150955, "episode/length": 244.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 71416, "time": 3632.6619045734406, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 71456, "time": 3635.7827863693237, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 71472, "time": 3637.9539098739624, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 71656, "time": 3645.6016392707825, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 71848, "time": 3653.733694791794, "episode/length": 53.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 71944, "time": 3658.464982032776, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 72232, "time": 3669.776159763336, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 72264, "time": 3672.8099954128265, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 72344, "time": 3677.1602737903595, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 72408, "time": 3680.960531949997, "episode/length": 69.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 72600, "time": 3689.1667020320892, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 72856, "time": 3699.4157433509827, "episode/length": 321.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 72984, "time": 3705.3452458381653, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 73056, "time": 3709.6085476875305, "episode/length": 56.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9298245614035088, "episode/intrinsic_return": 0.0}
{"step": 73384, "time": 3721.979699611664, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 73640, "time": 3732.1955981254578, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 73680, "time": 3735.391862630844, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 73688, "time": 3736.9846999645233, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 73768, "time": 3742.773586034775, "episode/length": 288.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 74152, "time": 3757.0056455135345, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 74400, "time": 3767.194614171982, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 74696, "time": 3778.4492089748383, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 74712, "time": 3780.553449869156, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 74984, "time": 3791.2645852565765, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 75064, "time": 3795.591173171997, "episode/length": 177.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 75160, "time": 3800.495739221573, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 75640, "time": 3818.1528096199036, "episode/length": 185.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 75664, "time": 3820.765122652054, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 75912, "time": 3830.5640349388123, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 75992, "time": 3834.862944841385, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 76176, "time": 3842.8534553050995, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 76304, "time": 3848.6564707756042, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 76536, "time": 3857.729151725769, "episode/length": 77.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 76576, "time": 3861.0596256256104, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 77000, "time": 3876.547330379486, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 77360, "time": 3890.584010362625, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 77416, "time": 3893.777249097824, "episode/length": 109.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 77792, "time": 3908.1663150787354, "episode/length": 328.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9969604863221885, "episode/intrinsic_return": 0.0}
{"step": 77848, "time": 3911.3073921203613, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 77880, "time": 3914.0700254440308, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 78144, "time": 3924.749558210373, "episode/length": 32.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 78440, "time": 3936.1245877742767, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 78728, "time": 3947.391122341156, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 78784, "time": 3951.203598022461, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 78840, "time": 3954.4512355327606, "episode/length": 396.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 79000, "time": 3961.3101241588593, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 79144, "time": 3967.717588663101, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 79216, "time": 3971.9725229740143, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 79384, "time": 3979.0395278930664, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 79648, "time": 3989.868598461151, "episode/length": 150.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 80040, "time": 4004.616525411606, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4023.0877373218536, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 80080, "time": 4030.1414201259613, "eval_episode/length": 136.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.948905109489051}
{"step": 80080, "time": 4031.9637789726257, "eval_episode/length": 139.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 80080, "time": 4033.9445521831512, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 80080, "time": 4035.525215148926, "eval_episode/length": 149.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9533333333333334}
{"step": 80080, "time": 4037.156133890152, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 80080, "time": 4040.157236814499, "eval_episode/length": 181.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 80080, "time": 4041.8095881938934, "eval_episode/length": 148.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 80528, "time": 4056.9033586978912, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 80800, "time": 4067.6321346759796, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 80856, "time": 4071.118510723114, "episode/length": 251.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 80864, "time": 4073.1911070346832, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 80976, "time": 4078.460530757904, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 80984, "time": 4080.025072813034, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 81264, "time": 4091.178288936615, "episode/length": 35.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 81808, "time": 4111.05936217308, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 82000, "time": 4120.35731959343, "episode/length": 244.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 82136, "time": 4126.241624832153, "episode/length": 418.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 82296, "time": 4133.301054954529, "episode/length": 36.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 82432, "time": 4139.732936859131, "episode/length": 203.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 82440, "time": 4141.329474449158, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 82672, "time": 4150.9269490242, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 82720, "time": 4154.106132268906, "episode/length": 34.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 82792, "time": 4157.855680704117, "episode/length": 240.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 82832, "time": 4161.076505184174, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 83424, "time": 4183.082069635391, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 83664, "time": 4192.965803146362, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 83720, "time": 4196.181438922882, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 83784, "time": 4199.909178495407, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 84088, "time": 4211.7386083602905, "episode/length": 161.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 84432, "time": 4225.11579823494, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 84528, "time": 4229.813677787781, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 84568, "time": 4232.41490983963, "episode/length": 97.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 84680, "time": 4237.758378744125, "episode/length": 230.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 84688, "time": 4239.839372873306, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 85296, "time": 4261.777865409851, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 85768, "time": 4279.012477874756, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 86016, "time": 4289.167912721634, "episode/length": 293.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 86048, "time": 4291.824709653854, "episode/length": 170.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 86048, "time": 4291.834963798523, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 86136, "time": 4298.072616815567, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 86432, "time": 4310.071826934814, "episode/length": 292.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9897610921501706, "episode/intrinsic_return": 0.0}
{"step": 86808, "time": 4324.585078954697, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 87160, "time": 4338.026242494583, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 87240, "time": 4342.472304105759, "episode/length": 152.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 87264, "time": 4345.121460199356, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 87440, "time": 4352.660348415375, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 87472, "time": 4355.419130325317, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 87520, "time": 4358.62210392952, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 87776, "time": 4368.86455655098, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 87777, "time": 4371.017014980316, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.947038089527803, "train/action_min": 0.0, "train/action_std": 3.360235275591121, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.055133689523619765, "train/actor_opt_grad_steps": 4705.0, "train/actor_opt_loss": 23.494255639982466, "train/adv_mag": 1.1150435310076265, "train/adv_max": 1.1150435310076265, "train/adv_mean": 0.008507539517268015, "train/adv_min": -0.5182129311210969, "train/adv_std": 0.09934974675450255, "train/cont_avg": 0.9943488625919118, "train/cont_loss_mean": 0.0008131781549841034, "train/cont_loss_std": 0.0208003309370731, "train/cont_neg_acc": 0.9725023376591065, "train/cont_neg_loss": 0.07492734593148832, "train/cont_pos_acc": 0.9998915572376812, "train/cont_pos_loss": 0.0003509585288174368, "train/cont_pred": 0.9943312735242003, "train/cont_rate": 0.9943488625919118, "train/dyn_loss_mean": 11.13961379668292, "train/dyn_loss_std": 7.896659637198729, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.272600634571384, "train/extr_critic_critic_opt_grad_steps": 4705.0, "train/extr_critic_critic_opt_loss": 14928.852804744945, "train/extr_critic_mag": 2.6308730437475094, "train/extr_critic_max": 2.6308730437475094, "train/extr_critic_mean": 0.694838908227051, "train/extr_critic_min": -0.10155200432328616, "train/extr_critic_std": 0.6834531509700943, "train/extr_return_normed_mag": 2.1171371743959537, "train/extr_return_normed_max": 2.1171371743959537, "train/extr_return_normed_mean": 0.33974948974654956, "train/extr_return_normed_min": -0.16477865720277324, "train/extr_return_normed_std": 0.34512370331760717, "train/extr_return_rate": 0.4109691164511092, "train/extr_return_raw_mag": 4.479852916563258, "train/extr_return_raw_max": 4.479852916563258, "train/extr_return_raw_mean": 0.7129604805480031, "train/extr_return_raw_min": -0.357364619808162, "train/extr_return_raw_std": 0.7328244528787977, "train/extr_reward_mag": 1.0036980106550104, "train/extr_reward_max": 1.0036980106550104, "train/extr_reward_mean": 0.013749595960903475, "train/extr_reward_min": -0.2814915013663909, "train/extr_reward_std": 0.09607045812641873, "train/image_loss_mean": 20.268094196039087, "train/image_loss_std": 20.063192648046158, "train/model_loss_mean": 27.01062907892115, "train/model_loss_std": 23.416146804304685, "train/model_opt_grad_norm": 119.08211870754467, "train/model_opt_grad_steps": 4696.0, "train/model_opt_loss": 10672.401151769302, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 397.51838235294116, "train/policy_entropy_mag": 2.3552564873414883, "train/policy_entropy_max": 2.3552564873414883, "train/policy_entropy_mean": 0.7574453568633865, "train/policy_entropy_min": 0.07942374554627082, "train/policy_entropy_std": 0.5140871992882561, "train/policy_logprob_mag": 7.438170825733858, "train/policy_logprob_max": -0.009462922503349973, "train/policy_logprob_mean": -0.7580199763178825, "train/policy_logprob_min": -7.438170825733858, "train/policy_logprob_std": 1.1757661971975775, "train/policy_randomness_mag": 0.8313021826393464, "train/policy_randomness_max": 0.8313021826393464, "train/policy_randomness_mean": 0.26734497091349435, "train/policy_randomness_min": 0.02803309682263609, "train/policy_randomness_std": 0.1814502225640942, "train/post_ent_mag": 47.565734666936535, "train/post_ent_max": 47.565734666936535, "train/post_ent_mean": 34.465129627900964, "train/post_ent_min": 18.69808980997871, "train/post_ent_std": 4.77282434351304, "train/prior_ent_mag": 59.74998098261216, "train/prior_ent_max": 59.74998098261216, "train/prior_ent_mean": 45.8888570841621, "train/prior_ent_min": 23.767292836133173, "train/prior_ent_std": 6.517469392103307, "train/rep_loss_mean": 11.13961379668292, "train/rep_loss_std": 7.896659637198729, "train/reward_avg": 0.013005514592377414, "train/reward_loss_mean": 0.05795341443873065, "train/reward_loss_std": 0.2952256067929899, "train/reward_max_data": 1.0073529429295485, "train/reward_max_pred": 1.000937662580434, "train/reward_neg_acc": 0.9939858172746265, "train/reward_neg_loss": 0.0376075394657057, "train/reward_pos_acc": 0.9080110420199001, "train/reward_pos_loss": 1.1667786446564339, "train/reward_pred": 0.011658183164613815, "train/reward_rate": 0.018073586856617647, "train_stats/sum_log_reward": 3.7833332950870195, "train_stats/max_log_achievement_collect_drink": 9.141666666666667, "train_stats/max_log_achievement_collect_sapling": 1.9333333333333333, "train_stats/max_log_achievement_collect_wood": 2.225, "train_stats/max_log_achievement_defeat_zombie": 0.31666666666666665, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016666666666666666, "train_stats/max_log_achievement_make_wood_sword": 0.008333333333333333, "train_stats/max_log_achievement_place_plant": 1.65, "train_stats/max_log_achievement_place_table": 0.65, "train_stats/max_log_achievement_wake_up": 1.7083333333333333, "train_stats/mean_log_entropy": 0.7745012295742829, "eval_stats/sum_log_reward": 3.4124999903142452, "eval_stats/max_log_achievement_collect_drink": 5.4375, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_wood": 1.8125, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 0.5625, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.021739130434782608, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_collect_stone": 0.06060606060606061, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.7588141417945735e-05, "report/cont_loss_std": 0.0004100868245586753, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005559067707508802, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.305635009885009e-06, "report/cont_pred": 0.9970852732658386, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.515819549560547, "report/dyn_loss_std": 7.724630832672119, "report/image_loss_mean": 16.543663024902344, "report/image_loss_std": 14.570528030395508, "report/model_loss_mean": 22.9058837890625, "report/model_loss_std": 17.89275550842285, "report/post_ent_mag": 47.414581298828125, "report/post_ent_max": 47.414581298828125, "report/post_ent_mean": 34.343666076660156, "report/post_ent_min": 16.95595932006836, "report/post_ent_std": 4.9754252433776855, "report/prior_ent_mag": 61.175498962402344, "report/prior_ent_max": 61.175498962402344, "report/prior_ent_mean": 45.549861907958984, "report/prior_ent_min": 24.46285057067871, "report/prior_ent_std": 6.123523235321045, "report/rep_loss_mean": 10.515819549560547, "report/rep_loss_std": 7.724630832672119, "report/reward_avg": 0.01865234412252903, "report/reward_loss_mean": 0.05271296203136444, "report/reward_loss_std": 0.27426135540008545, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006444454193115, "report/reward_neg_acc": 0.9910089373588562, "report/reward_neg_loss": 0.029964148998260498, "report/reward_pos_acc": 0.95652174949646, "report/reward_pos_loss": 1.0427809953689575, "report/reward_pred": 0.017878077924251556, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0009013146045617759, "eval/cont_loss_std": 0.028407614678144455, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0021281978115439415, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0008989136549644172, "eval/cont_pred": 0.9974588751792908, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 13.015192031860352, "eval/dyn_loss_std": 7.685281276702881, "eval/image_loss_mean": 19.29690933227539, "eval/image_loss_std": 16.978778839111328, "eval/model_loss_mean": 27.196094512939453, "eval/model_loss_std": 19.896135330200195, "eval/post_ent_mag": 48.58617401123047, "eval/post_ent_max": 48.58617401123047, "eval/post_ent_mean": 33.64576721191406, "eval/post_ent_min": 18.74350357055664, "eval/post_ent_std": 4.972216606140137, "eval/prior_ent_mag": 61.175498962402344, "eval/prior_ent_max": 61.175498962402344, "eval/prior_ent_mean": 44.69823455810547, "eval/prior_ent_min": 20.913433074951172, "eval/prior_ent_std": 7.016390323638916, "eval/rep_loss_mean": 13.015192031860352, "eval/rep_loss_std": 7.685281276702881, "eval/reward_avg": 0.013476562686264515, "eval/reward_loss_mean": 0.08916972577571869, "eval/reward_loss_std": 0.5493559241294861, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000710487365723, "eval/reward_neg_acc": 0.9871032238006592, "eval/reward_neg_loss": 0.07295191287994385, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.1108920574188232, "eval/reward_pred": 0.019024144858121872, "eval/reward_rate": 0.015625, "replay/size": 87273.0, "replay/inserts": 21912.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.4365285188884533e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.09928686867847e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17096.0, "eval_replay/inserts": 3232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3315146512324267e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5109894275665, "timer/env.step_count": 2739.0, "timer/env.step_total": 263.80840039253235, "timer/env.step_frac": 0.2636736659369109, "timer/env.step_avg": 0.09631558977456457, "timer/env.step_min": 0.02268528938293457, "timer/env.step_max": 3.522646427154541, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 12.159883499145508, "timer/replay._sample_frac": 0.012153673100684959, "timer/replay._sample_avg": 0.0005551444256366648, "timer/replay._sample_min": 0.00041675567626953125, "timer/replay._sample_max": 0.010390043258666992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3143.0, "timer/agent.policy_total": 53.54044437408447, "timer/agent.policy_frac": 0.053513099745878014, "timer/agent.policy_avg": 0.017034821627134735, "timer/agent.policy_min": 0.009810924530029297, "timer/agent.policy_max": 0.10587763786315918, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.15384507179260254, "timer/dataset_train_frac": 0.0001537664987374338, "timer/dataset_train_avg": 0.00011237770035982654, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.00033783912658691406, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 618.5512158870697, "timer/agent.train_frac": 0.6182353041828839, "timer/agent.train_avg": 0.451827038631899, "timer/agent.train_min": 0.43849730491638184, "timer/agent.train_max": 1.4916911125183105, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47275638580322266, "timer/agent.report_frac": 0.0004725149356667297, "timer/agent.report_avg": 0.23637819290161133, "timer/agent.report_min": 0.2275397777557373, "timer/agent.report_max": 0.24521660804748535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.622111541640505e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 21.90049801749184}
{"step": 88144, "time": 4383.638915300369, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 88184, "time": 4386.459147453308, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 88624, "time": 4403.056028366089, "episode/length": 172.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 88808, "time": 4410.5963435173035, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 88888, "time": 4414.870369195938, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 89160, "time": 4425.919848680496, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 89200, "time": 4429.121318817139, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 89448, "time": 4438.906403541565, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 89568, "time": 4444.864644050598, "episode/length": 255.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 89640, "time": 4448.709433078766, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 90032, "time": 4463.99112033844, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 90040, "time": 4465.6996483802795, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4483.222842931747, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.875}
{"step": 90064, "time": 4489.86775803566, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 90064, "time": 4491.479852676392, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 90064, "time": 4494.029118061066, "eval_episode/length": 141.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 90064, "time": 4496.065963745117, "eval_episode/length": 189.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 90064, "time": 4497.806978702545, "eval_episode/length": 194.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 90064, "time": 4499.716122865677, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 90064, "time": 4502.210242271423, "eval_episode/length": 221.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 90272, "time": 4510.538001060486, "episode/length": 138.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 90376, "time": 4515.3743550777435, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 90560, "time": 4523.445321083069, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 91296, "time": 4549.911878585815, "episode/length": 157.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 91376, "time": 4554.135729551315, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 91472, "time": 4558.918491125107, "episode/length": 237.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 91824, "time": 4572.361405611038, "episode/length": 296.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 91872, "time": 4575.470948457718, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 91896, "time": 4577.557412624359, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 92264, "time": 4591.782049417496, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 92352, "time": 4596.579076766968, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 92640, "time": 4607.793769836426, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 92752, "time": 4613.2663633823395, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 93208, "time": 4630.215977907181, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 93504, "time": 4642.029498577118, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 93680, "time": 4649.6552147865295, "episode/length": 297.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9899328859060402, "episode/intrinsic_return": 0.0}
{"step": 93776, "time": 4654.515867471695, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 93800, "time": 4656.649188280106, "episode/length": 144.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 93888, "time": 4661.516511440277, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 93984, "time": 4666.460077524185, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 94176, "time": 4674.599254608154, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 94312, "time": 4680.50199842453, "episode/length": 52.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 94440, "time": 4686.447077512741, "episode/length": 116.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 94856, "time": 4701.967180252075, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 95248, "time": 4716.781183481216, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 95336, "time": 4721.081098556519, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 95400, "time": 4724.747937917709, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 95400, "time": 4724.757276535034, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 95488, "time": 4731.351383686066, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 95616, "time": 4737.248098611832, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 95760, "time": 4743.6789610385895, "episode/length": 44.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 95848, "time": 4748.016385555267, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 95936, "time": 4752.704767227173, "episode/length": 186.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 96552, "time": 4774.742973327637, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 96696, "time": 4781.08488368988, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 96992, "time": 4792.924088716507, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 97024, "time": 4795.662324428558, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 97120, "time": 4800.569178104401, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 97120, "time": 4800.578685760498, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 97256, "time": 4808.304342508316, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 97848, "time": 4829.751683712006, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 98240, "time": 4844.82909822464, "episode/length": 192.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 98432, "time": 4854.2882397174835, "episode/length": 146.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 98488, "time": 4857.480313777924, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 98544, "time": 4861.171527147293, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 98608, "time": 4864.914123773575, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 98608, "time": 4864.924228191376, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 98704, "time": 4871.2249500751495, "episode/length": 33.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 98976, "time": 4882.17834353447, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 99448, "time": 4899.221413135529, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 99744, "time": 4910.920064687729, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 99912, "time": 4917.904289722443, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4944.232216596603, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 100048, "time": 4946.059356212616, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 100048, "time": 4948.923615217209, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9633507853403142}
{"step": 100048, "time": 4950.747979879379, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 100048, "time": 4952.518980026245, "eval_episode/length": 195.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 100048, "time": 4954.522977113724, "eval_episode/length": 43.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 100048, "time": 4956.163603782654, "eval_episode/length": 205.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 100048, "time": 4958.49235701561, "eval_episode/length": 221.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 100240, "time": 4964.936441421509, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 100288, "time": 4968.031795501709, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 100336, "time": 4971.284647464752, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 100360, "time": 4973.455479621887, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 100384, "time": 4976.073623418808, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 100856, "time": 4993.196569919586, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 100920, "time": 4997.045815944672, "episode/length": 125.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 101344, "time": 5013.199790716171, "episode/length": 199.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 101632, "time": 5024.547589063644, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 101632, "time": 5024.557281255722, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 101752, "time": 5031.691946744919, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 102280, "time": 5051.137408733368, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 102608, "time": 5064.133313655853, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 102680, "time": 5068.001865148544, "episode/length": 49.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 102736, "time": 5071.733095407486, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 102872, "time": 5077.658012628555, "episode/length": 313.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904458598726115, "episode/intrinsic_return": 0.0}
{"step": 102936, "time": 5081.396494150162, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 103064, "time": 5087.3940415382385, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 103088, "time": 5090.208778381348, "episode/length": 166.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 103160, "time": 5093.986111402512, "episode/length": 226.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 103464, "time": 5105.791902542114, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 104024, "time": 5126.217092752457, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 104120, "time": 5131.06547164917, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 104288, "time": 5138.693695068359, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 104288, "time": 5138.702878475189, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 104352, "time": 5144.230708122253, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 104456, "time": 5149.080030441284, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 104768, "time": 5161.396069765091, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 104880, "time": 5166.710540533066, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 105224, "time": 5179.862105846405, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.0}
{"step": 105536, "time": 5192.179147481918, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 105552, "time": 5194.373358249664, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 105608, "time": 5197.622929811478, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 105616, "time": 5200.20861697197, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 105800, "time": 5208.175563335419, "episode/length": 167.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 105856, "time": 5211.9084005355835, "episode/length": 121.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 105888, "time": 5214.562740802765, "episode/length": 41.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 105992, "time": 5219.345161676407, "episode/length": 56.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 106416, "time": 5235.359214067459, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 106472, "time": 5238.721130132675, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 106808, "time": 5252.855878353119, "episode/length": 41.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 107024, "time": 5262.050754308701, "episode/length": 176.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 107032, "time": 5263.739070892334, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 107120, "time": 5268.404819965363, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 107176, "time": 5271.820709228516, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 107712, "time": 5291.554510593414, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 107784, "time": 5295.292260885239, "episode/length": 247.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 108448, "time": 5319.417974472046, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 108552, "time": 5324.727212429047, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 108584, "time": 5327.391968727112, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 108776, "time": 5335.5394287109375, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 108952, "time": 5343.04276061058, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 109056, "time": 5348.263611078262, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 109240, "time": 5355.854966402054, "episode/length": 276.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9891696750902527, "episode/intrinsic_return": 0.0}
{"step": 109264, "time": 5358.464990615845, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 109577, "time": 5371.3084354400635, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.795454261946852, "train/action_min": 0.0, "train/action_std": 3.350391713372112, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05590088592067252, "train/actor_opt_grad_steps": 6070.0, "train/actor_opt_loss": 13.610763702949468, "train/adv_mag": 1.0047636810880507, "train/adv_max": 1.0015015950168136, "train/adv_mean": 0.006707868930795757, "train/adv_min": -0.4994284234342784, "train/adv_std": 0.09400491889593375, "train/cont_avg": 0.9944257527372263, "train/cont_loss_mean": 0.0009207230995369432, "train/cont_loss_std": 0.020514657115199952, "train/cont_neg_acc": 0.9773259210760576, "train/cont_neg_loss": 0.08131939020852165, "train/cont_pos_acc": 0.999834763307641, "train/cont_pos_loss": 0.0005178983192466344, "train/cont_pred": 0.9943664935383484, "train/cont_rate": 0.9944257527372263, "train/dyn_loss_mean": 12.40289864922962, "train/dyn_loss_std": 8.207518271286123, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.319860343515438, "train/extr_critic_critic_opt_grad_steps": 6070.0, "train/extr_critic_critic_opt_loss": 15360.014349053376, "train/extr_critic_mag": 3.1080195242471067, "train/extr_critic_max": 3.1080195242471067, "train/extr_critic_mean": 0.8102251006303912, "train/extr_critic_min": -0.11584481270643916, "train/extr_critic_std": 0.7558803414776377, "train/extr_return_normed_mag": 2.0035849531201553, "train/extr_return_normed_max": 2.0035849531201553, "train/extr_return_normed_mean": 0.352286669242121, "train/extr_return_normed_min": -0.15500607678707498, "train/extr_return_normed_std": 0.3372333746974486, "train/extr_return_rate": 0.5217243835438777, "train/extr_return_raw_mag": 4.745896391624952, "train/extr_return_raw_max": 4.745896391624952, "train/extr_return_raw_mean": 0.8261789120461819, "train/extr_return_raw_min": -0.3791710101339939, "train/extr_return_raw_std": 0.8007808488650914, "train/extr_reward_mag": 1.0069320262783634, "train/extr_reward_max": 1.0069320262783634, "train/extr_reward_mean": 0.01622654806931306, "train/extr_reward_min": -0.28049685224129334, "train/extr_reward_std": 0.10807077124388549, "train/image_loss_mean": 16.749353527152625, "train/image_loss_std": 16.71849544552991, "train/model_loss_mean": 24.24952163139399, "train/model_loss_std": 20.244557603432312, "train/model_opt_grad_norm": 101.55660916070869, "train/model_opt_grad_steps": 6060.481751824817, "train/model_opt_loss": 15493.555927805657, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 638.6861313868613, "train/policy_entropy_mag": 2.3147868396591966, "train/policy_entropy_max": 2.3147868396591966, "train/policy_entropy_mean": 0.6743943739111407, "train/policy_entropy_min": 0.07938620796168808, "train/policy_entropy_std": 0.4943866914641248, "train/policy_logprob_mag": 7.438291323446009, "train/policy_logprob_max": -0.009457679696544244, "train/policy_logprob_mean": -0.6741567210559427, "train/policy_logprob_min": -7.438291323446009, "train/policy_logprob_std": 1.1247705847677523, "train/policy_randomness_mag": 0.817018171731573, "train/policy_randomness_max": 0.817018171731573, "train/policy_randomness_mean": 0.23803161802518108, "train/policy_randomness_min": 0.028019847579463554, "train/policy_randomness_std": 0.1744968074299123, "train/post_ent_mag": 49.940233857092196, "train/post_ent_max": 49.940233857092196, "train/post_ent_mean": 35.692420346893535, "train/post_ent_min": 19.298534490766315, "train/post_ent_std": 5.22816594325713, "train/prior_ent_mag": 61.103533083505006, "train/prior_ent_max": 61.103533083505006, "train/prior_ent_mean": 48.28775854180329, "train/prior_ent_min": 26.00270741873414, "train/prior_ent_std": 6.121407909114866, "train/rep_loss_mean": 12.40289864922962, "train/rep_loss_std": 8.207518271286123, "train/reward_avg": 0.01464059633155265, "train/reward_loss_mean": 0.05750826596669907, "train/reward_loss_std": 0.2963091421083812, "train/reward_max_data": 1.0094890533572567, "train/reward_max_pred": 1.0027583202306372, "train/reward_neg_acc": 0.993603414427625, "train/reward_neg_loss": 0.03661596957240661, "train/reward_pos_acc": 0.9151520768221277, "train/reward_pos_loss": 1.1054152524384269, "train/reward_pred": 0.013758834650277765, "train/reward_rate": 0.01971658302919708, "train_stats/sum_log_reward": 3.7974789535798945, "train_stats/max_log_achievement_collect_drink": 6.773109243697479, "train_stats/max_log_achievement_collect_sapling": 1.8571428571428572, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.4201680672268906, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.31932773109243695, "train_stats/max_log_achievement_eat_cow": 0.05042016806722689, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01680672268907563, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6974789915966386, "train_stats/max_log_achievement_place_table": 0.7058823529411765, "train_stats/max_log_achievement_wake_up": 1.7478991596638656, "train_stats/mean_log_entropy": 0.7001058767322733, "eval_stats/sum_log_reward": 3.974999949336052, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_table": 0.625, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.6638255803845823e-05, "report/cont_loss_std": 0.0007113816682249308, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004538504872471094, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.5727603037448716e-08, "report/cont_pred": 0.994166910648346, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.985904693603516, "report/dyn_loss_std": 8.366534233093262, "report/image_loss_mean": 14.88251781463623, "report/image_loss_std": 13.860481262207031, "report/model_loss_mean": 23.319210052490234, "report/model_loss_std": 17.487789154052734, "report/post_ent_mag": 55.39234161376953, "report/post_ent_max": 55.39234161376953, "report/post_ent_mean": 36.02740478515625, "report/post_ent_min": 19.89763641357422, "report/post_ent_std": 5.688891410827637, "report/prior_ent_mag": 62.16173553466797, "report/prior_ent_max": 62.16173553466797, "report/prior_ent_mean": 49.974727630615234, "report/prior_ent_min": 26.35780143737793, "report/prior_ent_std": 6.29567813873291, "report/rep_loss_mean": 13.985904693603516, "report/rep_loss_std": 8.366534233093262, "report/reward_avg": 0.01435546763241291, "report/reward_loss_mean": 0.04512101039290428, "report/reward_loss_std": 0.21868568658828735, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0000629425048828, "report/reward_neg_acc": 0.9960119724273682, "report/reward_neg_loss": 0.024849101901054382, "report/reward_pos_acc": 0.9047619104385376, "report/reward_pos_loss": 1.0133459568023682, "report/reward_pred": 0.01117847952991724, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 4.7491377586084127e-07, "eval/cont_loss_std": 1.0943499546556268e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003276379720773548, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.551062638327494e-07, "eval/cont_pred": 0.9990236163139343, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.598634719848633, "eval/dyn_loss_std": 8.250944137573242, "eval/image_loss_mean": 22.48443603515625, "eval/image_loss_std": 18.008447647094727, "eval/model_loss_mean": 32.494293212890625, "eval/model_loss_std": 21.315353393554688, "eval/post_ent_mag": 46.82186508178711, "eval/post_ent_max": 46.82186508178711, "eval/post_ent_mean": 34.59681701660156, "eval/post_ent_min": 20.48114776611328, "eval/post_ent_std": 5.085320472717285, "eval/prior_ent_mag": 62.16173553466797, "eval/prior_ent_max": 62.16173553466797, "eval/prior_ent_mean": 47.776920318603516, "eval/prior_ent_min": 23.9080753326416, "eval/prior_ent_std": 7.276869773864746, "eval/rep_loss_mean": 16.598634719848633, "eval/rep_loss_std": 8.250944137573242, "eval/reward_avg": 0.011035156436264515, "eval/reward_loss_mean": 0.05067729204893112, "eval/reward_loss_std": 0.3976985216140747, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.998322606086731, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.025238828733563423, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.0290069580078125, "eval/reward_pred": 0.004757381044328213, "eval/reward_rate": 0.0126953125, "replay/size": 109073.0, "replay/inserts": 21800.0, "replay/samples": 21808.0, "replay/insert_wait_avg": 1.490717634148554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.013507966162611e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20648.0, "eval_replay/inserts": 3552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3939297951019562e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.279491186142, "timer/env.step_count": 2725.0, "timer/env.step_total": 263.5842206478119, "timer/env.step_frac": 0.2635105717655482, "timer/env.step_avg": 0.0967281543661695, "timer/env.step_min": 0.022566556930541992, "timer/env.step_max": 3.407723903656006, "timer/replay._sample_count": 21808.0, "timer/replay._sample_total": 12.133250951766968, "timer/replay._sample_frac": 0.012129860762594693, "timer/replay._sample_avg": 0.0005563669732101508, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.025143146514892578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3169.0, "timer/agent.policy_total": 53.93489456176758, "timer/agent.policy_frac": 0.05391982444607658, "timer/agent.policy_avg": 0.017019531259630034, "timer/agent.policy_min": 0.00964212417602539, "timer/agent.policy_max": 0.10427474975585938, "timer/dataset_train_count": 1363.0, "timer/dataset_train_total": 0.15198016166687012, "timer/dataset_train_frac": 0.00015193769641987806, "timer/dataset_train_avg": 0.00011150415382749091, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0006005764007568359, "timer/agent.train_count": 1363.0, "timer/agent.train_total": 616.4208090305328, "timer/agent.train_frac": 0.6162485729859107, "timer/agent.train_avg": 0.4522529780121297, "timer/agent.train_min": 0.43726062774658203, "timer/agent.train_max": 1.4723544120788574, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4804701805114746, "timer/agent.report_frac": 0.00048033593085241406, "timer/agent.report_avg": 0.2402350902557373, "timer/agent.report_min": 0.23395490646362305, "timer/agent.report_max": 0.24651527404785156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.933906555175781e-05, "timer/dataset_eval_frac": 3.932807370179022e-08, "timer/dataset_eval_avg": 3.933906555175781e-05, "timer/dataset_eval_min": 3.933906555175781e-05, "timer/dataset_eval_max": 3.933906555175781e-05, "fps": 21.793632033887118}
{"step": 110032, "time": 5400.885055541992, "eval_episode/length": 28.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8275862068965517}
{"step": 110032, "time": 5407.101003408432, "eval_episode/length": 137.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 110032, "time": 5409.2718937397, "eval_episode/length": 150.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 110032, "time": 5411.355430364609, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 110032, "time": 5413.6399784088135, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 110032, "time": 5416.460597515106, "eval_episode/length": 176.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 110032, "time": 5420.033601522446, "eval_episode/length": 247.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758064516129032}
{"step": 110032, "time": 5422.641699790955, "eval_episode/length": 273.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9854014598540146}
{"step": 110040, "time": 5422.694416761398, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 110128, "time": 5427.493528366089, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 110288, "time": 5434.526298046112, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 110336, "time": 5437.713890314102, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 110848, "time": 5456.652680635452, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 111000, "time": 5463.130977392197, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 111008, "time": 5465.158490896225, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 111160, "time": 5471.664242506027, "episode/length": 297.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9899328859060402, "episode/intrinsic_return": 0.0}
{"step": 111832, "time": 5495.8437242507935, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 111880, "time": 5498.951301813126, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 112208, "time": 5511.890722751617, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 112240, "time": 5514.536127328873, "episode/length": 134.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 112416, "time": 5521.978106021881, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 112464, "time": 5525.1538169384, "episode/length": 291.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 112888, "time": 5540.748442173004, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 113056, "time": 5548.16743183136, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 113160, "time": 5552.950380086899, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 113168, "time": 5555.000710964203, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 113184, "time": 5557.130594968796, "episode/length": 36.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 113616, "time": 5573.19567990303, "episode/length": 143.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 113752, "time": 5579.0769164562225, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 114016, "time": 5589.595295906067, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 114064, "time": 5592.861787319183, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 114320, "time": 5603.1482055187225, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 114448, "time": 5609.1305911540985, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 114456, "time": 5610.7391793727875, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 114712, "time": 5622.32924079895, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 114872, "time": 5629.505828619003, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 115168, "time": 5641.155452489853, "episode/length": 176.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 115216, "time": 5644.3739104270935, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 115328, "time": 5649.727302789688, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 115504, "time": 5657.201389074326, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 115704, "time": 5665.707192659378, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 115832, "time": 5671.671169042587, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 115976, "time": 5678.11957859993, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 116040, "time": 5681.926101922989, "episode/length": 41.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 116064, "time": 5684.555011034012, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 116216, "time": 5691.32822227478, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 116528, "time": 5703.488783836365, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 116800, "time": 5714.136583566666, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 116800, "time": 5714.145574808121, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 116872, "time": 5719.730050802231, "episode/length": 249.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 117352, "time": 5737.200484037399, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 117624, "time": 5747.8405656814575, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 118032, "time": 5763.39478635788, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 118184, "time": 5769.919601202011, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 118184, "time": 5769.929886102676, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 118248, "time": 5775.498139381409, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 118352, "time": 5780.815490961075, "episode/length": 227.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 118360, "time": 5782.42773103714, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 118624, "time": 5793.11589217186, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 118656, "time": 5795.5693526268005, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 119040, "time": 5809.983945846558, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 119520, "time": 5827.474651098251, "episode/length": 145.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 119616, "time": 5832.201809644699, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 119624, "time": 5833.909674882889, "episode/length": 179.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 119808, "time": 5841.834403991699, "episode/length": 194.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 119976, "time": 5848.764639139175, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5872.107366323471, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 120016, "time": 5875.968846321106, "eval_episode/length": 181.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 120016, "time": 5877.872727632523, "eval_episode/length": 189.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 120016, "time": 5879.406068086624, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 120016, "time": 5879.4121260643005, "eval_episode/length": 34.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 120016, "time": 5882.948976516724, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 120016, "time": 5884.959460020065, "eval_episode/length": 207.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 120016, "time": 5886.84704709053, "eval_episode/length": 211.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 120056, "time": 5887.9589767456055, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 120264, "time": 5896.364444971085, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 120520, "time": 5906.389575958252, "episode/length": 31.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 120536, "time": 5908.474823951721, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 121096, "time": 5928.892633676529, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 121104, "time": 5930.988397836685, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 121136, "time": 5933.649183988571, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 121184, "time": 5936.859801530838, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 121304, "time": 5942.3550481796265, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 121472, "time": 5949.705389738083, "episode/length": 35.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 121720, "time": 5959.320213317871, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 121720, "time": 5959.329871177673, "episode/length": 207.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 121800, "time": 5965.309820890427, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 122256, "time": 5982.126336812973, "episode/length": 118.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 122416, "time": 5989.246607303619, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 122432, "time": 5991.254599332809, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 122888, "time": 6008.071950435638, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 123312, "time": 6025.278347730637, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 123488, "time": 6032.612174272537, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 123624, "time": 6038.408604621887, "episode/length": 38.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 123744, "time": 6044.095678091049, "episode/length": 283.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 123880, "time": 6050.058044433594, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 123976, "time": 6054.76326751709, "episode/length": 281.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 124136, "time": 6061.5501918792725, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 124352, "time": 6070.6018850803375, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 124888, "time": 6089.84899187088, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 125128, "time": 6099.412913560867, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 125184, "time": 6103.022905826569, "episode/length": 150.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 125208, "time": 6105.188643455505, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 125672, "time": 6122.318983793259, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 125672, "time": 6122.328311681747, "episode/length": 191.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 126072, "time": 6139.184796094894, "episode/length": 273.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 126184, "time": 6144.5033638477325, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 126264, "time": 6148.7278881073, "episode/length": 346.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 126512, "time": 6158.911191940308, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 126576, "time": 6162.519973516464, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 127024, "time": 6179.121080636978, "episode/length": 55.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 127032, "time": 6180.768982410431, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 127168, "time": 6187.06525850296, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 127344, "time": 6194.415190935135, "episode/length": 158.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 127408, "time": 6198.127359628677, "episode/length": 46.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 127600, "time": 6206.1321675777435, "episode/length": 23.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 127880, "time": 6217.015366792679, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 127952, "time": 6221.318466186523, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 128024, "time": 6225.070612192154, "episode/length": 52.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 128216, "time": 6233.280645370483, "episode/length": 130.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 128352, "time": 6239.643171787262, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 128416, "time": 6243.601134061813, "episode/length": 400.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9925187032418953, "episode/intrinsic_return": 0.0}
{"step": 128632, "time": 6252.139698505402, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 129224, "time": 6273.471385717392, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 129240, "time": 6275.675975322723, "episode/length": 110.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 129312, "time": 6279.798631668091, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 129752, "time": 6296.218093633652, "episode/length": 224.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 129784, "time": 6298.810668468475, "episode/length": 439.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 129968, "time": 6306.842520236969, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6329.532085180283, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 130000, "time": 6331.5117127895355, "eval_episode/length": 165.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9879518072289156}
{"step": 130000, "time": 6333.404046535492, "eval_episode/length": 173.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 130000, "time": 6336.164327144623, "eval_episode/length": 202.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 130000, "time": 6338.146604776382, "eval_episode/length": 213.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 130000, "time": 6340.397279500961, "eval_episode/length": 224.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 130000, "time": 6344.072516441345, "eval_episode/length": 272.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 130000, "time": 6346.620543956757, "eval_episode/length": 139.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 130256, "time": 6355.276846647263, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 130400, "time": 6361.733550786972, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 130608, "time": 6370.317046403885, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 130609, "time": 6372.485556364059, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6156886442927005, "train/action_min": 0.0, "train/action_std": 3.084110740486902, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05623521553423568, "train/actor_opt_grad_steps": 7410.0, "train/actor_opt_loss": 9.975620295710236, "train/adv_mag": 0.9556467628661003, "train/adv_max": 0.9552268008239396, "train/adv_mean": 0.005959491925250751, "train/adv_min": -0.4926523666345436, "train/adv_std": 0.09061327599387133, "train/cont_avg": 0.9944164479961832, "train/cont_loss_mean": 0.0005760563418093382, "train/cont_loss_std": 0.016317664878935816, "train/cont_neg_acc": 0.9845753080062284, "train/cont_neg_loss": 0.04572378359187094, "train/cont_pos_acc": 0.9999174361920539, "train/cont_pos_loss": 0.0003092675169749737, "train/cont_pred": 0.9943790767939036, "train/cont_rate": 0.9944164479961832, "train/dyn_loss_mean": 13.628605966349594, "train/dyn_loss_std": 8.390280486973188, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.154313806814092, "train/extr_critic_critic_opt_grad_steps": 7410.0, "train/extr_critic_critic_opt_loss": 15439.673544847328, "train/extr_critic_mag": 3.3942267548946936, "train/extr_critic_max": 3.3942267548946936, "train/extr_critic_mean": 0.876230732857726, "train/extr_critic_min": -0.14518136741550824, "train/extr_critic_std": 0.8182426481756545, "train/extr_return_normed_mag": 1.923027012184376, "train/extr_return_normed_max": 1.923027012184376, "train/extr_return_normed_mean": 0.35843623275975234, "train/extr_return_normed_min": -0.15639458340770415, "train/extr_return_normed_std": 0.33699982596262723, "train/extr_return_rate": 0.5459297740732441, "train/extr_return_raw_mag": 4.891396467922298, "train/extr_return_raw_max": 4.891396467922298, "train/extr_return_raw_mean": 0.8914468795743608, "train/extr_return_raw_min": -0.42525201990404204, "train/extr_return_raw_std": 0.8620448872333265, "train/extr_reward_mag": 1.0097661091171148, "train/extr_reward_max": 1.0097661091171148, "train/extr_reward_mean": 0.01772564927556815, "train/extr_reward_min": -0.2865495608963129, "train/extr_reward_std": 0.11542362833523569, "train/image_loss_mean": 14.906593453793125, "train/image_loss_std": 15.837993614546216, "train/model_loss_mean": 23.1412416268851, "train/model_loss_std": 19.406215929803047, "train/model_opt_grad_norm": 98.87269312734823, "train/model_opt_grad_steps": 7399.320610687023, "train/model_opt_loss": 15906.450523318224, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 687.0229007633587, "train/policy_entropy_mag": 2.32810111446235, "train/policy_entropy_max": 2.32810111446235, "train/policy_entropy_mean": 0.5998964908013817, "train/policy_entropy_min": 0.07937865533674036, "train/policy_entropy_std": 0.4739194098319716, "train/policy_logprob_mag": 7.438352078881882, "train/policy_logprob_max": -0.009456471582689812, "train/policy_logprob_mean": -0.6007323742822837, "train/policy_logprob_min": -7.438352078881882, "train/policy_logprob_std": 1.08745552110308, "train/policy_randomness_mag": 0.8217175279864828, "train/policy_randomness_max": 0.8217175279864828, "train/policy_randomness_mean": 0.21173713384693815, "train/policy_randomness_min": 0.028017181874686527, "train/policy_randomness_std": 0.16727275520790624, "train/post_ent_mag": 51.47511180848566, "train/post_ent_max": 51.47511180848566, "train/post_ent_mean": 36.30017980910439, "train/post_ent_min": 19.534624245330576, "train/post_ent_std": 5.662870254225403, "train/prior_ent_mag": 62.13167653556999, "train/prior_ent_max": 62.13167653556999, "train/prior_ent_mean": 50.07989068067711, "train/prior_ent_min": 28.037618476925914, "train/prior_ent_std": 5.74795928984198, "train/rep_loss_mean": 13.628605966349594, "train/rep_loss_std": 8.390280486973188, "train/reward_avg": 0.016113281017169356, "train/reward_loss_mean": 0.05690862467327646, "train/reward_loss_std": 0.28345047654086397, "train/reward_max_data": 1.0190839740156217, "train/reward_max_pred": 1.0041318567654558, "train/reward_neg_acc": 0.9934773103881428, "train/reward_neg_loss": 0.03501344152249908, "train/reward_pos_acc": 0.9198040284273279, "train/reward_pos_loss": 1.0736374258995056, "train/reward_pred": 0.01491799744429024, "train/reward_rate": 0.021208552003816793, "eval_stats/sum_log_reward": 3.9333332628011703, "eval_stats/max_log_achievement_collect_drink": 5.583333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.4166666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.8333333333333335, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.2916666666666665, "eval_stats/max_log_achievement_place_table": 0.9166666666666666, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 4.16896545090552, "train_stats/max_log_achievement_collect_drink": 4.5344827586206895, "train_stats/max_log_achievement_collect_sapling": 2.810344827586207, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6551724137931036, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.31896551724137934, "train_stats/max_log_achievement_eat_cow": 0.09482758620689655, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008620689655172414, "train_stats/max_log_achievement_place_plant": 2.6982758620689653, "train_stats/max_log_achievement_place_table": 0.9224137931034483, "train_stats/max_log_achievement_wake_up": 1.7241379310344827, "train_stats/mean_log_entropy": 0.5873410218748553, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 8.731285197427496e-05, "report/cont_loss_std": 0.0013221895787864923, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0016876943409442902, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.62974304961972e-05, "report/cont_pred": 0.993100643157959, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.972103118896484, "report/dyn_loss_std": 8.771719932556152, "report/image_loss_mean": 14.305521011352539, "report/image_loss_std": 17.269018173217773, "report/model_loss_mean": 22.74927520751953, "report/model_loss_std": 21.107467651367188, "report/post_ent_mag": 50.501731872558594, "report/post_ent_max": 50.501731872558594, "report/post_ent_mean": 37.46876525878906, "report/post_ent_min": 18.801950454711914, "report/post_ent_std": 5.978724956512451, "report/prior_ent_mag": 62.93424987792969, "report/prior_ent_max": 62.93424987792969, "report/prior_ent_mean": 50.55280303955078, "report/prior_ent_min": 28.555137634277344, "report/prior_ent_std": 5.320741653442383, "report/rep_loss_mean": 13.972103118896484, "report/rep_loss_std": 8.771719932556152, "report/reward_avg": 0.011132813058793545, "report/reward_loss_mean": 0.06040409952402115, "report/reward_loss_std": 0.2912319600582123, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0049071311950684, "report/reward_neg_acc": 0.9980139136314392, "report/reward_neg_loss": 0.041945818811655045, "report/reward_pos_acc": 0.8823529481887817, "report/reward_pos_loss": 1.153786063194275, "report/reward_pred": 0.009358315728604794, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0023738218005746603, "eval/cont_loss_std": 0.07474216818809509, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.7979575991630554, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.6161462048767135e-05, "eval/cont_pred": 0.9979233145713806, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.47454833984375, "eval/dyn_loss_std": 8.14661693572998, "eval/image_loss_mean": 21.55077362060547, "eval/image_loss_std": 22.689260482788086, "eval/model_loss_mean": 32.11386489868164, "eval/model_loss_std": 25.760059356689453, "eval/post_ent_mag": 47.02955627441406, "eval/post_ent_max": 47.02955627441406, "eval/post_ent_mean": 35.63603591918945, "eval/post_ent_min": 20.701560974121094, "eval/post_ent_std": 4.573116302490234, "eval/prior_ent_mag": 62.93424987792969, "eval/prior_ent_max": 62.93424987792969, "eval/prior_ent_mean": 49.52655792236328, "eval/prior_ent_min": 26.485855102539062, "eval/prior_ent_std": 6.099721431732178, "eval/rep_loss_mean": 17.47454833984375, "eval/rep_loss_std": 8.14661693572998, "eval/reward_avg": 0.008105468936264515, "eval/reward_loss_mean": 0.0759880468249321, "eval/reward_loss_std": 0.5635334849357605, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9989950656890869, "eval/reward_neg_acc": 0.9980237483978271, "eval/reward_neg_loss": 0.03983994945883751, "eval/reward_pos_acc": 0.5833333730697632, "eval/reward_pos_loss": 3.1244773864746094, "eval/reward_pred": 0.003003857098519802, "eval/reward_rate": 0.01171875, "replay/size": 130105.0, "replay/inserts": 21032.0, "replay/samples": 21024.0, "replay/insert_wait_avg": 1.4414393706845894e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.069409181719683e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26928.0, "eval_replay/inserts": 6280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2518493992507838e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1639177799225, "timer/env.step_count": 2629.0, "timer/env.step_total": 254.06817317008972, "timer/env.step_frac": 0.2537728024932071, "timer/env.step_avg": 0.09664061360596794, "timer/env.step_min": 0.022499561309814453, "timer/env.step_max": 3.4544837474823, "timer/replay._sample_count": 21024.0, "timer/replay._sample_total": 11.261553049087524, "timer/replay._sample_frac": 0.011248460765605676, "timer/replay._sample_avg": 0.0005356522569010428, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.008554458618164062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3414.0, "timer/agent.policy_total": 56.9866783618927, "timer/agent.policy_frac": 0.05692042766409367, "timer/agent.policy_avg": 0.016692055759195284, "timer/agent.policy_min": 0.009319543838500977, "timer/agent.policy_max": 0.09110355377197266, "timer/dataset_train_count": 1314.0, "timer/dataset_train_total": 0.1488208770751953, "timer/dataset_train_frac": 0.00014864786318428763, "timer/dataset_train_avg": 0.00011325789731750024, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0002815723419189453, "timer/agent.train_count": 1314.0, "timer/agent.train_total": 590.3143832683563, "timer/agent.train_frac": 0.589628104633831, "timer/agent.train_avg": 0.4492499111631327, "timer/agent.train_min": 0.4355204105377197, "timer/agent.train_max": 1.4935698509216309, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769904613494873, "timer/agent.report_frac": 0.0004764359291006132, "timer/agent.report_avg": 0.23849523067474365, "timer/agent.report_min": 0.23134112358093262, "timer/agent.report_max": 0.2456493377685547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.524492750925115e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 21.00727418189153}
{"step": 130664, "time": 6374.404276132584, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 131032, "time": 6388.676624536514, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 131160, "time": 6395.931059122086, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 131464, "time": 6407.590605735779, "episode/length": 429.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 131488, "time": 6410.425715208054, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 131664, "time": 6417.891979217529, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 131920, "time": 6428.0467228889465, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 131944, "time": 6430.184751749039, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 132456, "time": 6449.0475442409515, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 132512, "time": 6452.768578529358, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567567567567568, "episode/intrinsic_return": 0.0}
{"step": 132520, "time": 6454.353287220001, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 132760, "time": 6463.934419870377, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 132760, "time": 6463.9423105716705, "episode/length": 30.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 132856, "time": 6470.527432441711, "episode/length": 170.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 133024, "time": 6478.517389059067, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 133048, "time": 6480.6413362026215, "episode/length": 35.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 133304, "time": 6490.845162391663, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 133312, "time": 6492.898530960083, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 133560, "time": 6502.532044410706, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 134088, "time": 6521.649211645126, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 134232, "time": 6528.131844997406, "episode/length": 183.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 134288, "time": 6531.955281257629, "episode/length": 121.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 134352, "time": 6535.714035511017, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 134432, "time": 6540.077392578125, "episode/length": 238.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 134472, "time": 6542.683095932007, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 134720, "time": 6552.794890403748, "episode/length": 53.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 134864, "time": 6559.251172542572, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 135048, "time": 6566.669772386551, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 135072, "time": 6569.206916093826, "episode/length": 104.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 135384, "time": 6581.046140909195, "episode/length": 113.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 135392, "time": 6583.050400018692, "episode/length": 39.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 135832, "time": 6599.036654949188, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 135832, "time": 6599.046369552612, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 135864, "time": 6603.4383363723755, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 136096, "time": 6612.922216176987, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 136160, "time": 6616.770778179169, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 136336, "time": 6624.329395532608, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 136360, "time": 6626.481307506561, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 136544, "time": 6634.420915365219, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 136960, "time": 6649.846071243286, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 137312, "time": 6663.114688873291, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 137456, "time": 6669.3908433914185, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 137600, "time": 6675.742790222168, "episode/length": 35.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 137640, "time": 6678.467785358429, "episode/length": 136.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 137776, "time": 6684.92303609848, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 137928, "time": 6691.422593593597, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 138040, "time": 6696.688319683075, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 138048, "time": 6698.8545553684235, "episode/length": 213.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 138072, "time": 6701.0106790065765, "episode/length": 76.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.948051948051948, "episode/intrinsic_return": 0.0}
{"step": 138288, "time": 6710.011901140213, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 138616, "time": 6722.284261226654, "episode/length": 85.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9302325581395349, "episode/intrinsic_return": 0.0}
{"step": 139016, "time": 6737.225431919098, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 139160, "time": 6743.651163101196, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 139288, "time": 6750.756633281708, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 139824, "time": 6770.520645141602, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 140080, "time": 6780.61363196373, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6801.485205411911, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 140088, "time": 6803.295826911926, "eval_episode/length": 159.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 140088, "time": 6805.526200532913, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 140088, "time": 6807.653594017029, "eval_episode/length": 29.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8333333333333334}
{"step": 140088, "time": 6809.527055740356, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 140088, "time": 6811.735082387924, "eval_episode/length": 211.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9858490566037735}
{"step": 140088, "time": 6813.6067888736725, "eval_episode/length": 218.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 140088, "time": 6817.358252763748, "eval_episode/length": 264.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 140104, "time": 6817.887986421585, "episode/length": 34.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 140120, "time": 6820.1128697395325, "episode/length": 255.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 140128, "time": 6822.195255756378, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 140696, "time": 6842.61162519455, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 140720, "time": 6845.112601041794, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 141480, "time": 6872.036224603653, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 141552, "time": 6876.271088600159, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 141768, "time": 6884.825289964676, "episode/length": 434.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 141824, "time": 6888.657366991043, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 141904, "time": 6892.933420658112, "episode/length": 326.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 141976, "time": 6896.740900039673, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 142160, "time": 6904.8211052417755, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 142232, "time": 6908.623272895813, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 142448, "time": 6917.513463020325, "episode/length": 120.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 143176, "time": 6943.153563976288, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 143184, "time": 6945.238728046417, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 143192, "time": 6946.781839609146, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 143384, "time": 6954.815775632858, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 143544, "time": 6961.656229019165, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 143568, "time": 6964.253049135208, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 143576, "time": 6965.842761993408, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 143680, "time": 6971.15251493454, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 144000, "time": 6983.4226360321045, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 144304, "time": 6995.041583299637, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 144344, "time": 6997.698096036911, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 144696, "time": 7011.07247543335, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 144800, "time": 7016.350535392761, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 144928, "time": 7022.212064266205, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 145040, "time": 7027.574784517288, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 145384, "time": 7040.51878118515, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 145488, "time": 7045.927240371704, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 145968, "time": 7063.695227861404, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 146232, "time": 7074.071015119553, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 146232, "time": 7074.080857515335, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 146440, "time": 7084.474759340286, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 146448, "time": 7086.521448135376, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 146776, "time": 7098.854492902756, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 146816, "time": 7102.379726409912, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 147312, "time": 7121.0872592926025, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 147512, "time": 7130.605374574661, "episode/length": 159.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 147528, "time": 7132.727559328079, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 147616, "time": 7137.463121891022, "episode/length": 408.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951100244498777, "episode/intrinsic_return": 0.0}
{"step": 147864, "time": 7146.999475002289, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 148080, "time": 7155.879616498947, "episode/length": 157.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 148152, "time": 7159.736157655716, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 148240, "time": 7164.393548488617, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 149040, "time": 7192.96830701828, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 149080, "time": 7195.60108423233, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 149080, "time": 7195.609705448151, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 149296, "time": 7206.399919748306, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 149464, "time": 7213.278589487076, "episode/length": 152.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 149544, "time": 7217.430375337601, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 149624, "time": 7221.740453958511, "episode/length": 192.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 149968, "time": 7234.895545959473, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 150000, "time": 7237.499291181564, "episode/length": 266.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7257.578518629074, "eval_episode/length": 68.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 150072, "time": 7261.674606084824, "eval_episode/length": 129.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9538461538461539}
{"step": 150072, "time": 7264.275917053223, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 150072, "time": 7266.1212248802185, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 150072, "time": 7269.0591497421265, "eval_episode/length": 191.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 150072, "time": 7270.894619703293, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 150072, "time": 7273.790652513504, "eval_episode/length": 232.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 150072, "time": 7275.898943662643, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 150400, "time": 7287.04206943512, "episode/length": 53.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 150560, "time": 7293.958437204361, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 150680, "time": 7299.912973165512, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 150824, "time": 7306.224843263626, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 150832, "time": 7308.252090454102, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 151144, "time": 7319.967250347137, "episode/length": 57.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 151368, "time": 7328.950783491135, "episode/length": 285.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 151768, "time": 7343.778913736343, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 151872, "time": 7349.109796285629, "episode/length": 321.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 151896, "time": 7351.40451669693, "episode/length": 132.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 152008, "time": 7356.644060373306, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 152136, "time": 7362.567218542099, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 152361, "time": 7372.617902517319, "train_stats/sum_log_reward": 4.099999971506072, "train_stats/max_log_achievement_collect_drink": 4.284552845528455, "train_stats/max_log_achievement_collect_sapling": 2.4471544715447155, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.991869918699187, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2601626016260163, "train_stats/max_log_achievement_eat_cow": 0.06504065040650407, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016260162601626018, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.341463414634146, "train_stats/max_log_achievement_place_table": 1.1544715447154472, "train_stats/max_log_achievement_wake_up": 2.065040650406504, "train_stats/mean_log_entropy": 0.5808853582153476, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.259100072524127, "train/action_min": 0.0, "train/action_std": 2.6885632346658146, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.053687052746467734, "train/actor_opt_grad_steps": 8745.0, "train/actor_opt_loss": 0.9993394044611383, "train/adv_mag": 0.9096886375371147, "train/adv_max": 0.9055380974622333, "train/adv_mean": 0.005004146452687136, "train/adv_min": -0.496767055024119, "train/adv_std": 0.08682097984916147, "train/cont_avg": 0.9944709329044118, "train/cont_loss_mean": 0.0006072483768421765, "train/cont_loss_std": 0.016746677094379735, "train/cont_neg_acc": 0.9783321689156925, "train/cont_neg_loss": 0.05995341377634384, "train/cont_pos_acc": 0.9999277451459099, "train/cont_pos_loss": 0.0002527064055740462, "train/cont_pred": 0.9944968298077583, "train/cont_rate": 0.9944709329044118, "train/dyn_loss_mean": 14.186876640600318, "train/dyn_loss_std": 8.495409372974844, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.198522270164069, "train/extr_critic_critic_opt_grad_steps": 8745.0, "train/extr_critic_critic_opt_loss": 15388.639002182905, "train/extr_critic_mag": 3.7517759309095493, "train/extr_critic_max": 3.7517759309095493, "train/extr_critic_mean": 0.8807784012135338, "train/extr_critic_min": -0.1610346094650381, "train/extr_critic_std": 0.8859525883899015, "train/extr_return_normed_mag": 1.895904804853832, "train/extr_return_normed_max": 1.895904804853832, "train/extr_return_normed_mean": 0.33294696788139205, "train/extr_return_normed_min": -0.16042701349429347, "train/extr_return_normed_std": 0.3342967888011652, "train/extr_return_rate": 0.4976792543688241, "train/extr_return_raw_mag": 5.256203518194311, "train/extr_return_raw_max": 5.256203518194311, "train/extr_return_raw_mean": 0.8946771078249988, "train/extr_return_raw_min": -0.4813601914793253, "train/extr_return_raw_std": 0.9324655993019834, "train/extr_reward_mag": 1.008894253303023, "train/extr_reward_max": 1.008894253303023, "train/extr_reward_mean": 0.018884771736338735, "train/extr_reward_min": -0.31839747726917267, "train/extr_reward_std": 0.12117773393059478, "train/image_loss_mean": 13.189790879978853, "train/image_loss_std": 14.99709153175354, "train/model_loss_mean": 21.756700417574713, "train/model_loss_std": 18.563780931865466, "train/model_opt_grad_norm": 91.90851466795978, "train/model_opt_grad_steps": 8733.39705882353, "train/model_opt_loss": 17897.97893928079, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 822.6102941176471, "train/policy_entropy_mag": 2.3781552262165966, "train/policy_entropy_max": 2.3781552262165966, "train/policy_entropy_mean": 0.6127987753819016, "train/policy_entropy_min": 0.0793771366314853, "train/policy_entropy_std": 0.5062419739277924, "train/policy_logprob_mag": 7.4383695756687835, "train/policy_logprob_max": -0.009456183761358261, "train/policy_logprob_mean": -0.6124275348642293, "train/policy_logprob_min": -7.4383695756687835, "train/policy_logprob_std": 1.1059588974013048, "train/policy_randomness_mag": 0.839384430909858, "train/policy_randomness_max": 0.839384430909858, "train/policy_randomness_mean": 0.21629107776371873, "train/policy_randomness_min": 0.028016645844806645, "train/policy_randomness_std": 0.17868120157543352, "train/post_ent_mag": 52.3639038029839, "train/post_ent_max": 52.3639038029839, "train/post_ent_mean": 36.67420959472656, "train/post_ent_min": 19.93526133368997, "train/post_ent_std": 5.934727521503673, "train/prior_ent_mag": 62.77455077451818, "train/prior_ent_max": 62.77455077451818, "train/prior_ent_mean": 51.07954841501572, "train/prior_ent_min": 30.14301811947542, "train/prior_ent_std": 5.410714300239787, "train/rep_loss_mean": 14.186876640600318, "train/rep_loss_std": 8.495409372974844, "train/reward_avg": 0.016692756106803083, "train/reward_loss_mean": 0.05417640590766335, "train/reward_loss_std": 0.2676806108039968, "train/reward_max_data": 1.013235297273187, "train/reward_max_pred": 1.004210666698568, "train/reward_neg_acc": 0.9939113320673213, "train/reward_neg_loss": 0.03329346234471921, "train/reward_pos_acc": 0.9394054141114739, "train/reward_pos_loss": 0.9934096625622582, "train/reward_pred": 0.015889993622241652, "train/reward_rate": 0.02177159926470588, "eval_stats/sum_log_reward": 4.162499941885471, "eval_stats/max_log_achievement_collect_drink": 4.0625, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.7646641481405823e-06, "report/cont_loss_std": 5.3794374252902344e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0017222176538780332, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.289194397548272e-08, "report/cont_pred": 0.9990251064300537, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 14.470270156860352, "report/dyn_loss_std": 8.62782096862793, "report/image_loss_mean": 10.589886665344238, "report/image_loss_std": 12.909605026245117, "report/model_loss_mean": 19.316234588623047, "report/model_loss_std": 16.764694213867188, "report/post_ent_mag": 48.08611297607422, "report/post_ent_max": 48.08611297607422, "report/post_ent_mean": 35.69942092895508, "report/post_ent_min": 17.896331787109375, "report/post_ent_std": 5.368242263793945, "report/prior_ent_mag": 62.72454071044922, "report/prior_ent_max": 62.72454071044922, "report/prior_ent_mean": 50.36158752441406, "report/prior_ent_min": 28.48599624633789, "report/prior_ent_std": 5.700314998626709, "report/rep_loss_mean": 14.470270156860352, "report/rep_loss_std": 8.62782096862793, "report/reward_avg": 0.02724609151482582, "report/reward_loss_mean": 0.044185589998960495, "report/reward_loss_std": 0.22950886189937592, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0019495487213135, "report/reward_neg_acc": 0.9939698576927185, "report/reward_neg_loss": 0.01956981047987938, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8887615203857422, "report/reward_pred": 0.02588691934943199, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.002054815646260977, "eval/cont_loss_std": 0.05711936205625534, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0013288292102515697, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0020583777222782373, "eval/cont_pred": 0.9940603971481323, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.51706314086914, "eval/dyn_loss_std": 9.084753036499023, "eval/image_loss_mean": 29.645832061767578, "eval/image_loss_std": 32.65347671508789, "eval/model_loss_mean": 40.807640075683594, "eval/model_loss_std": 36.35966110229492, "eval/post_ent_mag": 50.817161560058594, "eval/post_ent_max": 50.817161560058594, "eval/post_ent_mean": 37.254451751708984, "eval/post_ent_min": 20.543289184570312, "eval/post_ent_std": 5.234622955322266, "eval/prior_ent_mag": 62.72454071044922, "eval/prior_ent_max": 62.72454071044922, "eval/prior_ent_mean": 51.83819580078125, "eval/prior_ent_min": 29.06859588623047, "eval/prior_ent_std": 4.732307434082031, "eval/rep_loss_mean": 18.51706314086914, "eval/rep_loss_std": 9.084753036499023, "eval/reward_avg": 0.005664062686264515, "eval/reward_loss_mean": 0.049520645290613174, "eval/reward_loss_std": 0.3999996781349182, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9976514577865601, "eval/reward_neg_acc": 0.9990138411521912, "eval/reward_neg_loss": 0.029321759939193726, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.097687244415283, "eval/reward_pred": 0.0036778294015675783, "eval/reward_rate": 0.009765625, "replay/size": 151857.0, "replay/inserts": 21752.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.4342052527059742e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.827842333737542e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31024.0, "eval_replay/inserts": 4096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2185773812234402e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.118332862854, "timer/env.step_count": 2719.0, "timer/env.step_total": 268.4946961402893, "timer/env.step_frac": 0.26846292815343076, "timer/env.step_avg": 0.09874758960657937, "timer/env.step_min": 0.022214651107788086, "timer/env.step_max": 3.4615423679351807, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.302470207214355, "timer/replay._sample_frac": 0.011301132911803409, "timer/replay._sample_avg": 0.0005194149911403656, "timer/replay._sample_min": 0.00039505958557128906, "timer/replay._sample_max": 0.011110067367553711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3231.0, "timer/agent.policy_total": 53.31459045410156, "timer/agent.policy_frac": 0.05330828233243934, "timer/agent.policy_avg": 0.01650095650080519, "timer/agent.policy_min": 0.009278059005737305, "timer/agent.policy_max": 0.09935617446899414, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.14750146865844727, "timer/dataset_train_frac": 0.00014748401645255522, "timer/dataset_train_avg": 0.00010845696224885828, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0006983280181884766, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 611.744042634964, "timer/agent.train_frac": 0.6116716617760993, "timer/agent.train_avg": 0.44981179605512056, "timer/agent.train_min": 0.4368257522583008, "timer/agent.train_max": 1.5829286575317383, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47567248344421387, "timer/agent.report_frac": 0.00047561620241736205, "timer/agent.report_avg": 0.23783624172210693, "timer/agent.report_min": 0.23312926292419434, "timer/agent.report_max": 0.24254322052001953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.647372656205602e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 21.749141802618325}
{"step": 152504, "time": 7377.265378236771, "episode/length": 312.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 152752, "time": 7387.322129487991, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 152848, "time": 7392.129391670227, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 153184, "time": 7405.054066181183, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 153232, "time": 7408.30859708786, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 153336, "time": 7413.091302156448, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 153728, "time": 7428.138755321503, "episode/length": 48.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 153768, "time": 7430.867481708527, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 153944, "time": 7438.37083363533, "episode/length": 94.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 154144, "time": 7446.989119052887, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 154224, "time": 7451.239653587341, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 154264, "time": 7453.931595087051, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 154864, "time": 7475.854827880859, "episode/length": 136.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 155080, "time": 7484.4508402347565, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 155088, "time": 7486.534031867981, "episode/length": 401.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 155096, "time": 7488.158402681351, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 155176, "time": 7492.518199682236, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 155432, "time": 7503.445075511932, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 155488, "time": 7507.423195362091, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 156128, "time": 7531.750905752182, "episode/length": 247.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 156288, "time": 7538.68018913269, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 156408, "time": 7543.985271215439, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 156480, "time": 7548.185978412628, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 156552, "time": 7552.0462102890015, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 156664, "time": 7557.282840967178, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 157256, "time": 7578.745615005493, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 157376, "time": 7584.513700723648, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 157616, "time": 7594.1864647865295, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 157912, "time": 7605.504496335983, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 158080, "time": 7613.001702308655, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 158088, "time": 7614.727669000626, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 158232, "time": 7621.099831819534, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 158480, "time": 7631.178338527679, "episode/length": 137.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 158776, "time": 7642.470118761063, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 159024, "time": 7652.604129552841, "episode/length": 448.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955456570155902, "episode/intrinsic_return": 0.0}
{"step": 159216, "time": 7660.54923582077, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 159344, "time": 7666.446989059448, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 159408, "time": 7670.179713726044, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 159656, "time": 7679.767539978027, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7709.430136680603, "eval_episode/length": 31.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.96875}
{"step": 160056, "time": 7717.351699352264, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 160056, "time": 7719.95156955719, "eval_episode/length": 167.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 160056, "time": 7721.801124095917, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 160056, "time": 7724.286402463913, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 160056, "time": 7727.086709737778, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 160056, "time": 7729.219621419907, "eval_episode/length": 40.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 160056, "time": 7731.184880971909, "eval_episode/length": 213.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 160096, "time": 7732.756342172623, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 160296, "time": 7740.791293144226, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 160512, "time": 7749.82262635231, "episode/length": 303.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 160560, "time": 7753.015631914139, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 160680, "time": 7758.290887355804, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 160736, "time": 7762.071378946304, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 160880, "time": 7768.429428577423, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 161112, "time": 7777.5443387031555, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 161544, "time": 7793.533983945847, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 161696, "time": 7800.424562454224, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 161944, "time": 7810.54176402092, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 162232, "time": 7822.078884363174, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 162352, "time": 7827.92169880867, "episode/length": 50.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 162360, "time": 7829.53124499321, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 162432, "time": 7833.73090672493, "episode/length": 110.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 162464, "time": 7836.469936609268, "episode/length": 222.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 162472, "time": 7838.164151668549, "episode/length": 198.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 163488, "time": 7874.258999347687, "episode/length": 371.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 163672, "time": 7881.891948461533, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 163856, "time": 7891.283830404282, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 163872, "time": 7893.47123837471, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 163928, "time": 7896.783130645752, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 164320, "time": 7911.885524749756, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 164400, "time": 7916.1446578502655, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 164456, "time": 7919.426514387131, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 165088, "time": 7942.404648303986, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 165280, "time": 7950.594342470169, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 165688, "time": 7965.703289270401, "episode/length": 251.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 165768, "time": 7970.116646528244, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 166080, "time": 7983.297554016113, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 166416, "time": 7996.009628772736, "episode/length": 244.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 166704, "time": 8007.198703050613, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 166864, "time": 8014.030923128128, "episode/length": 221.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 167216, "time": 8027.5964596271515, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 167272, "time": 8031.012041807175, "episode/length": 424.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 167832, "time": 8051.6809322834015, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 167936, "time": 8056.942558526993, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 168280, "time": 8070.06387591362, "episode/length": 323.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 168280, "time": 8070.07331943512, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 168504, "time": 8080.8301866054535, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 168520, "time": 8082.879409790039, "episode/length": 514.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9844660194174757, "episode/intrinsic_return": 0.0}
{"step": 168664, "time": 8089.270692110062, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 169136, "time": 8106.871502399445, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 169464, "time": 8119.302864789963, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 169744, "time": 8130.692673921585, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 169760, "time": 8132.810761451721, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 169904, "time": 8139.23922753334, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 170000, "time": 8143.891833782196, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8161.434794425964, "eval_episode/length": 39.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9}
{"step": 170040, "time": 8163.296272516251, "eval_episode/length": 45.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 170040, "time": 8170.376682043076, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 170040, "time": 8172.28316617012, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 170040, "time": 8174.470327377319, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 170040, "time": 8176.308412075043, "eval_episode/length": 194.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 170040, "time": 8179.324192523956, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 170040, "time": 8181.261010169983, "eval_episode/length": 234.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 170048, "time": 8181.7627646923065, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 170352, "time": 8193.519414901733, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 170832, "time": 8211.333561897278, "episode/length": 270.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 171208, "time": 8225.215280771255, "episode/length": 162.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 171480, "time": 8235.798327207565, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 171632, "time": 8242.698351621628, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704797047970479, "episode/intrinsic_return": 0.0}
{"step": 171632, "time": 8242.70675110817, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 171952, "time": 8256.839934587479, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 172040, "time": 8261.40051317215, "episode/length": 248.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 172104, "time": 8266.742451190948, "episode/length": 158.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 172872, "time": 8294.151309728622, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 173152, "time": 8305.384687423706, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 173200, "time": 8308.51270031929, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 173200, "time": 8308.524288892746, "episode/length": 429.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 173232, "time": 8313.07677578926, "episode/length": 218.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 173352, "time": 8318.312791347504, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 173448, "time": 8323.168354988098, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 173464, "time": 8325.220885515213, "episode/length": 281.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 173632, "time": 8332.661743879318, "episode/length": 49.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 173792, "time": 8339.664419174194, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 174296, "time": 8358.356376171112, "episode/length": 142.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 174352, "time": 8362.132675170898, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 174600, "time": 8371.653453111649, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 174601, "time": 8374.724858522415, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4306561586668165, "train/action_min": 0.0, "train/action_std": 2.9414445719272972, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05466172200955933, "train/actor_opt_grad_steps": 10120.0, "train/actor_opt_loss": -0.4152127279223298, "train/adv_mag": 0.8577208064442916, "train/adv_max": 0.8460208183998684, "train/adv_mean": 0.004948722698500467, "train/adv_min": -0.5169016761745481, "train/adv_std": 0.08739739554605895, "train/cont_avg": 0.9945059577338129, "train/cont_loss_mean": 0.0005147590580512525, "train/cont_loss_std": 0.013795796623197465, "train/cont_neg_acc": 0.988183740660441, "train/cont_neg_loss": 0.036894874845503384, "train/cont_pos_acc": 0.9999293187539354, "train/cont_pos_loss": 0.00027929374394293586, "train/cont_pred": 0.9944907504019977, "train/cont_rate": 0.9945059577338129, "train/dyn_loss_mean": 14.721115318133677, "train/dyn_loss_std": 8.704247176218376, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0474101382193806, "train/extr_critic_critic_opt_grad_steps": 10120.0, "train/extr_critic_critic_opt_loss": 15757.396667041367, "train/extr_critic_mag": 4.000254387478177, "train/extr_critic_max": 4.000254387478177, "train/extr_critic_mean": 0.8879271389769136, "train/extr_critic_min": -0.1958096850690224, "train/extr_critic_std": 0.9174766304681627, "train/extr_return_normed_mag": 1.8801930859792146, "train/extr_return_normed_max": 1.8801930859792146, "train/extr_return_normed_mean": 0.334877335446344, "train/extr_return_normed_min": -0.15115731560605036, "train/extr_return_normed_std": 0.3333516999971952, "train/extr_return_rate": 0.49879630220879756, "train/extr_return_raw_mag": 5.361182590182737, "train/extr_return_raw_max": 5.361182590182737, "train/extr_return_raw_mean": 0.9022012783897867, "train/extr_return_raw_min": -0.5005986810588151, "train/extr_return_raw_std": 0.9622020880095392, "train/extr_reward_mag": 1.0099029026443151, "train/extr_reward_max": 1.0099029026443151, "train/extr_reward_mean": 0.021007802364208714, "train/extr_reward_min": -0.3103584188351528, "train/extr_reward_std": 0.12996497573398, "train/image_loss_mean": 12.680925293792066, "train/image_loss_std": 15.406535423059257, "train/model_loss_mean": 21.568056175177045, "train/model_loss_std": 19.05238955655544, "train/model_opt_grad_norm": 85.08009158701137, "train/model_opt_grad_steps": 10107.20143884892, "train/model_opt_loss": 15634.23339141187, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 714.9280575539568, "train/policy_entropy_mag": 2.4515336297398846, "train/policy_entropy_max": 2.4515336297398846, "train/policy_entropy_mean": 0.6354809000337724, "train/policy_entropy_min": 0.07937610165463935, "train/policy_entropy_std": 0.5600745755133869, "train/policy_logprob_mag": 7.438374975602404, "train/policy_logprob_max": -0.009455975413108043, "train/policy_logprob_mean": -0.6356328751543443, "train/policy_logprob_min": -7.438374975602404, "train/policy_logprob_std": 1.1174249546133357, "train/policy_randomness_mag": 0.8652837868217084, "train/policy_randomness_max": 0.8652837868217084, "train/policy_randomness_mean": 0.2242968696698868, "train/policy_randomness_min": 0.02801628050347455, "train/policy_randomness_std": 0.1976817458224811, "train/post_ent_mag": 53.27706826848092, "train/post_ent_max": 53.27706826848092, "train/post_ent_mean": 36.92744475989033, "train/post_ent_min": 19.965247847193435, "train/post_ent_std": 6.1957137979191845, "train/prior_ent_mag": 63.236357435048056, "train/prior_ent_max": 63.236357435048056, "train/prior_ent_mean": 51.73526497710523, "train/prior_ent_min": 32.99189659502866, "train/prior_ent_std": 5.187112382847628, "train/rep_loss_mean": 14.721115318133677, "train/rep_loss_std": 8.704247176218376, "train/reward_avg": 0.018053760065315224, "train/reward_loss_mean": 0.05394689315300193, "train/reward_loss_std": 0.27240706701501666, "train/reward_max_data": 1.015827341903028, "train/reward_max_pred": 1.00713948122889, "train/reward_neg_acc": 0.9932733902828299, "train/reward_neg_loss": 0.03195622897700226, "train/reward_pos_acc": 0.938682524849185, "train/reward_pos_loss": 0.996553003359184, "train/reward_pred": 0.017347742367884236, "train/reward_rate": 0.02290355215827338, "train_stats/sum_log_reward": 4.7363635735078295, "train_stats/max_log_achievement_collect_drink": 5.790909090909091, "train_stats/max_log_achievement_collect_sapling": 2.518181818181818, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.9272727272727272, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.35454545454545455, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.3727272727272726, "train_stats/max_log_achievement_place_table": 1.6272727272727272, "train_stats/max_log_achievement_wake_up": 2.2545454545454544, "train_stats/mean_log_entropy": 0.6215148763223128, "eval_stats/sum_log_reward": 3.287499944679439, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.29699264006922e-06, "report/cont_loss_std": 9.509087249170989e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010049925185739994, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.917152469057328e-07, "report/cont_pred": 0.9951217770576477, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.50109577178955, "report/dyn_loss_std": 8.760000228881836, "report/image_loss_mean": 8.930514335632324, "report/image_loss_std": 9.89759349822998, "report/model_loss_mean": 17.07865333557129, "report/model_loss_std": 13.642356872558594, "report/post_ent_mag": 56.43659210205078, "report/post_ent_max": 56.43659210205078, "report/post_ent_mean": 38.1740837097168, "report/post_ent_min": 18.7963924407959, "report/post_ent_std": 6.760205268859863, "report/prior_ent_mag": 63.17209243774414, "report/prior_ent_max": 63.17209243774414, "report/prior_ent_mean": 52.310333251953125, "report/prior_ent_min": 34.277244567871094, "report/prior_ent_std": 5.319618225097656, "report/rep_loss_mean": 13.50109577178955, "report/rep_loss_std": 8.760000228881836, "report/reward_avg": 0.01572265475988388, "report/reward_loss_mean": 0.047476936131715775, "report/reward_loss_std": 0.1846090704202652, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0004985332489014, "report/reward_neg_acc": 0.9940119981765747, "report/reward_neg_loss": 0.03290005400776863, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7113876342773438, "report/reward_pred": 0.015738986432552338, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.844005110906437e-05, "eval/cont_loss_std": 0.0014367365511134267, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006363462656736374, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.6121025409083813e-05, "eval/cont_pred": 0.9980043172836304, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.155071258544922, "eval/dyn_loss_std": 7.466424465179443, "eval/image_loss_mean": 44.69190979003906, "eval/image_loss_std": 48.6615104675293, "eval/model_loss_mean": 55.073753356933594, "eval/model_loss_std": 51.0629768371582, "eval/post_ent_mag": 49.341278076171875, "eval/post_ent_max": 49.341278076171875, "eval/post_ent_mean": 38.24553298950195, "eval/post_ent_min": 22.021875381469727, "eval/post_ent_std": 4.845083713531494, "eval/prior_ent_mag": 63.17209243774414, "eval/prior_ent_max": 63.17209243774414, "eval/prior_ent_mean": 52.051971435546875, "eval/prior_ent_min": 30.521188735961914, "eval/prior_ent_std": 5.343461513519287, "eval/rep_loss_mean": 17.155071258544922, "eval/rep_loss_std": 7.466424465179443, "eval/reward_avg": 0.00732421875, "eval/reward_loss_mean": 0.08873651921749115, "eval/reward_loss_std": 0.6940428018569946, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9972333908081055, "eval/reward_neg_acc": 0.9990138411521912, "eval/reward_neg_loss": 0.04826085641980171, "eval/reward_pos_acc": 0.4000000059604645, "eval/reward_pos_loss": 4.192969799041748, "eval/reward_pred": 0.002030265051871538, "eval/reward_rate": 0.009765625, "replay/size": 174097.0, "replay/inserts": 22240.0, "replay/samples": 22240.0, "replay/insert_wait_avg": 1.4362146528504735e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.494519501281299e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34872.0, "eval_replay/inserts": 3848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2427754312939555e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.0971703529358, "timer/env.step_count": 2780.0, "timer/env.step_total": 252.51804399490356, "timer/env.step_frac": 0.2519895789207422, "timer/env.step_avg": 0.09083382877514516, "timer/env.step_min": 0.022842884063720703, "timer/env.step_max": 3.4871697425842285, "timer/replay._sample_count": 22240.0, "timer/replay._sample_total": 11.705979585647583, "timer/replay._sample_frac": 0.011681481528906792, "timer/replay._sample_avg": 0.0005263480029517798, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.027336835861206055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3261.0, "timer/agent.policy_total": 55.66171193122864, "timer/agent.policy_frac": 0.05554522413392779, "timer/agent.policy_avg": 0.017068908902554015, "timer/agent.policy_min": 0.00961160659790039, "timer/agent.policy_max": 0.12409591674804688, "timer/dataset_train_count": 1390.0, "timer/dataset_train_total": 0.15892601013183594, "timer/dataset_train_frac": 0.00015859341272849085, "timer/dataset_train_avg": 0.00011433525908765176, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.000339508056640625, "timer/agent.train_count": 1390.0, "timer/agent.train_total": 626.3320043087006, "timer/agent.train_frac": 0.6250212283187151, "timer/agent.train_avg": 0.4505985642508637, "timer/agent.train_min": 0.43868565559387207, "timer/agent.train_max": 1.4646413326263428, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47592616081237793, "timer/agent.report_frac": 0.0004749301513791902, "timer/agent.report_avg": 0.23796308040618896, "timer/agent.report_min": 0.23038864135742188, "timer/agent.report_max": 0.24553751945495605, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 3.6877541274492154e-08, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05, "fps": 22.193198645511167}
{"step": 174648, "time": 8376.128644943237, "episode/length": 36.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 174728, "time": 8380.40020275116, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 175024, "time": 8392.304495096207, "episode/length": 52.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 175032, "time": 8394.014253377914, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 175120, "time": 8398.745187282562, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 175208, "time": 8403.019122123718, "episode/length": 113.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 175304, "time": 8407.83760881424, "episode/length": 262.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 175400, "time": 8412.567646980286, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 175496, "time": 8417.408305883408, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 175840, "time": 8430.728257417679, "episode/length": 42.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 176272, "time": 8446.889323234558, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 176440, "time": 8453.898520231247, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 176544, "time": 8459.155608177185, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647577092511013, "episode/intrinsic_return": 0.0}
{"step": 176576, "time": 8461.833569288254, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 176592, "time": 8464.06210899353, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 177104, "time": 8482.773562669754, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 177648, "time": 8502.590978860855, "episode/length": 304.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 177792, "time": 8509.190737009048, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 177792, "time": 8509.200248241425, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 178768, "time": 8545.343608617783, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 178936, "time": 8552.291932344437, "episode/length": 294.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 179000, "time": 8556.01986002922, "episode/length": 449.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 179208, "time": 8564.563579320908, "episode/length": 332.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 179248, "time": 8567.724140882492, "episode/length": 267.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 179376, "time": 8573.741276025772, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 179616, "time": 8583.356389284134, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 179688, "time": 8587.175414085388, "episode/length": 254.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 179776, "time": 8591.739139556885, "episode/length": 125.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8621.427451610565, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 180024, "time": 8623.125742673874, "eval_episode/length": 170.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 180024, "time": 8624.797674417496, "eval_episode/length": 171.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 180024, "time": 8626.703733444214, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9611111111111111}
{"step": 180024, "time": 8626.712208032608, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 180024, "time": 8630.39690542221, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 180024, "time": 8633.127500772476, "eval_episode/length": 209.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 180024, "time": 8635.081601142883, "eval_episode/length": 48.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 180320, "time": 8646.618123054504, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 180368, "time": 8649.886773586273, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 180592, "time": 8659.054298877716, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 180704, "time": 8664.394976854324, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 181152, "time": 8681.125568151474, "episode/length": 191.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 181200, "time": 8684.376940250397, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 181288, "time": 8688.844977140427, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653846153846154, "episode/intrinsic_return": 0.0}
{"step": 181592, "time": 8700.726323843002, "episode/length": 110.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 181616, "time": 8703.367951154709, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 181960, "time": 8716.204517126083, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 181992, "time": 8718.961437225342, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 181992, "time": 8718.970523834229, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 182456, "time": 8737.790593385696, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 182680, "time": 8747.654540777206, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 183168, "time": 8765.98011302948, "episode/length": 245.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 183192, "time": 8768.247200489044, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 183288, "time": 8773.063967227936, "episode/length": 208.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 183416, "time": 8778.99384880066, "episode/length": 227.0, "episode/score": 5.1000000461936, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 183960, "time": 8798.876287460327, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 183992, "time": 8801.501691102982, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 184256, "time": 8812.376272201538, "episode/length": 282.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 184384, "time": 8818.232229709625, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 184408, "time": 8820.458298444748, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 184480, "time": 8824.626702070236, "episode/length": 224.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 184616, "time": 8830.544773101807, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 184896, "time": 8841.67228937149, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 185184, "time": 8852.865499734879, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 185232, "time": 8856.117462158203, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 185408, "time": 8863.62298822403, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 185456, "time": 8866.676194190979, "episode/length": 133.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 185984, "time": 8886.092166662216, "episode/length": 135.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 186136, "time": 8892.513590097427, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 186264, "time": 8898.898652076721, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 186624, "time": 8912.771398305893, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 186680, "time": 8915.871350288391, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 186888, "time": 8924.36160993576, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 186976, "time": 8929.08855843544, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 187184, "time": 8937.683750391006, "episode/length": 149.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 187360, "time": 8945.138129711151, "episode/length": 237.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 187504, "time": 8951.547456741333, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 187704, "time": 8959.585390090942, "episode/length": 64.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 187952, "time": 8969.631937980652, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 188040, "time": 8973.912832975388, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9548022598870056, "episode/intrinsic_return": 0.0}
{"step": 188144, "time": 8979.311072587967, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 188320, "time": 8986.860204696655, "episode/length": 34.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 188360, "time": 8989.544199228287, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 188632, "time": 9001.510979890823, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 188712, "time": 9005.640175819397, "episode/length": 125.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 188792, "time": 9009.76741361618, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 189112, "time": 9022.096539497375, "episode/length": 59.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 189344, "time": 9031.821524143219, "episode/length": 229.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 189584, "time": 9041.90644812584, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 189632, "time": 9045.052823781967, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 189936, "time": 9056.900099992752, "episode/length": 223.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9077.872633934021, "eval_episode/length": 100.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9504950495049505}
{"step": 190008, "time": 9081.78458070755, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 190008, "time": 9083.628308296204, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 190008, "time": 9085.844797849655, "eval_episode/length": 179.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 190008, "time": 9087.694935798645, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 190008, "time": 9089.497203111649, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 190008, "time": 9092.928431510925, "eval_episode/length": 232.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 190008, "time": 9096.147272348404, "eval_episode/length": 271.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 190384, "time": 9108.968473672867, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 190400, "time": 9111.07673573494, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 190552, "time": 9117.500695705414, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 190776, "time": 9127.238315582275, "episode/length": 301.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 190928, "time": 9134.106375217438, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 191080, "time": 9140.455577611923, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 191136, "time": 9144.095910072327, "episode/length": 292.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 191488, "time": 9162.06504034996, "episode/length": 193.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 192008, "time": 9181.79906988144, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 192384, "time": 9196.785247564316, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 192528, "time": 9203.178567647934, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 192528, "time": 9203.186875104904, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 192664, "time": 9210.800569295883, "episode/length": 34.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 192824, "time": 9217.806884288788, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 192984, "time": 9224.743289232254, "episode/length": 322.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 193040, "time": 9228.421219348907, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 193048, "time": 9230.197005987167, "episode/length": 332.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 193304, "time": 9240.281854391098, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 193464, "time": 9247.33171749115, "episode/length": 116.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 193752, "time": 9258.654729366302, "episode/length": 35.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 194048, "time": 9270.404510736465, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 194072, "time": 9272.71731209755, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 194208, "time": 9279.632148742676, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 194448, "time": 9289.466166973114, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 194472, "time": 9291.574928760529, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 194544, "time": 9295.811422109604, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 194952, "time": 9310.626990795135, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 195504, "time": 9331.025193214417, "episode/length": 274.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 195728, "time": 9340.106310844421, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 195768, "time": 9342.846781015396, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 195792, "time": 9345.405323266983, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 195824, "time": 9347.95824933052, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 195832, "time": 9349.552817583084, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 195936, "time": 9354.848628044128, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 196184, "time": 9364.537602901459, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 196425, "time": 9375.026562929153, "train_stats/sum_log_reward": 4.6213674513448, "train_stats/max_log_achievement_collect_drink": 3.658119658119658, "train_stats/max_log_achievement_collect_sapling": 2.4957264957264957, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.811965811965812, "train_stats/max_log_achievement_defeat_skeleton": 0.008547008547008548, "train_stats/max_log_achievement_defeat_zombie": 0.2564102564102564, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.042735042735042736, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.41025641025641, "train_stats/max_log_achievement_place_table": 1.9743589743589745, "train_stats/max_log_achievement_wake_up": 1.9401709401709402, "train_stats/mean_log_entropy": 0.5847896401189331, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.224718079949818, "train/action_min": 0.0, "train/action_std": 2.779144046950514, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05069589117256394, "train/actor_opt_grad_steps": 11500.0, "train/actor_opt_loss": -2.1532264937014474, "train/adv_mag": 0.7523482576773984, "train/adv_max": 0.7482595548142482, "train/adv_mean": 0.004285128795126296, "train/adv_min": -0.48182911181101834, "train/adv_std": 0.08063871220406825, "train/cont_avg": 0.994368727189781, "train/cont_loss_mean": 0.00042177036214253105, "train/cont_loss_std": 0.011800121294012849, "train/cont_neg_acc": 0.989902677327177, "train/cont_neg_loss": 0.035834543660294135, "train/cont_pos_acc": 0.9999426046427149, "train/cont_pos_loss": 0.00018687175480693193, "train/cont_pred": 0.9943704135226508, "train/cont_rate": 0.994368727189781, "train/dyn_loss_mean": 14.921794362311816, "train/dyn_loss_std": 8.70468030358753, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.032296980819563, "train/extr_critic_critic_opt_grad_steps": 11500.0, "train/extr_critic_critic_opt_loss": 15761.252316662865, "train/extr_critic_mag": 4.313440336798229, "train/extr_critic_max": 4.313440336798229, "train/extr_critic_mean": 0.855216318673461, "train/extr_critic_min": -0.19818131593022034, "train/extr_critic_std": 0.9802218719120444, "train/extr_return_normed_mag": 1.8272247340557348, "train/extr_return_normed_max": 1.8272247340557348, "train/extr_return_normed_mean": 0.31330763108103815, "train/extr_return_normed_min": -0.13415641968485212, "train/extr_return_normed_std": 0.33517607578831, "train/extr_return_rate": 0.4602836303032228, "train/extr_return_raw_mag": 5.477354171502329, "train/extr_return_raw_max": 5.477354171502329, "train/extr_return_raw_mean": 0.8682795166969299, "train/extr_return_raw_min": -0.4948265750477784, "train/extr_return_raw_std": 1.0209544527269627, "train/extr_reward_mag": 1.0065040083697243, "train/extr_reward_max": 1.0065040083697243, "train/extr_reward_mean": 0.02119484581869014, "train/extr_reward_min": -0.30031593872682893, "train/extr_reward_std": 0.13190761872016601, "train/image_loss_mean": 11.488536946094818, "train/image_loss_std": 14.088160312958877, "train/model_loss_mean": 20.496459431891893, "train/model_loss_std": 17.644659028436145, "train/model_opt_grad_norm": 81.90603094727453, "train/model_opt_grad_steps": 11485.795620437957, "train/model_opt_loss": 13270.586407960767, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 647.8102189781022, "train/policy_entropy_mag": 2.5026889317227106, "train/policy_entropy_max": 2.5026889317227106, "train/policy_entropy_mean": 0.5988246404776608, "train/policy_entropy_min": 0.07937554318974488, "train/policy_entropy_std": 0.564349474045482, "train/policy_logprob_mag": 7.438379506995208, "train/policy_logprob_max": -0.00945589753941898, "train/policy_logprob_mean": -0.59875000241029, "train/policy_logprob_min": -7.438379506995208, "train/policy_logprob_std": 1.1112664529006846, "train/policy_randomness_mag": 0.8833393637281265, "train/policy_randomness_max": 0.8833393637281265, "train/policy_randomness_mean": 0.21135881978229884, "train/policy_randomness_min": 0.02801608352711166, "train/policy_randomness_std": 0.19919059876977963, "train/post_ent_mag": 54.197752235579664, "train/post_ent_max": 54.197752235579664, "train/post_ent_mean": 37.33990550911339, "train/post_ent_min": 19.8685343874632, "train/post_ent_std": 6.528244805161971, "train/prior_ent_mag": 63.554104937254074, "train/prior_ent_max": 63.554104937254074, "train/prior_ent_mean": 52.402365607936886, "train/prior_ent_min": 34.163315097780995, "train/prior_ent_std": 4.9892010584364845, "train/rep_loss_mean": 14.921794362311816, "train/rep_loss_std": 8.70468030358753, "train/reward_avg": 0.018414974783676385, "train/reward_loss_mean": 0.05442402674986498, "train/reward_loss_std": 0.2724340958316831, "train/reward_max_data": 1.0072992718132743, "train/reward_max_pred": 1.004521331647887, "train/reward_neg_acc": 0.9935241541723265, "train/reward_neg_loss": 0.03222790351613377, "train/reward_pos_acc": 0.9409438345554101, "train/reward_pos_loss": 0.9876159938582538, "train/reward_pred": 0.01730696982398194, "train/reward_rate": 0.023330577098540146, "eval_stats/sum_log_reward": 4.599999941885471, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 2.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.057667320012115e-05, "report/cont_loss_std": 0.0003577502502594143, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008010016172192991, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.609479608712718e-05, "report/cont_pred": 0.9941095113754272, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.496973991394043, "report/dyn_loss_std": 8.626060485839844, "report/image_loss_mean": 10.161592483520508, "report/image_loss_std": 11.738639831542969, "report/model_loss_mean": 18.91156768798828, "report/model_loss_std": 15.479920387268066, "report/post_ent_mag": 53.200401306152344, "report/post_ent_max": 53.200401306152344, "report/post_ent_mean": 36.790401458740234, "report/post_ent_min": 20.296340942382812, "report/post_ent_std": 6.24513578414917, "report/prior_ent_mag": 63.36466979980469, "report/prior_ent_max": 63.36466979980469, "report/prior_ent_mean": 51.727169036865234, "report/prior_ent_min": 35.97212219238281, "report/prior_ent_std": 4.512079238891602, "report/rep_loss_mean": 14.496973991394043, "report/rep_loss_std": 8.626060485839844, "report/reward_avg": 0.01992187462747097, "report/reward_loss_mean": 0.05175081640481949, "report/reward_loss_std": 0.3209972083568573, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021984577178955, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.02830437757074833, "report/reward_pos_acc": 0.9199999570846558, "report/reward_pos_loss": 0.9886706471443176, "report/reward_pred": 0.018214097246527672, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.490505645866506e-05, "eval/cont_loss_std": 0.0010091853328049183, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003888920764438808, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.359529677662067e-05, "eval/cont_pred": 0.9960423707962036, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.274545669555664, "eval/dyn_loss_std": 8.37857723236084, "eval/image_loss_mean": 31.654319763183594, "eval/image_loss_std": 32.317665100097656, "eval/model_loss_mean": 43.286529541015625, "eval/model_loss_std": 34.80912780761719, "eval/post_ent_mag": 50.868995666503906, "eval/post_ent_max": 50.868995666503906, "eval/post_ent_mean": 37.88761901855469, "eval/post_ent_min": 19.771804809570312, "eval/post_ent_std": 5.973301887512207, "eval/prior_ent_mag": 63.36466979980469, "eval/prior_ent_max": 63.36466979980469, "eval/prior_ent_mean": 53.51666259765625, "eval/prior_ent_min": 35.258094787597656, "eval/prior_ent_std": 3.8080666065216064, "eval/rep_loss_mean": 19.274545669555664, "eval/rep_loss_std": 8.37857723236084, "eval/reward_avg": 0.01220703125, "eval/reward_loss_mean": 0.06742513924837112, "eval/reward_loss_std": 0.500325620174408, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0002045631408691, "eval/reward_neg_acc": 0.9940477013587952, "eval/reward_neg_loss": 0.041544895619153976, "eval/reward_pos_acc": 0.8125, "eval/reward_pos_loss": 1.697880506515503, "eval/reward_pred": 0.010738976299762726, "eval/reward_rate": 0.015625, "replay/size": 195921.0, "replay/inserts": 21824.0, "replay/samples": 21824.0, "replay/insert_wait_avg": 1.394449353567666e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.491547865601928e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38808.0, "eval_replay/inserts": 3936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.207175778179634e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2900040149689, "timer/env.step_count": 2728.0, "timer/env.step_total": 259.5216724872589, "timer/env.step_frac": 0.25944643198031525, "timer/env.step_avg": 0.09513257789122394, "timer/env.step_min": 0.02242422103881836, "timer/env.step_max": 3.3403537273406982, "timer/replay._sample_count": 21824.0, "timer/replay._sample_total": 11.043574333190918, "timer/replay._sample_frac": 0.011040372580815729, "timer/replay._sample_avg": 0.0005060288825692319, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.010741710662841797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3220.0, "timer/agent.policy_total": 52.8295521736145, "timer/agent.policy_frac": 0.05281423583317537, "timer/agent.policy_avg": 0.01640669322161941, "timer/agent.policy_min": 0.009400606155395508, "timer/agent.policy_max": 0.07984495162963867, "timer/dataset_train_count": 1364.0, "timer/dataset_train_total": 0.15282440185546875, "timer/dataset_train_frac": 0.0001527800950145072, "timer/dataset_train_avg": 0.00011204135033392137, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010678768157958984, "timer/agent.train_count": 1364.0, "timer/agent.train_total": 616.875687122345, "timer/agent.train_frac": 0.6166968425619833, "timer/agent.train_avg": 0.45225490258236434, "timer/agent.train_min": 0.4392273426055908, "timer/agent.train_max": 1.5228893756866455, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4721510410308838, "timer/agent.report_frac": 0.00047201415503080274, "timer/agent.report_avg": 0.2360755205154419, "timer/agent.report_min": 0.22931909561157227, "timer/agent.report_max": 0.24283194541931152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.432232177950589e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 21.817421104243877}
{"step": 196624, "time": 9383.21464395523, "episode/length": 106.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 196784, "time": 9390.043781518936, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 196936, "time": 9396.328197479248, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 197152, "time": 9405.244348049164, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 197176, "time": 9407.396718502045, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 197360, "time": 9415.404109477997, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 197424, "time": 9419.056726932526, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 197496, "time": 9422.818789482117, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 197880, "time": 9437.242592096329, "episode/length": 156.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 198440, "time": 9457.62310886383, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 198440, "time": 9457.632452726364, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 198488, "time": 9462.531208515167, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 198912, "time": 9478.688736438751, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 198936, "time": 9480.817989349365, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 198944, "time": 9482.833835840225, "episode/length": 250.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 198984, "time": 9485.34494304657, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 199248, "time": 9495.772410869598, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 199832, "time": 9516.986377000809, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 199896, "time": 9520.615056037903, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 200048, "time": 9527.373191833496, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9545.728643655777, "eval_episode/length": 46.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 200096, "time": 9550.784109830856, "eval_episode/length": 135.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9558823529411765}
{"step": 200096, "time": 9552.663923501968, "eval_episode/length": 142.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 200096, "time": 9554.608346223831, "eval_episode/length": 151.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 200096, "time": 9557.396070957184, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 200096, "time": 9562.748587608337, "eval_episode/length": 216.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 200096, "time": 9565.29792714119, "eval_episode/length": 218.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 200096, "time": 9568.780496835709, "eval_episode/length": 69.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 200128, "time": 9569.890795230865, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 200248, "time": 9575.170788526535, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 200280, "time": 9577.731863737106, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 200424, "time": 9584.045267105103, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 200776, "time": 9597.961772680283, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 201232, "time": 9614.918221235275, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 201512, "time": 9625.68616938591, "episode/length": 182.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 201776, "time": 9636.371460676193, "episode/length": 67.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 201848, "time": 9640.09129691124, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 201888, "time": 9643.20601272583, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 202072, "time": 9650.74328827858, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 202224, "time": 9657.67335486412, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 202416, "time": 9665.62483882904, "episode/length": 437.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 202512, "time": 9670.423339605331, "episode/length": 282.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 202552, "time": 9673.003690481186, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 202944, "time": 9687.927640199661, "episode/length": 136.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 203320, "time": 9701.781769037247, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 203408, "time": 9706.566123723984, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 203576, "time": 9713.593000173569, "episode/length": 132.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 203584, "time": 9715.608388662338, "episode/length": 258.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 204072, "time": 9733.204138994217, "episode/length": 249.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 204488, "time": 9748.752936601639, "episode/length": 258.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 204536, "time": 9751.887647867203, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 204576, "time": 9755.081032514572, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 204680, "time": 9760.070262908936, "episode/length": 136.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 204880, "time": 9770.032104253769, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 204944, "time": 9773.654079914093, "episode/length": 298.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 205136, "time": 9781.554228782654, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 205144, "time": 9783.070111751556, "episode/length": 81.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 205376, "time": 9792.592643022537, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 206000, "time": 9814.87920331955, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 206264, "time": 9825.069766044617, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 206272, "time": 9827.141186714172, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 206296, "time": 9829.30906534195, "episode/length": 36.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 206424, "time": 9835.11480808258, "episode/length": 230.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 206512, "time": 9839.88088274002, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 206592, "time": 9844.004235744476, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 206608, "time": 9845.962386131287, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 206856, "time": 9855.619611024857, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 207024, "time": 9862.967938899994, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961864406779661, "episode/intrinsic_return": 0.0}
{"step": 207160, "time": 9868.835735559464, "episode/length": 251.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 207912, "time": 9895.462614536285, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 207944, "time": 9898.101220846176, "episode/length": 209.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 207992, "time": 9901.258959531784, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 208088, "time": 9905.923567056656, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 208264, "time": 9913.259375095367, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.961352657004831, "episode/intrinsic_return": 0.0}
{"step": 208320, "time": 9916.84083890915, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 208448, "time": 9922.908946990967, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 208792, "time": 9935.627223730087, "episode/length": 105.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 208824, "time": 9938.241362571716, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 209144, "time": 9950.678180217743, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 209168, "time": 9953.320338964462, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 209576, "time": 9968.232038021088, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 209600, "time": 9970.85002565384, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 209688, "time": 9975.221800327301, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 210024, "time": 9988.115333080292, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10008.273499011993, "eval_episode/length": 85.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9418604651162791}
{"step": 210080, "time": 10012.348834991455, "eval_episode/length": 142.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 210080, "time": 10014.407559633255, "eval_episode/length": 153.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 210080, "time": 10016.190640211105, "eval_episode/length": 158.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 210080, "time": 10017.985184907913, "eval_episode/length": 164.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 210080, "time": 10017.99293422699, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 210080, "time": 10023.138309955597, "eval_episode/length": 205.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 210080, "time": 10026.572641849518, "eval_episode/length": 236.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 210456, "time": 10038.955551147461, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 210664, "time": 10047.434416532516, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 210944, "time": 10058.51133108139, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 210992, "time": 10061.85440659523, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 211096, "time": 10066.602907896042, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 211144, "time": 10069.822624444962, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 211312, "time": 10077.168456315994, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 211672, "time": 10090.570406675339, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 211928, "time": 10100.914146184921, "episode/length": 279.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 211952, "time": 10104.107420921326, "episode/length": 240.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 212312, "time": 10117.446109294891, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 212392, "time": 10121.699695825577, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 212760, "time": 10135.61859035492, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 213128, "time": 10150.801258325577, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 213240, "time": 10156.037744760513, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 213320, "time": 10160.302422761917, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 213480, "time": 10167.105319738388, "episode/length": 297.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9899328859060402, "episode/intrinsic_return": 0.0}
{"step": 213704, "time": 10176.155048131943, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 213752, "time": 10179.898726463318, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 213800, "time": 10183.574535608292, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 213928, "time": 10190.06319141388, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 214136, "time": 10198.550271987915, "episode/length": 53.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 214344, "time": 10207.15489935875, "episode/length": 137.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 214544, "time": 10215.60883307457, "episode/length": 176.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 214872, "time": 10228.052126169205, "episode/length": 193.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 215360, "time": 10246.05652308464, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 215416, "time": 10249.296253681183, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 215472, "time": 10253.06697177887, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 215568, "time": 10257.854327201843, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 215736, "time": 10264.709441661835, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 216080, "time": 10278.032707929611, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 216344, "time": 10288.315955877304, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 216536, "time": 10296.142308235168, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 216760, "time": 10305.06447148323, "episode/length": 409.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9926829268292683, "episode/intrinsic_return": 0.0}
{"step": 216864, "time": 10310.340606451035, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 217056, "time": 10318.24982881546, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 217096, "time": 10320.976509809494, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 217224, "time": 10327.499059677124, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 217336, "time": 10332.825657844543, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 217528, "time": 10340.959424734116, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 217632, "time": 10346.137171268463, "episode/length": 269.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 217912, "time": 10356.8086977005, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 218328, "time": 10372.369653224945, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 218329, "time": 10375.375211000443, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.364021301269531, "train/action_min": 0.0, "train/action_std": 3.0840647378388573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051343313363545084, "train/actor_opt_grad_steps": 12865.0, "train/actor_opt_loss": -1.641209768898347, "train/adv_mag": 0.7544317118385259, "train/adv_max": 0.7390767984530505, "train/adv_mean": 0.004312530865076149, "train/adv_min": -0.5190397958983394, "train/adv_std": 0.07938928713145502, "train/cont_avg": 0.9948156020220589, "train/cont_loss_mean": 0.0003123341812019643, "train/cont_loss_std": 0.008577025276510393, "train/cont_neg_acc": 0.9860527561429668, "train/cont_neg_loss": 0.0382213620570891, "train/cont_pos_acc": 0.9999566490159315, "train/cont_pos_loss": 0.00011838164255714874, "train/cont_pred": 0.9948258430642241, "train/cont_rate": 0.9948156020220589, "train/dyn_loss_mean": 14.98116160841549, "train/dyn_loss_std": 8.779475769575905, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9966575779459056, "train/extr_critic_critic_opt_grad_steps": 12865.0, "train/extr_critic_critic_opt_loss": 15848.02044318704, "train/extr_critic_mag": 4.537218234118293, "train/extr_critic_max": 4.537218234118293, "train/extr_critic_mean": 0.8747662446078133, "train/extr_critic_min": -0.19885821815799265, "train/extr_critic_std": 0.9931870690163445, "train/extr_return_normed_mag": 1.8318069235366934, "train/extr_return_normed_max": 1.8318069235366934, "train/extr_return_normed_mean": 0.3098579332889879, "train/extr_return_normed_min": -0.12951528165927706, "train/extr_return_normed_std": 0.32973295121508484, "train/extr_return_rate": 0.46974238468443646, "train/extr_return_raw_mag": 5.664968644871431, "train/extr_return_raw_max": 5.664968644871431, "train/extr_return_raw_mean": 0.8882864402497516, "train/extr_return_raw_min": -0.4907415031510241, "train/extr_return_raw_std": 1.0348959284670212, "train/extr_reward_mag": 1.008312158724841, "train/extr_reward_max": 1.008312158724841, "train/extr_reward_mean": 0.02276571318918072, "train/extr_reward_min": -0.2976301978616154, "train/extr_reward_std": 0.13806413935826106, "train/image_loss_mean": 11.10956750196569, "train/image_loss_std": 14.347847966586842, "train/model_loss_mean": 20.15206454781925, "train/model_loss_std": 17.92960201992708, "train/model_opt_grad_norm": 76.92344003565171, "train/model_opt_grad_steps": 12849.536764705883, "train/model_opt_loss": 13047.625193876378, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 647.9779411764706, "train/policy_entropy_mag": 2.5198953134172104, "train/policy_entropy_max": 2.5198953134172104, "train/policy_entropy_mean": 0.660203255712986, "train/policy_entropy_min": 0.07937540360452498, "train/policy_entropy_std": 0.6367795011576485, "train/policy_logprob_mag": 7.438380669145023, "train/policy_logprob_max": -0.00945589063442586, "train/policy_logprob_mean": -0.6607005219249165, "train/policy_logprob_min": -7.438380669145023, "train/policy_logprob_std": 1.1605914769803776, "train/policy_randomness_mag": 0.8894124627113342, "train/policy_randomness_max": 0.8894124627113342, "train/policy_randomness_mean": 0.2330227772540906, "train/policy_randomness_min": 0.028016034171313924, "train/policy_randomness_std": 0.22475522088215633, "train/post_ent_mag": 54.811642815085015, "train/post_ent_max": 54.811642815085015, "train/post_ent_mean": 37.6369415731991, "train/post_ent_min": 19.693349698010614, "train/post_ent_std": 6.743457787177142, "train/prior_ent_mag": 63.92135053522446, "train/prior_ent_max": 63.92135053522446, "train/prior_ent_mean": 52.73129196727977, "train/prior_ent_min": 35.35873819799984, "train/prior_ent_std": 4.7501758705167205, "train/rep_loss_mean": 14.98116160841549, "train/rep_loss_std": 8.779475769575905, "train/reward_avg": 0.019292853697312668, "train/reward_loss_mean": 0.053487801677821314, "train/reward_loss_std": 0.2579725482227171, "train/reward_max_data": 1.0169117687379612, "train/reward_max_pred": 1.005955489242778, "train/reward_neg_acc": 0.9934718806077453, "train/reward_neg_loss": 0.03183554853860508, "train/reward_pos_acc": 0.952778552823207, "train/reward_pos_loss": 0.9305447063901845, "train/reward_pred": 0.018439549939049518, "train/reward_rate": 0.024083754595588234, "train_stats/sum_log_reward": 4.856302464709563, "train_stats/max_log_achievement_collect_drink": 4.336134453781512, "train_stats/max_log_achievement_collect_sapling": 2.411764705882353, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.1344537815126055, "train_stats/max_log_achievement_defeat_skeleton": 0.008403361344537815, "train_stats/max_log_achievement_defeat_zombie": 0.3865546218487395, "train_stats/max_log_achievement_eat_cow": 0.10084033613445378, "train_stats/max_log_achievement_make_wood_pickaxe": 0.058823529411764705, "train_stats/max_log_achievement_make_wood_sword": 0.008403361344537815, "train_stats/max_log_achievement_place_plant": 2.2857142857142856, "train_stats/max_log_achievement_place_table": 2.0588235294117645, "train_stats/max_log_achievement_wake_up": 2.092436974789916, "train_stats/mean_log_entropy": 0.6084905283040359, "eval_stats/sum_log_reward": 4.412499904632568, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.795245407265611e-05, "report/cont_loss_std": 0.00040143891237676144, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020045448036398739, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6876803783816285e-05, "report/cont_pred": 0.9941251277923584, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 16.13836669921875, "report/dyn_loss_std": 8.581853866577148, "report/image_loss_mean": 11.524027824401855, "report/image_loss_std": 15.25261116027832, "report/model_loss_mean": 21.26386833190918, "report/model_loss_std": 19.018218994140625, "report/post_ent_mag": 53.326927185058594, "report/post_ent_max": 53.326927185058594, "report/post_ent_mean": 35.23059844970703, "report/post_ent_min": 19.564748764038086, "report/post_ent_std": 5.392251968383789, "report/prior_ent_mag": 64.5960693359375, "report/prior_ent_max": 64.5960693359375, "report/prior_ent_mean": 52.059303283691406, "report/prior_ent_min": 35.19813537597656, "report/prior_ent_std": 5.350856304168701, "report/rep_loss_mean": 16.13836669921875, "report/rep_loss_std": 8.581853866577148, "report/reward_avg": 0.02792968787252903, "report/reward_loss_mean": 0.0568036288022995, "report/reward_loss_std": 0.24524468183517456, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0068995952606201, "report/reward_neg_acc": 0.9919354319572449, "report/reward_neg_loss": 0.035325150936841965, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7226364612579346, "report/reward_pred": 0.0292297825217247, "report/reward_rate": 0.03125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.000153429398778826, "eval/cont_loss_std": 0.004641384351998568, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.07423903048038483, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.447813343082089e-06, "eval/cont_pred": 0.9981732964515686, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.115428924560547, "eval/dyn_loss_std": 9.105667114257812, "eval/image_loss_mean": 20.814435958862305, "eval/image_loss_std": 21.717065811157227, "eval/model_loss_mean": 31.757396697998047, "eval/model_loss_std": 25.18934440612793, "eval/post_ent_mag": 54.87690734863281, "eval/post_ent_max": 54.87690734863281, "eval/post_ent_mean": 37.64176940917969, "eval/post_ent_min": 23.384437561035156, "eval/post_ent_std": 6.095215320587158, "eval/prior_ent_mag": 64.5960693359375, "eval/prior_ent_max": 64.5960693359375, "eval/prior_ent_mean": 53.28120422363281, "eval/prior_ent_min": 37.91390609741211, "eval/prior_ent_std": 4.484589576721191, "eval/rep_loss_mean": 18.115428924560547, "eval/rep_loss_std": 9.105667114257812, "eval/reward_avg": 0.02138671837747097, "eval/reward_loss_mean": 0.07355146110057831, "eval/reward_loss_std": 0.498238742351532, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0034077167510986, "eval/reward_neg_acc": 0.9930000305175781, "eval/reward_neg_loss": 0.02919190004467964, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 1.9218664169311523, "eval/reward_pred": 0.01665506139397621, "eval/reward_rate": 0.0234375, "replay/size": 217825.0, "replay/inserts": 21904.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.3639732727262554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.494881346419051e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42696.0, "eval_replay/inserts": 3888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2350793728612578e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3360495567322, "timer/env.step_count": 2738.0, "timer/env.step_total": 260.0418002605438, "timer/env.step_frac": 0.2599544426853089, "timer/env.step_avg": 0.09497509140268219, "timer/env.step_min": 0.022294044494628906, "timer/env.step_max": 3.321728467941284, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 11.326464653015137, "timer/replay._sample_frac": 0.011322659678249232, "timer/replay._sample_avg": 0.0005170957200974771, "timer/replay._sample_min": 0.00040721893310546875, "timer/replay._sample_max": 0.03521394729614258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3224.0, "timer/agent.policy_total": 53.473127603530884, "timer/agent.policy_frac": 0.05345516401935713, "timer/agent.policy_avg": 0.01658595769340288, "timer/agent.policy_min": 0.009315013885498047, "timer/agent.policy_max": 0.12609410285949707, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.1478404998779297, "timer/dataset_train_frac": 0.00014779083483339484, "timer/dataset_train_avg": 0.00010799159961864842, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.00044226646423339844, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 617.6092789173126, "timer/agent.train_frac": 0.6174018013156548, "timer/agent.train_avg": 0.4511389911740779, "timer/agent.train_min": 0.4382953643798828, "timer/agent.train_max": 1.5087487697601318, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776132106781006, "timer/agent.report_frac": 0.00047745276288877126, "timer/agent.report_avg": 0.2388066053390503, "timer/agent.report_min": 0.2309725284576416, "timer/agent.report_max": 0.24664068222045898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0030649180451406e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.89637208972048}
{"step": 218368, "time": 10376.770277500153, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 218448, "time": 10380.937498807907, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 218696, "time": 10390.478864431381, "episode/length": 30.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 218792, "time": 10395.195373535156, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 218984, "time": 10403.196609973907, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 219216, "time": 10412.601435661316, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 219408, "time": 10420.597737073898, "episode/length": 134.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 219432, "time": 10422.711598157883, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 219448, "time": 10424.83512878418, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10461.821928977966, "eval_episode/length": 40.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.975609756097561}
{"step": 220064, "time": 10465.45842719078, "eval_episode/length": 88.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9887640449438202}
{"step": 220064, "time": 10468.321412563324, "eval_episode/length": 105.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9528301886792453}
{"step": 220064, "time": 10473.645614147186, "eval_episode/length": 183.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 220064, "time": 10477.146071195602, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 220064, "time": 10477.155575037003, "eval_episode/length": 186.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 220064, "time": 10481.390347003937, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 220064, "time": 10482.99698472023, "eval_episode/length": 249.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.988}
{"step": 220184, "time": 10486.768380403519, "episode/length": 226.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 220416, "time": 10496.552971601486, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 220448, "time": 10499.25322508812, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 220504, "time": 10502.52411699295, "episode/length": 213.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 220776, "time": 10513.1271109581, "episode/length": 194.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 220864, "time": 10517.892169475555, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 221128, "time": 10528.064267396927, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 221616, "time": 10547.921654462814, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 221984, "time": 10561.648524522781, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 222088, "time": 10566.467715024948, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 222216, "time": 10572.253333806992, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 222232, "time": 10574.469885110855, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 222312, "time": 10578.741345405579, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 222440, "time": 10584.61387848854, "episode/length": 207.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 222544, "time": 10589.831164598465, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 222760, "time": 10598.357880592346, "episode/length": 39.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 222816, "time": 10601.94550204277, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 223328, "time": 10620.352206707, "episode/length": 213.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 223576, "time": 10630.045093536377, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 223600, "time": 10632.985582351685, "episode/length": 33.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 223728, "time": 10642.357778310776, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 223928, "time": 10650.405580997467, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 224032, "time": 10655.68658900261, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 224072, "time": 10658.462018728256, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 224256, "time": 10666.458884000778, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 224456, "time": 10674.566323280334, "episode/length": 295.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 224952, "time": 10692.538238048553, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 224984, "time": 10695.190145254135, "episode/length": 156.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 225416, "time": 10711.309211492538, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 225416, "time": 10711.319051742554, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 225480, "time": 10716.665925741196, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 225568, "time": 10721.385267734528, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 225928, "time": 10734.658758878708, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 226640, "time": 10760.017985343933, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 226808, "time": 10766.952432870865, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 227040, "time": 10776.525950431824, "episode/length": 388.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948586118251928, "episode/intrinsic_return": 0.0}
{"step": 227048, "time": 10778.15899682045, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 227112, "time": 10781.812948703766, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 227128, "time": 10783.91755247116, "episode/length": 267.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 227224, "time": 10788.671489953995, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 227864, "time": 10811.639839410782, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 227896, "time": 10814.387287139893, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 228168, "time": 10825.07118344307, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 228328, "time": 10832.507869005203, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 228392, "time": 10836.222058296204, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 228448, "time": 10839.801767349243, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 228536, "time": 10843.920386314392, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 228896, "time": 10857.735377073288, "episode/length": 44.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 228912, "time": 10859.914030313492, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 229344, "time": 10875.626254081726, "episode/length": 55.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 229352, "time": 10877.273467302322, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 229664, "time": 10892.280133485794, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 229688, "time": 10894.417155504227, "episode/length": 169.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 229864, "time": 10901.773364067078, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 229912, "time": 10904.985573768616, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 230024, "time": 10910.304125070572, "episode/length": 196.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10927.566704750061, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.868421052631579}
{"step": 230048, "time": 10930.152223587036, "eval_episode/length": 48.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 230048, "time": 10937.894280672073, "eval_episode/length": 168.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9822485207100592}
{"step": 230048, "time": 10940.07553076744, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 230048, "time": 10942.966586828232, "eval_episode/length": 186.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 230048, "time": 10945.087583065033, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 230048, "time": 10948.017852067947, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 230048, "time": 10949.765245199203, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 230264, "time": 10956.68002319336, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 230672, "time": 10972.054336309433, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 230920, "time": 10981.616954565048, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 231080, "time": 10988.526344060898, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 231128, "time": 10991.613594293594, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 231264, "time": 10997.943368434906, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 231696, "time": 11013.971343278885, "episode/length": 222.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 232056, "time": 11027.40937781334, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 232088, "time": 11030.193726539612, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 232152, "time": 11034.008179426193, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 232184, "time": 11036.584478139877, "episode/length": 314.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936507936507937, "episode/intrinsic_return": 0.0}
{"step": 232232, "time": 11039.784417390823, "episode/length": 163.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 232432, "time": 11048.254300355911, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 232752, "time": 11060.533784151077, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 232864, "time": 11065.883296966553, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 233128, "time": 11076.201259374619, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 233376, "time": 11086.080885648727, "episode/length": 148.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 233552, "time": 11093.634324550629, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 233704, "time": 11100.025464296341, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 233784, "time": 11104.242455482483, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 233832, "time": 11107.266020536423, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 234144, "time": 11119.554800748825, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 234376, "time": 11128.584086418152, "episode/length": 188.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 234912, "time": 11148.347923517227, "episode/length": 334.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 234920, "time": 11149.984118700027, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 234984, "time": 11153.610589504242, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 235176, "time": 11161.496854543686, "episode/length": 32.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 235280, "time": 11166.685912847519, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 235304, "time": 11168.848626852036, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 235312, "time": 11170.966081142426, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 235600, "time": 11181.986115694046, "episode/length": 220.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 235720, "time": 11187.360828399658, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 235920, "time": 11195.797215938568, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 236192, "time": 11206.415802955627, "episode/length": 126.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 236496, "time": 11218.206096887589, "episode/length": 111.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 236528, "time": 11220.882117509842, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 236560, "time": 11223.537448644638, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 236608, "time": 11226.793489456177, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 237208, "time": 11247.902116537094, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 237272, "time": 11251.5864610672, "episode/length": 244.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 237392, "time": 11257.39449095726, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 237848, "time": 11275.147191524506, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 238008, "time": 11281.991296768188, "episode/length": 285.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 238176, "time": 11289.388074159622, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 238232, "time": 11292.594372987747, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 238264, "time": 11295.546860933304, "episode/length": 206.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 238616, "time": 11308.881582975388, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 239240, "time": 11331.257470846176, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 239392, "time": 11338.030715465546, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 239400, "time": 11339.657582044601, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 239520, "time": 11345.445743322372, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 239592, "time": 11349.233425855637, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11379.989631175995, "eval_episode/length": 38.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 240032, "time": 11381.818160057068, "eval_episode/length": 46.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 240032, "time": 11390.050789833069, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 240032, "time": 11391.834421634674, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 240032, "time": 11393.485934019089, "eval_episode/length": 211.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 240032, "time": 11395.00388097763, "eval_episode/length": 212.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 240032, "time": 11397.242594003677, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 240032, "time": 11400.233062028885, "eval_episode/length": 221.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 240033, "time": 11400.808922052383, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.587567048914292, "train/action_min": 0.0, "train/action_std": 3.304454721072141, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050878696444937414, "train/actor_opt_grad_steps": 14225.0, "train/actor_opt_loss": -8.360792770543519, "train/adv_mag": 0.7756308439899894, "train/adv_max": 0.7631531000575599, "train/adv_mean": 0.0032819671363112693, "train/adv_min": -0.5084453260197359, "train/adv_std": 0.0786515842191875, "train/cont_avg": 0.9945140165441176, "train/cont_loss_mean": 0.0004612420896588741, "train/cont_loss_std": 0.013601751239912788, "train/cont_neg_acc": 0.9857551367843852, "train/cont_neg_loss": 0.04561559509617171, "train/cont_pos_acc": 0.99994226895711, "train/cont_pos_loss": 0.00021238681451564353, "train/cont_pred": 0.9945191158091321, "train/cont_rate": 0.9945140165441176, "train/dyn_loss_mean": 15.344168915468103, "train/dyn_loss_std": 8.725013217505287, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9696373878156438, "train/extr_critic_critic_opt_grad_steps": 14225.0, "train/extr_critic_critic_opt_loss": 15839.88966997932, "train/extr_critic_mag": 4.641016364097595, "train/extr_critic_max": 4.641016364097595, "train/extr_critic_mean": 0.8504356027526014, "train/extr_critic_min": -0.1994664853110033, "train/extr_critic_std": 1.0014200061559677, "train/extr_return_normed_mag": 1.8400450506631065, "train/extr_return_normed_max": 1.8400450506631065, "train/extr_return_normed_mean": 0.3024237582131344, "train/extr_return_normed_min": -0.1294770661248442, "train/extr_return_normed_std": 0.3310683679712169, "train/extr_return_rate": 0.44575197644093456, "train/extr_return_raw_mag": 5.680859088897705, "train/extr_return_raw_max": 5.680859088897705, "train/extr_return_raw_mean": 0.8607257725123096, "train/extr_return_raw_min": -0.49331944939844746, "train/extr_return_raw_std": 1.038103721159346, "train/extr_reward_mag": 1.00747811794281, "train/extr_reward_max": 1.00747811794281, "train/extr_reward_mean": 0.02259527213926263, "train/extr_reward_min": -0.2912534738288206, "train/extr_reward_std": 0.13741082221488743, "train/image_loss_mean": 10.97355101739659, "train/image_loss_std": 14.183623433113098, "train/model_loss_mean": 20.237605445525226, "train/model_loss_std": 17.70804483750287, "train/model_opt_grad_norm": 78.66249471552231, "train/model_opt_grad_steps": 14208.47794117647, "train/model_opt_loss": 15201.812600528492, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 753.6764705882352, "train/policy_entropy_mag": 2.507039040327072, "train/policy_entropy_max": 2.507039040327072, "train/policy_entropy_mean": 0.6546679099693018, "train/policy_entropy_min": 0.07937531217056162, "train/policy_entropy_std": 0.6275789224926163, "train/policy_logprob_mag": 7.4383801747770875, "train/policy_logprob_max": -0.009455891510964754, "train/policy_logprob_mean": -0.653493262389127, "train/policy_logprob_min": -7.4383801747770875, "train/policy_logprob_std": 1.16053587548873, "train/policy_randomness_mag": 0.8848747624193921, "train/policy_randomness_max": 0.8848747624193921, "train/policy_randomness_mean": 0.23106904240215526, "train/policy_randomness_min": 0.028016001985901418, "train/policy_randomness_std": 0.22150782134164781, "train/post_ent_mag": 54.84117524764117, "train/post_ent_max": 54.84117524764117, "train/post_ent_mean": 37.695363745969885, "train/post_ent_min": 20.01392754386453, "train/post_ent_std": 6.812392925514894, "train/prior_ent_mag": 64.14294054928948, "train/prior_ent_max": 64.14294054928948, "train/prior_ent_mean": 53.118889303768384, "train/prior_ent_min": 37.05999931167154, "train/prior_ent_std": 4.506906516411725, "train/rep_loss_mean": 15.344168915468103, "train/rep_loss_std": 8.725013217505287, "train/reward_avg": 0.019761747303966654, "train/reward_loss_mean": 0.05709183672169114, "train/reward_loss_std": 0.2796638415140264, "train/reward_max_data": 1.0117647086872774, "train/reward_max_pred": 1.0045010990956251, "train/reward_neg_acc": 0.992637021576657, "train/reward_neg_loss": 0.033967039239702415, "train/reward_pos_acc": 0.9455299666699242, "train/reward_pos_loss": 0.9704184957286891, "train/reward_pred": 0.01895425171481774, "train/reward_rate": 0.0247802734375, "train_stats/sum_log_reward": 4.732478553922768, "train_stats/max_log_achievement_collect_drink": 4.786324786324786, "train_stats/max_log_achievement_collect_sapling": 2.5555555555555554, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.495726495726496, "train_stats/max_log_achievement_defeat_skeleton": 0.017094017094017096, "train_stats/max_log_achievement_defeat_zombie": 0.37606837606837606, "train_stats/max_log_achievement_eat_cow": 0.08547008547008547, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03418803418803419, "train_stats/max_log_achievement_make_wood_sword": 0.03418803418803419, "train_stats/max_log_achievement_place_plant": 2.3675213675213675, "train_stats/max_log_achievement_place_table": 2.230769230769231, "train_stats/max_log_achievement_wake_up": 1.9658119658119657, "train_stats/mean_log_entropy": 0.6180278607922741, "eval_stats/sum_log_reward": 3.9333332820485034, "eval_stats/max_log_achievement_collect_drink": 3.6666666666666665, "eval_stats/max_log_achievement_collect_sapling": 1.2916666666666667, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4166666666666667, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_table": 1.8333333333333333, "eval_stats/max_log_achievement_wake_up": 1.5416666666666667, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.0136986301369863, "eval_stats/max_log_achievement_eat_plant": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0005712992860935628, "report/cont_loss_std": 0.016497069969773293, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002709129825234413, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0005629156366921961, "report/cont_pred": 0.9956588745117188, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 17.236194610595703, "report/dyn_loss_std": 7.930413722991943, "report/image_loss_mean": 11.681537628173828, "report/image_loss_std": 12.860519409179688, "report/model_loss_mean": 22.079483032226562, "report/model_loss_std": 16.20541000366211, "report/post_ent_mag": 54.321964263916016, "report/post_ent_max": 54.321964263916016, "report/post_ent_mean": 36.17204284667969, "report/post_ent_min": 21.413902282714844, "report/post_ent_std": 6.2584638595581055, "report/prior_ent_mag": 64.46348571777344, "report/prior_ent_max": 64.46348571777344, "report/prior_ent_mean": 53.80351638793945, "report/prior_ent_min": 36.63546371459961, "report/prior_ent_std": 3.6084814071655273, "report/rep_loss_mean": 17.236194610595703, "report/rep_loss_std": 7.930413722991943, "report/reward_avg": 0.02685546875, "report/reward_loss_mean": 0.05565599352121353, "report/reward_loss_std": 0.2299024611711502, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0060579776763916, "report/reward_neg_acc": 0.9939454793930054, "report/reward_neg_loss": 0.03380092605948448, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.711970329284668, "report/reward_pred": 0.027080902829766273, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0005896773654967546, "eval/cont_loss_std": 0.012633845210075378, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0787024274468422, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0002063960419036448, "eval/cont_pred": 0.995263934135437, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.905197143554688, "eval/dyn_loss_std": 9.774165153503418, "eval/image_loss_mean": 16.74016571044922, "eval/image_loss_std": 23.600379943847656, "eval/model_loss_mean": 27.567325592041016, "eval/model_loss_std": 27.421297073364258, "eval/post_ent_mag": 54.52414321899414, "eval/post_ent_max": 54.52414321899414, "eval/post_ent_mean": 38.11286163330078, "eval/post_ent_min": 20.790157318115234, "eval/post_ent_std": 6.465927600860596, "eval/prior_ent_mag": 64.46348571777344, "eval/prior_ent_max": 64.46348571777344, "eval/prior_ent_mean": 53.94796371459961, "eval/prior_ent_min": 31.21346664428711, "eval/prior_ent_std": 3.7499895095825195, "eval/rep_loss_mean": 17.905197143554688, "eval/rep_loss_std": 9.774165153503418, "eval/reward_avg": 0.01689453050494194, "eval/reward_loss_mean": 0.08345247805118561, "eval/reward_loss_std": 0.5139378309249878, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999532699584961, "eval/reward_neg_acc": 0.9960079789161682, "eval/reward_neg_loss": 0.042625442147254944, "eval/reward_pos_acc": 0.7272727489471436, "eval/reward_pos_loss": 1.9429384469985962, "eval/reward_pred": 0.012607680633664131, "eval/reward_rate": 0.021484375, "replay/size": 239529.0, "replay/inserts": 21704.0, "replay/samples": 21696.0, "replay/insert_wait_avg": 1.3589112028353248e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.669812282629773e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 48520.0, "eval_replay/inserts": 5824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.226643939594646e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1025.4199182987213, "timer/env.step_count": 2713.0, "timer/env.step_total": 256.45164799690247, "timer/env.step_frac": 0.25009427203479967, "timer/env.step_avg": 0.09452696203350626, "timer/env.step_min": 0.022666215896606445, "timer/env.step_max": 3.2754602432250977, "timer/replay._sample_count": 21696.0, "timer/replay._sample_total": 11.289437055587769, "timer/replay._sample_frac": 0.01100957456952672, "timer/replay._sample_avg": 0.0005203464719574009, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.01000213623046875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3441.0, "timer/agent.policy_total": 55.835548877716064, "timer/agent.policy_frac": 0.05445139876973822, "timer/agent.policy_avg": 0.016226547189106672, "timer/agent.policy_min": 0.009378433227539062, "timer/agent.policy_max": 0.10795474052429199, "timer/dataset_train_count": 1356.0, "timer/dataset_train_total": 0.14721035957336426, "timer/dataset_train_frac": 0.00014356104942607475, "timer/dataset_train_avg": 0.00010856221207475241, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0010700225830078125, "timer/agent.train_count": 1356.0, "timer/agent.train_total": 607.3116402626038, "timer/agent.train_frac": 0.5922565277161742, "timer/agent.train_avg": 0.44786994119661044, "timer/agent.train_min": 0.43303513526916504, "timer/agent.train_max": 1.4798862934112549, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737234115600586, "timer/agent.report_frac": 0.0004619799197445035, "timer/agent.report_avg": 0.2368617057800293, "timer/agent.report_min": 0.23082232475280762, "timer/agent.report_max": 0.24290108680725098, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.208613693656652e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.165703869547098}
{"step": 240080, "time": 11402.646509170532, "episode/length": 237.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 240128, "time": 11405.793421030045, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 240544, "time": 11421.11041021347, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 240544, "time": 11421.122896194458, "episode/length": 393.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9898477157360406, "episode/intrinsic_return": 0.0}
{"step": 240720, "time": 11431.468144655228, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 241080, "time": 11445.181225061417, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 241160, "time": 11449.412994384766, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 241320, "time": 11456.259865522385, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 241752, "time": 11471.996171236038, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 241808, "time": 11475.582560062408, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 242088, "time": 11486.255614042282, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 242208, "time": 11491.94612455368, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 242304, "time": 11497.277403593063, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 242432, "time": 11503.670176744461, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 242960, "time": 11523.327955245972, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 242976, "time": 11525.318451881409, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 242984, "time": 11526.905710935593, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 243224, "time": 11536.339035272598, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 243232, "time": 11538.31631731987, "episode/length": 127.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 243448, "time": 11546.74536561966, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 243984, "time": 11566.310238361359, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 244448, "time": 11583.327966451645, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 244672, "time": 11592.174017906189, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 244680, "time": 11593.774911165237, "episode/length": 280.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715302491103203, "episode/intrinsic_return": 0.0}
{"step": 244712, "time": 11596.847197055817, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 244800, "time": 11601.604329109192, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 244968, "time": 11608.469999790192, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 245032, "time": 11612.248500823975, "episode/length": 44.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 245112, "time": 11616.37245798111, "episode/length": 268.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 245320, "time": 11624.796441316605, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 246128, "time": 11654.88957643509, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 246160, "time": 11657.449419736862, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 246312, "time": 11663.900454998016, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 246480, "time": 11671.315946102142, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 246592, "time": 11676.690350532532, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 246720, "time": 11682.558295726776, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 246784, "time": 11686.20685505867, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 247328, "time": 11705.8892827034, "episode/length": 286.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 247656, "time": 11717.962366580963, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 247680, "time": 11720.590880393982, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 247744, "time": 11724.292583942413, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 248440, "time": 11748.757120132446, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 248456, "time": 11750.945070266724, "episode/length": 216.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 248560, "time": 11756.177651882172, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 248648, "time": 11760.488211154938, "episode/length": 270.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 248888, "time": 11770.217758893967, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 249080, "time": 11778.271705150604, "episode/length": 166.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 249288, "time": 11787.024489402771, "episode/length": 244.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 249344, "time": 11790.606288433075, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 249728, "time": 11804.977824926376, "episode/length": 134.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 249848, "time": 11810.35034584999, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11837.806722402573, "eval_episode/length": 134.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 250016, "time": 11840.393855571747, "eval_episode/length": 154.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9870967741935484}
{"step": 250016, "time": 11842.305649995804, "eval_episode/length": 162.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 250016, "time": 11842.3132750988, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 250016, "time": 11845.902574300766, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 250016, "time": 11847.723887443542, "eval_episode/length": 36.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 250016, "time": 11849.816626787186, "eval_episode/length": 182.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.994535519125683}
{"step": 250016, "time": 11852.16903758049, "eval_episode/length": 200.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 250328, "time": 11862.224972009659, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 250368, "time": 11865.191249370575, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 250616, "time": 11874.891510009766, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 250632, "time": 11877.022113800049, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 250824, "time": 11885.017395019531, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 250920, "time": 11889.701779603958, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 250928, "time": 11891.818215370178, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 250936, "time": 11893.469836950302, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 251048, "time": 11898.777260303497, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 251608, "time": 11918.54848742485, "episode/length": 159.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 251840, "time": 11927.921414852142, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 251928, "time": 11932.302462816238, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 252408, "time": 11949.784632205963, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 252416, "time": 11951.822159290314, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 252496, "time": 11956.11213684082, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 252680, "time": 11963.558559656143, "episode/length": 219.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 252936, "time": 11973.549803256989, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 253440, "time": 11992.023062229156, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 253456, "time": 11994.00773859024, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 253592, "time": 11999.727856874466, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 253808, "time": 12008.625339984894, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 254152, "time": 12022.696251630783, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 254304, "time": 12029.552901983261, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 254320, "time": 12031.68360543251, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 254344, "time": 12033.866245031357, "episode/length": 426.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 254696, "time": 12047.031301498413, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 255072, "time": 12061.29835987091, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 255080, "time": 12062.864977121353, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 255232, "time": 12069.638030290604, "episode/length": 134.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 255392, "time": 12076.486107587814, "episode/length": 86.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 255432, "time": 12079.41690826416, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 255576, "time": 12085.788616418839, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 255896, "time": 12097.905285358429, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 255984, "time": 12102.561093091965, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 256104, "time": 12107.745410203934, "episode/length": 224.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 256560, "time": 12124.582818984985, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 256664, "time": 12129.310653686523, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 256888, "time": 12138.201337337494, "episode/length": 428.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 257008, "time": 12144.077870845795, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 257040, "time": 12146.698810338974, "episode/length": 225.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 257128, "time": 12150.947084903717, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 257264, "time": 12158.172792196274, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 257456, "time": 12166.138244867325, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 258152, "time": 12190.36329984665, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 258192, "time": 12193.537400484085, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 258328, "time": 12199.492364883423, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 258384, "time": 12203.086764097214, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 258672, "time": 12214.294227600098, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 258896, "time": 12223.140905857086, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 258968, "time": 12226.804241418839, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 259128, "time": 12233.654451847076, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 259584, "time": 12250.710488319397, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 259672, "time": 12254.991936206818, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 259688, "time": 12257.175270080566, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 259808, "time": 12263.217862129211, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 259888, "time": 12267.34374833107, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 259944, "time": 12270.507948160172, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12293.97160744667, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 260000, "time": 12295.784642457962, "eval_episode/length": 172.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 260000, "time": 12297.451324939728, "eval_episode/length": 173.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 260000, "time": 12299.516443014145, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 260000, "time": 12302.083184957504, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 260000, "time": 12303.68931889534, "eval_episode/length": 40.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.975609756097561}
{"step": 260000, "time": 12305.732285499573, "eval_episode/length": 224.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 260000, "time": 12309.216943979263, "eval_episode/length": 276.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9747292418772563}
{"step": 260672, "time": 12331.273353099823, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 260760, "time": 12335.466343164444, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 260776, "time": 12337.551493883133, "episode/length": 234.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 261048, "time": 12348.622467041016, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 261672, "time": 12370.85618519783, "episode/length": 222.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 261832, "time": 12377.876849889755, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 262016, "time": 12385.782341480255, "episode/length": 258.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 262136, "time": 12390.979846715927, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 262136, "time": 12390.986332893372, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 262176, "time": 12397.167545080185, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 262217, "time": 12400.88579916954, "train_stats/sum_log_reward": 4.837288056010917, "train_stats/max_log_achievement_collect_drink": 5.966101694915254, "train_stats/max_log_achievement_collect_sapling": 2.4491525423728815, "train_stats/max_log_achievement_collect_stone": 0.00847457627118644, "train_stats/max_log_achievement_collect_wood": 5.762711864406779, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.4576271186440678, "train_stats/max_log_achievement_eat_cow": 0.059322033898305086, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05084745762711865, "train_stats/max_log_achievement_make_wood_sword": 0.01694915254237288, "train_stats/max_log_achievement_place_plant": 2.2966101694915255, "train_stats/max_log_achievement_place_table": 2.2288135593220337, "train_stats/max_log_achievement_wake_up": 1.9406779661016949, "train_stats/mean_log_entropy": 0.590017556891603, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.420871213185701, "train/action_min": 0.0, "train/action_std": 3.1374819793289515, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05229784963692693, "train/actor_opt_grad_steps": 15600.0, "train/actor_opt_loss": -3.671191888318645, "train/adv_mag": 0.7904530081817572, "train/adv_max": 0.778972979500997, "train/adv_mean": 0.004273498887506066, "train/adv_min": -0.5192355655080123, "train/adv_std": 0.08011869702943795, "train/cont_avg": 0.9946043165467626, "train/cont_loss_mean": 0.00028549191854532516, "train/cont_loss_std": 0.007970465980810554, "train/cont_neg_acc": 0.9955464215587368, "train/cont_neg_loss": 0.018227365281398948, "train/cont_pos_acc": 0.9999575825046292, "train/cont_pos_loss": 0.00017529402767373631, "train/cont_pred": 0.9945927669676088, "train/cont_rate": 0.9946043165467626, "train/dyn_loss_mean": 15.246069880698224, "train/dyn_loss_std": 8.77275188020665, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9319249503046488, "train/extr_critic_critic_opt_grad_steps": 15600.0, "train/extr_critic_critic_opt_loss": 15672.600108194694, "train/extr_critic_mag": 4.556012397189792, "train/extr_critic_max": 4.556012397189792, "train/extr_critic_mean": 0.8383815674473056, "train/extr_critic_min": -0.2050171267214439, "train/extr_critic_std": 0.969841069025959, "train/extr_return_normed_mag": 1.8616951824092178, "train/extr_return_normed_max": 1.8616951824092178, "train/extr_return_normed_mean": 0.30853216950413137, "train/extr_return_normed_min": -0.14519414308367015, "train/extr_return_normed_std": 0.33437363406737075, "train/extr_return_rate": 0.44208026468325007, "train/extr_return_raw_mag": 5.531876070036305, "train/extr_return_raw_max": 5.531876070036305, "train/extr_return_raw_mean": 0.8512498624890829, "train/extr_return_raw_min": -0.5163289949619513, "train/extr_return_raw_std": 1.007829847524492, "train/extr_reward_mag": 1.0073207162267013, "train/extr_reward_max": 1.0073207162267013, "train/extr_reward_mean": 0.023234631135898957, "train/extr_reward_min": -0.31391891987203696, "train/extr_reward_std": 0.14018654603537894, "train/image_loss_mean": 10.091946739087001, "train/image_loss_std": 13.598700742927386, "train/model_loss_mean": 19.295711798633604, "train/model_loss_std": 17.126668086154854, "train/model_opt_grad_norm": 77.2669166043508, "train/model_opt_grad_steps": 15582.280575539568, "train/model_opt_loss": 13000.812696717627, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 669.9640287769785, "train/policy_entropy_mag": 2.5146444444176104, "train/policy_entropy_max": 2.5146444444176104, "train/policy_entropy_mean": 0.6298630177545891, "train/policy_entropy_min": 0.07937528938055038, "train/policy_entropy_std": 0.595295119843037, "train/policy_logprob_mag": 7.43838193605272, "train/policy_logprob_max": -0.009455877101625041, "train/policy_logprob_mean": -0.6296811185294776, "train/policy_logprob_min": -7.43838193605272, "train/policy_logprob_std": 1.148605906706062, "train/policy_randomness_mag": 0.8875591399000703, "train/policy_randomness_max": 0.8875591399000703, "train/policy_randomness_mean": 0.22231400463220885, "train/policy_randomness_min": 0.028015993950928717, "train/policy_randomness_std": 0.21011305498562272, "train/post_ent_mag": 55.3613477748075, "train/post_ent_max": 55.3613477748075, "train/post_ent_mean": 38.187759728740446, "train/post_ent_min": 19.972077994037875, "train/post_ent_std": 7.019593715667725, "train/prior_ent_mag": 64.42183317554941, "train/prior_ent_max": 64.42183317554941, "train/prior_ent_mean": 53.49981189974778, "train/prior_ent_min": 38.02730195299327, "train/prior_ent_std": 4.408015764016899, "train/rep_loss_mean": 15.246069880698224, "train/rep_loss_std": 8.77275188020665, "train/reward_avg": 0.02138461084138575, "train/reward_loss_mean": 0.0558376339592522, "train/reward_loss_std": 0.268843208392747, "train/reward_max_data": 1.0086330955834697, "train/reward_max_pred": 1.0046002144436184, "train/reward_neg_acc": 0.9929331536773297, "train/reward_neg_loss": 0.0316873845717997, "train/reward_pos_acc": 0.9451967087581004, "train/reward_pos_loss": 0.9566045013263071, "train/reward_pred": 0.0201385006737366, "train/reward_rate": 0.026205598021582732, "eval_stats/sum_log_reward": 4.662500008940697, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.1184155482624192e-05, "report/cont_loss_std": 0.00016075849998742342, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0021871565841138363, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.071564714853594e-07, "report/cont_pred": 0.9951274394989014, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 16.263391494750977, "report/dyn_loss_std": 8.225366592407227, "report/image_loss_mean": 10.68896770477295, "report/image_loss_std": 12.406784057617188, "report/model_loss_mean": 20.502927780151367, "report/model_loss_std": 15.655132293701172, "report/post_ent_mag": 56.283355712890625, "report/post_ent_max": 56.283355712890625, "report/post_ent_mean": 37.63652801513672, "report/post_ent_min": 20.61042022705078, "report/post_ent_std": 6.443394660949707, "report/prior_ent_mag": 65.15884399414062, "report/prior_ent_max": 65.15884399414062, "report/prior_ent_mean": 54.02979278564453, "report/prior_ent_min": 34.881595611572266, "report/prior_ent_std": 4.559054374694824, "report/rep_loss_mean": 16.263391494750977, "report/rep_loss_std": 8.225366592407227, "report/reward_avg": 0.01923828013241291, "report/reward_loss_mean": 0.05591478943824768, "report/reward_loss_std": 0.30111008882522583, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003267526626587, "report/reward_neg_acc": 0.9959959983825684, "report/reward_neg_loss": 0.03763902559876442, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.7862141728401184, "report/reward_pred": 0.01864093542098999, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.763848508242518e-05, "eval/cont_loss_std": 0.0008180402801372111, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0027476740069687366, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.701089579204563e-05, "eval/cont_pred": 0.9960779547691345, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.99583625793457, "eval/dyn_loss_std": 9.788311958312988, "eval/image_loss_mean": 19.293685913085938, "eval/image_loss_std": 20.165733337402344, "eval/model_loss_mean": 30.786209106445312, "eval/model_loss_std": 23.966096878051758, "eval/post_ent_mag": 57.65662384033203, "eval/post_ent_max": 57.65662384033203, "eval/post_ent_mean": 37.87569046020508, "eval/post_ent_min": 21.49045753479004, "eval/post_ent_std": 6.59531307220459, "eval/prior_ent_mag": 65.15884399414062, "eval/prior_ent_max": 65.15884399414062, "eval/prior_ent_mean": 53.898162841796875, "eval/prior_ent_min": 37.982093811035156, "eval/prior_ent_std": 4.604435920715332, "eval/rep_loss_mean": 18.99583625793457, "eval/rep_loss_std": 9.788311958312988, "eval/reward_avg": 0.01953125, "eval/reward_loss_mean": 0.09498591721057892, "eval/reward_loss_std": 0.7197983264923096, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0046107769012451, "eval/reward_neg_acc": 0.9900199770927429, "eval/reward_neg_loss": 0.03453440964221954, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 2.8482773303985596, "eval/reward_pred": 0.01662556268274784, "eval/reward_rate": 0.021484375, "replay/size": 261713.0, "replay/inserts": 22184.0, "replay/samples": 22192.0, "replay/insert_wait_avg": 1.3562367360513648e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.635475322335593e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52344.0, "eval_replay/inserts": 3824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 2.400396259259978e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0642559528351, "timer/env.step_count": 2773.0, "timer/env.step_total": 260.8119201660156, "timer/env.step_frac": 0.26079516252435286, "timer/env.step_avg": 0.0940540642502761, "timer/env.step_min": 0.022595882415771484, "timer/env.step_max": 4.38897442817688, "timer/replay._sample_count": 22192.0, "timer/replay._sample_total": 11.636382579803467, "timer/replay._sample_frac": 0.011635634920994778, "timer/replay._sample_avg": 0.000524350332543415, "timer/replay._sample_min": 0.0004177093505859375, "timer/replay._sample_max": 0.011313199996948242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3251.0, "timer/agent.policy_total": 53.752862215042114, "timer/agent.policy_frac": 0.053749408495584905, "timer/agent.policy_avg": 0.0165342547570108, "timer/agent.policy_min": 0.009060144424438477, "timer/agent.policy_max": 0.13573074340820312, "timer/dataset_train_count": 1387.0, "timer/dataset_train_total": 0.15080618858337402, "timer/dataset_train_frac": 0.0001507964990106459, "timer/dataset_train_avg": 0.00010872832630380247, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.00041747093200683594, "timer/agent.train_count": 1387.0, "timer/agent.train_total": 619.4003038406372, "timer/agent.train_frac": 0.6193605062411602, "timer/agent.train_avg": 0.4465755615289381, "timer/agent.train_min": 0.43287014961242676, "timer/agent.train_max": 1.4683043956756592, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4668135643005371, "timer/agent.report_frac": 0.00046678357067743545, "timer/agent.report_avg": 0.23340678215026855, "timer/agent.report_min": 0.22187018394470215, "timer/agent.report_max": 0.24494338035583496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456847273957263e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 22.182281822791982}
{"step": 262328, "time": 12404.399755954742, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 262712, "time": 12418.771975755692, "episode/length": 47.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 262848, "time": 12425.073425769806, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 263088, "time": 12434.59381866455, "episode/length": 409.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 263296, "time": 12443.234096765518, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 263408, "time": 12448.554208040237, "episode/length": 158.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 263520, "time": 12453.946647167206, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 264192, "time": 12477.770201683044, "episode/length": 392.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.989821882951654, "episode/intrinsic_return": 0.0}
{"step": 264288, "time": 12482.556293010712, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 264320, "time": 12485.305635929108, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 264544, "time": 12494.326464176178, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 264952, "time": 12509.286596536636, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 264992, "time": 12512.368834972382, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 265192, "time": 12520.287533044815, "episode/length": 376.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 265360, "time": 12527.566895484924, "episode/length": 229.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 265648, "time": 12538.83669924736, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 265680, "time": 12541.400083065033, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 265752, "time": 12545.213100671768, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 266176, "time": 12560.92431306839, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 266400, "time": 12569.845703840256, "episode/length": 231.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 266584, "time": 12577.242347478867, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 266696, "time": 12582.556326389313, "episode/length": 212.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 266848, "time": 12589.458796024323, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 266880, "time": 12592.21708226204, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 267072, "time": 12600.24621295929, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 267120, "time": 12603.388710737228, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 267800, "time": 12627.429087877274, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 267840, "time": 12630.423789024353, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 268040, "time": 12638.50414276123, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 268136, "time": 12643.258527040482, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 268200, "time": 12646.928418397903, "episode/length": 49.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 268280, "time": 12651.135142564774, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 268480, "time": 12659.435493946075, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 268512, "time": 12661.961171150208, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 268664, "time": 12668.337821006775, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 269152, "time": 12686.313894033432, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 269424, "time": 12696.997928380966, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 269736, "time": 12708.830813646317, "episode/length": 236.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 269824, "time": 12713.522053956985, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 269872, "time": 12716.655775547028, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 270032, "time": 12723.560099601746, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12746.602576255798, "eval_episode/length": 156.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 270088, "time": 12748.271964073181, "eval_episode/length": 159.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.99375}
{"step": 270088, "time": 12750.448679208755, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 270088, "time": 12752.917363166809, "eval_episode/length": 196.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 270088, "time": 12754.69414138794, "eval_episode/length": 40.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 270088, "time": 12756.275172710419, "eval_episode/length": 202.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 270088, "time": 12758.347199201584, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 270088, "time": 12761.101958274841, "eval_episode/length": 244.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9918367346938776}
{"step": 270096, "time": 12761.595375537872, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 270208, "time": 12766.759837388992, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 270400, "time": 12776.056316137314, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 270968, "time": 12796.668136119843, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 270992, "time": 12799.40099477768, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 271288, "time": 12810.432303667068, "episode/length": 134.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 271568, "time": 12821.572935819626, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 271720, "time": 12828.020504951477, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 271752, "time": 12830.794680833817, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 271960, "time": 12839.283301353455, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 272312, "time": 12852.471735954285, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 272544, "time": 12861.975506544113, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 272736, "time": 12870.071974992752, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 272800, "time": 12873.73516869545, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 272864, "time": 12877.378806114197, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 272960, "time": 12882.046082258224, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 273152, "time": 12890.118377447128, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 273208, "time": 12894.009676218033, "episode/length": 433.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9976958525345622, "episode/intrinsic_return": 0.0}
{"step": 273296, "time": 12899.324707984924, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 274000, "time": 12924.273981332779, "episode/length": 149.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 274056, "time": 12927.533160448074, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 274152, "time": 12932.40019440651, "episode/length": 124.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 274152, "time": 12932.409386873245, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 274232, "time": 12938.336266040802, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 274416, "time": 12946.235307216644, "episode/length": 150.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 274808, "time": 12960.61854314804, "episode/length": 71.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 275008, "time": 12969.143470048904, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 275424, "time": 12984.5410759449, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 275496, "time": 12988.367688655853, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 275792, "time": 13000.030547618866, "episode/length": 36.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 276128, "time": 13012.767695426941, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 276168, "time": 13015.424375772476, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 276200, "time": 13018.064060926437, "episode/length": 255.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 276240, "time": 13021.1392390728, "episode/length": 437.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 276336, "time": 13025.9528901577, "episode/length": 239.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 276752, "time": 13041.450432300568, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 277240, "time": 13059.062495231628, "episode/length": 226.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 277544, "time": 13070.893594264984, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 277552, "time": 13072.895825147629, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 277576, "time": 13075.036361455917, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 277592, "time": 13077.132080078125, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 277608, "time": 13079.161107301712, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 277736, "time": 13085.10068154335, "episode/length": 191.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 278432, "time": 13110.284378290176, "episode/length": 282.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 278440, "time": 13111.926968574524, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 278616, "time": 13120.816332101822, "episode/length": 133.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 278792, "time": 13128.158422231674, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 278848, "time": 13131.992712974548, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 278992, "time": 13138.760333538055, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 279152, "time": 13145.576246023178, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 279288, "time": 13151.88080072403, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 279760, "time": 13169.164063453674, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 280016, "time": 13179.147019147873, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13197.087311029434, "eval_episode/length": 40.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 280072, "time": 13202.432262897491, "eval_episode/length": 133.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 280072, "time": 13204.944262266159, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 280072, "time": 13206.653510570526, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 280072, "time": 13208.456549167633, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 280072, "time": 13210.043695688248, "eval_episode/length": 167.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 280072, "time": 13212.876068115234, "eval_episode/length": 35.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 280072, "time": 13214.598526477814, "eval_episode/length": 44.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 280312, "time": 13222.60355091095, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 280368, "time": 13226.20826792717, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 280480, "time": 13231.51741886139, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 280496, "time": 13233.654569149017, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 280560, "time": 13237.260340452194, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 280624, "time": 13240.922717094421, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 280816, "time": 13248.921980142593, "episode/length": 39.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 281352, "time": 13268.279153585434, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 281376, "time": 13270.89810037613, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 281472, "time": 13275.711043834686, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 281800, "time": 13287.949461221695, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 282048, "time": 13297.915142774582, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 282104, "time": 13301.214650154114, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 282120, "time": 13303.311511993408, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 282584, "time": 13320.176580667496, "episode/length": 150.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 282952, "time": 13333.860931634903, "episode/length": 112.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 283312, "time": 13347.749865293503, "episode/length": 229.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 283472, "time": 13354.825010061264, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 283608, "time": 13360.68844628334, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 283704, "time": 13365.473976373672, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 283736, "time": 13368.507989406586, "episode/length": 427.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 284504, "time": 13396.269429206848, "episode/length": 148.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 284569, "time": 13401.012843132019, "train_stats/sum_log_reward": 4.927586154691104, "train_stats/max_log_achievement_collect_drink": 5.327586206896552, "train_stats/max_log_achievement_collect_sapling": 2.293103448275862, "train_stats/max_log_achievement_collect_stone": 0.02586206896551724, "train_stats/max_log_achievement_collect_wood": 5.387931034482759, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.3793103448275862, "train_stats/max_log_achievement_eat_cow": 0.08620689655172414, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05172413793103448, "train_stats/max_log_achievement_make_wood_sword": 0.017241379310344827, "train_stats/max_log_achievement_place_plant": 2.1724137931034484, "train_stats/max_log_achievement_place_table": 2.146551724137931, "train_stats/max_log_achievement_wake_up": 1.8620689655172413, "train_stats/mean_log_entropy": 0.581460245724382, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4018633725831835, "train/action_min": 0.0, "train/action_std": 3.135705800365201, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05188814001224881, "train/actor_opt_grad_steps": 16990.0, "train/actor_opt_loss": -2.850501119286465, "train/adv_mag": 0.8002611583085368, "train/adv_max": 0.7868678149559515, "train/adv_mean": 0.004454842105188756, "train/adv_min": -0.5083334956237738, "train/adv_std": 0.0801964155096802, "train/cont_avg": 0.9942741119604317, "train/cont_loss_mean": 0.0004421405270872449, "train/cont_loss_std": 0.01222971613170433, "train/cont_neg_acc": 0.9845152471562941, "train/cont_neg_loss": 0.04361155539955892, "train/cont_pos_acc": 0.9999434544885759, "train/cont_pos_loss": 0.00020261962496750003, "train/cont_pred": 0.9942761818282038, "train/cont_rate": 0.9942741119604317, "train/dyn_loss_mean": 15.340282069693366, "train/dyn_loss_std": 8.6828793278701, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9179363010598601, "train/extr_critic_critic_opt_grad_steps": 16990.0, "train/extr_critic_critic_opt_loss": 15587.662221785073, "train/extr_critic_mag": 4.574414507090617, "train/extr_critic_max": 4.574414507090617, "train/extr_critic_mean": 0.855075834466399, "train/extr_critic_min": -0.19811646972628807, "train/extr_critic_std": 0.9819939659653808, "train/extr_return_normed_mag": 1.8863071700651868, "train/extr_return_normed_max": 1.8863071700651868, "train/extr_return_normed_mean": 0.30600141975090656, "train/extr_return_normed_min": -0.14889725528175024, "train/extr_return_normed_std": 0.33913362476465514, "train/extr_return_rate": 0.44230508450552714, "train/extr_return_raw_mag": 5.622482793794261, "train/extr_return_raw_max": 5.622482793794261, "train/extr_return_raw_mean": 0.8684640610389572, "train/extr_return_raw_min": -0.5000829207811425, "train/extr_return_raw_std": 1.020351680491468, "train/extr_reward_mag": 1.0091767911430742, "train/extr_reward_max": 1.0091767911430742, "train/extr_reward_mean": 0.023651443187334982, "train/extr_reward_min": -0.3361791029250879, "train/extr_reward_std": 0.14246200496773068, "train/image_loss_mean": 9.861737779576144, "train/image_loss_std": 13.576196183403619, "train/model_loss_mean": 19.12193067811376, "train/model_loss_std": 17.01471389111855, "train/model_opt_grad_norm": 71.12217394053508, "train/model_opt_grad_steps": 16971.589928057554, "train/model_opt_loss": 19106.655470155125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 993.705035971223, "train/policy_entropy_mag": 2.529332136936325, "train/policy_entropy_max": 2.529332136936325, "train/policy_entropy_mean": 0.648870919248183, "train/policy_entropy_min": 0.07937526413433843, "train/policy_entropy_std": 0.6243918984056377, "train/policy_logprob_mag": 7.438382255087654, "train/policy_logprob_max": -0.009455865188736281, "train/policy_logprob_mean": -0.6502805270737023, "train/policy_logprob_min": -7.438382255087654, "train/policy_logprob_std": 1.161435020913323, "train/policy_randomness_mag": 0.892743247447254, "train/policy_randomness_max": 0.892743247447254, "train/policy_randomness_mean": 0.22902295829580843, "train/policy_randomness_min": 0.02801598497271109, "train/policy_randomness_std": 0.22038294031894465, "train/post_ent_mag": 55.6749799440233, "train/post_ent_max": 55.6749799440233, "train/post_ent_mean": 38.279176259212356, "train/post_ent_min": 19.925471504815192, "train/post_ent_std": 7.087627664744425, "train/prior_ent_mag": 64.52128205882559, "train/prior_ent_max": 64.52128205882559, "train/prior_ent_mean": 53.73299635743066, "train/prior_ent_min": 38.35969859061481, "train/prior_ent_std": 4.254371883200227, "train/rep_loss_mean": 15.340282069693366, "train/rep_loss_std": 8.6828793278701, "train/reward_avg": 0.021393041655742864, "train/reward_loss_mean": 0.05558157974867512, "train/reward_loss_std": 0.2611390747826734, "train/reward_max_data": 1.0122302187432488, "train/reward_max_pred": 1.005318227431757, "train/reward_neg_acc": 0.9933457460334832, "train/reward_neg_loss": 0.03209949781273981, "train/reward_pos_acc": 0.9528010410370586, "train/reward_pos_loss": 0.9167569249653987, "train/reward_pred": 0.020361402206015674, "train/reward_rate": 0.02663416142086331, "train_stats/max_log_achievement_collect_coal": 0.009174311926605505, "train_stats/max_log_achievement_place_stone": 0.009174311926605505, "eval_stats/sum_log_reward": 4.412499971687794, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 4.7202456698869355e-07, "report/cont_loss_std": 3.5820892207993893e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.109041714807972e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.127690260702366e-07, "report/cont_pred": 0.9990231990814209, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 12.754047393798828, "report/dyn_loss_std": 8.093843460083008, "report/image_loss_mean": 7.444886207580566, "report/image_loss_std": 10.365013122558594, "report/model_loss_mean": 15.127725601196289, "report/model_loss_std": 13.858288764953613, "report/post_ent_mag": 57.46866226196289, "report/post_ent_max": 57.46866226196289, "report/post_ent_mean": 40.711605072021484, "report/post_ent_min": 20.523845672607422, "report/post_ent_std": 7.367021560668945, "report/prior_ent_mag": 64.21003723144531, "report/prior_ent_max": 64.21003723144531, "report/prior_ent_mean": 53.90080261230469, "report/prior_ent_min": 39.16996765136719, "report/prior_ent_std": 4.050693988800049, "report/rep_loss_mean": 12.754047393798828, "report/rep_loss_std": 8.093843460083008, "report/reward_avg": 0.01611328125, "report/reward_loss_mean": 0.030410075560212135, "report/reward_loss_std": 0.14475995302200317, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0040264129638672, "report/reward_neg_acc": 0.9920477867126465, "report/reward_neg_loss": 0.01684943586587906, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7882993221282959, "report/reward_pred": 0.01525157317519188, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 4.3859736251761205e-06, "eval/cont_loss_std": 7.76178203523159e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.599176701158285e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.664668156488915e-06, "eval/cont_pred": 0.9921847581863403, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 19.062294006347656, "eval/dyn_loss_std": 9.903294563293457, "eval/image_loss_mean": 15.478313446044922, "eval/image_loss_std": 23.033647537231445, "eval/model_loss_mean": 26.990924835205078, "eval/model_loss_std": 26.733488082885742, "eval/post_ent_mag": 53.66580581665039, "eval/post_ent_max": 53.66580581665039, "eval/post_ent_mean": 38.02751922607422, "eval/post_ent_min": 21.536048889160156, "eval/post_ent_std": 6.81132698059082, "eval/prior_ent_mag": 64.21003723144531, "eval/prior_ent_max": 64.21003723144531, "eval/prior_ent_mean": 54.64905548095703, "eval/prior_ent_min": 41.27469253540039, "eval/prior_ent_std": 3.7253763675689697, "eval/rep_loss_mean": 19.062294006347656, "eval/rep_loss_std": 9.903294563293457, "eval/reward_avg": 0.02167968824505806, "eval/reward_loss_mean": 0.07522985339164734, "eval/reward_loss_std": 0.370514452457428, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0032105445861816, "eval/reward_neg_acc": 0.9899497628211975, "eval/reward_neg_loss": 0.04554714635014534, "eval/reward_pos_acc": 0.931034505367279, "eval/reward_pos_loss": 1.0936537981033325, "eval/reward_pred": 0.018717147409915924, "eval/reward_rate": 0.0283203125, "replay/size": 284065.0, "replay/inserts": 22352.0, "replay/samples": 22352.0, "replay/insert_wait_avg": 1.3709708290946594e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.646418334589572e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 55920.0, "eval_replay/inserts": 3576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1732914303773202e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1143217086792, "timer/env.step_count": 2794.0, "timer/env.step_total": 258.0361397266388, "timer/env.step_frac": 0.25800664396625, "timer/env.step_avg": 0.09235366489858225, "timer/env.step_min": 0.02234649658203125, "timer/env.step_max": 3.3051509857177734, "timer/replay._sample_count": 22352.0, "timer/replay._sample_total": 11.641816854476929, "timer/replay._sample_frac": 0.011640486094216782, "timer/replay._sample_avg": 0.0005208400525446013, "timer/replay._sample_min": 0.00038814544677734375, "timer/replay._sample_max": 0.010951995849609375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3241.0, "timer/agent.policy_total": 52.20139527320862, "timer/agent.policy_frac": 0.05219542820267124, "timer/agent.policy_avg": 0.016106570587228825, "timer/agent.policy_min": 0.009322404861450195, "timer/agent.policy_max": 0.10222268104553223, "timer/dataset_train_count": 1397.0, "timer/dataset_train_total": 0.15191054344177246, "timer/dataset_train_frac": 0.00015189317875404057, "timer/dataset_train_avg": 0.00010874054648659445, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0004801750183105469, "timer/agent.train_count": 1397.0, "timer/agent.train_total": 625.341227054596, "timer/agent.train_frac": 0.6252697451489451, "timer/agent.train_avg": 0.44763151542920254, "timer/agent.train_min": 0.431854248046875, "timer/agent.train_max": 1.4588265419006348, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47704529762268066, "timer/agent.report_frac": 0.00047699076722314753, "timer/agent.report_avg": 0.23852264881134033, "timer/agent.report_min": 0.23174667358398438, "timer/agent.report_max": 0.2452986240386963, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003730705053074e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 22.34914229324998}
{"step": 284736, "time": 13406.61781334877, "episode/length": 268.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9702602230483272, "episode/intrinsic_return": 0.0}
{"step": 284752, "time": 13408.721632242203, "episode/length": 424.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976470588235294, "episode/intrinsic_return": 0.0}
{"step": 284776, "time": 13410.87410902977, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 284840, "time": 13415.148813962936, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 284856, "time": 13417.245221376419, "episode/length": 43.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 284888, "time": 13419.90380525589, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 284960, "time": 13424.001364707947, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 285016, "time": 13427.196148395538, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 285568, "time": 13447.268850803375, "episode/length": 103.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 286128, "time": 13467.45054769516, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 286280, "time": 13473.913370847702, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 286304, "time": 13476.88233089447, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 286400, "time": 13481.60260438919, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 286416, "time": 13483.736106395721, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 286520, "time": 13488.691654205322, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 286568, "time": 13491.99676156044, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 286784, "time": 13502.320631742477, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 287616, "time": 13531.481890678406, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 287680, "time": 13535.315334320068, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 287688, "time": 13536.976912736893, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 287784, "time": 13541.65984082222, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 287840, "time": 13545.3304708004, "episode/length": 213.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 288024, "time": 13553.386239528656, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 288184, "time": 13560.424757242203, "episode/length": 42.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 288256, "time": 13564.652513742447, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 288784, "time": 13583.676295995712, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 288856, "time": 13587.388752937317, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 289024, "time": 13594.764006137848, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 289096, "time": 13598.723591566086, "episode/length": 133.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 289104, "time": 13600.728070020676, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 289488, "time": 13615.253699064255, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 289496, "time": 13616.802657365799, "episode/length": 48.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 289552, "time": 13620.413324594498, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 289976, "time": 13635.785903930664, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13661.985135316849, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 290056, "time": 13661.99373626709, "eval_episode/length": 169.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 290056, "time": 13666.376512527466, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9548022598870056}
{"step": 290056, "time": 13668.82956314087, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 290056, "time": 13671.59434914589, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 290056, "time": 13674.805195093155, "eval_episode/length": 220.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9864253393665159}
{"step": 290056, "time": 13677.112672567368, "eval_episode/length": 226.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 290056, "time": 13680.284013032913, "eval_episode/length": 53.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 290336, "time": 13689.83620429039, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 290408, "time": 13693.58268404007, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 290432, "time": 13696.077744722366, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 290880, "time": 13712.487920999527, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 290912, "time": 13715.062291622162, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 290912, "time": 13715.092842817307, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 291552, "time": 13739.825574159622, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 291552, "time": 13739.83714723587, "episode/length": 336.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 291648, "time": 13746.218890428543, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 292352, "time": 13771.208266735077, "episode/length": 239.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 292440, "time": 13775.520621299744, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 293024, "time": 13797.03515124321, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 293072, "time": 13800.325718164444, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 293112, "time": 13803.026197910309, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 293168, "time": 13806.673014163971, "episode/length": 344.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942028985507246, "episode/intrinsic_return": 0.0}
{"step": 293256, "time": 13810.96805882454, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 293888, "time": 13833.829227924347, "episode/length": 371.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 293992, "time": 13838.537950992584, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 294080, "time": 13843.221816778183, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 294184, "time": 13848.103701353073, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 294560, "time": 13862.483976840973, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 294712, "time": 13868.928578138351, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 294720, "time": 13870.91014456749, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 294760, "time": 13873.590085983276, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 294848, "time": 13878.40840268135, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 295416, "time": 13900.299197912216, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 295488, "time": 13904.494883775711, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 295736, "time": 13914.34487605095, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 295880, "time": 13920.778754472733, "episode/length": 48.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 296048, "time": 13928.217370986938, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 296056, "time": 13929.844889640808, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 296088, "time": 13932.438227653503, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 296352, "time": 13943.063959121704, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 296368, "time": 13945.219963312149, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 296672, "time": 13956.914692163467, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 296944, "time": 13967.498431444168, "episode/length": 33.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 297184, "time": 13977.23674440384, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 297224, "time": 13979.94231915474, "episode/length": 225.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 297328, "time": 13985.192467451096, "episode/length": 47.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 297472, "time": 13991.533724546432, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 297680, "time": 14000.014544725418, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 297760, "time": 14004.275501966476, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 298232, "time": 14021.243764400482, "episode/length": 433.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 298352, "time": 14027.11992096901, "episode/length": 437.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 298680, "time": 14039.456119775772, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 298816, "time": 14045.69034075737, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 298888, "time": 14049.345503807068, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 299208, "time": 14061.629059791565, "episode/length": 252.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 299304, "time": 14066.328144073486, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 299536, "time": 14075.722467899323, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 299552, "time": 14077.896802902222, "episode/length": 223.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 299688, "time": 14083.82293343544, "episode/length": 276.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14111.80715227127, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 300040, "time": 14117.987943649292, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 300040, "time": 14120.131745576859, "eval_episode/length": 165.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 300040, "time": 14122.183297157288, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 300040, "time": 14124.540822029114, "eval_episode/length": 197.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 300040, "time": 14126.466364383698, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 300040, "time": 14126.47454380989, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 300040, "time": 14131.259283304214, "eval_episode/length": 242.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 300184, "time": 14136.055903673172, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 300400, "time": 14144.938870668411, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 300688, "time": 14156.087388038635, "episode/length": 224.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 301000, "time": 14167.804198026657, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 301192, "time": 14175.767453432083, "episode/length": 206.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 301200, "time": 14177.91560292244, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 301216, "time": 14180.211249828339, "episode/length": 238.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 301336, "time": 14185.54984164238, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 301768, "time": 14201.29297709465, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 302360, "time": 14222.55536866188, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 302448, "time": 14227.35880947113, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 302528, "time": 14231.689718723297, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 303048, "time": 14250.328350543976, "episode/length": 294.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 303192, "time": 14258.163870334625, "episode/length": 348.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.997134670487106, "episode/intrinsic_return": 0.0}
{"step": 303352, "time": 14265.003118038177, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 303528, "time": 14273.09284567833, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 303544, "time": 14275.556786775589, "episode/length": 293.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 303768, "time": 14284.567576169968, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 303888, "time": 14290.35571885109, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 304280, "time": 14305.092262506485, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 304456, "time": 14313.24736237526, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 304712, "time": 14323.852516412735, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 304744, "time": 14326.395065784454, "episode/length": 35.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 304848, "time": 14331.719124794006, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 304856, "time": 14333.356796264648, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 304984, "time": 14339.266733407974, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 305024, "time": 14342.87876701355, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 305184, "time": 14350.282568693161, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 305304, "time": 14355.518445253372, "episode/length": 39.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 305848, "time": 14375.171723604202, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 306024, "time": 14382.539736032486, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 306336, "time": 14394.676789999008, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 306432, "time": 14399.570052623749, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 306433, "time": 14402.23681139946, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.61297607421875, "train/action_min": 0.0, "train/action_std": 3.3025460086599754, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05093151279283266, "train/actor_opt_grad_steps": 18370.0, "train/actor_opt_loss": -2.674032743612345, "train/adv_mag": 0.7357374003333766, "train/adv_max": 0.7230509935069258, "train/adv_mean": 0.004234833672847072, "train/adv_min": -0.5224554432134558, "train/adv_std": 0.07852159277366026, "train/cont_avg": 0.9945683166058394, "train/cont_loss_mean": 0.0002654822107503861, "train/cont_loss_std": 0.007340099293101612, "train/cont_neg_acc": 0.9904414328345417, "train/cont_neg_loss": 0.0333297739539807, "train/cont_pos_acc": 0.9999497789536079, "train/cont_pos_loss": 0.00012823270990823055, "train/cont_pred": 0.9945477669256447, "train/cont_rate": 0.9945683166058394, "train/dyn_loss_mean": 15.353784310556676, "train/dyn_loss_std": 8.730289427903447, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9773661746595897, "train/extr_critic_critic_opt_grad_steps": 18370.0, "train/extr_critic_critic_opt_loss": 15724.100721373175, "train/extr_critic_mag": 4.628970706549874, "train/extr_critic_max": 4.628970706549874, "train/extr_critic_mean": 0.8741607148281849, "train/extr_critic_min": -0.20526081367130697, "train/extr_critic_std": 0.991825095493428, "train/extr_return_normed_mag": 1.8667829271650662, "train/extr_return_normed_max": 1.8667829271650662, "train/extr_return_normed_mean": 0.31221909581744756, "train/extr_return_normed_min": -0.13836550806397505, "train/extr_return_normed_std": 0.33471018521890156, "train/extr_return_rate": 0.46049225025803503, "train/extr_return_raw_mag": 5.663326896890236, "train/extr_return_raw_max": 5.663326896890236, "train/extr_return_raw_mean": 0.8871288765085875, "train/extr_return_raw_min": -0.4972454540050813, "train/extr_return_raw_std": 1.0283994170000954, "train/extr_reward_mag": 1.0110044096508166, "train/extr_reward_max": 1.0110044096508166, "train/extr_reward_mean": 0.024794800213816828, "train/extr_reward_min": -0.3316987509275005, "train/extr_reward_std": 0.1452963595842793, "train/image_loss_mean": 9.564526881614741, "train/image_loss_std": 13.841224656487903, "train/model_loss_mean": 18.832246091243995, "train/model_loss_std": 17.317066317927228, "train/model_opt_grad_norm": 69.76038165684164, "train/model_opt_grad_steps": 18351.0, "train/model_opt_loss": 19721.888621977647, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1053.8321167883212, "train/policy_entropy_mag": 2.474614815120279, "train/policy_entropy_max": 2.474614815120279, "train/policy_entropy_mean": 0.7022408355761619, "train/policy_entropy_min": 0.079375246798035, "train/policy_entropy_std": 0.6756869432699941, "train/policy_logprob_mag": 7.438382239237319, "train/policy_logprob_max": -0.009455810375783566, "train/policy_logprob_mean": -0.7021026981137964, "train/policy_logprob_min": -7.438382239237319, "train/policy_logprob_std": 1.1804050346360588, "train/policy_randomness_mag": 0.8734304326294112, "train/policy_randomness_max": 0.8734304326294112, "train/policy_randomness_mean": 0.2478601994523167, "train/policy_randomness_min": 0.028015978661549354, "train/policy_randomness_std": 0.2384878404601647, "train/post_ent_mag": 55.49792956609796, "train/post_ent_max": 55.49792956609796, "train/post_ent_mean": 38.337942944826004, "train/post_ent_min": 19.778755682228255, "train/post_ent_std": 7.087985345046886, "train/prior_ent_mag": 64.75671564923586, "train/prior_ent_max": 64.75671564923586, "train/prior_ent_mean": 53.74332174593515, "train/prior_ent_min": 38.68624712254879, "train/prior_ent_std": 4.208075283217604, "train/rep_loss_mean": 15.353784310556676, "train/rep_loss_std": 8.730289427903447, "train/reward_avg": 0.02204465094518705, "train/reward_loss_mean": 0.05518321982537308, "train/reward_loss_std": 0.25758882269372035, "train/reward_max_data": 1.0072992718132743, "train/reward_max_pred": 1.0050503346171693, "train/reward_neg_acc": 0.9927233313992075, "train/reward_neg_loss": 0.03174816321472834, "train/reward_pos_acc": 0.9556406523189406, "train/reward_pos_loss": 0.9085584461253925, "train/reward_pred": 0.02121500910878399, "train/reward_rate": 0.026830520072992702, "train_stats/sum_log_reward": 4.789075577334196, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.176470588235294, "train_stats/max_log_achievement_collect_sapling": 2.4873949579831933, "train_stats/max_log_achievement_collect_stone": 0.05042016806722689, "train_stats/max_log_achievement_collect_wood": 6.016806722689076, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.33613445378151263, "train_stats/max_log_achievement_eat_cow": 0.058823529411764705, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.15126050420168066, "train_stats/max_log_achievement_make_wood_sword": 0.01680672268907563, "train_stats/max_log_achievement_place_plant": 2.2605042016806722, "train_stats/max_log_achievement_place_stone": 0.008403361344537815, "train_stats/max_log_achievement_place_table": 2.369747899159664, "train_stats/max_log_achievement_wake_up": 1.9747899159663866, "train_stats/mean_log_entropy": 0.6491473593882152, "eval_stats/sum_log_reward": 4.287499912083149, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.1875, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.014285714285714285, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.175704816589132e-06, "report/cont_loss_std": 9.28211011341773e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002835783816408366, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.3547366911079735e-06, "report/cont_pred": 0.9970678091049194, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.525075912475586, "report/dyn_loss_std": 8.7383451461792, "report/image_loss_mean": 8.442010879516602, "report/image_loss_std": 13.535811424255371, "report/model_loss_mean": 17.190231323242188, "report/model_loss_std": 17.25890350341797, "report/post_ent_mag": 56.28536605834961, "report/post_ent_max": 56.28536605834961, "report/post_ent_mean": 39.215850830078125, "report/post_ent_min": 21.45760726928711, "report/post_ent_std": 7.719019889831543, "report/prior_ent_mag": 64.7786865234375, "report/prior_ent_max": 64.7786865234375, "report/prior_ent_mean": 54.19887161254883, "report/prior_ent_min": 42.39204406738281, "report/prior_ent_std": 3.8189289569854736, "report/rep_loss_mean": 14.525075912475586, "report/rep_loss_std": 8.7383451461792, "report/reward_avg": 0.01904296875, "report/reward_loss_mean": 0.03317023441195488, "report/reward_loss_std": 0.2400292158126831, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9997178316116333, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009379379451274872, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 1.1167356967926025, "report/reward_pred": 0.015720339491963387, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.690031321137212e-05, "eval/cont_loss_std": 0.0015335779171437025, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00012078694999217987, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.664976924890652e-05, "eval/cont_pred": 0.9960390329360962, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.998178482055664, "eval/dyn_loss_std": 9.499863624572754, "eval/image_loss_mean": 18.919260025024414, "eval/image_loss_std": 21.29452896118164, "eval/model_loss_mean": 29.80377197265625, "eval/model_loss_std": 24.795547485351562, "eval/post_ent_mag": 55.63963317871094, "eval/post_ent_max": 55.63963317871094, "eval/post_ent_mean": 38.96411895751953, "eval/post_ent_min": 21.170289993286133, "eval/post_ent_std": 6.836308002471924, "eval/prior_ent_mag": 64.7786865234375, "eval/prior_ent_max": 64.7786865234375, "eval/prior_ent_mean": 54.58253479003906, "eval/prior_ent_min": 38.78467559814453, "eval/prior_ent_std": 4.125630855560303, "eval/rep_loss_mean": 17.998178482055664, "eval/rep_loss_std": 9.499863624572754, "eval/reward_avg": 0.01171875, "eval/reward_loss_mean": 0.08554814755916595, "eval/reward_loss_std": 0.561741828918457, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9992368221282959, "eval/reward_neg_acc": 0.9890873432159424, "eval/reward_neg_loss": 0.04747478663921356, "eval/reward_pos_acc": 0.6875, "eval/reward_pos_loss": 2.4841699600219727, "eval/reward_pred": 0.009436125867068768, "eval/reward_rate": 0.015625, "replay/size": 305929.0, "replay/inserts": 21864.0, "replay/samples": 21856.0, "replay/insert_wait_avg": 1.362357608922183e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.109016567861353e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 59864.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.203094969898402e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2045347690582, "timer/env.step_count": 2733.0, "timer/env.step_total": 264.10380029678345, "timer/env.step_frac": 0.26378606081493894, "timer/env.step_avg": 0.09663512634349924, "timer/env.step_min": 0.021626710891723633, "timer/env.step_max": 3.382150173187256, "timer/replay._sample_count": 21856.0, "timer/replay._sample_total": 11.439112663269043, "timer/replay._sample_frac": 0.011425350431425717, "timer/replay._sample_avg": 0.000523385462265238, "timer/replay._sample_min": 0.0003829002380371094, "timer/replay._sample_max": 0.010339021682739258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3226.0, "timer/agent.policy_total": 53.43825030326843, "timer/agent.policy_frac": 0.05337395951327239, "timer/agent.policy_avg": 0.016564863702191082, "timer/agent.policy_min": 0.009348392486572266, "timer/agent.policy_max": 0.12889409065246582, "timer/dataset_train_count": 1366.0, "timer/dataset_train_total": 0.1478276252746582, "timer/dataset_train_frac": 0.0001476497759858396, "timer/dataset_train_avg": 0.0001082193450034101, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0004978179931640625, "timer/agent.train_count": 1366.0, "timer/agent.train_total": 613.5293383598328, "timer/agent.train_frac": 0.6127912100411649, "timer/agent.train_avg": 0.44914300026342074, "timer/agent.train_min": 0.43384718894958496, "timer/agent.train_max": 1.552516222000122, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47347021102905273, "timer/agent.report_frac": 0.00047290058583111116, "timer/agent.report_avg": 0.23673510551452637, "timer/agent.report_min": 0.22861051559448242, "timer/agent.report_max": 0.2448596954345703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9052072419048683e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.837375806007817}
{"step": 306488, "time": 14404.201411008835, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 306608, "time": 14410.471236944199, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 306840, "time": 14419.693856477737, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 306856, "time": 14421.67645740509, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 307856, "time": 14456.709264755249, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 307872, "time": 14458.814267158508, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 307960, "time": 14463.105068445206, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 307984, "time": 14465.602428674698, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 308072, "time": 14469.846477270126, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 308152, "time": 14474.102576971054, "episode/length": 287.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 308216, "time": 14477.775915622711, "episode/length": 171.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 308256, "time": 14480.995130300522, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 308296, "time": 14483.63974738121, "episode/length": 225.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 309224, "time": 14516.104115009308, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 309672, "time": 14532.490509748459, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 309752, "time": 14536.641851902008, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 309816, "time": 14540.394839286804, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 309984, "time": 14547.800763845444, "episode/length": 249.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 310016, "time": 14550.42048406601, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14566.964285612106, "eval_episode/length": 42.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 310024, "time": 14572.970512628555, "eval_episode/length": 146.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 310024, "time": 14575.144994020462, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 310024, "time": 14576.806003808975, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 310024, "time": 14579.027932405472, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 310024, "time": 14580.642226934433, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 310024, "time": 14583.06097984314, "eval_episode/length": 34.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 310024, "time": 14585.320054531097, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 310656, "time": 14606.595814466476, "episode/length": 349.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 311080, "time": 14622.007283210754, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 311160, "time": 14626.142290592194, "episode/length": 375.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867021276595744, "episode/intrinsic_return": 0.0}
{"step": 311264, "time": 14631.399822235107, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 311328, "time": 14636.559597969055, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 311336, "time": 14638.174252033234, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 311576, "time": 14647.63761806488, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 311856, "time": 14658.680953025818, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 312256, "time": 14673.54394698143, "episode/length": 49.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 312272, "time": 14675.664138555527, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 312560, "time": 14686.761393070221, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 312648, "time": 14691.102187633514, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 312728, "time": 14695.215831518173, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 313000, "time": 14705.782403469086, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 313192, "time": 14713.672671079636, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 313280, "time": 14718.552684545517, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 313632, "time": 14731.96835064888, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 313704, "time": 14735.679015874863, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 314080, "time": 14749.950825214386, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 314120, "time": 14752.576160430908, "episode/length": 104.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 314184, "time": 14756.296689510345, "episode/length": 240.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 314208, "time": 14758.91715168953, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 314240, "time": 14761.472564935684, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 314496, "time": 14771.62583899498, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 314576, "time": 14776.00821852684, "episode/length": 45.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 315240, "time": 14799.630676269531, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 315424, "time": 14807.53347992897, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 315456, "time": 14810.297048330307, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 315464, "time": 14812.042146205902, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 316112, "time": 14835.283693313599, "episode/length": 300.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 316224, "time": 14840.545090913773, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 316616, "time": 14854.878636360168, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 316768, "time": 14861.685960531235, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 316776, "time": 14863.292460680008, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 316888, "time": 14868.58326792717, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 316976, "time": 14873.236694574356, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 317104, "time": 14878.983830690384, "episode/length": 315.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 317568, "time": 14895.8902592659, "episode/length": 415.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 317960, "time": 14910.209386348724, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 318104, "time": 14916.542781829834, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 318440, "time": 14929.422914028168, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 318656, "time": 14938.355031728745, "episode/length": 254.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 318688, "time": 14941.057683706284, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 318856, "time": 14947.962408065796, "episode/length": 260.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 318936, "time": 14952.05697464943, "episode/length": 61.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 319240, "time": 14963.744809150696, "episode/length": 208.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9904306220095693, "episode/intrinsic_return": 0.0}
{"step": 319360, "time": 14969.501323223114, "episode/length": 281.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 319424, "time": 14973.225243806839, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 319888, "time": 14991.802062273026, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15015.7790517807, "eval_episode/length": 120.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9917355371900827}
{"step": 320008, "time": 15018.89684343338, "eval_episode/length": 138.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9640287769784173}
{"step": 320008, "time": 15021.533672571182, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 320008, "time": 15024.288343191147, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 320008, "time": 15027.368569850922, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 320008, "time": 15029.492228984833, "eval_episode/length": 192.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 320008, "time": 15033.566043138504, "eval_episode/length": 235.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 320008, "time": 15038.894620656967, "eval_episode/length": 308.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9870550161812298}
{"step": 320192, "time": 15045.441777706146, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 320504, "time": 15058.043007612228, "episode/length": 226.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 320576, "time": 15062.217895269394, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 320880, "time": 15073.867313146591, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 320960, "time": 15078.022161006927, "episode/length": 47.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 321128, "time": 15085.057329893112, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 321168, "time": 15088.266347646713, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 321192, "time": 15090.412638187408, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 321440, "time": 15100.440943717957, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 321608, "time": 15107.29996085167, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 321616, "time": 15109.520075798035, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940298507462687, "episode/intrinsic_return": 0.0}
{"step": 322048, "time": 15125.349811077118, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 322384, "time": 15138.204316854477, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 322488, "time": 15143.017112255096, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 322632, "time": 15149.471305131912, "episode/length": 148.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 322664, "time": 15152.107361793518, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 322680, "time": 15154.205306768417, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 322936, "time": 15164.860552072525, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 323240, "time": 15176.51387166977, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 323680, "time": 15192.985713005066, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 323856, "time": 15200.524331569672, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 324040, "time": 15208.04711842537, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 324264, "time": 15217.082200288773, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 324560, "time": 15228.744414567947, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 324864, "time": 15240.547862529755, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 324920, "time": 15243.680176973343, "episode/length": 279.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 325520, "time": 15265.396378278732, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 325584, "time": 15269.073467969894, "episode/length": 237.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 325616, "time": 15271.71909570694, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 325848, "time": 15280.674434900284, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 325880, "time": 15283.293236494064, "episode/length": 436.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 326088, "time": 15291.822425603867, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 326136, "time": 15294.935137987137, "episode/length": 196.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 326192, "time": 15298.605291843414, "episode/length": 240.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 326576, "time": 15312.989125013351, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 327008, "time": 15328.920011758804, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 327032, "time": 15331.045585155487, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 327040, "time": 15333.044892072678, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 327416, "time": 15346.873039007187, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 327616, "time": 15355.305042266846, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567567567567568, "episode/intrinsic_return": 0.0}
{"step": 327688, "time": 15359.43369936943, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 328200, "time": 15379.744059562683, "episode/length": 322.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 328336, "time": 15386.10944199562, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 328504, "time": 15393.06330037117, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 328568, "time": 15396.793011188507, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 328641, "time": 15402.241655349731, "train_stats/sum_log_reward": 5.161946856870061, "train_stats/max_log_achievement_collect_coal": 0.008849557522123894, "train_stats/max_log_achievement_collect_drink": 5.353982300884955, "train_stats/max_log_achievement_collect_sapling": 2.84070796460177, "train_stats/max_log_achievement_collect_stone": 0.05309734513274336, "train_stats/max_log_achievement_collect_wood": 6.070796460176991, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.3805309734513274, "train_stats/max_log_achievement_eat_cow": 0.07079646017699115, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07964601769911504, "train_stats/max_log_achievement_make_wood_sword": 0.017699115044247787, "train_stats/max_log_achievement_place_plant": 2.690265486725664, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.353982300884956, "train_stats/max_log_achievement_wake_up": 1.9380530973451326, "train_stats/mean_log_entropy": 0.5597925779566301, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.321203876742356, "train/action_min": 0.0, "train/action_std": 2.9328534431594737, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04978946341777877, "train/actor_opt_grad_steps": 19750.0, "train/actor_opt_loss": -3.4854839860106543, "train/adv_mag": 0.7415135052564333, "train/adv_max": 0.7203707823650443, "train/adv_mean": 0.003958233687443281, "train/adv_min": -0.529654819116318, "train/adv_std": 0.07616911410427779, "train/cont_avg": 0.9945972909172662, "train/cont_loss_mean": 0.0004397857214552224, "train/cont_loss_std": 0.012903047045895835, "train/cont_neg_acc": 0.984132695112297, "train/cont_neg_loss": 0.05958455333535744, "train/cont_pos_acc": 0.9999434815036307, "train/cont_pos_loss": 0.0001675924736696145, "train/cont_pred": 0.9946028525880772, "train/cont_rate": 0.9945972909172662, "train/dyn_loss_mean": 15.265494463255079, "train/dyn_loss_std": 8.698420826479685, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8672558489463312, "train/extr_critic_critic_opt_grad_steps": 19750.0, "train/extr_critic_critic_opt_loss": 15629.86005648606, "train/extr_critic_mag": 4.675658510743285, "train/extr_critic_max": 4.675658510743285, "train/extr_critic_mean": 0.824656383811141, "train/extr_critic_min": -0.20415420669445888, "train/extr_critic_std": 0.9993507540483269, "train/extr_return_normed_mag": 1.8869915806132256, "train/extr_return_normed_max": 1.8869915806132256, "train/extr_return_normed_mean": 0.28937738147570935, "train/extr_return_normed_min": -0.14203738421201706, "train/extr_return_normed_std": 0.33252311739132556, "train/extr_return_rate": 0.4201673264983747, "train/extr_return_raw_mag": 5.805333415381343, "train/extr_return_raw_max": 5.805333415381343, "train/extr_return_raw_mean": 0.8369186672804166, "train/extr_return_raw_min": -0.5042735008027056, "train/extr_return_raw_std": 1.0339162890002025, "train/extr_reward_mag": 1.0107476814187688, "train/extr_reward_max": 1.0107476814187688, "train/extr_reward_mean": 0.02356745019930301, "train/extr_reward_min": -0.3178551763081722, "train/extr_reward_std": 0.14202126378206897, "train/image_loss_mean": 9.060423319288295, "train/image_loss_std": 12.908428497451672, "train/model_loss_mean": 18.27456233484282, "train/model_loss_std": 16.378554995969044, "train/model_opt_grad_norm": 69.57597971305573, "train/model_opt_grad_steps": 19729.273381294963, "train/model_opt_loss": 14836.640990332733, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 809.3525179856115, "train/policy_entropy_mag": 2.457509994506836, "train/policy_entropy_max": 2.457509994506836, "train/policy_entropy_mean": 0.6247175447374796, "train/policy_entropy_min": 0.07937523572564982, "train/policy_entropy_std": 0.6072336452470409, "train/policy_logprob_mag": 7.438382718202879, "train/policy_logprob_max": -0.009455796264165596, "train/policy_logprob_mean": -0.6244546700295784, "train/policy_logprob_min": -7.438382718202879, "train/policy_logprob_std": 1.141996206139489, "train/policy_randomness_mag": 0.8673931819071873, "train/policy_randomness_max": 0.8673931819071873, "train/policy_randomness_mean": 0.2204978796217939, "train/policy_randomness_min": 0.028015974775063904, "train/policy_randomness_std": 0.21432682936140102, "train/post_ent_mag": 56.04542761054828, "train/post_ent_max": 56.04542761054828, "train/post_ent_mean": 38.65448662188413, "train/post_ent_min": 19.924366985293602, "train/post_ent_std": 7.20142808406473, "train/prior_ent_mag": 65.03235906148129, "train/prior_ent_max": 65.03235906148129, "train/prior_ent_mean": 53.97026915515927, "train/prior_ent_min": 39.66057500221746, "train/prior_ent_std": 4.126595601761084, "train/rep_loss_mean": 15.265494463255079, "train/rep_loss_std": 8.698420826479685, "train/reward_avg": 0.021074780618115296, "train/reward_loss_mean": 0.054402487620496924, "train/reward_loss_std": 0.26237464551445394, "train/reward_max_data": 1.0122302187432488, "train/reward_max_pred": 1.006005871210167, "train/reward_neg_acc": 0.9930211348499326, "train/reward_neg_loss": 0.030944785954122492, "train/reward_pos_acc": 0.9498581976341687, "train/reward_pos_loss": 0.9360969049467457, "train/reward_pred": 0.020230343183435553, "train/reward_rate": 0.026058059802158272, "eval_stats/sum_log_reward": 4.849999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.1875, "eval_stats/max_log_achievement_collect_sapling": 3.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 3.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.733216767112026e-06, "report/cont_loss_std": 0.00015231045836117119, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00012127309310017154, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.052235792391002e-06, "report/cont_pred": 0.994136393070221, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.362585067749023, "report/dyn_loss_std": 8.39658260345459, "report/image_loss_mean": 7.290352821350098, "report/image_loss_std": 9.770121574401855, "report/model_loss_mean": 16.554298400878906, "report/model_loss_std": 13.131963729858398, "report/post_ent_mag": 55.718441009521484, "report/post_ent_max": 55.718441009521484, "report/post_ent_mean": 38.411651611328125, "report/post_ent_min": 18.054285049438477, "report/post_ent_std": 7.0519537925720215, "report/prior_ent_mag": 64.82868957519531, "report/prior_ent_max": 64.82868957519531, "report/prior_ent_mean": 53.8840446472168, "report/prior_ent_min": 39.33271026611328, "report/prior_ent_std": 4.329020977020264, "report/rep_loss_mean": 15.362585067749023, "report/rep_loss_std": 8.39658260345459, "report/reward_avg": 0.01708984375, "report/reward_loss_mean": 0.046388477087020874, "report/reward_loss_std": 0.24656300246715546, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009057521820068, "report/reward_neg_acc": 0.9920159578323364, "report/reward_neg_loss": 0.025232139974832535, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 1.0099633932113647, "report/reward_pred": 0.016033748164772987, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.011767380987294e-06, "eval/cont_loss_std": 2.6410580176161602e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.535687574185431e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.781945209397236e-07, "eval/cont_pred": 0.9990225434303284, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 20.248069763183594, "eval/dyn_loss_std": 9.441095352172852, "eval/image_loss_mean": 33.85899353027344, "eval/image_loss_std": 41.607547760009766, "eval/model_loss_mean": 46.09971618652344, "eval/model_loss_std": 43.95240783691406, "eval/post_ent_mag": 54.30284881591797, "eval/post_ent_max": 54.30284881591797, "eval/post_ent_mean": 37.422706604003906, "eval/post_ent_min": 21.23920249938965, "eval/post_ent_std": 6.369015693664551, "eval/prior_ent_mag": 64.82868957519531, "eval/prior_ent_max": 64.82868957519531, "eval/prior_ent_mean": 54.53230285644531, "eval/prior_ent_min": 38.57088088989258, "eval/prior_ent_std": 3.8644967079162598, "eval/rep_loss_mean": 20.248069763183594, "eval/rep_loss_std": 9.441095352172852, "eval/reward_avg": 0.02265624888241291, "eval/reward_loss_mean": 0.09187847375869751, "eval/reward_loss_std": 0.5852237343788147, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017848014831543, "eval/reward_neg_acc": 0.9839679598808289, "eval/reward_neg_loss": 0.036884602159261703, "eval/reward_pos_acc": 0.7307692766189575, "eval/reward_pos_loss": 2.2027974128723145, "eval/reward_pred": 0.01848623901605606, "eval/reward_rate": 0.025390625, "replay/size": 328137.0, "replay/inserts": 22208.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3557372759673368e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.606677775424221e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 64080.0, "eval_replay/inserts": 4216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.213242930750693e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9937756061554, "timer/env.step_count": 2776.0, "timer/env.step_total": 253.99508213996887, "timer/env.step_frac": 0.25399666311523533, "timer/env.step_avg": 0.091496787514398, "timer/env.step_min": 0.021987438201904297, "timer/env.step_max": 3.0980405807495117, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.578949213027954, "timer/replay._sample_frac": 0.01157902128541677, "timer/replay._sample_avg": 0.0005213864018834633, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.008893013000488281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3303.0, "timer/agent.policy_total": 53.60293698310852, "timer/agent.policy_frac": 0.05360327063097629, "timer/agent.policy_avg": 0.016228561000032855, "timer/agent.policy_min": 0.00945591926574707, "timer/agent.policy_max": 0.1015174388885498, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.1504194736480713, "timer/dataset_train_frac": 0.00015042040992394493, "timer/dataset_train_avg": 0.00010837137870898508, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0002658367156982422, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 621.0882647037506, "timer/agent.train_frac": 0.6210921306257854, "timer/agent.train_avg": 0.4474699313427598, "timer/agent.train_min": 0.4335286617279053, "timer/agent.train_max": 1.5256080627441406, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47112107276916504, "timer/agent.report_frac": 0.0004711240052305232, "timer/agent.report_avg": 0.23556053638458252, "timer/agent.report_min": 0.22281384468078613, "timer/agent.report_max": 0.2483072280883789, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.457090915268069e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 22.207825050603073}
{"step": 328856, "time": 15409.543111801147, "episode/length": 35.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 329096, "time": 15419.14888882637, "episode/length": 256.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 329224, "time": 15424.981835842133, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 329320, "time": 15429.72114443779, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 329392, "time": 15433.91777586937, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 329544, "time": 15440.49348282814, "episode/length": 265.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 329704, "time": 15447.31549358368, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 329712, "time": 15449.370485305786, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 329952, "time": 15458.892441987991, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15489.452816009521, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 330096, "time": 15491.368228435516, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 330096, "time": 15491.37624168396, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 330096, "time": 15495.052577257156, "eval_episode/length": 200.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 330096, "time": 15495.060909748077, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 330096, "time": 15498.918127298355, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 330096, "time": 15503.111441850662, "eval_episode/length": 257.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9961240310077519}
{"step": 330096, "time": 15508.941713094711, "eval_episode/length": 363.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9972527472527473}
{"step": 330240, "time": 15513.657321214676, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 330448, "time": 15522.054379463196, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 330600, "time": 15528.408127784729, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 330824, "time": 15537.947390317917, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 330984, "time": 15544.822031259537, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 331208, "time": 15554.015578269958, "episode/length": 187.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 331344, "time": 15560.537410259247, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 331664, "time": 15572.58902144432, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 331944, "time": 15583.398871183395, "episode/length": 248.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 332120, "time": 15590.869690418243, "episode/length": 189.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 332176, "time": 15594.477062702179, "episode/length": 215.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 332432, "time": 15604.441870212555, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 332928, "time": 15622.584918737411, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 332960, "time": 15625.369560480118, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 333176, "time": 15633.967928171158, "episode/length": 188.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 333240, "time": 15637.757045507431, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 333680, "time": 15654.26025891304, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 333760, "time": 15658.410986661911, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 334280, "time": 15676.953416109085, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 334368, "time": 15681.772778511047, "episode/length": 148.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 334496, "time": 15687.639521598816, "episode/length": 296.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 334520, "time": 15689.811876535416, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 334656, "time": 15696.0672955513, "episode/length": 413.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 334760, "time": 15700.83150601387, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 334952, "time": 15708.683730602264, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 335264, "time": 15720.796504497528, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 335320, "time": 15724.106671333313, "episode/length": 204.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 335616, "time": 15735.762327432632, "episode/length": 106.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 335616, "time": 15735.771091461182, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 335664, "time": 15740.720690250397, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 335824, "time": 15747.651279211044, "episode/length": 25.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.8846153846153846, "episode/intrinsic_return": 0.0}
{"step": 335920, "time": 15753.73419380188, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 335984, "time": 15757.428972482681, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 336208, "time": 15766.40655374527, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 337000, "time": 15794.087423324585, "episode/length": 209.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 337160, "time": 15801.068978786469, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 337240, "time": 15805.178510427475, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 337544, "time": 15816.845899105072, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 337664, "time": 15822.599894285202, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 338232, "time": 15842.817650794983, "episode/length": 300.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 338240, "time": 15844.90002822876, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758620689655172, "episode/intrinsic_return": 0.0}
{"step": 338568, "time": 15857.044399499893, "episode/length": 294.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 338808, "time": 15866.788048267365, "episode/length": 205.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 338888, "time": 15870.993965625763, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 339216, "time": 15883.814324617386, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 339288, "time": 15887.54499220848, "episode/length": 217.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 339288, "time": 15887.555039167404, "episode/length": 285.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 339616, "time": 15902.066040754318, "episode/length": 90.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 339616, "time": 15902.074571609497, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 339784, "time": 15910.540968418121, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 339984, "time": 15918.895904064178, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 339984, "time": 15918.904796361923, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 15939.923443555832, "eval_episode/length": 36.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8918918918918919}
{"step": 340080, "time": 15941.434879541397, "eval_episode/length": 37.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.868421052631579}
{"step": 340080, "time": 15947.37716460228, "eval_episode/length": 147.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 340080, "time": 15949.872478485107, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 340080, "time": 15951.667521953583, "eval_episode/length": 171.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 340080, "time": 15953.634282112122, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 340080, "time": 15955.39531135559, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 340080, "time": 15957.14328289032, "eval_episode/length": 191.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 340232, "time": 15961.927840709686, "episode/length": 126.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.0}
{"step": 340544, "time": 15973.974546432495, "episode/length": 69.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.0}
{"step": 340656, "time": 15979.24175786972, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 341112, "time": 15995.798340797424, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 341168, "time": 15999.456785917282, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 341760, "time": 16020.902755260468, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 341800, "time": 16023.706835508347, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 342056, "time": 16033.854978561401, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 342072, "time": 16036.432564973831, "episode/length": 285.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 342232, "time": 16043.770803451538, "episode/length": 132.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 342448, "time": 16052.845505475998, "episode/length": 353.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.980225988700565, "episode/intrinsic_return": 0.0}
{"step": 342472, "time": 16054.98789358139, "episode/length": 51.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 342520, "time": 16058.63479590416, "episode/length": 246.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 343000, "time": 16076.735008716583, "episode/length": 235.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 343520, "time": 16095.815334320068, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 343576, "time": 16099.107395410538, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 343744, "time": 16106.55405330658, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 343824, "time": 16110.739512205124, "episode/length": 252.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 343848, "time": 16112.81400847435, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 344272, "time": 16130.449827194214, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 344312, "time": 16133.156759738922, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 344336, "time": 16135.759330272675, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 344696, "time": 16149.805840969086, "episode/length": 139.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 344744, "time": 16152.950015068054, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 345192, "time": 16169.527007579803, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 345208, "time": 16171.624047994614, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 345544, "time": 16184.382625579834, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 345584, "time": 16187.419650793076, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 345656, "time": 16191.237047433853, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 345712, "time": 16195.035290718079, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 345960, "time": 16204.653058767319, "episode/length": 93.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 346696, "time": 16230.72762465477, "episode/length": 249.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 346784, "time": 16235.45457148552, "episode/length": 254.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 346848, "time": 16239.127899885178, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 347136, "time": 16250.3180103302, "episode/length": 43.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 347208, "time": 16254.16035914421, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 347280, "time": 16258.301914691925, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 347392, "time": 16263.561211585999, "episode/length": 225.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 347432, "time": 16266.259563207626, "episode/length": 279.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 347888, "time": 16283.034826517105, "episode/length": 271.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 348576, "time": 16307.386909008026, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 348648, "time": 16311.281165122986, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 348680, "time": 16313.837636709213, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 348816, "time": 16320.246873617172, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 348864, "time": 16323.388579368591, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 348944, "time": 16327.674425840378, "episode/length": 225.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 349160, "time": 16336.107033014297, "episode/length": 288.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 349240, "time": 16340.355170726776, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 349296, "time": 16343.975687265396, "episode/length": 53.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16389.90118432045, "eval_episode/length": 150.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 350064, "time": 16392.179317474365, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 350064, "time": 16393.909875631332, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 350064, "time": 16395.833228588104, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 350064, "time": 16397.64133834839, "eval_episode/length": 186.0, "eval_episode/score": 6.100000038743019, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 350064, "time": 16399.960027456284, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 350064, "time": 16401.81448984146, "eval_episode/length": 43.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 350064, "time": 16404.025409936905, "eval_episode/length": 38.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 350065, "time": 16404.60200738907, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.570328897504664, "train/action_min": 0.0, "train/action_std": 3.1203994412920366, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050900218480113724, "train/actor_opt_grad_steps": 21115.0, "train/actor_opt_loss": -5.822204648113963, "train/adv_mag": 0.773801459305322, "train/adv_max": 0.7556336444260469, "train/adv_mean": 0.003713176935709488, "train/adv_min": -0.49696380322548883, "train/adv_std": 0.07701159924713534, "train/cont_avg": 0.99462890625, "train/cont_loss_mean": 0.0004327424340255162, "train/cont_loss_std": 0.013012666901341726, "train/cont_neg_acc": 0.9882373854295531, "train/cont_neg_loss": 0.04625316712235872, "train/cont_pos_acc": 0.9999706229167198, "train/cont_pos_loss": 0.00017852762992888067, "train/cont_pred": 0.9946397209345404, "train/cont_rate": 0.99462890625, "train/dyn_loss_mean": 14.82708533130475, "train/dyn_loss_std": 8.714698211470647, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8562297300616307, "train/extr_critic_critic_opt_grad_steps": 21115.0, "train/extr_critic_critic_opt_loss": 15668.476664528918, "train/extr_critic_mag": 4.753108416030656, "train/extr_critic_max": 4.753108416030656, "train/extr_critic_mean": 0.858568817154685, "train/extr_critic_min": -0.22240097131302108, "train/extr_critic_std": 1.02378633173544, "train/extr_return_normed_mag": 1.8608050550987472, "train/extr_return_normed_max": 1.8608050550987472, "train/extr_return_normed_mean": 0.29679309754674116, "train/extr_return_normed_min": -0.1505320790543485, "train/extr_return_normed_std": 0.3341926688800997, "train/extr_return_rate": 0.4356897377700948, "train/extr_return_raw_mag": 5.821708280648759, "train/extr_return_raw_max": 5.821708280648759, "train/extr_return_raw_mean": 0.8702976143182214, "train/extr_return_raw_min": -0.5461540593584971, "train/extr_return_raw_std": 1.0583045980823573, "train/extr_reward_mag": 1.0135610726342272, "train/extr_reward_max": 1.0135610726342272, "train/extr_reward_mean": 0.02458291924767085, "train/extr_reward_min": -0.3394058853832643, "train/extr_reward_std": 0.1458275724591604, "train/image_loss_mean": 8.568485971707016, "train/image_loss_std": 12.468827713781328, "train/model_loss_mean": 17.519823173978434, "train/model_loss_std": 15.91942970788301, "train/model_opt_grad_norm": 66.53480773185616, "train/model_opt_grad_steps": 21093.68656716418, "train/model_opt_loss": 21899.778932486006, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.476849675178528, "train/policy_entropy_max": 2.476849675178528, "train/policy_entropy_mean": 0.648437316293147, "train/policy_entropy_min": 0.07937521181667029, "train/policy_entropy_std": 0.630397032445936, "train/policy_logprob_mag": 7.438382846205982, "train/policy_logprob_max": -0.009455760836656859, "train/policy_logprob_mean": -0.6470580745988818, "train/policy_logprob_min": -7.438382846205982, "train/policy_logprob_std": 1.1537331689649553, "train/policy_randomness_mag": 0.8742192432061949, "train/policy_randomness_max": 0.8742192432061949, "train/policy_randomness_mean": 0.22886991912304466, "train/policy_randomness_min": 0.02801596626305758, "train/policy_randomness_std": 0.22250248981055928, "train/post_ent_mag": 56.18388295529493, "train/post_ent_max": 56.18388295529493, "train/post_ent_mean": 39.09204007618463, "train/post_ent_min": 19.908177397144375, "train/post_ent_std": 7.2776010463486855, "train/prior_ent_mag": 65.09724819126414, "train/prior_ent_max": 65.09724819126414, "train/prior_ent_mean": 54.01768835267024, "train/prior_ent_min": 39.889495166380016, "train/prior_ent_std": 4.144588287196942, "train/rep_loss_mean": 14.82708533130475, "train/rep_loss_std": 8.714698211470647, "train/reward_avg": 0.022212424166083558, "train/reward_loss_mean": 0.05465336508159317, "train/reward_loss_std": 0.25731531441656513, "train/reward_max_data": 1.014179107858174, "train/reward_max_pred": 1.006061189210237, "train/reward_neg_acc": 0.9926330625121274, "train/reward_neg_loss": 0.03118382378328425, "train/reward_pos_acc": 0.9582231502924392, "train/reward_pos_loss": 0.9023771690788553, "train/reward_pred": 0.02152906609490625, "train/reward_rate": 0.02711054104477612, "train_stats/sum_log_reward": 5.109090833230452, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.3, "train_stats/max_log_achievement_collect_sapling": 3.2363636363636363, "train_stats/max_log_achievement_collect_stone": 0.02727272727272727, "train_stats/max_log_achievement_collect_wood": 6.054545454545455, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.34545454545454546, "train_stats/max_log_achievement_eat_cow": 0.08181818181818182, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.12727272727272726, "train_stats/max_log_achievement_make_wood_sword": 0.01818181818181818, "train_stats/max_log_achievement_place_plant": 3.0090909090909093, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.3, "train_stats/max_log_achievement_wake_up": 1.7272727272727273, "train_stats/mean_log_entropy": 0.6085998516191136, "eval_stats/sum_log_reward": 4.766666616002719, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.041666666666667, "eval_stats/max_log_achievement_collect_sapling": 3.1666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.041666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5416666666666666, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.20833333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.9583333333333335, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.4583333333333335, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.919111572438851e-06, "report/cont_loss_std": 2.757170659606345e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023796973982825875, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.009108463127632e-06, "report/cont_pred": 0.9960896968841553, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.735435485839844, "report/dyn_loss_std": 8.614395141601562, "report/image_loss_mean": 8.558058738708496, "report/image_loss_std": 10.162650108337402, "report/model_loss_mean": 17.456649780273438, "report/model_loss_std": 13.726432800292969, "report/post_ent_mag": 58.79881286621094, "report/post_ent_max": 58.79881286621094, "report/post_ent_mean": 40.29148483276367, "report/post_ent_min": 19.275741577148438, "report/post_ent_std": 7.764713287353516, "report/prior_ent_mag": 65.09466552734375, "report/prior_ent_max": 65.09466552734375, "report/prior_ent_mean": 55.39556884765625, "report/prior_ent_min": 43.051170349121094, "report/prior_ent_std": 4.092823505401611, "report/rep_loss_mean": 14.735435485839844, "report/rep_loss_std": 8.614395141601562, "report/reward_avg": 0.02744140475988388, "report/reward_loss_mean": 0.05732341110706329, "report/reward_loss_std": 0.2705884575843811, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001028060913086, "report/reward_neg_acc": 0.9919273257255554, "report/reward_neg_loss": 0.028588704764842987, "report/reward_pos_acc": 0.939393937587738, "report/reward_pos_loss": 0.9202352166175842, "report/reward_pred": 0.027807604521512985, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.2293912479653955e-05, "eval/cont_loss_std": 0.0002751950523816049, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007571683963760734, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7962627680390142e-05, "eval/cont_pred": 0.9941272735595703, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.95549774169922, "eval/dyn_loss_std": 9.500207901000977, "eval/image_loss_mean": 22.934431076049805, "eval/image_loss_std": 29.729137420654297, "eval/model_loss_mean": 35.01995086669922, "eval/model_loss_std": 33.05387496948242, "eval/post_ent_mag": 56.401023864746094, "eval/post_ent_max": 56.401023864746094, "eval/post_ent_mean": 37.46162414550781, "eval/post_ent_min": 20.924901962280273, "eval/post_ent_std": 6.817700386047363, "eval/prior_ent_mag": 65.09466552734375, "eval/prior_ent_max": 65.09466552734375, "eval/prior_ent_mean": 55.14020538330078, "eval/prior_ent_min": 43.277992248535156, "eval/prior_ent_std": 3.548740863800049, "eval/rep_loss_mean": 19.95549774169922, "eval/rep_loss_std": 9.500207901000977, "eval/reward_avg": 0.02548828348517418, "eval/reward_loss_mean": 0.11219759285449982, "eval/reward_loss_std": 0.6375943422317505, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0125494003295898, "eval/reward_neg_acc": 0.9879153966903687, "eval/reward_neg_loss": 0.05651462450623512, "eval/reward_pos_acc": 0.774193525314331, "eval/reward_pos_loss": 1.8958488702774048, "eval/reward_pred": 0.022571086883544922, "eval/reward_rate": 0.0302734375, "replay/size": 349561.0, "replay/inserts": 21424.0, "replay/samples": 21424.0, "replay/insert_wait_avg": 1.3524890391126864e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.670481228134008e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70336.0, "eval_replay/inserts": 6256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.175095663046288e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.3485596179962, "timer/env.step_count": 2678.0, "timer/env.step_total": 246.67585229873657, "timer/env.step_frac": 0.2460978767632957, "timer/env.step_avg": 0.09211196874486055, "timer/env.step_min": 0.022447586059570312, "timer/env.step_max": 3.4256393909454346, "timer/replay._sample_count": 21424.0, "timer/replay._sample_total": 11.247392416000366, "timer/replay._sample_frac": 0.011221039136612163, "timer/replay._sample_avg": 0.0005249903106796288, "timer/replay._sample_min": 0.000377655029296875, "timer/replay._sample_max": 0.028500080108642578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3460.0, "timer/agent.policy_total": 57.80388617515564, "timer/agent.policy_frac": 0.05766844838604368, "timer/agent.policy_avg": 0.016706325484149027, "timer/agent.policy_min": 0.009294509887695312, "timer/agent.policy_max": 1.0894546508789062, "timer/dataset_train_count": 1339.0, "timer/dataset_train_total": 0.14434242248535156, "timer/dataset_train_frac": 0.00014400421998946326, "timer/dataset_train_avg": 0.00010779867250586375, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.00048160552978515625, "timer/agent.train_count": 1339.0, "timer/agent.train_total": 599.8943631649017, "timer/agent.train_frac": 0.5984887765923729, "timer/agent.train_avg": 0.44801670139275707, "timer/agent.train_min": 0.4342312812805176, "timer/agent.train_max": 1.5878040790557861, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4747605323791504, "timer/agent.report_frac": 0.0004736481414809293, "timer/agent.report_avg": 0.2373802661895752, "timer/agent.report_min": 0.23309087753295898, "timer/agent.report_max": 0.2416696548461914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.710615232890487e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 21.373528511379085}
{"step": 350352, "time": 16414.4636156559, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 350368, "time": 16416.561061382294, "episode/length": 223.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 350536, "time": 16423.448837280273, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 350640, "time": 16428.910043478012, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 350688, "time": 16432.146961450577, "episode/length": 233.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 350720, "time": 16434.737554311752, "episode/length": 258.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 351016, "time": 16445.950076580048, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 351424, "time": 16461.228687286377, "episode/length": 91.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9347826086956522, "episode/intrinsic_return": 0.0}
{"step": 351840, "time": 16476.52531337738, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 352008, "time": 16483.428232192993, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 352024, "time": 16485.566293239594, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 352064, "time": 16489.210044145584, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 352328, "time": 16501.272656917572, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 352424, "time": 16506.09957408905, "episode/length": 397.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 352440, "time": 16508.311933994293, "episode/length": 46.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 353192, "time": 16534.844297409058, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 353576, "time": 16549.273153543472, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 353648, "time": 16553.476752519608, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 353696, "time": 16556.63525056839, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 354120, "time": 16572.175347328186, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 354136, "time": 16574.363242149353, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 354416, "time": 16585.535578727722, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 354448, "time": 16588.200454711914, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 354576, "time": 16594.031762361526, "episode/length": 444.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932584269662922, "episode/intrinsic_return": 0.0}
{"step": 354872, "time": 16605.188303232193, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 355080, "time": 16613.822071790695, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 355232, "time": 16620.809220314026, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 355664, "time": 16636.818739891052, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 355840, "time": 16644.201231002808, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 355920, "time": 16648.361691713333, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 356024, "time": 16653.078509807587, "episode/length": 235.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 356256, "time": 16662.400037288666, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 356272, "time": 16664.493122816086, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 356384, "time": 16669.744445323944, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 356520, "time": 16675.56553053856, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 356872, "time": 16688.855568170547, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 357000, "time": 16694.55673933029, "episode/length": 59.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 357256, "time": 16704.581142425537, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 357496, "time": 16714.02962732315, "episode/length": 228.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 357560, "time": 16717.69844698906, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 357600, "time": 16720.74767971039, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 357800, "time": 16728.756036281586, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 357920, "time": 16734.49513220787, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 358240, "time": 16746.57623577118, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 358384, "time": 16752.899526119232, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 358824, "time": 16768.8247320652, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 358896, "time": 16772.962886810303, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 359000, "time": 16777.769705057144, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 359056, "time": 16781.339252233505, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 359400, "time": 16794.249028921127, "episode/length": 237.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 359600, "time": 16803.0377805233, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 359632, "time": 16805.652922153473, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16840.000916719437, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 360048, "time": 16842.1824426651, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 360048, "time": 16844.201535463333, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 360048, "time": 16846.029945850372, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 360048, "time": 16847.886018276215, "eval_episode/length": 189.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 360048, "time": 16849.999551296234, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 360048, "time": 16852.651193857193, "eval_episode/length": 27.0, "eval_episode/score": 3.1000000163912773, "eval_episode/reward_rate": 0.8928571428571429}
{"step": 360048, "time": 16855.58816075325, "eval_episode/length": 263.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 360344, "time": 16865.196158885956, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 360344, "time": 16865.20547437668, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 360352, "time": 16868.905393838882, "episode/length": 245.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 360440, "time": 16873.209686517715, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 360504, "time": 16878.178697824478, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 360744, "time": 16887.688120365143, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 361224, "time": 16905.088631629944, "episode/length": 202.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 361288, "time": 16908.945840358734, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 361584, "time": 16920.5608420372, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 361608, "time": 16922.75672698021, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 361616, "time": 16924.802215099335, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 361720, "time": 16929.658934116364, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 361768, "time": 16932.66709780693, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 361880, "time": 16937.866477251053, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 362264, "time": 16952.29279613495, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 362904, "time": 16975.49233531952, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 362928, "time": 16978.11407160759, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 363056, "time": 16984.04421544075, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 363184, "time": 16989.975562095642, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 363400, "time": 16998.437325000763, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 363440, "time": 17001.716892004013, "episode/length": 208.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 363512, "time": 17005.41893863678, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 363808, "time": 17017.065473794937, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 364216, "time": 17031.91428041458, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 364280, "time": 17035.635237693787, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 364632, "time": 17048.94656586647, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 364680, "time": 17052.117879152298, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 364832, "time": 17059.148151636124, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 365264, "time": 17075.04670906067, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 365504, "time": 17084.604834794998, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 365704, "time": 17092.676560878754, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 365752, "time": 17095.861301660538, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 366072, "time": 17108.031530618668, "episode/length": 70.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9436619718309859, "episode/intrinsic_return": 0.0}
{"step": 366112, "time": 17111.11147236824, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 366152, "time": 17113.75986433029, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 366848, "time": 17138.631036758423, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 367120, "time": 17149.297099351883, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 367216, "time": 17154.044637918472, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 367496, "time": 17164.60734963417, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 367568, "time": 17168.844934225082, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 368120, "time": 17188.46284031868, "episode/length": 410.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951338199513382, "episode/intrinsic_return": 0.0}
{"step": 368280, "time": 17195.346164226532, "episode/length": 178.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 368680, "time": 17211.54786157608, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 368744, "time": 17215.16701889038, "episode/length": 662.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9864253393665159, "episode/intrinsic_return": 0.0}
{"step": 368784, "time": 17218.27737212181, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 368888, "time": 17223.063044071198, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 369184, "time": 17234.66992354393, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 369240, "time": 17237.841319561005, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 369288, "time": 17241.157408475876, "episode/length": 75.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 369320, "time": 17243.808946847916, "episode/length": 400.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900249376558603, "episode/intrinsic_return": 0.0}
{"step": 369600, "time": 17254.874972581863, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 369848, "time": 17264.395830631256, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 369984, "time": 17270.768733263016, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17295.349768400192, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 370032, "time": 17298.03892827034, "eval_episode/length": 174.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 370032, "time": 17299.706979990005, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9602272727272727}
{"step": 370032, "time": 17301.748441934586, "eval_episode/length": 182.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 370032, "time": 17303.36680340767, "eval_episode/length": 185.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 370032, "time": 17306.02842593193, "eval_episode/length": 211.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 370032, "time": 17307.674055814743, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 370032, "time": 17313.934940099716, "eval_episode/length": 325.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.99079754601227}
{"step": 370520, "time": 17330.028697490692, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 370592, "time": 17334.21677017212, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 370744, "time": 17340.59037041664, "episode/length": 187.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 370896, "time": 17347.492528438568, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 370984, "time": 17351.85602760315, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 371040, "time": 17355.50133228302, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 371616, "time": 17376.151447296143, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 371960, "time": 17388.986956119537, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 371968, "time": 17391.08495116234, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 372056, "time": 17395.391513586044, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 372265, "time": 17404.90350174904, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.348355739236736, "train/action_min": 0.0, "train/action_std": 3.0836401826186144, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05080558035335095, "train/actor_opt_grad_steps": 22480.0, "train/actor_opt_loss": -3.6657467008494646, "train/adv_mag": 0.7650352759326963, "train/adv_max": 0.7527415934655306, "train/adv_mean": 0.004096150103342558, "train/adv_min": -0.5179811098592745, "train/adv_std": 0.07735422923624945, "train/cont_avg": 0.9945270346223022, "train/cont_loss_mean": 0.0002819685465063315, "train/cont_loss_std": 0.008222935614666109, "train/cont_neg_acc": 0.9928057558244938, "train/cont_neg_loss": 0.02401024413504876, "train/cont_pos_acc": 0.9999646660235288, "train/cont_pos_loss": 0.000164360616048048, "train/cont_pred": 0.9945127831088553, "train/cont_rate": 0.9945270346223022, "train/dyn_loss_mean": 14.90317263706125, "train/dyn_loss_std": 8.722479700184554, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8630897981657398, "train/extr_critic_critic_opt_grad_steps": 22480.0, "train/extr_critic_critic_opt_loss": 15781.700019671762, "train/extr_critic_mag": 4.808964722448116, "train/extr_critic_max": 4.808964722448116, "train/extr_critic_mean": 0.8541075458629526, "train/extr_critic_min": -0.19973321355504098, "train/extr_critic_std": 1.0326634662614451, "train/extr_return_normed_mag": 1.8569337043830816, "train/extr_return_normed_max": 1.8569337043830816, "train/extr_return_normed_mean": 0.29218861975258204, "train/extr_return_normed_min": -0.13521517730123706, "train/extr_return_normed_std": 0.33413090390695943, "train/extr_return_rate": 0.43340127052163047, "train/extr_return_raw_mag": 5.858589114045068, "train/extr_return_raw_max": 5.858589114045068, "train/extr_return_raw_mean": 0.8671627419886829, "train/extr_return_raw_min": -0.4961878237106817, "train/extr_return_raw_std": 1.0662067854147164, "train/extr_reward_mag": 1.0115685805999974, "train/extr_reward_max": 1.0115685805999974, "train/extr_reward_mean": 0.024842780726633484, "train/extr_reward_min": -0.3069704402264931, "train/extr_reward_std": 0.14634708604581065, "train/image_loss_mean": 8.462915211272755, "train/image_loss_std": 12.617371535129685, "train/model_loss_mean": 17.46065676298073, "train/model_loss_std": 16.07904651010637, "train/model_opt_grad_norm": 68.59477789505668, "train/model_opt_grad_steps": 22456.956834532375, "train/model_opt_loss": 16945.226098808453, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 962.2302158273382, "train/policy_entropy_mag": 2.498065564272215, "train/policy_entropy_max": 2.498065564272215, "train/policy_entropy_mean": 0.6235421359967842, "train/policy_entropy_min": 0.07937519161178054, "train/policy_entropy_std": 0.6130602173239207, "train/policy_logprob_mag": 7.438383119569408, "train/policy_logprob_max": -0.009455741805245551, "train/policy_logprob_mean": -0.6239221531281368, "train/policy_logprob_min": -7.438383119569408, "train/policy_logprob_std": 1.1456989796041586, "train/policy_randomness_mag": 0.8817075190784263, "train/policy_randomness_max": 0.8817075190784263, "train/policy_randomness_mean": 0.22008300996084007, "train/policy_randomness_min": 0.028015959230687122, "train/policy_randomness_std": 0.2163833552341667, "train/post_ent_mag": 56.04989785942242, "train/post_ent_max": 56.04989785942242, "train/post_ent_mean": 39.13230558436552, "train/post_ent_min": 19.771134177557855, "train/post_ent_std": 7.27307268183866, "train/prior_ent_mag": 65.25097595873497, "train/prior_ent_max": 65.25097595873497, "train/prior_ent_mean": 54.08074520303191, "train/prior_ent_min": 39.403151230846376, "train/prior_ent_std": 4.093068697469698, "train/rep_loss_mean": 14.90317263706125, "train/rep_loss_std": 8.722479700184554, "train/reward_avg": 0.022061179023530844, "train/reward_loss_mean": 0.055556286903594036, "train/reward_loss_std": 0.2603184781271777, "train/reward_max_data": 1.0172661911669394, "train/reward_max_pred": 1.0067216475232899, "train/reward_neg_acc": 0.992615223788529, "train/reward_neg_loss": 0.031792442254025305, "train/reward_pos_acc": 0.9548223850538404, "train/reward_pos_loss": 0.908266910974928, "train/reward_pred": 0.021212647313908706, "train/reward_rate": 0.027041647931654676, "train_stats/sum_log_reward": 5.14347820489303, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.321739130434783, "train_stats/max_log_achievement_collect_sapling": 2.8869565217391306, "train_stats/max_log_achievement_collect_stone": 0.034782608695652174, "train_stats/max_log_achievement_collect_wood": 6.156521739130435, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "train_stats/max_log_achievement_defeat_zombie": 0.4434782608695652, "train_stats/max_log_achievement_eat_cow": 0.043478260869565216, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.13043478260869565, "train_stats/max_log_achievement_make_wood_sword": 0.017391304347826087, "train_stats/max_log_achievement_place_plant": 2.756521739130435, "train_stats/max_log_achievement_place_stone": 0.017391304347826087, "train_stats/max_log_achievement_place_table": 2.356521739130435, "train_stats/max_log_achievement_wake_up": 1.817391304347826, "train_stats/mean_log_entropy": 0.5631590609965117, "eval_stats/sum_log_reward": 5.4749999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.606393147492781e-05, "report/cont_loss_std": 0.0004026413371320814, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0023886796552687883, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.6837988116312772e-05, "report/cont_pred": 0.9960764646530151, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.400362014770508, "report/dyn_loss_std": 8.172082901000977, "report/image_loss_mean": 8.047423362731934, "report/image_loss_std": 12.288606643676758, "report/model_loss_mean": 17.339031219482422, "report/model_loss_std": 15.444887161254883, "report/post_ent_mag": 53.672637939453125, "report/post_ent_max": 53.672637939453125, "report/post_ent_mean": 38.368526458740234, "report/post_ent_min": 20.262775421142578, "report/post_ent_std": 6.691768646240234, "report/prior_ent_mag": 66.07373046875, "report/prior_ent_max": 66.07373046875, "report/prior_ent_mean": 53.975807189941406, "report/prior_ent_min": 41.23761749267578, "report/prior_ent_std": 3.704430341720581, "report/rep_loss_mean": 15.400362014770508, "report/rep_loss_std": 8.172082901000977, "report/reward_avg": 0.02910156175494194, "report/reward_loss_mean": 0.05135488510131836, "report/reward_loss_std": 0.2399103045463562, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029957294464111, "report/reward_neg_acc": 0.9929364323616028, "report/reward_neg_loss": 0.025785906240344048, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.8191990256309509, "report/reward_pred": 0.027061827480793, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.1803434063040186e-05, "eval/cont_loss_std": 0.00031570220016874373, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006388539914041758, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.057632834999822e-05, "eval/cont_pred": 0.9980376958847046, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.142183303833008, "eval/dyn_loss_std": 10.174873352050781, "eval/image_loss_mean": 15.796039581298828, "eval/image_loss_std": 17.547725677490234, "eval/model_loss_mean": 27.381675720214844, "eval/model_loss_std": 21.782909393310547, "eval/post_ent_mag": 56.162322998046875, "eval/post_ent_max": 56.162322998046875, "eval/post_ent_mean": 38.42823028564453, "eval/post_ent_min": 18.619464874267578, "eval/post_ent_std": 7.182839393615723, "eval/prior_ent_mag": 66.07373046875, "eval/prior_ent_max": 66.07373046875, "eval/prior_ent_mean": 55.11479187011719, "eval/prior_ent_min": 40.686798095703125, "eval/prior_ent_std": 4.0173563957214355, "eval/rep_loss_mean": 19.142183303833008, "eval/rep_loss_std": 10.174873352050781, "eval/reward_avg": 0.01699218712747097, "eval/reward_loss_mean": 0.10031498223543167, "eval/reward_loss_std": 0.7253705263137817, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.017052412033081, "eval/reward_neg_acc": 0.9950199723243713, "eval/reward_neg_loss": 0.04327782616019249, "eval/reward_pos_acc": 0.6500000357627869, "eval/reward_pos_loss": 2.96358060836792, "eval/reward_pred": 0.010051123797893524, "eval/reward_rate": 0.01953125, "replay/size": 371761.0, "replay/inserts": 22200.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3820222906164221e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.658745953947392e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75056.0, "eval_replay/inserts": 4720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2045694609819833e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.287346124649, "timer/env.step_count": 2775.0, "timer/env.step_total": 254.08259272575378, "timer/env.step_frac": 0.25400960405040623, "timer/env.step_avg": 0.09156129467594731, "timer/env.step_min": 0.022745609283447266, "timer/env.step_max": 3.2406222820281982, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.533586740493774, "timer/replay._sample_frac": 0.011530273561069858, "timer/replay._sample_avg": 0.0005193437833435597, "timer/replay._sample_min": 0.00039958953857421875, "timer/replay._sample_max": 0.011934280395507812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3365.0, "timer/agent.policy_total": 55.31555914878845, "timer/agent.policy_frac": 0.05529966900320601, "timer/agent.policy_avg": 0.01643850197586581, "timer/agent.policy_min": 0.009336709976196289, "timer/agent.policy_max": 0.11789655685424805, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.15015935897827148, "timer/dataset_train_frac": 0.00015011622366315492, "timer/dataset_train_avg": 0.00010818397620912931, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0004963874816894531, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 622.0664489269257, "timer/agent.train_frac": 0.621887751891453, "timer/agent.train_avg": 0.4481746750193989, "timer/agent.train_min": 0.43442344665527344, "timer/agent.train_max": 1.51865816116333, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763941764831543, "timer/agent.report_frac": 0.0004762573257862539, "timer/agent.report_avg": 0.23819708824157715, "timer/agent.report_min": 0.23264122009277344, "timer/agent.report_max": 0.24375295639038086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.933906555175781e-05, "timer/dataset_eval_frac": 3.932776487093104e-08, "timer/dataset_eval_avg": 3.933906555175781e-05, "timer/dataset_eval_min": 3.933906555175781e-05, "timer/dataset_eval_max": 3.933906555175781e-05, "fps": 22.193329319011564}
{"step": 372560, "time": 17414.798897266388, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 372632, "time": 17418.749894618988, "episode/length": 378.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9868073878627969, "episode/intrinsic_return": 0.0}
{"step": 372680, "time": 17421.933127641678, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 372904, "time": 17430.914091825485, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 373424, "time": 17450.033119916916, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 373464, "time": 17452.690786361694, "episode/length": 302.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 373544, "time": 17456.828330039978, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 373936, "time": 17471.707194805145, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 373952, "time": 17473.73815369606, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 374112, "time": 17480.65486431122, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 374152, "time": 17483.29560995102, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 374312, "time": 17490.140417099, "episode/length": 46.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 374488, "time": 17497.472455978394, "episode/length": 127.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 374688, "time": 17505.89433002472, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 375080, "time": 17520.205140590668, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 375216, "time": 17526.561864614487, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 375728, "time": 17545.3157081604, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 375744, "time": 17547.29341650009, "episode/length": 274.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 375896, "time": 17553.701585054398, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 375928, "time": 17556.355522871017, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 376104, "time": 17563.623913288116, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 376288, "time": 17571.695551156998, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 376952, "time": 17596.57632112503, "episode/length": 131.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 377008, "time": 17600.50635576248, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 377296, "time": 17611.623270988464, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 377480, "time": 17619.03650379181, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 377552, "time": 17623.236104488373, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 377560, "time": 17624.84005331993, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 377864, "time": 17636.50505566597, "episode/length": 37.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 378064, "time": 17645.463555574417, "episode/length": 95.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 378144, "time": 17649.72174692154, "episode/length": 141.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 378264, "time": 17654.99645113945, "episode/length": 316.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779179810725552, "episode/intrinsic_return": 0.0}
{"step": 378288, "time": 17657.48602962494, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 378632, "time": 17670.267853975296, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 378920, "time": 17681.410595417023, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 378944, "time": 17683.961423635483, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 379264, "time": 17696.152582406998, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9542857142857143, "episode/intrinsic_return": 0.0}
{"step": 379400, "time": 17701.97534251213, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 379512, "time": 17707.23992705345, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 379568, "time": 17710.831807136536, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 379864, "time": 17722.127653837204, "episode/length": 36.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 380000, "time": 17728.413325548172, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17744.946570396423, "eval_episode/length": 35.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 380016, "time": 17751.65939760208, "eval_episode/length": 158.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 380016, "time": 17753.39431643486, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 380016, "time": 17754.861364603043, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 380016, "time": 17757.903835773468, "eval_episode/length": 199.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.99}
{"step": 380016, "time": 17759.93115925789, "eval_episode/length": 209.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 380016, "time": 17761.93564414978, "eval_episode/length": 219.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9590909090909091}
{"step": 380016, "time": 17764.99170565605, "eval_episode/length": 216.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9861751152073732}
{"step": 380136, "time": 17768.757125854492, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 380392, "time": 17778.993554592133, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 380400, "time": 17781.079320669174, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 380504, "time": 17785.806120157242, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 381232, "time": 17811.836155653, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 381376, "time": 17818.143519878387, "episode/length": 171.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 381472, "time": 17822.88770222664, "episode/length": 200.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 381520, "time": 17826.06719493866, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 381536, "time": 17828.097871780396, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 381720, "time": 17835.499486207962, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 381832, "time": 17840.818004608154, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 382904, "time": 17878.008052110672, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 382912, "time": 17880.089646339417, "episode/length": 438.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9977220956719818, "episode/intrinsic_return": 0.0}
{"step": 383144, "time": 17889.31496500969, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 383240, "time": 17894.21693944931, "episode/length": 341.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9970760233918129, "episode/intrinsic_return": 0.0}
{"step": 383336, "time": 17899.68282532692, "episode/length": 52.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 383376, "time": 17903.216783046722, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 383416, "time": 17905.8616399765, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 383480, "time": 17909.596958875656, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 383800, "time": 17921.536293268204, "episode/length": 282.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 384184, "time": 17935.853989839554, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 384840, "time": 17959.749845981598, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 384976, "time": 17966.126959085464, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 385024, "time": 17969.502534866333, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 385096, "time": 17974.819679021835, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 385144, "time": 17977.867967128754, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 385256, "time": 17983.08573937416, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 385424, "time": 17990.519483089447, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 385448, "time": 17992.670063257217, "episode/length": 287.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 385856, "time": 18007.991718769073, "episode/length": 88.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 385872, "time": 18010.089797258377, "episode/length": 210.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 386280, "time": 18024.911036729813, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 386536, "time": 18034.91544699669, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 386624, "time": 18039.610678195953, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 387080, "time": 18056.144906759262, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 387160, "time": 18060.402448177338, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 387288, "time": 18066.09731245041, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 387328, "time": 18069.179523468018, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 387344, "time": 18071.30908536911, "episode/length": 260.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 388160, "time": 18099.93073296547, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 388512, "time": 18113.24600672722, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 388544, "time": 18115.857072353363, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 388544, "time": 18115.86616063118, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 388584, "time": 18120.23360133171, "episode/length": 244.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 388592, "time": 18122.34179520607, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 388736, "time": 18128.683327913284, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 388920, "time": 18136.15890431404, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 389264, "time": 18149.440911769867, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 389864, "time": 18170.881342172623, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18192.218544244766, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.875}
{"step": 390000, "time": 18194.077167987823, "eval_episode/length": 46.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 390000, "time": 18196.255834579468, "eval_episode/length": 60.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 390000, "time": 18202.200119495392, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 390000, "time": 18204.50635743141, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 390000, "time": 18206.751903533936, "eval_episode/length": 198.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 390000, "time": 18206.760310411453, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 390000, "time": 18210.43808031082, "eval_episode/length": 209.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 390024, "time": 18211.015293598175, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 390072, "time": 18214.42565703392, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 390496, "time": 18230.460807085037, "episode/length": 237.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 390736, "time": 18240.149924993515, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 390880, "time": 18246.538465976715, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 391288, "time": 18261.623111248016, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 391304, "time": 18263.6280772686, "episode/length": 153.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 391352, "time": 18266.82813310623, "episode/length": 303.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 391536, "time": 18274.723743200302, "episode/length": 208.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 391960, "time": 18290.604530096054, "episode/length": 426.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 391976, "time": 18292.63054037094, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 392184, "time": 18301.02650952339, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 392288, "time": 18306.251652002335, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 392640, "time": 18319.545076847076, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 392696, "time": 18322.695162296295, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 392824, "time": 18328.474759578705, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 393040, "time": 18337.601503133774, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 393120, "time": 18341.81896686554, "episode/length": 36.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 393176, "time": 18345.002631425858, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 393544, "time": 18360.218089580536, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 393880, "time": 18372.95335125923, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 393944, "time": 18376.608741998672, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 394056, "time": 18382.071640491486, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 394320, "time": 18392.538400411606, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 394360, "time": 18395.245360851288, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 394368, "time": 18397.341739416122, "episode/length": 165.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 394408, "time": 18399.98976969719, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 394489, "time": 18405.163625717163, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4020376896512685, "train/action_min": 0.0, "train/action_std": 3.208989361058111, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05182370422003062, "train/actor_opt_grad_steps": 23865.0, "train/actor_opt_loss": -5.960843586187432, "train/adv_mag": 0.7537486697884573, "train/adv_max": 0.7319369607645533, "train/adv_mean": 0.00375879943227198, "train/adv_min": -0.5257948412411455, "train/adv_std": 0.07822989016447378, "train/cont_avg": 0.9946784420289855, "train/cont_loss_mean": 0.00017329407540791036, "train/cont_loss_std": 0.0046594714777658764, "train/cont_neg_acc": 0.9946169784103615, "train/cont_neg_loss": 0.01881511041719405, "train/cont_pos_acc": 0.9999715305756831, "train/cont_pos_loss": 7.443464645408837e-05, "train/cont_pred": 0.9946876639041348, "train/cont_rate": 0.9946784420289855, "train/dyn_loss_mean": 14.76535415649414, "train/dyn_loss_std": 8.71861707991448, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8513472758341527, "train/extr_critic_critic_opt_grad_steps": 23865.0, "train/extr_critic_critic_opt_loss": 15876.737014549366, "train/extr_critic_mag": 4.883502649224323, "train/extr_critic_max": 4.883502649224323, "train/extr_critic_mean": 0.8947658493466999, "train/extr_critic_min": -0.21577605389166568, "train/extr_critic_std": 1.0503286766833153, "train/extr_return_normed_mag": 1.873647215573684, "train/extr_return_normed_max": 1.873647215573684, "train/extr_return_normed_mean": 0.3032892805294714, "train/extr_return_normed_min": -0.1409088227951872, "train/extr_return_normed_std": 0.33419114102919895, "train/extr_return_rate": 0.4554187657608502, "train/extr_return_raw_mag": 6.018640079360077, "train/extr_return_raw_max": 6.018640079360077, "train/extr_return_raw_mean": 0.9069943607285402, "train/extr_return_raw_min": -0.5391127888275229, "train/extr_return_raw_std": 1.0880399221095487, "train/extr_reward_mag": 1.0162008499753648, "train/extr_reward_max": 1.0162008499753648, "train/extr_reward_mean": 0.025963411065817312, "train/extr_reward_min": -0.3430926989817965, "train/extr_reward_std": 0.14979138716623402, "train/image_loss_mean": 8.235514036123304, "train/image_loss_std": 12.524974242500637, "train/model_loss_mean": 17.149608003920402, "train/model_loss_std": 15.961600448774254, "train/model_opt_grad_norm": 64.5800545733908, "train/model_opt_grad_steps": 23840.985507246376, "train/model_opt_loss": 18696.104669100998, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1086.9565217391305, "train/policy_entropy_mag": 2.446174412533857, "train/policy_entropy_max": 2.446174412533857, "train/policy_entropy_mean": 0.6264392532732176, "train/policy_entropy_min": 0.07937519300891005, "train/policy_entropy_std": 0.6175615407418513, "train/policy_logprob_mag": 7.43838315770246, "train/policy_logprob_max": -0.009455746701122194, "train/policy_logprob_mean": -0.6260648961516394, "train/policy_logprob_min": -7.43838315770246, "train/policy_logprob_std": 1.14333757110264, "train/policy_randomness_mag": 0.863392218299534, "train/policy_randomness_max": 0.863392218299534, "train/policy_randomness_mean": 0.2211055683269017, "train/policy_randomness_min": 0.028015959697465103, "train/policy_randomness_std": 0.21797212537216104, "train/post_ent_mag": 56.35193012071692, "train/post_ent_max": 56.35193012071692, "train/post_ent_mean": 39.33929224981778, "train/post_ent_min": 19.994721419569373, "train/post_ent_std": 7.292351809100828, "train/prior_ent_mag": 65.33599339360777, "train/prior_ent_max": 65.33599339360777, "train/prior_ent_mean": 54.15671553128008, "train/prior_ent_min": 40.00137848784958, "train/prior_ent_std": 4.043861245763475, "train/rep_loss_mean": 14.76535415649414, "train/rep_loss_std": 8.71861707991448, "train/reward_avg": 0.02320468168624717, "train/reward_loss_mean": 0.054708470414946045, "train/reward_loss_std": 0.2587737790916277, "train/reward_max_data": 1.0137681192246035, "train/reward_max_pred": 1.007697209931802, "train/reward_neg_acc": 0.9927254401255345, "train/reward_neg_loss": 0.030051066411956064, "train/reward_pos_acc": 0.9560841278753419, "train/reward_pos_loss": 0.9122444097546564, "train/reward_pred": 0.022106123588763286, "train/reward_rate": 0.0280372509057971, "train_stats/sum_log_reward": 5.337288055379512, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.864406779661017, "train_stats/max_log_achievement_collect_sapling": 2.9745762711864407, "train_stats/max_log_achievement_collect_stone": 0.11864406779661017, "train_stats/max_log_achievement_collect_wood": 5.771186440677966, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.3898305084745763, "train_stats/max_log_achievement_eat_cow": 0.0423728813559322, "train_stats/max_log_achievement_eat_plant": 0.00847457627118644, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3559322033898305, "train_stats/max_log_achievement_make_wood_sword": 0.03389830508474576, "train_stats/max_log_achievement_place_plant": 2.830508474576271, "train_stats/max_log_achievement_place_stone": 0.00847457627118644, "train_stats/max_log_achievement_place_table": 2.0762711864406778, "train_stats/max_log_achievement_wake_up": 1.61864406779661, "train_stats/mean_log_entropy": 0.5923384225974648, "eval_stats/sum_log_reward": 4.4124999810010195, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.7732032776839333e-06, "report/cont_loss_std": 5.497602978721261e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.555512224324048e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.591633801785065e-06, "report/cont_pred": 0.998044490814209, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 15.821098327636719, "report/dyn_loss_std": 9.121672630310059, "report/image_loss_mean": 8.377921104431152, "report/image_loss_std": 10.639599800109863, "report/model_loss_mean": 17.926647186279297, "report/model_loss_std": 14.494111061096191, "report/post_ent_mag": 53.45195770263672, "report/post_ent_max": 53.45195770263672, "report/post_ent_mean": 38.12324905395508, "report/post_ent_min": 20.65054702758789, "report/post_ent_std": 6.797456741333008, "report/prior_ent_mag": 65.6325454711914, "report/prior_ent_max": 65.6325454711914, "report/prior_ent_mean": 54.15471267700195, "report/prior_ent_min": 43.06126403808594, "report/prior_ent_std": 4.04442834854126, "report/rep_loss_mean": 15.821098327636719, "report/rep_loss_std": 9.121672630310059, "report/reward_avg": 0.02871093526482582, "report/reward_loss_mean": 0.056063320487737656, "report/reward_loss_std": 0.29460546374320984, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002903699874878, "report/reward_neg_acc": 0.9969757795333862, "report/reward_neg_loss": 0.02793251909315586, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.928118109703064, "report/reward_pred": 0.027279885485768318, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.4862913531032973e-06, "eval/cont_loss_std": 2.6358935429016128e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002398979413555935, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.513435894499708e-07, "eval/cont_pred": 0.9960941672325134, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.034927368164062, "eval/dyn_loss_std": 9.621756553649902, "eval/image_loss_mean": 20.472644805908203, "eval/image_loss_std": 24.717529296875, "eval/model_loss_mean": 31.98302459716797, "eval/model_loss_std": 28.638647079467773, "eval/post_ent_mag": 55.578941345214844, "eval/post_ent_max": 55.578941345214844, "eval/post_ent_mean": 38.236900329589844, "eval/post_ent_min": 21.183069229125977, "eval/post_ent_std": 7.004215717315674, "eval/prior_ent_mag": 65.6325454711914, "eval/prior_ent_max": 65.6325454711914, "eval/prior_ent_mean": 55.496009826660156, "eval/prior_ent_min": 36.039512634277344, "eval/prior_ent_std": 3.4104292392730713, "eval/rep_loss_mean": 19.034927368164062, "eval/rep_loss_std": 9.621756553649902, "eval/reward_avg": 0.02529296651482582, "eval/reward_loss_mean": 0.0894237756729126, "eval/reward_loss_std": 0.584036111831665, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023598670959473, "eval/reward_neg_acc": 0.9949748516082764, "eval/reward_neg_loss": 0.04055539891123772, "eval/reward_pos_acc": 0.8275861740112305, "eval/reward_pos_loss": 1.766114592552185, "eval/reward_pred": 0.021474018692970276, "eval/reward_rate": 0.0283203125, "replay/size": 393985.0, "replay/inserts": 22224.0, "replay/samples": 22224.0, "replay/insert_wait_avg": 1.357507585535125e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.592082624387364e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78760.0, "eval_replay/inserts": 3704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2000745110068929e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.245091676712, "timer/env.step_count": 2778.0, "timer/env.step_total": 261.47803139686584, "timer/env.step_frac": 0.26141396101084574, "timer/env.step_avg": 0.09412456133796467, "timer/env.step_min": 0.022769927978515625, "timer/env.step_max": 3.2739269733428955, "timer/replay._sample_count": 22224.0, "timer/replay._sample_total": 11.47852873802185, "timer/replay._sample_frac": 0.011475716135512726, "timer/replay._sample_avg": 0.0005164924738130782, "timer/replay._sample_min": 0.0004150867462158203, "timer/replay._sample_max": 0.009918451309204102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3241.0, "timer/agent.policy_total": 52.147751808166504, "timer/agent.policy_frac": 0.052134973959983316, "timer/agent.policy_avg": 0.01609001907070858, "timer/agent.policy_min": 0.009272575378417969, "timer/agent.policy_max": 0.09091877937316895, "timer/dataset_train_count": 1389.0, "timer/dataset_train_total": 0.15143561363220215, "timer/dataset_train_frac": 0.00015139850711824084, "timer/dataset_train_avg": 0.00010902491982159982, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0002655982971191406, "timer/agent.train_count": 1389.0, "timer/agent.train_total": 621.6691508293152, "timer/agent.train_frac": 0.6215168222292503, "timer/agent.train_avg": 0.44756598331844144, "timer/agent.train_min": 0.43397045135498047, "timer/agent.train_max": 1.6317222118377686, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4707975387573242, "timer/agent.report_frac": 0.0004706821784730038, "timer/agent.report_avg": 0.2353987693786621, "timer/agent.report_min": 0.22321796417236328, "timer/agent.report_max": 0.24757957458496094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.202957153320312e-05, "timer/dataset_eval_frac": 9.20070213780643e-08, "timer/dataset_eval_avg": 9.202957153320312e-05, "timer/dataset_eval_min": 9.202957153320312e-05, "timer/dataset_eval_max": 9.202957153320312e-05, "fps": 22.21823847188491}
{"step": 394776, "time": 18414.53382897377, "episode/length": 51.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 395304, "time": 18433.831463336945, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 395368, "time": 18437.433516025543, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 395392, "time": 18440.076060056686, "episode/length": 428.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 395552, "time": 18446.931688308716, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 395592, "time": 18450.085574150085, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 395720, "time": 18456.388514995575, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 396200, "time": 18473.767565011978, "episode/length": 228.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 396432, "time": 18483.251352787018, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 396512, "time": 18487.52307200432, "episode/length": 142.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 396664, "time": 18493.797991752625, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 396776, "time": 18499.06696677208, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 396952, "time": 18506.33606481552, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 397080, "time": 18512.104793787003, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 397648, "time": 18532.61593723297, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966804979253112, "episode/intrinsic_return": 0.0}
{"step": 397816, "time": 18539.443958759308, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 397824, "time": 18541.41361117363, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 397864, "time": 18544.00508403778, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 397880, "time": 18546.03412413597, "episode/length": 180.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 398160, "time": 18556.944977283478, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 398512, "time": 18570.28483247757, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 398664, "time": 18576.59872031212, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 398976, "time": 18588.748782634735, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 399048, "time": 18592.39923596382, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 399160, "time": 18597.6976852417, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 399384, "time": 18606.65038704872, "episode/length": 189.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 399392, "time": 18608.743701696396, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 399528, "time": 18614.609976768494, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 399648, "time": 18620.460299491882, "episode/length": 320.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 399672, "time": 18622.67283129692, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 399936, "time": 18633.220234394073, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18654.338537454605, "eval_episode/length": 42.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 400088, "time": 18659.747455835342, "eval_episode/length": 138.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712230215827338}
{"step": 400088, "time": 18663.11259818077, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 400088, "time": 18664.74333500862, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 400088, "time": 18667.494921684265, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 400088, "time": 18669.22404575348, "eval_episode/length": 215.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 400088, "time": 18671.22712945938, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 400088, "time": 18673.434371471405, "eval_episode/length": 239.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 400480, "time": 18686.57656431198, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 400712, "time": 18695.5512444973, "episode/length": 216.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 400896, "time": 18703.386500597, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 400952, "time": 18706.564949035645, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 401288, "time": 18719.46092391014, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 401400, "time": 18724.76477241516, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 401416, "time": 18727.144855499268, "episode/length": 235.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 401480, "time": 18732.191404104233, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 401736, "time": 18742.262506484985, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 401992, "time": 18752.360936641693, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 402392, "time": 18767.317066669464, "episode/length": 81.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 402400, "time": 18769.961162805557, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 402616, "time": 18779.180994033813, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 402712, "time": 18784.453413009644, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 402768, "time": 18788.082381010056, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 403152, "time": 18802.359694242477, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737704918032787, "episode/intrinsic_return": 0.0}
{"step": 403344, "time": 18810.19849729538, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 403768, "time": 18825.437200069427, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 403776, "time": 18827.47598052025, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 403840, "time": 18831.343846797943, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 403912, "time": 18834.997205495834, "episode/length": 94.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 404416, "time": 18853.690420627594, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 404784, "time": 18867.927770614624, "episode/length": 258.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 405048, "time": 18877.945243358612, "episode/length": 159.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 405088, "time": 18881.005465507507, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 405280, "time": 18888.95848798752, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 405280, "time": 18888.968823432922, "episode/length": 313.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 405576, "time": 18901.987281799316, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 406096, "time": 18921.575386047363, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 406168, "time": 18925.271788597107, "episode/length": 218.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 406384, "time": 18934.3486866951, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 406416, "time": 18937.017456293106, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 406496, "time": 18941.196982860565, "episode/length": 49.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 406560, "time": 18944.897819042206, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 406576, "time": 18947.087474822998, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 406736, "time": 18953.946835517883, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 406960, "time": 18962.89776611328, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 407464, "time": 18980.82027721405, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 407496, "time": 18983.416584968567, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 407872, "time": 18997.547807455063, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 407912, "time": 19000.13713669777, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 408040, "time": 19005.983275175095, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 408112, "time": 19010.726553201675, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 408352, "time": 19020.91664814949, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 408472, "time": 19026.818776369095, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 409008, "time": 19046.76215147972, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 409232, "time": 19055.720633506775, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 409456, "time": 19064.738351106644, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 409544, "time": 19069.06641459465, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 409704, "time": 19077.390642166138, "episode/length": 223.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 409784, "time": 19081.653707265854, "episode/length": 424.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 410008, "time": 19090.606612682343, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19115.534064531326, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 410072, "time": 19117.72198319435, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 410072, "time": 19119.388092517853, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 410072, "time": 19121.10262155533, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 410072, "time": 19123.30255317688, "eval_episode/length": 207.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 410072, "time": 19127.620626449585, "eval_episode/length": 274.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9890909090909091}
{"step": 410072, "time": 19129.873955249786, "eval_episode/length": 287.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 410072, "time": 19132.392874002457, "eval_episode/length": 312.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.987220447284345}
{"step": 410536, "time": 19147.75368332863, "episode/length": 190.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 410624, "time": 19152.477055072784, "episode/length": 394.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 410704, "time": 19156.74971818924, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 410944, "time": 19166.29908323288, "episode/length": 39.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 411104, "time": 19173.19452381134, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 411144, "time": 19175.88478565216, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 411280, "time": 19182.159739732742, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 411648, "time": 19195.81506037712, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 411792, "time": 19202.145069122314, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 411960, "time": 19210.178897857666, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 412296, "time": 19222.90147805214, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 412560, "time": 19233.577568769455, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 412584, "time": 19235.696487903595, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 412640, "time": 19239.341631889343, "episode/length": 366.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.989100817438692, "episode/intrinsic_return": 0.0}
{"step": 412808, "time": 19246.156476020813, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 413056, "time": 19256.200647592545, "episode/length": 175.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 413096, "time": 19258.867017269135, "episode/length": 99.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 413432, "time": 19271.516481399536, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 413648, "time": 19280.51160812378, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 413840, "time": 19288.417768716812, "episode/length": 50.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 413960, "time": 19293.69607281685, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 414048, "time": 19298.36265850067, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 414232, "time": 19305.85594701767, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 414384, "time": 19312.9348218441, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 414416, "time": 19315.66606068611, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 414552, "time": 19321.483836889267, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 414920, "time": 19335.18076491356, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 415312, "time": 19349.87907719612, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 415536, "time": 19358.799215316772, "episode/length": 196.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 415560, "time": 19360.966069459915, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 416032, "time": 19378.52856040001, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 416080, "time": 19381.576195955276, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 416112, "time": 19384.34122300148, "episode/length": 376.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761273209549072, "episode/intrinsic_return": 0.0}
{"step": 416200, "time": 19389.187198877335, "episode/length": 159.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 416264, "time": 19392.776387691498, "episode/length": 234.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 416569, "time": 19405.28902196884, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.72307420813519, "train/action_min": 0.0, "train/action_std": 3.343149641285772, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04957051974707755, "train/actor_opt_grad_steps": 25245.0, "train/actor_opt_loss": -4.704329714610957, "train/adv_mag": 0.7472779185011766, "train/adv_max": 0.7307659067969391, "train/adv_mean": 0.0033583349961217195, "train/adv_min": -0.5096764393906662, "train/adv_std": 0.07471956110194973, "train/cont_avg": 0.9946642889492754, "train/cont_loss_mean": 0.00022540692250718462, "train/cont_loss_std": 0.006779706608991065, "train/cont_neg_acc": 0.9882301277872445, "train/cont_neg_loss": 0.03272098607851439, "train/cont_pos_acc": 0.9999786351901897, "train/cont_pos_loss": 7.151159538031987e-05, "train/cont_pred": 0.9946794116842574, "train/cont_rate": 0.9946642889492754, "train/dyn_loss_mean": 14.695822985275932, "train/dyn_loss_std": 8.758436911347983, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8483279878678529, "train/extr_critic_critic_opt_grad_steps": 25245.0, "train/extr_critic_critic_opt_loss": 15669.164296025816, "train/extr_critic_mag": 4.949617275293322, "train/extr_critic_max": 4.949617275293322, "train/extr_critic_mean": 0.8494384772535684, "train/extr_critic_min": -0.21994732255521027, "train/extr_critic_std": 1.0654074731080427, "train/extr_return_normed_mag": 1.8393921549769416, "train/extr_return_normed_max": 1.8393921549769416, "train/extr_return_normed_mean": 0.28797721290501993, "train/extr_return_normed_min": -0.1411463265725668, "train/extr_return_normed_std": 0.3360630726252777, "train/extr_return_rate": 0.41659780958856363, "train/extr_return_raw_mag": 5.934799484584643, "train/extr_return_raw_max": 5.934799484584643, "train/extr_return_raw_mean": 0.8604372947112374, "train/extr_return_raw_min": -0.542909842254459, "train/extr_return_raw_std": 1.0991158416305764, "train/extr_reward_mag": 1.0144132634867793, "train/extr_reward_max": 1.0144132634867793, "train/extr_reward_mean": 0.025078624824358933, "train/extr_reward_min": -0.3689015939615775, "train/extr_reward_std": 0.14697899307677711, "train/image_loss_mean": 7.995681379152381, "train/image_loss_std": 12.080729722976685, "train/model_loss_mean": 16.86819076538086, "train/model_loss_std": 15.573035634082297, "train/model_opt_grad_norm": 61.95169089496999, "train/model_opt_grad_steps": 25219.115942028984, "train/model_opt_loss": 13478.32469995471, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 797.1014492753624, "train/policy_entropy_mag": 2.467467354691547, "train/policy_entropy_max": 2.467467354691547, "train/policy_entropy_mean": 0.6291913562926693, "train/policy_entropy_min": 0.0793751633145671, "train/policy_entropy_std": 0.632183501685875, "train/policy_logprob_mag": 7.438383233719978, "train/policy_logprob_max": -0.009455718417260527, "train/policy_logprob_mean": -0.6288897630529128, "train/policy_logprob_min": -7.438383233719978, "train/policy_logprob_std": 1.146101486855659, "train/policy_randomness_mag": 0.8709076936694159, "train/policy_randomness_max": 0.8709076936694159, "train/policy_randomness_mean": 0.2220769390679788, "train/policy_randomness_min": 0.02801594937193221, "train/policy_randomness_std": 0.2231330340323241, "train/post_ent_mag": 56.72899061009504, "train/post_ent_max": 56.72899061009504, "train/post_ent_mean": 39.51530511828437, "train/post_ent_min": 19.823085453199305, "train/post_ent_std": 7.355257946511974, "train/prior_ent_mag": 65.4622456094493, "train/prior_ent_max": 65.4622456094493, "train/prior_ent_mean": 54.24592015363168, "train/prior_ent_min": 40.0209553760031, "train/prior_ent_std": 4.033022203307221, "train/rep_loss_mean": 14.695822985275932, "train/rep_loss_std": 8.758436911347983, "train/reward_avg": 0.02209083425839418, "train/reward_loss_mean": 0.05479008323796417, "train/reward_loss_std": 0.25631054426017014, "train/reward_max_data": 1.013043481370677, "train/reward_max_pred": 1.008467403874881, "train/reward_neg_acc": 0.9925193527470464, "train/reward_neg_loss": 0.031111440925008577, "train/reward_pos_acc": 0.9564597222252168, "train/reward_pos_loss": 0.9126520200052123, "train/reward_pred": 0.021229492723131956, "train/reward_rate": 0.026982846467391304, "train_stats/sum_log_reward": 5.116949117789834, "train_stats/max_log_achievement_collect_coal": 0.00847457627118644, "train_stats/max_log_achievement_collect_drink": 4.8559322033898304, "train_stats/max_log_achievement_collect_sapling": 2.635593220338983, "train_stats/max_log_achievement_collect_stone": 0.16101694915254236, "train_stats/max_log_achievement_collect_wood": 6.059322033898305, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.3559322033898305, "train_stats/max_log_achievement_eat_cow": 0.05084745762711865, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.17796610169491525, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5338983050847457, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.347457627118644, "train_stats/max_log_achievement_wake_up": 1.576271186440678, "train_stats/mean_log_entropy": 0.566199009827638, "eval_stats/sum_log_reward": 5.224999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 3.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0001052748630172573, "report/cont_loss_std": 0.00249591376632452, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0178876630961895, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.6707404521839635e-07, "report/cont_pred": 0.9942420721054077, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.063718795776367, "report/dyn_loss_std": 8.40168571472168, "report/image_loss_mean": 7.300579071044922, "report/image_loss_std": 9.008845329284668, "report/model_loss_mean": 16.388526916503906, "report/model_loss_std": 12.404809951782227, "report/post_ent_mag": 58.33971405029297, "report/post_ent_max": 58.33971405029297, "report/post_ent_mean": 39.25728988647461, "report/post_ent_min": 19.345928192138672, "report/post_ent_std": 7.588785648345947, "report/prior_ent_mag": 65.54830932617188, "report/prior_ent_max": 65.54830932617188, "report/prior_ent_mean": 54.64626693725586, "report/prior_ent_min": 43.57337951660156, "report/prior_ent_std": 4.061282157897949, "report/rep_loss_mean": 15.063718795776367, "report/rep_loss_std": 8.40168571472168, "report/reward_avg": 0.03339843824505806, "report/reward_loss_mean": 0.04961084574460983, "report/reward_loss_std": 0.19242608547210693, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011520385742188, "report/reward_neg_acc": 0.9949238896369934, "report/reward_neg_loss": 0.020383866503834724, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7877794504165649, "report/reward_pred": 0.03138367831707001, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.673173407354625e-06, "eval/cont_loss_std": 6.694486364722252e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00044903860543854535, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.9305635962373344e-06, "eval/cont_pred": 0.996092677116394, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.436019897460938, "eval/dyn_loss_std": 9.350030899047852, "eval/image_loss_mean": 14.997947692871094, "eval/image_loss_std": 19.234046936035156, "eval/model_loss_mean": 25.545238494873047, "eval/model_loss_std": 22.695663452148438, "eval/post_ent_mag": 57.57763671875, "eval/post_ent_max": 57.57763671875, "eval/post_ent_mean": 39.47322082519531, "eval/post_ent_min": 20.344863891601562, "eval/post_ent_std": 7.483788013458252, "eval/prior_ent_mag": 65.54830932617188, "eval/prior_ent_max": 65.54830932617188, "eval/prior_ent_mean": 55.311317443847656, "eval/prior_ent_min": 39.35978698730469, "eval/prior_ent_std": 4.056910037994385, "eval/rep_loss_mean": 17.436019897460938, "eval/rep_loss_std": 9.350030899047852, "eval/reward_avg": 0.03173828125, "eval/reward_loss_mean": 0.08567356318235397, "eval/reward_loss_std": 0.5428851842880249, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9993391036987305, "eval/reward_neg_acc": 0.9939332008361816, "eval/reward_neg_loss": 0.028404440730810165, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 1.7039352655410767, "eval/reward_pred": 0.02469012141227722, "eval/reward_rate": 0.0341796875, "replay/size": 416065.0, "replay/inserts": 22080.0, "replay/samples": 22080.0, "replay/insert_wait_avg": 1.3655186563298323e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.57216543391131e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83184.0, "eval_replay/inserts": 4424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1622905731201172e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1123037338257, "timer/env.step_count": 2760.0, "timer/env.step_total": 262.858500957489, "timer/env.step_frac": 0.2628289842811966, "timer/env.step_avg": 0.09523858730343805, "timer/env.step_min": 0.022583723068237305, "timer/env.step_max": 3.3837296962738037, "timer/replay._sample_count": 22080.0, "timer/replay._sample_total": 11.341059684753418, "timer/replay._sample_frac": 0.011339786184424123, "timer/replay._sample_avg": 0.0005136349494906439, "timer/replay._sample_min": 0.000396728515625, "timer/replay._sample_max": 0.025221824645996094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3313.0, "timer/agent.policy_total": 54.248332262039185, "timer/agent.policy_frac": 0.05424224065588246, "timer/agent.policy_avg": 0.01637438341745825, "timer/agent.policy_min": 0.009365320205688477, "timer/agent.policy_max": 0.11423230171203613, "timer/dataset_train_count": 1380.0, "timer/dataset_train_total": 0.15176796913146973, "timer/dataset_train_frac": 0.00015175092693576334, "timer/dataset_train_avg": 0.0001099767892257027, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010712146759033203, "timer/agent.train_count": 1380.0, "timer/agent.train_total": 616.0968995094299, "timer/agent.train_frac": 0.6160277172966374, "timer/agent.train_avg": 0.44644702863002167, "timer/agent.train_min": 0.4345238208770752, "timer/agent.train_max": 1.6281530857086182, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4738595485687256, "timer/agent.report_frac": 0.00047380633834781885, "timer/agent.report_avg": 0.2369297742843628, "timer/agent.report_min": 0.23039746284484863, "timer/agent.report_max": 0.24346208572387695, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146771849912382e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.07720919876565}
{"step": 416856, "time": 19414.62522292137, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 416944, "time": 19419.342593193054, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 416952, "time": 19420.929857969284, "episode/length": 204.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 417472, "time": 19439.877153635025, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 417480, "time": 19441.471230983734, "episode/length": 170.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 417528, "time": 19444.623467206955, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 417600, "time": 19448.856950998306, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 418288, "time": 19474.548342227936, "episode/length": 252.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 418336, "time": 19477.653698921204, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 418352, "time": 19479.826167345047, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 418464, "time": 19485.021951436996, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 418624, "time": 19491.90711236, "episode/length": 33.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 418624, "time": 19491.914169073105, "episode/length": 35.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 418688, "time": 19498.222136497498, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 419040, "time": 19511.583652973175, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 419072, "time": 19514.24304819107, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 419416, "time": 19526.881932020187, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 419792, "time": 19541.005527973175, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 419856, "time": 19544.693903684616, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 419912, "time": 19547.8706741333, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19573.29291844368, "eval_episode/length": 149.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 420056, "time": 19575.04447865486, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 420056, "time": 19576.805683851242, "eval_episode/length": 155.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 420056, "time": 19578.596095323563, "eval_episode/length": 158.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 420056, "time": 19580.487468242645, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 420056, "time": 19582.366252422333, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 420056, "time": 19584.36775994301, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 420056, "time": 19586.55442070961, "eval_episode/length": 46.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 420184, "time": 19590.806975364685, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 420224, "time": 19593.898842334747, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 420272, "time": 19597.09695982933, "episode/length": 197.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 420912, "time": 19619.78625869751, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 421152, "time": 19629.333969831467, "episode/length": 161.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 421296, "time": 19635.655086278915, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 421320, "time": 19637.890021800995, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 421344, "time": 19640.628098726273, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 421808, "time": 19657.621557712555, "episode/length": 251.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 422000, "time": 19665.597221136093, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 422392, "time": 19679.82302546501, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 422592, "time": 19688.235138893127, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 422632, "time": 19690.9618537426, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 422864, "time": 19700.572908878326, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 423064, "time": 19708.452757120132, "episode/length": 220.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 423208, "time": 19714.88964366913, "episode/length": 372.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758713136729222, "episode/intrinsic_return": 0.0}
{"step": 423480, "time": 19725.499446630478, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 423656, "time": 19732.93571138382, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 423696, "time": 19736.074219703674, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 424024, "time": 19748.200626850128, "episode/length": 173.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 424440, "time": 19763.536757946014, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 424536, "time": 19768.233755350113, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 424928, "time": 19782.923444271088, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 424968, "time": 19785.504672050476, "episode/length": 237.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 425016, "time": 19788.72618675232, "episode/length": 191.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 425040, "time": 19791.36484479904, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 425576, "time": 19810.64742898941, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 425800, "time": 19819.832297086716, "episode/length": 157.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 425912, "time": 19825.597589969635, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 425976, "time": 19829.385464906693, "episode/length": 422.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 426368, "time": 19845.7041618824, "episode/length": 56.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9298245614035088, "episode/intrinsic_return": 0.0}
{"step": 426400, "time": 19848.37866973877, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 426480, "time": 19852.62703728676, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 426512, "time": 19855.201828718185, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 426944, "time": 19871.076513767242, "episode/length": 246.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 427144, "time": 19879.220120429993, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 427336, "time": 19887.14954853058, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 427384, "time": 19890.384312152863, "episode/length": 175.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 427464, "time": 19894.52064037323, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 427744, "time": 19905.482325553894, "episode/length": 167.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 427760, "time": 19907.549193143845, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 427952, "time": 19915.598868608475, "episode/length": 179.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 428208, "time": 19925.662998199463, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 428496, "time": 19936.72767353058, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 428624, "time": 19942.657359600067, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 429056, "time": 19958.44440984726, "episode/length": 321.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 429096, "time": 19961.12758564949, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 429400, "time": 19972.956129550934, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 429424, "time": 19975.533491134644, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 429648, "time": 19984.306152820587, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 429696, "time": 19987.400081396103, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 429976, "time": 19998.041951417923, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20020.896087884903, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 430040, "time": 20022.550374507904, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 430040, "time": 20024.45420241356, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 430040, "time": 20026.40133714676, "eval_episode/length": 176.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 430040, "time": 20028.1272687912, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 430040, "time": 20029.86371898651, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 430040, "time": 20033.531686782837, "eval_episode/length": 232.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 430040, "time": 20035.13486599922, "eval_episode/length": 233.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9829059829059829}
{"step": 430064, "time": 20036.153624534607, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 430216, "time": 20042.398337841034, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 430664, "time": 20058.791650295258, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 430776, "time": 20064.70952486992, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 430976, "time": 20073.066166639328, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 431048, "time": 20076.7030313015, "episode/length": 318.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 431152, "time": 20082.06040740013, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 431232, "time": 20086.16720032692, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 431352, "time": 20091.575570106506, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 431680, "time": 20104.253187656403, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 432216, "time": 20123.331474542618, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 432384, "time": 20130.650441884995, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 432480, "time": 20135.513402938843, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 432712, "time": 20144.431809663773, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 432760, "time": 20147.751366853714, "episode/length": 175.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 433112, "time": 20161.002867221832, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 433416, "time": 20172.854027748108, "episode/length": 282.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 433480, "time": 20176.33694410324, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 433808, "time": 20188.944446325302, "episode/length": 321.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 433944, "time": 20194.81130337715, "episode/length": 182.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 434008, "time": 20198.495076179504, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 434576, "time": 20220.61457848549, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9911894273127754, "episode/intrinsic_return": 0.0}
{"step": 434712, "time": 20226.504417181015, "episode/length": 311.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 434928, "time": 20235.494701623917, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 434976, "time": 20238.61953854561, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 435248, "time": 20249.25629901886, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 435280, "time": 20251.89998650551, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 435888, "time": 20273.55818605423, "episode/length": 146.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 436320, "time": 20289.30150294304, "episode/length": 362.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 436360, "time": 20292.05412220955, "episode/length": 293.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 436736, "time": 20306.424410820007, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 437080, "time": 20319.207621097565, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 437088, "time": 20321.253163576126, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 437272, "time": 20328.650453805923, "episode/length": 286.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 437416, "time": 20335.14052248001, "episode/length": 131.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 437472, "time": 20338.880888700485, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 437480, "time": 20340.442393779755, "episode/length": 278.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.992831541218638, "episode/intrinsic_return": 0.0}
{"step": 437576, "time": 20345.1913189888, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 437960, "time": 20359.57698225975, "episode/length": 85.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 438256, "time": 20371.13143467903, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 438504, "time": 20380.613488435745, "episode/length": 127.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 438608, "time": 20385.82129240036, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 438616, "time": 20387.450005292892, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 438912, "time": 20399.1943089962, "episode/length": 227.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 438928, "time": 20401.327101945877, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 438985, "time": 20405.42465853691, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.569778767037899, "train/action_min": 0.0, "train/action_std": 3.272446554603306, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05111419895650647, "train/actor_opt_grad_steps": 26640.0, "train/actor_opt_loss": -5.687695790584206, "train/adv_mag": 0.7393542160379126, "train/adv_max": 0.7208173241175658, "train/adv_mean": 0.003935319336734913, "train/adv_min": -0.5249945701014066, "train/adv_std": 0.07678422207633655, "train/cont_avg": 0.9946600731382979, "train/cont_loss_mean": 0.0002446383607977691, "train/cont_loss_std": 0.0066392241183650105, "train/cont_neg_acc": 0.9934988186714497, "train/cont_neg_loss": 0.02820262258430685, "train/cont_pos_acc": 0.9999790690469403, "train/cont_pos_loss": 6.712218593762132e-05, "train/cont_pred": 0.9946860201815342, "train/cont_rate": 0.9946600731382979, "train/dyn_loss_mean": 14.380637236520753, "train/dyn_loss_std": 8.698801679814116, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8302209571743688, "train/extr_critic_critic_opt_grad_steps": 26640.0, "train/extr_critic_critic_opt_loss": 15782.00020085328, "train/extr_critic_mag": 4.954982219858373, "train/extr_critic_max": 4.954982219858373, "train/extr_critic_mean": 0.8413616708407166, "train/extr_critic_min": -0.21919612935248842, "train/extr_critic_std": 1.0346279833333711, "train/extr_return_normed_mag": 1.8668306457235457, "train/extr_return_normed_max": 1.8668306457235457, "train/extr_return_normed_mean": 0.2905648431033953, "train/extr_return_normed_min": -0.1402413824718472, "train/extr_return_normed_std": 0.3315464526626235, "train/extr_return_rate": 0.42434159206583144, "train/extr_return_raw_mag": 5.944667207433822, "train/extr_return_raw_max": 5.944667207433822, "train/extr_return_raw_mean": 0.8540516444977294, "train/extr_return_raw_min": -0.5375864782654647, "train/extr_return_raw_std": 1.0709034500392616, "train/extr_reward_mag": 1.0157829058085772, "train/extr_reward_max": 1.0157829058085772, "train/extr_reward_mean": 0.025588776519958008, "train/extr_reward_min": -0.3641787606773647, "train/extr_reward_std": 0.14909202964804696, "train/image_loss_mean": 7.745209250889771, "train/image_loss_std": 12.012068136364011, "train/model_loss_mean": 16.428000118715545, "train/model_loss_std": 15.494965668265701, "train/model_opt_grad_norm": 60.23886259904145, "train/model_opt_grad_steps": 26613.58156028369, "train/model_opt_loss": 20935.070243240247, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1285.4609929078015, "train/policy_entropy_mag": 2.5358967527430107, "train/policy_entropy_max": 2.5358967527430107, "train/policy_entropy_mean": 0.6121700630120351, "train/policy_entropy_min": 0.07937514459621822, "train/policy_entropy_std": 0.629230426558366, "train/policy_logprob_mag": 7.43838329518095, "train/policy_logprob_max": -0.009455722994468313, "train/policy_logprob_mean": -0.6133000827427452, "train/policy_logprob_min": -7.43838329518095, "train/policy_logprob_std": 1.1455078387091346, "train/policy_randomness_mag": 0.895060269545156, "train/policy_randomness_max": 0.895060269545156, "train/policy_randomness_mean": 0.21606916537944307, "train/policy_randomness_min": 0.028015942781740893, "train/policy_randomness_std": 0.2220907287394747, "train/post_ent_mag": 56.68762518159041, "train/post_ent_max": 56.68762518159041, "train/post_ent_mean": 39.91321504200604, "train/post_ent_min": 19.744161795217096, "train/post_ent_std": 7.3597606361335055, "train/prior_ent_mag": 65.51714406114944, "train/prior_ent_max": 65.51714406114944, "train/prior_ent_mean": 54.385154237138465, "train/prior_ent_min": 40.9719258301647, "train/prior_ent_std": 3.903391958128476, "train/rep_loss_mean": 14.380637236520753, "train/rep_loss_std": 8.698801679814116, "train/reward_avg": 0.022495567144707164, "train/reward_loss_mean": 0.05416395845459708, "train/reward_loss_std": 0.2565939072387438, "train/reward_max_data": 1.0170212806539332, "train/reward_max_pred": 1.0112744307687096, "train/reward_neg_acc": 0.9930698998430942, "train/reward_neg_loss": 0.030228714379382893, "train/reward_pos_acc": 0.9584706916031263, "train/reward_pos_loss": 0.9103446911412774, "train/reward_pred": 0.021398970361878263, "train/reward_rate": 0.027309120124113476, "train_stats/sum_log_reward": 5.38205122642028, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.94017094017094, "train_stats/max_log_achievement_collect_sapling": 2.675213675213675, "train_stats/max_log_achievement_collect_stone": 0.4188034188034188, "train_stats/max_log_achievement_collect_wood": 6.632478632478633, "train_stats/max_log_achievement_defeat_skeleton": 0.008547008547008548, "train_stats/max_log_achievement_defeat_zombie": 0.3247863247863248, "train_stats/max_log_achievement_eat_cow": 0.10256410256410256, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.42735042735042733, "train_stats/max_log_achievement_make_wood_sword": 0.017094017094017096, "train_stats/max_log_achievement_place_plant": 2.5641025641025643, "train_stats/max_log_achievement_place_stone": 0.008547008547008548, "train_stats/max_log_achievement_place_table": 2.376068376068376, "train_stats/max_log_achievement_wake_up": 1.5128205128205128, "train_stats/mean_log_entropy": 0.5613021919360528, "eval_stats/sum_log_reward": 5.599999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 3.625, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 6.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0031200696248561144, "report/cont_loss_std": 0.09936050325632095, "report/cont_neg_acc": 0.8571429252624512, "report/cont_neg_loss": 0.4548909664154053, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0535254659771454e-05, "report/cont_pred": 0.9940927028656006, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 15.004560470581055, "report/dyn_loss_std": 9.054362297058105, "report/image_loss_mean": 9.22309684753418, "report/image_loss_std": 12.724302291870117, "report/model_loss_mean": 18.27716636657715, "report/model_loss_std": 16.424781799316406, "report/post_ent_mag": 54.941627502441406, "report/post_ent_max": 54.941627502441406, "report/post_ent_mean": 38.92449951171875, "report/post_ent_min": 17.077037811279297, "report/post_ent_std": 7.374326229095459, "report/prior_ent_mag": 65.11819458007812, "report/prior_ent_max": 65.11819458007812, "report/prior_ent_mean": 54.2043571472168, "report/prior_ent_min": 38.50201416015625, "report/prior_ent_std": 3.9421162605285645, "report/rep_loss_mean": 15.004560470581055, "report/rep_loss_std": 9.054362297058105, "report/reward_avg": 0.01455078087747097, "report/reward_loss_mean": 0.048213839530944824, "report/reward_loss_std": 0.23379357159137726, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016262531280518, "report/reward_neg_acc": 0.9960119724273682, "report/reward_neg_loss": 0.028800372034311295, "report/reward_pos_acc": 0.9047619104385376, "report/reward_pos_loss": 0.975438117980957, "report/reward_pred": 0.0143287293612957, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.892743188771419e-05, "eval/cont_loss_std": 0.0011331808054819703, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003529841487761587, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.738642772077583e-05, "eval/cont_pred": 0.9950823783874512, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.478229522705078, "eval/dyn_loss_std": 9.669742584228516, "eval/image_loss_mean": 11.003118515014648, "eval/image_loss_std": 12.967913627624512, "eval/model_loss_mean": 21.596969604492188, "eval/model_loss_std": 17.23227310180664, "eval/post_ent_mag": 54.59151077270508, "eval/post_ent_max": 54.59151077270508, "eval/post_ent_mean": 39.239097595214844, "eval/post_ent_min": 22.055410385131836, "eval/post_ent_std": 6.918457984924316, "eval/prior_ent_mag": 65.11819458007812, "eval/prior_ent_max": 65.11819458007812, "eval/prior_ent_mean": 54.94580841064453, "eval/prior_ent_min": 37.92131423950195, "eval/prior_ent_std": 4.215262413024902, "eval/rep_loss_mean": 17.478229522705078, "eval/rep_loss_std": 9.669742584228516, "eval/reward_avg": 0.02480468899011612, "eval/reward_loss_mean": 0.10687611997127533, "eval/reward_loss_std": 0.554735541343689, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005414485931396, "eval/reward_neg_acc": 0.9909273982048035, "eval/reward_neg_loss": 0.03647499531507492, "eval/reward_pos_acc": 0.59375, "eval/reward_pos_loss": 2.289310932159424, "eval/reward_pred": 0.013066248968243599, "eval/reward_rate": 0.03125, "replay/size": 438481.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3662056783367106e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.62235344009345e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86680.0, "eval_replay/inserts": 3496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1315334852554705e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1199486255646, "timer/env.step_count": 2802.0, "timer/env.step_total": 258.6771924495697, "timer/env.step_frac": 0.2586461681971869, "timer/env.step_avg": 0.09231876961083858, "timer/env.step_min": 0.022802114486694336, "timer/env.step_max": 4.182842254638672, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.505634307861328, "timer/replay._sample_frac": 0.0115042543883593, "timer/replay._sample_avg": 0.0005132777617711156, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.0117645263671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3239.0, "timer/agent.policy_total": 51.86516070365906, "timer/agent.policy_frac": 0.05185894029504743, "timer/agent.policy_avg": 0.01601270784305621, "timer/agent.policy_min": 0.009104490280151367, "timer/agent.policy_max": 0.11322855949401855, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.15317130088806152, "timer/dataset_train_frac": 0.00015315293040455832, "timer/dataset_train_avg": 0.00010932997922060067, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010678768157958984, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 625.6602544784546, "timer/agent.train_frac": 0.6255852163915749, "timer/agent.train_avg": 0.44658119520232303, "timer/agent.train_min": 0.43114519119262695, "timer/agent.train_max": 1.5594842433929443, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47437357902526855, "timer/agent.report_frac": 0.0004743166853907736, "timer/agent.report_avg": 0.23718678951263428, "timer/agent.report_min": 0.22825241088867188, "timer/agent.report_max": 0.24612116813659668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908357811516921e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.413008871047836}
{"step": 439208, "time": 20412.596138238907, "episode/length": 216.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 439336, "time": 20418.318288087845, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 439816, "time": 20435.941113233566, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20463.330088377, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 440024, "time": 20466.058602809906, "eval_episode/length": 171.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 440024, "time": 20469.073925971985, "eval_episode/length": 44.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9111111111111111}
{"step": 440024, "time": 20471.571871757507, "eval_episode/length": 206.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 440024, "time": 20474.43634390831, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 440024, "time": 20474.446753025055, "eval_episode/length": 222.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 440024, "time": 20478.743799209595, "eval_episode/length": 231.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 440024, "time": 20481.97456240654, "eval_episode/length": 38.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9487179487179487}
{"step": 440152, "time": 20486.219970941544, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 440272, "time": 20492.095513105392, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 440432, "time": 20499.060482501984, "episode/length": 271.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 440480, "time": 20502.20463204384, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 440544, "time": 20505.89522910118, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 440672, "time": 20512.237446784973, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 440816, "time": 20519.10973381996, "episode/length": 47.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 440856, "time": 20522.223431825638, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 441024, "time": 20529.52483201027, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 441688, "time": 20552.84699511528, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 441936, "time": 20562.974292755127, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 442032, "time": 20567.649944067, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 442032, "time": 20567.659026145935, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 442160, "time": 20575.252484321594, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 442320, "time": 20582.012352705002, "episode/length": 229.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 442552, "time": 20592.573035240173, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.0}
{"step": 442736, "time": 20600.574530363083, "episode/length": 257.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 443336, "time": 20622.221641540527, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 443640, "time": 20634.099123477936, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 443664, "time": 20636.687472105026, "episode/length": 187.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 444024, "time": 20649.918456077576, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 444080, "time": 20653.507821321487, "episode/length": 298.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 444176, "time": 20658.199701309204, "episode/length": 267.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 444264, "time": 20662.65254855156, "episode/length": 278.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 444320, "time": 20666.298744916916, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 444608, "time": 20677.38012933731, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 444872, "time": 20687.54115009308, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 445248, "time": 20701.7641954422, "episode/length": 133.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 445600, "time": 20714.98566865921, "episode/length": 244.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 445696, "time": 20719.765961170197, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 445760, "time": 20723.50847196579, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 445992, "time": 20732.569929599762, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 446600, "time": 20754.520801782608, "episode/length": 215.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 446760, "time": 20761.415650606155, "episode/length": 188.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 446784, "time": 20764.04742360115, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 446928, "time": 20770.306985855103, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 447120, "time": 20778.197323322296, "episode/length": 379.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 447184, "time": 20782.01872587204, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 447520, "time": 20794.592755794525, "episode/length": 190.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 447880, "time": 20807.642312288284, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 447912, "time": 20810.444612264633, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 448096, "time": 20818.22840833664, "episode/length": 435.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 448216, "time": 20823.551703214645, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 448288, "time": 20827.83827328682, "episode/length": 50.0, "episode/score": -0.9000000208616257, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 448600, "time": 20839.46308875084, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 448616, "time": 20841.42408847809, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 448896, "time": 20852.554612398148, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 448968, "time": 20856.30045413971, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 449232, "time": 20866.773544311523, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 449608, "time": 20880.682353258133, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 449648, "time": 20883.730253219604, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 449696, "time": 20886.914630651474, "episode/length": 136.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 449992, "time": 20898.170414686203, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 20919.91650366783, "eval_episode/length": 47.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 450008, "time": 20926.948447227478, "eval_episode/length": 141.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 450008, "time": 20929.82489514351, "eval_episode/length": 168.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9585798816568047}
{"step": 450008, "time": 20931.592048168182, "eval_episode/length": 172.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 450008, "time": 20933.386274814606, "eval_episode/length": 177.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 450008, "time": 20935.76724934578, "eval_episode/length": 197.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 450008, "time": 20937.50536298752, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 450008, "time": 20939.977108716965, "eval_episode/length": 46.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 450344, "time": 20951.006978034973, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 450392, "time": 20954.14780497551, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 450592, "time": 20963.925600767136, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 450688, "time": 20968.595417022705, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 450840, "time": 20975.106952428818, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 451120, "time": 20986.291112184525, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 451296, "time": 20993.82543683052, "episode/length": 210.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 451680, "time": 21008.055443763733, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 451784, "time": 21012.777184724808, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 451928, "time": 21019.151039600372, "episode/length": 278.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 452000, "time": 21023.36520051956, "episode/length": 206.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 452104, "time": 21028.14497947693, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 452744, "time": 21051.05436348915, "episode/length": 202.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 452984, "time": 21060.565776586533, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 453176, "time": 21068.541532754898, "episode/length": 291.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 453288, "time": 21073.956676721573, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 453480, "time": 21081.91218996048, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 453632, "time": 21088.610776901245, "episode/length": 42.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 453744, "time": 21093.884604215622, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 453760, "time": 21096.006560325623, "episode/length": 228.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 454032, "time": 21106.59937596321, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 454480, "time": 21122.881657600403, "episode/length": 216.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 454520, "time": 21125.540410995483, "episode/length": 191.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 454688, "time": 21132.944456338882, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 454696, "time": 21134.522866010666, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 454856, "time": 21141.56203174591, "episode/length": 46.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 455224, "time": 21155.23855471611, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 455232, "time": 21157.281841993332, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 455232, "time": 21157.29088306427, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 455528, "time": 21170.28424334526, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 455608, "time": 21174.387017965317, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 455920, "time": 21186.44603085518, "episode/length": 48.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 456096, "time": 21193.871703386307, "episode/length": 196.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 456272, "time": 21201.33890724182, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 456680, "time": 21216.183408737183, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 456896, "time": 21225.232587337494, "episode/length": 207.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 457048, "time": 21231.698608398438, "episode/length": 293.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 457488, "time": 21248.206951379776, "episode/length": 328.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 457728, "time": 21257.692546367645, "episode/length": 264.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 457776, "time": 21260.87484908104, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 457792, "time": 21263.064776420593, "episode/length": 138.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 457808, "time": 21265.172280550003, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 458072, "time": 21275.065024137497, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 458248, "time": 21282.402223587036, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 458616, "time": 21296.07133412361, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 459216, "time": 21319.270801782608, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 459328, "time": 21324.607634305954, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 459344, "time": 21326.696593999863, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 459520, "time": 21334.204873800278, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 459632, "time": 21339.511711120605, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21374.754576206207, "eval_episode/length": 128.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9689922480620154}
{"step": 460096, "time": 21377.732446193695, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 460096, "time": 21379.436374664307, "eval_episode/length": 161.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 460096, "time": 21382.287329912186, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 460096, "time": 21384.086503505707, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 460096, "time": 21386.145534992218, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 460096, "time": 21388.40702676773, "eval_episode/length": 225.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 460096, "time": 21390.664981603622, "eval_episode/length": 243.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 460136, "time": 21391.792794942856, "episode/length": 257.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 460272, "time": 21398.069532871246, "episode/length": 252.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 460425, "time": 21405.645707845688, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5440733041336285, "train/action_min": 0.0, "train/action_std": 3.0919406200522808, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051344312727451324, "train/actor_opt_grad_steps": 28015.0, "train/actor_opt_loss": -6.192016770145786, "train/adv_mag": 0.7647395529853764, "train/adv_max": 0.7496574207473157, "train/adv_mean": 0.0037234886323193367, "train/adv_min": -0.5440839664704764, "train/adv_std": 0.07697274597055877, "train/cont_avg": 0.9946726329291045, "train/cont_loss_mean": 0.0003439098747562571, "train/cont_loss_std": 0.009723370195579586, "train/cont_neg_acc": 0.9895810977856916, "train/cont_neg_loss": 0.034903788889821034, "train/cont_pos_acc": 0.9999706536086638, "train/cont_pos_loss": 0.00011646990433401941, "train/cont_pred": 0.9946920400235191, "train/cont_rate": 0.9946726329291045, "train/dyn_loss_mean": 14.482788754932916, "train/dyn_loss_std": 8.798086209083671, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7837744679913592, "train/extr_critic_critic_opt_grad_steps": 28015.0, "train/extr_critic_critic_opt_loss": 15646.811967992071, "train/extr_critic_mag": 5.116911404168428, "train/extr_critic_max": 5.116911404168428, "train/extr_critic_mean": 0.8392288268946889, "train/extr_critic_min": -0.226371719766019, "train/extr_critic_std": 1.0598709427598696, "train/extr_return_normed_mag": 1.9121656284403445, "train/extr_return_normed_max": 1.9121656284403445, "train/extr_return_normed_mean": 0.28700482567299657, "train/extr_return_normed_min": -0.14339446521072247, "train/extr_return_normed_std": 0.3358767798809863, "train/extr_return_rate": 0.4152922141018198, "train/extr_return_raw_mag": 6.161360381254509, "train/extr_return_raw_max": 6.161360381254509, "train/extr_return_raw_mean": 0.8513846134961541, "train/extr_return_raw_min": -0.5549582949102815, "train/extr_return_raw_std": 1.0975702872027213, "train/extr_reward_mag": 1.0136391209132636, "train/extr_reward_max": 1.0136391209132636, "train/extr_reward_mean": 0.02558740860879866, "train/extr_reward_min": -0.39152623646294893, "train/extr_reward_std": 0.14949420939630537, "train/image_loss_mean": 7.751745953488705, "train/image_loss_std": 12.064960244876236, "train/model_loss_mean": 16.496633885511713, "train/model_loss_std": 15.567091351124779, "train/model_opt_grad_norm": 62.663047278105324, "train/model_opt_grad_steps": 27987.141791044774, "train/model_opt_loss": 12955.026961141557, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 783.5820895522388, "train/policy_entropy_mag": 2.5558305694096126, "train/policy_entropy_max": 2.5558305694096126, "train/policy_entropy_mean": 0.6215809301209094, "train/policy_entropy_min": 0.07937513575402659, "train/policy_entropy_std": 0.6349699606201542, "train/policy_logprob_mag": 7.438383301692222, "train/policy_logprob_max": -0.009455721999115464, "train/policy_logprob_mean": -0.6204625872978523, "train/policy_logprob_min": -7.438383301692222, "train/policy_logprob_std": 1.1482859351741734, "train/policy_randomness_mag": 0.9020960330963135, "train/policy_randomness_max": 0.9020960330963135, "train/policy_randomness_mean": 0.2193907909651301, "train/policy_randomness_min": 0.028015939671713026, "train/policy_randomness_std": 0.22411653065859383, "train/post_ent_mag": 56.69045007050927, "train/post_ent_max": 56.69045007050927, "train/post_ent_mean": 39.77329832048559, "train/post_ent_min": 19.782510458533444, "train/post_ent_std": 7.384782004712233, "train/prior_ent_mag": 65.624739291063, "train/prior_ent_max": 65.624739291063, "train/prior_ent_mean": 54.29186089359113, "train/prior_ent_min": 39.99981048925599, "train/prior_ent_std": 3.982510822922436, "train/rep_loss_mean": 14.482788754932916, "train/rep_loss_std": 8.798086209083671, "train/reward_avg": 0.023777839206437123, "train/reward_loss_mean": 0.05487081958954014, "train/reward_loss_std": 0.25490691790829845, "train/reward_max_data": 1.008208957181048, "train/reward_max_pred": 1.005069899025248, "train/reward_neg_acc": 0.993072000012469, "train/reward_neg_loss": 0.030911548709524655, "train/reward_pos_acc": 0.9654288549921406, "train/reward_pos_loss": 0.8709639097327617, "train/reward_pred": 0.022998517500792643, "train/reward_rate": 0.028502506996268658, "train_stats/sum_log_reward": 5.599999937194365, "train_stats/max_log_achievement_collect_coal": 0.046296296296296294, "train_stats/max_log_achievement_collect_drink": 5.287037037037037, "train_stats/max_log_achievement_collect_sapling": 2.8796296296296298, "train_stats/max_log_achievement_collect_stone": 0.23148148148148148, "train_stats/max_log_achievement_collect_wood": 5.4907407407407405, "train_stats/max_log_achievement_defeat_skeleton": 0.009259259259259259, "train_stats/max_log_achievement_defeat_zombie": 0.6574074074074074, "train_stats/max_log_achievement_eat_cow": 0.09259259259259259, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3148148148148148, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.7777777777777777, "train_stats/max_log_achievement_place_stone": 0.027777777777777776, "train_stats/max_log_achievement_place_table": 1.9537037037037037, "train_stats/max_log_achievement_wake_up": 1.9259259259259258, "train_stats/mean_log_entropy": 0.5534834918324594, "eval_stats/sum_log_reward": 5.058333287636439, "eval_stats/max_log_achievement_collect_coal": 0.08333333333333333, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 1.5416666666666667, "eval_stats/max_log_achievement_collect_stone": 0.08333333333333333, "eval_stats/max_log_achievement_collect_wood": 5.541666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.20833333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5416666666666667, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00013547964044846594, "report/cont_loss_std": 0.004066449124366045, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04348471388220787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.106749191938434e-06, "report/cont_pred": 0.99718177318573, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 15.149261474609375, "report/dyn_loss_std": 9.011886596679688, "report/image_loss_mean": 9.189897537231445, "report/image_loss_std": 16.168895721435547, "report/model_loss_mean": 18.314071655273438, "report/model_loss_std": 19.677820205688477, "report/post_ent_mag": 53.00457000732422, "report/post_ent_max": 53.00457000732422, "report/post_ent_mean": 39.22288131713867, "report/post_ent_min": 20.892314910888672, "report/post_ent_std": 7.225849151611328, "report/prior_ent_mag": 65.46402740478516, "report/prior_ent_max": 65.46402740478516, "report/prior_ent_mean": 54.44097900390625, "report/prior_ent_min": 39.19093322753906, "report/prior_ent_std": 3.9535982608795166, "report/rep_loss_mean": 15.149261474609375, "report/rep_loss_std": 9.011886596679688, "report/reward_avg": 0.02197265625, "report/reward_loss_mean": 0.03448287770152092, "report/reward_loss_std": 0.1659802496433258, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005900859832764, "report/reward_neg_acc": 0.9959959983825684, "report/reward_neg_loss": 0.016783472150564194, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7417510747909546, "report/reward_pred": 0.022662952542304993, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 2.0963394490536302e-05, "eval/cont_loss_std": 0.00034744208096526563, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0030373476911336184, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.016531226445295e-07, "eval/cont_pred": 0.9931845664978027, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.890724182128906, "eval/dyn_loss_std": 8.775826454162598, "eval/image_loss_mean": 12.655354499816895, "eval/image_loss_std": 13.705204010009766, "eval/model_loss_mean": 24.076765060424805, "eval/model_loss_std": 16.960615158081055, "eval/post_ent_mag": 52.20920944213867, "eval/post_ent_max": 52.20920944213867, "eval/post_ent_mean": 37.48509216308594, "eval/post_ent_min": 21.69558334350586, "eval/post_ent_std": 6.370659351348877, "eval/prior_ent_mag": 65.46402740478516, "eval/prior_ent_max": 65.46402740478516, "eval/prior_ent_mean": 54.44720458984375, "eval/prior_ent_min": 42.0662841796875, "eval/prior_ent_std": 3.800879955291748, "eval/rep_loss_mean": 18.890724182128906, "eval/rep_loss_std": 8.775826454162598, "eval/reward_avg": 0.03115234524011612, "eval/reward_loss_mean": 0.08695444464683533, "eval/reward_loss_std": 0.4223886728286743, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0031158924102783, "eval/reward_neg_acc": 0.9908722043037415, "eval/reward_neg_loss": 0.04925336688756943, "eval/reward_pos_acc": 0.9473684430122375, "eval/reward_pos_loss": 1.0651981830596924, "eval/reward_pred": 0.02861972525715828, "eval/reward_rate": 0.037109375, "replay/size": 459921.0, "replay/inserts": 21440.0, "replay/samples": 21440.0, "replay/insert_wait_avg": 1.3887215016493157e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.617495842834017e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 92600.0, "eval_replay/inserts": 5920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2057053076254354e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2074301242828, "timer/env.step_count": 2680.0, "timer/env.step_total": 243.41202092170715, "timer/env.step_frac": 0.24336154040713484, "timer/env.step_avg": 0.09082538094093551, "timer/env.step_min": 0.022542953491210938, "timer/env.step_max": 3.42983078956604, "timer/replay._sample_count": 21440.0, "timer/replay._sample_total": 11.016159296035767, "timer/replay._sample_frac": 0.011013874686640682, "timer/replay._sample_avg": 0.0005138134000016682, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.025206565856933594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3420.0, "timer/agent.policy_total": 56.23378300666809, "timer/agent.policy_frac": 0.05622212084515374, "timer/agent.policy_avg": 0.01644262661013687, "timer/agent.policy_min": 0.009105682373046875, "timer/agent.policy_max": 0.11433982849121094, "timer/dataset_train_count": 1340.0, "timer/dataset_train_total": 0.1481468677520752, "timer/dataset_train_frac": 0.0001481161440019166, "timer/dataset_train_avg": 0.00011055736399408596, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0010750293731689453, "timer/agent.train_count": 1340.0, "timer/agent.train_total": 598.1295456886292, "timer/agent.train_frac": 0.5980055013331658, "timer/agent.train_avg": 0.44636533260345457, "timer/agent.train_min": 0.4326915740966797, "timer/agent.train_max": 1.5402636528015137, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47428202629089355, "timer/agent.report_frac": 0.00047418366631405714, "timer/agent.report_avg": 0.23714101314544678, "timer/agent.report_min": 0.23213481903076172, "timer/agent.report_max": 0.24214720726013184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8842665233654996e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.435276005540388}
{"step": 460720, "time": 21415.498779773712, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 460936, "time": 21423.94969344139, "episode/length": 82.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 460968, "time": 21426.615522146225, "episode/length": 204.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 461048, "time": 21431.175889015198, "episode/length": 212.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 461352, "time": 21442.874430418015, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 461456, "time": 21448.03252863884, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 461528, "time": 21451.72980427742, "episode/length": 236.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 461960, "time": 21467.62951874733, "episode/length": 417.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 462160, "time": 21475.99925136566, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 462384, "time": 21485.07125234604, "episode/length": 207.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 462440, "time": 21488.150678157806, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 462608, "time": 21495.48356962204, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 462720, "time": 21500.99617934227, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 462784, "time": 21504.68395137787, "episode/length": 42.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 463136, "time": 21517.951259851456, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 463224, "time": 21522.320912599564, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 463424, "time": 21530.799379348755, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 463712, "time": 21541.886073589325, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 463872, "time": 21548.76064682007, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 464024, "time": 21555.09532904625, "episode/length": 204.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 464192, "time": 21562.389414072037, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 464408, "time": 21570.853635072708, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 464448, "time": 21574.043068170547, "episode/length": 127.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 464656, "time": 21582.44920897484, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 464712, "time": 21585.61463212967, "episode/length": 185.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 465224, "time": 21604.094408512115, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 465496, "time": 21614.73322701454, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 465704, "time": 21623.27037668228, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 465720, "time": 21625.2919549942, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 465760, "time": 21628.415509223938, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 466080, "time": 21640.66869521141, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 466128, "time": 21643.930987596512, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 466176, "time": 21647.10272049904, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 466216, "time": 21649.82377886772, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 466592, "time": 21663.92143559456, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 466920, "time": 21676.169544935226, "episode/length": 40.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 467224, "time": 21689.31760263443, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 467328, "time": 21694.625669956207, "episode/length": 50.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 467600, "time": 21705.22190642357, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 467720, "time": 21710.749017715454, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 467856, "time": 21716.946084737778, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 468224, "time": 21730.5851893425, "episode/length": 255.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 468520, "time": 21741.643020153046, "episode/length": 377.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 468760, "time": 21751.165521860123, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 468768, "time": 21753.19657444954, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 469088, "time": 21765.376254081726, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 469384, "time": 21776.422951221466, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 469432, "time": 21779.548909425735, "episode/length": 262.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 469608, "time": 21786.896322011948, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 469712, "time": 21792.149418354034, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21824.53792476654, "eval_episode/length": 142.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 470080, "time": 21826.329278707504, "eval_episode/length": 149.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 470080, "time": 21828.924776792526, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 470080, "time": 21830.767760276794, "eval_episode/length": 176.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 470080, "time": 21832.406539916992, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 470080, "time": 21834.45333838463, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 470080, "time": 21836.514654636383, "eval_episode/length": 205.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 470080, "time": 21841.567415952682, "eval_episode/length": 290.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 470128, "time": 21843.158510923386, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 470296, "time": 21850.105095624924, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 470720, "time": 21865.952340364456, "episode/length": 52.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 470904, "time": 21873.543417692184, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 471048, "time": 21879.89900779724, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 471184, "time": 21886.08497285843, "episode/length": 302.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 471264, "time": 21890.377266168594, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 471552, "time": 21901.59088730812, "episode/length": 62.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 471632, "time": 21905.86997628212, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 472216, "time": 21926.650375127792, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 472240, "time": 21929.063275575638, "episode/length": 433.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9907834101382489, "episode/intrinsic_return": 0.0}
{"step": 472536, "time": 21940.154291391373, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 472616, "time": 21944.418018102646, "episode/length": 310.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 472696, "time": 21948.689625501633, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 472976, "time": 21959.788658857346, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 473056, "time": 21964.04923248291, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 473888, "time": 21993.386716365814, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 473912, "time": 21995.52072739601, "episode/length": 211.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 474296, "time": 22009.79035305977, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 474808, "time": 22028.440679073334, "episode/length": 320.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781931464174455, "episode/intrinsic_return": 0.0}
{"step": 474968, "time": 22035.361570835114, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 475336, "time": 22050.79763197899, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 475448, "time": 22056.07572412491, "episode/length": 476.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 475520, "time": 22060.353538513184, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 476048, "time": 22079.60046362877, "episode/length": 438.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 476160, "time": 22084.904460191727, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 476296, "time": 22090.792680501938, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 476480, "time": 22098.673833608627, "episode/length": 320.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 476552, "time": 22102.309937238693, "episode/length": 48.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 476656, "time": 22107.503712177277, "episode/length": 294.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 477000, "time": 22120.100695848465, "episode/length": 207.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 477016, "time": 22122.215854406357, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 477136, "time": 22127.988128900528, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 477632, "time": 22146.111255645752, "episode/length": 197.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 477912, "time": 22156.71420764923, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 477968, "time": 22160.2923514843, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 478000, "time": 22162.940696954727, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 478208, "time": 22171.422535657883, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 478496, "time": 22183.039090633392, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 478504, "time": 22184.813162326813, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 478512, "time": 22186.797214269638, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 479192, "time": 22210.43729376793, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 479288, "time": 22215.24897456169, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 479352, "time": 22218.986118793488, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 479504, "time": 22225.808290481567, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 479600, "time": 22230.547832250595, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22266.54580640793, "eval_episode/length": 154.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 480064, "time": 22268.527224063873, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 480064, "time": 22270.821538448334, "eval_episode/length": 179.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 480064, "time": 22273.272714614868, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 480064, "time": 22275.743985652924, "eval_episode/length": 224.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 480064, "time": 22277.85266971588, "eval_episode/length": 239.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 480064, "time": 22280.61158299446, "eval_episode/length": 88.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9887640449438202}
{"step": 480064, "time": 22284.282649040222, "eval_episode/length": 318.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.987460815047022}
{"step": 480072, "time": 22284.334000587463, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 480304, "time": 22293.703976869583, "episode/length": 225.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 480400, "time": 22298.48215699196, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 480584, "time": 22305.90176320076, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 480680, "time": 22311.267954587936, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 481120, "time": 22327.554004192352, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 481120, "time": 22327.581779003143, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 481632, "time": 22347.907419919968, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 481768, "time": 22353.80324459076, "episode/length": 282.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 481912, "time": 22360.1804087162, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 481928, "time": 22362.34125995636, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 482088, "time": 22369.261476755142, "episode/length": 175.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 482184, "time": 22373.931996822357, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 482656, "time": 22391.375461816788, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 482984, "time": 22403.71711587906, "episode/length": 232.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 482985, "time": 22406.261677980423, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.634089043799867, "train/action_min": 0.0, "train/action_std": 3.1923431200338594, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05268616723359054, "train/actor_opt_grad_steps": 29390.0, "train/actor_opt_loss": -4.995529985662999, "train/adv_mag": 0.7737170787567788, "train/adv_max": 0.7633026111210491, "train/adv_mean": 0.003829691166884133, "train/adv_min": -0.5150174092739186, "train/adv_std": 0.07777324223772009, "train/cont_avg": 0.9945284796099291, "train/cont_loss_mean": 0.0002066262438858809, "train/cont_loss_std": 0.006166461324264045, "train/cont_neg_acc": 0.9965541860182509, "train/cont_neg_loss": 0.008848629718989896, "train/cont_pos_acc": 0.9999303242838975, "train/cont_pos_loss": 0.000147030404471835, "train/cont_pred": 0.9944846317277732, "train/cont_rate": 0.9945284796099291, "train/dyn_loss_mean": 14.281450927680266, "train/dyn_loss_std": 8.701363817174384, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.806064951081648, "train/extr_critic_critic_opt_grad_steps": 29390.0, "train/extr_critic_critic_opt_loss": 15864.989465591756, "train/extr_critic_mag": 5.132209202921983, "train/extr_critic_max": 5.132209202921983, "train/extr_critic_mean": 0.8384318022017784, "train/extr_critic_min": -0.22996750114657355, "train/extr_critic_std": 1.081700952763253, "train/extr_return_normed_mag": 1.8675752506188468, "train/extr_return_normed_max": 1.8675752506188468, "train/extr_return_normed_mean": 0.2829078826921206, "train/extr_return_normed_min": -0.13914759372565763, "train/extr_return_normed_std": 0.3378464749730225, "train/extr_return_rate": 0.4087396782974825, "train/extr_return_raw_mag": 6.094630281975928, "train/extr_return_raw_max": 6.094630281975928, "train/extr_return_raw_mean": 0.8511077605240734, "train/extr_return_raw_min": -0.5456383553802544, "train/extr_return_raw_std": 1.1180635851325718, "train/extr_reward_mag": 1.014443465158449, "train/extr_reward_max": 1.014443465158449, "train/extr_reward_mean": 0.026555638951876907, "train/extr_reward_min": -0.3656294455764987, "train/extr_reward_std": 0.1517901173825805, "train/image_loss_mean": 7.517611266873407, "train/image_loss_std": 11.940231955643242, "train/model_loss_mean": 16.141822077703814, "train/model_loss_std": 15.37445219865082, "train/model_opt_grad_norm": 64.6722349072179, "train/model_opt_grad_steps": 29361.078014184397, "train/model_opt_loss": 12982.464906083776, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 806.7375886524823, "train/policy_entropy_mag": 2.5716944941392184, "train/policy_entropy_max": 2.5716944941392184, "train/policy_entropy_mean": 0.6413273557703546, "train/policy_entropy_min": 0.07937513482063374, "train/policy_entropy_std": 0.6688647874703644, "train/policy_logprob_mag": 7.438383389872016, "train/policy_logprob_max": -0.009455709572855039, "train/policy_logprob_mean": -0.6417585556388746, "train/policy_logprob_min": -7.438383389872016, "train/policy_logprob_std": 1.1624854059084087, "train/policy_randomness_mag": 0.9076952989219774, "train/policy_randomness_max": 0.9076952989219774, "train/policy_randomness_mean": 0.22636041362234888, "train/policy_randomness_min": 0.028015939426337573, "train/policy_randomness_std": 0.23607991773186002, "train/post_ent_mag": 56.492284707143796, "train/post_ent_max": 56.492284707143796, "train/post_ent_mean": 40.008096897855715, "train/post_ent_min": 19.95878515175894, "train/post_ent_std": 7.3258739802854285, "train/prior_ent_mag": 65.64327364441351, "train/prior_ent_max": 65.64327364441351, "train/prior_ent_mean": 54.339645493960546, "train/prior_ent_min": 40.1163461563435, "train/prior_ent_std": 3.9547676194644144, "train/rep_loss_mean": 14.281450927680266, "train/rep_loss_std": 8.701363817174384, "train/reward_avg": 0.02365289756645125, "train/reward_loss_mean": 0.05513384803495509, "train/reward_loss_std": 0.2518888647463305, "train/reward_max_data": 1.0170212806539332, "train/reward_max_pred": 1.0088983672730467, "train/reward_neg_acc": 0.9928910985906073, "train/reward_neg_loss": 0.031010872030511817, "train/reward_pos_acc": 0.9613427401434446, "train/reward_pos_loss": 0.8828099353093628, "train/reward_pred": 0.02275432036291306, "train/reward_rate": 0.028625055407801418, "train_stats/sum_log_reward": 5.514414387444655, "train_stats/max_log_achievement_collect_coal": 0.018018018018018018, "train_stats/max_log_achievement_collect_drink": 5.702702702702703, "train_stats/max_log_achievement_collect_sapling": 2.945945945945946, "train_stats/max_log_achievement_collect_stone": 0.2882882882882883, "train_stats/max_log_achievement_collect_wood": 5.927927927927928, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5585585585585585, "train_stats/max_log_achievement_eat_cow": 0.08108108108108109, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2882882882882883, "train_stats/max_log_achievement_make_wood_sword": 0.009009009009009009, "train_stats/max_log_achievement_place_plant": 2.855855855855856, "train_stats/max_log_achievement_place_stone": 0.02702702702702703, "train_stats/max_log_achievement_place_table": 2.2972972972972974, "train_stats/max_log_achievement_wake_up": 1.927927927927928, "train_stats/mean_log_entropy": 0.5897196916578052, "eval_stats/sum_log_reward": 5.974999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 3.375, "eval_stats/max_log_achievement_collect_stone": 0.25, "eval_stats/max_log_achievement_collect_wood": 5.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 2.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0017365326639264822, "report/cont_loss_std": 0.05120867118239403, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00025300384731963277, "report/cont_pos_acc": 0.999020516872406, "report/cont_pos_loss": 0.0017408918356522918, "report/cont_pred": 0.9961541295051575, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.24211311340332, "report/dyn_loss_std": 8.419581413269043, "report/image_loss_mean": 7.077147483825684, "report/image_loss_std": 8.88359546661377, "report/model_loss_mean": 15.664182662963867, "report/model_loss_std": 12.502066612243652, "report/post_ent_mag": 58.27909851074219, "report/post_ent_max": 58.27909851074219, "report/post_ent_mean": 39.612213134765625, "report/post_ent_min": 16.434078216552734, "report/post_ent_std": 7.147097110748291, "report/prior_ent_mag": 65.56742858886719, "report/prior_ent_max": 65.56742858886719, "report/prior_ent_mean": 53.99654769897461, "report/prior_ent_min": 38.08748245239258, "report/prior_ent_std": 3.954684257507324, "report/rep_loss_mean": 14.24211311340332, "report/rep_loss_std": 8.419581413269043, "report/reward_avg": 0.01591796800494194, "report/reward_loss_mean": 0.04003055393695831, "report/reward_loss_std": 0.17551997303962708, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003655195236206, "report/reward_neg_acc": 0.9940239191055298, "report/reward_neg_loss": 0.026106402277946472, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7390230894088745, "report/reward_pred": 0.017004922032356262, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.001244677696377039, "eval/cont_loss_std": 0.03977986425161362, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.42477402091026306, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.231375617611775e-07, "eval/cont_pred": 0.9977741241455078, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.94159698486328, "eval/dyn_loss_std": 10.042948722839355, "eval/image_loss_mean": 15.592540740966797, "eval/image_loss_std": 20.700597763061523, "eval/model_loss_mean": 27.03778839111328, "eval/model_loss_std": 24.630165100097656, "eval/post_ent_mag": 50.715126037597656, "eval/post_ent_max": 50.715126037597656, "eval/post_ent_mean": 36.955841064453125, "eval/post_ent_min": 21.004220962524414, "eval/post_ent_std": 6.5254034996032715, "eval/prior_ent_mag": 65.56742858886719, "eval/prior_ent_max": 65.56742858886719, "eval/prior_ent_mean": 53.746604919433594, "eval/prior_ent_min": 41.118080139160156, "eval/prior_ent_std": 3.3724355697631836, "eval/rep_loss_mean": 18.94159698486328, "eval/rep_loss_std": 10.042948722839355, "eval/reward_avg": 0.03837890550494194, "eval/reward_loss_mean": 0.0790453553199768, "eval/reward_loss_std": 0.4778333604335785, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005137920379639, "eval/reward_neg_acc": 0.9898167252540588, "eval/reward_neg_loss": 0.024631425738334656, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.3512948751449585, "eval/reward_pred": 0.03720156103372574, "eval/reward_rate": 0.041015625, "replay/size": 482481.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.3591232874714737e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.268384838780613e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97480.0, "eval_replay/inserts": 4880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.152128469748575e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.606427192688, "timer/env.step_count": 2820.0, "timer/env.step_total": 249.67511081695557, "timer/env.step_frac": 0.2495237928037767, "timer/env.step_avg": 0.08853727333934594, "timer/env.step_min": 0.021856069564819336, "timer/env.step_max": 3.4270639419555664, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.21186637878418, "timer/replay._sample_frac": 0.011205071318840427, "timer/replay._sample_avg": 0.0004969798926766037, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.011080265045166016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3430.0, "timer/agent.policy_total": 54.98380994796753, "timer/agent.policy_frac": 0.0549504864787154, "timer/agent.policy_avg": 0.016030265290952632, "timer/agent.policy_min": 0.00918126106262207, "timer/agent.policy_max": 0.10522913932800293, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.15472984313964844, "timer/dataset_train_frac": 0.00015463606762327134, "timer/dataset_train_avg": 0.00010973747740400599, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.00033736228942871094, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 627.9302930831909, "timer/agent.train_frac": 0.6275497298622384, "timer/agent.train_avg": 0.445340633392334, "timer/agent.train_min": 0.434070348739624, "timer/agent.train_max": 1.5940065383911133, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772491455078125, "timer/agent.report_frac": 0.0004769599040521734, "timer/agent.report_avg": 0.23862457275390625, "timer/agent.report_min": 0.23247575759887695, "timer/agent.report_max": 0.24477338790893555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4080276489257812e-05, "timer/dataset_eval_frac": 2.4065682405036805e-08, "timer/dataset_eval_avg": 2.4080276489257812e-05, "timer/dataset_eval_min": 2.4080276489257812e-05, "timer/dataset_eval_max": 2.4080276489257812e-05, "fps": 22.546061007698167}
{"step": 483088, "time": 22409.717099905014, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 483232, "time": 22416.028840780258, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 483520, "time": 22428.8755235672, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 483728, "time": 22437.315907001495, "episode/length": 226.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 483768, "time": 22439.964269161224, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 484400, "time": 22462.81957244873, "episode/length": 276.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 484448, "time": 22466.086913108826, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 484544, "time": 22470.77041196823, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 484640, "time": 22475.60573363304, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 484776, "time": 22481.43062567711, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 485320, "time": 22500.98934674263, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 485400, "time": 22505.197171211243, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 485976, "time": 22525.940165758133, "episode/length": 306.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 486272, "time": 22537.63135910034, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 486296, "time": 22539.786962270737, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 486400, "time": 22545.190296649933, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 486432, "time": 22547.865602970123, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 486960, "time": 22567.20282292366, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 487120, "time": 22574.120332479477, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 487696, "time": 22594.978847503662, "episode/length": 393.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 487752, "time": 22598.216697454453, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 487808, "time": 22601.87010550499, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 488112, "time": 22613.832842350006, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 488144, "time": 22616.61137199402, "episode/length": 55.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 488168, "time": 22618.826771259308, "episode/length": 130.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 488768, "time": 22640.806292533875, "episode/length": 225.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 489064, "time": 22651.910754919052, "episode/length": 467.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9978632478632479, "episode/intrinsic_return": 0.0}
{"step": 489072, "time": 22653.985003709793, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 489208, "time": 22659.786544799805, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 489448, "time": 22669.31352686882, "episode/length": 376.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9920424403183024, "episode/intrinsic_return": 0.0}
{"step": 489648, "time": 22677.811442136765, "episode/length": 184.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 489888, "time": 22687.46502971649, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 489896, "time": 22689.15374302864, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 489976, "time": 22693.345675468445, "episode/length": 65.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22713.232271194458, "eval_episode/length": 45.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 490048, "time": 22721.00225877762, "eval_episode/length": 170.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 490048, "time": 22722.828712701797, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 490048, "time": 22724.778523921967, "eval_episode/length": 184.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9837837837837838}
{"step": 490048, "time": 22726.470107793808, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 490048, "time": 22729.384803533554, "eval_episode/length": 169.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 490048, "time": 22731.356330633163, "eval_episode/length": 224.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 490048, "time": 22733.247993946075, "eval_episode/length": 231.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 490584, "time": 22750.928449869156, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 490880, "time": 22762.523326158524, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 490920, "time": 22765.16278910637, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 491144, "time": 22774.128436088562, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 491232, "time": 22778.98228621483, "episode/length": 156.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 491240, "time": 22780.579810380936, "episode/length": 253.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 491544, "time": 22793.959513902664, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 491904, "time": 22807.803037405014, "episode/length": 250.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 492128, "time": 22816.712399482727, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 492216, "time": 22821.045716047287, "episode/length": 290.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 492312, "time": 22825.79655265808, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 492664, "time": 22838.982175588608, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 493096, "time": 22855.053273439407, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 493104, "time": 22857.144285678864, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 493392, "time": 22868.16919541359, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 493416, "time": 22870.44468188286, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 493760, "time": 22883.697084903717, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 494048, "time": 22894.964348316193, "episode/length": 118.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 494128, "time": 22899.200778245926, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 494224, "time": 22904.054285287857, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 494296, "time": 22907.79930639267, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 494744, "time": 22924.38822746277, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 494784, "time": 22927.48505115509, "episode/length": 209.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 494856, "time": 22931.21353340149, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 495256, "time": 22946.1608979702, "episode/length": 186.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 495520, "time": 22956.76654291153, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 495920, "time": 22971.857308149338, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 495944, "time": 22973.97047352791, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 496064, "time": 22979.671812295914, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 496488, "time": 22995.094267368317, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 496640, "time": 23002.031059503555, "episode/length": 231.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 496664, "time": 23004.638295650482, "episode/length": 175.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 497096, "time": 23020.984497070312, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 497152, "time": 23024.648048877716, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 497400, "time": 23034.065051317215, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 497752, "time": 23047.219463586807, "episode/length": 157.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 497888, "time": 23053.550478458405, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 497992, "time": 23058.261476039886, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 498064, "time": 23062.502784252167, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 498088, "time": 23064.542798280716, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 498152, "time": 23068.165214538574, "episode/length": 425.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 498864, "time": 23093.465348482132, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 499320, "time": 23109.944353103638, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 499336, "time": 23111.917981863022, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 499464, "time": 23117.648491621017, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 499656, "time": 23125.620006084442, "episode/length": 98.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 499784, "time": 23132.76629137993, "episode/length": 328.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817629179331308, "episode/intrinsic_return": 0.0}
{"step": 499920, "time": 23139.106300115585, "episode/length": 56.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 500008, "time": 23143.326504468918, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23164.74019598961, "eval_episode/length": 42.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 500032, "time": 23170.1077272892, "eval_episode/length": 115.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9482758620689655}
{"step": 500032, "time": 23175.697359085083, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 500032, "time": 23177.327471017838, "eval_episode/length": 198.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 500032, "time": 23177.335720539093, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 500032, "time": 23182.52938103676, "eval_episode/length": 243.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 500032, "time": 23184.805300712585, "eval_episode/length": 218.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 500032, "time": 23187.67074251175, "eval_episode/length": 293.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9965986394557823}
{"step": 500456, "time": 23201.47816514969, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 500592, "time": 23207.86373233795, "episode/length": 436.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 500712, "time": 23213.421264886856, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 501016, "time": 23224.992745399475, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 501272, "time": 23235.019119024277, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 501328, "time": 23238.922504663467, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 501336, "time": 23240.980725049973, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 501872, "time": 23261.256213903427, "episode/length": 243.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 502008, "time": 23266.97688651085, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 502336, "time": 23279.85291147232, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 502376, "time": 23282.482610702515, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 502648, "time": 23293.00595974922, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 503088, "time": 23309.348960399628, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 503224, "time": 23315.2314081192, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 503344, "time": 23321.05405306816, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 503616, "time": 23331.753589630127, "episode/length": 324.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9815384615384616, "episode/intrinsic_return": 0.0}
{"step": 503624, "time": 23333.43171095848, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 503760, "time": 23339.71879839897, "episode/length": 310.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 504160, "time": 23354.429258584976, "episode/length": 101.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 504432, "time": 23366.41398191452, "episode/length": 150.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 504520, "time": 23370.60483264923, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 504656, "time": 23376.860218048096, "episode/length": 111.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 504904, "time": 23386.487021446228, "episode/length": 47.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 504928, "time": 23389.195372104645, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 504952, "time": 23391.319620370865, "episode/length": 452.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 504952, "time": 23391.3266415596, "episode/length": 36.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 505160, "time": 23401.452454805374, "episode/length": 124.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.952, "episode/intrinsic_return": 0.0}
{"step": 505233, "time": 23406.301354169846, "train_stats/sum_log_reward": 5.490909080071883, "train_stats/max_log_achievement_collect_coal": 0.07272727272727272, "train_stats/max_log_achievement_collect_drink": 4.7727272727272725, "train_stats/max_log_achievement_collect_sapling": 2.581818181818182, "train_stats/max_log_achievement_collect_stone": 0.43636363636363634, "train_stats/max_log_achievement_collect_wood": 5.927272727272728, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6818181818181818, "train_stats/max_log_achievement_eat_cow": 0.06363636363636363, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.34545454545454546, "train_stats/max_log_achievement_make_wood_sword": 0.00909090909090909, "train_stats/max_log_achievement_place_plant": 2.4909090909090907, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.172727272727273, "train_stats/max_log_achievement_wake_up": 2.118181818181818, "train_stats/mean_log_entropy": 0.6077221886678176, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.66473256941322, "train/action_min": 0.0, "train/action_std": 3.3141301158520817, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051701917574345634, "train/actor_opt_grad_steps": 30790.0, "train/actor_opt_loss": -4.655206892130186, "train/adv_mag": 0.7499942127749216, "train/adv_max": 0.7439423057672788, "train/adv_mean": 0.0038498014524887257, "train/adv_min": -0.5046246654266934, "train/adv_std": 0.07651495944252974, "train/cont_avg": 0.9947659060251799, "train/cont_loss_mean": 0.00017878524720479964, "train/cont_loss_std": 0.005218040518323067, "train/cont_neg_acc": 0.9939962325336265, "train/cont_neg_loss": 0.016814724931425037, "train/cont_pos_acc": 0.9999787974700654, "train/cont_pos_loss": 8.083855162137483e-05, "train/cont_pred": 0.9947676242684289, "train/cont_rate": 0.9947659060251799, "train/dyn_loss_mean": 13.990196488744063, "train/dyn_loss_std": 8.710538617140955, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7850556592289493, "train/extr_critic_critic_opt_grad_steps": 30790.0, "train/extr_critic_critic_opt_loss": 15694.871213185701, "train/extr_critic_mag": 5.175262626126516, "train/extr_critic_max": 5.175262626126516, "train/extr_critic_mean": 0.8426048985059312, "train/extr_critic_min": -0.23224454389201651, "train/extr_critic_std": 1.0609872980083492, "train/extr_return_normed_mag": 1.8640910833001993, "train/extr_return_normed_max": 1.8640910833001993, "train/extr_return_normed_mean": 0.2834103298273018, "train/extr_return_normed_min": -0.1397219810286443, "train/extr_return_normed_std": 0.33099976342787846, "train/extr_return_rate": 0.420106906470635, "train/extr_return_raw_mag": 6.094977965457834, "train/extr_return_raw_max": 6.094977965457834, "train/extr_return_raw_mean": 0.8553414061772737, "train/extr_return_raw_min": -0.5468860947185283, "train/extr_return_raw_std": 1.0972590172033516, "train/extr_reward_mag": 1.0137602613984251, "train/extr_reward_max": 1.0137602613984251, "train/extr_reward_mean": 0.025981068430240634, "train/extr_reward_min": -0.37234751869448657, "train/extr_reward_std": 0.1509482975271966, "train/image_loss_mean": 7.193307478650868, "train/image_loss_std": 11.45813420179079, "train/model_loss_mean": 15.64030977976408, "train/model_loss_std": 14.897364040072873, "train/model_opt_grad_norm": 61.00527078642262, "train/model_opt_grad_steps": 30760.510791366905, "train/model_opt_loss": 19695.262611004946, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9928057553957, "train/policy_entropy_mag": 2.5574219398361318, "train/policy_entropy_max": 2.5574219398361318, "train/policy_entropy_mean": 0.6705219252504033, "train/policy_entropy_min": 0.07937513222154095, "train/policy_entropy_std": 0.6950764544576192, "train/policy_logprob_mag": 7.438383342550813, "train/policy_logprob_max": -0.009455746059848679, "train/policy_logprob_mean": -0.6706842668622518, "train/policy_logprob_min": -7.438383342550813, "train/policy_logprob_std": 1.1752644803026597, "train/policy_randomness_mag": 0.90265771810957, "train/policy_randomness_max": 0.90265771810957, "train/policy_randomness_mean": 0.2366648147003256, "train/policy_randomness_min": 0.028015938393182033, "train/policy_randomness_std": 0.24533148506562485, "train/post_ent_mag": 56.91561434080275, "train/post_ent_max": 56.91561434080275, "train/post_ent_mean": 40.223483600204794, "train/post_ent_min": 19.418183168918965, "train/post_ent_std": 7.422123833525952, "train/prior_ent_mag": 65.77579651976662, "train/prior_ent_max": 65.77579651976662, "train/prior_ent_mean": 54.2865869261378, "train/prior_ent_min": 40.46788304829769, "train/prior_ent_std": 3.930328684745075, "train/rep_loss_mean": 13.990196488744063, "train/rep_loss_std": 8.710538617140955, "train/reward_avg": 0.02357379681424057, "train/reward_loss_mean": 0.052705694472403836, "train/reward_loss_std": 0.23902380745187937, "train/reward_max_data": 1.0165467665349837, "train/reward_max_pred": 1.0079470632745207, "train/reward_neg_acc": 0.9932402595341634, "train/reward_neg_loss": 0.029363141395151615, "train/reward_pos_acc": 0.9677468851315889, "train/reward_pos_loss": 0.8557371329918182, "train/reward_pred": 0.022838246623362354, "train/reward_rate": 0.028306261241007193, "eval_stats/sum_log_reward": 5.599999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_sapling": 2.6875, "eval_stats/max_log_achievement_collect_stone": 0.4375, "eval_stats/max_log_achievement_collect_wood": 4.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.53390668251086e-06, "report/cont_loss_std": 0.0001137324288720265, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010650209151208401, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.8527092480508145e-06, "report/cont_pred": 0.9931580424308777, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.073575973510742, "report/dyn_loss_std": 9.651416778564453, "report/image_loss_mean": 8.392786026000977, "report/image_loss_std": 13.759918212890625, "report/model_loss_mean": 16.897541046142578, "report/model_loss_std": 17.86554527282715, "report/post_ent_mag": 56.772911071777344, "report/post_ent_max": 56.772911071777344, "report/post_ent_mean": 40.29478454589844, "report/post_ent_min": 18.38703155517578, "report/post_ent_std": 7.556647777557373, "report/prior_ent_mag": 65.03148651123047, "report/prior_ent_max": 65.03148651123047, "report/prior_ent_mean": 54.357452392578125, "report/prior_ent_min": 39.9892463684082, "report/prior_ent_std": 3.412700891494751, "report/rep_loss_mean": 14.073575973510742, "report/rep_loss_std": 9.651416778564453, "report/reward_avg": 0.01845703087747097, "report/reward_loss_mean": 0.06060238182544708, "report/reward_loss_std": 0.2701399326324463, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00229811668396, "report/reward_neg_acc": 0.987000048160553, "report/reward_neg_loss": 0.038650646805763245, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.9752580523490906, "report/reward_pred": 0.01860230043530464, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.992862507904647e-06, "eval/cont_loss_std": 4.382326369523071e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.554868817445822e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9271953988209134e-06, "eval/cont_pred": 0.9980450868606567, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.328956604003906, "eval/dyn_loss_std": 9.897231101989746, "eval/image_loss_mean": 14.7435302734375, "eval/image_loss_std": 17.925827026367188, "eval/model_loss_mean": 25.81287384033203, "eval/model_loss_std": 21.782148361206055, "eval/post_ent_mag": 57.73145294189453, "eval/post_ent_max": 57.73145294189453, "eval/post_ent_mean": 38.66645812988281, "eval/post_ent_min": 18.959062576293945, "eval/post_ent_std": 7.141108512878418, "eval/prior_ent_mag": 65.03148651123047, "eval/prior_ent_max": 65.03148651123047, "eval/prior_ent_mean": 54.93353271484375, "eval/prior_ent_min": 41.40121078491211, "eval/prior_ent_std": 3.375553846359253, "eval/rep_loss_mean": 18.328956604003906, "eval/rep_loss_std": 9.897231101989746, "eval/reward_avg": 0.02138671837747097, "eval/reward_loss_mean": 0.071966752409935, "eval/reward_loss_std": 0.44280359148979187, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020148754119873, "eval/reward_neg_acc": 0.9879759550094604, "eval/reward_neg_loss": 0.03133115544915199, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.6317484378814697, "eval/reward_pred": 0.016255540773272514, "eval/reward_rate": 0.025390625, "replay/size": 504729.0, "replay/inserts": 22248.0, "replay/samples": 22240.0, "replay/insert_wait_avg": 1.3834235909087158e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.244537202574367e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.229940711772034e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.029402256012, "timer/env.step_count": 2781.0, "timer/env.step_total": 248.3222267627716, "timer/env.step_frac": 0.2483149257437533, "timer/env.step_avg": 0.08929242242458527, "timer/env.step_min": 0.02276778221130371, "timer/env.step_max": 3.292748212814331, "timer/replay._sample_count": 22240.0, "timer/replay._sample_total": 10.927345991134644, "timer/replay._sample_frac": 0.010927024711956614, "timer/replay._sample_avg": 0.0004913374996013778, "timer/replay._sample_min": 0.00040030479431152344, "timer/replay._sample_max": 0.025198698043823242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3307.0, "timer/agent.policy_total": 54.1277072429657, "timer/agent.policy_frac": 0.05412611581305163, "timer/agent.policy_avg": 0.01636761634199144, "timer/agent.policy_min": 0.009396076202392578, "timer/agent.policy_max": 0.11913895606994629, "timer/dataset_train_count": 1390.0, "timer/dataset_train_total": 0.15474295616149902, "timer/dataset_train_frac": 0.00015473840650325613, "timer/dataset_train_avg": 0.00011132586774208563, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010836124420166016, "timer/agent.train_count": 1390.0, "timer/agent.train_total": 624.0574123859406, "timer/agent.train_frac": 0.6240390642296126, "timer/agent.train_avg": 0.4489621671841299, "timer/agent.train_min": 0.4335906505584717, "timer/agent.train_max": 1.9162309169769287, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47739386558532715, "timer/agent.report_frac": 0.00047737982954136404, "timer/agent.report_avg": 0.23869693279266357, "timer/agent.report_min": 0.23006677627563477, "timer/agent.report_max": 0.24732708930969238, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075509243500012e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.24708178298097}
{"step": 505568, "time": 23417.706157922745, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 506040, "time": 23434.86070394516, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 506120, "time": 23439.193811893463, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 506296, "time": 23446.612273931503, "episode/length": 333.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 506312, "time": 23448.728217601776, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 506448, "time": 23455.0382604599, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 506736, "time": 23466.72994494438, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 506760, "time": 23468.851280212402, "episode/length": 231.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 507096, "time": 23481.56838965416, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 507232, "time": 23487.824632644653, "episode/length": 148.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 507536, "time": 23499.464111566544, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 507744, "time": 23507.91248369217, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 507792, "time": 23511.139691591263, "episode/length": 186.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 507808, "time": 23513.30344104767, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 508280, "time": 23531.863657951355, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 508472, "time": 23540.030030965805, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 508496, "time": 23542.630328655243, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 509112, "time": 23564.484890699387, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 509248, "time": 23570.861085891724, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 509312, "time": 23574.621857643127, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 509584, "time": 23585.235647678375, "episode/length": 293.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 509856, "time": 23595.856529712677, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 509872, "time": 23597.91526913643, "episode/length": 259.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 23624.102165937424, "eval_episode/length": 159.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.99375}
{"step": 510016, "time": 23626.30438017845, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 510016, "time": 23629.10839033127, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 510016, "time": 23631.00380897522, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 510016, "time": 23633.438883304596, "eval_episode/length": 218.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9680365296803652}
{"step": 510016, "time": 23635.761157035828, "eval_episode/length": 75.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9342105263157895}
{"step": 510016, "time": 23640.528348207474, "eval_episode/length": 138.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 510016, "time": 23642.25905418396, "eval_episode/length": 311.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9839743589743589}
{"step": 510056, "time": 23643.395950317383, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 510256, "time": 23651.834057331085, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 510464, "time": 23660.300501346588, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 510568, "time": 23665.09231877327, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 510744, "time": 23672.56785964966, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 510832, "time": 23677.18906235695, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 510992, "time": 23684.21063518524, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 511576, "time": 23704.93504023552, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 511648, "time": 23709.129312753677, "episode/length": 221.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 511784, "time": 23714.94371366501, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 511880, "time": 23719.80598473549, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 512256, "time": 23734.494025945663, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 512344, "time": 23738.91677880287, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 512728, "time": 23753.706137657166, "episode/length": 236.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 512936, "time": 23762.24658846855, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 513480, "time": 23781.970826387405, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 513736, "time": 23792.07697534561, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 513864, "time": 23797.893183469772, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 513992, "time": 23803.698917627335, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 514200, "time": 23812.385001897812, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 514424, "time": 23821.519466876984, "episode/length": 270.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 514440, "time": 23823.63125061989, "episode/length": 461.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 514520, "time": 23827.79765176773, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 514680, "time": 23834.61352610588, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 515168, "time": 23852.750326156616, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 515520, "time": 23865.961752414703, "episode/length": 206.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 515760, "time": 23875.621218681335, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 515800, "time": 23878.2304315567, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 515936, "time": 23884.462071180344, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 516064, "time": 23890.23736190796, "episode/length": 290.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 516088, "time": 23892.387806892395, "episode/length": 207.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 516472, "time": 23908.30321907997, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 516656, "time": 23916.363969802856, "episode/length": 246.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 517184, "time": 23935.368931770325, "episode/length": 172.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 517184, "time": 23935.377747535706, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 517416, "time": 23946.210458517075, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 517696, "time": 23957.232576847076, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 517984, "time": 23968.421527147293, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 518120, "time": 23974.18564081192, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 518160, "time": 23977.27781033516, "episode/length": 261.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 518280, "time": 23982.592869758606, "episode/length": 273.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 518864, "time": 24003.72622036934, "episode/length": 209.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 519128, "time": 24013.763340234756, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 519384, "time": 24024.07173061371, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 519408, "time": 24026.61093735695, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 519472, "time": 24030.288059473038, "episode/length": 285.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 519560, "time": 24034.600917816162, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 519608, "time": 24037.789692401886, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 519736, "time": 24043.69663500786, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24069.32856822014, "eval_episode/length": 55.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 520000, "time": 24072.108486652374, "eval_episode/length": 85.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9418604651162791}
{"step": 520000, "time": 24078.312881231308, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 520000, "time": 24080.404592514038, "eval_episode/length": 207.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 520000, "time": 24082.464116811752, "eval_episode/length": 217.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 520000, "time": 24084.133350610733, "eval_episode/length": 220.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 520000, "time": 24087.833716392517, "eval_episode/length": 30.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8387096774193549}
{"step": 520000, "time": 24092.40482711792, "eval_episode/length": 296.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.98989898989899}
{"step": 520448, "time": 24107.30565595627, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 520648, "time": 24115.36613726616, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 521016, "time": 24129.349638223648, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 521120, "time": 24134.64712357521, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 521184, "time": 24138.34092926979, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 521280, "time": 24143.162005662918, "episode/length": 214.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 521336, "time": 24146.554658174515, "episode/length": 232.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 521568, "time": 24156.550023794174, "episode/length": 47.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 521816, "time": 24166.184061288834, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 521904, "time": 24171.544426441193, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 522280, "time": 24185.416321516037, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 522640, "time": 24199.238307714462, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 522688, "time": 24202.46777200699, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 522728, "time": 24205.242510795593, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 522800, "time": 24209.413739204407, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 522864, "time": 24213.012308835983, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 523192, "time": 24225.087560653687, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 523384, "time": 24233.06936454773, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 524000, "time": 24255.353466510773, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 524176, "time": 24262.957654953003, "episode/length": 191.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 524208, "time": 24265.547091960907, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 524360, "time": 24273.39813542366, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 524392, "time": 24276.123157262802, "episode/length": 263.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 524408, "time": 24278.25261068344, "episode/length": 200.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 524616, "time": 24286.79852247238, "episode/length": 240.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 524616, "time": 24286.813675165176, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 524856, "time": 24298.29003047943, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 525792, "time": 24331.272773981094, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 525856, "time": 24335.051904439926, "episode/length": 205.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 525896, "time": 24337.718350172043, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 525952, "time": 24341.38426041603, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 526296, "time": 24354.864795207977, "episode/length": 237.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 526400, "time": 24360.25621318817, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 526424, "time": 24362.391471624374, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 526440, "time": 24364.45223045349, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 527024, "time": 24385.607494354248, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 527544, "time": 24404.25932908058, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 527545, "time": 24406.791721343994, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.707630184914568, "train/action_min": 0.0, "train/action_std": 3.394330993830729, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.052787495576006045, "train/actor_opt_grad_steps": 32180.0, "train/actor_opt_loss": -2.722640956993208, "train/adv_mag": 0.7394344973907196, "train/adv_max": 0.7323475921754357, "train/adv_mean": 0.00456892158577542, "train/adv_min": -0.5019912340229363, "train/adv_std": 0.07758018342282275, "train/cont_avg": 0.9949345211330936, "train/cont_loss_mean": 0.00022058602740157324, "train/cont_loss_std": 0.006408629921284634, "train/cont_neg_acc": 0.9880664840988491, "train/cont_neg_loss": 0.020558038523895317, "train/cont_pos_acc": 0.9999505422955794, "train/cont_pos_loss": 0.00010938634049341872, "train/cont_pred": 0.9949314495642408, "train/cont_rate": 0.9949345211330936, "train/dyn_loss_mean": 13.94100570678711, "train/dyn_loss_std": 8.701448718420894, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8201575708046234, "train/extr_critic_critic_opt_grad_steps": 32180.0, "train/extr_critic_critic_opt_loss": 15852.559092569694, "train/extr_critic_mag": 5.220378748804546, "train/extr_critic_max": 5.220378748804546, "train/extr_critic_mean": 0.8427136572573682, "train/extr_critic_min": -0.23287422536946029, "train/extr_critic_std": 1.0666470051669388, "train/extr_return_normed_mag": 1.8682315572560262, "train/extr_return_normed_max": 1.8682315572560262, "train/extr_return_normed_mean": 0.2856180082551009, "train/extr_return_normed_min": -0.14145629729727188, "train/extr_return_normed_std": 0.3306977307196144, "train/extr_return_rate": 0.4214029015182591, "train/extr_return_raw_mag": 6.160018001528953, "train/extr_return_raw_max": 6.160018001528953, "train/extr_return_raw_mean": 0.8580070963437608, "train/extr_return_raw_min": -0.5727605425196586, "train/extr_return_raw_std": 1.1079421000514957, "train/extr_reward_mag": 1.0159873181967427, "train/extr_reward_max": 1.0159873181967427, "train/extr_reward_mean": 0.02686447805637936, "train/extr_reward_min": -0.3857126518976774, "train/extr_reward_std": 0.1531672198459399, "train/image_loss_mean": 7.119283487470888, "train/image_loss_std": 11.998885964318145, "train/model_loss_mean": 15.53739386496784, "train/model_loss_std": 15.440214740286628, "train/model_opt_grad_norm": 58.48556091802583, "train/model_opt_grad_steps": 32149.251798561152, "train/model_opt_loss": 20407.254931991905, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1312.9496402877699, "train/policy_entropy_mag": 2.533584718223956, "train/policy_entropy_max": 2.533584718223956, "train/policy_entropy_mean": 0.6590419265863706, "train/policy_entropy_min": 0.07937513768887348, "train/policy_entropy_std": 0.6773807245621578, "train/policy_logprob_mag": 7.438383479770139, "train/policy_logprob_max": -0.009455730743277416, "train/policy_logprob_mean": -0.6582207244505985, "train/policy_logprob_min": -7.438383479770139, "train/policy_logprob_std": 1.172418086648845, "train/policy_randomness_mag": 0.8942442219034373, "train/policy_randomness_max": 0.8942442219034373, "train/policy_randomness_mean": 0.23261287926341132, "train/policy_randomness_min": 0.02801594038983043, "train/policy_randomness_std": 0.23908566914016394, "train/post_ent_mag": 56.94525651451495, "train/post_ent_max": 56.94525651451495, "train/post_ent_mean": 40.331966619697404, "train/post_ent_min": 19.681730695765655, "train/post_ent_std": 7.427660904342322, "train/prior_ent_mag": 65.79617616941603, "train/prior_ent_max": 65.79617616941603, "train/prior_ent_mean": 54.32263147916725, "train/prior_ent_min": 40.95876389098682, "train/prior_ent_std": 3.8758313381414617, "train/rep_loss_mean": 13.94100570678711, "train/rep_loss_std": 8.701448718420894, "train/reward_avg": 0.02379861729313358, "train/reward_loss_mean": 0.0532863333338885, "train/reward_loss_std": 0.2459470222322203, "train/reward_max_data": 1.018705040430851, "train/reward_max_pred": 1.0103560866211816, "train/reward_neg_acc": 0.9928890205115724, "train/reward_neg_loss": 0.02936587721216593, "train/reward_pos_acc": 0.9637776480304251, "train/reward_pos_loss": 0.8731539922652485, "train/reward_pred": 0.02299214494850138, "train/reward_rate": 0.028432722571942445, "train_stats/sum_log_reward": 5.751376086418782, "train_stats/max_log_achievement_collect_coal": 0.01834862385321101, "train_stats/max_log_achievement_collect_drink": 4.908256880733945, "train_stats/max_log_achievement_collect_sapling": 3.110091743119266, "train_stats/max_log_achievement_collect_stone": 0.23853211009174313, "train_stats/max_log_achievement_collect_wood": 6.477064220183486, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.7614678899082569, "train_stats/max_log_achievement_eat_cow": 0.06422018348623854, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.21100917431192662, "train_stats/max_log_achievement_make_wood_sword": 0.03669724770642202, "train_stats/max_log_achievement_place_plant": 2.963302752293578, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.3211009174311927, "train_stats/max_log_achievement_wake_up": 1.963302752293578, "train_stats/mean_log_entropy": 0.6046009189491972, "eval_stats/sum_log_reward": 5.162499874830246, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.8125, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.162912642234005e-05, "report/cont_loss_std": 0.0004732270317617804, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0029076109640300274, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.61940953755402e-06, "report/cont_pred": 0.9941530227661133, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.235919952392578, "report/dyn_loss_std": 8.601263999938965, "report/image_loss_mean": 7.246334075927734, "report/image_loss_std": 11.336424827575684, "report/model_loss_mean": 15.836945533752441, "report/model_loss_std": 14.741825103759766, "report/post_ent_mag": 56.54670715332031, "report/post_ent_max": 56.54670715332031, "report/post_ent_mean": 40.0631103515625, "report/post_ent_min": 20.189804077148438, "report/post_ent_std": 7.486606597900391, "report/prior_ent_mag": 65.89653015136719, "report/prior_ent_max": 65.89653015136719, "report/prior_ent_mean": 54.569053649902344, "report/prior_ent_min": 41.832210540771484, "report/prior_ent_std": 3.460428476333618, "report/rep_loss_mean": 14.235919952392578, "report/rep_loss_std": 8.601263999938965, "report/reward_avg": 0.02841796725988388, "report/reward_loss_mean": 0.04903770983219147, "report/reward_loss_std": 0.1919296234846115, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001142978668213, "report/reward_neg_acc": 0.9888888001441956, "report/reward_neg_loss": 0.024119924753904343, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.7745851278305054, "report/reward_pred": 0.027178604155778885, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.4828176063019782e-05, "eval/cont_loss_std": 0.00040723267011344433, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00038143436540849507, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.302932378166588e-05, "eval/cont_pred": 0.9951062202453613, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.87497329711914, "eval/dyn_loss_std": 9.425716400146484, "eval/image_loss_mean": 8.7025785446167, "eval/image_loss_std": 11.987776756286621, "eval/model_loss_mean": 18.32022476196289, "eval/model_loss_std": 15.489888191223145, "eval/post_ent_mag": 53.94096755981445, "eval/post_ent_max": 53.94096755981445, "eval/post_ent_mean": 39.3753547668457, "eval/post_ent_min": 21.61740493774414, "eval/post_ent_std": 7.174506664276123, "eval/prior_ent_mag": 65.89653015136719, "eval/prior_ent_max": 65.89653015136719, "eval/prior_ent_mean": 54.06550598144531, "eval/prior_ent_min": 41.14965057373047, "eval/prior_ent_std": 3.554624557495117, "eval/rep_loss_mean": 15.87497329711914, "eval/rep_loss_std": 9.425716400146484, "eval/reward_avg": 0.03447265923023224, "eval/reward_loss_mean": 0.09264471381902695, "eval/reward_loss_std": 0.5367484092712402, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002331018447876, "eval/reward_neg_acc": 0.9928862452507019, "eval/reward_neg_loss": 0.037634577602148056, "eval/reward_pos_acc": 0.9000000357627869, "eval/reward_pos_loss": 1.4458942413330078, "eval/reward_pred": 0.03038616105914116, "eval/reward_rate": 0.0390625, "replay/size": 527041.0, "replay/inserts": 22312.0, "replay/samples": 22320.0, "replay/insert_wait_avg": 1.3775533140667369e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.393860047863375e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1498117681794565e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4791197776794, "timer/env.step_count": 2789.0, "timer/env.step_total": 245.97676730155945, "timer/env.step_frac": 0.24585897140583898, "timer/env.step_avg": 0.08819532710704893, "timer/env.step_min": 0.02274179458618164, "timer/env.step_max": 3.526092290878296, "timer/replay._sample_count": 22320.0, "timer/replay._sample_total": 11.052045106887817, "timer/replay._sample_frac": 0.011046752389338957, "timer/replay._sample_avg": 0.0004951633112404936, "timer/replay._sample_min": 0.0004100799560546875, "timer/replay._sample_max": 0.02794790267944336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3398.0, "timer/agent.policy_total": 55.986642599105835, "timer/agent.policy_frac": 0.05595983113725238, "timer/agent.policy_avg": 0.01647635155947788, "timer/agent.policy_min": 0.009058952331542969, "timer/agent.policy_max": 0.12846064567565918, "timer/dataset_train_count": 1395.0, "timer/dataset_train_total": 0.15209412574768066, "timer/dataset_train_frac": 0.0001520212893413289, "timer/dataset_train_avg": 0.00010902804713095388, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0009093284606933594, "timer/agent.train_count": 1395.0, "timer/agent.train_total": 628.2789447307587, "timer/agent.train_frac": 0.6279780680184222, "timer/agent.train_avg": 0.4503791718500062, "timer/agent.train_min": 0.43375229835510254, "timer/agent.train_max": 1.575927734375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754352569580078, "timer/agent.report_frac": 0.00047520757561002997, "timer/agent.report_avg": 0.2377176284790039, "timer/agent.report_min": 0.23134231567382812, "timer/agent.report_max": 0.2440929412841797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00013136863708496094, "timer/dataset_eval_frac": 1.3130572591475263e-07, "timer/dataset_eval_avg": 0.00013136863708496094, "timer/dataset_eval_min": 0.00013136863708496094, "timer/dataset_eval_max": 0.00013136863708496094, "fps": 22.301040540175403}
{"step": 527624, "time": 24409.321497917175, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 527648, "time": 24411.988965511322, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 527688, "time": 24414.712340593338, "episode/length": 173.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 527720, "time": 24417.382321357727, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 528064, "time": 24430.79047727585, "episode/length": 207.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 528344, "time": 24441.63258743286, "episode/length": 239.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 528488, "time": 24448.131779432297, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 528504, "time": 24450.163635730743, "episode/length": 106.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 528720, "time": 24459.290647745132, "episode/length": 128.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 528744, "time": 24461.441737413406, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 529592, "time": 24491.26572918892, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 529624, "time": 24493.921942710876, "episode/length": 237.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 530032, "time": 24509.310331344604, "episode/length": 300.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 530048, "time": 24511.46585869789, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24533.263193130493, "eval_episode/length": 146.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 530088, "time": 24534.932063817978, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 530088, "time": 24537.06027150154, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 530088, "time": 24538.994129657745, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 530088, "time": 24541.004094839096, "eval_episode/length": 182.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 530088, "time": 24542.77964925766, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 530088, "time": 24544.844236135483, "eval_episode/length": 197.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 530088, "time": 24551.642882347107, "eval_episode/length": 179.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 530128, "time": 24553.198107004166, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 530272, "time": 24559.683946847916, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 530392, "time": 24564.936561584473, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 530552, "time": 24571.835646152496, "episode/length": 34.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 530888, "time": 24584.594977855682, "episode/length": 317.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 531128, "time": 24594.263526916504, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 531144, "time": 24596.45632171631, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 531248, "time": 24601.666785240173, "episode/length": 139.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 531832, "time": 24622.416011571884, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 531888, "time": 24626.116527318954, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 532080, "time": 24634.142943143845, "episode/length": 190.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.0}
{"step": 532400, "time": 24646.312841415405, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 532536, "time": 24653.73701119423, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 532640, "time": 24659.003528118134, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 532704, "time": 24662.74072122574, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 532720, "time": 24664.776440382004, "episode/length": 333.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9910179640718563, "episode/intrinsic_return": 0.0}
{"step": 533440, "time": 24690.439025878906, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 533640, "time": 24698.50879716873, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 533872, "time": 24708.048124313354, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 533960, "time": 24712.49092888832, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 534096, "time": 24718.847898244858, "episode/length": 275.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 534384, "time": 24730.145444869995, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 534680, "time": 24741.390594005585, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 534696, "time": 24743.402867794037, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 534808, "time": 24748.64394426346, "episode/length": 52.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 534880, "time": 24752.791410923004, "episode/length": 292.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 535120, "time": 24762.400897979736, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 535696, "time": 24783.20830965042, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 536360, "time": 24806.762088775635, "episode/length": 184.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 536464, "time": 24812.496606111526, "episode/length": 206.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 536512, "time": 24815.670822381973, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 536592, "time": 24820.041926383972, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 536816, "time": 24829.16413998604, "episode/length": 266.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 537056, "time": 24838.65047955513, "episode/length": 426.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 537168, "time": 24844.51755452156, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 537440, "time": 24855.157550096512, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 537536, "time": 24859.9777905941, "episode/length": 429.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 537872, "time": 24872.81093454361, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 537920, "time": 24876.039623498917, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 538224, "time": 24887.77872633934, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 538480, "time": 24897.807737350464, "episode/length": 207.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 538568, "time": 24902.445702314377, "episode/length": 256.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 539024, "time": 24919.48958659172, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 539136, "time": 24924.8176445961, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 539368, "time": 24933.978494405746, "episode/length": 180.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 539424, "time": 24937.717334508896, "episode/length": 235.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 539592, "time": 24944.640441656113, "episode/length": 214.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 539912, "time": 24957.009360790253, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 539968, "time": 24960.737488031387, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 24984.82293987274, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 540072, "time": 24986.765655755997, "eval_episode/length": 158.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 540072, "time": 24988.585208892822, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9567901234567902}
{"step": 540072, "time": 24990.71356678009, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 540072, "time": 24992.740521669388, "eval_episode/length": 185.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 540072, "time": 24994.39264678955, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 540072, "time": 24996.303853034973, "eval_episode/length": 25.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.8846153846153846}
{"step": 540072, "time": 24998.34908771515, "eval_episode/length": 212.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 540424, "time": 25010.053878068924, "episode/length": 231.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 540472, "time": 25013.265172481537, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 540976, "time": 25033.163496017456, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 541264, "time": 25044.542623758316, "episode/length": 279.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 541352, "time": 25048.81199336052, "episode/length": 240.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 541552, "time": 25057.407678604126, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 541552, "time": 25057.41742873192, "episode/length": 244.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 541632, "time": 25063.402015924454, "episode/length": 45.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 542344, "time": 25088.61728477478, "episode/length": 239.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 542400, "time": 25092.255499124527, "episode/length": 310.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 542632, "time": 25101.37183690071, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 542688, "time": 25105.046625375748, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 542744, "time": 25108.164155721664, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 542928, "time": 25116.061868190765, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 543280, "time": 25129.302470207214, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 543752, "time": 25146.549033880234, "episode/length": 264.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 544120, "time": 25161.116396427155, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 544496, "time": 25175.463918447495, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 544560, "time": 25179.188619852066, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 544568, "time": 25180.851620435715, "episode/length": 227.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 544864, "time": 25192.569836616516, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 544936, "time": 25196.325895786285, "episode/length": 422.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 544952, "time": 25198.308942079544, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 545288, "time": 25211.092066049576, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 545712, "time": 25227.014476776123, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 546096, "time": 25241.421061515808, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 546352, "time": 25251.63658452034, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 546400, "time": 25254.873429059982, "episode/length": 180.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 546608, "time": 25263.361026763916, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 546624, "time": 25265.487548828125, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 546760, "time": 25271.40021634102, "episode/length": 329.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 546768, "time": 25273.38947701454, "episode/length": 228.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 547800, "time": 25309.31818795204, "episode/length": 212.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 547856, "time": 25312.98070192337, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 547880, "time": 25315.256723165512, "episode/length": 190.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 547944, "time": 25318.903528690338, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 547992, "time": 25322.028353214264, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 548016, "time": 25324.590023756027, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 548256, "time": 25334.03609085083, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 549168, "time": 25367.576018333435, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 549280, "time": 25372.956624746323, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 549352, "time": 25376.84040403366, "episode/length": 186.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 549424, "time": 25381.035942792892, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 549632, "time": 25389.498391866684, "episode/length": 204.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 549664, "time": 25392.262634515762, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 549688, "time": 25394.416472434998, "episode/length": 384.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 549816, "time": 25400.307232618332, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 549945, "time": 25407.091423034668, "train_stats/sum_log_reward": 5.763636330989274, "train_stats/max_log_achievement_collect_coal": 0.05454545454545454, "train_stats/max_log_achievement_collect_drink": 5.6909090909090905, "train_stats/max_log_achievement_collect_sapling": 3.1, "train_stats/max_log_achievement_collect_stone": 0.2545454545454545, "train_stats/max_log_achievement_collect_wood": 5.845454545454546, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6727272727272727, "train_stats/max_log_achievement_eat_cow": 0.06363636363636363, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.03636363636363636, "train_stats/max_log_achievement_place_plant": 2.9, "train_stats/max_log_achievement_place_stone": 0.00909090909090909, "train_stats/max_log_achievement_place_table": 2.1363636363636362, "train_stats/max_log_achievement_wake_up": 2.0272727272727273, "train_stats/mean_log_entropy": 0.6366656643423168, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.042837960379464, "train/action_min": 0.0, "train/action_std": 3.677700115953173, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05166368620204074, "train/actor_opt_grad_steps": 33575.0, "train/actor_opt_loss": -6.34734893994672, "train/adv_mag": 0.7684233001300267, "train/adv_max": 0.7462844735809735, "train/adv_mean": 0.003733991257312092, "train/adv_min": -0.5085056045225689, "train/adv_std": 0.07656830219285829, "train/cont_avg": 0.9948521205357143, "train/cont_loss_mean": 0.0001541866545612233, "train/cont_loss_std": 0.004741146470291012, "train/cont_neg_acc": 0.9957348412747006, "train/cont_neg_loss": 0.021528367791492357, "train/cont_pos_acc": 0.9999789650951113, "train/cont_pos_loss": 3.905024181766034e-05, "train/cont_pred": 0.9948669595377786, "train/cont_rate": 0.9948521205357143, "train/dyn_loss_mean": 13.858696596963066, "train/dyn_loss_std": 8.71558074951172, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7968426167964935, "train/extr_critic_critic_opt_grad_steps": 33575.0, "train/extr_critic_critic_opt_loss": 15890.312527901786, "train/extr_critic_mag": 5.290957059179034, "train/extr_critic_max": 5.290957059179034, "train/extr_critic_mean": 0.8366675061838967, "train/extr_critic_min": -0.2285184153488704, "train/extr_critic_std": 1.0889425000974111, "train/extr_return_normed_mag": 1.890865981578827, "train/extr_return_normed_max": 1.890865981578827, "train/extr_return_normed_mean": 0.28474094346165657, "train/extr_return_normed_min": -0.13797904375408376, "train/extr_return_normed_std": 0.33514759082879336, "train/extr_return_rate": 0.40833754103098596, "train/extr_return_raw_mag": 6.240081637246268, "train/extr_return_raw_max": 6.240081637246268, "train/extr_return_raw_mean": 0.8492003660116877, "train/extr_return_raw_min": -0.5697675909314837, "train/extr_return_raw_std": 1.124968655194555, "train/extr_reward_mag": 1.017343773160662, "train/extr_reward_max": 1.017343773160662, "train/extr_reward_mean": 0.026753465132787823, "train/extr_reward_min": -0.40741464751107354, "train/extr_reward_std": 0.15304438152483532, "train/image_loss_mean": 7.090581849643162, "train/image_loss_std": 11.731763529777528, "train/model_loss_mean": 15.45942863055638, "train/model_loss_std": 15.141865505490983, "train/model_opt_grad_norm": 60.35270367080359, "train/model_opt_grad_steps": 33542.135714285716, "train/model_opt_loss": 12437.013141741072, "train/model_opt_model_opt_grad_overflow": 0.007142857142857143, "train/model_opt_model_opt_grad_scale": 799.1071428571429, "train/policy_entropy_mag": 2.486178813661848, "train/policy_entropy_max": 2.486178813661848, "train/policy_entropy_mean": 0.680462874685015, "train/policy_entropy_min": 0.07937512312616621, "train/policy_entropy_std": 0.7061396253960474, "train/policy_logprob_mag": 7.438383517946516, "train/policy_logprob_max": -0.009455712478873985, "train/policy_logprob_mean": -0.680646556190082, "train/policy_logprob_min": -7.438383517946516, "train/policy_logprob_std": 1.1792986895356858, "train/policy_randomness_mag": 0.8775120147636959, "train/policy_randomness_max": 0.8775120147636959, "train/policy_randomness_mean": 0.24017353409102984, "train/policy_randomness_min": 0.02801593518150704, "train/policy_randomness_std": 0.24923630080052783, "train/post_ent_mag": 57.212439618791855, "train/post_ent_max": 57.212439618791855, "train/post_ent_mean": 40.47824657985142, "train/post_ent_min": 19.62046401160104, "train/post_ent_std": 7.475436193602426, "train/prior_ent_mag": 65.90333420889718, "train/prior_ent_max": 65.90333420889718, "train/prior_ent_mean": 54.367923981802804, "train/prior_ent_min": 41.01970315660749, "train/prior_ent_std": 3.9328355584825787, "train/rep_loss_mean": 13.858696596963066, "train/rep_loss_std": 8.71558074951172, "train/reward_avg": 0.023657923876973134, "train/reward_loss_mean": 0.05347458914454494, "train/reward_loss_std": 0.24898020029067994, "train/reward_max_data": 1.0128571459225246, "train/reward_max_pred": 1.0064925917557308, "train/reward_neg_acc": 0.9926970311573573, "train/reward_neg_loss": 0.030220041051506996, "train/reward_pos_acc": 0.9675091415643692, "train/reward_pos_loss": 0.8546604224613734, "train/reward_pred": 0.022986661968752743, "train/reward_rate": 0.028334263392857145, "eval_stats/sum_log_reward": 5.412500001955777, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 5.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.496841443644371e-05, "report/cont_loss_std": 0.0007737901178188622, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9601659005274996e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5000044843181968e-05, "report/cont_pred": 0.9941161870956421, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.101370811462402, "report/dyn_loss_std": 8.808908462524414, "report/image_loss_mean": 6.820943832397461, "report/image_loss_std": 12.611151695251465, "report/model_loss_mean": 15.357166290283203, "report/model_loss_std": 15.927732467651367, "report/post_ent_mag": 57.03727722167969, "report/post_ent_max": 57.03727722167969, "report/post_ent_mean": 40.509979248046875, "report/post_ent_min": 21.873455047607422, "report/post_ent_std": 7.466361045837402, "report/prior_ent_mag": 66.40326690673828, "report/prior_ent_max": 66.40326690673828, "report/prior_ent_mean": 54.652862548828125, "report/prior_ent_min": 38.947021484375, "report/prior_ent_std": 4.049445629119873, "report/rep_loss_mean": 14.101370811462402, "report/rep_loss_std": 8.808908462524414, "report/reward_avg": 0.02499999850988388, "report/reward_loss_mean": 0.07537534087896347, "report/reward_loss_std": 0.3784564435482025, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9997186660766602, "report/reward_neg_acc": 0.9909456372261047, "report/reward_neg_loss": 0.048748552799224854, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 0.9576095938682556, "report/reward_pred": 0.024286020547151566, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.3155366761784535e-06, "eval/cont_loss_std": 4.883249494014308e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003612727450672537, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.542158874050074e-07, "eval/cont_pred": 0.9951184391975403, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.454666137695312, "eval/dyn_loss_std": 9.483633041381836, "eval/image_loss_mean": 11.680249214172363, "eval/image_loss_std": 13.362396240234375, "eval/model_loss_mean": 21.6396484375, "eval/model_loss_std": 16.985891342163086, "eval/post_ent_mag": 59.31791687011719, "eval/post_ent_max": 59.31791687011719, "eval/post_ent_mean": 40.196678161621094, "eval/post_ent_min": 21.248363494873047, "eval/post_ent_std": 7.346409797668457, "eval/prior_ent_mag": 66.40326690673828, "eval/prior_ent_max": 66.40326690673828, "eval/prior_ent_mean": 54.83641815185547, "eval/prior_ent_min": 37.449981689453125, "eval/prior_ent_std": 3.768547296524048, "eval/rep_loss_mean": 16.454666137695312, "eval/rep_loss_std": 9.483633041381836, "eval/reward_avg": 0.01982421800494194, "eval/reward_loss_mean": 0.08659837394952774, "eval/reward_loss_std": 0.47217613458633423, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999182224273682, "eval/reward_neg_acc": 0.9859578609466553, "eval/reward_neg_loss": 0.049803778529167175, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.4452729225158691, "eval/reward_pred": 0.019398534670472145, "eval/reward_rate": 0.0263671875, "replay/size": 549441.0, "replay/inserts": 22400.0, "replay/samples": 22400.0, "replay/insert_wait_avg": 1.3705555881772722e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.466546126774379e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1596414777967665e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2839879989624, "timer/env.step_count": 2800.0, "timer/env.step_total": 248.60417675971985, "timer/env.step_frac": 0.24853359620105978, "timer/env.step_avg": 0.08878720598561424, "timer/env.step_min": 0.02255845069885254, "timer/env.step_max": 3.3498096466064453, "timer/replay._sample_count": 22400.0, "timer/replay._sample_total": 11.103460550308228, "timer/replay._sample_frac": 0.01110030819599578, "timer/replay._sample_avg": 0.0004956902031387602, "timer/replay._sample_min": 0.0003991127014160156, "timer/replay._sample_max": 0.010837316513061523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3340.0, "timer/agent.policy_total": 53.81601428985596, "timer/agent.policy_frac": 0.05380073552663105, "timer/agent.policy_avg": 0.01611257912869939, "timer/agent.policy_min": 0.009374618530273438, "timer/agent.policy_max": 0.11954712867736816, "timer/dataset_train_count": 1400.0, "timer/dataset_train_total": 0.15352559089660645, "timer/dataset_train_frac": 0.0001534820038494565, "timer/dataset_train_avg": 0.00010966113635471889, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.001077413558959961, "timer/agent.train_count": 1400.0, "timer/agent.train_total": 631.1249208450317, "timer/agent.train_frac": 0.6309457398269245, "timer/agent.train_avg": 0.45080351488930837, "timer/agent.train_min": 0.43892860412597656, "timer/agent.train_max": 1.6262500286102295, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770064353942871, "timer/agent.report_frac": 0.0004768710097504649, "timer/agent.report_avg": 0.23850321769714355, "timer/agent.report_min": 0.23239517211914062, "timer/agent.report_max": 0.24461126327514648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741035238555486e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 22.39335511202836}
{"step": 550056, "time": 25430.56111931801, "eval_episode/length": 168.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 550056, "time": 25432.310053110123, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 550056, "time": 25433.981570243835, "eval_episode/length": 178.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 550056, "time": 25435.542682886124, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 550056, "time": 25438.4164955616, "eval_episode/length": 209.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 550056, "time": 25440.13222885132, "eval_episode/length": 215.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 550056, "time": 25442.987371206284, "eval_episode/length": 37.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 550056, "time": 25447.103842020035, "eval_episode/length": 310.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9903536977491961}
{"step": 550080, "time": 25448.12101125717, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 550728, "time": 25471.112038373947, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 550912, "time": 25479.060824394226, "episode/length": 194.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 551160, "time": 25489.020354747772, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 551176, "time": 25491.553956270218, "episode/length": 188.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 551216, "time": 25495.239278316498, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 551360, "time": 25502.041101932526, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 551472, "time": 25507.258323907852, "episode/length": 38.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 551552, "time": 25511.42553639412, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 551896, "time": 25524.270339250565, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 552304, "time": 25539.701792240143, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 552712, "time": 25554.7782394886, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 552952, "time": 25564.45091366768, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 553256, "time": 25576.38952445984, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 553408, "time": 25583.441152334213, "episode/length": 273.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 553576, "time": 25590.37064266205, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 553648, "time": 25594.598294973373, "episode/length": 271.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 553832, "time": 25602.348215341568, "episode/length": 308.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 553888, "time": 25606.464470386505, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 554056, "time": 25614.215149879456, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 554616, "time": 25634.464350938797, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 554792, "time": 25641.91388630867, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 554824, "time": 25644.577080965042, "episode/length": 233.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 554936, "time": 25649.89627957344, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 555040, "time": 25655.162687540054, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 555272, "time": 25664.208156585693, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 555624, "time": 25677.64793419838, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 555704, "time": 25681.91517806053, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 555832, "time": 25688.21470284462, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 555912, "time": 25692.493914604187, "episode/length": 161.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 556304, "time": 25707.372156620026, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 556416, "time": 25712.661353826523, "episode/length": 198.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 556888, "time": 25729.770567417145, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 556944, "time": 25733.451251983643, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 557232, "time": 25746.11349797249, "episode/length": 42.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 557432, "time": 25754.17277431488, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 557440, "time": 25756.211044311523, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 557528, "time": 25760.585485696793, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 557672, "time": 25766.899408578873, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 557976, "time": 25778.532697677612, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 558560, "time": 25799.776837587357, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 558712, "time": 25806.183006048203, "episode/length": 349.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 558920, "time": 25814.6724050045, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 559136, "time": 25823.743101596832, "episode/length": 211.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 559832, "time": 25848.313102960587, "episode/length": 299.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 25877.231077432632, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 560040, "time": 25879.517644882202, "eval_episode/length": 170.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 560040, "time": 25882.277074813843, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 560040, "time": 25884.404294252396, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 560040, "time": 25886.136165380478, "eval_episode/length": 214.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 560040, "time": 25888.515585899353, "eval_episode/length": 233.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 560040, "time": 25890.745465278625, "eval_episode/length": 249.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.996}
{"step": 560040, "time": 25894.134798526764, "eval_episode/length": 293.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9863945578231292}
{"step": 560336, "time": 25904.170169830322, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 560376, "time": 25906.753924369812, "episode/length": 337.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 560376, "time": 25906.763516664505, "episode/length": 299.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 560416, "time": 25911.602279663086, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 560576, "time": 25918.582116365433, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 560704, "time": 25924.417016744614, "episode/length": 433.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9907834101382489, "episode/intrinsic_return": 0.0}
{"step": 561440, "time": 25950.479997634888, "episode/length": 132.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 561704, "time": 25960.83853507042, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 561784, "time": 25965.044016361237, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 561872, "time": 25969.906516075134, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 561880, "time": 25971.49357318878, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 562040, "time": 25978.283408641815, "episode/length": 389.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.982051282051282, "episode/intrinsic_return": 0.0}
{"step": 562592, "time": 25998.436275720596, "episode/length": 281.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 562816, "time": 26007.500977516174, "episode/length": 263.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 562944, "time": 26013.328609466553, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 563024, "time": 26017.553735017776, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 563032, "time": 26019.279409885406, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 563240, "time": 26027.62736082077, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 563592, "time": 26040.905564546585, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 563632, "time": 26044.091495990753, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 563632, "time": 26044.099695444107, "episode/length": 101.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 563920, "time": 26056.83119058609, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 564288, "time": 26070.645829200745, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 564424, "time": 26076.539359807968, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 564528, "time": 26081.78055858612, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 564600, "time": 26085.55063676834, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 564904, "time": 26097.169117450714, "episode/length": 244.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 565168, "time": 26107.739491701126, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 565192, "time": 26109.950911283493, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 565448, "time": 26121.421248197556, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 565920, "time": 26138.94342160225, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 566048, "time": 26144.75126004219, "episode/length": 202.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 566120, "time": 26148.50121665001, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 566608, "time": 26166.591058254242, "episode/length": 85.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 566920, "time": 26178.33582019806, "episode/length": 218.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 567064, "time": 26184.907824754715, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 567096, "time": 26187.461582899094, "episode/length": 273.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 567248, "time": 26194.38070011139, "episode/length": 256.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 567376, "time": 26200.15815782547, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 567376, "time": 26200.16716480255, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 567384, "time": 26203.49022936821, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 567712, "time": 26216.271324396133, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 567904, "time": 26224.174798727036, "episode/length": 222.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 568200, "time": 26235.31472325325, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 568464, "time": 26246.054817914963, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 568648, "time": 26253.602016210556, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 568936, "time": 26264.78933572769, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 568944, "time": 26266.852811336517, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 569168, "time": 26276.44905257225, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 569312, "time": 26282.815168619156, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 569632, "time": 26294.935159921646, "episode/length": 338.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26324.22910118103, "eval_episode/length": 45.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.8913043478260869}
{"step": 570024, "time": 26326.173319339752, "eval_episode/length": 52.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 570024, "time": 26329.96774840355, "eval_episode/length": 108.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 570024, "time": 26333.502190351486, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 570024, "time": 26336.072108983994, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 570024, "time": 26338.12783908844, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 570024, "time": 26339.825935602188, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9}
{"step": 570024, "time": 26342.330218315125, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 570432, "time": 26356.084361076355, "episode/length": 245.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 570744, "time": 26367.878354549408, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9867256637168141, "episode/intrinsic_return": 0.0}
{"step": 570800, "time": 26371.60057592392, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 570864, "time": 26375.833783864975, "episode/length": 193.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 570976, "time": 26381.60781598091, "episode/length": 346.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 570984, "time": 26383.207756996155, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 571248, "time": 26393.724122047424, "episode/length": 47.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 571593, "time": 26407.3964073658, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.711376048900463, "train/action_min": 0.0, "train/action_std": 3.2408358008773237, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05086784851219919, "train/actor_opt_grad_steps": 34950.0, "train/actor_opt_loss": -5.573344806388572, "train/adv_mag": 0.7379763585549813, "train/adv_max": 0.7301198628213671, "train/adv_mean": 0.003873436260349721, "train/adv_min": -0.49584971026138025, "train/adv_std": 0.07627469602006454, "train/cont_avg": 0.9946325231481481, "train/cont_loss_mean": 0.0002848733080693617, "train/cont_loss_std": 0.008159126576198038, "train/cont_neg_acc": 0.9797942399978637, "train/cont_neg_loss": 0.03858866636139148, "train/cont_pos_acc": 0.9999854286511739, "train/cont_pos_loss": 8.242188323250772e-05, "train/cont_pred": 0.9946608976081566, "train/cont_rate": 0.9946325231481481, "train/dyn_loss_mean": 13.588477007548015, "train/dyn_loss_std": 8.716789139641655, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7882968496393274, "train/extr_critic_critic_opt_grad_steps": 34950.0, "train/extr_critic_critic_opt_loss": 15763.4552734375, "train/extr_critic_mag": 5.25806846971865, "train/extr_critic_max": 5.25806846971865, "train/extr_critic_mean": 0.8233043220308092, "train/extr_critic_min": -0.23615720448670563, "train/extr_critic_std": 1.072490680217743, "train/extr_return_normed_mag": 1.946324520640903, "train/extr_return_normed_max": 1.946324520640903, "train/extr_return_normed_mean": 0.2853880501455731, "train/extr_return_normed_min": -0.14143516730379174, "train/extr_return_normed_std": 0.33720768568692383, "train/extr_return_rate": 0.39983267971762904, "train/extr_return_raw_mag": 6.305520760571516, "train/extr_return_raw_max": 6.305520760571516, "train/extr_return_raw_mean": 0.8360669868963736, "train/extr_return_raw_min": -0.5700988325807783, "train/extr_return_raw_std": 1.110639797758173, "train/extr_reward_mag": 1.015584875036169, "train/extr_reward_max": 1.015584875036169, "train/extr_reward_mean": 0.026712039230322396, "train/extr_reward_min": -0.381595598326789, "train/extr_reward_std": 0.15326635936896008, "train/image_loss_mean": 6.820974367636222, "train/image_loss_std": 11.595721029352259, "train/model_loss_mean": 15.028843823185673, "train/model_loss_std": 15.085221036275227, "train/model_opt_grad_norm": 57.619819189001014, "train/model_opt_grad_steps": 34916.69629629629, "train/model_opt_loss": 20714.586161747684, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1379.6296296296296, "train/policy_entropy_mag": 2.5153946293724907, "train/policy_entropy_max": 2.5153946293724907, "train/policy_entropy_mean": 0.6126151597058331, "train/policy_entropy_min": 0.07937510223300369, "train/policy_entropy_std": 0.6421058283911811, "train/policy_logprob_mag": 7.438383487418846, "train/policy_logprob_max": -0.00945568735262862, "train/policy_logprob_mean": -0.6128911905818515, "train/policy_logprob_min": -7.438383487418846, "train/policy_logprob_std": 1.1491903516981337, "train/policy_randomness_mag": 0.8878239185721786, "train/policy_randomness_max": 0.8878239185721786, "train/policy_randomness_mean": 0.2162262679250152, "train/policy_randomness_min": 0.028015927791043563, "train/policy_randomness_std": 0.2266351792547438, "train/post_ent_mag": 57.26457171969943, "train/post_ent_max": 57.26457171969943, "train/post_ent_mean": 40.702810838487416, "train/post_ent_min": 19.73885365238896, "train/post_ent_std": 7.486012476461905, "train/prior_ent_mag": 65.95502161096644, "train/prior_ent_max": 65.95502161096644, "train/prior_ent_mean": 54.37832130149559, "train/prior_ent_min": 40.889813882333264, "train/prior_ent_std": 3.949156997821949, "train/rep_loss_mean": 13.588477007548015, "train/rep_loss_std": 8.716789139641655, "train/reward_avg": 0.0244010417273751, "train/reward_loss_mean": 0.05449841960712715, "train/reward_loss_std": 0.24828945188610643, "train/reward_max_data": 1.0125925955949007, "train/reward_max_pred": 1.0070907601603756, "train/reward_neg_acc": 0.9931773485960784, "train/reward_neg_loss": 0.03007255327646379, "train/reward_pos_acc": 0.960222225719028, "train/reward_pos_loss": 0.8719875128180893, "train/reward_pred": 0.023397049852819353, "train/reward_rate": 0.02922453703703704, "eval_stats/sum_log_reward": 5.183333297570546, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.791666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 6.208333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4583333333333333, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5833333333333335, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.5833333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 5.808737806614163, "train_stats/max_log_achievement_collect_coal": 0.009708737864077669, "train_stats/max_log_achievement_collect_drink": 5.281553398058253, "train_stats/max_log_achievement_collect_sapling": 3.4271844660194173, "train_stats/max_log_achievement_collect_stone": 0.1553398058252427, "train_stats/max_log_achievement_collect_wood": 5.912621359223301, "train_stats/max_log_achievement_defeat_skeleton": 0.009708737864077669, "train_stats/max_log_achievement_defeat_zombie": 0.6504854368932039, "train_stats/max_log_achievement_eat_cow": 0.10679611650485436, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3883495145631068, "train_stats/max_log_achievement_make_wood_sword": 0.11650485436893204, "train_stats/max_log_achievement_place_plant": 2.9611650485436893, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.1844660194174756, "train_stats/max_log_achievement_wake_up": 1.796116504854369, "train_stats/mean_log_entropy": 0.5677804363873399, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.5582464736071415e-06, "report/cont_loss_std": 9.942233009496704e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00018003833247348666, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.5239825137978187e-06, "report/cont_pred": 0.994138240814209, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.688529968261719, "report/dyn_loss_std": 8.796988487243652, "report/image_loss_mean": 7.453239917755127, "report/image_loss_std": 11.122659683227539, "report/model_loss_mean": 15.720273971557617, "report/model_loss_std": 14.495875358581543, "report/post_ent_mag": 55.403236389160156, "report/post_ent_max": 55.403236389160156, "report/post_ent_mean": 40.59381103515625, "report/post_ent_min": 20.881580352783203, "report/post_ent_std": 7.043524265289307, "report/prior_ent_mag": 65.94270324707031, "report/prior_ent_max": 65.94270324707031, "report/prior_ent_mean": 54.8199577331543, "report/prior_ent_min": 41.536216735839844, "report/prior_ent_std": 4.010213851928711, "report/rep_loss_mean": 13.688529968261719, "report/rep_loss_std": 8.796988487243652, "report/reward_avg": 0.02871093712747097, "report/reward_loss_mean": 0.053912341594696045, "report/reward_loss_std": 0.21335648000240326, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0023975372314453, "report/reward_neg_acc": 0.9868553280830383, "report/reward_neg_loss": 0.02730945497751236, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8056336641311646, "report/reward_pred": 0.027625061571598053, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.114911007491173e-07, "eval/cont_loss_std": 1.921447164932033e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.9208905945997685e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.355666251536604e-07, "eval/cont_pred": 0.9980466961860657, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.439973831176758, "eval/dyn_loss_std": 9.621734619140625, "eval/image_loss_mean": 12.008262634277344, "eval/image_loss_std": 14.778815269470215, "eval/model_loss_mean": 21.966066360473633, "eval/model_loss_std": 18.339641571044922, "eval/post_ent_mag": 54.89573669433594, "eval/post_ent_max": 54.89573669433594, "eval/post_ent_mean": 39.57966613769531, "eval/post_ent_min": 21.19316864013672, "eval/post_ent_std": 6.999804496765137, "eval/prior_ent_mag": 65.94270324707031, "eval/prior_ent_max": 65.94270324707031, "eval/prior_ent_mean": 54.782958984375, "eval/prior_ent_min": 41.20268630981445, "eval/prior_ent_std": 3.694854736328125, "eval/rep_loss_mean": 16.439973831176758, "eval/rep_loss_std": 9.621734619140625, "eval/reward_avg": 0.02685546875, "eval/reward_loss_mean": 0.09381881356239319, "eval/reward_loss_std": 0.5933583974838257, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010864734649658, "eval/reward_neg_acc": 0.9798792600631714, "eval/reward_neg_loss": 0.05462729185819626, "eval/reward_pos_acc": 0.9333333969116211, "eval/reward_pos_loss": 1.3923648595809937, "eval/reward_pred": 0.030305787920951843, "eval/reward_rate": 0.029296875, "replay/size": 571089.0, "replay/inserts": 21648.0, "replay/samples": 21648.0, "replay/insert_wait_avg": 1.3808189104507346e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.401680999214528e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1584790702568919e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2820386886597, "timer/env.step_count": 2706.0, "timer/env.step_total": 238.4211745262146, "timer/env.step_frac": 0.23835394949086333, "timer/env.step_avg": 0.0881083423969751, "timer/env.step_min": 0.022467851638793945, "timer/env.step_max": 3.3319497108459473, "timer/replay._sample_count": 21648.0, "timer/replay._sample_total": 10.771008729934692, "timer/replay._sample_frac": 0.010767971745304122, "timer/replay._sample_avg": 0.0004975521401484983, "timer/replay._sample_min": 0.0003743171691894531, "timer/replay._sample_max": 0.011009693145751953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3527.0, "timer/agent.policy_total": 58.00286674499512, "timer/agent.policy_frac": 0.05798651230510464, "timer/agent.policy_avg": 0.016445383256307095, "timer/agent.policy_min": 0.00946187973022461, "timer/agent.policy_max": 0.10705208778381348, "timer/dataset_train_count": 1353.0, "timer/dataset_train_total": 0.14708495140075684, "timer/dataset_train_frac": 0.00014704347945063663, "timer/dataset_train_avg": 0.00010871023754675301, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0004909038543701172, "timer/agent.train_count": 1353.0, "timer/agent.train_total": 606.6763823032379, "timer/agent.train_frac": 0.6065053243368969, "timer/agent.train_avg": 0.44839348285531255, "timer/agent.train_min": 0.4356505870819092, "timer/agent.train_max": 1.5309765338897705, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47528862953186035, "timer/agent.report_frac": 0.0004751546175466169, "timer/agent.report_avg": 0.23764431476593018, "timer/agent.report_min": 0.23273229598999023, "timer/agent.report_max": 0.24255633354187012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.8623809814453125e-05, "timer/dataset_eval_frac": 3.861291947727843e-08, "timer/dataset_eval_avg": 3.8623809814453125e-05, "timer/dataset_eval_min": 3.8623809814453125e-05, "timer/dataset_eval_max": 3.8623809814453125e-05, "fps": 21.641626203262955}
{"step": 571880, "time": 26416.668454408646, "episode/length": 403.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 571960, "time": 26420.847029209137, "episode/length": 190.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 572176, "time": 26429.872147083282, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 572200, "time": 26432.021883249283, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 572544, "time": 26445.1062977314, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 572600, "time": 26448.363698244095, "episode/length": 370.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 572928, "time": 26461.147884607315, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 572976, "time": 26464.267946720123, "episode/length": 46.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 573528, "time": 26485.551436185837, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 573792, "time": 26496.174107074738, "episode/length": 238.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 574256, "time": 26513.186678171158, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 574272, "time": 26515.201313734055, "episode/length": 410.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951338199513382, "episode/intrinsic_return": 0.0}
{"step": 574504, "time": 26524.262508630753, "episode/length": 244.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 574672, "time": 26531.674618959427, "episode/length": 338.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9882005899705014, "episode/intrinsic_return": 0.0}
{"step": 574816, "time": 26537.909829616547, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 575184, "time": 26551.67933487892, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 575416, "time": 26560.79974579811, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 575520, "time": 26565.926147699356, "episode/length": 215.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 575896, "time": 26579.717943668365, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 576016, "time": 26585.562048196793, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 576288, "time": 26596.322828531265, "episode/length": 251.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 576528, "time": 26606.766134023666, "episode/length": 213.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 576760, "time": 26616.35473203659, "episode/length": 281.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 577016, "time": 26626.34770345688, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 577208, "time": 26634.34767794609, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 577448, "time": 26644.016325950623, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 577656, "time": 26653.105565547943, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 577936, "time": 26664.785799980164, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 578064, "time": 26670.677217960358, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 578184, "time": 26675.998336315155, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 578256, "time": 26680.051468133926, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 578496, "time": 26689.696836471558, "episode/length": 371.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 578512, "time": 26691.831859111786, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 578720, "time": 26700.21606016159, "episode/length": 57.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 579416, "time": 26724.746595859528, "episode/length": 219.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 579592, "time": 26732.297056913376, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 579640, "time": 26735.994750261307, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 579648, "time": 26738.456547498703, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 26766.333632946014, "eval_episode/length": 36.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.972972972972973}
{"step": 580008, "time": 26773.480609178543, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 580008, "time": 26775.46347284317, "eval_episode/length": 177.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 580008, "time": 26777.967083454132, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 580008, "time": 26780.307096242905, "eval_episode/length": 211.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 580008, "time": 26782.390789031982, "eval_episode/length": 221.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 580008, "time": 26784.213857889175, "eval_episode/length": 47.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 580008, "time": 26786.096447229385, "eval_episode/length": 233.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 580248, "time": 26794.049837112427, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 580272, "time": 26796.667859315872, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 580552, "time": 26807.286284208298, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 580680, "time": 26813.210221529007, "episode/length": 403.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 580856, "time": 26820.675077199936, "episode/length": 157.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 581000, "time": 26827.234446763992, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 581080, "time": 26831.436710596085, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 581360, "time": 26842.623152017593, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 581672, "time": 26855.840364217758, "episode/length": 38.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 581704, "time": 26858.32698392868, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 581712, "time": 26860.525067329407, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 581960, "time": 26870.174883127213, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 582136, "time": 26877.516849040985, "episode/length": 57.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 582424, "time": 26888.586141824722, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 582632, "time": 26897.00522685051, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 582760, "time": 26902.94260597229, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 582912, "time": 26909.758615493774, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9688715953307393, "episode/intrinsic_return": 0.0}
{"step": 583360, "time": 26926.2203476429, "episode/length": 206.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 583616, "time": 26936.36179447174, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 583640, "time": 26938.533366680145, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 583864, "time": 26947.529818058014, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 583976, "time": 26952.798398017883, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 584336, "time": 26966.622308015823, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 584552, "time": 26975.151242733, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 584696, "time": 26981.485192775726, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 584936, "time": 26991.0705909729, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 585120, "time": 26999.023062944412, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 585184, "time": 27002.718357801437, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 585376, "time": 27010.65185713768, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 585632, "time": 27020.770983695984, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 585792, "time": 27027.674899101257, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 585848, "time": 27031.020692825317, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 586000, "time": 27037.9021525383, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 586304, "time": 27049.489780426025, "episode/length": 170.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 586320, "time": 27051.637479543686, "episode/length": 39.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 586456, "time": 27057.499772548676, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 586656, "time": 27065.920120716095, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 587360, "time": 27091.13138318062, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 587384, "time": 27093.277400016785, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 587512, "time": 27099.068465471268, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 587576, "time": 27102.919584989548, "episode/length": 274.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 587656, "time": 27106.994178295135, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 587728, "time": 27111.18494129181, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 587800, "time": 27115.0995657444, "episode/length": 270.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 588024, "time": 27123.97707605362, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 588216, "time": 27131.92196726799, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 588696, "time": 27149.542217493057, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 589104, "time": 27164.936232805252, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 589200, "time": 27170.302736997604, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 589336, "time": 27176.574382781982, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 589344, "time": 27178.65336537361, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 589352, "time": 27180.224834918976, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 589568, "time": 27189.182585716248, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 589912, "time": 27203.323783397675, "episode/length": 100.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27226.389647960663, "eval_episode/length": 54.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 590096, "time": 27231.783348083496, "eval_episode/length": 145.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.958904109589041}
{"step": 590096, "time": 27233.767913341522, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 590096, "time": 27236.5240213871, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 590096, "time": 27238.21547150612, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 590096, "time": 27240.1346013546, "eval_episode/length": 195.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 590096, "time": 27242.004305124283, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 590096, "time": 27243.605315208435, "eval_episode/length": 151.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993421052631579}
{"step": 590248, "time": 27248.559388399124, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 590488, "time": 27258.058690547943, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 590600, "time": 27263.410577774048, "episode/length": 377.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9973544973544973, "episode/intrinsic_return": 0.0}
{"step": 590600, "time": 27263.418611764908, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 591184, "time": 27286.221888065338, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 591408, "time": 27295.279759407043, "episode/length": 257.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 591808, "time": 27310.20782971382, "episode/length": 49.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 591872, "time": 27313.88201069832, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 591968, "time": 27318.54997944832, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 592080, "time": 27323.893647432327, "episode/length": 313.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 592224, "time": 27330.298504590988, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 592608, "time": 27344.599192142487, "episode/length": 250.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9681274900398407, "episode/intrinsic_return": 0.0}
{"step": 592632, "time": 27346.65269470215, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 592720, "time": 27351.420000314713, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 592992, "time": 27362.060691833496, "episode/length": 44.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 593080, "time": 27366.32211947441, "episode/length": 44.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 593296, "time": 27375.29957294464, "episode/length": 185.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 593736, "time": 27391.471111774445, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9656652360515021, "episode/intrinsic_return": 0.0}
{"step": 593864, "time": 27397.28080224991, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 593880, "time": 27399.389706373215, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 593928, "time": 27402.48345708847, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 594009, "time": 27407.617237091064, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.524660818917411, "train/action_min": 0.0, "train/action_std": 3.233311797891344, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051505077151315554, "train/actor_opt_grad_steps": 36325.0, "train/actor_opt_loss": 1.4791053318551608, "train/adv_mag": 0.7433499700256756, "train/adv_max": 0.7312749336872783, "train/adv_mean": 0.005189044261715026, "train/adv_min": -0.505549741429942, "train/adv_std": 0.0756127164299999, "train/cont_avg": 0.9946498325892857, "train/cont_loss_mean": 0.00029964631149052173, "train/cont_loss_std": 0.00893950902382455, "train/cont_neg_acc": 0.9847165554761886, "train/cont_neg_loss": 0.03881942917529549, "train/cont_pos_acc": 0.9999789054904665, "train/cont_pos_loss": 7.133705577625652e-05, "train/cont_pred": 0.9947018985237394, "train/cont_rate": 0.9946498325892857, "train/dyn_loss_mean": 13.563124472754343, "train/dyn_loss_std": 8.739241848673139, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8008953215820449, "train/extr_critic_critic_opt_grad_steps": 36325.0, "train/extr_critic_critic_opt_loss": 15860.616803850446, "train/extr_critic_mag": 5.3633280277252195, "train/extr_critic_max": 5.3633280277252195, "train/extr_critic_mean": 0.8869436721716608, "train/extr_critic_min": -0.23282722405024936, "train/extr_critic_std": 1.0881741698299134, "train/extr_return_normed_mag": 1.932597669533321, "train/extr_return_normed_max": 1.932597669533321, "train/extr_return_normed_mean": 0.2937027452247483, "train/extr_return_normed_min": -0.13518831524997948, "train/extr_return_normed_std": 0.33579028940626554, "train/extr_return_rate": 0.44035670342189925, "train/extr_return_raw_mag": 6.3902451719556534, "train/extr_return_raw_max": 6.3902451719556534, "train/extr_return_raw_mean": 0.9043098762631416, "train/extr_return_raw_min": -0.5324198256645883, "train/extr_return_raw_std": 1.124863527076585, "train/extr_reward_mag": 1.0134080580302647, "train/extr_reward_max": 1.0134080580302647, "train/extr_reward_mean": 0.025760785011308535, "train/extr_reward_min": -0.3636266759463719, "train/extr_reward_std": 0.15028784567756312, "train/image_loss_mean": 6.777224131992885, "train/image_loss_std": 11.040834362166269, "train/model_loss_mean": 14.968680041176933, "train/model_loss_std": 14.512983873912267, "train/model_opt_grad_norm": 58.85828958238874, "train/model_opt_grad_steps": 36290.46428571428, "train/model_opt_loss": 19595.657526506697, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1303.5714285714287, "train/policy_entropy_mag": 2.5386482289859225, "train/policy_entropy_max": 2.5386482289859225, "train/policy_entropy_mean": 0.558731489947864, "train/policy_entropy_min": 0.07937510567052024, "train/policy_entropy_std": 0.5926810611571585, "train/policy_logprob_mag": 7.438383555412292, "train/policy_logprob_max": -0.009455694737178938, "train/policy_logprob_mean": -0.5593052329761642, "train/policy_logprob_min": -7.438383555412292, "train/policy_logprob_std": 1.1121870866843633, "train/policy_randomness_mag": 0.896031420145716, "train/policy_randomness_max": 0.896031420145716, "train/policy_randomness_mean": 0.19720769684229578, "train/policy_randomness_min": 0.02801592896825501, "train/policy_randomness_std": 0.20919040675674166, "train/post_ent_mag": 57.198539815630234, "train/post_ent_max": 57.198539815630234, "train/post_ent_mean": 40.794078663417274, "train/post_ent_min": 19.50915057318551, "train/post_ent_std": 7.502772974967956, "train/prior_ent_mag": 66.00945145743233, "train/prior_ent_max": 66.00945145743233, "train/prior_ent_mean": 54.401894324166435, "train/prior_ent_min": 40.913865498134065, "train/prior_ent_std": 3.9692382335662844, "train/rep_loss_mean": 13.563124472754343, "train/rep_loss_std": 8.739241848673139, "train/reward_avg": 0.024196428333276083, "train/reward_loss_mean": 0.05328163267778499, "train/reward_loss_std": 0.24508685820869036, "train/reward_max_data": 1.0157142894608633, "train/reward_max_pred": 1.0078791643892016, "train/reward_neg_acc": 0.992691318477903, "train/reward_neg_loss": 0.029580302756013616, "train/reward_pos_acc": 0.9679675144808633, "train/reward_pos_loss": 0.8500852350677762, "train/reward_pred": 0.023723040906978504, "train/reward_rate": 0.028982979910714284, "train_stats/sum_log_reward": 5.5601769538052315, "train_stats/max_log_achievement_collect_coal": 0.008849557522123894, "train_stats/max_log_achievement_collect_drink": 4.327433628318584, "train_stats/max_log_achievement_collect_sapling": 4.353982300884955, "train_stats/max_log_achievement_collect_stone": 0.04424778761061947, "train_stats/max_log_achievement_collect_wood": 5.946902654867257, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.6814159292035398, "train_stats/max_log_achievement_eat_cow": 0.07964601769911504, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09734513274336283, "train_stats/max_log_achievement_make_wood_sword": 0.36283185840707965, "train_stats/max_log_achievement_place_plant": 2.52212389380531, "train_stats/max_log_achievement_place_stone": 0.008849557522123894, "train_stats/max_log_achievement_place_table": 2.150442477876106, "train_stats/max_log_achievement_wake_up": 1.5575221238938053, "train_stats/mean_log_entropy": 0.49519639350144207, "eval_stats/sum_log_reward": 4.787499979138374, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.8125, "eval_stats/max_log_achievement_collect_sapling": 4.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0003571193083189428, "report/cont_loss_std": 0.007803643587976694, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03310808539390564, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.671666051261127e-05, "report/cont_pred": 0.9914116859436035, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 14.451484680175781, "report/dyn_loss_std": 8.874635696411133, "report/image_loss_mean": 6.515887260437012, "report/image_loss_std": 8.165162086486816, "report/model_loss_mean": 15.253610610961914, "report/model_loss_std": 12.112837791442871, "report/post_ent_mag": 56.23630905151367, "report/post_ent_max": 56.23630905151367, "report/post_ent_mean": 39.54062271118164, "report/post_ent_min": 22.42540740966797, "report/post_ent_std": 7.345123291015625, "report/prior_ent_mag": 65.58456420898438, "report/prior_ent_max": 65.58456420898438, "report/prior_ent_mean": 54.32688903808594, "report/prior_ent_min": 41.029300689697266, "report/prior_ent_std": 3.802459239959717, "report/rep_loss_mean": 14.451484680175781, "report/rep_loss_std": 8.874635696411133, "report/reward_avg": 0.02626953274011612, "report/reward_loss_mean": 0.06647618860006332, "report/reward_loss_std": 0.22161059081554413, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005295753479004, "report/reward_neg_acc": 0.992929220199585, "report/reward_neg_loss": 0.04358988627791405, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7328714728355408, "report/reward_pred": 0.02515224739909172, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0078058852814137936, "eval/cont_loss_std": 0.2496444135904312, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 1.9981423616409302, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.454066578953643e-07, "eval/cont_pred": 0.9970694780349731, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.996028900146484, "eval/dyn_loss_std": 10.35275650024414, "eval/image_loss_mean": 20.950862884521484, "eval/image_loss_std": 26.99532699584961, "eval/model_loss_mean": 33.07792282104492, "eval/model_loss_std": 31.3278751373291, "eval/post_ent_mag": 53.772254943847656, "eval/post_ent_max": 53.772254943847656, "eval/post_ent_mean": 37.94744110107422, "eval/post_ent_min": 19.705713272094727, "eval/post_ent_std": 6.629312992095947, "eval/prior_ent_mag": 65.58456420898438, "eval/prior_ent_max": 65.58456420898438, "eval/prior_ent_mean": 54.911590576171875, "eval/prior_ent_min": 43.05910873413086, "eval/prior_ent_std": 3.4026236534118652, "eval/rep_loss_mean": 19.996028900146484, "eval/rep_loss_std": 10.35275650024414, "eval/reward_avg": 0.03193359449505806, "eval/reward_loss_mean": 0.12163685262203217, "eval/reward_loss_std": 0.6798045039176941, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023260116577148, "eval/reward_neg_acc": 0.9848023653030396, "eval/reward_neg_loss": 0.06028497964143753, "eval/reward_pos_acc": 0.7837837338447571, "eval/reward_pos_loss": 1.7582392692565918, "eval/reward_pred": 0.03032444603741169, "eval/reward_rate": 0.0361328125, "replay/size": 593505.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3771183060204277e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.464832956666695e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1448552008388804e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.218603849411, "timer/env.step_count": 2802.0, "timer/env.step_total": 255.5293836593628, "timer/env.step_frac": 0.2554735361609354, "timer/env.step_avg": 0.09119535462504025, "timer/env.step_min": 0.02298736572265625, "timer/env.step_max": 3.328011989593506, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.193175315856934, "timer/replay._sample_frac": 0.011190728979424316, "timer/replay._sample_avg": 0.0004993386561320902, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.010972023010253906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3243.0, "timer/agent.policy_total": 52.488431453704834, "timer/agent.policy_frac": 0.05247695978828973, "timer/agent.policy_avg": 0.01618514691757781, "timer/agent.policy_min": 0.009264469146728516, "timer/agent.policy_max": 0.10171270370483398, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.15415382385253906, "timer/dataset_train_frac": 0.00015412013259828134, "timer/dataset_train_avg": 0.00011003128040866457, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0006263256072998047, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 627.3649642467499, "timer/agent.train_frac": 0.6272278498243204, "timer/agent.train_avg": 0.4477979759077444, "timer/agent.train_min": 0.43336939811706543, "timer/agent.train_max": 1.545011043548584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4739401340484619, "timer/agent.report_frac": 0.0004738365515543005, "timer/agent.report_avg": 0.23697006702423096, "timer/agent.report_min": 0.23028206825256348, "timer/agent.report_max": 0.24365806579589844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122600773681168e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 22.410797545331867}
{"step": 594440, "time": 27421.823786973953, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 594592, "time": 27428.66327023506, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 594664, "time": 27432.515649795532, "episode/length": 322.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.0}
{"step": 594704, "time": 27435.58665728569, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 595256, "time": 27455.470304965973, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 595272, "time": 27457.622466802597, "episode/length": 191.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 595352, "time": 27461.831957817078, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 595464, "time": 27467.219561338425, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 595912, "time": 27483.713765382767, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 595928, "time": 27485.871458768845, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 596288, "time": 27499.76059937477, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 596312, "time": 27501.851152658463, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 596840, "time": 27520.92510867119, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 596856, "time": 27523.0282497406, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 597104, "time": 27533.064116954803, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 597584, "time": 27550.560807943344, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961352657004831, "episode/intrinsic_return": 0.0}
{"step": 597824, "time": 27560.58535552025, "episode/length": 188.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 598168, "time": 27575.603162765503, "episode/length": 281.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 598208, "time": 27578.694719791412, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 598208, "time": 27578.70216012001, "episode/length": 47.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 598360, "time": 27586.75201368332, "episode/length": 258.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 598464, "time": 27592.093081235886, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 598552, "time": 27596.23454284668, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 598704, "time": 27603.05589389801, "episode/length": 404.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 598848, "time": 27609.463085889816, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 599240, "time": 27623.767238616943, "episode/length": 266.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 599512, "time": 27634.463420391083, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 599552, "time": 27637.52576494217, "episode/length": 172.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 599648, "time": 27642.40400147438, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 600000, "time": 27655.833019018173, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 27680.005267381668, "eval_episode/length": 167.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 600080, "time": 27682.20667695999, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 600080, "time": 27686.783226013184, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 600080, "time": 27688.337909936905, "eval_episode/length": 209.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 600080, "time": 27690.65047454834, "eval_episode/length": 228.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 600080, "time": 27693.594717025757, "eval_episode/length": 259.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 600080, "time": 27695.514288425446, "eval_episode/length": 270.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.974169741697417}
{"step": 600080, "time": 27698.904196977615, "eval_episode/length": 312.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9712460063897763}
{"step": 600264, "time": 27704.74232697487, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 600440, "time": 27712.364157676697, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 600824, "time": 27726.84334230423, "episode/length": 146.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 600840, "time": 27729.466736078262, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 601240, "time": 27745.0768327713, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 601344, "time": 27750.43549633026, "episode/length": 223.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 601400, "time": 27753.758628845215, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 601744, "time": 27766.916158676147, "episode/length": 398.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 601760, "time": 27769.000314474106, "episode/length": 51.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 601792, "time": 27771.61771607399, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 602144, "time": 27784.815088510513, "episode/length": 234.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 602168, "time": 27787.004071474075, "episode/length": 167.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 602328, "time": 27793.865234375, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 602752, "time": 27809.690952301025, "episode/length": 52.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 603208, "time": 27826.178565740585, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 603352, "time": 27832.571168661118, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 603392, "time": 27835.736381053925, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 603424, "time": 27838.460264205933, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 603528, "time": 27843.36401104927, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 603984, "time": 27860.270210027695, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 604392, "time": 27875.246158123016, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 604656, "time": 27886.39718055725, "episode/length": 361.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 604704, "time": 27889.5265250206, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 604952, "time": 27899.22302699089, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 605056, "time": 27904.408321619034, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 605168, "time": 27909.824996948242, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 605304, "time": 27915.797792196274, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 605328, "time": 27918.325727701187, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 605792, "time": 27935.40415263176, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 606192, "time": 27950.332894563675, "episode/length": 185.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 606344, "time": 27958.124934911728, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 606488, "time": 27964.529935121536, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 606496, "time": 27966.64798808098, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 606576, "time": 27971.027881145477, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 606704, "time": 27976.83557844162, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 606768, "time": 27980.554973840714, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 607328, "time": 28000.557218551636, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 607520, "time": 28009.220351696014, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 608024, "time": 28027.460280895233, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 608056, "time": 28030.03980565071, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 608168, "time": 28035.38356113434, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 608320, "time": 28042.66361641884, "episode/length": 227.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 608344, "time": 28044.776242017746, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 608560, "time": 28053.84010696411, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 609088, "time": 28073.120236873627, "episode/length": 219.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 609216, "time": 28079.389377117157, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 609408, "time": 28087.381432294846, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 609704, "time": 28098.444252490997, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 609704, "time": 28098.47973561287, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 609832, "time": 28106.177939891815, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28130.35906791687, "eval_episode/length": 35.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8611111111111112}
{"step": 610064, "time": 28132.410125494003, "eval_episode/length": 44.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9111111111111111}
{"step": 610064, "time": 28134.312695980072, "eval_episode/length": 53.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 610064, "time": 28140.24863553047, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 610064, "time": 28142.38891839981, "eval_episode/length": 171.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 610064, "time": 28144.196009635925, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 610064, "time": 28147.109607696533, "eval_episode/length": 206.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 610064, "time": 28148.85502886772, "eval_episode/length": 50.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 610120, "time": 28150.49694252014, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 610536, "time": 28167.513324975967, "episode/length": 51.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 610640, "time": 28172.644023656845, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 610992, "time": 28186.162831544876, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 611104, "time": 28191.593450546265, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 611264, "time": 28198.49432373047, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 611320, "time": 28201.72979927063, "episode/length": 371.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 611328, "time": 28203.84047460556, "episode/length": 279.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 611360, "time": 28206.410987615585, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 611592, "time": 28215.52874827385, "episode/length": 40.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 611920, "time": 28229.0741147995, "episode/length": 159.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 611920, "time": 28229.082597970963, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 612296, "time": 28245.786719322205, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 612656, "time": 28259.574427127838, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 612768, "time": 28264.951778888702, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 612784, "time": 28267.171346902847, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 612824, "time": 28269.91951727867, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 612872, "time": 28273.17032146454, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 613392, "time": 28292.95025253296, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 613680, "time": 28304.090364933014, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 613808, "time": 28310.007253170013, "episode/length": 408.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 614064, "time": 28319.9747030735, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 614320, "time": 28330.057759284973, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 614392, "time": 28333.80210375786, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 614408, "time": 28336.24489378929, "episode/length": 191.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 614488, "time": 28341.961087465286, "episode/length": 212.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 614888, "time": 28356.83344101906, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 615488, "time": 28378.696227312088, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 615504, "time": 28380.803103923798, "episode/length": 227.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 615536, "time": 28383.431157827377, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 615624, "time": 28387.705427885056, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 615888, "time": 28398.214543819427, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 616105, "time": 28407.751747369766, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.559756491681655, "train/action_min": 0.0, "train/action_std": 3.317458854304801, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.052110836177849944, "train/actor_opt_grad_steps": 37720.0, "train/actor_opt_loss": -0.3605294251184669, "train/adv_mag": 0.7385806126131428, "train/adv_max": 0.7253343246394782, "train/adv_mean": 0.004750025046443049, "train/adv_min": -0.5065740394077712, "train/adv_std": 0.0764161213535628, "train/cont_avg": 0.9949626236510791, "train/cont_loss_mean": 0.00013967264346087727, "train/cont_loss_std": 0.0035449022307017107, "train/cont_neg_acc": 0.9920347380465355, "train/cont_neg_loss": 0.012692111531245298, "train/cont_pos_acc": 0.999978800471738, "train/cont_pos_loss": 5.5446654976577136e-05, "train/cont_pred": 0.9949781221451519, "train/cont_rate": 0.9949626236510791, "train/dyn_loss_mean": 13.506649655403852, "train/dyn_loss_std": 8.704319037979456, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8085317560237089, "train/extr_critic_critic_opt_grad_steps": 37720.0, "train/extr_critic_critic_opt_loss": 15831.283006407373, "train/extr_critic_mag": 5.5073254880287665, "train/extr_critic_max": 5.5073254880287665, "train/extr_critic_mean": 1.0110166651739492, "train/extr_critic_min": -0.20209517753381523, "train/extr_critic_std": 1.1165384534451601, "train/extr_return_normed_mag": 1.8945274678923243, "train/extr_return_normed_max": 1.8945274678923243, "train/extr_return_normed_mean": 0.29964935704529716, "train/extr_return_normed_min": -0.14519399744894007, "train/extr_return_normed_std": 0.32963622892074446, "train/extr_return_rate": 0.4972328633713208, "train/extr_return_raw_mag": 6.610936370684946, "train/extr_return_raw_max": 6.610936370684946, "train/extr_return_raw_mean": 1.0276401223038598, "train/extr_return_raw_min": -0.5296941179808953, "train/extr_return_raw_std": 1.15410362773662, "train/extr_reward_mag": 1.0159242719197445, "train/extr_reward_max": 1.0159242719197445, "train/extr_reward_mean": 0.028124898631902907, "train/extr_reward_min": -0.39103214860820085, "train/extr_reward_std": 0.15633132957297263, "train/image_loss_mean": 6.459086277502046, "train/image_loss_std": 10.772404921140602, "train/model_loss_mean": 14.615898036270691, "train/model_loss_std": 14.235397530974245, "train/model_opt_grad_norm": 57.1405561158983, "train/model_opt_grad_steps": 37684.12949640288, "train/model_opt_loss": 19082.991976731115, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1303.9568345323742, "train/policy_entropy_mag": 2.477001440610817, "train/policy_entropy_max": 2.477001440610817, "train/policy_entropy_mean": 0.5248859239567956, "train/policy_entropy_min": 0.07937510622491081, "train/policy_entropy_std": 0.582147108993942, "train/policy_logprob_mag": 7.438383623850432, "train/policy_logprob_max": -0.00945568989908738, "train/policy_logprob_mean": -0.5257118672346898, "train/policy_logprob_min": -7.438383623850432, "train/policy_logprob_std": 1.0889279786631358, "train/policy_randomness_mag": 0.8742728083253765, "train/policy_randomness_max": 0.8742728083253765, "train/policy_randomness_mean": 0.18526169743469292, "train/policy_randomness_min": 0.028015929133557587, "train/policy_randomness_std": 0.205472382281324, "train/post_ent_mag": 57.20601074987178, "train/post_ent_max": 57.20601074987178, "train/post_ent_mean": 40.8413010192432, "train/post_ent_min": 19.72775447625908, "train/post_ent_std": 7.488192976807519, "train/prior_ent_mag": 66.00621960317488, "train/prior_ent_max": 66.00621960317488, "train/prior_ent_mean": 54.40283299178528, "train/prior_ent_min": 40.99256350839738, "train/prior_ent_std": 3.861404072466514, "train/rep_loss_mean": 13.506649655403852, "train/rep_loss_std": 8.704319037979456, "train/reward_avg": 0.024690871890768303, "train/reward_loss_mean": 0.052682413619092046, "train/reward_loss_std": 0.2419612051235686, "train/reward_max_data": 1.015107917271072, "train/reward_max_pred": 1.0058265075409154, "train/reward_neg_acc": 0.9929408666898878, "train/reward_neg_loss": 0.028513809645937072, "train/reward_pos_acc": 0.9668243433074127, "train/reward_pos_loss": 0.8515622637254728, "train/reward_pred": 0.024023228646557537, "train/reward_rate": 0.029353080035971223, "train_stats/sum_log_reward": 5.653571396001747, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.6875, "train_stats/max_log_achievement_collect_sapling": 3.9464285714285716, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.241071428571429, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.7053571428571429, "train_stats/max_log_achievement_eat_cow": 0.0625, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.044642857142857144, "train_stats/max_log_achievement_make_wood_sword": 0.5982142857142857, "train_stats/max_log_achievement_place_plant": 2.5535714285714284, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.9196428571428572, "train_stats/max_log_achievement_wake_up": 1.2946428571428572, "train_stats/mean_log_entropy": 0.48048914410173893, "eval_stats/sum_log_reward": 5.287499889731407, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.5, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.6875, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 8.38331459362962e-07, "report/cont_loss_std": 1.4317964087240398e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.646566700714175e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.316762887261575e-07, "report/cont_pred": 0.9990227222442627, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 12.872785568237305, "report/dyn_loss_std": 8.920278549194336, "report/image_loss_mean": 7.807216644287109, "report/image_loss_std": 14.189413070678711, "report/model_loss_mean": 15.584583282470703, "report/model_loss_std": 17.79238510131836, "report/post_ent_mag": 58.48557662963867, "report/post_ent_max": 58.48557662963867, "report/post_ent_mean": 42.9134407043457, "report/post_ent_min": 19.196659088134766, "report/post_ent_std": 7.703229904174805, "report/prior_ent_mag": 65.84141540527344, "report/prior_ent_max": 65.84141540527344, "report/prior_ent_mean": 55.479339599609375, "report/prior_ent_min": 39.045799255371094, "report/prior_ent_std": 3.7000510692596436, "report/rep_loss_mean": 12.872785568237305, "report/rep_loss_std": 8.920278549194336, "report/reward_avg": 0.01806640625, "report/reward_loss_mean": 0.05369453877210617, "report/reward_loss_std": 0.24698665738105774, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0010426044464111, "report/reward_neg_acc": 0.9910089373588562, "report/reward_neg_loss": 0.03144704923033714, "report/reward_pos_acc": 0.8695652484893799, "report/reward_pos_loss": 1.0219439268112183, "report/reward_pred": 0.016731439158320427, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 3.100961748714326e-06, "eval/cont_loss_std": 4.71810890303459e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.0131122154416516e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.651905560924206e-06, "eval/cont_pred": 0.9921854138374329, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 17.250682830810547, "eval/dyn_loss_std": 9.663165092468262, "eval/image_loss_mean": 10.989784240722656, "eval/image_loss_std": 12.929722785949707, "eval/model_loss_mean": 21.419795989990234, "eval/model_loss_std": 16.55968475341797, "eval/post_ent_mag": 58.39423370361328, "eval/post_ent_max": 58.39423370361328, "eval/post_ent_mean": 40.24840545654297, "eval/post_ent_min": 18.886457443237305, "eval/post_ent_std": 8.05754566192627, "eval/prior_ent_mag": 65.84141540527344, "eval/prior_ent_max": 65.84141540527344, "eval/prior_ent_mean": 55.35951232910156, "eval/prior_ent_min": 42.849342346191406, "eval/prior_ent_std": 4.0223774909973145, "eval/rep_loss_mean": 17.250682830810547, "eval/rep_loss_std": 9.663165092468262, "eval/reward_avg": 0.01914062350988388, "eval/reward_loss_mean": 0.07959902286529541, "eval/reward_loss_std": 0.44318607449531555, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017437934875488, "eval/reward_neg_acc": 0.9939879775047302, "eval/reward_neg_loss": 0.039235860109329224, "eval/reward_pos_acc": 0.8076923489570618, "eval/reward_pos_loss": 1.6289236545562744, "eval/reward_pred": 0.015283351764082909, "eval/reward_rate": 0.025390625, "replay/size": 615601.0, "replay/inserts": 22096.0, "replay/samples": 22096.0, "replay/insert_wait_avg": 1.3838873489622962e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.428137139079365e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.153702499302289e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1201241016388, "timer/env.step_count": 2762.0, "timer/env.step_total": 258.06881403923035, "timer/env.step_frac": 0.2580378174782169, "timer/env.step_avg": 0.09343548661811381, "timer/env.step_min": 0.022698640823364258, "timer/env.step_max": 4.226105213165283, "timer/replay._sample_count": 22096.0, "timer/replay._sample_total": 11.183268785476685, "timer/replay._sample_frac": 0.011181925566713392, "timer/replay._sample_avg": 0.0005061218675541584, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.029363632202148438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3286.0, "timer/agent.policy_total": 53.52912664413452, "timer/agent.policy_frac": 0.053522697278206695, "timer/agent.policy_avg": 0.016290056799797482, "timer/agent.policy_min": 0.009286165237426758, "timer/agent.policy_max": 0.10854887962341309, "timer/dataset_train_count": 1381.0, "timer/dataset_train_total": 0.15314745903015137, "timer/dataset_train_frac": 0.00015312906453883885, "timer/dataset_train_avg": 0.00011089606012320881, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010793209075927734, "timer/agent.train_count": 1381.0, "timer/agent.train_total": 619.9968235492706, "timer/agent.train_frac": 0.6199223559331783, "timer/agent.train_avg": 0.448947736096503, "timer/agent.train_min": 0.4331386089324951, "timer/agent.train_max": 2.0141382217407227, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787020683288574, "timer/agent.report_frac": 0.0004786445715796921, "timer/agent.report_avg": 0.2393510341644287, "timer/agent.report_min": 0.23224449157714844, "timer/agent.report_max": 0.24645757675170898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8606793126862367e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.093034396295185}
{"step": 616152, "time": 28409.150918722153, "episode/length": 217.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 616448, "time": 28420.812028169632, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 616648, "time": 28428.94922852516, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 616768, "time": 28435.227100133896, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 617104, "time": 28448.371707439423, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 617128, "time": 28450.54558491707, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 617232, "time": 28455.80216383934, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 617400, "time": 28462.772767066956, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 617488, "time": 28467.447336435318, "episode/length": 232.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 618344, "time": 28497.280646324158, "episode/length": 273.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 618416, "time": 28501.433391094208, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 618448, "time": 28504.107129335403, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 618480, "time": 28506.724781513214, "episode/length": 155.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 618536, "time": 28509.94747686386, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 618552, "time": 28512.467767477036, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 618680, "time": 28518.90511918068, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 618920, "time": 28528.95871782303, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 618936, "time": 28531.090309381485, "episode/length": 73.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 619248, "time": 28543.135159254074, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 619760, "time": 28561.61484527588, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 619840, "time": 28565.971851587296, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 620008, "time": 28572.941524744034, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28590.506452083588, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.875}
{"step": 620048, "time": 28592.265238761902, "eval_episode/length": 43.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 620048, "time": 28599.2293510437, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 620048, "time": 28600.935950040817, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 620048, "time": 28602.78373861313, "eval_episode/length": 181.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 620048, "time": 28605.13952565193, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 620048, "time": 28608.27841591835, "eval_episode/length": 238.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9748953974895398}
{"step": 620048, "time": 28610.329731225967, "eval_episode/length": 247.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 620080, "time": 28611.387799739838, "episode/length": 199.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 620192, "time": 28616.616147518158, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 620408, "time": 28625.10812830925, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 620624, "time": 28634.039435863495, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 620816, "time": 28642.167670726776, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 620896, "time": 28646.37452507019, "episode/length": 60.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 621104, "time": 28654.836750745773, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 621400, "time": 28665.965923070908, "episode/length": 36.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 621736, "time": 28678.700355052948, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 622016, "time": 28689.757722377777, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 622048, "time": 28692.387714147568, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 622048, "time": 28692.39894604683, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 622168, "time": 28699.49443435669, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 622184, "time": 28701.60742998123, "episode/length": 170.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 623032, "time": 28733.057062387466, "episode/length": 161.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 623064, "time": 28735.68012237549, "episode/length": 270.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 623184, "time": 28741.461230039597, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 623544, "time": 28754.755172252655, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 623616, "time": 28759.45719909668, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 623704, "time": 28763.780121564865, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 624104, "time": 28778.52510023117, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 624168, "time": 28782.254742860794, "episode/length": 77.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 624400, "time": 28791.95298743248, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 624464, "time": 28796.17040705681, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 624568, "time": 28800.97712469101, "episode/length": 314.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 624904, "time": 28813.849992275238, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 625216, "time": 28826.101278543472, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 625488, "time": 28836.813879728317, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 625696, "time": 28845.236771821976, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 625824, "time": 28851.171711206436, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 625872, "time": 28854.31324672699, "episode/length": 162.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 626064, "time": 28862.27934026718, "episode/length": 236.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 626296, "time": 28871.288988113403, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 626520, "time": 28880.39047217369, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 626896, "time": 28894.84237599373, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 626904, "time": 28896.574104309082, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 626968, "time": 28900.221064567566, "episode/length": 158.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 627352, "time": 28914.651307582855, "episode/length": 184.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 627576, "time": 28923.69878411293, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 627584, "time": 28925.85036468506, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 627952, "time": 28939.862752199173, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 628000, "time": 28942.938505649567, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 628264, "time": 28953.019338846207, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 628320, "time": 28956.650074481964, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 628600, "time": 28967.3324842453, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 628648, "time": 28970.572338581085, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 629000, "time": 28984.01972603798, "episode/length": 309.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 629456, "time": 29001.11126446724, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 629504, "time": 29004.23036623001, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 629792, "time": 29015.38713145256, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 629960, "time": 29022.396637678146, "episode/length": 211.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 629992, "time": 29025.033923625946, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 29043.85041809082, "eval_episode/length": 70.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9295774647887324}
{"step": 630032, "time": 29049.003588438034, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 630032, "time": 29050.648001194, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 630032, "time": 29053.378742694855, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 630032, "time": 29055.963712453842, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 630032, "time": 29057.862345457077, "eval_episode/length": 219.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 630032, "time": 29060.06383252144, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 630032, "time": 29062.114884853363, "eval_episode/length": 239.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 630128, "time": 29065.352584838867, "episode/length": 184.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 630488, "time": 29078.68327140808, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 630944, "time": 29097.044484615326, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 631136, "time": 29104.94609451294, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 631296, "time": 29111.960038661957, "episode/length": 223.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 631440, "time": 29118.36020922661, "episode/length": 184.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 631456, "time": 29120.573073148727, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 631488, "time": 29123.177345991135, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 631872, "time": 29137.39351129532, "episode/length": 408.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 631888, "time": 29139.407845020294, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 632440, "time": 29159.115203857422, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 632792, "time": 29172.249127864838, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 632824, "time": 29174.78903746605, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 633360, "time": 29194.45894742012, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 633560, "time": 29202.515914201736, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 634064, "time": 29221.223371982574, "episode/length": 202.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 634096, "time": 29223.86345267296, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 634272, "time": 29231.239460229874, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 634384, "time": 29236.54836845398, "episode/length": 198.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 634456, "time": 29240.35875415802, "episode/length": 394.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949367088607595, "episode/intrinsic_return": 0.0}
{"step": 634496, "time": 29243.461254119873, "episode/length": 443.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 634664, "time": 29250.32108592987, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 634680, "time": 29252.476516723633, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 634992, "time": 29264.615202188492, "episode/length": 111.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 635152, "time": 29271.438279151917, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 635648, "time": 29289.344007730484, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 635880, "time": 29298.392778635025, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 635904, "time": 29300.983714818954, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 636136, "time": 29310.029887914658, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 636208, "time": 29314.24158000946, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 636520, "time": 29325.800558567047, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 636672, "time": 29332.848167419434, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 636840, "time": 29340.14256477356, "episode/length": 230.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 637464, "time": 29362.46629834175, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 637632, "time": 29369.838953733444, "episode/length": 247.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 637712, "time": 29374.059333086014, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 638024, "time": 29385.688775777817, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 638192, "time": 29393.197162866592, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 638192, "time": 29393.208611488342, "episode/length": 247.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 638224, "time": 29397.519400835037, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 638473, "time": 29408.07157254219, "train_stats/sum_log_reward": 5.985964878282526, "train_stats/max_log_achievement_collect_coal": 0.03508771929824561, "train_stats/max_log_achievement_collect_drink": 4.973684210526316, "train_stats/max_log_achievement_collect_sapling": 3.1578947368421053, "train_stats/max_log_achievement_collect_stone": 0.07017543859649122, "train_stats/max_log_achievement_collect_wood": 6.201754385964913, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.8508771929824561, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.14035087719298245, "train_stats/max_log_achievement_make_wood_sword": 0.6140350877192983, "train_stats/max_log_achievement_place_plant": 2.6228070175438596, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.9736842105263157, "train_stats/max_log_achievement_wake_up": 1.5789473684210527, "train_stats/mean_log_entropy": 0.5156654647567815, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.676041637393211, "train/action_min": 0.0, "train/action_std": 3.452855827139436, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.052439040712100995, "train/actor_opt_grad_steps": 39110.0, "train/actor_opt_loss": -6.279659398704124, "train/adv_mag": 0.7108286241833255, "train/adv_max": 0.6876710591127546, "train/adv_mean": 0.0037095233877401717, "train/adv_min": -0.5252659155739298, "train/adv_std": 0.07611010052102933, "train/cont_avg": 0.9943865220323741, "train/cont_loss_mean": 0.00021534079327083542, "train/cont_loss_std": 0.00598875084696531, "train/cont_neg_acc": 0.9922490591625516, "train/cont_neg_loss": 0.018743619704080814, "train/cont_pos_acc": 0.999943429617573, "train/cont_pos_loss": 0.00011221237518938358, "train/cont_pred": 0.9943666059336216, "train/cont_rate": 0.9943865220323741, "train/dyn_loss_mean": 13.355628034193739, "train/dyn_loss_std": 8.724772748329656, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7265875671836112, "train/extr_critic_critic_opt_grad_steps": 39110.0, "train/extr_critic_critic_opt_loss": 15649.705162432554, "train/extr_critic_mag": 5.559229854199526, "train/extr_critic_max": 5.559229854199526, "train/extr_critic_mean": 1.0190234038469603, "train/extr_critic_min": -0.2023923122625557, "train/extr_critic_std": 1.1239788257818428, "train/extr_return_normed_mag": 1.9030054747629508, "train/extr_return_normed_max": 1.9030054747629508, "train/extr_return_normed_mean": 0.30720785656850114, "train/extr_return_normed_min": -0.14004055528546408, "train/extr_return_normed_std": 0.33370138329567667, "train/extr_return_rate": 0.5236829579305305, "train/extr_return_raw_mag": 6.58243586176591, "train/extr_return_raw_max": 6.58243586176591, "train/extr_return_raw_mean": 1.031926297669788, "train/extr_return_raw_min": -0.5230494205900234, "train/extr_return_raw_std": 1.1606049464760924, "train/extr_reward_mag": 1.0178297234953737, "train/extr_reward_max": 1.0178297234953737, "train/extr_reward_mean": 0.027882472682315453, "train/extr_reward_min": -0.3955036487510736, "train/extr_reward_std": 0.156150986822389, "train/image_loss_mean": 6.453272486762177, "train/image_loss_std": 11.023802126054283, "train/model_loss_mean": 14.52186441764557, "train/model_loss_std": 14.466308902493484, "train/model_opt_grad_norm": 56.548133587491684, "train/model_opt_grad_steps": 39072.68345323741, "train/model_opt_loss": 18692.273121346672, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 1276.978417266187, "train/policy_entropy_mag": 2.4796836787848164, "train/policy_entropy_max": 2.4796836787848164, "train/policy_entropy_mean": 0.5646514305107885, "train/policy_entropy_min": 0.07937509861352632, "train/policy_entropy_std": 0.6264076635991926, "train/policy_logprob_mag": 7.438383572393184, "train/policy_logprob_max": -0.009455683942643001, "train/policy_logprob_mean": -0.5650233294037607, "train/policy_logprob_min": -7.438383572393184, "train/policy_logprob_std": 1.1102672583765263, "train/policy_randomness_mag": 0.8752195217626558, "train/policy_randomness_max": 0.8752195217626558, "train/policy_randomness_mean": 0.19929717899226457, "train/policy_randomness_min": 0.02801592641329165, "train/policy_randomness_std": 0.2210944178078672, "train/post_ent_mag": 57.42552572017093, "train/post_ent_max": 57.42552572017093, "train/post_ent_mean": 40.940675337537584, "train/post_ent_min": 19.771396403690037, "train/post_ent_std": 7.531604701666523, "train/prior_ent_mag": 66.00128936767578, "train/prior_ent_max": 66.00128936767578, "train/prior_ent_mean": 54.37658334636002, "train/prior_ent_min": 40.71082358051547, "train/prior_ent_std": 3.9571744726716185, "train/rep_loss_mean": 13.355628034193739, "train/rep_loss_std": 8.724772748329656, "train/reward_avg": 0.025849398319348158, "train/reward_loss_mean": 0.054999742409040174, "train/reward_loss_std": 0.25272649880364645, "train/reward_max_data": 1.0179856157988953, "train/reward_max_pred": 1.0081480063980433, "train/reward_neg_acc": 0.9932479330961653, "train/reward_neg_loss": 0.02981622950274417, "train/reward_pos_acc": 0.9681428426461254, "train/reward_pos_loss": 0.8516625024431901, "train/reward_pred": 0.02501133050126352, "train/reward_rate": 0.03071605215827338, "eval_stats/sum_log_reward": 5.662500001490116, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.6875, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 4.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.5625, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.6875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.029299584042747e-07, "report/cont_loss_std": 1.273789894185029e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010765838669613004, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8310464611204225e-07, "report/cont_pred": 0.9960940480232239, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.896828651428223, "report/dyn_loss_std": 8.589090347290039, "report/image_loss_mean": 6.648184299468994, "report/image_loss_std": 13.030208587646484, "report/model_loss_mean": 14.420654296875, "report/model_loss_std": 16.38207244873047, "report/post_ent_mag": 56.56145477294922, "report/post_ent_max": 56.56145477294922, "report/post_ent_mean": 40.39507293701172, "report/post_ent_min": 18.30038070678711, "report/post_ent_std": 6.8993964195251465, "report/prior_ent_mag": 66.0644760131836, "report/prior_ent_max": 66.0644760131836, "report/prior_ent_mean": 54.14002227783203, "report/prior_ent_min": 42.50560760498047, "report/prior_ent_std": 3.6737356185913086, "report/rep_loss_mean": 12.896828651428223, "report/rep_loss_std": 8.589090347290039, "report/reward_avg": 0.0224609375, "report/reward_loss_mean": 0.03437282145023346, "report/reward_loss_std": 0.16224126517772675, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016558170318604, "report/reward_neg_acc": 0.9979979991912842, "report/reward_neg_loss": 0.017161909490823746, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7221207022666931, "report/reward_pred": 0.021474942564964294, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.7954498616745695e-05, "eval/cont_loss_std": 0.0004482245130930096, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.901544788386673e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7535672668600455e-05, "eval/cont_pred": 0.9941238760948181, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.048418045043945, "eval/dyn_loss_std": 9.53785514831543, "eval/image_loss_mean": 21.258275985717773, "eval/image_loss_std": 28.77610206604004, "eval/model_loss_mean": 32.17818069458008, "eval/model_loss_std": 31.5822811126709, "eval/post_ent_mag": 54.483360290527344, "eval/post_ent_max": 54.483360290527344, "eval/post_ent_mean": 39.08873748779297, "eval/post_ent_min": 19.14453125, "eval/post_ent_std": 7.4295477867126465, "eval/prior_ent_mag": 66.0644760131836, "eval/prior_ent_max": 66.0644760131836, "eval/prior_ent_mean": 55.046566009521484, "eval/prior_ent_min": 42.43907928466797, "eval/prior_ent_std": 3.6957273483276367, "eval/rep_loss_mean": 18.048418045043945, "eval/rep_loss_std": 9.53785514831543, "eval/reward_avg": 0.03789062425494194, "eval/reward_loss_mean": 0.09083721041679382, "eval/reward_loss_std": 0.523930013179779, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.999956488609314, "eval/reward_neg_acc": 0.991836667060852, "eval/reward_neg_loss": 0.03788597881793976, "eval/reward_pos_acc": 0.9090909361839294, "eval/reward_pos_loss": 1.2702054977416992, "eval/reward_pred": 0.03597396984696388, "eval/reward_rate": 0.04296875, "replay/size": 637969.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.3781229143320065e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.635512747648618e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1709625603722744e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3041408061981, "timer/env.step_count": 2796.0, "timer/env.step_total": 255.82833123207092, "timer/env.step_frac": 0.2557505470545042, "timer/env.step_avg": 0.09149797254365913, "timer/env.step_min": 0.023090600967407227, "timer/env.step_max": 3.282855272293091, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 11.268259525299072, "timer/replay._sample_frac": 0.011264833429778052, "timer/replay._sample_avg": 0.0005037669673327553, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.010154485702514648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3284.0, "timer/agent.policy_total": 53.17306995391846, "timer/agent.policy_frac": 0.053156902770654796, "timer/agent.policy_avg": 0.016191556015200503, "timer/agent.policy_min": 0.00933527946472168, "timer/agent.policy_max": 0.1106107234954834, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.15217852592468262, "timer/dataset_train_frac": 0.00015213225629760353, "timer/dataset_train_avg": 0.00010885445345113206, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0004227161407470703, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 625.7215926647186, "timer/agent.train_frac": 0.6255313430577388, "timer/agent.train_avg": 0.4475833996171092, "timer/agent.train_min": 0.4336409568786621, "timer/agent.train_max": 1.4900026321411133, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47374486923217773, "timer/agent.report_frac": 0.0004736008278945658, "timer/agent.report_avg": 0.23687243461608887, "timer/agent.report_min": 0.2324352264404297, "timer/agent.report_max": 0.24130964279174805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146168365957368e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.360902090372473}
{"step": 639016, "time": 29427.31813454628, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 639120, "time": 29432.4771463871, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 639568, "time": 29449.085499048233, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 639680, "time": 29454.416266202927, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 639696, "time": 29457.015592098236, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 639816, "time": 29462.771678686142, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 29485.88042640686, "eval_episode/length": 44.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 640016, "time": 29492.682126522064, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 640016, "time": 29494.52140903473, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 640016, "time": 29498.96135210991, "eval_episode/length": 209.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 640016, "time": 29501.233506917953, "eval_episode/length": 226.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 640016, "time": 29503.640513658524, "eval_episode/length": 244.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 640016, "time": 29506.82560157776, "eval_episode/length": 284.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 640016, "time": 29509.844528198242, "eval_episode/length": 317.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9968553459119497}
{"step": 640064, "time": 29511.417443037033, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 640160, "time": 29516.0832695961, "episode/length": 531.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9943609022556391, "episode/intrinsic_return": 0.0}
{"step": 640176, "time": 29518.221881389618, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 641064, "time": 29548.9993224144, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 641416, "time": 29562.28145480156, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 641424, "time": 29564.310552835464, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 641432, "time": 29565.904231786728, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 641440, "time": 29568.025893211365, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 641600, "time": 29574.968894720078, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 641832, "time": 29584.038791656494, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 642040, "time": 29592.518606185913, "episode/length": 364.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 642552, "time": 29611.186816453934, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 642856, "time": 29622.871353387833, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 642984, "time": 29628.755646944046, "episode/length": 193.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 643144, "time": 29635.638588428497, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 643480, "time": 29648.481621980667, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 644264, "time": 29676.086416959763, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 644280, "time": 29678.355726242065, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 644320, "time": 29681.47559404373, "episode/length": 284.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 644800, "time": 29698.942731142044, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 644952, "time": 29705.367628335953, "episode/length": 225.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 645048, "time": 29710.083102941513, "episode/length": 401.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 645080, "time": 29712.737406015396, "episode/length": 457.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9978165938864629, "episode/intrinsic_return": 0.0}
{"step": 645176, "time": 29717.42183637619, "episode/length": 46.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 645712, "time": 29737.154708385468, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 645736, "time": 29739.36030268669, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 645920, "time": 29747.301202058792, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 646112, "time": 29755.30569076538, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995085995085995, "episode/intrinsic_return": 0.0}
{"step": 646304, "time": 29763.216376304626, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 646656, "time": 29777.25395679474, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 646960, "time": 29789.51341152191, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 647000, "time": 29792.246895074844, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 647448, "time": 29810.224007368088, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 647448, "time": 29810.23282122612, "episode/length": 216.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 647608, "time": 29819.002836942673, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 647688, "time": 29823.889859437943, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 648088, "time": 29839.395843029022, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 648272, "time": 29847.87131333351, "episode/length": 82.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 648552, "time": 29858.56378340721, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 648720, "time": 29865.88236474991, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 648728, "time": 29867.494217395782, "episode/length": 159.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 648768, "time": 29870.657762765884, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 649336, "time": 29890.914577960968, "episode/length": 235.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 649384, "time": 29894.075788259506, "episode/length": 211.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 649688, "time": 29905.836551189423, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 29939.39688515663, "eval_episode/length": 200.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 650000, "time": 29942.60927581787, "eval_episode/length": 237.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 650000, "time": 29944.27676177025, "eval_episode/length": 240.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975103734439834}
{"step": 650000, "time": 29945.966623544693, "eval_episode/length": 242.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9876543209876543}
{"step": 650000, "time": 29951.096468925476, "eval_episode/length": 326.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9847094801223242}
{"step": 650000, "time": 29953.888595342636, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 650000, "time": 29955.921454906464, "eval_episode/length": 366.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.989100817438692}
{"step": 650000, "time": 29958.07128071785, "eval_episode/length": 381.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9895287958115183}
{"step": 650096, "time": 29961.36512184143, "episode/length": 192.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 650104, "time": 29962.996171712875, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 650104, "time": 29963.005029439926, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 650112, "time": 29966.770981788635, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 650376, "time": 29976.866554021835, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 651368, "time": 30011.291887044907, "episode/length": 247.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 651408, "time": 30014.452038526535, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 651432, "time": 30016.53794527054, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 651648, "time": 30025.588928222656, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 651704, "time": 30028.86983180046, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 651768, "time": 30032.515623807907, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 651888, "time": 30038.302098751068, "episode/length": 318.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 652224, "time": 30051.06223511696, "episode/length": 230.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 652976, "time": 30077.58496236801, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 653056, "time": 30081.813163518906, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 653064, "time": 30083.443358659744, "episode/length": 203.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 653264, "time": 30091.947784900665, "episode/length": 236.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 653528, "time": 30102.084946155548, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 653536, "time": 30104.393580436707, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 653728, "time": 30112.87714624405, "episode/length": 244.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 653920, "time": 30120.969705820084, "episode/length": 106.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 654320, "time": 30135.81416773796, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 654416, "time": 30140.613047361374, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 654752, "time": 30153.26960158348, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 654808, "time": 30156.437688827515, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 654960, "time": 30163.300864458084, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 654976, "time": 30165.42291522026, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 655752, "time": 30194.088295936584, "episode/length": 228.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 655992, "time": 30203.73649954796, "episode/length": 208.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 656000, "time": 30205.685035467148, "episode/length": 129.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 656056, "time": 30208.748771190643, "episode/length": 204.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 656056, "time": 30208.76070666313, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 656264, "time": 30219.04759168625, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 656336, "time": 30223.268543720245, "episode/length": 42.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 656432, "time": 30228.136710882187, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 656624, "time": 30236.7452647686, "episode/length": 226.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 656888, "time": 30246.69255423546, "episode/length": 418.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904534606205251, "episode/intrinsic_return": 0.0}
{"step": 657416, "time": 30265.918516635895, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 657488, "time": 30270.040029525757, "episode/length": 152.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 657616, "time": 30275.8993370533, "episode/length": 159.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 657648, "time": 30278.412433624268, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 658064, "time": 30294.034351348877, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 658232, "time": 30300.92492389679, "episode/length": 434.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 658424, "time": 30308.80589389801, "episode/length": 96.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 658504, "time": 30313.076148986816, "episode/length": 54.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 658744, "time": 30322.713641881943, "episode/length": 231.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 658840, "time": 30327.475700378418, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 658992, "time": 30334.320692062378, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 659216, "time": 30343.387912750244, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 659360, "time": 30349.988718271255, "episode/length": 412.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 659512, "time": 30356.94733262062, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 659944, "time": 30372.75534582138, "episode/length": 179.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 30397.341737270355, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 660088, "time": 30399.374224185944, "eval_episode/length": 146.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 660088, "time": 30401.644681215286, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 660088, "time": 30403.358502149582, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 660088, "time": 30406.202020168304, "eval_episode/length": 34.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 660088, "time": 30408.318198919296, "eval_episode/length": 43.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 660088, "time": 30410.272503614426, "eval_episode/length": 219.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 660088, "time": 30412.189026355743, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 660089, "time": 30413.21790409088, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6323450159143515, "train/action_min": 0.0, "train/action_std": 3.4092065510926424, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05206375552548303, "train/actor_opt_grad_steps": 40480.0, "train/actor_opt_loss": -5.9255694666118535, "train/adv_mag": 0.7365221911006503, "train/adv_max": 0.7106375354307669, "train/adv_mean": 0.003745098038146992, "train/adv_min": -0.5205144835842981, "train/adv_std": 0.07606963280726362, "train/cont_avg": 0.9946397569444444, "train/cont_loss_mean": 0.00019527230405510973, "train/cont_loss_std": 0.005633141916671405, "train/cont_neg_acc": 0.9886537339952257, "train/cont_neg_loss": 0.02476132801317632, "train/cont_pos_acc": 0.9999781370162963, "train/cont_pos_loss": 6.455735176850205e-05, "train/cont_pred": 0.9946635369901304, "train/cont_rate": 0.9946397569444444, "train/dyn_loss_mean": 13.302683469984267, "train/dyn_loss_std": 8.728679455651177, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7373897565735711, "train/extr_critic_critic_opt_grad_steps": 40480.0, "train/extr_critic_critic_opt_loss": 15729.61339699074, "train/extr_critic_mag": 5.556149899518048, "train/extr_critic_max": 5.556149899518048, "train/extr_critic_mean": 0.9673345172846759, "train/extr_critic_min": -0.2132356776131524, "train/extr_critic_std": 1.1338370323181153, "train/extr_return_normed_mag": 1.8804918536433468, "train/extr_return_normed_max": 1.8804918536433468, "train/extr_return_normed_mean": 0.2943570201043729, "train/extr_return_normed_min": -0.13242462302247685, "train/extr_return_normed_std": 0.33278388767330735, "train/extr_return_rate": 0.4655290558382317, "train/extr_return_raw_mag": 6.569561668678566, "train/extr_return_raw_max": 6.569561668678566, "train/extr_return_raw_mean": 0.9805384322449013, "train/extr_return_raw_min": -0.5234884169366625, "train/extr_return_raw_std": 1.172946442939617, "train/extr_reward_mag": 1.0184957928127714, "train/extr_reward_max": 1.0184957928127714, "train/extr_reward_mean": 0.028864984883478394, "train/extr_reward_min": -0.37999305371884945, "train/extr_reward_std": 0.15935221397214466, "train/image_loss_mean": 6.419675406703242, "train/image_loss_std": 11.045809533860949, "train/model_loss_mean": 14.455670194272642, "train/model_loss_std": 14.500125694274903, "train/model_opt_grad_norm": 56.783297023066766, "train/model_opt_grad_steps": 40441.42222222222, "train/model_opt_loss": 18069.587622974537, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5122727040891295, "train/policy_entropy_max": 2.5122727040891295, "train/policy_entropy_mean": 0.5944619567305953, "train/policy_entropy_min": 0.07937510057731911, "train/policy_entropy_std": 0.6573671396131868, "train/policy_logprob_mag": 7.438383575722023, "train/policy_logprob_max": -0.009455682095830087, "train/policy_logprob_mean": -0.5940656871707352, "train/policy_logprob_min": -7.438383575722023, "train/policy_logprob_std": 1.124695990703724, "train/policy_randomness_mag": 0.8867220136854383, "train/policy_randomness_max": 0.8867220136854383, "train/policy_randomness_mean": 0.2098189816430763, "train/policy_randomness_min": 0.02801592710117499, "train/policy_randomness_std": 0.2320217533244027, "train/post_ent_mag": 57.242946850812, "train/post_ent_max": 57.242946850812, "train/post_ent_mean": 40.968564407913775, "train/post_ent_min": 19.656350863421405, "train/post_ent_std": 7.5512210492734555, "train/prior_ent_mag": 66.01544342041015, "train/prior_ent_max": 66.01544342041015, "train/prior_ent_mean": 54.35124296965422, "train/prior_ent_min": 41.14303156534831, "train/prior_ent_std": 3.897430843777127, "train/rep_loss_mean": 13.302683469984267, "train/rep_loss_std": 8.728679455651177, "train/reward_avg": 0.025950520637410657, "train/reward_loss_mean": 0.054189437531210756, "train/reward_loss_std": 0.2441023234967832, "train/reward_max_data": 1.0185185229336773, "train/reward_max_pred": 1.010573900187457, "train/reward_neg_acc": 0.9932684646712409, "train/reward_neg_loss": 0.0293365186356284, "train/reward_pos_acc": 0.9691219082585087, "train/reward_pos_loss": 0.8412385379826581, "train/reward_pred": 0.025287907370538622, "train/reward_rate": 0.030656828703703703, "train_stats/sum_log_reward": 6.313592226904573, "train_stats/max_log_achievement_collect_coal": 0.038834951456310676, "train_stats/max_log_achievement_collect_drink": 6.815533980582524, "train_stats/max_log_achievement_collect_sapling": 2.6601941747572817, "train_stats/max_log_achievement_collect_stone": 0.5048543689320388, "train_stats/max_log_achievement_collect_wood": 7.038834951456311, "train_stats/max_log_achievement_defeat_skeleton": 0.019417475728155338, "train_stats/max_log_achievement_defeat_zombie": 0.970873786407767, "train_stats/max_log_achievement_eat_cow": 0.05825242718446602, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4563106796116505, "train_stats/max_log_achievement_make_wood_sword": 0.39805825242718446, "train_stats/max_log_achievement_place_plant": 2.3300970873786406, "train_stats/max_log_achievement_place_stone": 0.038834951456310676, "train_stats/max_log_achievement_place_table": 2.1844660194174756, "train_stats/max_log_achievement_wake_up": 1.766990291262136, "train_stats/mean_log_entropy": 0.5598872143377378, "eval_stats/sum_log_reward": 6.0583332777023315, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.2916666666666667, "eval_stats/max_log_achievement_collect_wood": 7.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0833333333333333, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.4166666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.5833333333333334, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.7083333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.1, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.8396634661476128e-06, "report/cont_loss_std": 2.627847970870789e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.391293482010951e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.822236183419591e-06, "report/cont_pred": 0.9951143860816956, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.597898483276367, "report/dyn_loss_std": 9.229497909545898, "report/image_loss_mean": 6.3289079666137695, "report/image_loss_std": 14.563661575317383, "report/model_loss_mean": 14.548004150390625, "report/model_loss_std": 18.081459045410156, "report/post_ent_mag": 55.9173583984375, "report/post_ent_max": 55.9173583984375, "report/post_ent_mean": 40.822021484375, "report/post_ent_min": 19.2618465423584, "report/post_ent_std": 7.77146053314209, "report/prior_ent_mag": 65.92938232421875, "report/prior_ent_max": 65.92938232421875, "report/prior_ent_mean": 54.30445098876953, "report/prior_ent_min": 43.041717529296875, "report/prior_ent_std": 3.343498945236206, "report/rep_loss_mean": 13.597898483276367, "report/rep_loss_std": 9.229497909545898, "report/reward_avg": 0.03076171875, "report/reward_loss_mean": 0.06035497412085533, "report/reward_loss_std": 0.29760506749153137, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016217231750488, "report/reward_neg_acc": 0.9888664484024048, "report/reward_neg_loss": 0.0363197922706604, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7199872732162476, "report/reward_pred": 0.031891413033008575, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.2076958430261584e-06, "eval/cont_loss_std": 2.1010426280554384e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.810613407040364e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.1998307602189016e-06, "eval/cont_pred": 0.9951150417327881, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.31780433654785, "eval/dyn_loss_std": 9.620847702026367, "eval/image_loss_mean": 14.975349426269531, "eval/image_loss_std": 18.365070343017578, "eval/model_loss_mean": 26.055713653564453, "eval/model_loss_std": 22.01980972290039, "eval/post_ent_mag": 57.84073257446289, "eval/post_ent_max": 57.84073257446289, "eval/post_ent_mean": 39.253456115722656, "eval/post_ent_min": 21.187326431274414, "eval/post_ent_std": 7.4294209480285645, "eval/prior_ent_mag": 65.92938232421875, "eval/prior_ent_max": 65.92938232421875, "eval/prior_ent_mean": 55.217262268066406, "eval/prior_ent_min": 45.510597229003906, "eval/prior_ent_std": 3.491086959838867, "eval/rep_loss_mean": 18.31780433654785, "eval/rep_loss_std": 9.620847702026367, "eval/reward_avg": 0.02617187425494194, "eval/reward_loss_mean": 0.08967924118041992, "eval/reward_loss_std": 0.47236526012420654, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017344951629639, "eval/reward_neg_acc": 0.992943525314331, "eval/reward_neg_loss": 0.04929680749773979, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.3415346145629883, "eval/reward_pred": 0.02397509664297104, "eval/reward_rate": 0.03125, "replay/size": 659585.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.3874183311716527e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.575767998515368e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1403326592141885e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1005.1319839954376, "timer/env.step_count": 2702.0, "timer/env.step_total": 238.66071844100952, "timer/env.step_frac": 0.23744216902970708, "timer/env.step_avg": 0.08832743095522189, "timer/env.step_min": 0.022552967071533203, "timer/env.step_max": 3.355569362640381, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 10.867504358291626, "timer/replay._sample_frac": 0.010812017258761268, "timer/replay._sample_avg": 0.0005027527922969849, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.006852626800537109, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3629.0, "timer/agent.policy_total": 59.975165128707886, "timer/agent.policy_frac": 0.059668945057647395, "timer/agent.policy_avg": 0.01652663685001595, "timer/agent.policy_min": 0.00938558578491211, "timer/agent.policy_max": 0.11309456825256348, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.14984989166259766, "timer/dataset_train_frac": 0.00014908479090172683, "timer/dataset_train_avg": 0.00011091775844751862, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0010826587677001953, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 605.7548580169678, "timer/agent.train_frac": 0.6026620062462537, "timer/agent.train_avg": 0.4483751724774003, "timer/agent.train_min": 0.4360532760620117, "timer/agent.train_max": 1.5349595546722412, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4765639305114746, "timer/agent.report_frac": 0.0004741306993506614, "timer/agent.report_avg": 0.2382819652557373, "timer/agent.report_min": 0.2299487590789795, "timer/agent.report_max": 0.24661517143249512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.893855445209139e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.505349649226286}
{"step": 660104, "time": 30413.29840683937, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 660304, "time": 30422.276857614517, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 660360, "time": 30425.40718603134, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 660400, "time": 30428.557682037354, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 660672, "time": 30439.1137008667, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 660912, "time": 30448.656188726425, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 661224, "time": 30460.329126119614, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 661704, "time": 30478.085336446762, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 661952, "time": 30488.164429187775, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 662096, "time": 30494.619279146194, "episode/length": 216.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 662272, "time": 30502.111359119415, "episode/length": 169.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 662440, "time": 30509.011647701263, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 662744, "time": 30520.692108631134, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 662920, "time": 30528.151907444, "episode/length": 314.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 663176, "time": 30538.295090675354, "episode/length": 134.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 663208, "time": 30540.897393226624, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 663272, "time": 30544.611463308334, "episode/length": 164.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 663792, "time": 30565.027627944946, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 664080, "time": 30576.051528453827, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 664336, "time": 30586.069328069687, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 664408, "time": 30589.79660463333, "episode/length": 512.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9844054580896686, "episode/intrinsic_return": 0.0}
{"step": 664504, "time": 30594.518693447113, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 664680, "time": 30601.864109516144, "episode/length": 183.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 664712, "time": 30604.408647298813, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 664904, "time": 30612.813272953033, "episode/length": 49.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 665048, "time": 30619.202372550964, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 665264, "time": 30628.171340227127, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 665576, "time": 30639.80120587349, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 665952, "time": 30654.044186115265, "episode/length": 46.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 666056, "time": 30658.775496721268, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 666176, "time": 30664.517357587814, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 666336, "time": 30671.370574951172, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 666856, "time": 30690.124160528183, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 667008, "time": 30696.97316980362, "episode/length": 262.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 667352, "time": 30709.77916288376, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 667704, "time": 30722.94700527191, "episode/length": 377.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 668000, "time": 30734.575534582138, "episode/length": 242.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 668152, "time": 30741.098911762238, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 668184, "time": 30743.763551950455, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 668216, "time": 30746.409740924835, "episode/length": 254.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 668440, "time": 30755.443018436432, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 668544, "time": 30760.676820755005, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 668984, "time": 30776.615964889526, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 669024, "time": 30779.767912387848, "episode/length": 108.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.944954128440367, "episode/intrinsic_return": 0.0}
{"step": 669072, "time": 30782.928258657455, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 669456, "time": 30797.07358264923, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 670016, "time": 30817.353716135025, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 30840.932999372482, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 670072, "time": 30844.02283358574, "eval_episode/length": 189.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 670072, "time": 30846.02998161316, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 670072, "time": 30847.894270658493, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 670072, "time": 30849.836802959442, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 670072, "time": 30852.23059630394, "eval_episode/length": 217.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 670072, "time": 30857.015696287155, "eval_episode/length": 285.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9825174825174825}
{"step": 670072, "time": 30861.341229200363, "eval_episode/length": 310.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.977491961414791}
{"step": 670312, "time": 30869.473968744278, "episode/length": 261.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 670344, "time": 30872.12733721733, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 670440, "time": 30876.791657686234, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 670440, "time": 30876.799862384796, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 670624, "time": 30886.363152742386, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 670872, "time": 30896.109542369843, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 671024, "time": 30902.85557460785, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 671384, "time": 30916.65264439583, "episode/length": 133.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 671664, "time": 30927.686128377914, "episode/length": 205.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 671816, "time": 30935.496850013733, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 671856, "time": 30938.50043773651, "episode/length": 58.0, "episode/score": 2.0999999567866325, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 672136, "time": 30949.295056819916, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 672216, "time": 30954.058613061905, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 673208, "time": 30989.37421154976, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 673288, "time": 30993.56631755829, "episode/length": 301.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 673584, "time": 31005.263112783432, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 673688, "time": 31010.0545668602, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 673776, "time": 31014.72461628914, "episode/length": 393.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9873096446700508, "episode/intrinsic_return": 0.0}
{"step": 673928, "time": 31021.139453172684, "episode/length": 447.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 674016, "time": 31025.822707891464, "episode/length": 234.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 674336, "time": 31037.88805627823, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 674616, "time": 31048.65526151657, "episode/length": 344.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 674712, "time": 31053.405599594116, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 675016, "time": 31064.94340109825, "episode/length": 37.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 675040, "time": 31067.477413892746, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 675536, "time": 31085.7155752182, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 675792, "time": 31095.790534496307, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 675816, "time": 31097.94341802597, "episode/length": 278.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 675864, "time": 31101.116323709488, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 676080, "time": 31110.0891623497, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 676464, "time": 31124.713252305984, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 676496, "time": 31127.26341843605, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 676848, "time": 31140.58669400215, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 677160, "time": 31152.295288085938, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 677296, "time": 31158.4246134758, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 677848, "time": 31178.158315896988, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 677928, "time": 31182.44268345833, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 678416, "time": 31200.375062942505, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 678512, "time": 31205.08557319641, "episode/length": 255.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 678712, "time": 31213.006537675858, "episode/length": 364.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 678744, "time": 31215.739996671677, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 678840, "time": 31220.442759513855, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 679000, "time": 31227.221177577972, "episode/length": 364.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.989041095890411, "episode/intrinsic_return": 0.0}
{"step": 679408, "time": 31242.434713363647, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31285.83438563347, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 680056, "time": 31287.894538879395, "eval_episode/length": 158.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 680056, "time": 31290.270417928696, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 680056, "time": 31292.51408958435, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 680056, "time": 31294.1527364254, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 680056, "time": 31296.971972942352, "eval_episode/length": 47.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 680056, "time": 31298.71796154976, "eval_episode/length": 230.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 680056, "time": 31300.65870118141, "eval_episode/length": 239.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 680072, "time": 31301.19273328781, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 680088, "time": 31303.35852074623, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 680208, "time": 31309.22229027748, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 680416, "time": 31317.613925218582, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 680848, "time": 31333.502690315247, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 681040, "time": 31341.56513428688, "episode/length": 286.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 681072, "time": 31344.191170930862, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 681152, "time": 31348.372420310974, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 681792, "time": 31371.277135372162, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 681984, "time": 31379.194882154465, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 682368, "time": 31393.53806400299, "episode/length": 47.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 682544, "time": 31401.056405305862, "episode/length": 211.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 682576, "time": 31403.646987199783, "episode/length": 310.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 682728, "time": 31410.01296520233, "episode/length": 206.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 682761, "time": 31413.57272028923, "train_stats/sum_log_reward": 6.671428580511184, "train_stats/max_log_achievement_collect_coal": 0.08571428571428572, "train_stats/max_log_achievement_collect_drink": 6.057142857142857, "train_stats/max_log_achievement_collect_sapling": 2.8, "train_stats/max_log_achievement_collect_stone": 0.8, "train_stats/max_log_achievement_collect_wood": 8.085714285714285, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.0666666666666667, "train_stats/max_log_achievement_eat_cow": 0.1523809523809524, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0761904761904761, "train_stats/max_log_achievement_make_wood_sword": 0.19047619047619047, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.5619047619047617, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.4, "train_stats/max_log_achievement_wake_up": 1.7333333333333334, "train_stats/mean_log_entropy": 0.5400863999412173, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.427447681695643, "train/action_min": 0.0, "train/action_std": 3.1436139227638784, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051511661346319695, "train/actor_opt_grad_steps": 41865.0, "train/actor_opt_loss": -0.9883292183594804, "train/adv_mag": 0.7055502924281107, "train/adv_max": 0.6908566966442995, "train/adv_mean": 0.0042927409568350615, "train/adv_min": -0.48777426023718334, "train/adv_std": 0.07497915169092971, "train/cont_avg": 0.994903994278169, "train/cont_loss_mean": 0.00018590223602598583, "train/cont_loss_std": 0.005664201512724101, "train/cont_neg_acc": 0.993617021445687, "train/cont_neg_loss": 0.024813020071912193, "train/cont_pos_acc": 0.9999792235837855, "train/cont_pos_loss": 7.486781582134277e-05, "train/cont_pred": 0.9949029230735671, "train/cont_rate": 0.994903994278169, "train/dyn_loss_mean": 13.179670031641571, "train/dyn_loss_std": 8.774331519301509, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7594218707420457, "train/extr_critic_critic_opt_grad_steps": 41865.0, "train/extr_critic_critic_opt_loss": 15767.910500110036, "train/extr_critic_mag": 5.53801575848754, "train/extr_critic_max": 5.53801575848754, "train/extr_critic_mean": 0.9586127824346784, "train/extr_critic_min": -0.2192675488095888, "train/extr_critic_std": 1.119868214701263, "train/extr_return_normed_mag": 1.8711347621931156, "train/extr_return_normed_max": 1.8711347621931156, "train/extr_return_normed_mean": 0.29624041558151515, "train/extr_return_normed_min": -0.1306740202429429, "train/extr_return_normed_std": 0.3282358851021444, "train/extr_return_rate": 0.468405704892857, "train/extr_return_raw_mag": 6.520388945727281, "train/extr_return_raw_max": 6.520388945727281, "train/extr_return_raw_mean": 0.9736921959359881, "train/extr_return_raw_min": -0.5300342643135031, "train/extr_return_raw_std": 1.156316642190369, "train/extr_reward_mag": 1.0162428130566235, "train/extr_reward_max": 1.0162428130566235, "train/extr_reward_mean": 0.028330586358747432, "train/extr_reward_min": -0.3875878008318619, "train/extr_reward_std": 0.1572465802162466, "train/image_loss_mean": 6.485562667040758, "train/image_loss_std": 11.35016539399053, "train/model_loss_mean": 14.447047193285446, "train/model_loss_std": 14.828797313529002, "train/model_opt_grad_norm": 55.90097216342358, "train/model_opt_grad_steps": 41825.211267605635, "train/model_opt_loss": 20128.535445092428, "train/model_opt_model_opt_grad_overflow": 0.007042253521126761, "train/model_opt_model_opt_grad_scale": 1399.6478873239437, "train/policy_entropy_mag": 2.532277592470948, "train/policy_entropy_max": 2.532277592470948, "train/policy_entropy_mean": 0.5783866303907313, "train/policy_entropy_min": 0.07937509183522681, "train/policy_entropy_std": 0.6384773619577918, "train/policy_logprob_mag": 7.438383612834232, "train/policy_logprob_max": -0.009455682552406485, "train/policy_logprob_mean": -0.5773298448660005, "train/policy_logprob_min": -7.438383612834232, "train/policy_logprob_std": 1.115561110033116, "train/policy_randomness_mag": 0.8937828658332287, "train/policy_randomness_max": 0.8937828658332287, "train/policy_randomness_mean": 0.20414509855105845, "train/policy_randomness_min": 0.028015924119193788, "train/policy_randomness_std": 0.22535449067051982, "train/post_ent_mag": 57.467618378115375, "train/post_ent_max": 57.467618378115375, "train/post_ent_mean": 41.11015290273747, "train/post_ent_min": 19.55954407974028, "train/post_ent_std": 7.5397367175196255, "train/prior_ent_mag": 66.07249907372703, "train/prior_ent_max": 66.07249907372703, "train/prior_ent_mean": 54.347837018295074, "train/prior_ent_min": 41.255488059890105, "train/prior_ent_std": 3.9389606865359026, "train/rep_loss_mean": 13.179670031641571, "train/rep_loss_std": 8.774331519301509, "train/reward_avg": 0.025478652940774466, "train/reward_loss_mean": 0.053496642261218856, "train/reward_loss_std": 0.24643579387748746, "train/reward_max_data": 1.015492961440288, "train/reward_max_pred": 1.0092684332753572, "train/reward_neg_acc": 0.9927527551919642, "train/reward_neg_loss": 0.028841112615724265, "train/reward_pos_acc": 0.9671118595230748, "train/reward_pos_loss": 0.8515692932505003, "train/reward_pred": 0.02467789275335594, "train/reward_rate": 0.02995020906690141, "eval_stats/sum_log_reward": 5.912499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.0, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.833984116383363e-07, "report/cont_loss_std": 1.6028134268708527e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.040043369168416e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.58770460404412e-08, "report/cont_pred": 0.9931646585464478, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.212648391723633, "report/dyn_loss_std": 8.482137680053711, "report/image_loss_mean": 5.587700843811035, "report/image_loss_std": 13.72572135925293, "report/model_loss_mean": 12.98105239868164, "report/model_loss_std": 16.854949951171875, "report/post_ent_mag": 57.17173767089844, "report/post_ent_max": 57.17173767089844, "report/post_ent_mean": 40.81949996948242, "report/post_ent_min": 17.27897071838379, "report/post_ent_std": 7.451084613800049, "report/prior_ent_mag": 65.96703338623047, "report/prior_ent_max": 65.96703338623047, "report/prior_ent_mean": 53.35176467895508, "report/prior_ent_min": 42.003807067871094, "report/prior_ent_std": 4.037458896636963, "report/rep_loss_mean": 12.212648391723633, "report/rep_loss_std": 8.482137680053711, "report/reward_avg": 0.02988281473517418, "report/reward_loss_mean": 0.06576216220855713, "report/reward_loss_std": 0.35082751512527466, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006332397460938, "report/reward_neg_acc": 0.9959472417831421, "report/reward_neg_loss": 0.04143739864230156, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7146415114402771, "report/reward_pred": 0.03099207766354084, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.005452977027744055, "eval/cont_loss_std": 0.1459074765443802, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.9267341494560242, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3029899239190854e-05, "eval/cont_pred": 0.9957512617111206, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.129852294921875, "eval/dyn_loss_std": 9.612181663513184, "eval/image_loss_mean": 10.662482261657715, "eval/image_loss_std": 13.117986679077148, "eval/model_loss_mean": 20.433271408081055, "eval/model_loss_std": 16.848798751831055, "eval/post_ent_mag": 60.875885009765625, "eval/post_ent_max": 60.875885009765625, "eval/post_ent_mean": 40.76020050048828, "eval/post_ent_min": 19.402881622314453, "eval/post_ent_std": 7.731288909912109, "eval/prior_ent_mag": 65.96703338623047, "eval/prior_ent_max": 65.96703338623047, "eval/prior_ent_mean": 55.31427764892578, "eval/prior_ent_min": 43.61931228637695, "eval/prior_ent_std": 3.832660675048828, "eval/rep_loss_mean": 16.129852294921875, "eval/rep_loss_std": 9.612181663513184, "eval/reward_avg": 0.02871093899011612, "eval/reward_loss_mean": 0.08742418140172958, "eval/reward_loss_std": 0.536899983882904, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035855770111084, "eval/reward_neg_acc": 0.996966540813446, "eval/reward_neg_loss": 0.031429681926965714, "eval/reward_pos_acc": 0.7714285850524902, "eval/reward_pos_loss": 1.6696686744689941, "eval/reward_pred": 0.022096138447523117, "eval/reward_rate": 0.0341796875, "replay/size": 682257.0, "replay/inserts": 22672.0, "replay/samples": 22672.0, "replay/insert_wait_avg": 1.3746820710962223e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.594123892827865e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1843042667894312e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3443512916565, "timer/env.step_count": 2834.0, "timer/env.step_total": 240.66493964195251, "timer/env.step_frac": 0.2405820948868288, "timer/env.step_avg": 0.08492058561819073, "timer/env.step_min": 0.022374629974365234, "timer/env.step_max": 3.323850631713867, "timer/replay._sample_count": 22672.0, "timer/replay._sample_total": 11.44646406173706, "timer/replay._sample_frac": 0.01144252381388194, "timer/replay._sample_avg": 0.0005048722680723827, "timer/replay._sample_min": 0.00037169456481933594, "timer/replay._sample_max": 0.008495569229125977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3385.0, "timer/agent.policy_total": 54.76079177856445, "timer/agent.policy_frac": 0.054741941320363, "timer/agent.policy_avg": 0.01617748649292894, "timer/agent.policy_min": 0.009306907653808594, "timer/agent.policy_max": 0.11432790756225586, "timer/dataset_train_count": 1417.0, "timer/dataset_train_total": 0.1548314094543457, "timer/dataset_train_frac": 0.00015477811141176092, "timer/dataset_train_avg": 0.00010926704972078032, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010716915130615234, "timer/agent.train_count": 1417.0, "timer/agent.train_total": 633.61705327034, "timer/agent.train_frac": 0.6333989415266914, "timer/agent.train_avg": 0.44715388374759346, "timer/agent.train_min": 0.43390464782714844, "timer/agent.train_max": 1.5367603302001953, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4740920066833496, "timer/agent.report_frac": 0.0004739288086859254, "timer/agent.report_avg": 0.2370460033416748, "timer/agent.report_min": 0.23210358619689941, "timer/agent.report_max": 0.2419884204864502, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146041900548566e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.66389765485927}
{"step": 683048, "time": 31422.962522745132, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 683192, "time": 31429.441627025604, "episode/length": 268.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 683368, "time": 31436.830746889114, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 683472, "time": 31442.135256290436, "episode/length": 407.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 683992, "time": 31460.84538793564, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 684424, "time": 31476.843544721603, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 684576, "time": 31483.83986234665, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 684600, "time": 31486.023379087448, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 684688, "time": 31490.842104911804, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 685024, "time": 31503.46410369873, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 685072, "time": 31506.551530361176, "episode/length": 311.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 685528, "time": 31522.926126003265, "episode/length": 269.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 685568, "time": 31525.97577905655, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 685816, "time": 31535.474540948868, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 686224, "time": 31550.85599756241, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 686504, "time": 31561.451284885406, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 686648, "time": 31567.75267124176, "episode/length": 139.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 686728, "time": 31571.886191368103, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 686848, "time": 31577.74819278717, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 687008, "time": 31584.64719939232, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 687032, "time": 31586.863413095474, "episode/length": 292.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 688080, "time": 31623.537322044373, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 688128, "time": 31626.840260267258, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 688192, "time": 31632.30561876297, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 688224, "time": 31635.354471445084, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 688384, "time": 31642.81741142273, "episode/length": 168.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 688512, "time": 31648.580481529236, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 689280, "time": 31675.520780086517, "episode/length": 346.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9827089337175793, "episode/intrinsic_return": 0.0}
{"step": 689368, "time": 31679.69126176834, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 689496, "time": 31685.56765604019, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 689608, "time": 31690.909140348434, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 31725.793327331543, "eval_episode/length": 146.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9863945578231292}
{"step": 690040, "time": 31728.15242624283, "eval_episode/length": 166.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 690040, "time": 31730.98620033264, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 690040, "time": 31733.16303753853, "eval_episode/length": 206.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 690040, "time": 31734.86193728447, "eval_episode/length": 207.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 690040, "time": 31737.160932064056, "eval_episode/length": 221.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 690040, "time": 31738.810299158096, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 690040, "time": 31738.819344758987, "eval_episode/length": 222.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 690160, "time": 31743.064450979233, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 690192, "time": 31745.797026872635, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 690440, "time": 31755.343784093857, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 690648, "time": 31763.852051973343, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 690808, "time": 31770.675296783447, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 690848, "time": 31773.851531267166, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 691064, "time": 31782.471870183945, "episode/length": 181.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 691312, "time": 31792.50259232521, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 691688, "time": 31806.268542289734, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 691920, "time": 31816.292584180832, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 691992, "time": 31820.083093881607, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 692256, "time": 31830.753292560577, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 692568, "time": 31842.548251628876, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 692592, "time": 31845.130747318268, "episode/length": 299.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 693064, "time": 31862.244976758957, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 693232, "time": 31869.59617114067, "episode/length": 239.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 693368, "time": 31875.39842247963, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 693480, "time": 31880.828669309616, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 693520, "time": 31883.96081852913, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 693704, "time": 31891.435715198517, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 693800, "time": 31896.190299987793, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 694072, "time": 31906.77858400345, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 694592, "time": 31925.857387304306, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 695048, "time": 31942.365011692047, "episode/length": 195.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 695056, "time": 31944.403117895126, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 695080, "time": 31946.641400575638, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 695296, "time": 31955.519639492035, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 695304, "time": 31957.62198638916, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 695504, "time": 31966.54456305504, "episode/length": 55.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 696136, "time": 31988.793548107147, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 696568, "time": 32006.41675925255, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 696688, "time": 32012.20321559906, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 696928, "time": 32021.690992116928, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 697104, "time": 32028.984411001205, "episode/length": 256.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 697176, "time": 32032.764103889465, "episode/length": 433.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 697808, "time": 32056.044303894043, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 697808, "time": 32056.05233669281, "episode/length": 109.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 697824, "time": 32060.00717830658, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 698008, "time": 32067.490713834763, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 698160, "time": 32074.34372663498, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 698480, "time": 32086.73388814926, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 699064, "time": 32107.591067314148, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 699416, "time": 32120.93141913414, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 699512, "time": 32125.63159918785, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 699512, "time": 32125.640784740448, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 699688, "time": 32134.880336523056, "episode/length": 232.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32167.608580827713, "eval_episode/length": 154.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9870967741935484}
{"step": 700024, "time": 32171.992564439774, "eval_episode/length": 219.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 700024, "time": 32173.863130807877, "eval_episode/length": 226.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 700024, "time": 32176.29942893982, "eval_episode/length": 247.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 700024, "time": 32180.23369026184, "eval_episode/length": 303.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9868421052631579}
{"step": 700024, "time": 32182.33381319046, "eval_episode/length": 313.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9777070063694268}
{"step": 700024, "time": 32186.323071479797, "eval_episode/length": 372.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9973190348525469}
{"step": 700024, "time": 32188.59676527977, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.95}
{"step": 700032, "time": 32189.10071182251, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 700304, "time": 32199.642468452454, "episode/length": 778.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9897304236200257, "episode/intrinsic_return": 0.0}
{"step": 700352, "time": 32202.84663963318, "episode/length": 82.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 700992, "time": 32225.617822170258, "episode/length": 240.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 701312, "time": 32237.650755882263, "episode/length": 353.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 701336, "time": 32239.91058945656, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 701336, "time": 32239.91932296753, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 701728, "time": 32256.383563756943, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 702208, "time": 32273.72207760811, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 702368, "time": 32280.614984035492, "episode/length": 368.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.986449864498645, "episode/intrinsic_return": 0.0}
{"step": 702424, "time": 32283.77432203293, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 702576, "time": 32290.757400035858, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 702664, "time": 32295.566570997238, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 702704, "time": 32299.238013505936, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 702896, "time": 32307.114238739014, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 703736, "time": 32336.19334077835, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 703992, "time": 32346.34005522728, "episode/length": 331.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9789156626506024, "episode/intrinsic_return": 0.0}
{"step": 704000, "time": 32348.357896327972, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 704048, "time": 32351.45354962349, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 704088, "time": 32354.190259456635, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 704096, "time": 32356.14523792267, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 704224, "time": 32362.077579021454, "episode/length": 165.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 704408, "time": 32369.481397390366, "episode/length": 228.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 705160, "time": 32397.476495027542, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 705352, "time": 32405.47042274475, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 705529, "time": 32413.777069330215, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.293632399867958, "train/action_min": 0.0, "train/action_std": 3.1286526280389704, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05049994724317336, "train/actor_opt_grad_steps": 43285.0, "train/actor_opt_loss": -3.3634257072083362, "train/adv_mag": 0.6970367410653074, "train/adv_max": 0.6813266644595375, "train/adv_mean": 0.00390077894978827, "train/adv_min": -0.4814709017814045, "train/adv_std": 0.07353081278712817, "train/cont_avg": 0.994690801056338, "train/cont_loss_mean": 0.00032066479110826675, "train/cont_loss_std": 0.00957739345435296, "train/cont_neg_acc": 0.9909293047079804, "train/cont_neg_loss": 0.026826477392853817, "train/cont_pos_acc": 0.9999584635378609, "train/cont_pos_loss": 0.00015706656259307453, "train/cont_pred": 0.9947051951583002, "train/cont_rate": 0.994690801056338, "train/dyn_loss_mean": 13.186380775881485, "train/dyn_loss_std": 8.727476999793254, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7386970788660184, "train/extr_critic_critic_opt_grad_steps": 43285.0, "train/extr_critic_critic_opt_loss": 15774.117744553258, "train/extr_critic_mag": 5.557764197739077, "train/extr_critic_max": 5.557764197739077, "train/extr_critic_mean": 0.9615142240490712, "train/extr_critic_min": -0.20766775037201357, "train/extr_critic_std": 1.1180546233351802, "train/extr_return_normed_mag": 1.8620988080199337, "train/extr_return_normed_max": 1.8620988080199337, "train/extr_return_normed_mean": 0.29047128022976326, "train/extr_return_normed_min": -0.12813040989280586, "train/extr_return_normed_std": 0.3232503725399434, "train/extr_return_rate": 0.47261455319297146, "train/extr_return_raw_mag": 6.594702912048555, "train/extr_return_raw_max": 6.594702912048555, "train/extr_return_raw_mean": 0.9754436654104314, "train/extr_return_raw_min": -0.5211669200322997, "train/extr_return_raw_std": 1.1558196737732687, "train/extr_reward_mag": 1.0169608156446, "train/extr_reward_max": 1.0169608156446, "train/extr_reward_mean": 0.02707156598646666, "train/extr_reward_min": -0.3830072216584649, "train/extr_reward_std": 0.1550961428020202, "train/image_loss_mean": 6.442493193586108, "train/image_loss_std": 11.131735976313202, "train/model_loss_mean": 14.40832207908093, "train/model_loss_std": 14.60131672066702, "train/model_opt_grad_norm": 53.83437689928941, "train/model_opt_grad_steps": 43243.711267605635, "train/model_opt_loss": 18291.185746313822, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.4084507042253, "train/policy_entropy_mag": 2.5260304111829948, "train/policy_entropy_max": 2.5260304111829948, "train/policy_entropy_mean": 0.5522703725687215, "train/policy_entropy_min": 0.07937508144638908, "train/policy_entropy_std": 0.6072936765324901, "train/policy_logprob_mag": 7.438383629624273, "train/policy_logprob_max": -0.009455670891198474, "train/policy_logprob_mean": -0.5521396106817353, "train/policy_logprob_min": -7.438383629624273, "train/policy_logprob_std": 1.1022281688703617, "train/policy_randomness_mag": 0.8915778826659834, "train/policy_randomness_max": 0.8915778826659834, "train/policy_randomness_mean": 0.19492720497745863, "train/policy_randomness_min": 0.02801592044637237, "train/policy_randomness_std": 0.2143480193237184, "train/post_ent_mag": 57.32199064442809, "train/post_ent_max": 57.32199064442809, "train/post_ent_mean": 41.24316075821997, "train/post_ent_min": 19.646893380393443, "train/post_ent_std": 7.535697910147653, "train/prior_ent_mag": 66.09552007325938, "train/prior_ent_max": 66.09552007325938, "train/prior_ent_mean": 54.478969735159, "train/prior_ent_min": 41.61986826507138, "train/prior_ent_std": 3.9285367341108723, "train/rep_loss_mean": 13.186380775881485, "train/rep_loss_std": 8.727476999793254, "train/reward_avg": 0.024611437981817086, "train/reward_loss_mean": 0.05367981655601884, "train/reward_loss_std": 0.23895395641595546, "train/reward_max_data": 1.0183098635203403, "train/reward_max_pred": 1.0091208001257668, "train/reward_neg_acc": 0.9930600557528751, "train/reward_neg_loss": 0.030094557074488888, "train/reward_pos_acc": 0.9719301537728645, "train/reward_pos_loss": 0.8386203466166913, "train/reward_pred": 0.02391343068620059, "train/reward_rate": 0.029413787411971832, "train_stats/sum_log_reward": 6.903921594806746, "train_stats/max_log_achievement_collect_coal": 0.049019607843137254, "train_stats/max_log_achievement_collect_drink": 5.911764705882353, "train_stats/max_log_achievement_collect_sapling": 2.5392156862745097, "train_stats/max_log_achievement_collect_stone": 0.7549019607843137, "train_stats/max_log_achievement_collect_wood": 8.598039215686274, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 1.1862745098039216, "train_stats/max_log_achievement_eat_cow": 0.10784313725490197, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1372549019607843, "train_stats/max_log_achievement_make_wood_sword": 0.2647058823529412, "train_stats/max_log_achievement_place_furnace": 0.00980392156862745, "train_stats/max_log_achievement_place_plant": 2.1666666666666665, "train_stats/max_log_achievement_place_stone": 0.0196078431372549, "train_stats/max_log_achievement_place_table": 2.7450980392156863, "train_stats/max_log_achievement_wake_up": 1.696078431372549, "train_stats/mean_log_entropy": 0.5120191337431178, "eval_stats/sum_log_reward": 7.1000001430511475, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_sapling": 3.1875, "eval_stats/max_log_achievement_collect_stone": 1.3125, "eval_stats/max_log_achievement_collect_wood": 8.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.3125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.6148264876392204e-06, "report/cont_loss_std": 3.3918870030902326e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003692614263854921, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.730750227579847e-07, "report/cont_pred": 0.9960950613021851, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.504732131958008, "report/dyn_loss_std": 8.203287124633789, "report/image_loss_mean": 5.518357753753662, "report/image_loss_std": 8.278462409973145, "report/model_loss_mean": 13.670668601989746, "report/model_loss_std": 11.760847091674805, "report/post_ent_mag": 58.34103775024414, "report/post_ent_max": 58.34103775024414, "report/post_ent_mean": 39.88337326049805, "report/post_ent_min": 19.76494598388672, "report/post_ent_std": 7.125929832458496, "report/prior_ent_mag": 65.9240951538086, "report/prior_ent_max": 65.9240951538086, "report/prior_ent_mean": 53.80148696899414, "report/prior_ent_min": 44.18669128417969, "report/prior_ent_std": 3.5871779918670654, "report/rep_loss_mean": 13.504732131958008, "report/rep_loss_std": 8.203287124633789, "report/reward_avg": 0.03046874888241291, "report/reward_loss_mean": 0.04946950450539589, "report/reward_loss_std": 0.1743949055671692, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018668174743652, "report/reward_neg_acc": 0.9848178625106812, "report/reward_neg_loss": 0.025968037545681, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6944542527198792, "report/reward_pred": 0.031579215079545975, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 7.286300984787886e-08, "eval/cont_loss_std": 3.1680770007369574e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.666156984167174e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.348539471900949e-08, "eval/cont_pred": 0.9990234375, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.497955322265625, "eval/dyn_loss_std": 9.87341594696045, "eval/image_loss_mean": 12.801227569580078, "eval/image_loss_std": 19.684951782226562, "eval/model_loss_mean": 23.992900848388672, "eval/model_loss_std": 22.915328979492188, "eval/post_ent_mag": 53.75901794433594, "eval/post_ent_max": 53.75901794433594, "eval/post_ent_mean": 38.186309814453125, "eval/post_ent_min": 19.542293548583984, "eval/post_ent_std": 7.236959457397461, "eval/prior_ent_mag": 65.9240951538086, "eval/prior_ent_max": 65.9240951538086, "eval/prior_ent_mean": 54.40876770019531, "eval/prior_ent_min": 45.286251068115234, "eval/prior_ent_std": 3.427692174911499, "eval/rep_loss_mean": 18.497955322265625, "eval/rep_loss_std": 9.87341594696045, "eval/reward_avg": 0.03085937537252903, "eval/reward_loss_mean": 0.09289751201868057, "eval/reward_loss_std": 0.674461841583252, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001772165298462, "eval/reward_neg_acc": 0.9959676861763, "eval/reward_neg_loss": 0.008483328856527805, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 2.7097373008728027, "eval/reward_pred": 0.018695130944252014, "eval/reward_rate": 0.03125, "replay/size": 705025.0, "replay/inserts": 22768.0, "replay/samples": 22768.0, "replay/insert_wait_avg": 1.3759541662327437e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.580429085190667e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1858983047660165e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1919658184052, "timer/env.step_count": 2846.0, "timer/env.step_total": 239.8091757297516, "timer/env.step_frac": 0.23976314940055352, "timer/env.step_avg": 0.08426183265275881, "timer/env.step_min": 0.022574663162231445, "timer/env.step_max": 3.448615789413452, "timer/replay._sample_count": 22768.0, "timer/replay._sample_total": 11.530828475952148, "timer/replay._sample_frac": 0.011528615375866443, "timer/replay._sample_avg": 0.0005064488965193319, "timer/replay._sample_min": 0.0004267692565917969, "timer/replay._sample_max": 0.025620222091674805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3457.0, "timer/agent.policy_total": 56.09510374069214, "timer/agent.policy_frac": 0.05608433746495097, "timer/agent.policy_avg": 0.016226526971562665, "timer/agent.policy_min": 0.009521007537841797, "timer/agent.policy_max": 0.10329818725585938, "timer/dataset_train_count": 1423.0, "timer/dataset_train_total": 0.15873169898986816, "timer/dataset_train_frac": 0.00015870123377764413, "timer/dataset_train_avg": 0.00011154722346441895, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010066032409667969, "timer/agent.train_count": 1423.0, "timer/agent.train_total": 636.6280274391174, "timer/agent.train_frac": 0.6365058400746079, "timer/agent.train_avg": 0.44738441843929544, "timer/agent.train_min": 0.43289875984191895, "timer/agent.train_max": 1.651479959487915, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4707341194152832, "timer/agent.report_frac": 0.00047064377189843344, "timer/agent.report_avg": 0.2353670597076416, "timer/agent.report_min": 0.2295064926147461, "timer/agent.report_max": 0.2412276268005371, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7889619901173475e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.76334480463675}
{"step": 705608, "time": 32416.22612786293, "episode/length": 201.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 705752, "time": 32422.667404413223, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 705904, "time": 32429.42989039421, "episode/length": 186.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 705944, "time": 32432.161364793777, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 705944, "time": 32432.171067237854, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 706872, "time": 32466.206140756607, "episode/length": 115.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 707088, "time": 32475.117302894592, "episode/length": 26.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 707152, "time": 32478.936264276505, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 707304, "time": 32485.300590991974, "episode/length": 243.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 707416, "time": 32490.631733894348, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 707440, "time": 32493.229949235916, "episode/length": 429.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 707472, "time": 32495.92858362198, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 707640, "time": 32502.861605882645, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 708056, "time": 32518.33109641075, "episode/length": 51.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 708224, "time": 32526.21243929863, "episode/length": 308.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 708360, "time": 32532.063768148422, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 708736, "time": 32546.348508358, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 708920, "time": 32553.769930124283, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 709088, "time": 32561.233763694763, "episode/length": 201.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 709248, "time": 32568.126679182053, "episode/length": 225.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 709416, "time": 32575.0991666317, "episode/length": 282.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 709768, "time": 32588.333342313766, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32619.666370630264, "eval_episode/length": 164.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 710008, "time": 32621.335483312607, "eval_episode/length": 167.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 710008, "time": 32623.301916360855, "eval_episode/length": 178.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.994413407821229}
{"step": 710008, "time": 32625.250063180923, "eval_episode/length": 187.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 710008, "time": 32627.055257081985, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 710008, "time": 32629.367443084717, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 710008, "time": 32631.337528944016, "eval_episode/length": 217.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 710008, "time": 32633.08202266693, "eval_episode/length": 221.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 710024, "time": 32633.62322950363, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 710424, "time": 32648.529002428055, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 710448, "time": 32651.108382463455, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 710824, "time": 32665.043788909912, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 710944, "time": 32670.797896385193, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 711136, "time": 32678.71503162384, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 711144, "time": 32680.400809288025, "episode/length": 364.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9917808219178083, "episode/intrinsic_return": 0.0}
{"step": 711216, "time": 32684.556831121445, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 711640, "time": 32700.23529982567, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 712296, "time": 32723.66344499588, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 712320, "time": 32726.197085618973, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 712680, "time": 32739.599395513535, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 712744, "time": 32744.864620685577, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 712936, "time": 32752.97288250923, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 712976, "time": 32756.104469060898, "episode/length": 368.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 713008, "time": 32758.6930475235, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 713048, "time": 32761.302087068558, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 713928, "time": 32792.47535943985, "episode/length": 109.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 714096, "time": 32799.76877593994, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 714216, "time": 32804.99641108513, "episode/length": 183.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 714304, "time": 32809.7281537056, "episode/length": 247.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 714392, "time": 32813.99485206604, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 714544, "time": 32820.73275351524, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 714736, "time": 32828.64355015755, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 714776, "time": 32831.28823804855, "episode/length": 309.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 714936, "time": 32838.032683610916, "episode/length": 89.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 715256, "time": 32850.18095421791, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 715888, "time": 32872.97879219055, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 715968, "time": 32877.2073636055, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 716216, "time": 32886.81059551239, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 716472, "time": 32896.97184920311, "episode/length": 270.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 716472, "time": 32896.98089814186, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 716680, "time": 32907.30385708809, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 716688, "time": 32909.20089554787, "episode/length": 459.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9804347826086957, "episode/intrinsic_return": 0.0}
{"step": 716848, "time": 32916.06950354576, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 717768, "time": 32948.07560253143, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 717928, "time": 32955.651429891586, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 718040, "time": 32961.42605495453, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 718048, "time": 32963.59575533867, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 718224, "time": 32970.98477220535, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 718304, "time": 32975.26875948906, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 718432, "time": 32981.15149760246, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 719184, "time": 33007.58479452133, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 719376, "time": 33015.487131118774, "episode/length": 200.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 719416, "time": 33018.12030982971, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 719824, "time": 33033.64201140404, "episode/length": 199.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 719904, "time": 33037.814765930176, "episode/length": 402.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950372208436724, "episode/intrinsic_return": 0.0}
{"step": 720040, "time": 33043.569071769714, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33067.644288778305, "eval_episode/length": 152.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 720096, "time": 33071.339626312256, "eval_episode/length": 183.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 720096, "time": 33073.9912071228, "eval_episode/length": 196.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 720096, "time": 33077.253606796265, "eval_episode/length": 221.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 720096, "time": 33079.16688466072, "eval_episode/length": 226.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 720096, "time": 33081.701966285706, "eval_episode/length": 250.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 720096, "time": 33083.81935548782, "eval_episode/length": 262.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9847908745247148}
{"step": 720096, "time": 33086.100967884064, "eval_episode/length": 278.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 720216, "time": 33089.873450517654, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 720360, "time": 33096.126341581345, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 720488, "time": 33101.75857973099, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 720728, "time": 33111.335181713104, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 721080, "time": 33126.01228952408, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 721480, "time": 33140.835144758224, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 721816, "time": 33153.53107094765, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 721968, "time": 33160.42817687988, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 722112, "time": 33166.87788486481, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 722168, "time": 33170.18730926514, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 722552, "time": 33184.359212875366, "episode/length": 257.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 723088, "time": 33204.29581284523, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 723200, "time": 33209.57668042183, "episode/length": 308.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 723336, "time": 33215.33268237114, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 723640, "time": 33226.9441652298, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 723728, "time": 33231.70247173309, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 723856, "time": 33237.54779338837, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 723872, "time": 33239.57546710968, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 723872, "time": 33239.582946777344, "episode/length": 66.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 724360, "time": 33258.75778436661, "episode/length": 280.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 724600, "time": 33268.21769976616, "episode/length": 188.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 725016, "time": 33284.013530254364, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 725432, "time": 33299.65242433548, "episode/length": 133.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 725544, "time": 33305.372091293335, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 725568, "time": 33307.98605275154, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9608695652173913, "episode/intrinsic_return": 0.0}
{"step": 725688, "time": 33313.377427101135, "episode/length": 255.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 725904, "time": 33322.32907915115, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 726256, "time": 33335.45518231392, "episode/length": 297.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 726960, "time": 33360.308864831924, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 726984, "time": 33362.45580911636, "episode/length": 176.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 727104, "time": 33368.30862522125, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 727200, "time": 33373.09877562523, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 727360, "time": 33380.08418893814, "episode/length": 181.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 727440, "time": 33384.32221531868, "episode/length": 29.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 727696, "time": 33394.36958169937, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 727784, "time": 33398.67370676994, "episode/length": 345.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 728169, "time": 33414.057252407074, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.083981366224692, "train/action_min": 0.0, "train/action_std": 2.9047794274880854, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05246164715311057, "train/actor_opt_grad_steps": 44705.0, "train/actor_opt_loss": -2.5827042300936203, "train/adv_mag": 0.6996650561480455, "train/adv_max": 0.6840905484179376, "train/adv_mean": 0.004590731624132235, "train/adv_min": -0.48656834745910804, "train/adv_std": 0.07471434063684772, "train/cont_avg": 0.9948008362676056, "train/cont_loss_mean": 9.169201039652639e-05, "train/cont_loss_std": 0.00275022192834154, "train/cont_neg_acc": 0.9974569640528987, "train/cont_neg_loss": 0.00961808891769047, "train/cont_pos_acc": 0.9999930862809571, "train/cont_pos_loss": 2.6772919132284e-05, "train/cont_pred": 0.9948072563594496, "train/cont_rate": 0.9948008362676056, "train/dyn_loss_mean": 13.052547011576907, "train/dyn_loss_std": 8.705061892388573, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.744990618505948, "train/extr_critic_critic_opt_grad_steps": 44705.0, "train/extr_critic_critic_opt_loss": 15904.006980358714, "train/extr_critic_mag": 5.586446970281466, "train/extr_critic_max": 5.586446970281466, "train/extr_critic_mean": 1.0035253322460282, "train/extr_critic_min": -0.21119804701334993, "train/extr_critic_std": 1.1280575239322554, "train/extr_return_normed_mag": 1.8759363075377236, "train/extr_return_normed_max": 1.8759363075377236, "train/extr_return_normed_mean": 0.2976050348558896, "train/extr_return_normed_min": -0.13269678679045657, "train/extr_return_normed_std": 0.3250826187956501, "train/extr_return_rate": 0.5393605406435442, "train/extr_return_raw_mag": 6.68990219143075, "train/extr_return_raw_max": 6.68990219143075, "train/extr_return_raw_mean": 1.020020669614765, "train/extr_return_raw_min": -0.5256804713690785, "train/extr_return_raw_std": 1.1678070724010468, "train/extr_reward_mag": 1.0213783744355323, "train/extr_reward_max": 1.0213783744355323, "train/extr_reward_mean": 0.027541877013224532, "train/extr_reward_min": -0.40730997206459585, "train/extr_reward_std": 0.1566402304025603, "train/image_loss_mean": 6.348640482190629, "train/image_loss_std": 10.796686850802999, "train/model_loss_mean": 14.234864416256757, "train/model_loss_std": 14.227410652268102, "train/model_opt_grad_norm": 54.35644194105981, "train/model_opt_grad_steps": 44662.47887323944, "train/model_opt_loss": 18887.959802761885, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1329.225352112676, "train/policy_entropy_mag": 2.5231244161095416, "train/policy_entropy_max": 2.5231244161095416, "train/policy_entropy_mean": 0.5128567982727373, "train/policy_entropy_min": 0.0793750790852896, "train/policy_entropy_std": 0.5772844347315775, "train/policy_logprob_mag": 7.438383690068419, "train/policy_logprob_max": -0.009455668392368185, "train/policy_logprob_mean": -0.5118635135217452, "train/policy_logprob_min": -7.438383690068419, "train/policy_logprob_std": 1.078139300917236, "train/policy_randomness_mag": 0.8905521950251619, "train/policy_randomness_max": 0.8905521950251619, "train/policy_randomness_mean": 0.18101594355744374, "train/policy_randomness_min": 0.028015919528167014, "train/policy_randomness_std": 0.20375607404070842, "train/post_ent_mag": 57.35025220521739, "train/post_ent_max": 57.35025220521739, "train/post_ent_mean": 41.38176485518335, "train/post_ent_min": 19.618696414249044, "train/post_ent_std": 7.603165643315919, "train/prior_ent_mag": 66.12487325534015, "train/prior_ent_max": 66.12487325534015, "train/prior_ent_mean": 54.53421248852367, "train/prior_ent_min": 41.23093374010543, "train/prior_ent_std": 3.944408443612112, "train/rep_loss_mean": 13.052547011576907, "train/rep_loss_std": 8.705061892388573, "train/reward_avg": 0.025436702092558567, "train/reward_loss_mean": 0.054603972773946505, "train/reward_loss_std": 0.2489400148181848, "train/reward_max_data": 1.0140845104002616, "train/reward_max_pred": 1.009301353508318, "train/reward_neg_acc": 0.9927583760778669, "train/reward_neg_loss": 0.030212191045021927, "train/reward_pos_acc": 0.9687364932516931, "train/reward_pos_loss": 0.8439023796941193, "train/reward_pred": 0.024778026047910393, "train/reward_rate": 0.03010838468309859, "train_stats/sum_log_reward": 6.958490683011851, "train_stats/max_log_achievement_collect_coal": 0.0660377358490566, "train_stats/max_log_achievement_collect_drink": 5.89622641509434, "train_stats/max_log_achievement_collect_sapling": 2.4716981132075473, "train_stats/max_log_achievement_collect_stone": 0.9056603773584906, "train_stats/max_log_achievement_collect_wood": 9.452830188679245, "train_stats/max_log_achievement_defeat_skeleton": 0.009433962264150943, "train_stats/max_log_achievement_defeat_zombie": 1.2735849056603774, "train_stats/max_log_achievement_eat_cow": 0.08490566037735849, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9150943396226414, "train_stats/max_log_achievement_make_wood_sword": 0.32075471698113206, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.047169811320755, "train_stats/max_log_achievement_place_stone": 0.009433962264150943, "train_stats/max_log_achievement_place_table": 2.707547169811321, "train_stats/max_log_achievement_wake_up": 1.5660377358490567, "train_stats/mean_log_entropy": 0.47778201201614345, "eval_stats/sum_log_reward": 7.60000017285347, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 5.6875, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 2.125, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00010800681775435805, "report/cont_loss_std": 0.003334761131554842, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0012600142508745193, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00010462188220117241, "report/cont_pred": 0.9969750642776489, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.706924438476562, "report/dyn_loss_std": 8.57887077331543, "report/image_loss_mean": 5.752169132232666, "report/image_loss_std": 10.107455253601074, "report/model_loss_mean": 14.033594131469727, "report/model_loss_std": 13.76134967803955, "report/post_ent_mag": 55.438133239746094, "report/post_ent_max": 55.438133239746094, "report/post_ent_mean": 40.09687805175781, "report/post_ent_min": 21.402111053466797, "report/post_ent_std": 7.529173374176025, "report/prior_ent_mag": 66.3603515625, "report/prior_ent_max": 66.3603515625, "report/prior_ent_mean": 53.840415954589844, "report/prior_ent_min": 42.58649826049805, "report/prior_ent_std": 3.403663158416748, "report/rep_loss_mean": 13.706924438476562, "report/rep_loss_std": 8.57887077331543, "report/reward_avg": 0.03730468824505806, "report/reward_loss_mean": 0.057162754237651825, "report/reward_loss_std": 0.24771125614643097, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0096304416656494, "report/reward_neg_acc": 0.9877800941467285, "report/reward_neg_loss": 0.026534823700785637, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7732729315757751, "report/reward_pred": 0.037662070244550705, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.1829989716716227e-06, "eval/cont_loss_std": 3.584252772270702e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001147574046626687, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.238222738375043e-08, "eval/cont_pred": 0.9990245699882507, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 15.937240600585938, "eval/dyn_loss_std": 10.083456039428711, "eval/image_loss_mean": 11.479547500610352, "eval/image_loss_std": 14.15561294555664, "eval/model_loss_mean": 21.135326385498047, "eval/model_loss_std": 17.712373733520508, "eval/post_ent_mag": 56.74982452392578, "eval/post_ent_max": 56.74982452392578, "eval/post_ent_mean": 40.77681350708008, "eval/post_ent_min": 20.547697067260742, "eval/post_ent_std": 8.307538032531738, "eval/prior_ent_mag": 66.3603515625, "eval/prior_ent_max": 66.3603515625, "eval/prior_ent_mean": 54.85432434082031, "eval/prior_ent_min": 45.65302658081055, "eval/prior_ent_std": 3.6767117977142334, "eval/rep_loss_mean": 15.937240600585938, "eval/rep_loss_std": 10.083456039428711, "eval/reward_avg": 0.03544921800494194, "eval/reward_loss_mean": 0.09343264997005463, "eval/reward_loss_std": 0.5607513785362244, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023083686828613, "eval/reward_neg_acc": 0.976673424243927, "eval/reward_neg_loss": 0.022825507447123528, "eval/reward_pos_acc": 0.7368420958518982, "eval/reward_pos_loss": 1.9255021810531616, "eval/reward_pred": 0.027919262647628784, "eval/reward_rate": 0.037109375, "replay/size": 727665.0, "replay/inserts": 22640.0, "replay/samples": 22640.0, "replay/insert_wait_avg": 1.3660415743770533e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.474169714290767e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.221478818181508e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2688601016998, "timer/env.step_count": 2830.0, "timer/env.step_total": 244.284086227417, "timer/env.step_frac": 0.24421842563666335, "timer/env.step_avg": 0.08631946509802721, "timer/env.step_min": 0.022884130477905273, "timer/env.step_max": 3.4774656295776367, "timer/replay._sample_count": 22640.0, "timer/replay._sample_total": 11.318669080734253, "timer/replay._sample_frac": 0.011315626760172715, "timer/replay._sample_avg": 0.0004999412138133504, "timer/replay._sample_min": 0.000408172607421875, "timer/replay._sample_max": 0.011363744735717773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3331.0, "timer/agent.policy_total": 55.46408247947693, "timer/agent.policy_frac": 0.05544917440880621, "timer/agent.policy_avg": 0.016650880360095145, "timer/agent.policy_min": 0.00933384895324707, "timer/agent.policy_max": 0.12388491630554199, "timer/dataset_train_count": 1415.0, "timer/dataset_train_total": 0.1547527313232422, "timer/dataset_train_frac": 0.00015471113567157142, "timer/dataset_train_avg": 0.00010936588786094855, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.000274658203125, "timer/agent.train_count": 1415.0, "timer/agent.train_total": 631.0769350528717, "timer/agent.train_frac": 0.6309073092495437, "timer/agent.train_avg": 0.4459907668218175, "timer/agent.train_min": 0.43329882621765137, "timer/agent.train_max": 1.5892789363861084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4773988723754883, "timer/agent.report_frac": 0.000477270553365972, "timer/agent.report_avg": 0.23869943618774414, "timer/agent.report_min": 0.23181819915771484, "timer/agent.report_max": 0.24558067321777344, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0986084361410434e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 22.63362219530668}
{"step": 728728, "time": 33432.47820353508, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 728808, "time": 33436.70987582207, "episode/length": 227.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 729008, "time": 33445.51899456978, "episode/length": 205.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 729088, "time": 33450.33645820618, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 729112, "time": 33454.2912273407, "episode/length": 563.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.99822695035461, "episode/intrinsic_return": 0.0}
{"step": 729328, "time": 33463.16307139397, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 729504, "time": 33470.577724933624, "episode/length": 257.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 730048, "time": 33491.85247588158, "episode/length": 385.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 33514.149114370346, "eval_episode/length": 166.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 730080, "time": 33516.78827667236, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 730080, "time": 33516.79610514641, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 730080, "time": 33520.95532441139, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 730080, "time": 33522.86778998375, "eval_episode/length": 203.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 730080, "time": 33525.56000447273, "eval_episode/length": 230.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 730080, "time": 33527.32045817375, "eval_episode/length": 234.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9872340425531915}
{"step": 730080, "time": 33529.0304415226, "eval_episode/length": 237.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9831932773109243}
{"step": 730184, "time": 33532.244139909744, "episode/length": 171.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 730624, "time": 33548.54923534393, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 730824, "time": 33556.6269569397, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 730920, "time": 33561.48707270622, "episode/length": 225.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 731304, "time": 33575.70824146271, "episode/length": 246.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 731456, "time": 33582.482885599136, "episode/length": 340.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9882697947214076, "episode/intrinsic_return": 0.0}
{"step": 731656, "time": 33590.44820857048, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 731976, "time": 33602.608152627945, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 732016, "time": 33605.727138996124, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9325842696629213, "episode/intrinsic_return": 0.0}
{"step": 732360, "time": 33618.49990105629, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 732408, "time": 33621.68845295906, "episode/length": 414.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9975903614457832, "episode/intrinsic_return": 0.0}
{"step": 732680, "time": 33632.3813393116, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 732928, "time": 33642.46924114227, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 733112, "time": 33650.0785946846, "episode/length": 181.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 733144, "time": 33652.64018988609, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 733680, "time": 33672.278611660004, "episode/length": 356.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9943977591036415, "episode/intrinsic_return": 0.0}
{"step": 733856, "time": 33679.86009120941, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 733960, "time": 33684.68770360947, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 734048, "time": 33689.44037413597, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 734376, "time": 33701.761293411255, "episode/length": 245.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 734496, "time": 33708.03647565842, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 734736, "time": 33717.78535270691, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 735392, "time": 33741.519954919815, "episode/length": 284.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 735616, "time": 33751.25411820412, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 735656, "time": 33753.94236469269, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 735752, "time": 33758.70178985596, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 735800, "time": 33761.94669556618, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 735952, "time": 33768.91799211502, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 736312, "time": 33782.12507081032, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 736480, "time": 33789.414633989334, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 736664, "time": 33796.898141384125, "episode/length": 158.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 737024, "time": 33811.36750292778, "episode/length": 158.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 737080, "time": 33814.61599731445, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 737192, "time": 33819.83394598961, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 737352, "time": 33828.12346839905, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 737880, "time": 33847.488817453384, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 737904, "time": 33850.491472005844, "episode/length": 262.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 738152, "time": 33860.65958094597, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 738352, "time": 33869.18978071213, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 738520, "time": 33876.0404009819, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 738688, "time": 33883.432631492615, "episode/length": 41.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 738776, "time": 33887.64709043503, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 738864, "time": 33892.46842336655, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 739120, "time": 33902.46033978462, "episode/length": 261.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 739440, "time": 33914.615107774734, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 739480, "time": 33917.295706510544, "episode/length": 196.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 739872, "time": 33932.225803136826, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 33959.1352314949, "eval_episode/length": 145.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.958904109589041}
{"step": 740064, "time": 33961.51854610443, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 740064, "time": 33963.16332530975, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 740064, "time": 33964.96875810623, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 740064, "time": 33966.8954744339, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 740064, "time": 33968.6860537529, "eval_episode/length": 189.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 740064, "time": 33971.152842760086, "eval_episode/length": 213.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 740064, "time": 33978.78685760498, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 740152, "time": 33981.51067566872, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 740368, "time": 33990.55255317688, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 740376, "time": 33992.10776281357, "episode/length": 231.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 740592, "time": 34001.089547395706, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 740680, "time": 34005.2895758152, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 740888, "time": 34013.826693058014, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 741424, "time": 34033.39269113541, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 741640, "time": 34041.971551418304, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 741824, "time": 34049.90763950348, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 742328, "time": 34068.034333229065, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 742608, "time": 34079.319371938705, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 742672, "time": 34083.044340610504, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 742872, "time": 34091.09872293472, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 743000, "time": 34096.89523601532, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 743016, "time": 34099.0787525177, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 743064, "time": 34102.284098148346, "episode/length": 177.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 743376, "time": 34115.201288700104, "episode/length": 44.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 743616, "time": 34124.72930312157, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 743816, "time": 34133.347046375275, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 743976, "time": 34140.20340061188, "episode/length": 660.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9954614220877458, "episode/intrinsic_return": 0.0}
{"step": 744376, "time": 34155.00359630585, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 744480, "time": 34160.31373167038, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 744928, "time": 34176.81971478462, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 744992, "time": 34180.48179984093, "episode/length": 248.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 745040, "time": 34183.55999851227, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 745288, "time": 34193.25836157799, "episode/length": 238.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 745464, "time": 34200.67993021011, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 745584, "time": 34208.003982782364, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 745952, "time": 34221.85692644119, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 746120, "time": 34228.83922314644, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 746304, "time": 34236.61301898956, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 746440, "time": 34242.549013376236, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 746560, "time": 34248.35738825798, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 746792, "time": 34257.44963669777, "episode/length": 165.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 746960, "time": 34264.86503505707, "episode/length": 208.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 747112, "time": 34271.30755734444, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 747256, "time": 34277.687101602554, "episode/length": 141.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 747408, "time": 34285.10255455971, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 748192, "time": 34312.90412712097, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 748208, "time": 34314.98930287361, "episode/length": 205.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 748232, "time": 34317.15974187851, "episode/length": 223.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 748336, "time": 34322.42041540146, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 748456, "time": 34327.73308944702, "episode/length": 30.0, "episode/score": 1.1000000163912773, "episode/reward_rate": 0.9032258064516129, "episode/intrinsic_return": 0.0}
{"step": 748904, "time": 34344.05715084076, "episode/length": 223.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9866071428571429, "episode/intrinsic_return": 0.0}
{"step": 748928, "time": 34346.76811623573, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34406.26610779762, "eval_episode/length": 142.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.972027972027972}
{"step": 750048, "time": 34409.43037343025, "eval_episode/length": 179.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 750048, "time": 34411.05634045601, "eval_episode/length": 181.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 750048, "time": 34412.75351405144, "eval_episode/length": 185.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 750048, "time": 34415.518917798996, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 750048, "time": 34418.0531129837, "eval_episode/length": 234.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 750048, "time": 34420.05742478371, "eval_episode/length": 243.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9795081967213115}
{"step": 750048, "time": 34426.39293861389, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 750049, "time": 34426.97301244736, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.078110298101049, "train/action_min": 0.0, "train/action_std": 3.043060158291002, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05206051180615042, "train/actor_opt_grad_steps": 46100.0, "train/actor_opt_loss": 3.7956242740263035, "train/adv_mag": 0.704320322858156, "train/adv_max": 0.6869748580629809, "train/adv_mean": 0.006334037973862447, "train/adv_min": -0.5043366523119654, "train/adv_std": 0.07610391670443716, "train/cont_avg": 0.9950245209854015, "train/cont_loss_mean": 0.0002690019555602346, "train/cont_loss_std": 0.008216271174907796, "train/cont_neg_acc": 0.9884862717050705, "train/cont_neg_loss": 0.03071544036074357, "train/cont_pos_acc": 0.9999713197241734, "train/cont_pos_loss": 0.00010424305047620129, "train/cont_pred": 0.9950308351621141, "train/cont_rate": 0.9950245209854015, "train/dyn_loss_mean": 13.188443483227362, "train/dyn_loss_std": 8.798680938943459, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7888194674993083, "train/extr_critic_critic_opt_grad_steps": 46100.0, "train/extr_critic_critic_opt_loss": 16002.889099566606, "train/extr_critic_mag": 5.685710635498492, "train/extr_critic_max": 5.685710635498492, "train/extr_critic_mean": 1.1432674079045761, "train/extr_critic_min": -0.21271069728545028, "train/extr_critic_std": 1.1367094595066822, "train/extr_return_normed_mag": 1.8895108299533816, "train/extr_return_normed_max": 1.8895108299533816, "train/extr_return_normed_mean": 0.3234689514132312, "train/extr_return_normed_min": -0.1385575660987057, "train/extr_return_normed_std": 0.32378657956192963, "train/extr_return_rate": 0.6569528747214018, "train/extr_return_raw_mag": 6.855276723847772, "train/extr_return_raw_max": 6.855276723847772, "train/extr_return_raw_mean": 1.1663197165858137, "train/extr_return_raw_min": -0.5133650603085539, "train/extr_return_raw_std": 1.176720798450665, "train/extr_reward_mag": 1.0221576481840036, "train/extr_reward_max": 1.0221576481840036, "train/extr_reward_mean": 0.02852550271327478, "train/extr_reward_min": -0.3810034859789549, "train/extr_reward_std": 0.1587664383823854, "train/image_loss_mean": 6.3679964246541045, "train/image_loss_std": 11.171329463485383, "train/model_loss_mean": 14.33521460094591, "train/model_loss_std": 14.631809895926148, "train/model_opt_grad_norm": 55.04270947680754, "train/model_opt_grad_steps": 46056.06569343065, "train/model_opt_loss": 17465.691356352647, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 1218.065693430657, "train/policy_entropy_mag": 2.545592285420773, "train/policy_entropy_max": 2.545592285420773, "train/policy_entropy_mean": 0.4916398864592949, "train/policy_entropy_min": 0.07937508402732167, "train/policy_entropy_std": 0.5644157565858242, "train/policy_logprob_mag": 7.438383669748793, "train/policy_logprob_max": -0.009455674830960097, "train/policy_logprob_mean": -0.4916577889536419, "train/policy_logprob_min": -7.438383669748793, "train/policy_logprob_std": 1.060903414322512, "train/policy_randomness_mag": 0.8984823683752631, "train/policy_randomness_max": 0.8984823683752631, "train/policy_randomness_mean": 0.1735273044909874, "train/policy_randomness_min": 0.028015921341024177, "train/policy_randomness_std": 0.19921399457176237, "train/post_ent_mag": 57.59463498192112, "train/post_ent_max": 57.59463498192112, "train/post_ent_mean": 41.286202312385946, "train/post_ent_min": 19.259375474748822, "train/post_ent_std": 7.661502204672264, "train/prior_ent_mag": 66.28535517114793, "train/prior_ent_max": 66.28535517114793, "train/prior_ent_mean": 54.523264335019746, "train/prior_ent_min": 41.71258065996379, "train/prior_ent_std": 3.9142044895756856, "train/rep_loss_mean": 13.188443483227362, "train/rep_loss_std": 8.798680938943459, "train/reward_avg": 0.02587819319000862, "train/reward_loss_mean": 0.053883056054367634, "train/reward_loss_std": 0.24504149982528964, "train/reward_max_data": 1.020437961077168, "train/reward_max_pred": 1.0113308238287042, "train/reward_neg_acc": 0.9925730841873336, "train/reward_neg_loss": 0.02916328107299161, "train/reward_pos_acc": 0.9681415414288096, "train/reward_pos_loss": 0.8482149978623773, "train/reward_pred": 0.025051569566130638, "train/reward_rate": 0.030351847627737225, "train_stats/sum_log_reward": 7.250000075101853, "train_stats/max_log_achievement_collect_coal": 0.07, "train_stats/max_log_achievement_collect_drink": 5.22, "train_stats/max_log_achievement_collect_sapling": 2.31, "train_stats/max_log_achievement_collect_stone": 1.28, "train_stats/max_log_achievement_collect_wood": 11.67, "train_stats/max_log_achievement_defeat_skeleton": 0.01, "train_stats/max_log_achievement_defeat_zombie": 1.36, "train_stats/max_log_achievement_eat_cow": 0.2, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01, "train_stats/max_log_achievement_make_wood_pickaxe": 1.42, "train_stats/max_log_achievement_make_wood_sword": 1.75, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.86, "train_stats/max_log_achievement_place_stone": 0.02, "train_stats/max_log_achievement_place_table": 2.89, "train_stats/max_log_achievement_wake_up": 1.5, "train_stats/mean_log_entropy": 0.4564358513057232, "train_stats/max_log_achievement_make_stone_sword": 0.021505376344086023, "eval_stats/sum_log_reward": 7.433333416779836, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 4.958333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.8333333333333335, "eval_stats/max_log_achievement_collect_stone": 0.5, "eval_stats/max_log_achievement_collect_wood": 12.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 2.0833333333333335, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6666666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00014152959920465946, "report/cont_loss_std": 0.003390980651602149, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04360107704997063, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3832598597218748e-05, "report/cont_pred": 0.9971789121627808, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.716135025024414, "report/dyn_loss_std": 8.968113899230957, "report/image_loss_mean": 6.677482604980469, "report/image_loss_std": 8.93116569519043, "report/model_loss_mean": 14.346813201904297, "report/model_loss_std": 12.538375854492188, "report/post_ent_mag": 59.54906463623047, "report/post_ent_max": 59.54906463623047, "report/post_ent_mean": 42.76704025268555, "report/post_ent_min": 19.266780853271484, "report/post_ent_std": 8.383341789245605, "report/prior_ent_mag": 66.36334991455078, "report/prior_ent_max": 66.36334991455078, "report/prior_ent_mean": 55.62892150878906, "report/prior_ent_min": 42.388458251953125, "report/prior_ent_std": 3.7326717376708984, "report/rep_loss_mean": 12.716135025024414, "report/rep_loss_std": 8.968113899230957, "report/reward_avg": 0.02587890625, "report/reward_loss_mean": 0.03950844705104828, "report/reward_loss_std": 0.22026540338993073, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0009455680847168, "report/reward_neg_acc": 0.9969848990440369, "report/reward_neg_loss": 0.01569073647260666, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8567022681236267, "report/reward_pred": 0.02593071013689041, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.773657115540118e-06, "eval/cont_loss_std": 5.5355321819661185e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006303653935901821, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5454929780389648e-06, "eval/cont_pred": 0.9980466961860657, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.328994750976562, "eval/dyn_loss_std": 9.802760124206543, "eval/image_loss_mean": 11.099830627441406, "eval/image_loss_std": 17.459741592407227, "eval/model_loss_mean": 21.611980438232422, "eval/model_loss_std": 21.313335418701172, "eval/post_ent_mag": 56.10367965698242, "eval/post_ent_max": 56.10367965698242, "eval/post_ent_mean": 38.96902847290039, "eval/post_ent_min": 18.178720474243164, "eval/post_ent_std": 7.282603740692139, "eval/prior_ent_mag": 66.36334991455078, "eval/prior_ent_max": 66.36334991455078, "eval/prior_ent_mean": 54.29747772216797, "eval/prior_ent_min": 45.048728942871094, "eval/prior_ent_std": 3.449795722961426, "eval/rep_loss_mean": 17.328994750976562, "eval/rep_loss_std": 9.802760124206543, "eval/reward_avg": 0.03916015475988388, "eval/reward_loss_mean": 0.11474940180778503, "eval/reward_loss_std": 0.6575189828872681, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0032939910888672, "eval/reward_neg_acc": 0.9887869358062744, "eval/reward_neg_loss": 0.04813390225172043, "eval/reward_pos_acc": 0.8372092843055725, "eval/reward_pos_loss": 1.6345123052597046, "eval/reward_pred": 0.03515242785215378, "eval/reward_rate": 0.0419921875, "replay/size": 749545.0, "replay/inserts": 21880.0, "replay/samples": 21872.0, "replay/insert_wait_avg": 1.39215528638097e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.492766034978101e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.144465175700337e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1012.8970563411713, "timer/env.step_count": 2735.0, "timer/env.step_total": 236.7794213294983, "timer/env.step_frac": 0.23376454679886496, "timer/env.step_avg": 0.08657382863967031, "timer/env.step_min": 0.023036479949951172, "timer/env.step_max": 3.40879225730896, "timer/replay._sample_count": 21872.0, "timer/replay._sample_total": 10.954698085784912, "timer/replay._sample_frac": 0.010815213665795345, "timer/replay._sample_avg": 0.0005008548868775106, "timer/replay._sample_min": 0.0003924369812011719, "timer/replay._sample_max": 0.025503158569335938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3693.0, "timer/agent.policy_total": 60.9016637802124, "timer/agent.policy_frac": 0.06012621262836316, "timer/agent.policy_avg": 0.016491108524292555, "timer/agent.policy_min": 0.009445905685424805, "timer/agent.policy_max": 0.1289224624633789, "timer/dataset_train_count": 1367.0, "timer/dataset_train_total": 0.15227794647216797, "timer/dataset_train_frac": 0.00015033901571619992, "timer/dataset_train_avg": 0.0001113957179752509, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0005614757537841797, "timer/agent.train_count": 1367.0, "timer/agent.train_total": 612.7975418567657, "timer/agent.train_frac": 0.6049948886911948, "timer/agent.train_avg": 0.4482791088930254, "timer/agent.train_min": 0.43228793144226074, "timer/agent.train_max": 2.257046699523926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4696037769317627, "timer/agent.report_frac": 0.00046362438709031785, "timer/agent.report_avg": 0.23480188846588135, "timer/agent.report_min": 0.22803354263305664, "timer/agent.report_max": 0.24157023429870605, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.083515118024454e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.601132661260138}
{"step": 750072, "time": 34427.668957710266, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 750176, "time": 34433.22406220436, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9855491329479769, "episode/intrinsic_return": 0.0}
{"step": 750400, "time": 34442.781690597534, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 750496, "time": 34447.51096200943, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 750632, "time": 34453.93154120445, "episode/length": 540.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9852125693160814, "episode/intrinsic_return": 0.0}
{"step": 750720, "time": 34459.17915225029, "episode/length": 223.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 751096, "time": 34473.43084144592, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 751792, "time": 34498.309061050415, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 751928, "time": 34504.19894814491, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 751960, "time": 34506.80705285072, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 751968, "time": 34508.85078430176, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 752520, "time": 34528.50004315376, "episode/length": 235.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 752592, "time": 34532.66547417641, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 752592, "time": 34532.71000790596, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 753120, "time": 34553.485916376114, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 753240, "time": 34558.775470495224, "episode/length": 158.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 753360, "time": 34564.43830180168, "episode/length": 627.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952229299363057, "episode/intrinsic_return": 0.0}
{"step": 753408, "time": 34567.47595453262, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 753496, "time": 34571.62676239014, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 753536, "time": 34574.72272372246, "episode/length": 51.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 753968, "time": 34592.29204392433, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 754256, "time": 34603.36255145073, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 754288, "time": 34605.917036771774, "episode/length": 211.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 754520, "time": 34615.120166778564, "episode/length": 249.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 754640, "time": 34620.94536495209, "episode/length": 43.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 754832, "time": 34628.91438961029, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 754984, "time": 34635.274356365204, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 755112, "time": 34641.133343696594, "episode/length": 201.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 755152, "time": 34644.271872997284, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 755624, "time": 34661.19976687431, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 756248, "time": 34683.687517642975, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 756360, "time": 34688.90234899521, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 756480, "time": 34694.63428068161, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 756496, "time": 34696.67736005783, "episode/length": 246.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 757128, "time": 34719.10617733002, "episode/length": 80.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 757192, "time": 34722.76786565781, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 757768, "time": 34743.445249557495, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 757800, "time": 34746.11099219322, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 757984, "time": 34753.938596487045, "episode/length": 465.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9978540772532188, "episode/intrinsic_return": 0.0}
{"step": 758328, "time": 34766.74032616615, "episode/length": 337.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.0}
{"step": 758856, "time": 34785.82497191429, "episode/length": 294.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 758880, "time": 34788.38045454025, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 759432, "time": 34807.97816848755, "episode/length": 574.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9895652173913043, "episode/intrinsic_return": 0.0}
{"step": 759456, "time": 34810.56741857529, "episode/length": 183.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 759616, "time": 34817.60423088074, "episode/length": 226.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 34854.422478437424, "eval_episode/length": 189.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 760032, "time": 34856.202568769455, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 760032, "time": 34857.887627363205, "eval_episode/length": 197.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 760032, "time": 34859.6126396656, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 760032, "time": 34862.18937635422, "eval_episode/length": 223.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 760032, "time": 34864.07821011543, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 760032, "time": 34865.82670378685, "eval_episode/length": 236.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 760032, "time": 34872.40556383133, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9551282051282052}
{"step": 760040, "time": 34872.459342718124, "episode/length": 355.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859550561797753, "episode/intrinsic_return": 0.0}
{"step": 760088, "time": 34875.720056056976, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 760128, "time": 34878.93172264099, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 760336, "time": 34887.44934415817, "episode/length": 320.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 760384, "time": 34890.599157094955, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 760960, "time": 34911.60054063797, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 761520, "time": 34931.8792347908, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 761544, "time": 34934.0808866024, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 761640, "time": 34938.96760940552, "episode/length": 199.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 761928, "time": 34951.72778534889, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 762384, "time": 34968.82980465889, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 762520, "time": 34974.556792497635, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 762584, "time": 34978.249239206314, "episode/length": 132.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 763088, "time": 34996.875586509705, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 763408, "time": 35009.342411756516, "episode/length": 496.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9818913480885312, "episode/intrinsic_return": 0.0}
{"step": 763488, "time": 35013.624126672745, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 763600, "time": 35018.940747737885, "episode/length": 407.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 763624, "time": 35021.217176914215, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 763952, "time": 35034.14937400818, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 764296, "time": 35046.87402510643, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 764552, "time": 35056.954624414444, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 765000, "time": 35073.57962393761, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 765024, "time": 35076.155542850494, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 765200, "time": 35083.50395154953, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 765272, "time": 35087.20235681534, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 765704, "time": 35103.149495363235, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 765712, "time": 35105.19678759575, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 766120, "time": 35120.05821752548, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 766336, "time": 35128.954730033875, "episode/length": 341.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 766448, "time": 35134.370404958725, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 766760, "time": 35146.080048561096, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 767424, "time": 35170.029766082764, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 767552, "time": 35175.90362048149, "episode/length": 293.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 767760, "time": 35184.51146030426, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 767784, "time": 35186.79150676727, "episode/length": 313.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777070063694268, "episode/intrinsic_return": 0.0}
{"step": 767864, "time": 35191.09865164757, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 768136, "time": 35201.816893815994, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 768272, "time": 35208.12841105461, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 768304, "time": 35210.8063416481, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 769304, "time": 35245.56889009476, "episode/length": 128.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 769400, "time": 35250.282462358475, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 769416, "time": 35252.33039402962, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 769792, "time": 35266.679476737976, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 769912, "time": 35272.20200967789, "episode/length": 255.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35297.311589717865, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 770016, "time": 35299.428473711014, "eval_episode/length": 172.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9884393063583815}
{"step": 770016, "time": 35301.34278059006, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 770016, "time": 35303.68619322777, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 770016, "time": 35305.85421180725, "eval_episode/length": 209.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 770016, "time": 35308.012303590775, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 770016, "time": 35309.75748991966, "eval_episode/length": 230.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 770016, "time": 35312.65957903862, "eval_episode/length": 263.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 770352, "time": 35325.404834747314, "episode/length": 320.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 770616, "time": 35335.46431326866, "episode/length": 163.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 771048, "time": 35351.286143541336, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 771128, "time": 35355.44943356514, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 771312, "time": 35363.56754612923, "episode/length": 443.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9977477477477478, "episode/intrinsic_return": 0.0}
{"step": 771760, "time": 35379.94415521622, "episode/length": 431.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9884259259259259, "episode/intrinsic_return": 0.0}
{"step": 771760, "time": 35379.95488977432, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 771784, "time": 35383.82794594765, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 771896, "time": 35389.214455366135, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 772112, "time": 35398.23682785034, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 772776, "time": 35421.753845214844, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 772865, "time": 35426.97640633583, "train_stats/sum_log_reward": 6.970000038146972, "train_stats/max_log_achievement_collect_coal": 0.01, "train_stats/max_log_achievement_collect_drink": 6.57, "train_stats/max_log_achievement_collect_sapling": 2.21, "train_stats/max_log_achievement_collect_stone": 0.32, "train_stats/max_log_achievement_collect_wood": 14.45, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.57, "train_stats/max_log_achievement_eat_cow": 0.22, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.25, "train_stats/max_log_achievement_make_wood_sword": 4.29, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.89, "train_stats/max_log_achievement_place_stone": 0.01, "train_stats/max_log_achievement_place_table": 3.47, "train_stats/max_log_achievement_wake_up": 1.44, "train_stats/mean_log_entropy": 0.4504394344985485, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.082260776573504, "train/action_min": 0.0, "train/action_std": 2.969887181067131, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04934996007089044, "train/actor_opt_grad_steps": 47495.0, "train/actor_opt_loss": 4.050897725136347, "train/adv_mag": 0.6673013964589213, "train/adv_max": 0.6499732919562031, "train/adv_mean": 0.006636938444399406, "train/adv_min": -0.46287056341977184, "train/adv_std": 0.07317437176448359, "train/cont_avg": 0.9944707306338029, "train/cont_loss_mean": 0.00031265146847758875, "train/cont_loss_std": 0.009424550824452177, "train/cont_neg_acc": 0.9925217993662391, "train/cont_neg_loss": 0.028573258343241422, "train/cont_pos_acc": 0.9999584820069057, "train/cont_pos_loss": 0.00015202131479158935, "train/cont_pred": 0.9944699624894371, "train/cont_rate": 0.9944707306338029, "train/dyn_loss_mean": 13.040822022397753, "train/dyn_loss_std": 8.845037107736292, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.834571553787715, "train/extr_critic_critic_opt_grad_steps": 47495.0, "train/extr_critic_critic_opt_loss": 16009.96181778169, "train/extr_critic_mag": 5.949221013297497, "train/extr_critic_max": 5.949221013297497, "train/extr_critic_mean": 1.402514294839241, "train/extr_critic_min": -0.19392552929864804, "train/extr_critic_std": 1.240041025087867, "train/extr_return_normed_mag": 1.8356104283265664, "train/extr_return_normed_max": 1.8356104283265664, "train/extr_return_normed_mean": 0.3544995510871981, "train/extr_return_normed_min": -0.136311063359321, "train/extr_return_normed_std": 0.3252358014734698, "train/extr_return_rate": 0.7288379736349616, "train/extr_return_raw_mag": 7.276744338828073, "train/extr_return_raw_max": 7.276744338828073, "train/extr_return_raw_mean": 1.4288561054518525, "train/extr_return_raw_min": -0.51117569869253, "train/extr_return_raw_std": 1.2852458152132975, "train/extr_reward_mag": 1.0195972936254152, "train/extr_reward_max": 1.0195972936254152, "train/extr_reward_mean": 0.03052637556200506, "train/extr_reward_min": -0.39675303244254956, "train/extr_reward_std": 0.16354532739226246, "train/image_loss_mean": 6.28382258348062, "train/image_loss_std": 11.05262244923014, "train/model_loss_mean": 14.164519538342113, "train/model_loss_std": 14.572117630864533, "train/model_opt_grad_norm": 51.31021780363271, "train/model_opt_grad_steps": 47449.0, "train/model_opt_loss": 12080.496764277068, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 849.4718309859155, "train/policy_entropy_mag": 2.5022815415557003, "train/policy_entropy_max": 2.5022815415557003, "train/policy_entropy_mean": 0.4581932387721371, "train/policy_entropy_min": 0.07937508223342224, "train/policy_entropy_std": 0.5346954414542292, "train/policy_logprob_mag": 7.438383686710411, "train/policy_logprob_max": -0.009455671724141903, "train/policy_logprob_mean": -0.4585431392343951, "train/policy_logprob_min": -7.438383686710411, "train/policy_logprob_std": 1.0361072803047342, "train/policy_randomness_mag": 0.8831955719162041, "train/policy_randomness_max": 0.8831955719162041, "train/policy_randomness_mean": 0.1617221068328535, "train/policy_randomness_min": 0.028015920734951193, "train/policy_randomness_std": 0.18872402650369724, "train/post_ent_mag": 57.612055550158864, "train/post_ent_max": 57.612055550158864, "train/post_ent_mean": 41.4396194941561, "train/post_ent_min": 19.3409493406054, "train/post_ent_std": 7.696015948980627, "train/prior_ent_mag": 66.26587349260357, "train/prior_ent_max": 66.26587349260357, "train/prior_ent_mean": 54.513631552038056, "train/prior_ent_min": 41.321494706919495, "train/prior_ent_std": 3.9506980785181827, "train/rep_loss_mean": 13.040822022397753, "train/rep_loss_std": 8.845037107736292, "train/reward_avg": 0.026966879177104, "train/reward_loss_mean": 0.055891045946365514, "train/reward_loss_std": 0.24533725739784643, "train/reward_max_data": 1.016901412480314, "train/reward_max_pred": 1.010679284451713, "train/reward_neg_acc": 0.992442228004966, "train/reward_neg_loss": 0.03043548095787705, "train/reward_pos_acc": 0.9712072497522327, "train/reward_pos_loss": 0.83601739121155, "train/reward_pred": 0.026326507434878552, "train/reward_rate": 0.031772667253521125, "eval_stats/sum_log_reward": 6.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 13.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.375, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 4.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.75, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.8811309928423725e-05, "report/cont_loss_std": 0.00038402783684432507, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0034660715609788895, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8963918364534038e-06, "report/cont_pred": 0.9951322078704834, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.162372589111328, "report/dyn_loss_std": 8.750030517578125, "report/image_loss_mean": 6.938276767730713, "report/image_loss_std": 12.055849075317383, "report/model_loss_mean": 15.493542671203613, "report/model_loss_std": 15.379708290100098, "report/post_ent_mag": 59.015472412109375, "report/post_ent_max": 59.015472412109375, "report/post_ent_mean": 40.84162139892578, "report/post_ent_min": 20.62835121154785, "report/post_ent_std": 7.449516773223877, "report/prior_ent_mag": 66.67695617675781, "report/prior_ent_max": 66.67695617675781, "report/prior_ent_mean": 54.634674072265625, "report/prior_ent_min": 39.83176803588867, "report/prior_ent_std": 4.4872660636901855, "report/rep_loss_mean": 14.162372589111328, "report/rep_loss_std": 8.750030517578125, "report/reward_avg": 0.02890625037252903, "report/reward_loss_mean": 0.05782429873943329, "report/reward_loss_std": 0.2807141840457916, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0738837718963623, "report/reward_neg_acc": 0.9878543019294739, "report/reward_neg_loss": 0.028107542544603348, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.8733841776847839, "report/reward_pred": 0.028931086882948875, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0024531709495931864, "eval/cont_loss_std": 0.07824663817882538, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.6262831091880798, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.779117939004209e-06, "eval/cont_pred": 0.9969838857650757, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.969778060913086, "eval/dyn_loss_std": 10.096288681030273, "eval/image_loss_mean": 11.449209213256836, "eval/image_loss_std": 19.01909828186035, "eval/model_loss_mean": 21.735828399658203, "eval/model_loss_std": 22.620119094848633, "eval/post_ent_mag": 56.64628601074219, "eval/post_ent_max": 56.64628601074219, "eval/post_ent_mean": 40.476375579833984, "eval/post_ent_min": 20.655723571777344, "eval/post_ent_std": 7.846802711486816, "eval/prior_ent_mag": 66.67695617675781, "eval/prior_ent_max": 66.67695617675781, "eval/prior_ent_mean": 55.037994384765625, "eval/prior_ent_min": 45.40983963012695, "eval/prior_ent_std": 3.723871946334839, "eval/rep_loss_mean": 16.969778060913086, "eval/rep_loss_std": 10.096288681030273, "eval/reward_avg": 0.03525390475988388, "eval/reward_loss_mean": 0.10229778289794922, "eval/reward_loss_std": 0.5903163552284241, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023672580718994, "eval/reward_neg_acc": 0.9827236533164978, "eval/reward_neg_loss": 0.03405962884426117, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 1.7809566259384155, "eval/reward_pred": 0.030871517956256866, "eval/reward_rate": 0.0390625, "replay/size": 772361.0, "replay/inserts": 22816.0, "replay/samples": 22816.0, "replay/insert_wait_avg": 1.3917224771678867e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.371790445870805e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1615239538947103e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9941494464874, "timer/env.step_count": 2852.0, "timer/env.step_total": 234.59896850585938, "timer/env.step_frac": 0.23460034104770874, "timer/env.step_avg": 0.08225770284216669, "timer/env.step_min": 0.023250102996826172, "timer/env.step_max": 3.3516409397125244, "timer/replay._sample_count": 22816.0, "timer/replay._sample_total": 11.421693325042725, "timer/replay._sample_frac": 0.011421760148661681, "timer/replay._sample_avg": 0.0005006001632644953, "timer/replay._sample_min": 0.00035309791564941406, "timer/replay._sample_max": 0.02842855453491211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3474.0, "timer/agent.policy_total": 56.23446035385132, "timer/agent.policy_frac": 0.056234789358495726, "timer/agent.policy_avg": 0.016187236716710223, "timer/agent.policy_min": 0.009443044662475586, "timer/agent.policy_max": 0.11463165283203125, "timer/dataset_train_count": 1426.0, "timer/dataset_train_total": 0.15234160423278809, "timer/dataset_train_frac": 0.00015234249552071037, "timer/dataset_train_avg": 0.0001068314195180842, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.00026607513427734375, "timer/agent.train_count": 1426.0, "timer/agent.train_total": 639.2438418865204, "timer/agent.train_frac": 0.6392475818387057, "timer/agent.train_avg": 0.44827758898072956, "timer/agent.train_min": 0.4318082332611084, "timer/agent.train_max": 1.6389389038085938, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4703483581542969, "timer/agent.report_frac": 0.0004703511099686354, "timer/agent.report_avg": 0.23517417907714844, "timer/agent.report_min": 0.22764372825622559, "timer/agent.report_max": 0.2427046298980713, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.433247625461455e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 22.81581965711854}
{"step": 772984, "time": 35431.03093957901, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 773112, "time": 35437.400851011276, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 773232, "time": 35443.40784287453, "episode/length": 239.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 773320, "time": 35448.133501291275, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 773344, "time": 35450.93507814407, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 773520, "time": 35458.30789232254, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 774112, "time": 35479.32322907448, "episode/length": 109.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 774280, "time": 35486.19142317772, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 774320, "time": 35489.302872657776, "episode/length": 192.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 774512, "time": 35497.262476205826, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 774896, "time": 35511.98235678673, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 775024, "time": 35517.91422843933, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 775256, "time": 35527.05005002022, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 775304, "time": 35530.09858775139, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9641255605381166, "episode/intrinsic_return": 0.0}
{"step": 775624, "time": 35542.481612443924, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 775736, "time": 35547.839926958084, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 775912, "time": 35555.24106359482, "episode/length": 35.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 775976, "time": 35558.89921760559, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 776552, "time": 35579.85315036774, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 776752, "time": 35588.2468791008, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 776768, "time": 35590.35160446167, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 776776, "time": 35591.91127681732, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 777536, "time": 35619.10716533661, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 777552, "time": 35621.65904760361, "episode/length": 286.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 777608, "time": 35625.1832408905, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 778016, "time": 35640.69268107414, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 778264, "time": 35652.01323604584, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 778480, "time": 35661.04820203781, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 778632, "time": 35667.403475522995, "episode/length": 331.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9909638554216867, "episode/intrinsic_return": 0.0}
{"step": 778696, "time": 35671.55085682869, "episode/length": 242.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 779096, "time": 35686.91862845421, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 779272, "time": 35694.44008183479, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 779296, "time": 35697.048411130905, "episode/length": 217.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 779800, "time": 35715.078563690186, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 779968, "time": 35722.45195436478, "episode/length": 243.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35739.52580308914, "eval_episode/length": 37.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 780000, "time": 35741.56630373001, "eval_episode/length": 50.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 780000, "time": 35745.4848177433, "eval_episode/length": 55.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 780000, "time": 35750.7505774498, "eval_episode/length": 114.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9652173913043478}
{"step": 780000, "time": 35752.720910310745, "eval_episode/length": 160.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 780000, "time": 35754.5737991333, "eval_episode/length": 166.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 780000, "time": 35756.38592338562, "eval_episode/length": 168.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 780000, "time": 35760.366691827774, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 780256, "time": 35768.86226606369, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 780320, "time": 35772.56870865822, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 780720, "time": 35787.47621512413, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 780784, "time": 35791.10523438454, "episode/length": 268.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 780872, "time": 35795.44407725334, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 780984, "time": 35800.68113875389, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 781096, "time": 35805.92635822296, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 781360, "time": 35816.60312438011, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 781432, "time": 35820.31654763222, "episode/length": 80.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 781600, "time": 35827.64529776573, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 782024, "time": 35843.47311639786, "episode/length": 212.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 782392, "time": 35857.332726955414, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 782472, "time": 35861.558720350266, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 782664, "time": 35869.54452967644, "episode/length": 153.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 782784, "time": 35875.29951095581, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 782792, "time": 35876.86397314072, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 783056, "time": 35887.421959877014, "episode/length": 272.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 783120, "time": 35890.96908330917, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 783688, "time": 35911.18033289909, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 784032, "time": 35924.344297647476, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 784176, "time": 35930.75584602356, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 784200, "time": 35932.91402077675, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 784216, "time": 35934.99155473709, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 784456, "time": 35944.3793489933, "episode/length": 174.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 784480, "time": 35946.865721702576, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 785328, "time": 35976.630108594894, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 785544, "time": 35985.03590679169, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 785576, "time": 35987.7564368248, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 785704, "time": 35993.699893713, "episode/length": 208.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 785992, "time": 36004.71891403198, "episode/length": 358.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 786136, "time": 36011.085975170135, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 786416, "time": 36022.41533994675, "episode/length": 244.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 786768, "time": 36037.09840488434, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 786920, "time": 36043.59768867493, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 787128, "time": 36052.207731962204, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 787152, "time": 36054.819298028946, "episode/length": 180.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 787352, "time": 36062.92560458183, "episode/length": 169.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 787760, "time": 36078.440865278244, "episode/length": 442.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9977426636568849, "episode/intrinsic_return": 0.0}
{"step": 787976, "time": 36087.22131061554, "episode/length": 229.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 788104, "time": 36092.99303150177, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 788392, "time": 36104.21941924095, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 788632, "time": 36113.85563802719, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 788960, "time": 36126.56979846954, "episode/length": 228.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 789040, "time": 36130.785074949265, "episode/length": 210.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 789352, "time": 36142.55806016922, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 789504, "time": 36149.32513976097, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 789672, "time": 36156.19765138626, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 789728, "time": 36159.731372356415, "episode/length": 166.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 36192.77606201172, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 790088, "time": 36192.78344082832, "eval_episode/length": 175.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 790088, "time": 36196.9398932457, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 790088, "time": 36198.67171955109, "eval_episode/length": 195.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 790088, "time": 36200.623366594315, "eval_episode/length": 204.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.975609756097561}
{"step": 790088, "time": 36203.10599541664, "eval_episode/length": 225.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 790088, "time": 36204.941821575165, "eval_episode/length": 232.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9613733905579399}
{"step": 790088, "time": 36211.46839213371, "eval_episode/length": 143.0, "eval_episode/score": 5.1000000312924385, "eval_episode/reward_rate": 0.9513888888888888}
{"step": 790144, "time": 36213.5495800972, "episode/length": 137.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 790600, "time": 36230.32059717178, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 790800, "time": 36238.73417043686, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 791192, "time": 36253.1436984539, "episode/length": 319.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 791312, "time": 36259.0164000988, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 791656, "time": 36271.812906742096, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 791696, "time": 36274.98069834709, "episode/length": 567.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 792408, "time": 36300.14153122902, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 792456, "time": 36303.32607936859, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 792712, "time": 36313.29362130165, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 792792, "time": 36317.54821920395, "episode/length": 478.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9853862212943633, "episode/intrinsic_return": 0.0}
{"step": 792944, "time": 36324.435750961304, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875621890547264, "episode/intrinsic_return": 0.0}
{"step": 792960, "time": 36326.47196769714, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 793192, "time": 36335.42962145805, "episode/length": 59.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 793648, "time": 36352.44227600098, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 793880, "time": 36361.50127196312, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9688473520249221, "episode/intrinsic_return": 0.0}
{"step": 793888, "time": 36363.48440027237, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 794416, "time": 36382.709619522095, "episode/length": 202.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 794680, "time": 36394.36200428009, "episode/length": 216.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 794856, "time": 36401.762550115585, "episode/length": 150.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 794880, "time": 36404.418061733246, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 795144, "time": 36414.552681684494, "episode/length": 341.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9970760233918129, "episode/intrinsic_return": 0.0}
{"step": 795192, "time": 36417.67251062393, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 795401, "time": 36427.13886094093, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9955561211768615, "train/action_min": 0.0, "train/action_std": 2.965972918990656, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04674099665795658, "train/actor_opt_grad_steps": 48910.0, "train/actor_opt_loss": 2.335031028123612, "train/adv_mag": 0.6024989935945957, "train/adv_max": 0.5866466555612307, "train/adv_mean": 0.005729044412641706, "train/adv_min": -0.4277335500463526, "train/adv_std": 0.06787474926376173, "train/cont_avg": 0.9950063718971631, "train/cont_loss_mean": 0.00025134566492667534, "train/cont_loss_std": 0.007475731843909838, "train/cont_neg_acc": 0.9917173258801724, "train/cont_neg_loss": 0.01735598115010523, "train/cont_pos_acc": 0.9999721193989963, "train/cont_pos_loss": 0.00014911403680479545, "train/cont_pred": 0.9950079068224481, "train/cont_rate": 0.9950063718971631, "train/dyn_loss_mean": 13.187086112110327, "train/dyn_loss_std": 8.820296202991026, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8813914618593581, "train/extr_critic_critic_opt_grad_steps": 48910.0, "train/extr_critic_critic_opt_loss": 15881.24415447695, "train/extr_critic_mag": 6.3292759158087115, "train/extr_critic_max": 6.3292759158087115, "train/extr_critic_mean": 1.6526119700560333, "train/extr_critic_min": -0.19426338385182915, "train/extr_critic_std": 1.3357376511215318, "train/extr_return_normed_mag": 1.7256617182535483, "train/extr_return_normed_max": 1.7256617182535483, "train/extr_return_normed_mean": 0.373991126498432, "train/extr_return_normed_min": -0.13523579436413785, "train/extr_return_normed_std": 0.3203269427127026, "train/extr_return_rate": 0.76719446469706, "train/extr_return_raw_mag": 7.486262206490158, "train/extr_return_raw_max": 7.486262206490158, "train/extr_return_raw_mean": 1.6772606313651335, "train/extr_return_raw_min": -0.5120901757098258, "train/extr_return_raw_std": 1.3773960035743442, "train/extr_reward_mag": 1.0274529913638502, "train/extr_reward_max": 1.0274529913638502, "train/extr_reward_mean": 0.02983627375215292, "train/extr_reward_min": -0.40099281537617354, "train/extr_reward_std": 0.16209612068132306, "train/image_loss_mean": 6.334290528128333, "train/image_loss_std": 11.0361364614879, "train/model_loss_mean": 14.300848013965796, "train/model_loss_std": 14.536869657800553, "train/model_opt_grad_norm": 53.53733338700964, "train/model_opt_grad_steps": 48863.0, "train/model_opt_loss": 11544.34966824579, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 806.7375886524823, "train/policy_entropy_mag": 2.498533784920442, "train/policy_entropy_max": 2.498533784920442, "train/policy_entropy_mean": 0.4674625997002243, "train/policy_entropy_min": 0.07937506686711142, "train/policy_entropy_std": 0.5488180000308558, "train/policy_logprob_mag": 7.438383721290751, "train/policy_logprob_max": -0.00945566427491024, "train/policy_logprob_mean": -0.46733544375879543, "train/policy_logprob_min": -7.438383721290751, "train/policy_logprob_std": 1.0390413217510737, "train/policy_randomness_mag": 0.8818727803568468, "train/policy_randomness_max": 0.8818727803568468, "train/policy_randomness_mean": 0.1649937832609136, "train/policy_randomness_min": 0.028015915225160882, "train/policy_randomness_std": 0.19370867058317712, "train/post_ent_mag": 57.57492384673856, "train/post_ent_max": 57.57492384673856, "train/post_ent_mean": 41.23238794854347, "train/post_ent_min": 19.3380681572231, "train/post_ent_std": 7.648855449460077, "train/prior_ent_mag": 66.32239126651845, "train/prior_ent_max": 66.32239126651845, "train/prior_ent_mean": 54.49446925711125, "train/prior_ent_min": 41.3914260323166, "train/prior_ent_std": 3.9088680642716427, "train/rep_loss_mean": 13.187086112110327, "train/rep_loss_std": 8.820296202991026, "train/reward_avg": 0.02619334528262311, "train/reward_loss_mean": 0.05405451463046649, "train/reward_loss_std": 0.24473260712961778, "train/reward_max_data": 1.0191489407356749, "train/reward_max_pred": 1.0098511589334367, "train/reward_neg_acc": 0.9927647756346574, "train/reward_neg_loss": 0.02872868441705797, "train/reward_pos_acc": 0.9672351268166346, "train/reward_pos_loss": 0.8525912939233983, "train/reward_pred": 0.02538634213810483, "train/reward_rate": 0.030695921985815604, "train_stats/sum_log_reward": 7.600000126181908, "train_stats/max_log_achievement_collect_coal": 0.018867924528301886, "train_stats/max_log_achievement_collect_drink": 4.80188679245283, "train_stats/max_log_achievement_collect_sapling": 2.169811320754717, "train_stats/max_log_achievement_collect_stone": 1.0849056603773586, "train_stats/max_log_achievement_collect_wood": 15.056603773584905, "train_stats/max_log_achievement_defeat_skeleton": 0.03773584905660377, "train_stats/max_log_achievement_defeat_zombie": 1.509433962264151, "train_stats/max_log_achievement_eat_cow": 0.20754716981132076, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0943396226415094, "train_stats/max_log_achievement_make_wood_sword": 3.3773584905660377, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6226415094339623, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.6037735849056602, "train_stats/max_log_achievement_wake_up": 1.330188679245283, "train_stats/mean_log_entropy": 0.4192103333068344, "eval_stats/sum_log_reward": 6.475000128149986, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.4375, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.75, "eval_stats/max_log_achievement_collect_wood": 11.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0002235976280644536, "report/cont_loss_std": 0.007040752097964287, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00013303052401170135, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0002239527675556019, "report/cont_pred": 0.9958942532539368, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.710456848144531, "report/dyn_loss_std": 8.7764310836792, "report/image_loss_mean": 6.265759468078613, "report/image_loss_std": 15.020365715026855, "report/model_loss_mean": 14.536300659179688, "report/model_loss_std": 18.18802833557129, "report/post_ent_mag": 57.37627410888672, "report/post_ent_max": 57.37627410888672, "report/post_ent_mean": 40.62111282348633, "report/post_ent_min": 15.70794677734375, "report/post_ent_std": 7.377993106842041, "report/prior_ent_mag": 66.49075317382812, "report/prior_ent_max": 66.49075317382812, "report/prior_ent_mean": 54.36341857910156, "report/prior_ent_min": 42.21758270263672, "report/prior_ent_std": 3.7826950550079346, "report/rep_loss_mean": 13.710456848144531, "report/rep_loss_std": 8.7764310836792, "report/reward_avg": 0.02119140513241291, "report/reward_loss_mean": 0.04404507577419281, "report/reward_loss_std": 0.1998686045408249, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005927085876465, "report/reward_neg_acc": 0.9979960322380066, "report/reward_neg_loss": 0.024940667673945427, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.7773604989051819, "report/reward_pred": 0.01959313452243805, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00018532793910708278, "eval/cont_loss_std": 0.005875660106539726, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.488833489333047e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0001858504838310182, "eval/cont_pred": 0.996901273727417, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.365652084350586, "eval/dyn_loss_std": 9.576942443847656, "eval/image_loss_mean": 11.685436248779297, "eval/image_loss_std": 15.248178482055664, "eval/model_loss_mean": 21.5994815826416, "eval/model_loss_std": 18.761226654052734, "eval/post_ent_mag": 57.22071838378906, "eval/post_ent_max": 57.22071838378906, "eval/post_ent_mean": 40.42015838623047, "eval/post_ent_min": 19.842227935791016, "eval/post_ent_std": 7.400218486785889, "eval/prior_ent_mag": 66.49075317382812, "eval/prior_ent_max": 66.49075317382812, "eval/prior_ent_mean": 54.90472412109375, "eval/prior_ent_min": 40.739986419677734, "eval/prior_ent_std": 3.9337494373321533, "eval/rep_loss_mean": 16.365652084350586, "eval/rep_loss_std": 9.576942443847656, "eval/reward_avg": 0.02939452975988388, "eval/reward_loss_mean": 0.09446822106838226, "eval/reward_loss_std": 0.5700084567070007, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0006186962127686, "eval/reward_neg_acc": 0.9919191002845764, "eval/reward_neg_loss": 0.0373421385884285, "eval/reward_pos_acc": 0.8529411554336548, "eval/reward_pos_loss": 1.7578452825546265, "eval/reward_pred": 0.025509899482131004, "eval/reward_rate": 0.033203125, "replay/size": 794897.0, "replay/inserts": 22536.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.3781220175756983e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.470462912782191e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1609970695442623e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1461462974548, "timer/env.step_count": 2817.0, "timer/env.step_total": 244.2378261089325, "timer/env.step_frac": 0.24420213687079828, "timer/env.step_avg": 0.08670139371989084, "timer/env.step_min": 0.0233762264251709, "timer/env.step_max": 2.1136250495910645, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.308941125869751, "timer/replay._sample_frac": 0.011307288607505512, "timer/replay._sample_avg": 0.0005016386233973452, "timer/replay._sample_min": 0.00040841102600097656, "timer/replay._sample_max": 0.028228282928466797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3393.0, "timer/agent.policy_total": 56.639118909835815, "timer/agent.policy_frac": 0.05663084252187949, "timer/agent.policy_avg": 0.0166929321868069, "timer/agent.policy_min": 0.009202241897583008, "timer/agent.policy_max": 0.20343995094299316, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.15282964706420898, "timer/dataset_train_frac": 0.00015280731484092097, "timer/dataset_train_avg": 0.00010846674738410858, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010018348693847656, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 631.1937901973724, "timer/agent.train_frac": 0.6311015570414928, "timer/agent.train_avg": 0.44797288161630405, "timer/agent.train_min": 0.43321728706359863, "timer/agent.train_max": 1.550915002822876, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770541191101074, "timer/agent.report_frac": 0.0004769844096047, "timer/agent.report_avg": 0.2385270595550537, "timer/agent.report_min": 0.23160243034362793, "timer/agent.report_max": 0.2454516887664795, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 4.004846835369387e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 22.532408468703146}
{"step": 795432, "time": 36427.90096282959, "episode/length": 193.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 795528, "time": 36432.890923023224, "episode/length": 204.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 796048, "time": 36451.936467409134, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 796456, "time": 36466.99699497223, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 796472, "time": 36469.30005455017, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 796976, "time": 36487.970299482346, "episode/length": 222.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 796984, "time": 36490.09626340866, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 797440, "time": 36507.69939112663, "episode/length": 250.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 797744, "time": 36519.465498924255, "episode/length": 324.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9784615384615385, "episode/intrinsic_return": 0.0}
{"step": 797944, "time": 36527.521276474, "episode/length": 301.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 798168, "time": 36536.651604652405, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 798312, "time": 36543.15023136139, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 798352, "time": 36546.75522208214, "episode/length": 287.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 798536, "time": 36554.242077589035, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 799096, "time": 36574.34425282478, "episode/length": 327.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 799336, "time": 36583.884440898895, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 799664, "time": 36596.71835374832, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 799712, "time": 36599.86309218407, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 799816, "time": 36604.67395567894, "episode/length": 187.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 799920, "time": 36609.838700294495, "episode/length": 172.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 36636.7516412735, "eval_episode/length": 172.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9595375722543352}
{"step": 800072, "time": 36638.494797468185, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 800072, "time": 36641.43196153641, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 800072, "time": 36643.27482962608, "eval_episode/length": 216.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 800072, "time": 36645.95362043381, "eval_episode/length": 242.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 800072, "time": 36650.6988530159, "eval_episode/length": 310.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9967845659163987}
{"step": 800072, "time": 36654.039692640305, "eval_episode/length": 350.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9943019943019943}
{"step": 800072, "time": 36656.18618154526, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 800296, "time": 36663.902020931244, "episode/length": 265.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 800536, "time": 36674.01920390129, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 800800, "time": 36684.525297403336, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 800832, "time": 36687.15999865532, "episode/length": 113.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 801072, "time": 36696.651242733, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 801160, "time": 36700.84829688072, "episode/length": 44.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 801184, "time": 36703.44497847557, "episode/length": 183.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 801808, "time": 36726.1144387722, "episode/length": 338.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9882005899705014, "episode/intrinsic_return": 0.0}
{"step": 802216, "time": 36741.99271607399, "episode/length": 172.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 802336, "time": 36747.7264790535, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 802360, "time": 36749.97019934654, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 802512, "time": 36756.98346185684, "episode/length": 276.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 802664, "time": 36763.35260462761, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 803288, "time": 36787.58702421188, "episode/length": 265.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 803288, "time": 36787.59610414505, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 803320, "time": 36792.09114432335, "episode/length": 137.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.0}
{"step": 803752, "time": 36808.30869269371, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 803920, "time": 36815.78231024742, "episode/length": 194.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 804240, "time": 36828.05991983414, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 804528, "time": 36839.449054956436, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 804808, "time": 36850.189026117325, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 805184, "time": 36864.79455447197, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 805408, "time": 36873.96596121788, "episode/length": 541.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9870848708487084, "episode/intrinsic_return": 0.0}
{"step": 805472, "time": 36877.70569062233, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 805888, "time": 36893.25055932999, "episode/length": 169.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 805888, "time": 36893.260187625885, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 806048, "time": 36901.93451619148, "episode/length": 340.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765395894428153, "episode/intrinsic_return": 0.0}
{"step": 806424, "time": 36915.889632463455, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 806680, "time": 36926.181931734085, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 806696, "time": 36928.22021818161, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 807392, "time": 36953.47547745705, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 807656, "time": 36963.76588845253, "episode/length": 545.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 807704, "time": 36966.96451163292, "episode/length": 226.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 807776, "time": 36971.12932372093, "episode/length": 235.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 808432, "time": 36995.26682281494, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 808440, "time": 36996.840676784515, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 808784, "time": 37010.37235212326, "episode/length": 262.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 808944, "time": 37017.32714056969, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 809072, "time": 37023.1557404995, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 809224, "time": 37030.0244243145, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 809352, "time": 37035.87554168701, "episode/length": 520.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9846449136276392, "episode/intrinsic_return": 0.0}
{"step": 809368, "time": 37037.92496109009, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 809696, "time": 37050.77488780022, "episode/length": 156.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 809744, "time": 37053.950164079666, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 37081.57809972763, "eval_episode/length": 59.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 810056, "time": 37087.17867517471, "eval_episode/length": 153.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 810056, "time": 37088.901206970215, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 810056, "time": 37091.04942941666, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 810056, "time": 37093.41413283348, "eval_episode/length": 188.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 810056, "time": 37098.36464381218, "eval_episode/length": 226.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 810056, "time": 37100.99148964882, "eval_episode/length": 248.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 810056, "time": 37102.87943148613, "eval_episode/length": 194.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 810184, "time": 37107.1538105011, "episode/length": 154.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 810408, "time": 37116.25523376465, "episode/length": 246.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 810544, "time": 37123.02580690384, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 810680, "time": 37128.98669600487, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 810840, "time": 37135.960488796234, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 810936, "time": 37140.8830807209, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 811272, "time": 37155.269813776016, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 811328, "time": 37158.96625685692, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 811408, "time": 37163.28080558777, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 811824, "time": 37178.74465298653, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 811832, "time": 37180.422248363495, "episode/length": 52.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 811896, "time": 37184.11179161072, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 812192, "time": 37195.64996814728, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 812232, "time": 37198.38324761391, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 812752, "time": 37217.56412482262, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 812776, "time": 37219.818742752075, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 812872, "time": 37224.50377702713, "episode/length": 192.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 813096, "time": 37233.689791202545, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 813616, "time": 37253.11721754074, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 813720, "time": 37257.836673498154, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 813760, "time": 37260.92380666733, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 814136, "time": 37274.96715259552, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 814208, "time": 37279.29091835022, "episode/length": 288.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 814208, "time": 37279.2995262146, "episode/length": 166.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9520958083832335, "episode/intrinsic_return": 0.0}
{"step": 814528, "time": 37293.2262840271, "episode/length": 218.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 814640, "time": 37298.5128326416, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 814880, "time": 37308.16595005989, "episode/length": 157.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 815184, "time": 37319.87818026543, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 815312, "time": 37325.675169467926, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 815600, "time": 37336.8427734375, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 815784, "time": 37344.43711781502, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 815800, "time": 37346.52387189865, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 816176, "time": 37360.899483919144, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 816560, "time": 37375.405123233795, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 816664, "time": 37380.76877593994, "episode/length": 252.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 816904, "time": 37390.77115869522, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 817192, "time": 37402.319789886475, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 817312, "time": 37408.54307436943, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 817801, "time": 37427.304332733154, "train_stats/sum_log_reward": 7.747058951387219, "train_stats/max_log_achievement_collect_coal": 0.1568627450980392, "train_stats/max_log_achievement_collect_drink": 4.970588235294118, "train_stats/max_log_achievement_collect_sapling": 2.049019607843137, "train_stats/max_log_achievement_collect_stone": 1.411764705882353, "train_stats/max_log_achievement_collect_wood": 14.96078431372549, "train_stats/max_log_achievement_defeat_skeleton": 0.058823529411764705, "train_stats/max_log_achievement_defeat_zombie": 1.3529411764705883, "train_stats/max_log_achievement_eat_cow": 0.24509803921568626, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4803921568627452, "train_stats/max_log_achievement_make_wood_sword": 2.9313725490196076, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.7745098039215685, "train_stats/max_log_achievement_place_stone": 0.029411764705882353, "train_stats/max_log_achievement_place_table": 3.8823529411764706, "train_stats/max_log_achievement_wake_up": 1.392156862745098, "train_stats/mean_log_entropy": 0.42599764349413854, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9917898995535714, "train/action_min": 0.0, "train/action_std": 2.882332159791674, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04370662962485637, "train/actor_opt_grad_steps": 50315.0, "train/actor_opt_loss": -1.1551873295434885, "train/adv_mag": 0.5823649738516127, "train/adv_max": 0.5472741546375411, "train/adv_mean": 0.004621454284694794, "train/adv_min": -0.44703513756394386, "train/adv_std": 0.06369049833821398, "train/cont_avg": 0.9951241629464286, "train/cont_loss_mean": 0.0002215772703516805, "train/cont_loss_std": 0.006698298835794552, "train/cont_neg_acc": 0.9947242209379622, "train/cont_neg_loss": 0.022419156922533868, "train/cont_pos_acc": 0.9999789480652128, "train/cont_pos_loss": 0.00012556993823900392, "train/cont_pred": 0.995116319826671, "train/cont_rate": 0.9951241629464286, "train/dyn_loss_mean": 13.243095145906722, "train/dyn_loss_std": 8.835387100492206, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8772286074502128, "train/extr_critic_critic_opt_grad_steps": 50315.0, "train/extr_critic_critic_opt_loss": 16096.383112444197, "train/extr_critic_mag": 6.795226952007838, "train/extr_critic_max": 6.795226952007838, "train/extr_critic_mean": 1.8801955206053598, "train/extr_critic_min": -0.171218912090574, "train/extr_critic_std": 1.4954156611646925, "train/extr_return_normed_mag": 1.67010435291699, "train/extr_return_normed_max": 1.67010435291699, "train/extr_return_normed_mean": 0.37726730512721196, "train/extr_return_normed_min": -0.11745370871254376, "train/extr_return_normed_std": 0.31921491197177343, "train/extr_return_rate": 0.7810854213578361, "train/extr_return_raw_mag": 8.118119488443647, "train/extr_return_raw_max": 8.118119488443647, "train/extr_return_raw_mean": 1.9023864362921035, "train/extr_return_raw_min": -0.47722308241895267, "train/extr_return_raw_std": 1.535639990227563, "train/extr_reward_mag": 1.0276179824556624, "train/extr_reward_max": 1.0276179824556624, "train/extr_reward_mean": 0.03135796377568373, "train/extr_reward_min": -0.3938002390520913, "train/extr_reward_std": 0.16586692040520054, "train/image_loss_mean": 6.420274788992746, "train/image_loss_std": 11.744882134028844, "train/model_loss_mean": 14.419774913787842, "train/model_loss_std": 15.243879563467843, "train/model_opt_grad_norm": 53.20921024594988, "train/model_opt_grad_steps": 50267.45, "train/model_opt_loss": 18548.94681919643, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1285.7142857142858, "train/policy_entropy_mag": 2.449279073306492, "train/policy_entropy_max": 2.449279073306492, "train/policy_entropy_mean": 0.461736033643995, "train/policy_entropy_min": 0.07937507395233427, "train/policy_entropy_std": 0.5430738357560975, "train/policy_logprob_mag": 7.438383790424892, "train/policy_logprob_max": -0.009455663478001952, "train/policy_logprob_mean": -0.46254809690373283, "train/policy_logprob_min": -7.438383790424892, "train/policy_logprob_std": 1.0372351723057882, "train/policy_randomness_mag": 0.8644880316087178, "train/policy_randomness_max": 0.8644880316087178, "train/policy_randomness_mean": 0.1629725579704557, "train/policy_randomness_min": 0.028015917712556463, "train/policy_randomness_std": 0.19168123166475978, "train/post_ent_mag": 57.58587978907994, "train/post_ent_max": 57.58587978907994, "train/post_ent_mean": 41.21305443899972, "train/post_ent_min": 19.289358615875244, "train/post_ent_std": 7.632101821899414, "train/prior_ent_mag": 66.24853243146624, "train/prior_ent_max": 66.24853243146624, "train/prior_ent_mean": 54.46527998788016, "train/prior_ent_min": 41.493052918570385, "train/prior_ent_std": 3.8606007575988768, "train/rep_loss_mean": 13.243095145906722, "train/rep_loss_std": 8.835387100492206, "train/reward_avg": 0.02617675767812346, "train/reward_loss_mean": 0.05342135374833431, "train/reward_loss_std": 0.23721691189067703, "train/reward_max_data": 1.0100000023841857, "train/reward_max_pred": 1.0104183384350367, "train/reward_neg_acc": 0.9929984897375107, "train/reward_neg_loss": 0.02867505817141916, "train/reward_pos_acc": 0.9711563225303378, "train/reward_pos_loss": 0.8341992527246476, "train/reward_pred": 0.025351460384471076, "train/reward_rate": 0.030684988839285714, "eval_stats/sum_log_reward": 7.78750005364418, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 5.8125, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 12.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.6875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.590875737951137e-06, "report/cont_loss_std": 4.937953781336546e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00024135105195455253, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.474921398577862e-07, "report/cont_pred": 0.9931647777557373, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.775115013122559, "report/dyn_loss_std": 8.591643333435059, "report/image_loss_mean": 4.169103622436523, "report/image_loss_std": 10.856226921081543, "report/model_loss_mean": 11.278306007385254, "report/model_loss_std": 14.05994987487793, "report/post_ent_mag": 56.77711486816406, "report/post_ent_max": 56.77711486816406, "report/post_ent_mean": 42.069122314453125, "report/post_ent_min": 21.638717651367188, "report/post_ent_std": 8.03746509552002, "report/prior_ent_mag": 66.16755676269531, "report/prior_ent_max": 66.16755676269531, "report/prior_ent_mean": 54.001495361328125, "report/prior_ent_min": 41.90104675292969, "report/prior_ent_std": 3.7368648052215576, "report/rep_loss_mean": 11.775115013122559, "report/rep_loss_std": 8.591643333435059, "report/reward_avg": 0.02705078199505806, "report/reward_loss_mean": 0.04413146525621414, "report/reward_loss_std": 0.1741180419921875, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0019774436950684, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020193424075841904, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7629980444908142, "report/reward_pred": 0.025205543264746666, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.37725509275333e-06, "eval/cont_loss_std": 0.000148881328641437, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0016100717475637794, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.621885972890595e-07, "eval/cont_pred": 0.9970744252204895, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.828019142150879, "eval/dyn_loss_std": 10.016773223876953, "eval/image_loss_mean": 9.973724365234375, "eval/image_loss_std": 13.86824893951416, "eval/model_loss_mean": 19.573801040649414, "eval/model_loss_std": 17.984941482543945, "eval/post_ent_mag": 56.553810119628906, "eval/post_ent_max": 56.553810119628906, "eval/post_ent_mean": 40.550010681152344, "eval/post_ent_min": 19.924476623535156, "eval/post_ent_std": 7.836915493011475, "eval/prior_ent_mag": 66.16755676269531, "eval/prior_ent_max": 66.16755676269531, "eval/prior_ent_mean": 54.37607192993164, "eval/prior_ent_min": 40.734275817871094, "eval/prior_ent_std": 3.89548659324646, "eval/rep_loss_mean": 15.828019142150879, "eval/rep_loss_std": 10.016773223876953, "eval/reward_avg": 0.03056640550494194, "eval/reward_loss_mean": 0.10326007008552551, "eval/reward_loss_std": 0.6853922605514526, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017096996307373, "eval/reward_neg_acc": 0.9878664612770081, "eval/reward_neg_loss": 0.033111803233623505, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.085449695587158, "eval/reward_pred": 0.027008965611457825, "eval/reward_rate": 0.0341796875, "replay/size": 817297.0, "replay/inserts": 22400.0, "replay/samples": 22400.0, "replay/insert_wait_avg": 1.3847116913114276e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.447600364685058e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.173172342149835e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1500346660614, "timer/env.step_count": 2800.0, "timer/env.step_total": 242.75824570655823, "timer/env.step_frac": 0.2427218290179957, "timer/env.step_avg": 0.08669937346662794, "timer/env.step_min": 0.02342510223388672, "timer/env.step_max": 3.4296092987060547, "timer/replay._sample_count": 22400.0, "timer/replay._sample_total": 11.265636444091797, "timer/replay._sample_frac": 0.01126394646164589, "timer/replay._sample_avg": 0.0005029301983969552, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.010936975479125977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3408.0, "timer/agent.policy_total": 56.58453845977783, "timer/agent.policy_frac": 0.05657605009099536, "timer/agent.policy_avg": 0.016603444383737627, "timer/agent.policy_min": 0.009468793869018555, "timer/agent.policy_max": 0.1090700626373291, "timer/dataset_train_count": 1400.0, "timer/dataset_train_total": 0.1510636806488037, "timer/dataset_train_frac": 0.00015104101925991748, "timer/dataset_train_avg": 0.00010790262903485979, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0004105567932128906, "timer/agent.train_count": 1400.0, "timer/agent.train_total": 629.6687531471252, "timer/agent.train_frac": 0.6295742951779874, "timer/agent.train_avg": 0.44976339510508945, "timer/agent.train_min": 0.4334566593170166, "timer/agent.train_max": 1.6851146221160889, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47385478019714355, "timer/agent.report_frac": 0.0004737836962184961, "timer/agent.report_avg": 0.23692739009857178, "timer/agent.report_min": 0.23191118240356445, "timer/agent.report_max": 0.2419435977935791, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908270323672234e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.39633524475149}
{"step": 818000, "time": 37434.13903427124, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 818200, "time": 37442.64925909042, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 818320, "time": 37448.401918411255, "episode/length": 429.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 818424, "time": 37453.27704334259, "episode/length": 280.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 818544, "time": 37459.17689538002, "episode/length": 153.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 818752, "time": 37467.59539294243, "episode/length": 260.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 819432, "time": 37493.086218595505, "episode/length": 315.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 819520, "time": 37497.85388612747, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 819608, "time": 37502.104064941406, "episode/length": 147.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 819760, "time": 37508.926361083984, "episode/length": 320.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 819888, "time": 37514.79530262947, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 37542.17414069176, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 820040, "time": 37544.437499284744, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 820040, "time": 37546.18164682388, "eval_episode/length": 212.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 820040, "time": 37548.48103308678, "eval_episode/length": 228.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 820040, "time": 37551.14534831047, "eval_episode/length": 248.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9718875502008032}
{"step": 820040, "time": 37553.266904592514, "eval_episode/length": 262.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 820040, "time": 37555.77707839012, "eval_episode/length": 285.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.986013986013986}
{"step": 820040, "time": 37560.694229364395, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 820496, "time": 37576.07401204109, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 820640, "time": 37582.54481291771, "episode/length": 289.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 820704, "time": 37586.20570850372, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 820840, "time": 37591.90295958519, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 820896, "time": 37595.50477576256, "episode/length": 49.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 821328, "time": 37611.624237537384, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 821408, "time": 37615.910527706146, "episode/length": 224.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 821520, "time": 37621.2452685833, "episode/length": 249.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 822056, "time": 37640.329144477844, "episode/length": 270.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 822112, "time": 37643.91994023323, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 822208, "time": 37648.5918302536, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 822240, "time": 37651.202273607254, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 822584, "time": 37664.197221040726, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 822872, "time": 37675.389560222626, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 823120, "time": 37685.39971137047, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 823168, "time": 37688.5987432003, "episode/length": 138.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 823352, "time": 37696.27741909027, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 823640, "time": 37707.554948329926, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 823656, "time": 37710.159965753555, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 824248, "time": 37731.9403731823, "episode/length": 171.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 824280, "time": 37734.52699494362, "episode/length": 138.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 824416, "time": 37740.78646445274, "episode/length": 161.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 824480, "time": 37744.5114364624, "episode/length": 236.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 824528, "time": 37747.56873393059, "episode/length": 289.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 824680, "time": 37753.95737719536, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 825368, "time": 37778.32374334335, "episode/length": 213.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 825496, "time": 37784.20138525963, "episode/length": 151.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 825536, "time": 37787.2307574749, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 825952, "time": 37802.70262861252, "episode/length": 191.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 826016, "time": 37806.37734699249, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 826328, "time": 37818.07384943962, "episode/length": 259.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 826384, "time": 37821.90057897568, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 826456, "time": 37825.669775247574, "episode/length": 221.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 826816, "time": 37839.364307165146, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 827080, "time": 37849.544961452484, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 827336, "time": 37859.601002693176, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 827800, "time": 37878.682747125626, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 827824, "time": 37881.71258687973, "episode/length": 233.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 828208, "time": 37896.46163511276, "episode/length": 218.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 828216, "time": 37898.03665518761, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 828264, "time": 37901.18458151817, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 828816, "time": 37921.53505516052, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 829040, "time": 37930.59175133705, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 829480, "time": 37946.69724178314, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 829536, "time": 37950.29984045029, "episode/length": 216.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 829744, "time": 37958.86475276947, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 37984.95697212219, "eval_episode/length": 50.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 830024, "time": 37992.16337943077, "eval_episode/length": 182.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 830024, "time": 37994.09582352638, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 830024, "time": 37994.10427212715, "eval_episode/length": 190.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 830024, "time": 37997.36474823952, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 830024, "time": 37999.14669561386, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 830024, "time": 38002.16900849342, "eval_episode/length": 229.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9739130434782609}
{"step": 830024, "time": 38003.85609984398, "eval_episode/length": 233.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 830064, "time": 38005.44002079964, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 830080, "time": 38007.52437496185, "episode/length": 461.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 830264, "time": 38014.953558683395, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 830408, "time": 38021.325548648834, "episode/length": 267.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 830896, "time": 38039.45614862442, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 830944, "time": 38042.59737086296, "episode/length": 237.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 831472, "time": 38061.96942329407, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 831512, "time": 38064.65723657608, "episode/length": 180.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 831640, "time": 38071.06429219246, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 831648, "time": 38073.195942640305, "episode/length": 237.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 831912, "time": 38083.22960424423, "episode/length": 228.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 832176, "time": 38094.06158423424, "episode/length": 153.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 832336, "time": 38100.99551844597, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 832728, "time": 38115.436138391495, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 832792, "time": 38119.38654065132, "episode/length": 159.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 833024, "time": 38128.95729422569, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 833296, "time": 38139.61520051956, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 833480, "time": 38147.15585041046, "episode/length": 229.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 833744, "time": 38158.51386594772, "episode/length": 228.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 833784, "time": 38161.76493525505, "episode/length": 180.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 834176, "time": 38177.04933285713, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 834208, "time": 38179.87271595001, "episode/length": 184.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 834488, "time": 38190.610709667206, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 835000, "time": 38209.54143500328, "episode/length": 275.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 835200, "time": 38218.05492973328, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 835288, "time": 38222.75508785248, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 835440, "time": 38229.53309082985, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 835600, "time": 38237.939937114716, "episode/length": 38.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 835728, "time": 38243.81453824043, "episode/length": 280.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 835744, "time": 38245.93013238907, "episode/length": 249.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 835824, "time": 38250.27639079094, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 836168, "time": 38263.40677380562, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 836768, "time": 38285.25655055046, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 836864, "time": 38290.09318780899, "episode/length": 141.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 837128, "time": 38300.38445019722, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 837224, "time": 38305.73354291916, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 837360, "time": 38312.63568162918, "episode/length": 269.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 837376, "time": 38314.63402080536, "episode/length": 221.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 837488, "time": 38320.02718877792, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 838272, "time": 38348.459277153015, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 838464, "time": 38356.65856552124, "episode/length": 211.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 838584, "time": 38362.68318939209, "episode/length": 392.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.989821882951654, "episode/intrinsic_return": 0.0}
{"step": 838744, "time": 38370.228267908096, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 838776, "time": 38373.3654923439, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 839152, "time": 38387.794682979584, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 839184, "time": 38390.55351114273, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 839184, "time": 38390.56288981438, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 839720, "time": 38411.31786823273, "episode/length": 141.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 839984, "time": 38421.9131526947, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 38438.08196949959, "eval_episode/length": 29.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.8666666666666667}
{"step": 840008, "time": 38445.497525691986, "eval_episode/length": 169.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 840008, "time": 38447.74440741539, "eval_episode/length": 183.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 840008, "time": 38450.69991517067, "eval_episode/length": 214.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 840008, "time": 38452.54895782471, "eval_episode/length": 221.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 840008, "time": 38454.178141117096, "eval_episode/length": 222.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 840008, "time": 38456.91826939583, "eval_episode/length": 220.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 840008, "time": 38458.93030023575, "eval_episode/length": 261.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 840009, "time": 38459.95328807831, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.052441054968525, "train/action_min": 0.0, "train/action_std": 2.833155867007139, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04219598317746636, "train/actor_opt_grad_steps": 51710.0, "train/actor_opt_loss": -2.8551983395926386, "train/adv_mag": 0.5509027321990445, "train/adv_max": 0.5191946364135194, "train/adv_mean": 0.004197886575612959, "train/adv_min": -0.43733193119652836, "train/adv_std": 0.06127066149128427, "train/cont_avg": 0.9950328799460432, "train/cont_loss_mean": 0.00010715024855556772, "train/cont_loss_std": 0.0031321938797511046, "train/cont_neg_acc": 0.9970023983674083, "train/cont_neg_loss": 0.007117511991261034, "train/cont_pos_acc": 0.9999717482559972, "train/cont_pos_loss": 7.10426179656754e-05, "train/cont_pred": 0.9950057109482855, "train/cont_rate": 0.9950328799460432, "train/dyn_loss_mean": 13.220524403688719, "train/dyn_loss_std": 8.785633893321744, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.865520713569449, "train/extr_critic_critic_opt_grad_steps": 51710.0, "train/extr_critic_critic_opt_loss": 15981.014311207284, "train/extr_critic_mag": 7.074350116921844, "train/extr_critic_max": 7.074350116921844, "train/extr_critic_mean": 2.0536929171719995, "train/extr_critic_min": -0.17380426427443252, "train/extr_critic_std": 1.576189074584906, "train/extr_return_normed_mag": 1.6230404900132323, "train/extr_return_normed_max": 1.6230404900132323, "train/extr_return_normed_mean": 0.38889783352827856, "train/extr_return_normed_min": -0.11695575022654568, "train/extr_return_normed_std": 0.31806428666166264, "train/extr_return_rate": 0.8098068833351135, "train/extr_return_raw_mag": 8.329261189742054, "train/extr_return_raw_max": 8.329261189742054, "train/extr_return_raw_mean": 2.0748048283213336, "train/extr_return_raw_min": -0.4890307819457363, "train/extr_return_raw_std": 1.6122707986145568, "train/extr_reward_mag": 1.0301710067035483, "train/extr_reward_max": 1.0301710067035483, "train/extr_reward_mean": 0.032701334668149194, "train/extr_reward_min": -0.41740727853431975, "train/extr_reward_std": 0.16942164264351345, "train/image_loss_mean": 6.231482468063025, "train/image_loss_std": 10.949269267294904, "train/model_loss_mean": 14.218380495798673, "train/model_loss_std": 14.451927829989426, "train/model_opt_grad_norm": 53.28346299095977, "train/model_opt_grad_steps": 51661.18705035971, "train/model_opt_loss": 19639.287706553507, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1384.8920863309352, "train/policy_entropy_mag": 2.485629280694097, "train/policy_entropy_max": 2.485629280694097, "train/policy_entropy_mean": 0.46681633677414, "train/policy_entropy_min": 0.07937504645946214, "train/policy_entropy_std": 0.5716624172042599, "train/policy_logprob_mag": 7.438383819387971, "train/policy_logprob_max": -0.009455660967786106, "train/policy_logprob_mean": -0.4665978435132143, "train/policy_logprob_min": -7.438383819387971, "train/policy_logprob_std": 1.0365349779026114, "train/policy_randomness_mag": 0.8773180572249049, "train/policy_randomness_max": 0.8773180572249049, "train/policy_randomness_mean": 0.1647656825806597, "train/policy_randomness_min": 0.028015908001245354, "train/policy_randomness_std": 0.2017717470796846, "train/post_ent_mag": 57.477736960212106, "train/post_ent_max": 57.477736960212106, "train/post_ent_mean": 41.228633825727506, "train/post_ent_min": 19.3144386277782, "train/post_ent_std": 7.629185192876583, "train/prior_ent_mag": 66.228729632261, "train/prior_ent_max": 66.228729632261, "train/prior_ent_mean": 54.499772655020514, "train/prior_ent_min": 41.77244971295912, "train/prior_ent_std": 3.846066660160641, "train/rep_loss_mean": 13.220524403688719, "train/rep_loss_std": 8.785633893321744, "train/reward_avg": 0.02611637230051293, "train/reward_loss_mean": 0.054476271805574565, "train/reward_loss_std": 0.24738699208489426, "train/reward_max_data": 1.0136690680071605, "train/reward_max_pred": 1.007907359720134, "train/reward_neg_acc": 0.9925428110060932, "train/reward_neg_loss": 0.029545456104034144, "train/reward_pos_acc": 0.9672636364003737, "train/reward_pos_loss": 0.845353609795193, "train/reward_pred": 0.02553200229948802, "train/reward_rate": 0.030694975269784174, "train_stats/sum_log_reward": 7.949056805304761, "train_stats/max_log_achievement_collect_coal": 0.04716981132075472, "train_stats/max_log_achievement_collect_drink": 4.528301886792453, "train_stats/max_log_achievement_collect_sapling": 2.150943396226415, "train_stats/max_log_achievement_collect_stone": 0.8679245283018868, "train_stats/max_log_achievement_collect_wood": 14.764150943396226, "train_stats/max_log_achievement_defeat_skeleton": 0.02830188679245283, "train_stats/max_log_achievement_defeat_zombie": 1.6132075471698113, "train_stats/max_log_achievement_eat_cow": 0.18867924528301888, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.0283018867924527, "train_stats/max_log_achievement_make_wood_sword": 1.5377358490566038, "train_stats/max_log_achievement_place_furnace": 0.009433962264150943, "train_stats/max_log_achievement_place_plant": 2.0283018867924527, "train_stats/max_log_achievement_place_stone": 0.009433962264150943, "train_stats/max_log_achievement_place_table": 4.084905660377358, "train_stats/max_log_achievement_wake_up": 1.471698113207547, "train_stats/mean_log_entropy": 0.42857312650050755, "eval_stats/sum_log_reward": 7.850000257293384, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 3.8333333333333335, "eval_stats/max_log_achievement_collect_sapling": 2.0833333333333335, "eval_stats/max_log_achievement_collect_stone": 1.2916666666666667, "eval_stats/max_log_achievement_collect_wood": 14.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5833333333333333, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.0416666666666665, "eval_stats/max_log_achievement_make_wood_sword": 1.4166666666666667, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0416666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 4.0, "eval_stats/max_log_achievement_wake_up": 1.5416666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 3.0125260309432633e-05, "report/cont_loss_std": 0.0009472866076976061, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.55261586769484e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0153831175994128e-05, "report/cont_pred": 0.9980173110961914, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 13.080877304077148, "report/dyn_loss_std": 8.050930976867676, "report/image_loss_mean": 5.563882827758789, "report/image_loss_std": 8.95601749420166, "report/model_loss_mean": 13.442970275878906, "report/model_loss_std": 12.261883735656738, "report/post_ent_mag": 55.70305633544922, "report/post_ent_max": 55.70305633544922, "report/post_ent_mean": 40.68759536743164, "report/post_ent_min": 20.844757080078125, "report/post_ent_std": 6.868853569030762, "report/prior_ent_mag": 65.87679290771484, "report/prior_ent_max": 65.87679290771484, "report/prior_ent_mean": 54.05621337890625, "report/prior_ent_min": 42.52118682861328, "report/prior_ent_std": 3.4638445377349854, "report/rep_loss_mean": 13.080877304077148, "report/rep_loss_std": 8.050930976867676, "report/reward_avg": 0.02109374850988388, "report/reward_loss_mean": 0.030531033873558044, "report/reward_loss_std": 0.13132619857788086, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0135536193847656, "report/reward_neg_acc": 0.9970000386238098, "report/reward_neg_loss": 0.01505247037857771, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6754711866378784, "report/reward_pred": 0.02216842956840992, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.446482646220829e-06, "eval/cont_loss_std": 0.00014098592509981245, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012390417978167534, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.088555437600007e-07, "eval/cont_pred": 0.9960980415344238, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.363630294799805, "eval/dyn_loss_std": 10.282930374145508, "eval/image_loss_mean": 13.465522766113281, "eval/image_loss_std": 26.49894142150879, "eval/model_loss_mean": 24.002010345458984, "eval/model_loss_std": 30.081483840942383, "eval/post_ent_mag": 56.60833740234375, "eval/post_ent_max": 56.60833740234375, "eval/post_ent_mean": 38.760433197021484, "eval/post_ent_min": 20.04816436767578, "eval/post_ent_std": 7.506345272064209, "eval/prior_ent_mag": 65.87679290771484, "eval/prior_ent_max": 65.87679290771484, "eval/prior_ent_mean": 53.9176025390625, "eval/prior_ent_min": 44.84375, "eval/prior_ent_std": 3.4808247089385986, "eval/rep_loss_mean": 17.363630294799805, "eval/rep_loss_std": 10.282930374145508, "eval/reward_avg": 0.04667969048023224, "eval/reward_loss_mean": 0.11830475926399231, "eval/reward_loss_std": 0.5935584902763367, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00059175491333, "eval/reward_neg_acc": 0.9825283288955688, "eval/reward_neg_loss": 0.06145559623837471, "eval/reward_pos_acc": 0.8823529481887817, "eval/reward_pos_loss": 1.2028979063034058, "eval/reward_pred": 0.04924558848142624, "eval/reward_rate": 0.0498046875, "replay/size": 839505.0, "replay/inserts": 22208.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3907356805004374e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.494274924055643e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1565793266695135e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1032.6410670280457, "timer/env.step_count": 2776.0, "timer/env.step_total": 249.28394150733948, "timer/env.step_frac": 0.2414042492274512, "timer/env.step_avg": 0.08979969074471883, "timer/env.step_min": 0.02296137809753418, "timer/env.step_max": 3.256575584411621, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.164301633834839, "timer/replay._sample_frac": 0.010811405812056113, "timer/replay._sample_avg": 0.0005027153113218137, "timer/replay._sample_min": 0.00038361549377441406, "timer/replay._sample_max": 0.010854482650756836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3637.0, "timer/agent.policy_total": 58.60963487625122, "timer/agent.policy_frac": 0.05675702501831591, "timer/agent.policy_avg": 0.01611482949580732, "timer/agent.policy_min": 0.009458303451538086, "timer/agent.policy_max": 0.11485457420349121, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.15101051330566406, "timer/dataset_train_frac": 0.00014623717584685478, "timer/dataset_train_avg": 0.00010879719978794241, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0010755062103271484, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 624.6923322677612, "timer/agent.train_frac": 0.604946241452157, "timer/agent.train_avg": 0.4500665218067444, "timer/agent.train_min": 0.43345212936401367, "timer/agent.train_max": 1.5733931064605713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47669053077697754, "timer/agent.report_frac": 0.00046162267412906504, "timer/agent.report_avg": 0.23834526538848877, "timer/agent.report_min": 0.23167800903320312, "timer/agent.report_max": 0.24501252174377441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.25544090068687e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 21.505742316588396}
{"step": 840248, "time": 38467.714579582214, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 840264, "time": 38469.817244529724, "episode/length": 248.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 840400, "time": 38476.1156039238, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 840536, "time": 38482.052778720856, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 840712, "time": 38489.516629457474, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 841496, "time": 38517.17780280113, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 841800, "time": 38528.974551677704, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 841864, "time": 38532.7414188385, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 841904, "time": 38535.87673664093, "episode/length": 170.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 841928, "time": 38538.576956272125, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 842040, "time": 38544.46022319794, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 842384, "time": 38557.81886076927, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 842816, "time": 38573.74904489517, "episode/length": 453.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 842952, "time": 38579.63544178009, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 843288, "time": 38592.541801929474, "episode/length": 172.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 843424, "time": 38598.93418955803, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 843656, "time": 38607.88672351837, "episode/length": 201.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 843720, "time": 38611.57186770439, "episode/length": 223.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 843768, "time": 38614.66716122627, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 844120, "time": 38629.525095939636, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 844904, "time": 38656.935406684875, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 845288, "time": 38671.564823150635, "episode/length": 203.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 845312, "time": 38674.14233994484, "episode/length": 311.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 845336, "time": 38676.380269765854, "episode/length": 238.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 845360, "time": 38679.06368136406, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 845624, "time": 38689.23685002327, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 846024, "time": 38703.95104908943, "episode/length": 383.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 846248, "time": 38712.85806107521, "episode/length": 309.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 846648, "time": 38727.7474758625, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 847160, "time": 38746.47963809967, "episode/length": 63.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 847240, "time": 38750.857815504074, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 847328, "time": 38755.526512384415, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 847368, "time": 38758.111577034, "episode/length": 250.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 847720, "time": 38771.39336156845, "episode/length": 183.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 847816, "time": 38776.19325065613, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 847848, "time": 38778.99189591408, "episode/length": 59.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 848336, "time": 38797.00111365318, "episode/length": 374.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9893333333333333, "episode/intrinsic_return": 0.0}
{"step": 848592, "time": 38807.1695728302, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 848648, "time": 38810.494884729385, "episode/length": 175.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 849032, "time": 38824.82297873497, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 849120, "time": 38830.09474277496, "episode/length": 478.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832985386221295, "episode/intrinsic_return": 0.0}
{"step": 849424, "time": 38841.94455552101, "episode/length": 261.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 849424, "time": 38841.95622134209, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 849432, "time": 38845.23473620415, "episode/length": 201.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 849720, "time": 38856.40857338905, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 849880, "time": 38863.213131189346, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 849952, "time": 38867.47446727753, "episode/length": 169.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 38895.652141332626, "eval_episode/length": 162.0, "eval_episode/score": 9.100000068545341, "eval_episode/reward_rate": 0.9877300613496932}
{"step": 850096, "time": 38898.4722840786, "eval_episode/length": 189.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 850096, "time": 38900.44748902321, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 850096, "time": 38902.32543802261, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 850096, "time": 38903.99630975723, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 850096, "time": 38906.314407110214, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 850096, "time": 38908.195051670074, "eval_episode/length": 224.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 850096, "time": 38910.39336633682, "eval_episode/length": 229.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 850224, "time": 38914.78124666214, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 850680, "time": 38931.67261958122, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 850992, "time": 38943.79504108429, "episode/length": 233.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 851064, "time": 38947.501895427704, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 851280, "time": 38956.41351866722, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.0}
{"step": 851304, "time": 38958.62117910385, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 851408, "time": 38963.98201036453, "episode/length": 51.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 851504, "time": 38968.77560091019, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 851704, "time": 38976.81162929535, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 852080, "time": 38992.819393634796, "episode/length": 294.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 852392, "time": 39004.55775284767, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 852760, "time": 39018.546986579895, "episode/length": 45.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 852856, "time": 39023.34306240082, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 852920, "time": 39027.176970243454, "episode/length": 151.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 853168, "time": 39037.213787555695, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 853240, "time": 39040.96333551407, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 853272, "time": 39043.49608421326, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 854016, "time": 39069.9661295414, "episode/length": 241.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 854576, "time": 39090.342494010925, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 854584, "time": 39092.00794529915, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 854720, "time": 39098.456138134, "episode/length": 232.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 854904, "time": 39105.9370470047, "episode/length": 479.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9979166666666667, "episode/intrinsic_return": 0.0}
{"step": 854904, "time": 39105.972207546234, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 855168, "time": 39118.40296840668, "episode/length": 240.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 855376, "time": 39127.04613018036, "episode/length": 275.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 855416, "time": 39130.31990361214, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 856176, "time": 39157.888625621796, "episode/length": 199.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 856256, "time": 39162.02637410164, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 856352, "time": 39166.84735202789, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 856376, "time": 39169.07653570175, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 856400, "time": 39171.68248915672, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 856568, "time": 39178.48016214371, "episode/length": 148.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 856592, "time": 39181.09971809387, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 857016, "time": 39196.39991784096, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 857096, "time": 39200.57269239426, "episode/length": 89.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 857504, "time": 39215.897043943405, "episode/length": 165.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 857744, "time": 39225.5119638443, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 857784, "time": 39228.307775974274, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 858256, "time": 39247.9222536087, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 858336, "time": 39251.97663855553, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 858448, "time": 39257.33748412132, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 858664, "time": 39266.089550733566, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 858968, "time": 39277.683245420456, "episode/length": 182.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 859048, "time": 39281.8872115612, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 859224, "time": 39289.47332930565, "episode/length": 328.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 859320, "time": 39294.24093937874, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 859784, "time": 39311.18563961983, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39322.87217736244, "episode/length": 217.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39342.595010757446, "eval_episode/length": 167.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 860080, "time": 39344.7411775589, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 860080, "time": 39346.88037800789, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 860080, "time": 39348.75408864021, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 860080, "time": 39350.79394364357, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 860080, "time": 39352.60969996452, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 860080, "time": 39354.80493950844, "eval_episode/length": 225.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 860080, "time": 39356.45139789581, "eval_episode/length": 227.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 860120, "time": 39359.164070129395, "episode/length": 181.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 860176, "time": 39364.150450229645, "episode/length": 215.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 860704, "time": 39383.468177080154, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 860864, "time": 39390.365911245346, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 861288, "time": 39405.71126270294, "episode/length": 187.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 861360, "time": 39409.86756896973, "episode/length": 266.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 861360, "time": 39409.8762049675, "episode/length": 159.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 861536, "time": 39418.89039373398, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 861720, "time": 39426.4149646759, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 861936, "time": 39435.3738489151, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 862040, "time": 39440.15330719948, "episode/length": 146.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 862569, "time": 39460.324979543686, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.106663480718085, "train/action_min": 0.0, "train/action_std": 2.953322397056201, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04094369570784112, "train/actor_opt_grad_steps": 53110.0, "train/actor_opt_loss": -4.138981151031264, "train/adv_mag": 0.5403557491640673, "train/adv_max": 0.49139453946275913, "train/adv_mean": 0.0034896497107325584, "train/adv_min": -0.4425018288142292, "train/adv_std": 0.05985547927148799, "train/cont_avg": 0.9946808510638298, "train/cont_loss_mean": 0.00016452814494922232, "train/cont_loss_std": 0.004978738453743153, "train/cont_neg_acc": 0.9935119054147176, "train/cont_neg_loss": 0.02291713151910569, "train/cont_pos_acc": 0.999993014420178, "train/cont_pos_loss": 3.286710697406265e-05, "train/cont_pred": 0.9947096764618624, "train/cont_rate": 0.9946808510638298, "train/dyn_loss_mean": 12.883579227095801, "train/dyn_loss_std": 8.83169897228268, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8437622058476116, "train/extr_critic_critic_opt_grad_steps": 53110.0, "train/extr_critic_critic_opt_loss": 15838.74652316046, "train/extr_critic_mag": 7.396656979905798, "train/extr_critic_max": 7.396656979905798, "train/extr_critic_mean": 2.1297222866234202, "train/extr_critic_min": -0.16680960367757378, "train/extr_critic_std": 1.6651728601320415, "train/extr_return_normed_mag": 1.6062986512556143, "train/extr_return_normed_max": 1.6062986512556143, "train/extr_return_normed_mean": 0.3874629021536374, "train/extr_return_normed_min": -0.10955256355781082, "train/extr_return_normed_std": 0.3228305947061972, "train/extr_return_rate": 0.8035350615251149, "train/extr_return_raw_mag": 8.563636769639684, "train/extr_return_raw_max": 8.563636769639684, "train/extr_return_raw_mean": 2.148058186186121, "train/extr_return_raw_min": -0.4687616746899084, "train/extr_return_raw_std": 1.7000387653391411, "train/extr_reward_mag": 1.0273049841535853, "train/extr_reward_max": 1.0273049841535853, "train/extr_reward_mean": 0.035053274402698724, "train/extr_reward_min": -0.4058038571202163, "train/extr_reward_std": 0.1755002013123627, "train/image_loss_mean": 6.049827568919946, "train/image_loss_std": 11.047211751870229, "train/model_loss_mean": 13.836066482760382, "train/model_loss_std": 14.566023508707682, "train/model_opt_grad_norm": 48.035739262898765, "train/model_opt_grad_steps": 53059.72340425532, "train/model_opt_loss": 17666.023257424644, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.595744680851, "train/policy_entropy_mag": 2.4802301944570337, "train/policy_entropy_max": 2.4802301944570337, "train/policy_entropy_mean": 0.460330031865032, "train/policy_entropy_min": 0.07937505381538514, "train/policy_entropy_std": 0.5713674979852447, "train/policy_logprob_mag": 7.438383782163579, "train/policy_logprob_max": -0.009455658402954432, "train/policy_logprob_mean": -0.4606996647855069, "train/policy_logprob_min": -7.438383782163579, "train/policy_logprob_std": 1.0358013798159065, "train/policy_randomness_mag": 0.8754124172190403, "train/policy_randomness_max": 0.8754124172190403, "train/policy_randomness_mean": 0.16247630198585225, "train/policy_randomness_min": 0.02801591065441463, "train/policy_randomness_std": 0.2016676535420384, "train/post_ent_mag": 57.90817404131517, "train/post_ent_max": 57.90817404131517, "train/post_ent_mean": 41.663963263761914, "train/post_ent_min": 19.206370739226646, "train/post_ent_std": 7.777126721456542, "train/prior_ent_mag": 66.29183337705355, "train/prior_ent_max": 66.29183337705355, "train/prior_ent_mean": 54.60112949127846, "train/prior_ent_min": 41.775399011923064, "train/prior_ent_std": 3.885586442676842, "train/rep_loss_mean": 12.883579227095801, "train/rep_loss_std": 8.83169897228268, "train/reward_avg": 0.02668439687381611, "train/reward_loss_mean": 0.05592693367325668, "train/reward_loss_std": 0.2469359764181976, "train/reward_max_data": 1.0212766008174166, "train/reward_max_pred": 1.0163819384067616, "train/reward_neg_acc": 0.9921791587315553, "train/reward_neg_loss": 0.031087707216250347, "train/reward_pos_acc": 0.9727576539871541, "train/reward_pos_loss": 0.8252613464145796, "train/reward_pred": 0.02615844995338232, "train/reward_rate": 0.03130540780141844, "train_stats/sum_log_reward": 8.071698333857194, "train_stats/max_log_achievement_collect_coal": 0.04716981132075472, "train_stats/max_log_achievement_collect_drink": 4.415094339622642, "train_stats/max_log_achievement_collect_sapling": 2.1132075471698113, "train_stats/max_log_achievement_collect_stone": 0.8018867924528302, "train_stats/max_log_achievement_collect_wood": 15.320754716981131, "train_stats/max_log_achievement_defeat_skeleton": 0.03773584905660377, "train_stats/max_log_achievement_defeat_zombie": 1.7735849056603774, "train_stats/max_log_achievement_eat_cow": 0.24528301886792453, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.1320754716981134, "train_stats/max_log_achievement_make_wood_sword": 1.9056603773584906, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.0754716981132075, "train_stats/max_log_achievement_place_stone": 0.018867924528301886, "train_stats/max_log_achievement_place_table": 4.113207547169812, "train_stats/max_log_achievement_wake_up": 1.5943396226415094, "train_stats/mean_log_entropy": 0.4324214461277116, "eval_stats/sum_log_reward": 7.850000262260437, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_stone": 0.3125, "eval_stats/max_log_achievement_collect_wood": 16.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.8125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.5, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.875, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.5795390027051326e-06, "report/cont_loss_std": 2.8318609111011028e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00016830033564474434, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.614780201947724e-07, "report/cont_pred": 0.9951173663139343, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.297446250915527, "report/dyn_loss_std": 9.504688262939453, "report/image_loss_mean": 6.400910377502441, "report/image_loss_std": 12.371530532836914, "report/model_loss_mean": 14.434093475341797, "report/model_loss_std": 15.674516677856445, "report/post_ent_mag": 58.913997650146484, "report/post_ent_max": 58.913997650146484, "report/post_ent_mean": 41.08533477783203, "report/post_ent_min": 19.457555770874023, "report/post_ent_std": 8.1858549118042, "report/prior_ent_mag": 66.5838851928711, "report/prior_ent_max": 66.5838851928711, "report/prior_ent_mean": 54.337562561035156, "report/prior_ent_min": 41.726226806640625, "report/prior_ent_std": 4.310351848602295, "report/rep_loss_mean": 13.297446250915527, "report/rep_loss_std": 9.504688262939453, "report/reward_avg": 0.03281249850988388, "report/reward_loss_mean": 0.05471336841583252, "report/reward_loss_std": 0.21784476935863495, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011072158813477, "report/reward_neg_acc": 0.9929006099700928, "report/reward_neg_loss": 0.028884824365377426, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7248960733413696, "report/reward_pred": 0.03205784410238266, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0004788191872648895, "eval/cont_loss_std": 0.01191385742276907, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.518847319763154e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00048048049211502075, "eval/cont_pred": 0.9956793189048767, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.815338134765625, "eval/dyn_loss_std": 10.081671714782715, "eval/image_loss_mean": 9.613179206848145, "eval/image_loss_std": 15.967299461364746, "eval/model_loss_mean": 19.825284957885742, "eval/model_loss_std": 19.789443969726562, "eval/post_ent_mag": 57.91703796386719, "eval/post_ent_max": 57.91703796386719, "eval/post_ent_mean": 40.12039566040039, "eval/post_ent_min": 18.8481502532959, "eval/post_ent_std": 7.794497013092041, "eval/prior_ent_mag": 66.5838851928711, "eval/prior_ent_max": 66.5838851928711, "eval/prior_ent_mean": 55.2198486328125, "eval/prior_ent_min": 43.68482208251953, "eval/prior_ent_std": 3.892650604248047, "eval/rep_loss_mean": 16.815338134765625, "eval/rep_loss_std": 10.081671714782715, "eval/reward_avg": 0.04707031324505806, "eval/reward_loss_mean": 0.12242365628480911, "eval/reward_loss_std": 0.6559865474700928, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0008659362792969, "eval/reward_neg_acc": 0.9866393208503723, "eval/reward_neg_loss": 0.0346355214715004, "eval/reward_pos_acc": 0.8039215803146362, "eval/reward_pos_loss": 1.79728364944458, "eval/reward_pred": 0.0362815223634243, "eval/reward_rate": 0.0498046875, "replay/size": 862065.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.4091320071660036e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.560489870977739e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1728970765026376e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3568623065948, "timer/env.step_count": 2820.0, "timer/env.step_total": 245.97171926498413, "timer/env.step_frac": 0.2458839725433876, "timer/env.step_avg": 0.08722401392375324, "timer/env.step_min": 0.02337646484375, "timer/env.step_max": 3.4293124675750732, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.29113245010376, "timer/replay._sample_frac": 0.011287104507954273, "timer/replay._sample_avg": 0.0005004934596677199, "timer/replay._sample_min": 0.0003898143768310547, "timer/replay._sample_max": 0.00699162483215332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3278.0, "timer/agent.policy_total": 54.454506635665894, "timer/agent.policy_frac": 0.05443508080716937, "timer/agent.policy_avg": 0.016612113067622298, "timer/agent.policy_min": 0.009412527084350586, "timer/agent.policy_max": 0.12127161026000977, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.15534543991088867, "timer/dataset_train_frac": 0.0001552900227551771, "timer/dataset_train_avg": 0.00011017407085878629, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0010712146759033203, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 633.6028499603271, "timer/agent.train_frac": 0.6333768216468105, "timer/agent.train_avg": 0.4493637233761185, "timer/agent.train_min": 0.43325376510620117, "timer/agent.train_max": 2.486034870147705, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47523975372314453, "timer/agent.report_frac": 0.00047507021906897305, "timer/agent.report_avg": 0.23761987686157227, "timer/agent.report_min": 0.23099589347839355, "timer/agent.report_max": 0.24424386024475098, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289002670522163e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 22.551652536061127}
{"step": 862976, "time": 39474.00676417351, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 863136, "time": 39480.955505132675, "episode/length": 199.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 863296, "time": 39487.94117450714, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 863328, "time": 39490.52077436447, "episode/length": 245.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 863344, "time": 39492.63533115387, "episode/length": 247.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 863544, "time": 39500.675543785095, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 863640, "time": 39505.45339179039, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 863760, "time": 39511.234768390656, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 864352, "time": 39532.48515558243, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 864480, "time": 39538.2873339653, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 864720, "time": 39547.86776971817, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 864736, "time": 39550.47978949547, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 865008, "time": 39561.997004032135, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 865024, "time": 39564.46363854408, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 865120, "time": 39569.717651605606, "episode/length": 169.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 865200, "time": 39573.97855472565, "episode/length": 57.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 865584, "time": 39588.312890291214, "episode/length": 254.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 866256, "time": 39612.54742527008, "episode/length": 237.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 866360, "time": 39617.38923740387, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 866440, "time": 39621.86087560654, "episode/length": 244.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 866672, "time": 39631.60245037079, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 866792, "time": 39636.835349559784, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 867088, "time": 39648.5387237072, "episode/length": 235.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9872881355932204, "episode/intrinsic_return": 0.0}
{"step": 867152, "time": 39652.31476640701, "episode/length": 253.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 867432, "time": 39662.893146276474, "episode/length": 230.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 867872, "time": 39679.495077848434, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 868168, "time": 39690.77297091484, "episode/length": 225.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 868296, "time": 39696.63735246658, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 868392, "time": 39703.020548820496, "episode/length": 64.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 868680, "time": 39714.21548318863, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 868976, "time": 39725.970723629, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 868984, "time": 39727.55102944374, "episode/length": 236.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 869144, "time": 39734.45375299454, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 869336, "time": 39742.50710773468, "episode/length": 332.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 869768, "time": 39758.627311229706, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 869800, "time": 39761.196855306625, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 39791.47840309143, "eval_episode/length": 167.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 870064, "time": 39793.615033864975, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 870064, "time": 39793.62294125557, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 870064, "time": 39797.776201725006, "eval_episode/length": 198.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 870064, "time": 39799.98240494728, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 870064, "time": 39803.569110155106, "eval_episode/length": 259.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9769230769230769}
{"step": 870064, "time": 39807.48675298691, "eval_episode/length": 134.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 870064, "time": 39810.98443698883, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 870264, "time": 39817.48399591446, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 870360, "time": 39822.20541167259, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 870680, "time": 39834.42681789398, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 871040, "time": 39848.16869497299, "episode/length": 330.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 871056, "time": 39850.198808670044, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 871104, "time": 39853.339797735214, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 871240, "time": 39859.26638150215, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 871376, "time": 39865.62204480171, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 871968, "time": 39886.860721588135, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 872488, "time": 39905.954058885574, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 872512, "time": 39908.68689465523, "episode/length": 183.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 872632, "time": 39914.05824923515, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 872680, "time": 39917.21714925766, "episode/length": 179.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 872824, "time": 39923.607766866684, "episode/length": 307.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 873000, "time": 39931.04927778244, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 873488, "time": 39949.214738845825, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 873840, "time": 39962.48339891434, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 874072, "time": 39971.642037153244, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 874080, "time": 39973.6794629097, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 874256, "time": 39981.34380078316, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 874312, "time": 39984.543137550354, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 874696, "time": 39998.990941524506, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 875008, "time": 40011.1724896431, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 875592, "time": 40032.222576618195, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 875712, "time": 40037.9653980732, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 876040, "time": 40050.40693759918, "episode/length": 215.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 876208, "time": 40057.83118224144, "episode/length": 603.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 876224, "time": 40059.98240399361, "episode/length": 267.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 876496, "time": 40070.734102249146, "episode/length": 331.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.0}
{"step": 876576, "time": 40076.61163878441, "episode/length": 195.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 876984, "time": 40091.5981695652, "episode/length": 285.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 876992, "time": 40093.70489668846, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 877208, "time": 40102.165778398514, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 877352, "time": 40109.21128177643, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 877640, "time": 40121.03907251358, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 877664, "time": 40123.52402687073, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 877856, "time": 40131.637746572495, "episode/length": 169.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 878328, "time": 40148.72675871849, "episode/length": 218.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 878728, "time": 40163.78830194473, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 878760, "time": 40166.291284799576, "episode/length": 220.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 878984, "time": 40175.41354727745, "episode/length": 203.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 879216, "time": 40185.05550146103, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 879584, "time": 40199.08631134033, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 879688, "time": 40203.93075418472, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 879856, "time": 40211.22416615486, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693593314763231, "episode/intrinsic_return": 0.0}
{"step": 879872, "time": 40213.32796025276, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 40241.387284994125, "eval_episode/length": 176.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 880048, "time": 40243.35443210602, "eval_episode/length": 184.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 880048, "time": 40245.51192498207, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 880048, "time": 40247.18552184105, "eval_episode/length": 199.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.985}
{"step": 880048, "time": 40249.02284812927, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 880048, "time": 40251.131939888, "eval_episode/length": 210.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.976303317535545}
{"step": 880048, "time": 40252.660734176636, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9672897196261683}
{"step": 880048, "time": 40254.29159927368, "eval_episode/length": 32.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8787878787878788}
{"step": 880184, "time": 40258.61423420906, "episode/length": 149.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 880312, "time": 40264.46825170517, "episode/length": 56.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 880976, "time": 40288.552931308746, "episode/length": 173.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 880984, "time": 40290.14249587059, "episode/length": 281.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 881056, "time": 40294.25169587135, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 881168, "time": 40299.51518321037, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 881432, "time": 40309.68660068512, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 881672, "time": 40319.172028541565, "episode/length": 169.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 882176, "time": 40337.64318943024, "episode/length": 248.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 882256, "time": 40342.023111104965, "episode/length": 436.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9931350114416476, "episode/intrinsic_return": 0.0}
{"step": 882360, "time": 40346.93101143837, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 882552, "time": 40355.03515577316, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 882840, "time": 40366.17319607735, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 883192, "time": 40379.66689610481, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 883304, "time": 40385.08914422989, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 883320, "time": 40387.14505696297, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 884160, "time": 40417.26027107239, "episode/length": 247.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 884232, "time": 40421.11460161209, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 884568, "time": 40434.06058835983, "episode/length": 50.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 884576, "time": 40436.16467690468, "episode/length": 289.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 884600, "time": 40438.404268980026, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 884752, "time": 40446.93832540512, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 884912, "time": 40453.95750141144, "episode/length": 214.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 885033, "time": 40460.5071413517, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.239146205357143, "train/action_min": 0.0, "train/action_std": 3.041778893130166, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039493229280092884, "train/actor_opt_grad_steps": 54515.0, "train/actor_opt_loss": -6.35428535632257, "train/adv_mag": 0.5373226144484111, "train/adv_max": 0.5029212779232434, "train/adv_mean": 0.0031682088319809868, "train/adv_min": -0.42423517512423653, "train/adv_std": 0.058740202417331085, "train/cont_avg": 0.994921875, "train/cont_loss_mean": 0.0001851328319615066, "train/cont_loss_std": 0.005661753627652745, "train/cont_neg_acc": 0.9914078690867493, "train/cont_neg_loss": 0.016872594388165664, "train/cont_pos_acc": 0.9999718891722815, "train/cont_pos_loss": 0.0001003120720446203, "train/cont_pred": 0.9949151107243129, "train/cont_rate": 0.994921875, "train/dyn_loss_mean": 12.845140082495552, "train/dyn_loss_std": 8.817026131493705, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8813510724476405, "train/extr_critic_critic_opt_grad_steps": 54515.0, "train/extr_critic_critic_opt_loss": 15922.819203404018, "train/extr_critic_mag": 7.5666471890040805, "train/extr_critic_max": 7.5666471890040805, "train/extr_critic_mean": 2.084810563496181, "train/extr_critic_min": -0.177991418327604, "train/extr_critic_std": 1.6745049485138483, "train/extr_return_normed_mag": 1.6024645362581527, "train/extr_return_normed_max": 1.6024645362581527, "train/extr_return_normed_mean": 0.37532278671860697, "train/extr_return_normed_min": -0.11470058054796287, "train/extr_return_normed_std": 0.32073285547750335, "train/extr_return_rate": 0.7961542457342148, "train/extr_return_raw_mag": 8.6248945917402, "train/extr_return_raw_max": 8.6248945917402, "train/extr_return_raw_mean": 2.101607461486544, "train/extr_return_raw_min": -0.5031977693949427, "train/extr_return_raw_std": 1.705139866045543, "train/extr_reward_mag": 1.0337332112448556, "train/extr_reward_max": 1.0337332112448556, "train/extr_reward_mean": 0.03424668244219252, "train/extr_reward_min": -0.4200933856623513, "train/extr_reward_std": 0.17384339666792326, "train/image_loss_mean": 6.0084475823811125, "train/image_loss_std": 10.737975130762372, "train/model_loss_mean": 13.770249782289778, "train/model_loss_std": 14.255981976645334, "train/model_opt_grad_norm": 53.093350941794256, "train/model_opt_grad_steps": 54463.54285714286, "train/model_opt_loss": 19020.172551618303, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1383.9285714285713, "train/policy_entropy_mag": 2.4772397092410494, "train/policy_entropy_max": 2.4772397092410494, "train/policy_entropy_mean": 0.44772426784038544, "train/policy_entropy_min": 0.07937506059450762, "train/policy_entropy_std": 0.5592212730220386, "train/policy_logprob_mag": 7.438383780206952, "train/policy_logprob_max": -0.00945566178831671, "train/policy_logprob_mean": -0.4476534175021308, "train/policy_logprob_min": -7.438383780206952, "train/policy_logprob_std": 1.0289933068411692, "train/policy_randomness_mag": 0.8743569042001452, "train/policy_randomness_max": 0.8743569042001452, "train/policy_randomness_mean": 0.158027019990342, "train/policy_randomness_min": 0.02801591305594359, "train/policy_randomness_std": 0.19738057074802262, "train/post_ent_mag": 57.93732076372419, "train/post_ent_max": 57.93732076372419, "train/post_ent_mean": 41.64045241219657, "train/post_ent_min": 19.242629017148698, "train/post_ent_std": 7.772013017109463, "train/prior_ent_mag": 66.3014092036656, "train/prior_ent_max": 66.3014092036656, "train/prior_ent_mean": 54.552192769731796, "train/prior_ent_min": 41.75492899758475, "train/prior_ent_std": 3.9082211290087017, "train/rep_loss_mean": 12.845140082495552, "train/rep_loss_std": 8.817026131493705, "train/reward_avg": 0.026393694038103734, "train/reward_loss_mean": 0.054533010721206664, "train/reward_loss_std": 0.23630693373935563, "train/reward_max_data": 1.0157142894608633, "train/reward_max_pred": 1.0090770091329302, "train/reward_neg_acc": 0.9917776614427567, "train/reward_neg_loss": 0.029542705569682377, "train/reward_pos_acc": 0.9718881219625473, "train/reward_pos_loss": 0.8345252126455307, "train/reward_pred": 0.0256854756336127, "train/reward_rate": 0.030915178571428573, "train_stats/sum_log_reward": 8.00476206824893, "train_stats/max_log_achievement_collect_coal": 0.1619047619047619, "train_stats/max_log_achievement_collect_drink": 5.352380952380952, "train_stats/max_log_achievement_collect_sapling": 1.9714285714285715, "train_stats/max_log_achievement_collect_stone": 1.6476190476190475, "train_stats/max_log_achievement_collect_wood": 15.352380952380953, "train_stats/max_log_achievement_defeat_skeleton": 0.009523809523809525, "train_stats/max_log_achievement_defeat_zombie": 1.5904761904761904, "train_stats/max_log_achievement_eat_cow": 0.1523809523809524, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.3904761904761904, "train_stats/max_log_achievement_make_wood_sword": 1.561904761904762, "train_stats/max_log_achievement_place_furnace": 0.009523809523809525, "train_stats/max_log_achievement_place_plant": 1.9142857142857144, "train_stats/max_log_achievement_place_stone": 0.02857142857142857, "train_stats/max_log_achievement_place_table": 4.285714285714286, "train_stats/max_log_achievement_wake_up": 1.3523809523809525, "train_stats/mean_log_entropy": 0.42870237018380847, "eval_stats/sum_log_reward": 7.47500020917505, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.6875, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 13.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0001097050990210846, "report/cont_loss_std": 0.00349802034907043, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02241664193570614, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5006085024870117e-07, "report/cont_pred": 0.9952205419540405, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.449932098388672, "report/dyn_loss_std": 9.08421516418457, "report/image_loss_mean": 6.314416408538818, "report/image_loss_std": 10.069644927978516, "report/model_loss_mean": 14.442974090576172, "report/model_loss_std": 13.788939476013184, "report/post_ent_mag": 59.09663391113281, "report/post_ent_max": 59.09663391113281, "report/post_ent_mean": 41.23694610595703, "report/post_ent_min": 16.789997100830078, "report/post_ent_std": 7.70565128326416, "report/prior_ent_mag": 66.69352722167969, "report/prior_ent_max": 66.69352722167969, "report/prior_ent_mean": 54.921630859375, "report/prior_ent_min": 42.424720764160156, "report/prior_ent_std": 3.740729331970215, "report/rep_loss_mean": 13.449932098388672, "report/rep_loss_std": 9.08421516418457, "report/reward_avg": 0.03105468675494194, "report/reward_loss_mean": 0.058489058166742325, "report/reward_loss_std": 0.23912735283374786, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014729499816895, "report/reward_neg_acc": 0.9949442744255066, "report/reward_neg_loss": 0.03320835158228874, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7728495597839355, "report/reward_pred": 0.02969500981271267, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 9.699388101580553e-07, "eval/cont_loss_std": 2.5925861336872913e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.4654293408966623e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.431592502551212e-07, "eval/cont_pred": 0.9980460405349731, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.967586517333984, "eval/dyn_loss_std": 10.259861946105957, "eval/image_loss_mean": 11.080690383911133, "eval/image_loss_std": 17.1014347076416, "eval/model_loss_mean": 21.326492309570312, "eval/model_loss_std": 21.13523292541504, "eval/post_ent_mag": 56.25823211669922, "eval/post_ent_max": 56.25823211669922, "eval/post_ent_mean": 39.75063705444336, "eval/post_ent_min": 19.480863571166992, "eval/post_ent_std": 7.801825046539307, "eval/prior_ent_mag": 66.69352722167969, "eval/prior_ent_max": 66.69352722167969, "eval/prior_ent_mean": 54.4993896484375, "eval/prior_ent_min": 38.864898681640625, "eval/prior_ent_std": 3.424825429916382, "eval/rep_loss_mean": 16.967586517333984, "eval/rep_loss_std": 10.259861946105957, "eval/reward_avg": 0.03750000149011612, "eval/reward_loss_mean": 0.06525149941444397, "eval/reward_loss_std": 0.3338315486907959, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023813247680664, "eval/reward_neg_acc": 0.9857578873634338, "eval/reward_neg_loss": 0.030879100784659386, "eval/reward_pos_acc": 0.9756097197532654, "eval/reward_pos_loss": 0.8893504738807678, "eval/reward_pred": 0.03989846259355545, "eval/reward_rate": 0.0400390625, "replay/size": 884529.0, "replay/inserts": 22464.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.3895545080516412e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.436570958194569e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1455332119159632e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1687052249908, "timer/env.step_count": 2808.0, "timer/env.step_total": 243.7096405029297, "timer/env.step_frac": 0.24366853234835667, "timer/env.step_avg": 0.08679118251528835, "timer/env.step_min": 0.023093223571777344, "timer/env.step_max": 2.1583657264709473, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.393807888031006, "timer/replay._sample_frac": 0.01139188601733738, "timer/replay._sample_avg": 0.0005072029864686168, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.028472185134887695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3386.0, "timer/agent.policy_total": 54.48100280761719, "timer/agent.policy_frac": 0.054471813128127745, "timer/agent.policy_avg": 0.0160900776159531, "timer/agent.policy_min": 0.009177684783935547, "timer/agent.policy_max": 0.12115025520324707, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.1524360179901123, "timer/dataset_train_frac": 0.0001524103055752193, "timer/dataset_train_avg": 0.00010857266238611988, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0010836124420166016, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 633.448789358139, "timer/agent.train_frac": 0.633341941263442, "timer/agent.train_avg": 0.4511743513946859, "timer/agent.train_min": 0.4367249011993408, "timer/agent.train_max": 1.613098382949829, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472562313079834, "timer/agent.report_frac": 0.00047248260279602504, "timer/agent.report_avg": 0.236281156539917, "timer/agent.report_min": 0.229888916015625, "timer/agent.report_max": 0.24267339706420898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027405215511822e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 22.459897156938894}
{"step": 885072, "time": 40461.89375782013, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 885464, "time": 40476.5233631134, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 885696, "time": 40486.51948618889, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 886224, "time": 40505.946157455444, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 886384, "time": 40512.95324373245, "episode/length": 163.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 886416, "time": 40515.554762363434, "episode/length": 230.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 886448, "time": 40518.203557014465, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 886880, "time": 40534.38868570328, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 887064, "time": 40541.874138355255, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 887280, "time": 40550.85582137108, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 887504, "time": 40560.08932495117, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 887576, "time": 40563.93196940422, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 887632, "time": 40567.62170171738, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 887808, "time": 40575.03554272652, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 888224, "time": 40590.56303215027, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 888584, "time": 40604.164283037186, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 888648, "time": 40608.40083646774, "episode/length": 52.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 888896, "time": 40619.37577009201, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 888928, "time": 40622.078997612, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 888976, "time": 40625.19014620781, "episode/length": 261.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 889176, "time": 40633.039805173874, "episode/length": 199.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 889568, "time": 40647.98617529869, "episode/length": 257.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 889648, "time": 40652.207201480865, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 890008, "time": 40665.6710460186, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 40683.698158979416, "eval_episode/length": 58.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 890032, "time": 40691.45762038231, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 890032, "time": 40694.39235210419, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 890032, "time": 40696.106786727905, "eval_episode/length": 196.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 890032, "time": 40697.87258028984, "eval_episode/length": 202.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 890032, "time": 40699.6718313694, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 890032, "time": 40702.07077670097, "eval_episode/length": 225.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 890032, "time": 40705.53263735771, "eval_episode/length": 271.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9963235294117647}
{"step": 890120, "time": 40708.24871587753, "episode/length": 68.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 890208, "time": 40713.016103982925, "episode/length": 153.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 890232, "time": 40715.01663303375, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 890304, "time": 40719.24030256271, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 890504, "time": 40727.277134656906, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 890680, "time": 40734.94526410103, "episode/length": 55.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 890784, "time": 40740.056414842606, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 890984, "time": 40748.06003284454, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 891240, "time": 40758.676144361496, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 891384, "time": 40765.102038383484, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 891616, "time": 40774.78766989708, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 891688, "time": 40778.57089614868, "episode/length": 209.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 891976, "time": 40789.84304237366, "episode/length": 231.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 892120, "time": 40796.408672332764, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 892512, "time": 40811.3743083477, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 892712, "time": 40819.5116379261, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 893048, "time": 40833.758985996246, "episode/length": 257.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 893152, "time": 40839.002766132355, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 893240, "time": 40843.29638624191, "episode/length": 202.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 893336, "time": 40848.09083342552, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 893544, "time": 40856.66921043396, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 893912, "time": 40870.409408569336, "episode/length": 241.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 894136, "time": 40879.497786045074, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 894624, "time": 40897.74640607834, "episode/length": 238.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 894792, "time": 40904.8224670887, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 895024, "time": 40914.75982117653, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 895056, "time": 40917.859362602234, "episode/length": 237.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 895184, "time": 40924.28082942963, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 895224, "time": 40926.93136239052, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 895544, "time": 40939.27425265312, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 896272, "time": 40965.401201725006, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 896328, "time": 40968.656593322754, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 896464, "time": 40975.08455038071, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 896656, "time": 40983.03537464142, "episode/length": 426.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 896672, "time": 40985.05732822418, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 896752, "time": 40989.254247903824, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 897080, "time": 41001.42145371437, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 897208, "time": 41007.2414226532, "episode/length": 56.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 897592, "time": 41021.56121277809, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 897752, "time": 41028.5916492939, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 897848, "time": 41033.42260718346, "episode/length": 146.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 898112, "time": 41044.07925534248, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 898424, "time": 41056.010264635086, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 898528, "time": 41061.38496017456, "episode/length": 180.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 898544, "time": 41063.519468545914, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 899088, "time": 41083.18064522743, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 899296, "time": 41091.65774512291, "episode/length": 212.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 899624, "time": 41103.99009394646, "episode/length": 233.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 899776, "time": 41110.941767930984, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 899840, "time": 41114.677505254745, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 899864, "time": 41116.885192632675, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 899880, "time": 41119.061876535416, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 41145.82462120056, "eval_episode/length": 174.0, "eval_episode/score": 7.100000038743019, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 900016, "time": 41147.525696754456, "eval_episode/length": 178.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9608938547486033}
{"step": 900016, "time": 41150.02191257477, "eval_episode/length": 185.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 900016, "time": 41152.013261795044, "eval_episode/length": 198.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 900016, "time": 41154.36692881584, "eval_episode/length": 219.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 900016, "time": 41157.00093984604, "eval_episode/length": 246.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.979757085020243}
{"step": 900016, "time": 41159.112766981125, "eval_episode/length": 257.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9806201550387597}
{"step": 900016, "time": 41162.84334897995, "eval_episode/length": 310.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9903536977491961}
{"step": 900144, "time": 41167.11978292465, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 900352, "time": 41175.730365753174, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 901064, "time": 41200.94409942627, "episode/length": 160.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 901104, "time": 41204.075684547424, "episode/length": 184.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 901296, "time": 41213.59008717537, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.968, "episode/intrinsic_return": 0.0}
{"step": 901744, "time": 41230.19617271423, "episode/length": 232.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 901776, "time": 41232.81816124916, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 901824, "time": 41235.99128365517, "episode/length": 247.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 902056, "time": 41245.38968491554, "episode/length": 238.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 902248, "time": 41253.900131464005, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 902752, "time": 41272.46354532242, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 902992, "time": 41281.95470190048, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 903328, "time": 41294.71409916878, "episode/length": 282.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 903432, "time": 41299.762473106384, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 903464, "time": 41302.35856938362, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 903512, "time": 41305.483720541, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 903696, "time": 41313.45580339432, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 903744, "time": 41316.73390960693, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 904208, "time": 41333.69798541069, "episode/length": 181.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 904624, "time": 41349.20313024521, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 904760, "time": 41355.0958302021, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 904816, "time": 41358.95314216614, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 905040, "time": 41367.96059679985, "episode/length": 161.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 905280, "time": 41377.645713567734, "episode/length": 243.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 905440, "time": 41384.59585762024, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 905632, "time": 41392.76722860336, "episode/length": 264.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 905672, "time": 41395.45574092865, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 905944, "time": 41406.17241811752, "episode/length": 147.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 906152, "time": 41414.82178783417, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 906496, "time": 41428.18457508087, "episode/length": 233.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 906528, "time": 41430.857308626175, "episode/length": 135.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 906664, "time": 41436.785569906235, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 906992, "time": 41449.7060508728, "episode/length": 169.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 907000, "time": 41451.730697631836, "episode/length": 41.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 907177, "time": 41460.65022921562, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.283505227068345, "train/action_min": 0.0, "train/action_std": 3.10311064274191, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039827235632663154, "train/actor_opt_grad_steps": 55910.0, "train/actor_opt_loss": -8.850108213561901, "train/adv_mag": 0.529811281952069, "train/adv_max": 0.48020708410859964, "train/adv_mean": 0.0023386067374604803, "train/adv_min": -0.43758304899545025, "train/adv_std": 0.058456736261681685, "train/cont_avg": 0.9949274955035972, "train/cont_loss_mean": 0.00017494864777770888, "train/cont_loss_std": 0.005376334027485521, "train/cont_neg_acc": 0.9951353214627547, "train/cont_neg_loss": 0.01687925879271219, "train/cont_pos_acc": 0.9999576412516532, "train/cont_pos_loss": 8.182839996100797e-05, "train/cont_pred": 0.9949207554618231, "train/cont_rate": 0.9949274955035972, "train/dyn_loss_mean": 12.905989996820903, "train/dyn_loss_std": 8.864442331327808, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.844240375988775, "train/extr_critic_critic_opt_grad_steps": 55910.0, "train/extr_critic_critic_opt_loss": 15837.796116232015, "train/extr_critic_mag": 7.621334885521758, "train/extr_critic_max": 7.621334885521758, "train/extr_critic_mean": 2.140263309581674, "train/extr_critic_min": -0.17042940297572734, "train/extr_critic_std": 1.6587092996501236, "train/extr_return_normed_mag": 1.594033272146321, "train/extr_return_normed_max": 1.594033272146321, "train/extr_return_normed_mean": 0.38231300835986787, "train/extr_return_normed_min": -0.11361051616158417, "train/extr_return_normed_std": 0.3194438778667999, "train/extr_return_rate": 0.8164493818934873, "train/extr_return_raw_mag": 8.554454683399886, "train/extr_return_raw_max": 8.554454683399886, "train/extr_return_raw_mean": 2.1526370528790593, "train/extr_return_raw_min": -0.46709896323921013, "train/extr_return_raw_std": 1.6874654121536146, "train/extr_reward_mag": 1.0297841030916721, "train/extr_reward_max": 1.0297841030916721, "train/extr_reward_mean": 0.035239161910127395, "train/extr_reward_min": -0.4197831162445837, "train/extr_reward_std": 0.17646130769372845, "train/image_loss_mean": 5.960941067702478, "train/image_loss_std": 11.133378522859203, "train/model_loss_mean": 13.759235649657764, "train/model_loss_std": 14.669688979498774, "train/model_opt_grad_norm": 51.03068934927742, "train/model_opt_grad_steps": 55857.11510791367, "train/model_opt_loss": 16858.805541113983, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1227.5179856115108, "train/policy_entropy_mag": 2.467918269068217, "train/policy_entropy_max": 2.467918269068217, "train/policy_entropy_mean": 0.461479312438759, "train/policy_entropy_min": 0.07937506827519095, "train/policy_entropy_std": 0.5805037411854421, "train/policy_logprob_mag": 7.438383809096521, "train/policy_logprob_max": -0.009455662669627357, "train/policy_logprob_mean": -0.46157979086148654, "train/policy_logprob_min": -7.438383809096521, "train/policy_logprob_std": 1.0367818573395984, "train/policy_randomness_mag": 0.8710668477223074, "train/policy_randomness_max": 0.8710668477223074, "train/policy_randomness_mean": 0.16288194671380435, "train/policy_randomness_min": 0.028015915679631475, "train/policy_randomness_std": 0.20489234761368458, "train/post_ent_mag": 57.83786397700687, "train/post_ent_max": 57.83786397700687, "train/post_ent_mean": 41.5858015430917, "train/post_ent_min": 19.00235242637799, "train/post_ent_std": 7.74477677722629, "train/prior_ent_mag": 66.32026880936657, "train/prior_ent_max": 66.32026880936657, "train/prior_ent_mean": 54.54831934318268, "train/prior_ent_min": 41.627832261778465, "train/prior_ent_std": 3.863098626514133, "train/rep_loss_mean": 12.905989996820903, "train/rep_loss_std": 8.864442331327808, "train/reward_avg": 0.027310729395303365, "train/reward_loss_mean": 0.054525767754522156, "train/reward_loss_std": 0.24581419649741632, "train/reward_max_data": 1.0244604374864976, "train/reward_max_pred": 1.014823957312879, "train/reward_neg_acc": 0.9931434375776661, "train/reward_neg_loss": 0.02905859105396185, "train/reward_pos_acc": 0.9693945693455154, "train/reward_pos_loss": 0.8287019399430254, "train/reward_pred": 0.02665340754357602, "train/reward_rate": 0.03184717850719424, "train_stats/sum_log_reward": 7.7727274027737705, "train_stats/max_log_achievement_collect_coal": 0.16363636363636364, "train_stats/max_log_achievement_collect_drink": 5.072727272727272, "train_stats/max_log_achievement_collect_sapling": 1.7181818181818183, "train_stats/max_log_achievement_collect_stone": 2.327272727272727, "train_stats/max_log_achievement_collect_wood": 14.763636363636364, "train_stats/max_log_achievement_defeat_skeleton": 0.05454545454545454, "train_stats/max_log_achievement_defeat_zombie": 1.4636363636363636, "train_stats/max_log_achievement_eat_cow": 0.12727272727272726, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.481818181818182, "train_stats/max_log_achievement_make_wood_sword": 0.5636363636363636, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6545454545454545, "train_stats/max_log_achievement_place_stone": 0.00909090909090909, "train_stats/max_log_achievement_place_table": 4.2727272727272725, "train_stats/max_log_achievement_wake_up": 1.1272727272727272, "train_stats/mean_log_entropy": 0.4014649125662717, "eval_stats/sum_log_reward": 7.350000083446503, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 5.1875, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 1.0625, "eval_stats/max_log_achievement_collect_wood": 18.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 4.875, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 5.25, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.4224427508888766e-05, "report/cont_loss_std": 0.0010468896944075823, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.0381731903617037e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.437745544943027e-05, "report/cont_pred": 0.9950833916664124, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.76400375366211, "report/dyn_loss_std": 8.646537780761719, "report/image_loss_mean": 6.828251838684082, "report/image_loss_std": 8.15329647064209, "report/model_loss_mean": 14.553215026855469, "report/model_loss_std": 11.437076568603516, "report/post_ent_mag": 58.59363555908203, "report/post_ent_max": 58.59363555908203, "report/post_ent_mean": 42.588706970214844, "report/post_ent_min": 19.50150489807129, "report/post_ent_std": 8.082468032836914, "report/prior_ent_mag": 66.3729248046875, "report/prior_ent_max": 66.3729248046875, "report/prior_ent_mean": 55.24237060546875, "report/prior_ent_min": 42.83732986450195, "report/prior_ent_std": 4.078680515289307, "report/rep_loss_mean": 12.76400375366211, "report/rep_loss_std": 8.646537780761719, "report/reward_avg": 0.03388671949505806, "report/reward_loss_mean": 0.0665266215801239, "report/reward_loss_std": 0.2774958908557892, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002375841140747, "report/reward_neg_acc": 0.997967541217804, "report/reward_neg_loss": 0.03570796176791191, "report/reward_pos_acc": 0.9750000238418579, "report/reward_pos_loss": 0.8246656656265259, "report/reward_pred": 0.030822306871414185, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.5992125049233437e-06, "eval/cont_loss_std": 6.219706847332418e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005517820245586336, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.094050028579659e-07, "eval/cont_pred": 0.9951188564300537, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.53727149963379, "eval/dyn_loss_std": 9.739452362060547, "eval/image_loss_mean": 8.904144287109375, "eval/image_loss_std": 13.373642921447754, "eval/model_loss_mean": 18.93851089477539, "eval/model_loss_std": 17.027191162109375, "eval/post_ent_mag": 58.30343246459961, "eval/post_ent_max": 58.30343246459961, "eval/post_ent_mean": 40.582637786865234, "eval/post_ent_min": 18.5259952545166, "eval/post_ent_std": 8.0236234664917, "eval/prior_ent_mag": 66.3729248046875, "eval/prior_ent_max": 66.3729248046875, "eval/prior_ent_mean": 55.33417510986328, "eval/prior_ent_min": 43.05893325805664, "eval/prior_ent_std": 3.5355284214019775, "eval/rep_loss_mean": 16.53727149963379, "eval/rep_loss_std": 9.739452362060547, "eval/reward_avg": 0.02763671800494194, "eval/reward_loss_mean": 0.11199946701526642, "eval/reward_loss_std": 0.7285579442977905, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002403974533081, "eval/reward_neg_acc": 0.9888888001441956, "eval/reward_neg_loss": 0.046023257076740265, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 2.033071279525757, "eval/reward_pred": 0.0259990431368351, "eval/reward_rate": 0.033203125, "replay/size": 906673.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.3957564541370193e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.527239749886396e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1847317729969581e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1264593601227, "timer/env.step_count": 2768.0, "timer/env.step_total": 251.70351004600525, "timer/env.step_frac": 0.25167168380591015, "timer/env.step_avg": 0.0909333490050597, "timer/env.step_min": 0.02337956428527832, "timer/env.step_max": 2.3534305095672607, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.281084060668945, "timer/replay._sample_frac": 0.011279657642381086, "timer/replay._sample_avg": 0.0005094420186357002, "timer/replay._sample_min": 0.0003941059112548828, "timer/replay._sample_max": 0.011148691177368164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3351.0, "timer/agent.policy_total": 55.720677852630615, "timer/agent.policy_frac": 0.05571363234233449, "timer/agent.policy_avg": 0.01662807456061791, "timer/agent.policy_min": 0.009328603744506836, "timer/agent.policy_max": 0.12543153762817383, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.14963436126708984, "timer/dataset_train_frac": 0.00014961544099415726, "timer/dataset_train_avg": 0.00010811731305425566, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004906654357910156, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 623.8395953178406, "timer/agent.train_frac": 0.62376071493696, "timer/agent.train_avg": 0.450751152686301, "timer/agent.train_min": 0.4371795654296875, "timer/agent.train_max": 1.5435974597930908, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47260022163391113, "timer/agent.report_frac": 0.00047254046446914226, "timer/agent.report_avg": 0.23630011081695557, "timer/agent.report_min": 0.22878193855285645, "timer/agent.report_max": 0.2438182830810547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1228884677531024e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 22.14090078888949}
{"step": 907256, "time": 41463.10377120972, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 907432, "time": 41470.58257627487, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 907696, "time": 41481.92814254761, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 907784, "time": 41486.224443912506, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 907880, "time": 41490.998904943466, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 908040, "time": 41497.8252120018, "episode/length": 75.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 908224, "time": 41505.60796046257, "episode/length": 152.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 908328, "time": 41510.6338198185, "episode/length": 380.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9868766404199475, "episode/intrinsic_return": 0.0}
{"step": 908512, "time": 41518.4847342968, "episode/length": 35.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 908608, "time": 41523.1675093174, "episode/length": 201.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 909080, "time": 41540.381786584854, "episode/length": 227.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 909152, "time": 41544.53304696083, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 909624, "time": 41563.05516386032, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 909640, "time": 41565.16306638718, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 909864, "time": 41574.328610658646, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 909920, "time": 41578.03046989441, "episode/length": 198.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41596.37239027023, "eval_episode/length": 28.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8620689655172413}
{"step": 910000, "time": 41604.40514087677, "eval_episode/length": 179.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 910000, "time": 41606.585173130035, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 910000, "time": 41608.83712053299, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 910000, "time": 41611.13927030563, "eval_episode/length": 195.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 910000, "time": 41613.81540417671, "eval_episode/length": 246.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 910000, "time": 41615.416942596436, "eval_episode/length": 247.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 910000, "time": 41617.59816241264, "eval_episode/length": 263.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9734848484848485}
{"step": 910088, "time": 41620.291602134705, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 910112, "time": 41622.8007273674, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 911072, "time": 41656.11547470093, "episode/length": 239.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 911208, "time": 41662.024725914, "episode/length": 195.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 911592, "time": 41676.38518714905, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 911600, "time": 41678.46223974228, "episode/length": 188.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 911608, "time": 41679.90134859085, "episode/length": 247.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 911688, "time": 41684.09406065941, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 911936, "time": 41694.3612241745, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 912024, "time": 41698.69216346741, "episode/length": 53.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 912496, "time": 41716.170028448105, "episode/length": 58.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 912576, "time": 41720.53036952019, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 913264, "time": 41745.34289765358, "episode/length": 522.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.994263862332696, "episode/intrinsic_return": 0.0}
{"step": 913296, "time": 41748.05626654625, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 913392, "time": 41752.96775341034, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 913424, "time": 41755.63244557381, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 913568, "time": 41762.01108980179, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 913736, "time": 41769.05600452423, "episode/length": 144.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 914160, "time": 41784.961337566376, "episode/length": 73.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 914368, "time": 41793.51206612587, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 914800, "time": 41809.38144373894, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 914808, "time": 41811.028527498245, "episode/length": 358.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 915208, "time": 41825.89687156677, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 915264, "time": 41829.51676297188, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 915520, "time": 41839.4649271965, "episode/length": 222.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 915544, "time": 41841.57616877556, "episode/length": 280.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9679715302491103, "episode/intrinsic_return": 0.0}
{"step": 915608, "time": 41845.20853185654, "episode/length": 180.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 916272, "time": 41869.11047077179, "episode/length": 237.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 916416, "time": 41875.369596004486, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 916800, "time": 41889.78577828407, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 916824, "time": 41891.9451854229, "episode/length": 50.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 916944, "time": 41897.75390601158, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 917120, "time": 41905.24342465401, "episode/length": 238.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 917296, "time": 41912.690247774124, "episode/length": 221.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 917304, "time": 41914.34417510033, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 917528, "time": 41924.909712314606, "episode/length": 247.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 917952, "time": 41940.89950942993, "episode/length": 143.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 918272, "time": 41953.15799498558, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 918352, "time": 41957.425151348114, "episode/length": 259.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 918640, "time": 41968.580753088, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 918688, "time": 41971.72312068939, "episode/length": 173.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 918776, "time": 41975.98093152046, "episode/length": 183.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 919168, "time": 41990.90608525276, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 919616, "time": 42007.44092941284, "episode/length": 333.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 919800, "time": 42014.91593384743, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 42044.46120977402, "eval_episode/length": 129.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 920088, "time": 42048.978623628616, "eval_episode/length": 193.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 920088, "time": 42048.98589682579, "eval_episode/length": 193.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 920088, "time": 42052.75285625458, "eval_episode/length": 203.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 920088, "time": 42055.381970644, "eval_episode/length": 227.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 920088, "time": 42057.16649198532, "eval_episode/length": 233.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 920088, "time": 42064.138702869415, "eval_episode/length": 317.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 920088, "time": 42069.056718826294, "eval_episode/length": 262.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9771863117870723}
{"step": 920384, "time": 42079.20123362541, "episode/length": 253.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 920416, "time": 42081.801787137985, "episode/length": 221.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 920912, "time": 42099.94894552231, "episode/length": 266.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 921200, "time": 42111.10024690628, "episode/length": 253.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 921224, "time": 42113.21029138565, "episode/length": 316.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 921464, "time": 42122.783472537994, "episode/length": 438.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9931662870159453, "episode/intrinsic_return": 0.0}
{"step": 921584, "time": 42128.63371181488, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 922112, "time": 42147.897280454636, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 922384, "time": 42158.671001672745, "episode/length": 144.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 922440, "time": 42161.94555211067, "episode/length": 256.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 922712, "time": 42172.6025056839, "episode/length": 155.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 922736, "time": 42175.225424051285, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 923128, "time": 42189.79867434502, "episode/length": 240.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 923448, "time": 42202.18180298805, "episode/length": 91.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 923640, "time": 42210.122373104095, "episode/length": 502.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9980119284294234, "episode/intrinsic_return": 0.0}
{"step": 923864, "time": 42219.19945216179, "episode/length": 284.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 924016, "time": 42226.04425883293, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 924048, "time": 42228.683336019516, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 924656, "time": 42250.38645744324, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 924864, "time": 42259.180292606354, "episode/length": 302.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 924992, "time": 42265.665085315704, "episode/length": 359.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 925520, "time": 42285.45710706711, "episode/length": 234.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 925624, "time": 42290.94993400574, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 925640, "time": 42293.40560603142, "episode/length": 122.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 926056, "time": 42310.95935368538, "episode/length": 325.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 926624, "time": 42331.71888756752, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 926832, "time": 42340.213841199875, "episode/length": 347.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.0}
{"step": 927088, "time": 42350.31669473648, "episode/length": 383.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 927200, "time": 42355.56710481644, "episode/length": 196.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 927216, "time": 42357.63521671295, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 927496, "time": 42368.189781188965, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808306709265175, "episode/intrinsic_return": 0.0}
{"step": 927776, "time": 42379.360673666, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 928400, "time": 42401.61470890045, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 928840, "time": 42417.80688071251, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 928856, "time": 42419.94879364967, "episode/length": 252.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 928960, "time": 42425.15309405327, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 929176, "time": 42433.6319103241, "episode/length": 260.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 929592, "time": 42449.05444645882, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 929784, "time": 42456.93239283562, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 929833, "time": 42461.09887838364, "train_stats/sum_log_reward": 8.450000205039977, "train_stats/max_log_achievement_collect_coal": 0.23, "train_stats/max_log_achievement_collect_drink": 5.54, "train_stats/max_log_achievement_collect_sapling": 1.71, "train_stats/max_log_achievement_collect_stone": 3.32, "train_stats/max_log_achievement_collect_wood": 15.04, "train_stats/max_log_achievement_defeat_skeleton": 0.06, "train_stats/max_log_achievement_defeat_zombie": 1.54, "train_stats/max_log_achievement_eat_cow": 0.25, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.49, "train_stats/max_log_achievement_make_wood_sword": 1.2, "train_stats/max_log_achievement_place_furnace": 0.01, "train_stats/max_log_achievement_place_plant": 1.66, "train_stats/max_log_achievement_place_stone": 0.04, "train_stats/max_log_achievement_place_table": 4.25, "train_stats/max_log_achievement_wake_up": 1.37, "train_stats/mean_log_entropy": 0.4494086696207523, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.288724425836658, "train/action_min": 0.0, "train/action_std": 3.1503901599992252, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04215769087961802, "train/actor_opt_grad_steps": 57310.0, "train/actor_opt_loss": -4.055117163820364, "train/adv_mag": 0.5561552538093946, "train/adv_max": 0.5063462181294218, "train/adv_mean": 0.0035496811427985953, "train/adv_min": -0.4545371965736362, "train/adv_std": 0.062130125384804204, "train/cont_avg": 0.9949509640957447, "train/cont_loss_mean": 0.00016682188780942588, "train/cont_loss_std": 0.005093190507604539, "train/cont_neg_acc": 0.9900709230003627, "train/cont_neg_loss": 0.019895478659480187, "train/cont_pos_acc": 0.9999651735556041, "train/cont_pos_loss": 8.934416868092055e-05, "train/cont_pred": 0.9949465199565211, "train/cont_rate": 0.9949509640957447, "train/dyn_loss_mean": 12.765237267135728, "train/dyn_loss_std": 8.789189095192768, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8451559306881952, "train/extr_critic_critic_opt_grad_steps": 57310.0, "train/extr_critic_critic_opt_loss": 15991.150605330231, "train/extr_critic_mag": 7.6078220732668616, "train/extr_critic_max": 7.6078220732668616, "train/extr_critic_mean": 2.1414045661899217, "train/extr_critic_min": -0.16324011231145114, "train/extr_critic_std": 1.6058779642091576, "train/extr_return_normed_mag": 1.629534584410647, "train/extr_return_normed_max": 1.629534584410647, "train/extr_return_normed_mean": 0.3836486030977668, "train/extr_return_normed_min": -0.1303496408864116, "train/extr_return_normed_std": 0.31820253224660316, "train/extr_return_rate": 0.8352407931436038, "train/extr_return_raw_mag": 8.57301985963862, "train/extr_return_raw_max": 8.57301985963862, "train/extr_return_raw_mean": 2.159679423832724, "train/extr_return_raw_min": -0.4862730213513611, "train/extr_return_raw_std": 1.638042022150459, "train/extr_reward_mag": 1.0267139309686972, "train/extr_reward_max": 1.0267139309686972, "train/extr_reward_mean": 0.03676614236641437, "train/extr_reward_min": -0.42974837282870676, "train/extr_reward_std": 0.17972042480259076, "train/image_loss_mean": 5.945651742583471, "train/image_loss_std": 10.694697938066847, "train/model_loss_mean": 13.658657689466544, "train/model_loss_std": 14.194999992424714, "train/model_opt_grad_norm": 49.75028378912743, "train/model_opt_grad_steps": 57256.0, "train/model_opt_loss": 13103.322719276373, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 961.8794326241135, "train/policy_entropy_mag": 2.474942995301375, "train/policy_entropy_max": 2.474942995301375, "train/policy_entropy_mean": 0.4735279812457714, "train/policy_entropy_min": 0.07937504837276242, "train/policy_entropy_std": 0.5921513966634764, "train/policy_logprob_mag": 7.4383838125999935, "train/policy_logprob_max": -0.009455659241805263, "train/policy_logprob_mean": -0.47478628602433715, "train/policy_logprob_min": -7.4383838125999935, "train/policy_logprob_std": 1.049769843723757, "train/policy_randomness_mag": 0.8735462706139747, "train/policy_randomness_max": 0.8735462706139747, "train/policy_randomness_mean": 0.16713459705207365, "train/policy_randomness_min": 0.028015908699297737, "train/policy_randomness_std": 0.20900345768066161, "train/post_ent_mag": 57.82806515524573, "train/post_ent_max": 57.82806515524573, "train/post_ent_mean": 41.73693071189501, "train/post_ent_min": 19.201892683692012, "train/post_ent_std": 7.74048003068207, "train/prior_ent_mag": 66.32344358187196, "train/prior_ent_max": 66.32344358187196, "train/prior_ent_mean": 54.55287511297997, "train/prior_ent_min": 41.567912189673024, "train/prior_ent_std": 3.9301754971767995, "train/rep_loss_mean": 12.765237267135728, "train/rep_loss_std": 8.789189095192768, "train/reward_avg": 0.026899794711077465, "train/reward_loss_mean": 0.053696883247887836, "train/reward_loss_std": 0.23285816599291267, "train/reward_max_data": 1.0198581607629222, "train/reward_max_pred": 1.01128706948977, "train/reward_neg_acc": 0.9928769845489069, "train/reward_neg_loss": 0.029062670999015053, "train/reward_pos_acc": 0.975279041638611, "train/reward_pos_loss": 0.811393123991946, "train/reward_pred": 0.026424120563406046, "train/reward_rate": 0.03147855718085106, "eval_stats/sum_log_reward": 8.100000181235373, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 3.75, "eval_stats/max_log_achievement_collect_wood": 14.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.75, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.9375, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.364940312167164e-06, "report/cont_loss_std": 9.057496208697557e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007572403992526233, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.085661089447967e-07, "report/cont_pred": 0.9960964322090149, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.386299133300781, "report/dyn_loss_std": 8.876846313476562, "report/image_loss_mean": 5.013594627380371, "report/image_loss_std": 10.539643287658691, "report/model_loss_mean": 13.703592300415039, "report/model_loss_std": 13.74820327758789, "report/post_ent_mag": 56.95985412597656, "report/post_ent_max": 56.95985412597656, "report/post_ent_mean": 39.684410095214844, "report/post_ent_min": 20.384605407714844, "report/post_ent_std": 7.604197025299072, "report/prior_ent_mag": 66.37872314453125, "report/prior_ent_max": 66.37872314453125, "report/prior_ent_mean": 54.42094421386719, "report/prior_ent_min": 44.59515380859375, "report/prior_ent_std": 3.5534138679504395, "report/rep_loss_mean": 14.386299133300781, "report/rep_loss_std": 8.876846313476562, "report/reward_avg": 0.03486328199505806, "report/reward_loss_mean": 0.058214589953422546, "report/reward_loss_std": 0.2715170681476593, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029263496398926, "report/reward_neg_acc": 0.9949187636375427, "report/reward_neg_loss": 0.02267371490597725, "report/reward_pos_acc": 0.925000011920929, "report/reward_pos_loss": 0.9325202107429504, "report/reward_pred": 0.0308479443192482, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.301246129514766e-06, "eval/cont_loss_std": 3.2131571060745046e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.200882803066634e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2809729241780587e-06, "eval/cont_pred": 0.997069239616394, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.110811233520508, "eval/dyn_loss_std": 9.751222610473633, "eval/image_loss_mean": 9.54637336730957, "eval/image_loss_std": 11.891637802124023, "eval/model_loss_mean": 19.907543182373047, "eval/model_loss_std": 15.738243103027344, "eval/post_ent_mag": 57.8486328125, "eval/post_ent_max": 57.8486328125, "eval/post_ent_mean": 39.55160903930664, "eval/post_ent_min": 19.77236557006836, "eval/post_ent_std": 7.821449279785156, "eval/prior_ent_mag": 66.37872314453125, "eval/prior_ent_max": 66.37872314453125, "eval/prior_ent_mean": 55.14014434814453, "eval/prior_ent_min": 42.813880920410156, "eval/prior_ent_std": 3.572979688644409, "eval/rep_loss_mean": 17.110811233520508, "eval/rep_loss_std": 9.751222610473633, "eval/reward_avg": 0.0380859375, "eval/reward_loss_mean": 0.09468157589435577, "eval/reward_loss_std": 0.5138387680053711, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005884170532227, "eval/reward_neg_acc": 0.9908162951469421, "eval/reward_neg_loss": 0.04682079702615738, "eval/reward_pos_acc": 0.9090909361839294, "eval/reward_pos_loss": 1.1606719493865967, "eval/reward_pred": 0.03603751212358475, "eval/reward_rate": 0.04296875, "replay/size": 929329.0, "replay/inserts": 22656.0, "replay/samples": 22656.0, "replay/insert_wait_avg": 1.384092673743512e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.439636241244731e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1551688613775478e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4402058124542, "timer/env.step_count": 2832.0, "timer/env.step_total": 235.90022945404053, "timer/env.step_frac": 0.23579643049478077, "timer/env.step_avg": 0.08329810362077703, "timer/env.step_min": 0.022862672805786133, "timer/env.step_max": 2.1215169429779053, "timer/replay._sample_count": 22656.0, "timer/replay._sample_total": 11.481181144714355, "timer/replay._sample_frac": 0.011476129285898227, "timer/replay._sample_avg": 0.0005067611734072367, "timer/replay._sample_min": 0.0003864765167236328, "timer/replay._sample_max": 0.010993242263793945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3489.0, "timer/agent.policy_total": 58.11262273788452, "timer/agent.policy_frac": 0.0580870524797546, "timer/agent.policy_avg": 0.016655953779846525, "timer/agent.policy_min": 0.00928354263305664, "timer/agent.policy_max": 0.13729572296142578, "timer/dataset_train_count": 1416.0, "timer/dataset_train_total": 0.15887165069580078, "timer/dataset_train_frac": 0.00015880174524451627, "timer/dataset_train_avg": 0.00011219749342923784, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.00535273551940918, "timer/agent.train_count": 1416.0, "timer/agent.train_total": 635.2054896354675, "timer/agent.train_frac": 0.6349259915235206, "timer/agent.train_avg": 0.4485914474826748, "timer/agent.train_min": 0.4329349994659424, "timer/agent.train_max": 1.6314806938171387, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4681251049041748, "timer/agent.report_frac": 0.0004679191241859497, "timer/agent.report_avg": 0.2340625524520874, "timer/agent.report_min": 0.22726774215698242, "timer/agent.report_max": 0.24085736274719238, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0742463692894785e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.645737748422256}
{"step": 929992, "time": 42466.13210821152, "episode/length": 143.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 42490.761378765106, "eval_episode/length": 182.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 930072, "time": 42493.517592191696, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 930072, "time": 42496.14909911156, "eval_episode/length": 230.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 930072, "time": 42497.984021663666, "eval_episode/length": 234.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 930072, "time": 42501.433267593384, "eval_episode/length": 273.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9890510948905109}
{"step": 930072, "time": 42505.29049420357, "eval_episode/length": 329.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9878787878787879}
{"step": 930072, "time": 42509.80451488495, "eval_episode/length": 186.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.983957219251337}
{"step": 930072, "time": 42512.98941731453, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 930072, "time": 42512.999489068985, "eval_episode/length": 237.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9831932773109243}
{"step": 930528, "time": 42528.29613637924, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 930592, "time": 42532.148324251175, "episode/length": 203.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 930624, "time": 42534.733228206635, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 931224, "time": 42555.94123387337, "episode/length": 255.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 931280, "time": 42559.71069383621, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 931520, "time": 42569.15856742859, "episode/length": 240.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 931768, "time": 42578.81490278244, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 931808, "time": 42581.95435142517, "episode/length": 573.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.980836236933798, "episode/intrinsic_return": 0.0}
{"step": 931832, "time": 42584.0307393074, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 932024, "time": 42591.985886096954, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 932248, "time": 42600.96237325668, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 932744, "time": 42619.1620388031, "episode/length": 152.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 932768, "time": 42621.71631503105, "episode/length": 192.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 932776, "time": 42623.38250541687, "episode/length": 65.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 933056, "time": 42634.49498176575, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 933112, "time": 42637.64496254921, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 933280, "time": 42645.04976415634, "episode/length": 156.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 933544, "time": 42655.23030543327, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 934104, "time": 42676.91919088364, "episode/length": 291.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 934160, "time": 42680.57050585747, "episode/length": 172.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 934184, "time": 42682.641261577606, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 934408, "time": 42691.72338581085, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 934688, "time": 42702.90863060951, "episode/length": 175.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 935136, "time": 42719.61360168457, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 935616, "time": 42737.06091761589, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 935736, "time": 42742.47950553894, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 935752, "time": 42744.67806768417, "episode/length": 167.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 935800, "time": 42747.870470047, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 936128, "time": 42760.506242752075, "episode/length": 123.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 936296, "time": 42767.473279476166, "episode/length": 404.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901234567901235, "episode/intrinsic_return": 0.0}
{"step": 936544, "time": 42777.529047489166, "episode/length": 231.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 936968, "time": 42792.95875787735, "episode/length": 427.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 937200, "time": 42802.50359392166, "episode/length": 174.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 937256, "time": 42805.68836522102, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 937296, "time": 42808.82768583298, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 937592, "time": 42820.20334458351, "episode/length": 246.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 937688, "time": 42825.50090932846, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 937752, "time": 42829.818853616714, "episode/length": 202.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 938392, "time": 42852.75943827629, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 938448, "time": 42856.435770750046, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 938960, "time": 42875.20375132561, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 939120, "time": 42882.1019384861, "episode/length": 190.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 939224, "time": 42886.98862862587, "episode/length": 240.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 939272, "time": 42890.37477040291, "episode/length": 189.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 939328, "time": 42894.02557826042, "episode/length": 204.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 939664, "time": 42906.70075297356, "episode/length": 87.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 939808, "time": 42913.15133857727, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 939936, "time": 42918.94497132301, "episode/length": 423.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 42943.85730886459, "eval_episode/length": 151.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.993421052631579}
{"step": 940056, "time": 42945.94272470474, "eval_episode/length": 162.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 940056, "time": 42949.30688595772, "eval_episode/length": 169.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 940056, "time": 42951.53102350235, "eval_episode/length": 182.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 940056, "time": 42955.31824398041, "eval_episode/length": 233.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9871794871794872}
{"step": 940056, "time": 42957.10993742943, "eval_episode/length": 236.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 940056, "time": 42960.26340007782, "eval_episode/length": 273.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9781021897810219}
{"step": 940056, "time": 42963.518976688385, "eval_episode/length": 162.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9815950920245399}
{"step": 940464, "time": 42977.22141265869, "episode/length": 258.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 940640, "time": 42984.776534080505, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 941000, "time": 42998.01312494278, "episode/length": 221.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 941024, "time": 43000.54446029663, "episode/length": 218.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 941488, "time": 43017.58952856064, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 941784, "time": 43028.79391884804, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 941800, "time": 43030.97418856621, "episode/length": 248.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 942168, "time": 43046.45317816734, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 942488, "time": 43058.77470040321, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 942584, "time": 43063.65730547905, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 942832, "time": 43073.88627934456, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 943176, "time": 43086.68177819252, "episode/length": 42.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 943256, "time": 43090.89550471306, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 943552, "time": 43102.7588596344, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 943936, "time": 43117.14886236191, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 944080, "time": 43123.550953149796, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 944088, "time": 43125.12804555893, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 944160, "time": 43129.46555519104, "episode/length": 294.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 944592, "time": 43145.344379901886, "episode/length": 81.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 944736, "time": 43151.700053453445, "episode/length": 675.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 944760, "time": 43153.80726504326, "episode/length": 74.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 945040, "time": 43164.89444899559, "episode/length": 222.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 945144, "time": 43169.78214430809, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 945304, "time": 43176.769710063934, "episode/length": 218.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 945736, "time": 43193.44757246971, "episode/length": 205.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 945848, "time": 43198.76538276672, "episode/length": 220.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 946496, "time": 43222.40955066681, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 946608, "time": 43227.74375915527, "episode/length": 251.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 946688, "time": 43231.99730682373, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 946840, "time": 43238.45551753044, "episode/length": 262.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9695817490494296, "episode/intrinsic_return": 0.0}
{"step": 947096, "time": 43248.638531923294, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 947216, "time": 43254.469787836075, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 947272, "time": 43257.69607448578, "episode/length": 265.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 947560, "time": 43268.82862353325, "episode/length": 213.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 948184, "time": 43291.322764873505, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 948616, "time": 43307.306740283966, "episode/length": 221.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 948696, "time": 43311.77054858208, "episode/length": 184.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 948728, "time": 43314.40340709686, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 948816, "time": 43319.185337781906, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 949392, "time": 43340.24429678917, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 949944, "time": 43359.98898649216, "episode/length": 355.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 43380.11734008789, "eval_episode/length": 46.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 950040, "time": 43387.14857673645, "eval_episode/length": 170.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 950040, "time": 43391.43608880043, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9637305699481865}
{"step": 950040, "time": 43394.09529542923, "eval_episode/length": 215.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 950040, "time": 43395.93450307846, "eval_episode/length": 222.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 950040, "time": 43397.93223953247, "eval_episode/length": 229.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 950040, "time": 43399.70779442787, "eval_episode/length": 230.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 950040, "time": 43401.69965624809, "eval_episode/length": 194.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 950104, "time": 43403.82781505585, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 950288, "time": 43413.29911804199, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 950808, "time": 43432.36145186424, "episode/length": 176.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 950960, "time": 43439.25223851204, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 950968, "time": 43440.86934828758, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 950976, "time": 43442.91503429413, "episode/length": 294.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 951168, "time": 43450.88339281082, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 951240, "time": 43454.583062410355, "episode/length": 592.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9915682967959528, "episode/intrinsic_return": 0.0}
{"step": 951369, "time": 43461.32579374313, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.252820276331018, "train/action_min": 0.0, "train/action_std": 3.035483070656105, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04141650100549062, "train/actor_opt_grad_steps": 58690.0, "train/actor_opt_loss": -3.9596004588736426, "train/adv_mag": 0.5290350739602689, "train/adv_max": 0.4966381593986794, "train/adv_mean": 0.003507178884809845, "train/adv_min": -0.4132394967255769, "train/adv_std": 0.06069492926752126, "train/cont_avg": 0.9951895254629629, "train/cont_loss_mean": 0.0001077767530024108, "train/cont_loss_std": 0.0031839237334864907, "train/cont_neg_acc": 0.9944444448859603, "train/cont_neg_loss": 0.011273361425072735, "train/cont_pos_acc": 0.9999708754044992, "train/cont_pos_loss": 6.0215881141958665e-05, "train/cont_pred": 0.995182670045782, "train/cont_rate": 0.9951895254629629, "train/dyn_loss_mean": 12.975763441015173, "train/dyn_loss_std": 8.864130023673729, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.843773834793656, "train/extr_critic_critic_opt_grad_steps": 58690.0, "train/extr_critic_critic_opt_loss": 15723.131922743056, "train/extr_critic_mag": 7.612126823707863, "train/extr_critic_max": 7.612126823707863, "train/extr_critic_mean": 2.1675001868495234, "train/extr_critic_min": -0.15817121223167138, "train/extr_critic_std": 1.605714166605914, "train/extr_return_normed_mag": 1.6310372485054865, "train/extr_return_normed_max": 1.6310372485054865, "train/extr_return_normed_mean": 0.38475776105015363, "train/extr_return_normed_min": -0.12090249045027626, "train/extr_return_normed_std": 0.31541854915795503, "train/extr_return_rate": 0.8525154789288839, "train/extr_return_raw_mag": 8.664134590714067, "train/extr_return_raw_max": 8.664134590714067, "train/extr_return_raw_mean": 2.1857188525023283, "train/extr_return_raw_min": -0.4429825080765618, "train/extr_return_raw_std": 1.6398088781921951, "train/extr_reward_mag": 1.0297350804011027, "train/extr_reward_max": 1.0297350804011027, "train/extr_reward_mean": 0.035736307639766624, "train/extr_reward_min": -0.4176757574081421, "train/extr_reward_std": 0.17714447412225937, "train/image_loss_mean": 5.9508513203373665, "train/image_loss_std": 10.682137612943295, "train/model_loss_mean": 13.791679820307978, "train/model_loss_std": 14.240223524305556, "train/model_opt_grad_norm": 52.31540121855559, "train/model_opt_grad_steps": 58635.14074074074, "train/model_opt_loss": 17761.48968460648, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1287.037037037037, "train/policy_entropy_mag": 2.4780470300603796, "train/policy_entropy_max": 2.4780470300603796, "train/policy_entropy_mean": 0.46136903365453086, "train/policy_entropy_min": 0.07937504798173904, "train/policy_entropy_std": 0.5663877089818319, "train/policy_logprob_mag": 7.438383833567301, "train/policy_logprob_max": -0.009455659316369781, "train/policy_logprob_mean": -0.46137232272713274, "train/policy_logprob_min": -7.438383833567301, "train/policy_logprob_std": 1.0382486829051265, "train/policy_randomness_mag": 0.8746418582068549, "train/policy_randomness_max": 0.8746418582068549, "train/policy_randomness_mean": 0.16284302235753448, "train/policy_randomness_min": 0.028015908598899842, "train/policy_randomness_std": 0.19991000725163355, "train/post_ent_mag": 57.689826795789934, "train/post_ent_max": 57.689826795789934, "train/post_ent_mean": 41.52236605043765, "train/post_ent_min": 19.295639843410918, "train/post_ent_std": 7.718482197655572, "train/prior_ent_mag": 66.42080270272714, "train/prior_ent_max": 66.42080270272714, "train/prior_ent_mean": 54.57402151602286, "train/prior_ent_min": 41.38928061591254, "train/prior_ent_std": 3.908256747987535, "train/rep_loss_mean": 12.975763441015173, "train/rep_loss_std": 8.864130023673729, "train/reward_avg": 0.02778862831355245, "train/reward_loss_mean": 0.055262666802715375, "train/reward_loss_std": 0.24579859100006246, "train/reward_max_data": 1.0214814866030657, "train/reward_max_pred": 1.013630508493494, "train/reward_neg_acc": 0.9929171147169891, "train/reward_neg_loss": 0.029048858444999767, "train/reward_pos_acc": 0.9694601376851399, "train/reward_pos_loss": 0.8454512596130371, "train/reward_pred": 0.026865778877227395, "train/reward_rate": 0.03224826388888889, "train_stats/sum_log_reward": 8.355102259285596, "train_stats/max_log_achievement_collect_coal": 0.2653061224489796, "train_stats/max_log_achievement_collect_drink": 5.377551020408164, "train_stats/max_log_achievement_collect_sapling": 2.0408163265306123, "train_stats/max_log_achievement_collect_stone": 3.7551020408163267, "train_stats/max_log_achievement_collect_wood": 13.153061224489797, "train_stats/max_log_achievement_defeat_skeleton": 0.04081632653061224, "train_stats/max_log_achievement_defeat_zombie": 1.5816326530612246, "train_stats/max_log_achievement_eat_cow": 0.29591836734693877, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0816326530612246, "train_stats/max_log_achievement_make_wood_sword": 1.1938775510204083, "train_stats/max_log_achievement_place_furnace": 0.01020408163265306, "train_stats/max_log_achievement_place_plant": 1.8877551020408163, "train_stats/max_log_achievement_place_stone": 0.030612244897959183, "train_stats/max_log_achievement_place_table": 3.877551020408163, "train_stats/max_log_achievement_wake_up": 1.5204081632653061, "train_stats/mean_log_entropy": 0.44301100546608163, "eval_stats/sum_log_reward": 8.380000267028809, "eval_stats/max_log_achievement_collect_coal": 0.12, "eval_stats/max_log_achievement_collect_drink": 4.56, "eval_stats/max_log_achievement_collect_sapling": 1.68, "eval_stats/max_log_achievement_collect_stone": 2.72, "eval_stats/max_log_achievement_collect_wood": 14.88, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.56, "eval_stats/max_log_achievement_eat_cow": 0.16, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.52, "eval_stats/max_log_achievement_make_wood_sword": 1.36, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.96, "eval_stats/max_log_achievement_wake_up": 1.12, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.565446089254692e-05, "report/cont_loss_std": 0.002659425837919116, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019347498891875148, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.663043263368309e-05, "report/cont_pred": 0.9950438737869263, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.302867889404297, "report/dyn_loss_std": 8.53857421875, "report/image_loss_mean": 5.286306858062744, "report/image_loss_std": 11.394720077514648, "report/model_loss_mean": 12.724319458007812, "report/model_loss_std": 14.60204792022705, "report/post_ent_mag": 56.680877685546875, "report/post_ent_max": 56.680877685546875, "report/post_ent_mean": 42.1536865234375, "report/post_ent_min": 19.635770797729492, "report/post_ent_std": 7.765076160430908, "report/prior_ent_mag": 66.52896118164062, "report/prior_ent_max": 66.52896118164062, "report/prior_ent_mean": 54.73982238769531, "report/prior_ent_min": 40.2242546081543, "report/prior_ent_std": 3.9078338146209717, "report/rep_loss_mean": 12.302867889404297, "report/rep_loss_std": 8.53857421875, "report/reward_avg": 0.03125, "report/reward_loss_mean": 0.05619533360004425, "report/reward_loss_std": 0.21530193090438843, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0954303741455078, "report/reward_neg_acc": 0.9959472417831421, "report/reward_neg_loss": 0.029586924239993095, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7659924030303955, "report/reward_pred": 0.030855584889650345, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.670620784163475e-07, "eval/cont_loss_std": 7.937621376186144e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001279447169508785, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.939641596341971e-07, "eval/cont_pred": 0.9970701932907104, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.882617950439453, "eval/dyn_loss_std": 10.168965339660645, "eval/image_loss_mean": 7.885347366333008, "eval/image_loss_std": 14.13136100769043, "eval/model_loss_mean": 18.08806610107422, "eval/model_loss_std": 17.831844329833984, "eval/post_ent_mag": 61.314453125, "eval/post_ent_max": 61.314453125, "eval/post_ent_mean": 39.46873092651367, "eval/post_ent_min": 20.73074722290039, "eval/post_ent_std": 7.997270107269287, "eval/prior_ent_mag": 66.52896118164062, "eval/prior_ent_max": 66.52896118164062, "eval/prior_ent_mean": 54.5128173828125, "eval/prior_ent_min": 42.77012634277344, "eval/prior_ent_std": 3.58109188079834, "eval/rep_loss_mean": 16.882617950439453, "eval/rep_loss_std": 10.168965339660645, "eval/reward_avg": 0.03671874850988388, "eval/reward_loss_mean": 0.07314741611480713, "eval/reward_loss_std": 0.37895894050598145, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028572082519531, "eval/reward_neg_acc": 0.9938962459564209, "eval/reward_neg_loss": 0.03199275583028793, "eval/reward_pos_acc": 0.9268292188644409, "eval/reward_pos_loss": 1.059855580329895, "eval/reward_pred": 0.03438270092010498, "eval/reward_rate": 0.0400390625, "replay/size": 950865.0, "replay/inserts": 21536.0, "replay/samples": 21536.0, "replay/insert_wait_avg": 1.3861733241031641e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.557191430725279e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.17225515330496e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2135825157166, "timer/env.step_count": 2692.0, "timer/env.step_total": 229.55460166931152, "timer/env.step_frac": 0.22950558328946158, "timer/env.step_avg": 0.08527288323525688, "timer/env.step_min": 0.02299046516418457, "timer/env.step_max": 2.1019504070281982, "timer/replay._sample_count": 21536.0, "timer/replay._sample_total": 10.948894500732422, "timer/replay._sample_frac": 0.010946556507655084, "timer/replay._sample_avg": 0.0005083996332063718, "timer/replay._sample_min": 0.0004162788391113281, "timer/replay._sample_max": 0.011010408401489258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3670.0, "timer/agent.policy_total": 60.92096281051636, "timer/agent.policy_frac": 0.06090795393648746, "timer/agent.policy_avg": 0.016599717387061678, "timer/agent.policy_min": 0.0094146728515625, "timer/agent.policy_max": 0.12884759902954102, "timer/dataset_train_count": 1346.0, "timer/dataset_train_total": 0.14554405212402344, "timer/dataset_train_frac": 0.00014551297309715994, "timer/dataset_train_avg": 0.00010813079652602039, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0010838508605957031, "timer/agent.train_count": 1346.0, "timer/agent.train_total": 603.61044049263, "timer/agent.train_frac": 0.6034815473855509, "timer/agent.train_avg": 0.44844757837491084, "timer/agent.train_min": 0.4332761764526367, "timer/agent.train_max": 1.650322675704956, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47287750244140625, "timer/agent.report_frac": 0.00047277652564168795, "timer/agent.report_avg": 0.23643875122070312, "timer/agent.report_min": 0.22977733612060547, "timer/agent.report_max": 0.24310016632080078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1702899835405455e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 21.531110343559053}
{"step": 951536, "time": 43466.922914505005, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 951592, "time": 43470.11664414406, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 951728, "time": 43476.373918533325, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 952424, "time": 43500.68432569504, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 952816, "time": 43515.473764419556, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 952976, "time": 43522.410519599915, "episode/length": 225.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 953264, "time": 43533.492654562, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 953288, "time": 43535.63195538521, "episode/length": 218.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.0}
{"step": 953304, "time": 43537.62944793701, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 953400, "time": 43542.384836912155, "episode/length": 302.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 953872, "time": 43559.8008313179, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 953984, "time": 43565.141822338104, "episode/length": 376.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9920424403183024, "episode/intrinsic_return": 0.0}
{"step": 954440, "time": 43581.69774675369, "episode/length": 202.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 954768, "time": 43594.3437461853, "episode/length": 187.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 954944, "time": 43601.64946436882, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 955072, "time": 43607.40061211586, "episode/length": 222.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 955272, "time": 43615.45531487465, "episode/length": 40.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 955392, "time": 43621.20233750343, "episode/length": 301.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 955456, "time": 43624.96524834633, "episode/length": 268.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 955648, "time": 43632.92000889778, "episode/length": 31.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 955728, "time": 43637.07316970825, "episode/length": 231.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 956096, "time": 43650.97500658035, "episode/length": 45.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 956352, "time": 43660.955436229706, "episode/length": 295.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 956424, "time": 43664.759456157684, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 956440, "time": 43666.88769578934, "episode/length": 249.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 957320, "time": 43697.64356613159, "episode/length": 280.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 957328, "time": 43699.92722964287, "episode/length": 233.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 957456, "time": 43705.7475631237, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 957640, "time": 43713.2231733799, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 958112, "time": 43730.6073179245, "episode/length": 208.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 958480, "time": 43745.96832513809, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 958688, "time": 43754.6242723465, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717314487632509, "episode/intrinsic_return": 0.0}
{"step": 958840, "time": 43760.930730342865, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 959088, "time": 43770.94171357155, "episode/length": 476.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9979035639412998, "episode/intrinsic_return": 0.0}
{"step": 959128, "time": 43773.60835361481, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 959144, "time": 43775.65350031853, "episode/length": 226.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 959888, "time": 43802.113682985306, "episode/length": 149.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 959992, "time": 43806.88916015625, "episode/length": 143.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 43829.70857048035, "eval_episode/length": 152.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.954248366013072}
{"step": 960024, "time": 43832.917625427246, "eval_episode/length": 177.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 960024, "time": 43835.90567731857, "eval_episode/length": 196.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 960024, "time": 43840.070682525635, "eval_episode/length": 243.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 960024, "time": 43842.80811405182, "eval_episode/length": 272.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 960024, "time": 43846.8848695755, "eval_episode/length": 333.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9910179640718563}
{"step": 960024, "time": 43848.479075193405, "eval_episode/length": 335.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9851190476190477}
{"step": 960024, "time": 43851.11909222603, "eval_episode/length": 163.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 960104, "time": 43853.767255306244, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 960112, "time": 43855.80376124382, "episode/length": 308.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 960200, "time": 43860.006499528885, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 960952, "time": 43886.46777319908, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 961280, "time": 43899.67494750023, "episode/length": 266.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 961688, "time": 43914.76228737831, "episode/length": 224.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 961696, "time": 43916.69971847534, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 961888, "time": 43924.64894247055, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 962040, "time": 43931.06668639183, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 962384, "time": 43944.484964609146, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 962432, "time": 43947.71823692322, "episode/length": 143.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 962880, "time": 43964.1132273674, "episode/length": 240.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 963080, "time": 43972.16626787186, "episode/length": 359.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 963264, "time": 43980.03263473511, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 963704, "time": 43996.1589243412, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 963984, "time": 44007.23534798622, "episode/length": 199.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 964056, "time": 44011.01747369766, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 964264, "time": 44019.578214883804, "episode/length": 321.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 964408, "time": 44025.9617125988, "episode/length": 190.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 964896, "time": 44043.96305131912, "episode/length": 113.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 964912, "time": 44046.06919336319, "episode/length": 228.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 965024, "time": 44051.22099041939, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 965368, "time": 44063.994891643524, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 965520, "time": 44070.91187930107, "episode/length": 226.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 965688, "time": 44077.8546192646, "episode/length": 498.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9859719438877755, "episode/intrinsic_return": 0.0}
{"step": 965984, "time": 44089.50254702568, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 966232, "time": 44099.00462794304, "episode/length": 227.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 966336, "time": 44104.287566423416, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 966384, "time": 44107.46145749092, "episode/length": 185.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 966720, "time": 44121.82993936539, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 967296, "time": 44142.50589513779, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 967384, "time": 44146.734335422516, "episode/length": 143.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 967480, "time": 44151.6426486969, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 967632, "time": 44158.42481637001, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 967728, "time": 44163.105028152466, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 968216, "time": 44180.64107751846, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 968328, "time": 44185.93965268135, "episode/length": 369.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 968528, "time": 44194.3295340538, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 968736, "time": 44202.74591970444, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 968808, "time": 44206.55896949768, "episode/length": 177.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 969000, "time": 44214.50493192673, "episode/length": 170.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 969016, "time": 44216.52781248093, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 969120, "time": 44221.722165584564, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 969488, "time": 44235.42444944382, "episode/length": 158.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 969800, "time": 44247.20804476738, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 44270.72352099419, "eval_episode/length": 57.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 970008, "time": 44275.440046310425, "eval_episode/length": 134.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 970008, "time": 44278.772525548935, "eval_episode/length": 174.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 970008, "time": 44280.844962358475, "eval_episode/length": 187.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9680851063829787}
{"step": 970008, "time": 44282.55570054054, "eval_episode/length": 190.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 970008, "time": 44284.344997644424, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 970008, "time": 44287.446506261826, "eval_episode/length": 228.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 970008, "time": 44292.2907602787, "eval_episode/length": 246.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.97165991902834}
{"step": 970112, "time": 44295.96154332161, "episode/length": 171.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 970272, "time": 44303.00160360336, "episode/length": 217.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 970328, "time": 44306.1859190464, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 970432, "time": 44311.56160712242, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 970856, "time": 44327.53462290764, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 970936, "time": 44331.80147027969, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9558011049723757, "episode/intrinsic_return": 0.0}
{"step": 971024, "time": 44336.4623939991, "episode/length": 250.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 971536, "time": 44354.89593887329, "episode/length": 157.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 971568, "time": 44357.56223940849, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 971616, "time": 44360.7143137455, "episode/length": 147.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 972040, "time": 44376.00082445145, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 972488, "time": 44392.381711006165, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 972976, "time": 44410.274134874344, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 972976, "time": 44410.28270506859, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 973168, "time": 44420.07242321968, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 973360, "time": 44427.93967676163, "episode/length": 223.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 973504, "time": 44434.34134840965, "episode/length": 462.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9978401727861771, "episode/intrinsic_return": 0.0}
{"step": 973600, "time": 44439.17139482498, "episode/length": 332.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.987987987987988, "episode/intrinsic_return": 0.0}
{"step": 973896, "time": 44450.36525607109, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 973912, "time": 44452.53461885452, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 974024, "time": 44458.362939834595, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 974025, "time": 44461.46630239487, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.313966563050176, "train/action_min": 0.0, "train/action_std": 3.1830729162189324, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04135379622834669, "train/actor_opt_grad_steps": 60075.0, "train/actor_opt_loss": -1.1294623399284525, "train/adv_mag": 0.5429591307757606, "train/adv_max": 0.4972304126746218, "train/adv_mean": 0.0038008650212311332, "train/adv_min": -0.4267929941415787, "train/adv_std": 0.06002876524564246, "train/cont_avg": 0.995179082306338, "train/cont_loss_mean": 0.00027129726646575375, "train/cont_loss_std": 0.008032292225664952, "train/cont_neg_acc": 0.9895896666438867, "train/cont_neg_loss": 0.025841858139179066, "train/cont_pos_acc": 0.9999515565348344, "train/cont_pos_loss": 0.00013119356556871598, "train/cont_pred": 0.9951763564432171, "train/cont_rate": 0.995179082306338, "train/dyn_loss_mean": 12.804243866826447, "train/dyn_loss_std": 8.815699060198288, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8205565873166205, "train/extr_critic_critic_opt_grad_steps": 60075.0, "train/extr_critic_critic_opt_loss": 15648.976493727992, "train/extr_critic_mag": 7.7941138643614005, "train/extr_critic_max": 7.7941138643614005, "train/extr_critic_mean": 2.277076559167513, "train/extr_critic_min": -0.15032649459973188, "train/extr_critic_std": 1.653038178531217, "train/extr_return_normed_mag": 1.6294688296989657, "train/extr_return_normed_max": 1.6294688296989657, "train/extr_return_normed_mean": 0.3913439520647828, "train/extr_return_normed_min": -0.12326304667012793, "train/extr_return_normed_std": 0.3172763023577945, "train/extr_return_rate": 0.8561244254380884, "train/extr_return_raw_mag": 8.888294397945135, "train/extr_return_raw_max": 8.888294397945135, "train/extr_return_raw_mean": 2.297269371193899, "train/extr_return_raw_min": -0.4410194358985189, "train/extr_return_raw_std": 1.6887496449577977, "train/extr_reward_mag": 1.035694290214861, "train/extr_reward_max": 1.035694290214861, "train/extr_reward_mean": 0.038081730663461585, "train/extr_reward_min": -0.40480243320196446, "train/extr_reward_std": 0.18334323786933657, "train/image_loss_mean": 5.9149449291363565, "train/image_loss_std": 10.977029921303332, "train/model_loss_mean": 13.653293817815646, "train/model_loss_std": 14.516315003515968, "train/model_opt_grad_norm": 51.906093678004304, "train/model_opt_grad_steps": 60018.66901408451, "train/model_opt_loss": 17331.60577822403, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.605633802817, "train/policy_entropy_mag": 2.4354277177595756, "train/policy_entropy_max": 2.4354277177595756, "train/policy_entropy_mean": 0.4665329418551754, "train/policy_entropy_min": 0.07937504734161874, "train/policy_entropy_std": 0.5757025381628896, "train/policy_logprob_mag": 7.438383804240697, "train/policy_logprob_max": -0.009455658397047033, "train/policy_logprob_mean": -0.4653193556087118, "train/policy_logprob_min": -7.438383804240697, "train/policy_logprob_std": 1.0341961895915823, "train/policy_randomness_mag": 0.8595991088470942, "train/policy_randomness_max": 0.8595991088470942, "train/policy_randomness_mean": 0.16466565687261836, "train/policy_randomness_min": 0.028015908417882214, "train/policy_randomness_std": 0.20319773445666675, "train/post_ent_mag": 58.02831193091164, "train/post_ent_max": 58.02831193091164, "train/post_ent_mean": 41.71107778414874, "train/post_ent_min": 19.16074439841257, "train/post_ent_std": 7.776197655100218, "train/prior_ent_mag": 66.31877340397365, "train/prior_ent_max": 66.31877340397365, "train/prior_ent_mean": 54.56648375282825, "train/prior_ent_min": 41.37921271525638, "train/prior_ent_std": 3.8919953410054595, "train/rep_loss_mean": 12.804243866826447, "train/rep_loss_std": 8.815699060198288, "train/reward_avg": 0.027755006400107498, "train/reward_loss_mean": 0.055531403023592184, "train/reward_loss_std": 0.24840735318795057, "train/reward_max_data": 1.0190140890403532, "train/reward_max_pred": 1.013263035827959, "train/reward_neg_acc": 0.9925379996568384, "train/reward_neg_loss": 0.02965594189320232, "train/reward_pos_acc": 0.9690465809593738, "train/reward_pos_loss": 0.835317568459981, "train/reward_pred": 0.02718306097372527, "train/reward_rate": 0.032233439700704226, "train_stats/sum_log_reward": 8.705769456349886, "train_stats/max_log_achievement_collect_coal": 0.3076923076923077, "train_stats/max_log_achievement_collect_drink": 5.740384615384615, "train_stats/max_log_achievement_collect_sapling": 1.9519230769230769, "train_stats/max_log_achievement_collect_stone": 4.163461538461538, "train_stats/max_log_achievement_collect_wood": 14.39423076923077, "train_stats/max_log_achievement_defeat_skeleton": 0.038461538461538464, "train_stats/max_log_achievement_defeat_zombie": 1.4230769230769231, "train_stats/max_log_achievement_eat_cow": 0.3173076923076923, "train_stats/max_log_achievement_eat_plant": 0.009615384615384616, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009615384615384616, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.25, "train_stats/max_log_achievement_make_wood_sword": 1.1826923076923077, "train_stats/max_log_achievement_place_furnace": 0.009615384615384616, "train_stats/max_log_achievement_place_plant": 1.8557692307692308, "train_stats/max_log_achievement_place_stone": 0.028846153846153848, "train_stats/max_log_achievement_place_table": 3.923076923076923, "train_stats/max_log_achievement_wake_up": 1.2403846153846154, "train_stats/mean_log_entropy": 0.45647104256428206, "eval_stats/sum_log_reward": 8.03750029951334, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 1.5, "eval_stats/max_log_achievement_collect_wood": 13.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.4375, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.9375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00011895273200934753, "report/cont_loss_std": 0.0035240838769823313, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00027335205231793225, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00011819513019872829, "report/cont_pred": 0.9950068593025208, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.816856384277344, "report/dyn_loss_std": 8.901456832885742, "report/image_loss_mean": 4.655656814575195, "report/image_loss_std": 10.471142768859863, "report/model_loss_mean": 12.432611465454102, "report/model_loss_std": 14.074048042297363, "report/post_ent_mag": 59.20341110229492, "report/post_ent_max": 59.20341110229492, "report/post_ent_mean": 40.87445068359375, "report/post_ent_min": 18.558700561523438, "report/post_ent_std": 7.62099552154541, "report/prior_ent_mag": 66.46005249023438, "report/prior_ent_max": 66.46005249023438, "report/prior_ent_mean": 53.75617980957031, "report/prior_ent_min": 40.796348571777344, "report/prior_ent_std": 4.139726161956787, "report/rep_loss_mean": 12.816856384277344, "report/rep_loss_std": 8.901456832885742, "report/reward_avg": 0.04531249776482582, "report/reward_loss_mean": 0.08672225475311279, "report/reward_loss_std": 0.40172693133354187, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003328800201416, "report/reward_neg_acc": 0.9856115579605103, "report/reward_neg_loss": 0.04033428058028221, "report/reward_pos_acc": 0.9411765336990356, "report/reward_pos_loss": 0.9717321395874023, "report/reward_pred": 0.042735543102025986, "report/reward_rate": 0.0498046875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.052635399100836e-06, "eval/cont_loss_std": 2.374098949076142e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000308614457026124, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.460537977342028e-06, "eval/cont_pred": 0.9980420470237732, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.717254638671875, "eval/dyn_loss_std": 10.46280288696289, "eval/image_loss_mean": 10.72972297668457, "eval/image_loss_std": 13.824971199035645, "eval/model_loss_mean": 21.44013214111328, "eval/model_loss_std": 17.744441986083984, "eval/post_ent_mag": 59.5533447265625, "eval/post_ent_max": 59.5533447265625, "eval/post_ent_mean": 39.43182373046875, "eval/post_ent_min": 19.661161422729492, "eval/post_ent_std": 7.90552282333374, "eval/prior_ent_mag": 66.46005249023438, "eval/prior_ent_max": 66.46005249023438, "eval/prior_ent_mean": 54.7913818359375, "eval/prior_ent_min": 43.438148498535156, "eval/prior_ent_std": 3.7466588020324707, "eval/rep_loss_mean": 17.717254638671875, "eval/rep_loss_std": 10.46280288696289, "eval/reward_avg": 0.02910155989229679, "eval/reward_loss_mean": 0.08005108684301376, "eval/reward_loss_std": 0.4719488024711609, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020742416381836, "eval/reward_neg_acc": 0.9898989200592041, "eval/reward_neg_loss": 0.042608510702848434, "eval/reward_pos_acc": 0.9117646813392639, "eval/reward_pos_loss": 1.1702907085418701, "eval/reward_pred": 0.027788851410150528, "eval/reward_rate": 0.033203125, "replay/size": 973521.0, "replay/inserts": 22656.0, "replay/samples": 22656.0, "replay/insert_wait_avg": 1.370285948117574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.499935431668987e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1947330411848004e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1279771327972, "timer/env.step_count": 2832.0, "timer/env.step_total": 240.78310585021973, "timer/env.step_frac": 0.24075229506178336, "timer/env.step_avg": 0.08502228313920188, "timer/env.step_min": 0.02338695526123047, "timer/env.step_max": 3.3873534202575684, "timer/replay._sample_count": 22656.0, "timer/replay._sample_total": 11.489127159118652, "timer/replay._sample_frac": 0.011487657001713015, "timer/replay._sample_avg": 0.0005071118979130761, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.02800750732421875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3498.0, "timer/agent.policy_total": 56.30020570755005, "timer/agent.policy_frac": 0.056293001490622725, "timer/agent.policy_avg": 0.016094970185120083, "timer/agent.policy_min": 0.009404897689819336, "timer/agent.policy_max": 0.10607457160949707, "timer/dataset_train_count": 1416.0, "timer/dataset_train_total": 0.15311050415039062, "timer/dataset_train_frac": 0.0001530909120144137, "timer/dataset_train_avg": 0.00010812888711185779, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0005469322204589844, "timer/agent.train_count": 1416.0, "timer/agent.train_total": 630.4915113449097, "timer/agent.train_frac": 0.6304108331739957, "timer/agent.train_avg": 0.445262366769004, "timer/agent.train_min": 0.4325888156890869, "timer/agent.train_max": 1.758167028427124, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47368621826171875, "timer/agent.report_frac": 0.0004736256050147696, "timer/agent.report_avg": 0.23684310913085938, "timer/agent.report_min": 0.22971558570861816, "timer/agent.report_max": 0.24397063255310059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8844956576450748e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.65282347692642}
{"step": 974288, "time": 44470.491789102554, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 974368, "time": 44474.6752884388, "episode/length": 173.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 974520, "time": 44481.161839962006, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 974792, "time": 44491.68177175522, "episode/length": 178.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 974816, "time": 44494.286157369614, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 975744, "time": 44528.15722680092, "episode/length": 230.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 975848, "time": 44533.046689510345, "episode/length": 165.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 975976, "time": 44538.995279312134, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 976032, "time": 44542.74107718468, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 976200, "time": 44549.74945092201, "episode/length": 172.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 976448, "time": 44559.87542772293, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 976984, "time": 44579.055384874344, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 977264, "time": 44590.14825344086, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 977296, "time": 44592.77510666847, "episode/length": 157.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 977448, "time": 44599.28957939148, "episode/length": 183.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 977480, "time": 44601.808245658875, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 977856, "time": 44616.14865517616, "episode/length": 175.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 978520, "time": 44639.71351957321, "episode/length": 465.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 978904, "time": 44654.12158417702, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 979160, "time": 44664.14986205101, "episode/length": 31.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 979528, "time": 44677.83893442154, "episode/length": 278.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 979832, "time": 44689.513092279434, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 44717.491691589355, "eval_episode/length": 112.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9469026548672567}
{"step": 980096, "time": 44720.61445069313, "eval_episode/length": 148.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 980096, "time": 44723.87497854233, "eval_episode/length": 188.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 980096, "time": 44725.50350141525, "eval_episode/length": 189.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 980096, "time": 44727.048754930496, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 980096, "time": 44730.157161951065, "eval_episode/length": 222.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 980096, "time": 44732.22814297676, "eval_episode/length": 223.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 980096, "time": 44734.74526762962, "eval_episode/length": 233.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9829059829059829}
{"step": 980128, "time": 44735.87861537933, "episode/length": 334.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9731343283582089, "episode/intrinsic_return": 0.0}
{"step": 980160, "time": 44739.02792716026, "episode/length": 494.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 980520, "time": 44752.416108846664, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 980752, "time": 44761.96096611023, "episode/length": 152.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 980912, "time": 44768.869811058044, "episode/length": 490.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9857433808553971, "episode/intrinsic_return": 0.0}
{"step": 981432, "time": 44787.459409713745, "episode/length": 283.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 981448, "time": 44789.531084775925, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 981608, "time": 44796.46737289429, "episode/length": 515.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.998062015503876, "episode/intrinsic_return": 0.0}
{"step": 982216, "time": 44818.34444642067, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 982528, "time": 44830.52578449249, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 982768, "time": 44840.209827661514, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 982784, "time": 44842.34425711632, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 982952, "time": 44849.20353055, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 983048, "time": 44854.3659183979, "episode/length": 565.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9876325088339223, "episode/intrinsic_return": 0.0}
{"step": 983152, "time": 44861.39567112923, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 983912, "time": 44888.5773499012, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 984264, "time": 44901.95146727562, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 984272, "time": 44903.958758592606, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 984368, "time": 44908.69182229042, "episode/length": 164.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 984464, "time": 44913.52289438248, "episode/length": 188.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 984544, "time": 44917.79904484749, "episode/length": 366.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 984896, "time": 44931.72876191139, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 985176, "time": 44942.54703140259, "episode/length": 300.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 985416, "time": 44952.04392504692, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 986128, "time": 44977.4803249836, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 986312, "time": 44984.82715654373, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 986520, "time": 44993.65335345268, "episode/length": 281.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 986744, "time": 45002.600524663925, "episode/length": 274.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 986920, "time": 45009.96042108536, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 986984, "time": 45013.6064350605, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 987672, "time": 45037.89736533165, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 987784, "time": 45043.044003248215, "episode/length": 426.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 988040, "time": 45053.25324869156, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 988152, "time": 45058.38469457626, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 988288, "time": 45064.65346240997, "episode/length": 220.0, "episode/score": 11.10000005364418, "episode/reward_rate": 0.9638009049773756, "episode/intrinsic_return": 0.0}
{"step": 988616, "time": 45076.82745838165, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 988656, "time": 45080.00268793106, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 988688, "time": 45082.53669786453, "episode/length": 473.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9852320675105485, "episode/intrinsic_return": 0.0}
{"step": 989192, "time": 45100.47428202629, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 989440, "time": 45110.6299264431, "episode/length": 102.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 989512, "time": 45114.85106086731, "episode/length": 183.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 989712, "time": 45123.68016219139, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 989752, "time": 45126.380255937576, "episode/length": 182.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 989808, "time": 45130.00910758972, "episode/length": 36.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.918918918918919, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 45160.87188529968, "eval_episode/length": 136.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 990080, "time": 45163.36480164528, "eval_episode/length": 157.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 990080, "time": 45165.2715382576, "eval_episode/length": 163.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 990080, "time": 45167.67007160187, "eval_episode/length": 182.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 990080, "time": 45169.38381242752, "eval_episode/length": 183.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9836956521739131}
{"step": 990080, "time": 45171.86125731468, "eval_episode/length": 39.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9}
{"step": 990080, "time": 45173.45683979988, "eval_episode/length": 204.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9902439024390244}
{"step": 990080, "time": 45176.03768157959, "eval_episode/length": 231.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 990216, "time": 45180.303297281265, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 990264, "time": 45183.493976831436, "episode/length": 309.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 990464, "time": 45191.85099482536, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 990880, "time": 45207.12530565262, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 991072, "time": 45215.0654835701, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 991104, "time": 45217.65501332283, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 991632, "time": 45238.45558285713, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 992232, "time": 45260.28853559494, "episode/length": 220.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 992264, "time": 45262.86413311958, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 992624, "time": 45276.66150975227, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 993288, "time": 45300.08542871475, "episode/length": 300.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 993424, "time": 45306.85412788391, "episode/length": 463.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 993600, "time": 45314.16912436485, "episode/length": 245.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 993632, "time": 45316.8641474247, "episode/length": 426.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 993704, "time": 45320.707847595215, "episode/length": 324.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 993760, "time": 45324.371940374374, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 994224, "time": 45341.186121463776, "episode/length": 57.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 994328, "time": 45345.89852166176, "episode/length": 261.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 994576, "time": 45355.866104364395, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 994936, "time": 45369.33472442627, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 995056, "time": 45375.08998441696, "episode/length": 220.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 995128, "time": 45378.97202205658, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 995272, "time": 45385.28766870499, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 995440, "time": 45392.731171131134, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 996008, "time": 45413.019798994064, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 996136, "time": 45418.81871128082, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 996224, "time": 45423.52963399887, "episode/length": 26.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 996360, "time": 45429.27028465271, "episode/length": 222.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 996704, "time": 45442.598246097565, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 996784, "time": 45446.86987352371, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 996888, "time": 45451.631226062775, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 996976, "time": 45456.258597135544, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 997065, "time": 45461.5641412735, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.347477806939019, "train/action_min": 0.0, "train/action_std": 3.2004419217507043, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0407049321802333, "train/actor_opt_grad_steps": 61505.0, "train/actor_opt_loss": -4.008497555688438, "train/adv_mag": 0.524609966824452, "train/adv_max": 0.47328212795158225, "train/adv_mean": 0.0033183113658247342, "train/adv_min": -0.4389829333457682, "train/adv_std": 0.059782657539471984, "train/cont_avg": 0.9948187934027778, "train/cont_loss_mean": 0.0001380590441387102, "train/cont_loss_std": 0.004060070063637116, "train/cont_neg_acc": 0.992925786309772, "train/cont_neg_loss": 0.011330045299560412, "train/cont_pos_acc": 0.9999795291158888, "train/cont_pos_loss": 7.121538314140234e-05, "train/cont_pred": 0.9948169800142447, "train/cont_rate": 0.9948187934027778, "train/dyn_loss_mean": 12.821615563498604, "train/dyn_loss_std": 8.851994958188799, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.826467826962471, "train/extr_critic_critic_opt_grad_steps": 61505.0, "train/extr_critic_critic_opt_loss": 15749.744974772135, "train/extr_critic_mag": 7.987690230210622, "train/extr_critic_max": 7.987690230210622, "train/extr_critic_mean": 2.3310744952824383, "train/extr_critic_min": -0.15577610747681725, "train/extr_critic_std": 1.724400508734915, "train/extr_return_normed_mag": 1.6100253131654527, "train/extr_return_normed_max": 1.6100253131654527, "train/extr_return_normed_mean": 0.3901725982626279, "train/extr_return_normed_min": -0.12598647120305234, "train/extr_return_normed_std": 0.3207719496761759, "train/extr_return_rate": 0.8540053065452311, "train/extr_return_raw_mag": 9.03615626361635, "train/extr_return_raw_max": 9.03615626361635, "train/extr_return_raw_mean": 2.3492645455731287, "train/extr_return_raw_min": -0.4808330808041824, "train/extr_return_raw_std": 1.7590042518244848, "train/extr_reward_mag": 1.0363763752910826, "train/extr_reward_max": 1.0363763752910826, "train/extr_reward_mean": 0.03937479567765775, "train/extr_reward_min": -0.4348732042643759, "train/extr_reward_std": 0.186233247940739, "train/image_loss_mean": 6.020253313912286, "train/image_loss_std": 11.526443329122332, "train/model_loss_mean": 13.770469506581625, "train/model_loss_std": 15.029572586218515, "train/model_opt_grad_norm": 49.32218215515564, "train/model_opt_grad_steps": 61447.368055555555, "train/model_opt_loss": 17327.61267768012, "train/model_opt_model_opt_grad_overflow": 0.006944444444444444, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.475646495819092, "train/policy_entropy_max": 2.475646495819092, "train/policy_entropy_mean": 0.4866342627339893, "train/policy_entropy_min": 0.07937504263180825, "train/policy_entropy_std": 0.6153492223885324, "train/policy_logprob_mag": 7.438383837540944, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48748567783170277, "train/policy_logprob_min": -7.438383837540944, "train/policy_logprob_std": 1.0547499714626207, "train/policy_randomness_mag": 0.8737945738765929, "train/policy_randomness_max": 0.8737945738765929, "train/policy_randomness_mean": 0.17176053890337548, "train/policy_randomness_min": 0.028015906741428707, "train/policy_randomness_std": 0.21719127355350387, "train/post_ent_mag": 57.88548607296414, "train/post_ent_max": 57.88548607296414, "train/post_ent_mean": 41.66472180684408, "train/post_ent_min": 19.065942578845554, "train/post_ent_std": 7.7339051895671425, "train/prior_ent_mag": 66.3644248644511, "train/prior_ent_max": 66.3644248644511, "train/prior_ent_mean": 54.519415113661026, "train/prior_ent_min": 41.24174042542776, "train/prior_ent_std": 3.9439675642384424, "train/rep_loss_mean": 12.821615563498604, "train/rep_loss_std": 8.851994958188799, "train/reward_avg": 0.028427462973114517, "train/reward_loss_mean": 0.05710889426215241, "train/reward_loss_std": 0.25548158172104096, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0127284990416632, "train/reward_neg_acc": 0.9921735036704276, "train/reward_neg_loss": 0.030265298206359148, "train/reward_pos_acc": 0.9666374371283584, "train/reward_pos_loss": 0.8495511644416385, "train/reward_pred": 0.027576966967899352, "train/reward_rate": 0.032999674479166664, "train_stats/sum_log_reward": 8.814285948568461, "train_stats/max_log_achievement_collect_coal": 0.46938775510204084, "train_stats/max_log_achievement_collect_drink": 5.13265306122449, "train_stats/max_log_achievement_collect_sapling": 2.0510204081632653, "train_stats/max_log_achievement_collect_stone": 4.612244897959184, "train_stats/max_log_achievement_collect_wood": 14.255102040816327, "train_stats/max_log_achievement_defeat_skeleton": 0.061224489795918366, "train_stats/max_log_achievement_defeat_zombie": 1.4795918367346939, "train_stats/max_log_achievement_eat_cow": 0.336734693877551, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.01020408163265306, "train_stats/max_log_achievement_make_wood_pickaxe": 2.204081632653061, "train_stats/max_log_achievement_make_wood_sword": 1.2244897959183674, "train_stats/max_log_achievement_place_furnace": 0.030612244897959183, "train_stats/max_log_achievement_place_plant": 1.9489795918367347, "train_stats/max_log_achievement_place_stone": 0.07142857142857142, "train_stats/max_log_achievement_place_table": 3.9489795918367347, "train_stats/max_log_achievement_wake_up": 1.3979591836734695, "train_stats/mean_log_entropy": 0.5015291941105103, "eval_stats/sum_log_reward": 7.9125001430511475, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 2.5, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5625, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.791663741343655e-06, "report/cont_loss_std": 4.7842622734606266e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020200070866849273, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.4342754133831477e-06, "report/cont_pred": 0.9931620359420776, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.997328758239746, "report/dyn_loss_std": 8.450801849365234, "report/image_loss_mean": 4.99889612197876, "report/image_loss_std": 9.178457260131836, "report/model_loss_mean": 12.25912857055664, "report/model_loss_std": 12.708776473999023, "report/post_ent_mag": 57.266048431396484, "report/post_ent_max": 57.266048431396484, "report/post_ent_mean": 42.060157775878906, "report/post_ent_min": 19.15764045715332, "report/post_ent_std": 7.214890003204346, "report/prior_ent_mag": 66.2155532836914, "report/prior_ent_max": 66.2155532836914, "report/prior_ent_mean": 54.09314727783203, "report/prior_ent_min": 41.62665939331055, "report/prior_ent_std": 4.054197788238525, "report/rep_loss_mean": 11.997328758239746, "report/rep_loss_std": 8.450801849365234, "report/reward_avg": 0.02734375, "report/reward_loss_mean": 0.061830490827560425, "report/reward_loss_std": 0.32066455483436584, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0006370544433594, "report/reward_neg_acc": 0.9919273257255554, "report/reward_neg_loss": 0.034704145044088364, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.8764427304267883, "report/reward_pred": 0.027029266580939293, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.4420493243960664e-05, "eval/cont_loss_std": 0.0002376237971475348, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0009471543016843498, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.843782208918128e-06, "eval/cont_pred": 0.9951120615005493, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.681598663330078, "eval/dyn_loss_std": 10.312846183776855, "eval/image_loss_mean": 9.97144889831543, "eval/image_loss_std": 15.480029106140137, "eval/model_loss_mean": 20.099613189697266, "eval/model_loss_std": 19.63559341430664, "eval/post_ent_mag": 57.57781219482422, "eval/post_ent_max": 57.57781219482422, "eval/post_ent_mean": 39.76222229003906, "eval/post_ent_min": 18.41812515258789, "eval/post_ent_std": 7.830320358276367, "eval/prior_ent_mag": 66.2155532836914, "eval/prior_ent_max": 66.2155532836914, "eval/prior_ent_mean": 54.407958984375, "eval/prior_ent_min": 41.63392639160156, "eval/prior_ent_std": 4.0836639404296875, "eval/rep_loss_mean": 16.681598663330078, "eval/rep_loss_std": 10.312846183776855, "eval/reward_avg": 0.03183593600988388, "eval/reward_loss_mean": 0.11919283866882324, "eval/reward_loss_std": 0.6401235461235046, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012259483337402, "eval/reward_neg_acc": 0.976673424243927, "eval/reward_neg_loss": 0.06829168647527695, "eval/reward_pos_acc": 0.8947368264198303, "eval/reward_pos_loss": 1.4399436712265015, "eval/reward_pred": 0.03763331100344658, "eval/reward_rate": 0.037109375, "replay/size": 996561.0, "replay/inserts": 23040.0, "replay/samples": 23040.0, "replay/insert_wait_avg": 1.371186226606369e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.485556933614943e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1715638279403227e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0839407444, "timer/env.step_count": 2880.0, "timer/env.step_total": 236.329119682312, "timer/env.step_frac": 0.23630928370512916, "timer/env.step_avg": 0.0820587221119139, "timer/env.step_min": 0.023061037063598633, "timer/env.step_max": 3.3865442276000977, "timer/replay._sample_count": 23040.0, "timer/replay._sample_total": 11.638738870620728, "timer/replay._sample_frac": 0.011637761988216287, "timer/replay._sample_avg": 0.0005051535968151358, "timer/replay._sample_min": 0.0004112720489501953, "timer/replay._sample_max": 0.009793996810913086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3346.0, "timer/agent.policy_total": 55.697901010513306, "timer/agent.policy_frac": 0.05569322607965814, "timer/agent.policy_avg": 0.01664611506590356, "timer/agent.policy_min": 0.009355306625366211, "timer/agent.policy_max": 0.1215972900390625, "timer/dataset_train_count": 1440.0, "timer/dataset_train_total": 0.157501220703125, "timer/dataset_train_frac": 0.00015748800104308338, "timer/dataset_train_avg": 0.00010937584771050347, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0002980232238769531, "timer/agent.train_count": 1440.0, "timer/agent.train_total": 641.5764307975769, "timer/agent.train_frac": 0.6415225809145855, "timer/agent.train_avg": 0.4455391880538728, "timer/agent.train_min": 0.43350744247436523, "timer/agent.train_max": 1.6076269149780273, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47243332862854004, "timer/agent.report_frac": 0.00047239367555176436, "timer/agent.report_avg": 0.23621666431427002, "timer/agent.report_min": 0.23118901252746582, "timer/agent.report_max": 0.24124431610107422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7415835291057007e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 23.03776917842}
{"step": 997096, "time": 45462.309329748154, "episode/length": 206.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 997864, "time": 45489.523143053055, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 997912, "time": 45492.6845369339, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 997944, "time": 45495.30579614639, "episode/length": 154.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 998288, "time": 45508.54838323593, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 998416, "time": 45514.393157958984, "episode/length": 164.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 998448, "time": 45517.03916096687, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 998568, "time": 45522.29273724556, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 998760, "time": 45530.312309503555, "episode/length": 105.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 998768, "time": 45532.48739385605, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 999320, "time": 45551.99529957771, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 999760, "time": 45570.358038425446, "episode/length": 226.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 999856, "time": 45577.39888381958, "episode/length": 179.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 999888, "time": 45579.90061378479, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45604.67938041687, "eval_episode/length": 105.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9905660377358491}
{"step": 1000064, "time": 45608.20849323273, "eval_episode/length": 151.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9802631578947368}
{"step": 1000064, "time": 45611.44157361984, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 1000064, "time": 45613.66971158981, "eval_episode/length": 205.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 1000064, "time": 45615.66916203499, "eval_episode/length": 213.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 1000064, "time": 45617.561166763306, "eval_episode/length": 221.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 1000064, "time": 45619.60535693169, "eval_episode/length": 228.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 1000064, "time": 45621.54292392731, "eval_episode/length": 130.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9618320610687023}
{"step": 1000128, "time": 45623.68646526337, "episode/length": 209.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1000368, "time": 45633.05870485306, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1000664, "time": 45644.233696460724, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 1000784, "time": 45650.01007604599, "episode/length": 311.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 1000896, "time": 45655.14376759529, "episode/length": 196.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1001456, "time": 45675.23107933998, "episode/length": 199.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1001592, "time": 45681.1025121212, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1001640, "time": 45684.24449253082, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1001760, "time": 45690.119878053665, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1002024, "time": 45700.323657274246, "episode/length": 169.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1002632, "time": 45722.77535367012, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1002688, "time": 45726.47823762894, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1003096, "time": 45741.37282514572, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1003112, "time": 45743.47452402115, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 1003304, "time": 45751.516820669174, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1003328, "time": 45754.11442041397, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 1004128, "time": 45782.21773099899, "episode/length": 333.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 1004680, "time": 45802.214797735214, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 1004696, "time": 45804.74356627464, "episode/length": 257.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1005008, "time": 45817.657995700836, "episode/length": 579.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 1005056, "time": 45820.784123659134, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1005088, "time": 45823.388855457306, "episode/length": 48.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 1005216, "time": 45829.25432634354, "episode/length": 264.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.969811320754717, "episode/intrinsic_return": 0.0}
{"step": 1005768, "time": 45848.93359589577, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1005904, "time": 45855.218148231506, "episode/length": 111.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 1006152, "time": 45864.87870144844, "episode/length": 432.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 1006256, "time": 45870.14152479172, "episode/length": 196.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 1006296, "time": 45872.82598686218, "episode/length": 134.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 1006344, "time": 45876.01039528847, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1006416, "time": 45880.23625874519, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 1006624, "time": 45888.811646938324, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1006912, "time": 45899.97369337082, "episode/length": 231.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1006928, "time": 45902.00447154045, "episode/length": 452.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 1007512, "time": 45922.80243444443, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 1007688, "time": 45931.74315047264, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 1008104, "time": 45947.05693125725, "episode/length": 210.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1008312, "time": 45955.67527461052, "episode/length": 269.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1008480, "time": 45963.04956030846, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 1008664, "time": 45970.53638124466, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1008784, "time": 45976.452704668045, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 1009384, "time": 45997.66314673424, "episode/length": 211.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1009736, "time": 46010.92692708969, "episode/length": 388.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 1009848, "time": 46016.28928613663, "episode/length": 437.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1009888, "time": 46019.48241662979, "episode/length": 222.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 46046.8883099556, "eval_episode/length": 178.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 1010048, "time": 46048.652443647385, "eval_episode/length": 183.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 1010048, "time": 46050.35503792763, "eval_episode/length": 186.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 1010048, "time": 46052.919496297836, "eval_episode/length": 212.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 1010048, "time": 46054.75708293915, "eval_episode/length": 218.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 1010048, "time": 46058.56964826584, "eval_episode/length": 272.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1010048, "time": 46061.72684454918, "eval_episode/length": 311.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9839743589743589}
{"step": 1010048, "time": 46063.33339834213, "eval_episode/length": 99.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.99}
{"step": 1010056, "time": 46063.38665151596, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1010112, "time": 46067.0222992897, "episode/length": 27.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 1010192, "time": 46071.35245037079, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 1010424, "time": 46080.37295150757, "episode/length": 38.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1010912, "time": 46098.39032483101, "episode/length": 190.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1010920, "time": 46100.1339161396, "episode/length": 325.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 1011320, "time": 46114.97180104256, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1011800, "time": 46132.60802149773, "episode/length": 243.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 1011848, "time": 46135.88787460327, "episode/length": 223.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1012200, "time": 46148.94831228256, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1012352, "time": 46155.62595009804, "episode/length": 269.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1012472, "time": 46161.17731285095, "episode/length": 255.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1013088, "time": 46183.34577345848, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1013168, "time": 46187.39657306671, "episode/length": 562.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9982238010657194, "episode/intrinsic_return": 0.0}
{"step": 1013320, "time": 46193.91777300835, "episode/length": 249.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1013424, "time": 46199.0761320591, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1013776, "time": 46212.32106566429, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 1013896, "time": 46217.560109615326, "episode/length": 372.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9839142091152815, "episode/intrinsic_return": 0.0}
{"step": 1014328, "time": 46233.55603694916, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 1014536, "time": 46241.97094535828, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 1014816, "time": 46252.94975090027, "episode/length": 376.0, "episode/score": 9.10000005364418, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 1014912, "time": 46257.67672538757, "episode/length": 185.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1015136, "time": 46266.64787840843, "episode/length": 245.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1015200, "time": 46270.39486575127, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1015408, "time": 46278.94814705849, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1015608, "time": 46286.876242399216, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 1015864, "time": 46298.59453654289, "episode/length": 191.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1016208, "time": 46311.99624466896, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 1016608, "time": 46326.80996751785, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 1017096, "time": 46344.34049463272, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 1017096, "time": 46344.348860025406, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1017320, "time": 46355.150210380554, "episode/length": 264.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1017680, "time": 46368.9832303524, "episode/length": 226.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1018056, "time": 46382.77445745468, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 1018224, "time": 46390.16038441658, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1018360, "time": 46395.94091320038, "episode/length": 442.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9841986455981941, "episode/intrinsic_return": 0.0}
{"step": 1018848, "time": 46414.0107896328, "episode/length": 463.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9978448275862069, "episode/intrinsic_return": 0.0}
{"step": 1018888, "time": 46416.66648840904, "episode/length": 223.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1018952, "time": 46420.385524988174, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1019328, "time": 46434.617300748825, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 1019840, "time": 46453.11480665207, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 1019848, "time": 46454.75709104538, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 1019977, "time": 46461.64627599716, "train_stats/sum_log_reward": 8.620000237226487, "train_stats/max_log_achievement_collect_coal": 0.43, "train_stats/max_log_achievement_collect_drink": 6.24, "train_stats/max_log_achievement_collect_sapling": 1.87, "train_stats/max_log_achievement_collect_stone": 4.82, "train_stats/max_log_achievement_collect_wood": 12.21, "train_stats/max_log_achievement_defeat_skeleton": 0.03, "train_stats/max_log_achievement_defeat_zombie": 1.53, "train_stats/max_log_achievement_eat_cow": 0.3, "train_stats/max_log_achievement_eat_plant": 0.01, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.71, "train_stats/max_log_achievement_make_wood_sword": 1.2, "train_stats/max_log_achievement_place_furnace": 0.03, "train_stats/max_log_achievement_place_plant": 1.78, "train_stats/max_log_achievement_place_stone": 0.05, "train_stats/max_log_achievement_place_table": 3.44, "train_stats/max_log_achievement_wake_up": 1.27, "train_stats/mean_log_entropy": 0.4847815455496311, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3274433696186625, "train/action_min": 0.0, "train/action_std": 3.17805757389202, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.040186010926336675, "train/actor_opt_grad_steps": 62940.0, "train/actor_opt_loss": -3.2445837163685503, "train/adv_mag": 0.5272575954457263, "train/adv_max": 0.4838135073651801, "train/adv_mean": 0.0032374631414218225, "train/adv_min": -0.4208514629960894, "train/adv_std": 0.05830580952180015, "train/cont_avg": 0.9951718203671329, "train/cont_loss_mean": 0.00014572491324099462, "train/cont_loss_std": 0.004104321423926888, "train/cont_neg_acc": 0.9972054559580037, "train/cont_neg_loss": 0.010930404227328324, "train/cont_pos_acc": 0.999972510587919, "train/cont_pos_loss": 8.634928595682226e-05, "train/cont_pred": 0.9951583172057892, "train/cont_rate": 0.9951718203671329, "train/dyn_loss_mean": 12.717145459635274, "train/dyn_loss_std": 8.801739079135281, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8427791295351682, "train/extr_critic_critic_opt_grad_steps": 62940.0, "train/extr_critic_critic_opt_loss": 15677.62704190341, "train/extr_critic_mag": 8.022482345154236, "train/extr_critic_max": 8.022482345154236, "train/extr_critic_mean": 2.376076355680719, "train/extr_critic_min": -0.15504948659376663, "train/extr_critic_std": 1.7203102261870058, "train/extr_return_normed_mag": 1.601190763753611, "train/extr_return_normed_max": 1.601190763753611, "train/extr_return_normed_mean": 0.39129072656998265, "train/extr_return_normed_min": -0.12246878447753566, "train/extr_return_normed_std": 0.3152514034426296, "train/extr_return_rate": 0.8635576467414002, "train/extr_return_raw_mag": 9.119038171701497, "train/extr_return_raw_max": 9.119038171701497, "train/extr_return_raw_mean": 2.3940594829879442, "train/extr_return_raw_min": -0.46170341395414793, "train/extr_return_raw_std": 1.7524427950799049, "train/extr_reward_mag": 1.0361533565121097, "train/extr_reward_max": 1.0361533565121097, "train/extr_reward_mean": 0.03879931795742962, "train/extr_reward_min": -0.43512554685552635, "train/extr_reward_std": 0.18509656805675345, "train/image_loss_mean": 5.877749376363687, "train/image_loss_std": 10.566970301674797, "train/model_loss_mean": 13.564479454413995, "train/model_loss_std": 14.096917132397632, "train/model_opt_grad_norm": 51.93981881208823, "train/model_opt_grad_steps": 62881.08391608392, "train/model_opt_loss": 19037.502458479023, "train/model_opt_model_opt_grad_overflow": 0.006993006993006993, "train/model_opt_model_opt_grad_scale": 1398.6013986013986, "train/policy_entropy_mag": 2.479108521988342, "train/policy_entropy_max": 2.479108521988342, "train/policy_entropy_mean": 0.47879555779737193, "train/policy_entropy_min": 0.07937504366769657, "train/policy_entropy_std": 0.5933886034922167, "train/policy_logprob_mag": 7.438383812670941, "train/policy_logprob_max": -0.009455660045459554, "train/policy_logprob_mean": -0.47703180571536086, "train/policy_logprob_min": -7.438383812670941, "train/policy_logprob_std": 1.0447186181595276, "train/policy_randomness_mag": 0.8750165150715754, "train/policy_randomness_max": 0.8750165150715754, "train/policy_randomness_mean": 0.16899382093778023, "train/policy_randomness_min": 0.02801590708533784, "train/policy_randomness_std": 0.209440139206973, "train/post_ent_mag": 58.004827085908474, "train/post_ent_max": 58.004827085908474, "train/post_ent_mean": 41.79536336618703, "train/post_ent_min": 19.25165563863474, "train/post_ent_std": 7.810606342929226, "train/prior_ent_mag": 66.36271112615412, "train/prior_ent_max": 66.36271112615412, "train/prior_ent_mean": 54.57882490358153, "train/prior_ent_min": 41.068082636052914, "train/prior_ent_std": 3.922047236582616, "train/rep_loss_mean": 12.717145459635274, "train/rep_loss_std": 8.801739079135281, "train/reward_avg": 0.029518138037642815, "train/reward_loss_mean": 0.05629716803143908, "train/reward_loss_std": 0.24277170533900494, "train/reward_max_data": 1.0174825216506744, "train/reward_max_pred": 1.0126616988148722, "train/reward_neg_acc": 0.992756545126855, "train/reward_neg_loss": 0.029528471602166033, "train/reward_pos_acc": 0.9710863941199296, "train/reward_pos_loss": 0.8203215678255041, "train/reward_pred": 0.028662350478132703, "train/reward_rate": 0.033872377622377624, "eval_stats/sum_log_reward": 8.537500023841858, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 5.6875, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 3.875, "eval_stats/max_log_achievement_collect_wood": 11.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.355889243219281e-06, "report/cont_loss_std": 7.512012962251902e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005740692722611129, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.778308142609603e-07, "report/cont_pred": 0.9921911954879761, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.280326843261719, "report/dyn_loss_std": 9.40839958190918, "report/image_loss_mean": 6.293844223022461, "report/image_loss_std": 10.588826179504395, "report/model_loss_mean": 14.31879711151123, "report/model_loss_std": 14.463884353637695, "report/post_ent_mag": 59.801292419433594, "report/post_ent_max": 59.801292419433594, "report/post_ent_mean": 41.846649169921875, "report/post_ent_min": 20.07379913330078, "report/post_ent_std": 8.24612808227539, "report/prior_ent_mag": 66.29065704345703, "report/prior_ent_max": 66.29065704345703, "report/prior_ent_mean": 54.861907958984375, "report/prior_ent_min": 42.94342041015625, "report/prior_ent_std": 4.328296184539795, "report/rep_loss_mean": 13.280326843261719, "report/rep_loss_std": 9.40839958190918, "report/reward_avg": 0.02900390326976776, "report/reward_loss_mean": 0.05675148963928223, "report/reward_loss_std": 0.2236129641532898, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015616416931152, "report/reward_neg_acc": 0.9979757070541382, "report/reward_neg_loss": 0.03066735714673996, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.772615909576416, "report/reward_pred": 0.027155902236700058, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.1161408792759175e-06, "eval/cont_loss_std": 1.496418371971231e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00024151515390258282, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.0977735693559225e-07, "eval/cont_pred": 0.9970706701278687, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.02971649169922, "eval/dyn_loss_std": 10.48373031616211, "eval/image_loss_mean": 9.823673248291016, "eval/image_loss_std": 12.825674057006836, "eval/model_loss_mean": 20.726394653320312, "eval/model_loss_std": 16.922527313232422, "eval/post_ent_mag": 57.77146911621094, "eval/post_ent_max": 57.77146911621094, "eval/post_ent_mean": 38.87135696411133, "eval/post_ent_min": 20.17108917236328, "eval/post_ent_std": 7.874259948730469, "eval/prior_ent_mag": 66.29065704345703, "eval/prior_ent_max": 66.29065704345703, "eval/prior_ent_mean": 54.30658721923828, "eval/prior_ent_min": 43.31288146972656, "eval/prior_ent_std": 3.8071341514587402, "eval/rep_loss_mean": 18.02971649169922, "eval/rep_loss_std": 10.48373031616211, "eval/reward_avg": 0.03242187201976776, "eval/reward_loss_mean": 0.08488945662975311, "eval/reward_loss_std": 0.4972873628139496, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0585007667541504, "eval/reward_neg_acc": 0.991894543170929, "eval/reward_neg_loss": 0.036884091794490814, "eval/reward_pos_acc": 0.8918918371200562, "eval/reward_pos_loss": 1.365464687347412, "eval/reward_pred": 0.03023347072303295, "eval/reward_rate": 0.0361328125, "replay/size": 1000000.0, "replay/inserts": 22912.0, "replay/samples": 22912.0, "replay/insert_wait_avg": 1.3394291673958635e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.260882155189301e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1626156893643465e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0621552467346, "timer/env.step_count": 2864.0, "timer/env.step_total": 236.74823665618896, "timer/env.step_frac": 0.23673352242569223, "timer/env.step_avg": 0.08266349045257995, "timer/env.step_min": 0.02290511131286621, "timer/env.step_max": 3.3783044815063477, "timer/replay._sample_count": 22912.0, "timer/replay._sample_total": 11.471178770065308, "timer/replay._sample_frac": 0.011470465820432077, "timer/replay._sample_avg": 0.0005006624812353923, "timer/replay._sample_min": 0.00042057037353515625, "timer/replay._sample_max": 0.025082111358642578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3414.0, "timer/agent.policy_total": 54.97337508201599, "timer/agent.policy_frac": 0.05496995841068798, "timer/agent.policy_avg": 0.01610233599356063, "timer/agent.policy_min": 0.00943613052368164, "timer/agent.policy_max": 0.09193825721740723, "timer/dataset_train_count": 1432.0, "timer/dataset_train_total": 0.15574097633361816, "timer/dataset_train_frac": 0.00015573129681644023, "timer/dataset_train_avg": 0.00010875766503744286, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004849433898925781, "timer/agent.train_count": 1432.0, "timer/agent.train_total": 640.0954616069794, "timer/agent.train_frac": 0.6400556787883404, "timer/agent.train_avg": 0.44699403743504146, "timer/agent.train_min": 0.43299150466918945, "timer/agent.train_max": 2.7422873973846436, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789159297943115, "timer/agent.report_frac": 0.0004788861645065988, "timer/agent.report_avg": 0.23945796489715576, "timer/agent.report_min": 0.23336005210876465, "timer/agent.report_max": 0.24555587768554688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003887389317841e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 22.910270738586956}
